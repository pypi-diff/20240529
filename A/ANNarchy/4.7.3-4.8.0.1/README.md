# Comparing `tmp/ANNarchy-4.7.3.tar.gz` & `tmp/annarchy-4.8.0.1.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "ANNarchy-4.7.3.tar", last modified: Thu Mar 21 20:45:45 2024, max compression
+gzip compressed data, was "annarchy-4.8.0.1.tar", last modified: Wed May 29 12:35:07 2024, max compression
```

## Comparing `ANNarchy-4.7.3.tar` & `annarchy-4.8.0.1.tar`

### file list

```diff
@@ -1,275 +1,241 @@
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.816075 ANNarchy-4.7.3/
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.779308 ANNarchy-4.7.3/ANNarchy/
--rw-r--r--   0 vitay      (501) staff       (20)     2110 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/__init__.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.783032 ANNarchy-4.7.3/ANNarchy/core/
--rw-r--r--   0 vitay      (501) staff       (20)    27239 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/core/ConnectorMethods.py
--rw-r--r--   0 vitay      (501) staff       (20)    15318 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/core/Dendrite.py
--rw-r--r--   0 vitay      (501) staff       (20)    29064 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/core/Global.py
--rw-r--r--   0 vitay      (501) staff       (20)    19962 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/core/IO.py
--rw-r--r--   0 vitay      (501) staff       (20)    37599 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/core/Monitor.py
--rw-r--r--   0 vitay      (501) staff       (20)    33705 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/core/Network.py
--rw-r--r--   0 vitay      (501) staff       (20)     7023 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/core/NetworkManager.py
--rw-r--r--   0 vitay      (501) staff       (20)     7515 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/core/Neuron.py
--rw-r--r--   0 vitay      (501) staff       (20)    32486 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/core/Population.py
--rw-r--r--   0 vitay      (501) staff       (20)    11893 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/core/PopulationView.py
--rw-r--r--   0 vitay      (501) staff       (20)     6525 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/core/Profiler.py
--rw-r--r--   0 vitay      (501) staff       (20)    65839 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/core/Projection.py
--rw-r--r--   0 vitay      (501) staff       (20)     8324 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/core/Random.py
--rw-r--r--   0 vitay      (501) staff       (20)     9223 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/core/Simulate.py
--rw-r--r--   0 vitay      (501) staff       (20)    98277 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/core/SpecificPopulation.py
--rw-r--r--   0 vitay      (501) staff       (20)    14568 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/core/SpecificProjection.py
--rw-r--r--   0 vitay      (501) staff       (20)     4871 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/core/Synapse.py
--rw-r--r--   0 vitay      (501) staff       (20)     3789 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/core/Utils.py
--rw-r--r--   0 vitay      (501) staff       (20)        1 2019-07-10 20:15:51.000000 ANNarchy-4.7.3/ANNarchy/core/__init__.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.783840 ANNarchy-4.7.3/ANNarchy/core/cython_ext/
--rw-r--r--   0 vitay      (501) staff       (20)     1683 2022-05-18 09:30:59.000000 ANNarchy-4.7.3/ANNarchy/core/cython_ext/Connector.pxd
--rw-r--r--   0 vitay      (501) staff       (20)    21582 2022-12-14 10:27:19.000000 ANNarchy-4.7.3/ANNarchy/core/cython_ext/Connector.pyx
--rw-r--r--   0 vitay      (501) staff       (20)      924 2017-07-25 21:21:04.000000 ANNarchy-4.7.3/ANNarchy/core/cython_ext/Coordinates.pxd
--rw-r--r--   0 vitay      (501) staff       (20)     4941 2022-01-07 10:51:43.000000 ANNarchy-4.7.3/ANNarchy/core/cython_ext/Coordinates.pyx
--rw-r--r--   0 vitay      (501) staff       (20)     2866 2022-02-02 12:38:23.000000 ANNarchy-4.7.3/ANNarchy/core/cython_ext/Transformations.pyx
--rw-r--r--   0 vitay      (501) staff       (20)        0 2020-05-31 10:28:52.000000 ANNarchy-4.7.3/ANNarchy/core/cython_ext/__init__.pxd
--rw-r--r--   0 vitay      (501) staff       (20)      405 2020-03-10 16:42:34.000000 ANNarchy-4.7.3/ANNarchy/core/cython_ext/__init__.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.783956 ANNarchy-4.7.3/ANNarchy/extensions/
--rw-r--r--   0 vitay      (501) staff       (20)       21 2017-07-25 21:21:04.000000 ANNarchy-4.7.3/ANNarchy/extensions/__init__.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.784409 ANNarchy-4.7.3/ANNarchy/extensions/ann_to_snn_conversion/
--rw-r--r--   0 vitay      (501) staff       (20)    23580 2024-03-21 20:38:39.000000 ANNarchy-4.7.3/ANNarchy/extensions/ann_to_snn_conversion/ANNtoSNNConverter.py
--rw-r--r--   0 vitay      (501) staff       (20)     2736 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/ann_to_snn_conversion/InputEncoding.py
--rw-r--r--   0 vitay      (501) staff       (20)     1719 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/ann_to_snn_conversion/ReadOut.py
--rw-r--r--   0 vitay      (501) staff       (20)       48 2022-12-14 10:27:19.000000 ANNarchy-4.7.3/ANNarchy/extensions/ann_to_snn_conversion/__init__.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.785326 ANNarchy-4.7.3/ANNarchy/extensions/bold/
--rw-r--r--   0 vitay      (501) staff       (20)    12317 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/bold/AccProjection.py
--rw-r--r--   0 vitay      (501) staff       (20)     2012 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/bold/BoldModel.py
--rw-r--r--   0 vitay      (501) staff       (20)     9517 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/bold/BoldMonitor.py
--rw-r--r--   0 vitay      (501) staff       (20)    14234 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/bold/NormProjection.py
--rw-r--r--   0 vitay      (501) staff       (20)    26965 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/bold/PredefinedModels.py
--rw-r--r--   0 vitay      (501) staff       (20)      386 2021-10-01 13:31:48.000000 ANNarchy-4.7.3/ANNarchy/extensions/bold/__init__.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.786719 ANNarchy-4.7.3/ANNarchy/extensions/convolution/
--rw-r--r--   0 vitay      (501) staff       (20)    52492 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/convolution/Convolve.py
--rw-r--r--   0 vitay      (501) staff       (20)    15470 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/convolution/ConvolveTemplate.py
--rw-r--r--   0 vitay      (501) staff       (20)     8523 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/convolution/Copy.py
--rw-r--r--   0 vitay      (501) staff       (20)     3574 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/convolution/CopyTemplate.py
--rw-r--r--   0 vitay      (501) staff       (20)    24843 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/convolution/Pooling.py
--rw-r--r--   0 vitay      (501) staff       (20)    14205 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/convolution/PoolingTemplate.py
--rw-r--r--   0 vitay      (501) staff       (20)    13197 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/convolution/Transpose.py
--rw-r--r--   0 vitay      (501) staff       (20)      667 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/convolution/Utils.py
--rw-r--r--   0 vitay      (501) staff       (20)      858 2021-10-01 13:31:48.000000 ANNarchy-4.7.3/ANNarchy/extensions/convolution/__init__.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.787046 ANNarchy-4.7.3/ANNarchy/extensions/diagonal/
--rw-r--r--   0 vitay      (501) staff       (20)    15604 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/diagonal/DiagonalProjection.py
--rw-r--r--   0 vitay      (501) staff       (20)       50 2017-07-25 21:21:04.000000 ANNarchy-4.7.3/ANNarchy/extensions/diagonal/__init__.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.787316 ANNarchy-4.7.3/ANNarchy/extensions/hybrid/
--rw-r--r--   0 vitay      (501) staff       (20)    20879 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/hybrid/HybridPopulation.py
--rw-r--r--   0 vitay      (501) staff       (20)       72 2017-07-25 21:21:04.000000 ANNarchy-4.7.3/ANNarchy/extensions/hybrid/__init__.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.787594 ANNarchy-4.7.3/ANNarchy/extensions/image/
--rw-r--r--   0 vitay      (501) staff       (20)    10042 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/image/ImagePopulation.py
--rw-r--r--   0 vitay      (501) staff       (20)       62 2017-07-25 21:21:04.000000 ANNarchy-4.7.3/ANNarchy/extensions/image/__init__.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.787859 ANNarchy-4.7.3/ANNarchy/extensions/tensorboard/
--rw-r--r--   0 vitay      (501) staff       (20)    11806 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/extensions/tensorboard/Logger.py
--rw-r--r--   0 vitay      (501) staff       (20)       26 2020-05-31 10:28:52.000000 ANNarchy-4.7.3/ANNarchy/extensions/tensorboard/__init__.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.789221 ANNarchy-4.7.3/ANNarchy/generator/
--rw-r--r--   0 vitay      (501) staff       (20)     4246 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/CmdLineArgParser.py
--rw-r--r--   0 vitay      (501) staff       (20)    42263 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/CodeGenerator.py
--rw-r--r--   0 vitay      (501) staff       (20)    35038 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Compiler.py
--rw-r--r--   0 vitay      (501) staff       (20)     9739 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/MonitorGenerator.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.790515 ANNarchy-4.7.3/ANNarchy/generator/Population/
--rw-r--r--   0 vitay      (501) staff       (20)    61986 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Population/CUDAGenerator.py
--rw-r--r--   0 vitay      (501) staff       (20)    26957 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Population/CUDATemplates.py
--rw-r--r--   0 vitay      (501) staff       (20)    41084 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Population/OpenMPGenerator.py
--rw-r--r--   0 vitay      (501) staff       (20)    13693 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Population/OpenMPTemplates.py
--rw-r--r--   0 vitay      (501) staff       (20)    22078 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Population/PopulationGenerator.py
--rw-r--r--   0 vitay      (501) staff       (20)    35611 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Population/SingleThreadGenerator.py
--rw-r--r--   0 vitay      (501) staff       (20)    12637 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Population/SingleThreadTemplates.py
--rw-r--r--   0 vitay      (501) staff       (20)      142 2021-10-01 13:31:48.000000 ANNarchy-4.7.3/ANNarchy/generator/Population/__init__.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.791424 ANNarchy-4.7.3/ANNarchy/generator/Profile/
--rw-r--r--   0 vitay      (501) staff       (20)    13953 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Profile/CPP11Profile.py
--rw-r--r--   0 vitay      (501) staff       (20)     7717 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Profile/CUDAProfile.py
--rw-r--r--   0 vitay      (501) staff       (20)     6034 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Profile/PAPIProfile.py
--rw-r--r--   0 vitay      (501) staff       (20)     3013 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Profile/ProfileGenerator.py
--rw-r--r--   0 vitay      (501) staff       (20)    30855 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Profile/ProfileTemplate.py
--rw-r--r--   0 vitay      (501) staff       (20)      159 2020-03-10 16:42:34.000000 ANNarchy-4.7.3/ANNarchy/generator/Profile/__init__.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.792153 ANNarchy-4.7.3/ANNarchy/generator/Projection/
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.794459 ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/
--rw-r--r--   0 vitay      (501) staff       (20)    14586 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/BSR.py
--rw-r--r--   0 vitay      (501) staff       (20)    10177 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/BaseTemplates.py
--rw-r--r--   0 vitay      (501) staff       (20)    10168 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/COO.py
--rw-r--r--   0 vitay      (501) staff       (20)    39116 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/CSR.py
--rw-r--r--   0 vitay      (501) staff       (20)    12622 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/CSR_Scalar.py
--rw-r--r--   0 vitay      (501) staff       (20)    12463 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/CSR_T.py
--rw-r--r--   0 vitay      (501) staff       (20)    14801 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/CSR_Vector.py
--rw-r--r--   0 vitay      (501) staff       (20)    23959 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/Dense.py
--rw-r--r--   0 vitay      (501) staff       (20)    10907 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/Dense_T.py
--rw-r--r--   0 vitay      (501) staff       (20)    15625 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/ELL.py
--rw-r--r--   0 vitay      (501) staff       (20)    16792 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/ELLR.py
--rw-r--r--   0 vitay      (501) staff       (20)     7469 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/HYB.py
--rw-r--r--   0 vitay      (501) staff       (20)    10200 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/SELL.py
--rw-r--r--   0 vitay      (501) staff       (20)     1514 2022-12-14 10:27:19.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/__init__.py
--rw-r--r--   0 vitay      (501) staff       (20)    77558 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDAGenerator.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.796798 ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/
--rw-r--r--   0 vitay      (501) staff       (20)     7967 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/BSR.py
--rw-r--r--   0 vitay      (501) staff       (20)    11951 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/BaseTemplates.py
--rw-r--r--   0 vitay      (501) staff       (20)     2783 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/COO.py
--rw-r--r--   0 vitay      (501) staff       (20)    36651 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/CSR.py
--rw-r--r--   0 vitay      (501) staff       (20)     7563 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/CSR_P.py
--rw-r--r--   0 vitay      (501) staff       (20)     7248 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/CSR_T.py
--rw-r--r--   0 vitay      (501) staff       (20)     5992 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/CSR_T_P.py
--rw-r--r--   0 vitay      (501) staff       (20)    18305 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/Dense.py
--rw-r--r--   0 vitay      (501) staff       (20)     3879 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/Dense_T.py
--rw-r--r--   0 vitay      (501) staff       (20)     7888 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/ELL.py
--rw-r--r--   0 vitay      (501) staff       (20)     4239 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/ELLR.py
--rw-r--r--   0 vitay      (501) staff       (20)    50636 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/LIL.py
--rw-r--r--   0 vitay      (501) staff       (20)    22029 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/LIL_P.py
--rw-r--r--   0 vitay      (501) staff       (20)     3989 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/SELL.py
--rw-r--r--   0 vitay      (501) staff       (20)     1565 2022-12-14 10:27:19.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/__init__.py
--rw-r--r--   0 vitay      (501) staff       (20)    62306 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMPGenerator.py
--rw-r--r--   0 vitay      (501) staff       (20)    51285 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/ProjectionGenerator.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.799055 ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/
--rw-r--r--   0 vitay      (501) staff       (20)    18307 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/BSR.py
--rw-r--r--   0 vitay      (501) staff       (20)    11646 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/BaseTemplates.py
--rw-r--r--   0 vitay      (501) staff       (20)     2542 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/COO.py
--rw-r--r--   0 vitay      (501) staff       (20)    36733 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/CSR.py
--rw-r--r--   0 vitay      (501) staff       (20)     6419 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/CSR_T.py
--rw-r--r--   0 vitay      (501) staff       (20)    16946 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/Dense.py
--rw-r--r--   0 vitay      (501) staff       (20)     3571 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/Dense_PV.py
--rw-r--r--   0 vitay      (501) staff       (20)     3848 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/Dense_PV_T.py
--rw-r--r--   0 vitay      (501) staff       (20)     5288 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/Dense_T.py
--rw-r--r--   0 vitay      (501) staff       (20)     7717 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/ELL.py
--rw-r--r--   0 vitay      (501) staff       (20)    16164 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/ELLR.py
--rw-r--r--   0 vitay      (501) staff       (20)     3736 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/HYB.py
--rw-r--r--   0 vitay      (501) staff       (20)    44535 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/LIL.py
--rw-r--r--   0 vitay      (501) staff       (20)     3973 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/SELL.py
--rw-r--r--   0 vitay      (501) staff       (20)     1671 2022-12-14 10:27:19.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/__init__.py
--rw-r--r--   0 vitay      (501) staff       (20)    58653 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThreadGenerator.py
--rw-r--r--   0 vitay      (501) staff       (20)      233 2021-10-01 13:31:48.000000 ANNarchy-4.7.3/ANNarchy/generator/Projection/__init__.py
--rw-r--r--   0 vitay      (501) staff       (20)    53905 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/PyxGenerator.py
--rw-r--r--   0 vitay      (501) staff       (20)    13943 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Sanity.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.800018 ANNarchy-4.7.3/ANNarchy/generator/Template/
--rw-r--r--   0 vitay      (501) staff       (20)    33691 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Template/BaseTemplate.py
--rw-r--r--   0 vitay      (501) staff       (20)    17690 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Template/GlobalOperationTemplate.py
--rw-r--r--   0 vitay      (501) staff       (20)     2525 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Template/MakefileTemplate.py
--rw-r--r--   0 vitay      (501) staff       (20)    22008 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Template/MonitorTemplate.py
--rw-r--r--   0 vitay      (501) staff       (20)    14191 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Template/PyxTemplate.py
--rw-r--r--   0 vitay      (501) staff       (20)        0 2017-07-25 21:21:04.000000 ANNarchy-4.7.3/ANNarchy/generator/Template/__init__.py
--rw-r--r--   0 vitay      (501) staff       (20)    15004 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/generator/Utils.py
--rw-r--r--   0 vitay      (501) staff       (20)       30 2017-07-25 21:21:04.000000 ANNarchy-4.7.3/ANNarchy/generator/__init__.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.805531 ANNarchy-4.7.3/ANNarchy/include/
--rw-r--r--   0 vitay      (501) staff       (20)     8527 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/BSRInvMatrix.hpp
--rw-r--r--   0 vitay      (501) staff       (20)    27288 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/BSRMatrix.hpp
--rw-r--r--   0 vitay      (501) staff       (20)     7084 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/BSRMatrixCUDA.hpp
--rw-r--r--   0 vitay      (501) staff       (20)    17465 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/COOMatrix.hpp
--rw-r--r--   0 vitay      (501) staff       (20)     8563 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/COOMatrixCUDA.hpp
--rw-r--r--   0 vitay      (501) staff       (20)    10989 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/CSRCMatrix.hpp
--rw-r--r--   0 vitay      (501) staff       (20)     8926 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/CSRCMatrixCUDA.hpp
--rw-r--r--   0 vitay      (501) staff       (20)     8600 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/CSRCMatrixCUDAT.hpp
--rw-r--r--   0 vitay      (501) staff       (20)    22747 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/CSRCMatrixT.hpp
--rw-r--r--   0 vitay      (501) staff       (20)    22670 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/CSRMatrix.hpp
--rw-r--r--   0 vitay      (501) staff       (20)     9302 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/CSRMatrixCUDA.hpp
--rw-r--r--   0 vitay      (501) staff       (20)    30581 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/DenseMatrix.hpp
--rw-r--r--   0 vitay      (501) staff       (20)     8879 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/DenseMatrixCUDA.hpp
--rw-r--r--   0 vitay      (501) staff       (20)    10925 2022-12-14 10:27:19.000000 ANNarchy-4.7.3/ANNarchy/include/DenseMatrixOffsets.hpp
--rw-r--r--   0 vitay      (501) staff       (20)    32799 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/ELLMatrix.hpp
--rw-r--r--   0 vitay      (501) staff       (20)     9493 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/ELLMatrixCUDA.hpp
--rw-r--r--   0 vitay      (501) staff       (20)    31031 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/ELLRMatrix.hpp
--rw-r--r--   0 vitay      (501) staff       (20)    10629 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/ELLRMatrixCUDA.hpp
--rw-r--r--   0 vitay      (501) staff       (20)    19241 2022-12-14 10:27:19.000000 ANNarchy-4.7.3/ANNarchy/include/HYBMatrix.hpp
--rw-r--r--   0 vitay      (501) staff       (20)     5284 2022-12-14 10:27:19.000000 ANNarchy-4.7.3/ANNarchy/include/HYBMatrixCUDA.hpp
--rw-r--r--   0 vitay      (501) staff       (20)    10267 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/LILInvMatrix.hpp
--rw-r--r--   0 vitay      (501) staff       (20)    39297 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/LILMatrix.hpp
--rw-r--r--   0 vitay      (501) staff       (20)    24689 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/PartitionedMatrix.hpp
--rw-r--r--   0 vitay      (501) staff       (20)    25701 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/SELLMatrix.hpp
--rw-r--r--   0 vitay      (501) staff       (20)     9540 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/SELLMatrixCUDA.hpp
--rw-r--r--   0 vitay      (501) staff       (20)     1092 2022-02-02 12:32:46.000000 ANNarchy-4.7.3/ANNarchy/include/Specific.hpp
--rw-r--r--   0 vitay      (501) staff       (20)     4143 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/include/VecTransformation.hpp
--rw-r--r--   0 vitay      (501) staff       (20)     1430 2022-02-02 12:32:46.000000 ANNarchy-4.7.3/ANNarchy/include/helper_functions.hpp
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.806151 ANNarchy-4.7.3/ANNarchy/models/
--rw-r--r--   0 vitay      (501) staff       (20)    44201 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/models/Neurons.py
--rw-r--r--   0 vitay      (501) staff       (20)    10911 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/models/Synapses.py
--rw-r--r--   0 vitay      (501) staff       (20)      352 2019-07-10 20:15:51.000000 ANNarchy-4.7.3/ANNarchy/models/__init__.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.807695 ANNarchy-4.7.3/ANNarchy/parser/
--rw-r--r--   0 vitay      (501) staff       (20)    14086 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/parser/AnalyseNeuron.py
--rw-r--r--   0 vitay      (501) staff       (20)    20654 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/parser/AnalyseSynapse.py
--rw-r--r--   0 vitay      (501) staff       (20)    13232 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/parser/CoupledEquations.py
--rw-r--r--   0 vitay      (501) staff       (20)    28430 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/parser/Equation.py
--rw-r--r--   0 vitay      (501) staff       (20)    27914 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/parser/Extraction.py
--rw-r--r--   0 vitay      (501) staff       (20)     3599 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/parser/Function.py
--rw-r--r--   0 vitay      (501) staff       (20)     5317 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/parser/ITE.py
--rw-r--r--   0 vitay      (501) staff       (20)     3130 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/parser/ParserTemplate.py
--rw-r--r--   0 vitay      (501) staff       (20)     6886 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/ANNarchy/parser/StringManipulation.py
--rw-r--r--   0 vitay      (501) staff       (20)       86 2019-07-10 20:15:51.000000 ANNarchy-4.7.3/ANNarchy/parser/__init__.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.808472 ANNarchy-4.7.3/ANNarchy/parser/report/
--rw-r--r--   0 vitay      (501) staff       (20)    16861 2023-01-25 15:17:04.000000 ANNarchy-4.7.3/ANNarchy/parser/report/LatexParser.py
--rw-r--r--   0 vitay      (501) staff       (20)    22711 2024-02-08 08:00:55.000000 ANNarchy-4.7.3/ANNarchy/parser/report/LatexReport.py
--rw-r--r--   0 vitay      (501) staff       (20)    15846 2021-04-01 06:34:12.000000 ANNarchy-4.7.3/ANNarchy/parser/report/MarkdownReport.py
--rw-r--r--   0 vitay      (501) staff       (20)     1985 2021-06-05 08:46:21.000000 ANNarchy-4.7.3/ANNarchy/parser/report/Report.py
--rw-r--r--   0 vitay      (501) staff       (20)        0 2019-07-10 20:15:51.000000 ANNarchy-4.7.3/ANNarchy/parser/report/__init__.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.808567 ANNarchy-4.7.3/ANNarchy/thirdparty/
--rw-r--r--   0 vitay      (501) staff       (20)    26759 2022-12-14 10:27:19.000000 ANNarchy-4.7.3/ANNarchy/thirdparty/randutils.hpp
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.779940 ANNarchy-4.7.3/ANNarchy.egg-info/
--rw-r--r--   0 vitay      (501) staff       (20)     2996 2024-03-21 20:45:45.000000 ANNarchy-4.7.3/ANNarchy.egg-info/PKG-INFO
--rw-r--r--   0 vitay      (501) staff       (20)     8687 2024-03-21 20:45:45.000000 ANNarchy-4.7.3/ANNarchy.egg-info/SOURCES.txt
--rw-r--r--   0 vitay      (501) staff       (20)        1 2024-03-21 20:45:45.000000 ANNarchy-4.7.3/ANNarchy.egg-info/dependency_links.txt
--rw-r--r--   0 vitay      (501) staff       (20)       47 2024-03-21 20:45:45.000000 ANNarchy-4.7.3/ANNarchy.egg-info/requires.txt
--rw-r--r--   0 vitay      (501) staff       (20)        9 2024-03-21 20:45:45.000000 ANNarchy-4.7.3/ANNarchy.egg-info/top_level.txt
--rw-r--r--   0 vitay      (501) staff       (20)      155 2024-03-21 20:38:14.000000 ANNarchy-4.7.3/AUTHORS
--rw-r--r--   0 vitay      (501) staff       (20)    18092 2017-07-25 21:20:59.000000 ANNarchy-4.7.3/LICENSE
--rw-r--r--   0 vitay      (501) staff       (20)      274 2021-06-05 08:46:21.000000 ANNarchy-4.7.3/MANIFEST.in
--rw-r--r--   0 vitay      (501) staff       (20)     2996 2024-03-21 20:45:45.816159 ANNarchy-4.7.3/PKG-INFO
--rw-r--r--   0 vitay      (501) staff       (20)     1803 2024-02-08 08:00:55.000000 ANNarchy-4.7.3/README.md
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.777596 ANNarchy-4.7.3/examples/
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.808987 ANNarchy-4.7.3/examples/ann_to_snn/
--rw-r--r--   0 vitay      (501) staff       (20)     3912 2024-03-21 20:38:15.000000 ANNarchy-4.7.3/examples/ann_to_snn/ANNtoSNN.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.809383 ANNarchy-4.7.3/examples/bar_learning/
--rw-r--r--   0 vitay      (501) staff       (20)     1844 2021-10-01 13:31:48.000000 ANNarchy-4.7.3/examples/bar_learning/BarLearning.py
--rw-r--r--   0 vitay      (501) staff       (20)     2104 2022-12-14 10:27:19.000000 ANNarchy-4.7.3/examples/bar_learning/BarLearningGPU.py
--rw-r--r--   0 vitay      (501) staff       (20)     1610 2022-02-01 11:22:20.000000 ANNarchy-4.7.3/examples/bar_learning/Viz.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.809650 ANNarchy-4.7.3/examples/bold_monitor/
--rw-r--r--   0 vitay      (501) staff       (20)     2529 2021-10-04 08:20:34.000000 ANNarchy-4.7.3/examples/bold_monitor/BOLD.py
--rw-r--r--   0 vitay      (501) staff       (20)     3003 2021-10-04 08:20:34.000000 ANNarchy-4.7.3/examples/bold_monitor/BOLD_two_inputs.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.809774 ANNarchy-4.7.3/examples/gap_junctions/
--rw-r--r--   0 vitay      (501) staff       (20)      888 2021-10-01 13:31:48.000000 ANNarchy-4.7.3/examples/gap_junctions/GapJunctions.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.809896 ANNarchy-4.7.3/examples/hodgkin_huxley/
--rw-r--r--   0 vitay      (501) staff       (20)     2496 2023-04-12 11:51:52.000000 ANNarchy-4.7.3/examples/hodgkin_huxley/HodgkinHuxley.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.810195 ANNarchy-4.7.3/examples/homeostatic_stdp/
--rw-r--r--   0 vitay      (501) staff       (20)     5055 2024-03-21 20:38:15.000000 ANNarchy-4.7.3/examples/homeostatic_stdp/Ramp.py
--rw-r--r--   0 vitay      (501) staff       (20)     7090 2024-03-21 20:38:15.000000 ANNarchy-4.7.3/examples/homeostatic_stdp/SORF.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.810382 ANNarchy-4.7.3/examples/hybrid/
--rw-r--r--   0 vitay      (501) staff       (20)     2865 2019-07-10 20:15:51.000000 ANNarchy-4.7.3/examples/hybrid/Hybrid.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.810988 ANNarchy-4.7.3/examples/image/
--rw-r--r--   0 vitay      (501) staff       (20)     6177 2024-03-21 20:38:15.000000 ANNarchy-4.7.3/examples/image/Image.py
--rw-r--r--   0 vitay      (501) staff       (20)     7210 2020-05-31 10:28:52.000000 ANNarchy-4.7.3/examples/image/Webcam.ipynb
--rw-r--r--   0 vitay      (501) staff       (20)     2959 2020-05-31 10:28:52.000000 ANNarchy-4.7.3/examples/image/Webcam.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.811108 ANNarchy-4.7.3/examples/izhikevich/
--rw-r--r--   0 vitay      (501) staff       (20)     1901 2022-02-01 11:22:20.000000 ANNarchy-4.7.3/examples/izhikevich/Izhikevich.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.811241 ANNarchy-4.7.3/examples/multinetwork/
--rw-r--r--   0 vitay      (501) staff       (20)     1973 2022-02-02 12:32:46.000000 ANNarchy-4.7.3/examples/multinetwork/MultiNetwork.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.811738 ANNarchy-4.7.3/examples/neural_field/
--rw-r--r--   0 vitay      (501) staff       (20)     1849 2020-05-31 10:28:52.000000 ANNarchy-4.7.3/examples/neural_field/BubbleWorld.pyx
--rw-r--r--   0 vitay      (501) staff       (20)     1490 2020-03-10 16:42:35.000000 ANNarchy-4.7.3/examples/neural_field/NeuralField.py
--rw-r--r--   0 vitay      (501) staff       (20)     2281 2022-02-01 11:22:20.000000 ANNarchy-4.7.3/examples/neural_field/Viz.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.812464 ANNarchy-4.7.3/examples/pyNN/
--rw-r--r--   0 vitay      (501) staff       (20)     1644 2019-07-10 20:15:51.000000 ANNarchy-4.7.3/examples/pyNN/AEIF_cond_exp.py
--rw-r--r--   0 vitay      (501) staff       (20)     2251 2019-07-10 20:15:51.000000 ANNarchy-4.7.3/examples/pyNN/EIF_cond_exp.py
--rw-r--r--   0 vitay      (501) staff       (20)     1427 2019-07-10 20:15:51.000000 ANNarchy-4.7.3/examples/pyNN/IF_cond_exp.py
--rw-r--r--   0 vitay      (501) staff       (20)     1361 2019-07-10 20:15:51.000000 ANNarchy-4.7.3/examples/pyNN/IF_curr_alpha.py
--rw-r--r--   0 vitay      (501) staff       (20)     1316 2019-07-10 20:15:51.000000 ANNarchy-4.7.3/examples/pyNN/non_linear_synapse.py
--rw-r--r--   0 vitay      (501) staff       (20)     2646 2019-07-10 20:15:51.000000 ANNarchy-4.7.3/examples/pyNN/short_term_plasticity2.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.812578 ANNarchy-4.7.3/examples/refractoriness/
--rw-r--r--   0 vitay      (501) staff       (20)     1070 2019-07-10 20:15:51.000000 ANNarchy-4.7.3/examples/refractoriness/Refractoriness.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.812706 ANNarchy-4.7.3/examples/simple_stdp/
--rw-r--r--   0 vitay      (501) staff       (20)     2208 2021-10-01 13:31:48.000000 ANNarchy-4.7.3/examples/simple_stdp/SimpleSTDPModel.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.812838 ANNarchy-4.7.3/examples/structural_plasticity/
--rw-r--r--   0 vitay      (501) staff       (20)     1923 2021-10-01 13:31:48.000000 ANNarchy-4.7.3/examples/structural_plasticity/StructuralPlasticity.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.814623 ANNarchy-4.7.3/examples/tensorboard/
--rw-r--r--   0 vitay      (501) staff       (20)  1014400 2021-10-01 13:31:48.000000 ANNarchy-4.7.3/examples/tensorboard/BasalGanglia.ipynb
--rw-r--r--   0 vitay      (501) staff       (20)   208036 2021-07-27 06:26:43.000000 ANNarchy-4.7.3/examples/tensorboard/BayesianOptimization.ipynb
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.815413 ANNarchy-4.7.3/examples/tsodyks_markram/
--rw-r--r--   0 vitay      (501) staff       (20)     3872 2023-04-12 10:39:20.000000 ANNarchy-4.7.3/examples/tsodyks_markram/TsodyksMarkram.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.815652 ANNarchy-4.7.3/examples/vogels_abbott/
--rw-r--r--   0 vitay      (501) staff       (20)     2857 2024-03-21 20:38:15.000000 ANNarchy-4.7.3/examples/vogels_abbott/COBA.py
--rw-r--r--   0 vitay      (501) staff       (20)     2724 2024-03-21 20:38:15.000000 ANNarchy-4.7.3/examples/vogels_abbott/CUBA.py
--rw-r--r--   0 vitay      (501) staff       (20)     1355 2024-03-21 20:38:15.000000 ANNarchy-4.7.3/pyproject.toml
--rw-r--r--   0 vitay      (501) staff       (20)       99 2024-02-08 08:00:55.000000 ANNarchy-4.7.3/requirements.txt
--rw-r--r--   0 vitay      (501) staff       (20)      101 2024-03-21 20:45:45.816358 ANNarchy-4.7.3/setup.cfg
--rw-r--r--   0 vitay      (501) staff       (20)     8508 2024-03-21 20:38:15.000000 ANNarchy-4.7.3/setup.py
-drwxr-xr-x   0 vitay      (501) staff       (20)        0 2024-03-21 20:45:45.815974 ANNarchy-4.7.3/tests/
--rw-r--r--   0 vitay      (501) staff       (20)     1122 2022-12-14 10:27:19.000000 ANNarchy-4.7.3/tests/test_CUDA.py
--rw-r--r--   0 vitay      (501) staff       (20)     1062 2022-12-14 10:27:19.000000 ANNarchy-4.7.3/tests/test_openmp.py
--rw-r--r--   0 vitay      (501) staff       (20)     1149 2022-12-14 10:27:19.000000 ANNarchy-4.7.3/tests/test_single_thread.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.615846 annarchy-4.8.0.1/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.571846 annarchy-4.8.0.1/ANNarchy/
+-rw-r--r--   0 runner    (1001) docker     (127)     1984 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.579846 annarchy-4.8.0.1/ANNarchy/core/
+-rw-r--r--   0 runner    (1001) docker     (127)    27449 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/core/ConnectorMethods.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2778 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/core/Constant.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15820 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/core/Dendrite.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12015 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/core/Global.py
+-rw-r--r--   0 runner    (1001) docker     (127)    20348 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/core/IO.py
+-rw-r--r--   0 runner    (1001) docker     (127)    38733 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/core/Monitor.py
+-rw-r--r--   0 runner    (1001) docker     (127)    34060 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/core/Network.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7657 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/core/Neuron.py
+-rw-r--r--   0 runner    (1001) docker     (127)    34285 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/core/Population.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12331 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/core/PopulationView.py
+-rw-r--r--   0 runner    (1001) docker     (127)    68627 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/core/Projection.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8507 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/core/Random.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9582 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/core/Simulate.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5266 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/core/Synapse.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3792 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/core/Utils.py
+-rw-r--r--   0 runner    (1001) docker     (127)        1 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/core/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.579846 annarchy-4.8.0.1/ANNarchy/cython_ext/
+-rw-r--r--   0 runner    (1001) docker     (127)     1800 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/cython_ext/Connector.pxd
+-rw-r--r--   0 runner    (1001) docker     (127)    22716 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/cython_ext/Connector.pyx
+-rw-r--r--   0 runner    (1001) docker     (127)      924 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/cython_ext/Coordinates.pxd
+-rw-r--r--   0 runner    (1001) docker     (127)     4941 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/cython_ext/Coordinates.pyx
+-rw-r--r--   0 runner    (1001) docker     (127)     2893 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/cython_ext/Transformations.pyx
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/cython_ext/__init__.pxd
+-rw-r--r--   0 runner    (1001) docker     (127)      405 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/cython_ext/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.579846 annarchy-4.8.0.1/ANNarchy/extensions/
+-rw-r--r--   0 runner    (1001) docker     (127)       21 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.579846 annarchy-4.8.0.1/ANNarchy/extensions/ann_to_snn_conversion/
+-rw-r--r--   0 runner    (1001) docker     (127)    21947 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/ann_to_snn_conversion/ANNtoSNNConverter.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2738 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/ann_to_snn_conversion/InputEncoding.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1719 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/ann_to_snn_conversion/ReadOut.py
+-rw-r--r--   0 runner    (1001) docker     (127)       48 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/ann_to_snn_conversion/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.579846 annarchy-4.8.0.1/ANNarchy/extensions/bold/
+-rw-r--r--   0 runner    (1001) docker     (127)    12425 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/bold/AccProjection.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5014 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/bold/BoldModel.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9783 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/bold/BoldMonitor.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14339 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/bold/NormProjection.py
+-rw-r--r--   0 runner    (1001) docker     (127)    26705 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/bold/PredefinedModels.py
+-rw-r--r--   0 runner    (1001) docker     (127)      386 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/bold/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.583846 annarchy-4.8.0.1/ANNarchy/extensions/convolution/
+-rw-r--r--   0 runner    (1001) docker     (127)    52674 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/convolution/Convolve.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15470 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/convolution/ConvolveTemplate.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8628 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/convolution/Copy.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3574 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/convolution/CopyTemplate.py
+-rw-r--r--   0 runner    (1001) docker     (127)    25083 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/convolution/Pooling.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14205 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/convolution/PoolingTemplate.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13312 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/convolution/Transpose.py
+-rw-r--r--   0 runner    (1001) docker     (127)      667 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/convolution/Utils.py
+-rw-r--r--   0 runner    (1001) docker     (127)      858 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/convolution/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.583846 annarchy-4.8.0.1/ANNarchy/extensions/diagonal/
+-rw-r--r--   0 runner    (1001) docker     (127)    15763 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/diagonal/DiagonalProjection.py
+-rw-r--r--   0 runner    (1001) docker     (127)       50 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/diagonal/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.583846 annarchy-4.8.0.1/ANNarchy/extensions/hybrid/
+-rw-r--r--   0 runner    (1001) docker     (127)    21017 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/hybrid/HybridPopulation.py
+-rw-r--r--   0 runner    (1001) docker     (127)       72 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/hybrid/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.583846 annarchy-4.8.0.1/ANNarchy/extensions/image/
+-rw-r--r--   0 runner    (1001) docker     (127)    10119 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/image/ImagePopulation.py
+-rw-r--r--   0 runner    (1001) docker     (127)       62 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/image/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.583846 annarchy-4.8.0.1/ANNarchy/extensions/tensorboard/
+-rw-r--r--   0 runner    (1001) docker     (127)    11976 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/tensorboard/Logger.py
+-rw-r--r--   0 runner    (1001) docker     (127)       26 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/extensions/tensorboard/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.587846 annarchy-4.8.0.1/ANNarchy/generator/
+-rw-r--r--   0 runner    (1001) docker     (127)     4414 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/CmdLineArgParser.py
+-rw-r--r--   0 runner    (1001) docker     (127)    43837 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/CodeGenerator.py
+-rw-r--r--   0 runner    (1001) docker     (127)    35511 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Compiler.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9917 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/MonitorGenerator.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.587846 annarchy-4.8.0.1/ANNarchy/generator/Population/
+-rw-r--r--   0 runner    (1001) docker     (127)    62308 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Population/CUDAGenerator.py
+-rw-r--r--   0 runner    (1001) docker     (127)    26864 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Population/CUDATemplates.py
+-rw-r--r--   0 runner    (1001) docker     (127)    41222 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Population/OpenMPGenerator.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13599 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Population/OpenMPTemplates.py
+-rw-r--r--   0 runner    (1001) docker     (127)    22671 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Population/PopulationGenerator.py
+-rw-r--r--   0 runner    (1001) docker     (127)    35745 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Population/SingleThreadGenerator.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12543 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Population/SingleThreadTemplates.py
+-rw-r--r--   0 runner    (1001) docker     (127)      142 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Population/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.587846 annarchy-4.8.0.1/ANNarchy/generator/Profile/
+-rw-r--r--   0 runner    (1001) docker     (127)    14047 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Profile/CPP11Profile.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7755 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Profile/CUDAProfile.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6127 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Profile/PAPIProfile.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3013 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Profile/ProfileGenerator.py
+-rw-r--r--   0 runner    (1001) docker     (127)    30855 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Profile/ProfileTemplate.py
+-rw-r--r--   0 runner    (1001) docker     (127)      159 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Profile/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.591846 annarchy-4.8.0.1/ANNarchy/generator/Projection/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.591846 annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/
+-rw-r--r--   0 runner    (1001) docker     (127)    14586 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/BSR.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10177 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/BaseTemplates.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10168 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/COO.py
+-rw-r--r--   0 runner    (1001) docker     (127)    39116 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/CSR.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12622 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/CSR_Scalar.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12463 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/CSR_T.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14801 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/CSR_Vector.py
+-rw-r--r--   0 runner    (1001) docker     (127)    23959 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/Dense.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10907 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/Dense_T.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15625 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/ELL.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16792 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/ELLR.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7469 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/HYB.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10200 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/SELL.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1514 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    77871 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDAGenerator.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.595846 annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/
+-rw-r--r--   0 runner    (1001) docker     (127)     7967 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/BSR.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11951 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/BaseTemplates.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2783 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/COO.py
+-rw-r--r--   0 runner    (1001) docker     (127)    36651 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/CSR.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7563 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/CSR_P.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7248 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/CSR_T.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5992 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/CSR_T_P.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3535 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/DIA.py
+-rw-r--r--   0 runner    (1001) docker     (127)    18305 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/Dense.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5476 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/Dense_T.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7888 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/ELL.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4239 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/ELLR.py
+-rw-r--r--   0 runner    (1001) docker     (127)    52044 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/LIL.py
+-rw-r--r--   0 runner    (1001) docker     (127)    22029 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/LIL_P.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3989 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/SELL.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1615 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    64299 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMPGenerator.py
+-rw-r--r--   0 runner    (1001) docker     (127)    52009 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/ProjectionGenerator.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.599846 annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/
+-rw-r--r--   0 runner    (1001) docker     (127)    18307 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/BSR.py
+-rw-r--r--   0 runner    (1001) docker     (127)    11646 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/BaseTemplates.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2542 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/COO.py
+-rw-r--r--   0 runner    (1001) docker     (127)    36733 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/CSR.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6419 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/CSR_T.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3469 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/DIA.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16946 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/Dense.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3571 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/Dense_PV.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3848 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/Dense_PV_T.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5288 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/Dense_T.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7717 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/ELL.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16164 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/ELLR.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3736 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/HYB.py
+-rw-r--r--   0 runner    (1001) docker     (127)    45605 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/LIL.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3973 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/SELL.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1764 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    59725 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThreadGenerator.py
+-rw-r--r--   0 runner    (1001) docker     (127)      233 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Projection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    55116 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/PyxGenerator.py
+-rw-r--r--   0 runner    (1001) docker     (127)    14690 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Sanity.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.599846 annarchy-4.8.0.1/ANNarchy/generator/Template/
+-rw-r--r--   0 runner    (1001) docker     (127)    34682 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Template/BaseTemplate.py
+-rw-r--r--   0 runner    (1001) docker     (127)    17690 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Template/GlobalOperationTemplate.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2525 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Template/MakefileTemplate.py
+-rw-r--r--   0 runner    (1001) docker     (127)    22008 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Template/MonitorTemplate.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13592 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Template/PyxTemplate.py
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Template/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    15133 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/Utils.py
+-rw-r--r--   0 runner    (1001) docker     (127)       30 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/generator/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.607846 annarchy-4.8.0.1/ANNarchy/include/
+-rw-r--r--   0 runner    (1001) docker     (127)     8568 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/BSRInvMatrix.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    27797 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/BSRMatrix.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     7125 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/BSRMatrixCUDA.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    17849 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/COOMatrix.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     8604 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/COOMatrixCUDA.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    11030 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/CSRCMatrix.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     8967 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/CSRCMatrixCUDA.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     8641 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/CSRCMatrixCUDAT.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    22788 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/CSRCMatrixT.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    23175 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/CSRMatrix.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     9343 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/CSRMatrixCUDA.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    30929 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/DenseMatrix.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     8920 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/DenseMatrixCUDA.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    10948 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/DenseMatrixOffsets.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    17710 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/DiaMatrix.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    33221 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/ELLMatrix.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     9534 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/ELLMatrixCUDA.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    31389 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/ELLRMatrix.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    10670 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/ELLRMatrixCUDA.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    19241 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/HYBMatrix.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     5284 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/HYBMatrixCUDA.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    10309 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/LILInvMatrix.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    40266 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/LILMatrix.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    25175 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/PartitionedMatrix.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)    26099 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/SELLMatrix.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     9581 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/SELLMatrixCUDA.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     1092 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/Specific.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     4143 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/VecTransformation.hpp
+-rw-r--r--   0 runner    (1001) docker     (127)     1430 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/include/helper_functions.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.607846 annarchy-4.8.0.1/ANNarchy/inputs/
+-rw-r--r--   0 runner    (1001) docker     (127)     5152 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/inputs/CurrentInjection.py
+-rw-r--r--   0 runner    (1001) docker     (127)     8193 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/inputs/DecodingProjection.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2291 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/inputs/InputArray.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6999 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/inputs/PoissonPopulation.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10619 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/inputs/SpikeSourceArray.py
+-rw-r--r--   0 runner    (1001) docker     (127)    32989 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/inputs/SpikeTrains.py
+-rw-r--r--   0 runner    (1001) docker     (127)    47618 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/inputs/TimedArray.py
+-rw-r--r--   0 runner    (1001) docker     (127)      616 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/inputs/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.607846 annarchy-4.8.0.1/ANNarchy/intern/
+-rw-r--r--   0 runner    (1001) docker     (127)    13201 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/intern/ConfigManagement.py
+-rw-r--r--   0 runner    (1001) docker     (127)     4040 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/intern/GlobalObjects.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2680 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/intern/Messages.py
+-rw-r--r--   0 runner    (1001) docker     (127)    17369 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/intern/NetworkManager.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7095 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/intern/Profiler.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1994 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/intern/SpecificPopulation.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2004 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/intern/SpecificProjection.py
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/intern/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.611846 annarchy-4.8.0.1/ANNarchy/models/
+-rw-r--r--   0 runner    (1001) docker     (127)    45463 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/models/Neurons.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10916 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/models/Synapses.py
+-rw-r--r--   0 runner    (1001) docker     (127)      352 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.611846 annarchy-4.8.0.1/ANNarchy/parser/
+-rw-r--r--   0 runner    (1001) docker     (127)    14192 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/parser/AnalyseNeuron.py
+-rw-r--r--   0 runner    (1001) docker     (127)    20765 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/parser/AnalyseSynapse.py
+-rw-r--r--   0 runner    (1001) docker     (127)    13341 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/parser/CoupledEquations.py
+-rw-r--r--   0 runner    (1001) docker     (127)    28564 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/parser/Equation.py
+-rw-r--r--   0 runner    (1001) docker     (127)    28252 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/parser/Extraction.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3692 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/parser/Function.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5344 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/parser/ITE.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3206 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/parser/ParserTemplate.py
+-rw-r--r--   0 runner    (1001) docker     (127)     7411 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/parser/StringManipulation.py
+-rw-r--r--   0 runner    (1001) docker     (127)       86 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/parser/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.611846 annarchy-4.8.0.1/ANNarchy/parser/report/
+-rw-r--r--   0 runner    (1001) docker     (127)    17186 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/parser/report/LatexParser.py
+-rw-r--r--   0 runner    (1001) docker     (127)    22650 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/parser/report/LatexReport.py
+-rw-r--r--   0 runner    (1001) docker     (127)    16208 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/parser/report/MarkdownReport.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1806 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/parser/report/Report.py
+-rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/parser/report/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.611846 annarchy-4.8.0.1/ANNarchy/thirdparty/
+-rw-r--r--   0 runner    (1001) docker     (127)    26759 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/ANNarchy/thirdparty/randutils.hpp
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.615846 annarchy-4.8.0.1/ANNarchy.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (127)     3269 2024-05-29 12:35:07.000000 annarchy-4.8.0.1/ANNarchy.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (127)     8029 2024-05-29 12:35:07.000000 annarchy-4.8.0.1/ANNarchy.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (127)        1 2024-05-29 12:35:07.000000 annarchy-4.8.0.1/ANNarchy.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (127)       47 2024-05-29 12:35:07.000000 annarchy-4.8.0.1/ANNarchy.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (127)        9 2024-05-29 12:35:07.000000 annarchy-4.8.0.1/ANNarchy.egg-info/top_level.txt
+-rw-r--r--   0 runner    (1001) docker     (127)      155 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/AUTHORS
+-rw-r--r--   0 runner    (1001) docker     (127)    18092 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/LICENSE
+-rw-r--r--   0 runner    (1001) docker     (127)      263 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/MANIFEST.in
+-rw-r--r--   0 runner    (1001) docker     (127)     3269 2024-05-29 12:35:07.615846 annarchy-4.8.0.1/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (127)     2103 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/README.md
+-rw-r--r--   0 runner    (1001) docker     (127)     1214 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/pyproject.toml
+-rw-r--r--   0 runner    (1001) docker     (127)       98 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/requirements.txt
+-rw-r--r--   0 runner    (1001) docker     (127)       38 2024-05-29 12:35:07.615846 annarchy-4.8.0.1/setup.cfg
+-rw-r--r--   0 runner    (1001) docker     (127)     8464 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-29 12:35:07.615846 annarchy-4.8.0.1/tests/
+-rw-r--r--   0 runner    (1001) docker     (127)     1122 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/tests/test_CUDA.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1062 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/tests/test_openmp.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1149 2024-05-29 12:34:56.000000 annarchy-4.8.0.1/tests/test_single_thread.py
```

### Comparing `ANNarchy-4.7.3/ANNarchy/__init__.py` & `annarchy-4.8.0.1/ANNarchy/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,37 +1,38 @@
 # Generic imports
 import os, sys
 import numpy as np
 
 # ANNarchy core
 from .core.Global import *
 from .core.Simulate import *
+from .core.Constant import Constant
 from .core.Neuron import Neuron
 from .core.Synapse import Synapse
 from .core.Population import Population
 from .core.Projection import Projection
-from .core.SpecificPopulation import PoissonPopulation, SpikeSourceArray, TimedArray, HomogeneousCorrelatedSpikeTrains, TimedPoissonPopulation
-from .core.SpecificProjection import DecodingProjection, CurrentInjection
+from .inputs import *
 from .core.Dendrite import Dendrite
 from .core.Random import Uniform, DiscreteUniform, Normal, LogNormal, Gamma, Exponential, Binomial
 from .core.IO import save, load, load_parameter, load_parameters, save_parameters
 from .core.Utils import sparse_random_matrix, sparse_delays_from_weights
 from .core.Monitor import *
 from .core.Network import Network, parallel_run
 from .parser.report.Report import report
 from .models.Neurons import *
 from .models.Synapses import *
 from .extensions import *
+from .intern.ConfigManagement import setup
 
 # Cython modules
 try:
     # HD: until version 4.6 the connectivity class wasn't named properly. To ensure backward compability
     #     we rename the LILConnectivity to CSR
-    from .core.cython_ext import LILConnectivity
-    from .core.cython_ext import LILConnectivity as CSR
+    from .cython_ext import LILConnectivity
+    from .cython_ext import LILConnectivity as CSR
 except Exception as e:
     print(e)
     print("""
 Warning: Cython modules can not be imported. If you are installing ANNarchy, this is normal, ignore this message. If ANNarchy is already installed, something went wrong with the compilation, try reinstalling.
 """)
 
 # ANNarchy compilation
@@ -45,12 +46,12 @@
 # Automatically call ANNarchy.core.Global.clear()
 # if the script terminates
 import atexit
 atexit.register(check_profile_results)
 atexit.register(clear)
 
 # Version
-__version__ = '4.7'
-__release__ = '4.7.3'
+__version__ = '4.8'
+__release__ = '4.8.0'
 
 print( 'ANNarchy ' + __version__ + ' (' + __release__ + \
                     ') on ' + sys.platform + ' (' + os.name + ').' )
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/ConnectorMethods.py` & `annarchy-4.8.0.1/ANNarchy/core/ConnectorMethods.py`

 * *Files 8% similar despite different names*

```diff
@@ -3,69 +3,74 @@
 for more details: https://annarchy.readthedocs.io/en/latest/manual/Connector.html
 
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 import numpy as np
 
-from ANNarchy.core import Global
 from ANNarchy.core.Random import RandomDistribution, DiscreteUniform
 from ANNarchy.core.PopulationView import PopulationView
 from ANNarchy.parser.report.LatexParser import _process_random
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern import Messages
 
 try:
-    from ANNarchy.core.cython_ext import *
+    from ANNarchy.cython_ext import *
 except Exception as e:
-    Global._print(e)
+    Messages._print(e)
 
 ################################
 ## Connector methods
 ################################
-def connect_one_to_one(self, weights=1.0, delays=0.0, force_multiple_weights=False, storage_format=None, storage_order=None):
-    """
-    Builds a one-to-one connection pattern between the two populations.
-
-    :param weights: initial synaptic values, either a single value (float) or a random distribution object.
-    :param delays: synaptic delays, either a single value or a random distribution object (default=dt).
-    :param force_multiple_weights: if a single value is provided for ``weights`` and there is no learning, a single weight value will be used for the whole projection instead of one per synapse. Setting ``force_multiple_weights`` to True ensures that a value per synapse will be used.
-    :param storage_format: for some of the default connection patterns, ANNarchy provide different storage formats. For one-to-one we support list-of-list ("lil") or compressed sparse row ("csr"), by default lil is chosen.
-    :param storage_order: for some of the available storage formats, ANNarchy provides different storage orderings. For one-to-one we support *pre_to_post* and *post_to_pre*, by default *post_to_pre* is chosen.
+def connect_one_to_one(self, 
+                       weights: float | RandomDistribution = 1.0, 
+                       delays: float | RandomDistribution = 0.0, 
+                       force_multiple_weights:bool=False, 
+                       storage_format:str=None, storage_order:str=None) -> "Projection":
+    """
+    one-to-one connection pattern.
+
+    :param weights: Initial synaptic values, either a single value (float) or a random distribution object.
+    :param delays: Synaptic delays, either a single value or a random distribution object (default=dt).
+    :param force_multiple_weights: If a single value is provided for ``weights`` and there is no learning, a single weight value will be used for the whole projection instead of one per synapse. Setting ``force_multiple_weights`` to True ensures that a value per synapse will be used.
     """
     if self.pre.size != self.post.size:
-        Global._warning("connect_one_to_one() between", self.pre.name, 'and', self.post.name, 'with target', self.target)
-        Global._print("\t the two populations have different sizes, please check the connection pattern is what you expect.")
+        Messages._warning("connect_one_to_one() between", self.pre.name, 'and', self.post.name, 'with target', self.target)
+        Messages._print("\t the two populations have different sizes, please check the connection pattern is what you expect.")
 
     self.connector_name = "One-to-One"
     self.connector_description = "One-to-One, weights %(weight)s, delays %(delay)s" % {'weight': _process_random(weights), 'delay': _process_random(delays)}
 
     if isinstance(weights, (int, float)) and not force_multiple_weights:
         self._single_constant_weight = True
 
     if storage_format == "dense":
-        Global._error("The usage of 'dense' storage format on one-to-one pattern is not allowed.")
+        Messages._error("The usage of 'dense' storage format on one-to-one pattern is not allowed.")
 
     # if weights or delays are from random distribution I need to know this in code generator
     self.connector_weight_dist = weights if isinstance(weights, RandomDistribution) else None
     self.connector_delay_dist = delays if isinstance(delays, RandomDistribution) else None
 
     self._store_connectivity(one_to_one, (weights, delays, storage_format, storage_order), delays, storage_format, storage_order)
-    return self
 
-def connect_all_to_all(self, weights, delays=0.0, allow_self_connections=False, force_multiple_weights=False, storage_format=None, storage_order=None):
-    """
-    Builds an all-to-all connection pattern between the two populations.
-
-    :param weights: synaptic values, either a single value or a random distribution object.
-    :param delays: synaptic delays, either a single value or a random distribution object (default=dt).
-    :param allow_self_connections: if True, self-connections between a neuron and itself are allowed (default = False if the pre- and post-populations are identical, True otherwise).
-    :param force_multiple_weights: if a single value is provided for ``weights`` and there is no learning, a single weight value will be used for the whole projection instead of one per synapse. Setting ``force_multiple_weights`` to True ensures that a value per synapse will be used.
-    :param storage_format: for some of the default connection patterns, ANNarchy provide different storage formats. For all-to-all we support list-of-list ("lil") or compressed sparse row ("csr"), by default lil is chosen.
-    :param storage_order: for some of the available storage formats, ANNarchy provides different storage orderings. For all-to-all we support pre_to_post and post_to_pre, by default post_to_pre is chosen.
+    return self
 
-    Please note, the last two arguments should be changed carefully, as they can have large impact on the computational performance of ANNarchy.
+def connect_all_to_all(self, 
+                       weights: float | RandomDistribution, 
+                       delays: float | RandomDistribution =0.0, 
+                       allow_self_connections:bool=False, 
+                       force_multiple_weights:bool=False, 
+                       storage_format:str=None, storage_order:str=None)  -> "Projection":
+    """
+    all-to-all (fully-connected) connection pattern.
+
+    :param weights: Synaptic values, either a single value or a random distribution object.
+    :param delays: Synaptic delays, either a single value or a random distribution object (default=dt).
+    :param allow_self_connections: If True, self-connections between a neuron and itself are allowed (default = False if the pre- and post-populations are identical, True otherwise).
+    :param force_multiple_weights: If a single value is provided for ``weights`` and there is no learning, a single weight value will be used for the whole projection instead of one per synapse. Setting ``force_multiple_weights`` to True ensures that a value per synapse will be used.
     """
     pre_pop = self.pre if not isinstance(self.pre, PopulationView) else self.pre.population
     post_pop = self.post if not isinstance(self.post, PopulationView) else self.post.population
     if pre_pop != post_pop:
         allow_self_connections = True
 
     self.connector_name = "All-to-All"
@@ -77,88 +82,86 @@
 
     # if weights or delays are from random distribution I need to know this in code generator
     self.connector_weight_dist = weights if isinstance(weights, RandomDistribution) else None
     self.connector_delay_dist = delays if isinstance(delays, RandomDistribution) else None
 
     # Store the connectivity
     self._store_connectivity(all_to_all, (weights, delays, allow_self_connections, storage_format, storage_order), delays, storage_format, storage_order)
+
     return self
 
-def connect_gaussian(self, amp, sigma, delays=0.0, limit=0.01, allow_self_connections=False, storage_format=None):
+def connect_gaussian(self, amp:float, sigma:float, delays: float | RandomDistribution=0.0, limit:float=0.01, allow_self_connections:bool=False, storage_format:str=None)  -> "Projection":
     """
-    Builds a Gaussian connection pattern between the two populations.
+    Gaussian connection pattern.
 
-    Each neuron in the postsynaptic population is connected to a region of the presynaptic population centered around
-    the neuron with the same normalized coordinates using a Gaussian profile.
+    Each neuron in the postsynaptic population is connected to a region of the presynaptic population centered around the neuron with the same normalized coordinates using a Gaussian profile.
 
-    :param amp: amplitude of the Gaussian function
-    :param sigma: width of the Gaussian function
-    :param delays: synaptic delay, either a single value or a random distribution object (default=dt).
-    :param limit: proportion of *amp* below which synapses are not created (default: 0.01)
-    :param allow_self_connections: allows connections between a neuron and itself.
-    :param storage_format: for some of the default connection patterns, ANNarchy provide different storage formats. By default *lil* (list-in-list) is chosen.
+    :param amp: Amplitude of the Gaussian function
+    :param sigma: Width of the Gaussian function
+    :param delays: Synaptic delay, either a single value or a random distribution object (default=dt).
+    :param limit: Proportion of `amp` below which synapses are not created
+    :param allow_self_connections: Allows connections between a neuron and itself.
     """
     if self.pre != self.post:
         allow_self_connections = True
 
     if isinstance(self.pre, PopulationView) or isinstance(self.post, PopulationView):
-        Global._error('Gaussian connector is only possible on whole populations, not PopulationViews.')
+        Messages._error('Gaussian connector is only possible on whole populations, not PopulationViews.')
 
     self.connector_name = "Gaussian"
-    self.connector_description = "Gaussian, $A$ %(A)s, $\sigma$ %(sigma)s, delays %(delay)s"% {'A': str(amp), 'sigma': str(sigma), 'delay': _process_random(delays)}
+    self.connector_description = f"Gaussian, amplitude {amp}, sigma {sigma}, delays {_process_random(delays)}"
 
     # weights are not drawn, delays possibly
     self.connector_delay_dist = delays if isinstance(delays, RandomDistribution) else None
 
     self._store_connectivity(gaussian, (amp, sigma, delays, limit, allow_self_connections, storage_format, "post_to_pre"), delays, storage_format, "post_to_pre")
+    
     return self
 
-def connect_dog(self, amp_pos, sigma_pos, amp_neg, sigma_neg, delays=0.0, limit=0.01, allow_self_connections=False, storage_format=None):
+def connect_dog(self, amp_pos:float, sigma_pos:float, amp_neg:float, sigma_neg:float, delays:float | RandomDistribution=0.0, limit:float=0.01, allow_self_connections:bool=False, storage_format:str=None)  -> "Projection":
     """
-    Builds a Difference-Of-Gaussians connection pattern between the two populations.
+    Difference-Of-Gaussians connection pattern.
 
-    Each neuron in the postsynaptic population is connected to a region of the presynaptic population centered around
-    the neuron with the same normalized coordinates using a Difference-Of-Gaussians profile.
+    Each neuron in the postsynaptic population is connected to a region of the presynaptic population centered around the neuron with the same normalized coordinates using a Difference-Of-Gaussians profile.
 
-    :param amp_pos: amplitude of the positive Gaussian function
-    :param sigma_pos: width of the positive Gaussian function
-    :param amp_neg: amplitude of the negative Gaussian function
-    :param sigma_neg: width of the negative Gaussian function
-    :param delays: synaptic delay, either a single value or a random distribution object (default=dt).
-    :param limit: proportion of *amp* below which synapses are not created (default: 0.01)
-    :param allow_self_connections: allows connections between a neuron and itself.
-    :param storage_format: for some of the default connection patterns, ANNarchy provide different storage formats. By default *lil* (list-in-list) is chosen.
+    :param amp_pos: Amplitude of the positive Gaussian function
+    :param sigma_pos: Width of the positive Gaussian function
+    :param amp_neg: Amplitude of the negative Gaussian function
+    :param sigma_neg: Width of the negative Gaussian function
+    :param delays: Synaptic delay, either a single value or a random distribution object (default=dt).
+    :param limit: Proportion of *amp* below which synapses are not created (default: 0.01)
+    :param allow_self_connections: Allows connections between a neuron and itself.
     """
     if self.pre != self.post:
         allow_self_connections = True
 
     if isinstance(self.pre, PopulationView) or isinstance(self.post, PopulationView):
-        Global._error('DoG connector is only possible on whole populations, not PopulationViews.')
+        Messages._error('DoG connector is only possible on whole populations, not PopulationViews.')
 
     self.connector_name = "Difference-of-Gaussian"
-    self.connector_description = "Difference-of-Gaussian, $A^+ %(Aplus)s, $\sigma^+$ %(sigmaplus)s, $A^- %(Aminus)s, $\sigma^-$ %(sigmaminus)s, delays %(delay)s"% {'Aplus': str(amp_pos), 'sigmaplus': str(sigma_pos), 'Aminus': str(amp_neg), 'sigmaminus': str(sigma_neg), 'delay': _process_random(delays)}
+    self.connector_description = f"Difference-of-Gaussian, A+ {amp_pos}, sigma+ {sigma_pos}, A- {amp_neg}, sigma- {sigma_neg}, delays {_process_random(delays)}"
 
     # delays are possibly drawn from distribution, weights not
     self.connector_delay_dist = delays if isinstance(delays, RandomDistribution) else None
 
     self._store_connectivity(dog, (amp_pos, sigma_pos, amp_neg, sigma_neg, delays, limit, allow_self_connections, storage_format, "post_to_pre"), delays, storage_format, "post_to_pre")
+
     return self
 
-def connect_fixed_probability(self, probability, weights, delays=0.0, allow_self_connections=False, force_multiple_weights=False, storage_format=None, storage_order=None):
+def connect_fixed_probability(self, probability:float, weights:float | RandomDistribution, delays:float | RandomDistribution=0.0, allow_self_connections:bool=False, force_multiple_weights:bool=False, storage_format:str=None, storage_order:str=None)  -> "Projection":
     """
-    Builds a probabilistic connection pattern between the two populations.
+    Probabilistic sparse connection pattern.
 
     Each neuron in the postsynaptic population is connected to neurons of the presynaptic population with the given probability. Self-connections are avoided by default.
 
-    :param probability: probability that a synapse is created.
-    :param weights: either a single value for all synapses or a RandomDistribution object.
-    :param delays: either a single value for all synapses or a RandomDistribution object (default = dt)
-    :param allow_self_connections: defines if self-connections are allowed (default=False).
-    :param force_multiple_weights: if a single value is provided for ``weights`` and there is no learning, a single weight value will be used for the whole projection instead of one per synapse. Setting ``force_multiple_weights`` to True ensures that a value per synapse will be used.
-    :param storage_format: for some of the default connection patterns ANNarchy provide different storage formats. For all-to-all we support list-of-list ("lil") or compressed sparse row ("csr"), by default lil is chosen.
+    :param probability: Probability that a synapse is created.
+    :param weights: Either a single value for all synapses or a RandomDistribution object.
+    :param delays: Either a single value for all synapses or a RandomDistribution object (default = dt)
+    :param allow_self_connections: Defines if self-connections are allowed (default=False).
+    :param force_multiple_weights: If a single value is provided for `weights` and there is no learning, a single weight value will be used for the whole projection instead of one per synapse. Setting `force_multiple_weights` to True ensures that a value per synapse will be used.
     """
     if self.pre != self.post:
         allow_self_connections = True
 
     self.connector_name = "Random"
     self.connector_description = "Random, sparseness %(proba)s, weights %(weight)s, delays %(delay)s" % {'weight': _process_random(weights), 'delay': _process_random(delays), 'proba': probability}
 
@@ -166,115 +169,148 @@
         self._single_constant_weight = True
 
     # if weights or delays are from random distribution I need to know this in code generator
     self.connector_weight_dist = weights if isinstance(weights, RandomDistribution) else None
     self.connector_delay_dist = delays if isinstance(delays, RandomDistribution) else None
 
     self._store_connectivity(fixed_probability, (probability, weights, delays, allow_self_connections, storage_format, storage_order), delays, storage_format, storage_order)
+
     return self
 
-def connect_fixed_number_pre(self, number, weights, delays=0.0, allow_self_connections=False, force_multiple_weights=False, storage_format=None, storage_order=None):
+def connect_fixed_number_pre(self, number:int, weights: float | RandomDistribution, delays: float | RandomDistribution=0.0, allow_self_connections:bool=False, force_multiple_weights:bool=False, storage_format:str=None, storage_order:str=None)  -> "Projection":
     """
-    Builds a connection pattern between the two populations with a fixed number of pre-synaptic neurons.
+    Connection pattern where each post-synaptic neuron receives a fixed number of pre-synaptic neurons.
 
-    Each neuron in the postsynaptic population receives connections from a fixed number of neurons of the presynaptic population chosen randomly.
-
-    :param number: number of synapses per postsynaptic neuron.
-    :param weights: either a single value for all synapses or a RandomDistribution object.
-    :param delays: either a single value for all synapses or a RandomDistribution object (default = dt)
-    :param allow_self_connections: defines if self-connections are allowed (default=False).
-    :param force_multiple_weights: if a single value is provided for ``weights`` and there is no learning, a single weight value will be used for the whole projection instead of one per synapse. Setting ``force_multiple_weights`` to True ensures that a value per synapse will be used.
+    :param number: Number of synapses per postsynaptic neuron.
+    :param weights: Either a single value for all synapses or a RandomDistribution object.
+    :param delays: Either a single value for all synapses or a RandomDistribution object (default = dt)
+    :param allow_self_connections: Defines if self-connections are allowed (default=False).
+    :param force_multiple_weights: If a single value is provided for ``weights`` and there is no learning, a single weight value will be used for the whole projection instead of one per synapse. Setting ``force_multiple_weights`` to True ensures that a value per synapse will be used.
     """
     if self.pre != self.post:
         allow_self_connections = True
 
     if number > self.pre.size:
-        Global._error('connect_fixed_number_pre: the number of pre-synaptic neurons exceeds the size of the population.')
+        Messages._error('connect_fixed_number_pre: the number of pre-synaptic neurons exceeds the size of the population.')
 
     self.connector_name = "Random Convergent"
     self.connector_description = "Random Convergent %(number)s $\\rightarrow$ 1, weights %(weight)s, delays %(delay)s"% {'weight': _process_random(weights), 'delay': _process_random(delays), 'number': number}
 
     if isinstance(weights, (int, float)) and not force_multiple_weights:
         self._single_constant_weight = True
 
     # if weights or delays are from random distribution I need to know this in code generator
     self.connector_weight_dist = weights if isinstance(weights, RandomDistribution) else None
     self.connector_delay_dist = delays if isinstance(delays, RandomDistribution) else None
 
     self._store_connectivity(fixed_number_pre, (number, weights, delays, allow_self_connections, storage_format, storage_order), delays, storage_format, storage_order)
+
     return self
 
-def connect_fixed_number_post(self, number, weights=1.0, delays=0.0, allow_self_connections=False, force_multiple_weights=False, storage_format=None, storage_order=None):
+def connect_fixed_number_post(self, number:int, weights:float | RandomDistribution=1.0, delays:float | RandomDistribution=0.0, allow_self_connections:bool=False, force_multiple_weights:bool=False, storage_format:str=None, storage_order:str=None)  -> "Projection":
     """
-    Builds a connection pattern between the two populations with a fixed number of post-synaptic neurons.
+    Each pre-synaptic neuron randomly sends a fixed number of connections to the post-synaptic neurons.
 
-    Each neuron in the pre-synaptic population sends connections to a fixed number of neurons of the post-synaptic population chosen randomly.
-
-    :param number: number of synapses per pre-synaptic neuron.
-    :param weights: either a single value for all synapses or a RandomDistribution object.
-    :param delays: either a single value for all synapses or a RandomDistribution object (default = dt)
-    :param allow_self_connections: defines if self-connections are allowed (default=False)
-    :param force_multiple_weights: if a single value is provided for ``weights`` and there is no learning, a single weight value will be used for the whole projection instead of one per synapse. Setting ``force_multiple_weights`` to True ensures that a value per synapse will be used.
+    :param number: Number of synapses per pre-synaptic neuron.
+    :param weights: Either a single value for all synapses or a RandomDistribution object.
+    :param delays: Either a single value for all synapses or a RandomDistribution object (default = dt)
+    :param allow_self_connections: Defines if self-connections are allowed (default=False)
+    :param force_multiple_weights: If a single value is provided for ``weights`` and there is no learning, a single weight value will be used for the whole projection instead of one per synapse. Setting ``force_multiple_weights`` to True ensures that a value per synapse will be used.
     """
     if self.pre != self.post:
         allow_self_connections = True
 
     if number > self.post.size:
-        Global._error('connect_fixed_number_post: the number of post-synaptic neurons exceeds the size of the population.')
+        Messages._error('connect_fixed_number_post: the number of post-synaptic neurons exceeds the size of the population.')
 
     self.connector_name = "Random Divergent"
     self.connector_description = "Random Divergent 1 $\\rightarrow$ %(number)s, weights %(weight)s, delays %(delay)s"% {'weight': _process_random(weights), 'delay': _process_random(delays), 'number': number}
 
     if isinstance(weights, (int, float)) and not force_multiple_weights:
         self._single_constant_weight = True
 
     # if weights or delays are from random distribution I need to know this in code generator
     self.connector_weight_dist = weights if isinstance(weights, RandomDistribution) else None
     self.connector_delay_dist = delays if isinstance(delays, RandomDistribution) else None
 
     self._store_connectivity(fixed_number_post, (number, weights, delays, allow_self_connections, storage_format, storage_order), delays, storage_format, storage_order)
     return self
 
-def connect_with_func(self, method, storage_format=None, storage_order=None, **args):
+
+def connect_with_func(self, method, storage_format:str=None, storage_order:str=None, **args) -> "Projection":
     """
-    Builds a connection pattern based on a user-defined method.
+    Connection pattern based on a user-defined function.
+
+    The two first arguments of the function must be the pre and post populations. Additional arguments can be passed at creation time.
+
+    The function must return a `ann.LILConnectivity` object.
+
+    Example:
+
+    ```python
+    def probabilistic_pattern(pre, post, weight, probability):
+        # Create a LIL structure for the connectivity matrix
+        synapses = ann.LILConnectivity()
+        # For all neurons in the post-synaptic population
+        for post_rank in xrange(post.size):
+            # Decide which pre-synaptic neurons should form synapses
+            ranks = []
+            for pre_rank in xrange(pre.size):
+                if random.random() < probability:
+                    ranks.append(pre_rank)
+            # Create weights and delays arrays of the same size
+            values = [weight for i in xrange(len(ranks)) ]
+            delays = [0 for i in xrange(len(ranks)) ]
+            # Add this information to the LIL matrix
+            synapses.add(post_rank, ranks, values, delays)
+
+        return synapses
+
+    proj = ann.Projection(pop1, pop2, target = 'inh')
+    proj.connect_with_func(
+        method=probabilistic_pattern, 
+        weight=1.0, 
+        probability=0.3
+    ) 
 
-    :param method: method to call. The method **must** return a CSR object.
-    :param args: list of arguments needed by the function
+    ```
+
+    :param method: Method to call. The method **must** return a LILConnectivity object.
+    :param args: List of additional arguments needed by the function.
     """
     # Invoke the method directly, we need the delays already....
     synapses = method(self.pre, self.post, **args)
     synapses.validate()
 
     # Treat delays
     if synapses.uniform_delay != -1: # uniform delay
-        d = synapses.max_delay * Global.config['dt']
+        d = synapses.max_delay * get_global_config('dt')
         self.connector_delay_dist = None
     else:
         # Just to trick _store_connectivity(), the real delays are in the CSR
-        d = DiscreteUniform(0., synapses.max_delay * Global.config['dt'])
-        self.connector_delay_dist = DiscreteUniform(0., synapses.max_delay * Global.config['dt'])
+        d = DiscreteUniform(0., synapses.max_delay * get_global_config('dt'))
+        self.connector_delay_dist = DiscreteUniform(0., synapses.max_delay * get_global_config('dt'))
 
     self._store_connectivity(self._load_from_lil, (synapses, ), d, storage_format=storage_format, storage_order=storage_order)
 
     self.connector_name = "User-defined"
     self.connector_description = "Created by the method " + method.__name__
     return self
 
-def connect_from_matrix_market(self, filename, storage_format=None, storage_order=None):
+def connect_from_matrix_market(self, filename:str, storage_format:str=None, storage_order:str=None) -> "Projection":
     """
-    Read in a weight matrix encoded in the Matrix Market format. This connector is intended for benchmarking purposes.
+    Loads a weight matrix encoded in the Matrix Market format. This connector is intended for benchmarking purposes.
 
-    TODO: check if the routine works for empty rows!
+    :param filename: Filename of the Matrix Market (.mtx) file.
     """
     from scipy.io import mmread
     from scipy.sparse import coo_matrix
     import tarfile
 
-    from ANNarchy.core.cython_ext import LILConnectivity
+    from ANNarchy.cython_ext import LILConnectivity
     if not filename.endswith(".mtx"):
         raise ValueError("connect_from_matrix_market(): expected .mtx file.")
 
     # read with SciPy
     tmp = mmread(filename)
 
     # scipy should return a coo_matrix in case of sparse matrices
@@ -313,36 +349,36 @@
 
 def _load_from_lil(self, pre, post, synapses):
     """
     Load from LILConnectivity instance.
     """
     return synapses
 
-def connect_from_matrix(self, weights, delays=0.0, pre_post=False, storage_format=None, storage_order=None):
+def connect_from_matrix(self, weights: np.array, delays=0.0, pre_post=False, storage_format=None, storage_order=None) -> "Projection":
     """
     Builds a connection pattern according to a dense connectivity matrix.
 
     The matrix must be N*M, where N is the number of neurons in the post-synaptic population and M in the pre-synaptic one. Lists of lists must have the same size.
 
     If a synapse should not be created, the weight value should be None.
 
-    :param weights: a matrix or list of lists representing the weights. If a value is None, the synapse will not be created.
-    :param delays: a matrix or list of lists representing the delays. Must represent the same synapses as weights. If the argument is omitted, delays are 0.
-    :param pre_post: states which index is first. By default, the first dimension is related to the post-synaptic population. If ``pre_post`` is True, the first dimension is the pre-synaptic population.
+    :param weights: Numpy array (or list of lists of equal size) representing the weights. If a value is None, the corresponding synapse will not be created.
+    :param delays: Numpy array representing the delays. Must represent the same synapses as the `weights` argument. If omitted, the delays are considered 0.
+    :param pre_post: States which index is first. By default, the first dimension is related to the post-synaptic population. If ``pre_post`` is True, the first dimension is the pre-synaptic population.
     """
 
     # Store the synapses
     self.connector_name = "Connectivity matrix"
     self.connector_description = "Connectivity matrix"
 
     if isinstance(weights, list):
         try:
             weights = np.array(weights)
         except:
-            Global._error('connect_from_matrix(): You must provide a dense 2D matrix.')
+            Messages._error('connect_from_matrix(): You must provide a dense 2D matrix.')
 
     self._store_connectivity(self._load_from_matrix, (weights, delays, pre_post), delays, storage_format, storage_order)
 
     return self
 
 def _load_from_matrix(self, pre, post, weights, delays, pre_post):
     """
@@ -358,33 +394,33 @@
     lil = LILConnectivity()
 
     uniform_delay = not isinstance(delays, (list, np.ndarray))
     if isinstance(delays, list):
         try:
             delays = np.array(delays)
         except:
-            Global._error('connect_from_matrix(): You must provide a dense 2D matrix.')
+            Messages._error('connect_from_matrix(): You must provide a dense 2D matrix.')
 
     if pre_post: # if the user prefers pre as the first index...
         weights = weights.T
         if isinstance(delays, np.ndarray):
             delays = delays.T
 
     shape = weights.shape
     if shape != (self.post.size, self.pre.size):
         if not pre_post:
-            Global._print("ERROR: connect_from_matrix(): the matrix does not have the correct dimensions.")
-            Global._print('Expected:', (self.post.size, self.pre.size))
-            Global._print('Received:', shape)
+            Messages._print("ERROR: connect_from_matrix(): the matrix does not have the correct dimensions.")
+            Messages._print('Expected:', (self.post.size, self.pre.size))
+            Messages._print('Received:', shape)
 
         else:
-            Global._print("ERROR: connect_from_matrix(): the matrix does not have the correct dimensions.")
-            Global._print('Expected:', (self.pre.size, self.post.size))
-            Global._print('Received:', shape)
-        Global._error('Quitting...')
+            Messages._print("ERROR: connect_from_matrix(): the matrix does not have the correct dimensions.")
+            Messages._print('Expected:', (self.pre.size, self.post.size))
+            Messages._print('Received:', shape)
+        Messages._error('Quitting...')
 
     for i in range(self.post.size):
         if isinstance(self.post, PopulationView):
             rk_post = self.post.ranks[i]
         else:
             rk_post = i
         r = []
@@ -404,33 +440,33 @@
         if uniform_delay:
             d.append(delays)
         if len(r) > 0:
             lil.add(rk_post, r, w, d)
 
     return lil
 
-def connect_from_sparse(self, weights, delays=0.0, storage_format=None, storage_order=None):
+def connect_from_sparse(self, weights:"scipy.sparse.lil_matrix", delays: int | float=0.0, storage_format:str=None, storage_order:str=None) -> "Projection":
     """
     Builds a connectivity pattern using a Scipy sparse matrix for the weights and (optionally) delays.
 
     Warning: a sparse matrix has pre-synaptic ranks as first dimension.
 
     :param weights: a sparse lil_matrix object created from scipy.
-    :param delays: the value of the constant delay (default: dt).
+    :param delays: the value of the constant delay (default: dt). Variable delays are not allowed.
     """
     try:
         from scipy.sparse import lil_matrix, csr_matrix, csc_matrix
     except:
-        Global._error("connect_from_sparse(): scipy is not installed, sparse matrices can not be loaded.")
+        Messages._error("connect_from_sparse(): scipy is not installed, sparse matrices can not be loaded.")
 
     if not isinstance(weights, (lil_matrix, csr_matrix, csc_matrix)):
-        Global._error("connect_from_sparse(): only lil, csr and csc matrices are allowed for now.")
+        Messages._error("connect_from_sparse(): only lil, csr and csc matrices are allowed for now.")
 
     if not isinstance(delays, (int, float)):
-        Global._error("connect_from_sparse(): only constant delays are allowed for sparse matrices.")
+        Messages._error("connect_from_sparse(): only constant delays are allowed for sparse matrices.")
 
     weights = csc_matrix(weights)
 
     # if weights[weights.nonzero()].max() == weights[weights.nonzero()].min() :
     #     self._single_constant_weight = True
 
     # Store the synapses
@@ -456,50 +492,47 @@
         post_ranks = [i for i in range(self.post.size)]
 
     # Process the sparse matrix and fill the lil
     weights.sort_indices()
     (pre, post) = weights.shape
 
     if (pre, post) != (len(pre_ranks), len(post_ranks)):
-        Global._print("ERROR: connect_from_sparse(): the sparse matrix does not have the correct dimensions.")
-        Global._print('Expected:', (len(pre_ranks), len(post_ranks)))
-        Global._print('Received:', (pre, post))
-        Global._error('Quitting...')
-
+        Messages._print("ERROR: connect_from_sparse(): the sparse matrix does not have the correct dimensions.")
+        Messages._print('Expected:', (len(pre_ranks), len(post_ranks)))
+        Messages._print('Received:', (pre, post))
+        Messages._error('Quitting...')
 
     for idx_post in range(post):
         idx_pre = weights.getcol(idx_post).indices
         w = weights.getcol(idx_post).data
         pr = [pre_ranks[i] for i in idx_pre]
         lil.add(post_ranks[idx_post], pr, w, [float(delays)])
 
     return lil
 
-def connect_from_file(self, filename, pickle_encoding=None, storage_format=None, storage_order=None):
+def connect_from_file(self, filename:str, pickle_encoding:str=None, storage_format:str=None, storage_order:str=None)  -> "Projection":
     """
-    Builds the connectivity matrix using data saved using the Projection.save_connectivity() method (not save()!).
+    Builds the connectivity matrix using data saved using `Projection.save_connectivity()` (not `save()`!).
 
     Admissible file formats are compressed Numpy files (.npz), gunzipped binary text files (.gz) or binary text files.
 
-    :param filename: file where the connections were saved.
+    Note: Only the ranks, weights and delays are loaded, not the other variables.
 
-    .. note::
-
-        Only the ranks, weights and delays are loaded, not the other variables.
+    :param filename: file where the connections were saved.
     """
     # Create an empty LIL object
     lil = LILConnectivity()
 
     # Load the data
     from ANNarchy.core.IO import _load_connectivity_data
     try:
         data = _load_connectivity_data(filename, pickle_encoding)
     except Exception as e:
-        Global._print(e)
-        Global._error('connect_from_file(): Unable to load the data', filename, 'into the projection.')
+        Messages._print(e)
+        Messages._error('connect_from_file(): Unable to load the data', filename, 'into the projection.')
 
     # Load the LIL object
     try:
         # Size
         lil.size = data['size']
         lil.nb_synapses = data['nb_synapses']
 
@@ -524,16 +557,16 @@
         if data['delay'] is not None:
             if lil.uniform_delay == -1:
                 lil.delay = list(data['delay'])
             else:
                 lil.delay = [[lil.max_delay]]
 
     except Exception as e:
-        Global._print(e)
-        Global._error('Unable to load the data', filename, 'into the projection.')
+        Messages._print(e)
+        Messages._error('Unable to load the data', filename, 'into the projection.')
 
     # Store the synapses
     self.connector_name = "From File"
     self.connector_description = "From File"
     self._store_connectivity(self._load_from_lil, (lil,), lil.max_delay if lil.uniform_delay > 0 else lil.delay, storage_format=storage_format, storage_order=storage_order)
 
     return self
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/Dendrite.py` & `annarchy-4.8.0.1/ANNarchy/core/Dendrite.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,87 +1,88 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-import ANNarchy.core.Global as Global
-from ANNarchy.core import Synapse
-from ANNarchy.core.Random import RandomDistribution
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern import Messages
 
 import numpy as np
 
 class Dendrite :
     """
-    A ``Dendrite`` is a sub-group of a ``Projection``, gathering the synapses between the pre-synaptic population and a single post-synaptic neuron.
+    A `Dendrite` is a sub-group of a `Projection`, gathering the synapses between the pre-synaptic population and a single post-synaptic neuron.
 
     It can not be created directly, only through a call to ``Projection.dendrite(rank)``:
 
     ```python
     dendrite = proj.dendrite(6)
     ```
     """
     def __init__(self, proj, post_rank, idx):
 
         self.post_rank = post_rank
+        "Rank of the post-synaptic neuron."
         self.idx = idx
         self.proj = proj
+        "Parent projection."
         self.pre = proj.pre
 
         self.target = self.proj.target
 
         self.attributes = self.proj.attributes
         self.parameters = self.proj.parameters
         self.variables = self.proj.variables
 
     @property
-    def size(self):
+    def size(self) -> int:
         """
         Number of synapses.
         """
         if self.proj.cyInstance:
             return self.proj.cyInstance.dendrite_size(self.idx)
         return 0
 
     @property
-    def pre_ranks(self):
+    def pre_ranks(self) -> list[int]:
         """
         List of ranks of pre-synaptic neurons.
         """
         if self.proj.cyInstance:
             return self.proj.cyInstance.pre_rank(self.idx)
         return []
 
     def __len__(self):
         # Number of synapses.
-        
         return self.size
 
     @property
-    def synapses(self):
+    def synapses(self) -> "IndividualSynapse":
         """
         Iteratively returns the synapses corresponding to this dendrite.
         """
         for n in self.pre_ranks:
             yield IndividualSynapse(self, n)
 
-    def synapse(self, pos):
+    def synapse(self, pos:int|tuple[int]) -> "IndividualSynapse":
         """
         Returns the synapse coming from the corresponding presynaptic neuron.
 
         :param pos: can be either the rank or the coordinates of the presynaptic neuron
+        :returns: `IndividualSynapse` wrapper instance.
         """
         if isinstance(pos, int):
             rank = pos
         else:
             rank = self.proj.pre.rank_from_coordinates(pos)
 
         if rank in self.pre_ranks:
             return IndividualSynapse(self, rank)
         else:
-            Global._error(" The neuron of rank "+ str(rank) + " has no synapse in this dendrite.")
+            Messages._error(" The neuron of rank "+ str(rank) + " has no synapse in this dendrite.")
             return None
 
     # Iterators
     def __getitem__(self, *args, **kwds):
         # Returns the synapse of the given position in the presynaptic population.
         # If only one argument is given, it is a rank. If it is a tuple, it is coordinates.
         
@@ -99,28 +100,28 @@
     #########################
     def __getattr__(self, name):
         # Method called when accessing an attribute.
         if name == 'proj':
             return object.__getattribute__(self, name)
         elif hasattr(self, 'proj'):
             if name == 'rank': # TODO: remove 'rank' in a future version
-                Global._warning("Dendrite.rank: the attribute is deprecated, use Dendrite.pre_ranks instead.")
+                Messages._warning("Dendrite.rank: the attribute is deprecated, use Dendrite.pre_ranks instead.")
                 return self.proj.cyInstance.pre_rank(self.idx)
             
             elif name == 'pre_rank':
                 return self.proj.cyInstance.pre_rank(self.idx)
             
             elif name == 'delay':
                 if self.proj.uniform_delay == -1:
-                    return [d*Global.config['dt'] for d in self.proj.cyInstance.get_dendrite_delay(self.idx)]
+                    return [d*get_global_config('dt') for d in self.proj.cyInstance.get_dendrite_delay(self.idx)]
                 else:
-                    return self.proj.max_delay * Global.config['dt']
+                    return self.proj.max_delay * get_global_config('dt')
             
             elif name == "w" and self.proj._has_single_weight():
-                return self.proj.cyInstance.get_global_attribute(name, Global.config["precision"])
+                return self.proj.cyInstance.get_global_attribute(name, get_global_config('precision'))
             
             elif name in self.proj.attributes:
                 # Determine C++ data type
                 ctype = None
                 for var in self.proj.synapse_type.description['variables']+self.proj.synapse_type.description['parameters']:
                     if var['name'] == name:
                         ctype = var['ctype']
@@ -156,21 +157,22 @@
                     else:
                         self.proj.cyInstance.set_local_attribute_row(name, self.idx, value * np.ones(self.size), ctype)
 
                 elif name in self.proj.synapse_type.description['semiglobal']:
                     self.proj.cyInstance.set_semiglobal_attribute(name, self.idx, value, ctype)
 
                 else:
-                    raise Global._error("Projection attributes marked as *projection* should not be updated through dendrites.")
+                    # HD: will break the execution of the program
+                    Messages._error("Projection attributes marked as *projection* should not be updated through dendrites.")
             else:
                 object.__setattr__(self, name, value)
         else:
             object.__setattr__(self, name, value)
 
-    def set(self, value):
+    def set(self, value:dict) -> None:
         """
         Sets the value of a parameter/variable of all synapses.
 
         Example:
 
         ```python
         dendrite.set( { 'tau' : 20, 'w'= Uniform(0.0, 1.0) } )
@@ -179,105 +181,107 @@
         :param value: a dictionary containing the parameter/variable names as keys.
         """
         for key, value in value.items():
             # sanity check and then forward to __setattr__
             if key in self.attributes:
                 setattr(self, key, value)
             else:
-                Global._error("Dendrite has no parameter/variable called", key)
+                Messages._error("Dendrite has no parameter/variable called", key)
 
-    def get(self, name):
+    def get(self, name:str) -> float:
         """
         Returns the value of a variable/parameter.
 
         Example:
 
         ```python
         dendrite.get('w')
         ```
 
         :param name: name of the parameter/variable.
+        :returns: a single value.
         """
         if name == 'rank':
-            Global._warning("Dendrite.get('rank'): the attribute is deprecated, use Dendrite.pre_ranks instead.")
+            Messages._warning("Dendrite.get('rank'): the attribute is deprecated, use Dendrite.pre_ranks instead.")
             return self.proj.cyInstance.pre_rank(self.idx)
         elif name == 'pre_ranks':
             return self.proj.cyInstance.pre_rank(self.idx)
         elif name in self.attributes:
             return getattr(self, name)
         else:
-            Global._error("Dendrite has no parameter/variable called", name)
+            Messages._error("Dendrite has no parameter/variable called", name)
 
 
     #########################
     ### Formatting
     #########################
-    def receptive_field(self, variable='w', fill=0.0):
+    def receptive_field(self, variable:str='w', fill:float=0.0) -> np.array:
         """
         Returns the given variable as a receptive field.
 
         A Numpy array of the same geometry as the pre-synaptic population is returned. 
         Non-existing synapses are replaced by zeros (or the value ``fill``).
 
         :param variable: name of the variable (default = 'w')
         :param fill: value to use when a synapse does not exist (default: 0.0).
+        :returns: an array.
         """
         values = getattr(self.proj.cyInstance, 'get_dendrite_'+variable)(self.idx)
         pre_ranks = self.proj.cyInstance.pre_rank( self.idx )
 
         m = fill * np.ones( self.pre.size )
         m[pre_ranks] = values
 
         return m.reshape(self.pre.geometry)
 
 
     #########################
     ### Structural plasticity
     #########################
-    def create_synapse(self, rank, w=0.0, delay=0):
+    def create_synapse(self, rank:int, w:float=0.0, delay:float=0) -> None:
         """
         Creates a synapse for this dendrite with the given pre-synaptic neuron.
 
         :param rank: rank of the pre-synaptic neuron
-        :param w: synaptic weight (defalt: 0.0).
-        :param delay: synaptic delay (default = dt)
+        :param w: synaptic weight.
+        :param delay: synaptic delay.
         """
-        if not Global.config['structural_plasticity']:
-            Global._error('"structural_plasticity" has not been set to True in setup(), can not add the synapse.')
+        if not get_global_config('structural_plasticity'):
+            Messages._error('"structural_plasticity" has not been set to True in setup(), can not add the synapse.')
             return
 
         if self.proj.cyInstance.dendrite_index(self.post_rank, rank) != -1:
-            Global._error('the synapse of rank ' + str(rank) + ' already exists.')
+            Messages._error('the synapse of rank ' + str(rank) + ' already exists.')
             return
 
         # Set default values for the additional variables
         extra_attributes = {}
         for var in self.proj.synapse_type.description['parameters'] + self.proj.synapse_type.description['variables']:
             if not var['name'] in ['w', 'delay'] and  var['name'] in self.proj.synapse_type.description['local']:
                 if not isinstance(self.proj.init[var['name']], (int, float, bool)):
                     init = var['init']
                 else:
                     init = self.proj.init[var['name']]
                 extra_attributes[var['name']] = init
 
         try:
-            self.proj.cyInstance.add_synapse(self.post_rank, rank, w, int(delay/Global.config['dt']), **extra_attributes)
+            self.proj.cyInstance.add_synapse(self.post_rank, rank, w, int(delay/get_global_config('dt')), **extra_attributes)
         except Exception as e:
-            Global._print(e)
+            Messages._print(e)
 
-    def create_synapses(self, ranks, weights=None, delays=None):
+    def create_synapses(self, ranks:list[int], weights:list[float]=None, delays:list[float]=None) -> None:
         """
-        Creates a synapse for this dendrite with the given pre-synaptic neuron.
+        Creates a synapse for this dendrite with the given pre-synaptic neurons.
 
-        :param ranks: rank of the pre-synaptic neuron
-        :param weights: synaptic weight (defalt: 0.0).
-        :param delays: synaptic delay (default = dt)
+        :param ranks: list of ranks of the pre-synaptic neurons.
+        :param weights: list of synaptic weights (default: 0.0).
+        :param delays: list of synaptic delays (default = dt).
         """
-        if not Global.config['structural_plasticity']:
-            Global._error('"structural_plasticity" has not been set to True in setup(), can not add the synapse.')
+        if not get_global_config('structural_plasticity'):
+            Messages._error('"structural_plasticity" has not been set to True in setup(), can not add the synapse.')
             return
 
         # No user-side init
         if weights is None:
             weights = [0.0] * len(ranks)
 
         if delays is None:
@@ -288,55 +292,55 @@
         for var in self.proj.synapse_type.description['parameters'] + self.proj.synapse_type.description['variables']:
             if not var['name'] in ['w', 'delay'] and  var['name'] in self.proj.synapse_type.description['local']:
                 extra_attribute_names.append[var['name']]
 
         # Create the synapses
         for rank, w, delay in zip(ranks, weights, delays):
             if self.proj.cyInstance.dendrite_index(self.post_rank, rank) != -1:
-                Global._error('the synapse of rank ' + str(ranks) + ' already exists.')
+                Messages._error('the synapse of rank ' + str(ranks) + ' already exists.')
                 return
 
             # Set default values for the additional variables
             extra_attributes = {}
             for var in extra_attribute_names:
                 if not isinstance(self.proj.init[var], (int, float, bool)):
                     init = var['init']
                 else:
                     init = self.proj.init[var]
                 extra_attributes[var] = init
 
             try:
-                self.proj.cyInstance.add_synapse(self.post_rank, rank, w, int(delay/Global.config['dt']), **extra_attributes)
+                self.proj.cyInstance.add_synapse(self.post_rank, rank, w, int(delay/get_global_config('dt')), **extra_attributes)
             except Exception as e:
-                Global._print(e)
+                Messages._print(e)
 
-    def prune_synapse(self, rank):
+    def prune_synapse(self, rank:int) -> None:
         """
         Removes the synapse with the given pre-synaptic neuron from the dendrite.
 
         :param rank: rank of the pre-synaptic neuron
         """
-        if not Global.config['structural_plasticity']:
-            Global._error('"structural_plasticity" has not been set to True in setup(), can not remove the synapse.')
+        if not get_global_config('structural_plasticity'):
+            Messages._error('"structural_plasticity" has not been set to True in setup(), can not remove the synapse.')
             return
 
         if not rank in self.pre_ranks:
-            Global._error('the synapse with the pre-synaptic neuron of rank ' + str(rank) + ' did not already exist.')
+            Messages._error('the synapse with the pre-synaptic neuron of rank ' + str(rank) + ' did not already exist.')
             return
 
         self.proj.cyInstance.remove_synapse(self.post_rank, rank)
 
-    def prune_synapses(self, ranks):
+    def prune_synapses(self, ranks:list[int]):
         """
         Removes the synapses which belong to the provided pre-synaptic neurons from the dendrite.
 
-        :param ranks: list of ranks of the pre-synaptic neurons
+        :param ranks: list of ranks of the pre-synaptic neurons.
         """
-        if not Global.config['structural_plasticity']:
-            Global._error('"structural_plasticity" has not been set to True in setup(), can not remove the synapse.')
+        if not get_global_config('structural_plasticity'):
+            Messages._error('"structural_plasticity" has not been set to True in setup(), can not remove the synapse.')
             return
 
         for rank in ranks:
             self.prune_synapse(rank)
 
 class IndividualSynapse :
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/Global.py` & `annarchy-4.8.0.1/ANNarchy/core/Network.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,806 +1,834 @@
 """
-Contains global available functions and state variables,
-e.g., the config dictionary and holds a reference to 
-network instances.
-
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-import sys, os
-import inspect
-import traceback
+from .Population import Population
+from .PopulationView import PopulationView
+from .Projection import Projection
+from .Monitor import Monitor
+from ANNarchy.intern.NetworkManager import NetworkManager
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern import Messages
+from ANNarchy.extensions.bold import BoldMonitor
+
+import ANNarchy.core.Global as Global
+import ANNarchy.core.Simulate as Simulate
+import ANNarchy.core.IO as IO
+import ANNarchy.generator.Compiler as Compiler
 import numpy as np
 
-from ANNarchy.core.NetworkManager import NetworkManager
-
-# High-level structures
-_objects = {
-    'functions': [],
-    'neurons': [],
-    'synapses': [],
-    'constants': [],
-}
-
-# Data for the different networks
-_network = NetworkManager()
-
-# Configuration
-config = dict(
-   {
-    'dt' : 1.0,
-    'verbose': False,
-    'debug': False,
-    'show_time': False,
-    'suppress_warnings': False,
-    'num_threads': 1,
-    'visible_cores': [],
-    'paradigm': "openmp",
-    'method': "explicit",
-    'sparse_matrix_format': "default",
-    'sparse_matrix_storage_order': "post_to_pre",
-    'precision': "double",
-    'only_int_idx_type': True,
-    'seed': -1,
-    'structural_plasticity': False,
-    'profiling': False,
-    'profile_out': None,
-    'disable_parallel_rng': True,
-    'use_seed_seq': True,
-    'use_cpp_connectors': False,
-    'disable_split_matrix': True,
-    'disable_SIMD_SpMV': True,
-    'disable_SIMD_Eq': False,
-    'disable_shared_library_time_offset': False
-   }
-)
-
-# This flags can not be configured through setup()
-_performance_related_config_keys = [
-    'disable_parallel_rng', 'use_seed_seq', 'use_cpp_connectors',
-    'disable_split_matrix', 'disable_SIMD_SpMV', 'disable_SIMD_Eq', 'only_int_idx_type'
-]
-
-# Profiling instance
-_profiler = None
-
-# Minimum number of neurons to apply OMP parallel regions
-OMP_MIN_NB_NEURONS = 100
-
-# Authorized keywork for attributes
-authorized_keywords = [
-    # Init
-    'init',
-    # Bounds
-    'min',
-    'max',
-    # Locality
-    'population',
-    'postsynaptic',
-    'projection',
-    # Numerical methods
-    'explicit',
-    'implicit',
-    'semiimplicit',
-    'exponential',
-    'midpoint',
-    'rk4',
-    'runge-kutta4', # backward compatibility
-    'exact',
-    'event-driven',
-    # Refractory
-    'unless_refractory',
-    # Type
-    'int',
-    'bool',
-    'float',
-    # Event-based
-    'unless_post',
-]
-
-def setup(**keyValueArgs):
+class Network :
     """
-    The setup function is used to configure ANNarchy simulation environment. It takes various optional arguments:
+    A network gathers already defined populations, projections and monitors in order to run them independently.
 
-    * dt: simulation step size (default: 1.0 ms).
-    * paradigm: parallel framework for code generation. Accepted values: "openmp" or "cuda" (default: "openmp").
-    * method: default method to numerize ODEs. Default is the explicit forward Euler method ('explicit').
-    * sparse_matrix_format: the default matrix format for projections in ANNarchy (by default: List-In-List for CPUs and Compressed Sparse Row).
-                            Note that affects only the C++ data structures.
-    * sparse_matrix_storage_order: encodes whether the row in a connectivity matrix encodes pre-synaptic neurons (post_to_pre, default) or 
-                                   post-synaptic neurons (pre_to_post). Note that affects only the C++ data structures.
-    * precision: default floating precision for variables in ANNarchy. Accepted values: "float" or "double" (default: "double")
-    * num_threads: number of treads used by openMP (overrides the environment variable ``OMP_NUM_THREADS`` when set, default = None).
-    * visible_cores: allows a fine-grained control which cores are useable for the created threads (default = [] for no limitation).
-                     It can be used to limit created openMP threads to a physical socket.
-    * structural_plasticity: allows synapses to be dynamically added/removed during the simulation (default: False).
-    * seed: the seed (integer) to be used in the random number generators (default = -1 is equivalent to time(NULL)).
-
-    The following parameters are mainly for debugging and profiling, and should be ignored by most users:
-
-    * verbose: shows details about compilation process on console (by default False). Additional some information of the network construction will be shown.
-    * suppress_warnings: if True, warnings (e. g. from the mathematical parser) are suppressed.
-    * show_time: if True, initialization times are shown. Attention: verbose should be set to True additionally.
-    * disable_shared_library_time_offset: by default False. If set to True, the shared library generated by ANNarchy will not be extended by time offset.
+    This is particularly useful when varying single parameters of a network and comparing the results (see the ``parallel_run()`` method).
 
-    **Note:**
+    Only objects declared before the creation of the network can be used. Global methods such as ``simulate()`` must be used on the network object.
+    The objects must be accessed through the ``get()`` method, as the original ones will not be part of the network (a copy is made).
 
-    This function should be used before any other functions of ANNarchy (including importing a network definition), right after `from ANNarchy import *`:
+    Each network must be individually compiled, but it does not matter if the original objects were already compiled.
 
-    ```python
-    from ANNarchy import *
-    setup(dt=1.0, method='midpoint', num_threads=2)
-    ```
+    When passing ``everything=True`` to the constructor, all populations/projections/monitors already defined at the global level will be added to the network.
 
-    """
-    if len(_network[0]['populations']) > 0 or len(_network[0]['projections']) > 0 or len(_network[0]['monitors']) > 0:
-        if 'dt' in keyValueArgs:
-            _warning('setup(): populations or projections have already been created. Changing dt now might lead to strange behaviors with the synaptic delays (internally generated in steps, not ms)...')
-        if 'precision' in keyValueArgs:
-            _warning('setup(): populations or projections have already been created. Changing precision now might lead to strange behaviors...')
-
-    for key in keyValueArgs:
-        # sanity check: filter out performance flags
-        if key in _performance_related_config_keys:
-            _error("Performance related flags can not be configured by setup()")
-
-        if key in config.keys():
-            config[key] = keyValueArgs[key]
-        else:
-            _warning('setup(): unknown key:', key)
-
-        if key == 'seed': # also seed numpy
-            np.random.seed(keyValueArgs[key])
-
-def _optimization_flags(**keyValueArgs):
-    """
-    In particular the ANNarchy 4.7.x releases added various optional arguments to control the code generation. Please take in mind, that these
-    flags might not being tested thoroughly on all features available in ANNarchy. They are intended for experimental features or performance analysis.
+    If not, you can select which object will be added to network with the ``add()`` method.
 
-    * only_int_idx_type: if set to True (default) only signed integers are used to store pre-/post-synaptic ranks which was default until 4.7.
-                         If set to False, the index type used in a single projection is selected based on the size of the corresponding populations.
-    * disable_parallel_rng: determines if random numbers drawn from distributions are generated from a single source (default: True). 
-                            If this flag is set to true only one RNG source is used und the values are drawn by one thread which 
-                            reduces parallel performance (this is the behavior of all ANNarchy versions prior to 4.7). 
-                            If set to false a seed sequence is generated to allow usage of one RNG per thread. Please note, that this
-                            flag won't effect the GPUs which draw from multiple sources anyways.
-    * use_seed_seq: If parallel RNGs are used the single generators need to be initialized. By default (use_seed_seq == True) we use
-                    the STL seed sequence to generate a list of seeds from the given master seed (*seed* argument). If set to False,
-                    we use an improved version of the sequence generator proposed by M.E. O'Neill (https://www.pcg-random.org/posts/simple-portable-cpp-seed-entropy.html)
-    * use_cpp_connectors:   For some of the default connectivity methods of ANNarchy we offer a CPP-side construction of the pattern to improve the
-                            initialization time (default=False). For maximum performance the disable_parallel_rng should be set to False to allow
-                            a parallel construction of the pattern.
-    * disable_split_matrix: determines if projections can use thread-local allocation. If set to *True* (default) no thread local allocation is allowed.
-                            This equals the behavior of ANNarchy until 4.7. If set to *False* the code generator can use sliced versions if they
-                            are available.
-    * disable_SIMD_SpMV: determines if the hand-written implementation is used (by default False) if the current hardware platform and used sparse matrix
-                         format does support the vectorization). Disabling is intended for performance analysis.
-
-    * disable_SIMD_Eq: this flags disables auto-vectorization and openMP simd (by default False). Disabling is intended for performance analysis.
-
-    **Note:**
-
-    This function should be used only for special purposes therefore its not publicly available.
+    Example with ``everything=True``:
 
     ```python
-    from ANNarchy import *  # will not work
-    from ANNarchy.core.Global import _optimization_flags
-    _optimization_flags(disable_parallel_rng=False)
-    ```
-
-    """
-    if len(_network[0]['populations']) > 0 or len(_network[0]['projections']) > 0 or len(_network[0]['monitors']) > 0:
-        if 'dt' in keyValueArgs:
-            _warning('setup(): populations or projections have already been created. Changing dt now might lead to strange behaviors with the synaptic delays (internally generated in steps, not ms)...')
-        if 'precision' in keyValueArgs:
-            _warning('setup(): populations or projections have already been created. Changing precision now might lead to strange behaviors...')
-
-    for key in keyValueArgs:
-        if key not in _performance_related_config_keys:
-            _error("The key", key, "does not belong to the performance related keys.")
-
-        if key in config.keys():
-            config[key] = keyValueArgs[key]
-
-            if key == "use_cpp_connectors":
-                if config[key] == True:
-                    _warning("use_cpp_connectors is an experimental feature, we greatly appreciate bug reports.")
-
-                    if "disable_parallel_rng" in config.keys():
-                        if config["use_cpp_connectors"] and config["disable_parallel_rng"]:
-                            _warning("If 'use_cpp_connectors' is enabled, the 'disable_parallel_rng' flag should be disabled for maximum efficiency.")
-
-        else:
-            _warning('_optimization_flags(): unknown key:', key)
-
-        if key == 'seed': # also seed numpy
-            np.random.seed(keyValueArgs[key])
-
-        if key == 'sparse_matrix_format':
-            # check if this is a supported format
-            if keyValueArgs[key] not in ["lil", "csr", "csr_vector", "csr_scalar", "dense", "ell", "ellr", "sell", "coo", "bsr", "hyb", "auto"]:
-                _error("The value", keyValueArgs[key], "provided to sparse_matrix_format is not valid.")
+    pop = ann.Population(100, Izhikevich)
+    proj = ann.Projection(pop, pop, 'exc')
+    proj.connect_all_to_all(1.0)
+    m = ann.Monitor(pop, 'spike')
+
+    ann.compile() # Optional
+
+    net = ann.Network(everything=True)
+    net.get(pop).a = 0.02
+    net.compile()
+    net.simulate(1000.)
+
+    net2 = ann.Network(everything=True)
+    net2.get(pop).a = 0.05
+    net2.compile()
+    net2.simulate(1000.)
 
-
-def clear(functions=True, neurons=True, synapses=True, constants=True):
-    """
-    Clears all variables (erasing already defined populations, projections, monitors and constants), as if you had just imported ANNarchy.
-
-    * functions: if True (default), all functions defined with ``add_function`` are erased.
-    * neurons: if True (default), all neurons defined with ``Neuron`` are erased.
-    * synapses: if True (default), all synapses defined with ``Synapse`` are erased.
-    * constants: if True (default), all constants defined with ``Constant`` are erased.
-
-    Useful when re-running Jupyter/IPython notebooks multiple times:
-
-    ```python
-    from ANNarchy import *
-    clear()
+    t, n = net.get(m).raster_plot()
+    t2, n2 = net2.get(m).raster_plot()
     ```
-    """
-    # Reset objects
-    global _objects
-    _objects = {
-        'functions': [] if functions else _objects['functions'],
-        'neurons': [] if neurons else _objects['neurons'],
-        'synapses': [] if synapses else _objects['synapses'],
-        'constants': [] if constants else _objects['constants'],
-    }
-
-    # Remove the present profiler
-    global _profiler
-    if _profiler is not None:
-        check_profile_results()
-
-        del _profiler
-
-        # restore default values
-        _profiler = None
-        config["profiling"] = False
-
-    # Reinitialize initial state
-    global _network
-    _network.clear()
-
-def check_profile_results():
-    """
-    If the user enabled profiling, we here check if we recorded some results.
-    """
-    if _profiler:
-        _profiler.print_profile()
 
-        _profiler.store_cpp_time_as_csv()
+    Example with ``everything=False`` (the default):
 
-def get_profiling_instance():
-    """
-    Get profiling instance which requires Global.config["profiling"] == True.
-    """
-    if _profiler:
-        return _profiler
-    else:
-        _warning("To use Profiler instance please activate profiling first.")
-        return None
+    ```python
+    pop = ann.Population(100, Izhikevich)
+    proj1 = ann.Projection(pop, pop, 'exc')
+    proj1.connect_all_to_all(1.0)
+    proj2 = ann.Projection(pop, pop, 'exc')
+    proj2.connect_all_to_all(2.0)
+    m = ann.Monitor(pop, 'spike')
+
+    net = ann.Network()
+    net.add([pop, proj1, m])
+    net.compile()
+    net.simulate(1000.)
+
+    net2 = ann.Network()
+    net2.add([pop, proj2, m])
+    net2.compile()
+    net2.simulate(1000.)
 
-def reset(populations=True, projections=False, synapses=False, monitors=True, net_id=0):
+    t, n = net.get(m).raster_plot()
+    t2, n2 = net2.get(m).raster_plot()
+    ```
+    
+    :param everything: defines if all existing populations and projections should be automatically added (default: False).   
     """
-    Reinitialises the network to its state before the call to compile. The network time will be set to 0ms.
 
-    All monitors are emptied.
+    def __init__(self, everything:bool=False):
 
-    :param populations: if True (default), the neural parameters and variables will be reset to their initial value.
-    :param projections: if True, the synaptic parameters and variables (except the connections) will be reset (default=False).
-    :param synapses: if True, the synaptic weights will be erased and recreated (default=False).
-    :param monitors: if True, the monitors will be emptied and reset (default=True).
-    """
+        self.id = NetworkManager().add_network(self)
+        self.everything = everything
 
-    _network[net_id]['instance'].set_time(0)
-    
-    if populations:
-        for pop in _network[net_id]['populations']:
-            pop.reset()
+        Simulate._callbacks.append([])
+        Simulate._callbacks_enabled.append(True)
+        
+        self.populations = []
+        self.projections = []
+        self.monitors = []
+        self.extensions = []
+
+        if everything:
+            self.add(NetworkManager().get_populations(net_id=0))
+            self.add(NetworkManager().get_projections(net_id=0))
+            self.add(NetworkManager().get_monitors(net_id=0))
+            self.add(NetworkManager().get_extensions(net_id=0))
 
-        # pop.reset only clears spike container with no or uniform delay
-        for proj in _network[net_id]['projections']:
-            if hasattr(proj.cyInstance, 'reset_ring_buffer'):
-                proj.cyInstance.reset_ring_buffer()
+    def __del__(self):
+        
+        # Overridden destructor for two reasons:
+        # 
+        # a) track destruction of objects
+        # b) manually deallocate C++ container data
+        # 
+        # Hint: this function can be called explicitly (which is not recommended in many cases) or as
+        #       finalizer from the garbage collection. If called explicitely, one should take in mind,
+        #       that the function will be called twice. The better approach is to trigger this function
+        #       by del on the network object.
+        for pop in self.get_populations():
+            pop._clear()
+            del pop
+
+        for proj in self.get_projections(suppress_error=True):
+            proj._clear()
+            del proj
+
+        for mon in self.monitors:
+            mon._clear()
+            del mon
+
+        for ext in self.extensions:
+            ext._clear()
+            del ext
 
-    if synapses and not projections:
-        _warning("reset(): if synapses is set to true this automatically enables projections==true")
-        projections = True
+        NetworkManager()._remove_network(self)
 
-    if projections:
-        for proj in _network[net_id]['projections']:
-            proj.reset(attributes=-1, synapses=synapses)
+    def _cpp_memory_footprint(self):
+        """
+        Print the C++ memory consumption for populations, projections on the console.
+        """
+        for pop in self.get_populations():
+            print(pop.name, pop.size_in_bytes())
 
-    if monitors:
-        for monitor in _network[net_id]['monitors']:
-            monitor.reset()
+        for proj in self.get_projections():
+            print(proj.name, proj.size_in_bytes())
 
+        for mon in self.monitors:
+            print(type(mon), mon.size_in_bytes())
 
-def get_population(name, net_id=0):
-    """
-    Returns the population with the given ``name``.
+    def add(self, objects:list) -> None:
+        """
+        Adds a Population, Projection or Monitor to the network.
 
-    :param name: name of the population.
-    :return: The requested ``Population`` object if existing, ``None`` otherwise.
-    """
-    for pop in _network[net_id]['populations']:
-        if pop.name == name:
-            return pop
+        :param objects: A single object or a list to add to the network.
+        """
+        if isinstance(objects, list):
+            for item in objects:
+                self._add_object(item)
+        else:
+            self._add_object(objects)
 
-    _warning("get_population(): the population", name, "does not exist.")
-    return None
+    def _add_object(self, obj):
+        """
+        Add the object *obj* to the network.
 
-def get_projection(name, net_id=0):
-    """
-    Returns the projection with the given *name*.
+        TODO: instead of creating copies by object construction, one should check if deepcopy works ...
+        """
+        if isinstance(obj, Population):
+            # Create a copy
+            pop = obj._copy()
+
+            # Remove the object created by _copy from the global network
+            NetworkManager()._remove_last_item_from_list(net_id=0, list_name='populations')
+
+            # Copy import properties
+            pop.id = obj.id
+            pop.name = obj.name
+            pop.class_name = obj.class_name
+            pop.init = obj.init
+            pop.enabled = obj.enabled
+            if not obj.enabled: # Also copy the enabled state:
+                pop.disable()
+
+            # Add the copy to the local network
+            NetworkManager().add_population(net_id=self.id, population=pop)
+            self.populations.append(pop)
+
+            # Check whether the computation of mean-firing rate is requested
+            if obj._compute_mean_fr > 0:
+                pop.compute_firing_rate(obj._compute_mean_fr)
+
+        elif isinstance(obj, Projection):
+            # Check the pre- or post- populations
+            try:
+                pre_pop = self.get(obj.pre)
+                if isinstance(obj.pre, PopulationView):
+                    pre = PopulationView(population=pre_pop.population, ranks=obj.pre.ranks)
+                else:
+                    pre = pre_pop
+                post_pop = self.get(obj.post)
+                if isinstance(obj.post, PopulationView):
+                    post = PopulationView(population=post_pop.population, ranks=obj.post.ranks)
+                else:
+                    post = post_pop
+            except:
+                Messages._error('Network.add(): The pre- or post-synaptic population of this projection are not in the network.')
+
+            # Create the projection
+            proj = obj._copy(pre=pre, post=post)
+
+            # Remove the object created by _copy from the global network
+            NetworkManager()._remove_last_item_from_list(net_id=0, list_name='projections')
+
+            # Copy import properties
+            proj.id = obj.id
+            proj.name = obj.name
+            proj.init = obj.init
+
+            # Copy the connectivity properties if the projection is not already set
+            if proj._connection_method is None:
+                proj._store_connectivity(method=obj._connection_method, args=obj._connection_args, delay=obj._connection_delay, storage_format=obj._storage_format, storage_order=obj._storage_order)
+
+            # Add the copy to the local network
+            NetworkManager().add_projection(net_id=self.id, projection=proj)
+            self.projections.append(proj)
+
+        elif isinstance(obj, BoldMonitor):
+            # Create a copy of the monitor
+            m = BoldMonitor(
+                populations=obj._populations,
+                bold_model=obj._bold_model,
+                mapping=obj._mapping,
+                scale_factor=obj._scale_factor,
+                normalize_input=obj._normalize_input,
+                recorded_variables=obj._recorded_variables,
+                start=obj._start,
+                net_id=self.id,
+                copied=True
+            )
+
+            # there is a bad mismatch between object ids:
+            #
+            # m.id     is dependent on len(_network[net_id].monitors)
+            # obj.id   is dependent on len(_network[0].monitors)
+            m.id = obj.id # TODO: check this !!!!
+
+            # Stop the master monitor, otherwise it gets data.
+            for var in obj._monitor.variables:
+                try:
+                    setattr(obj._monitor.cyInstance, 'record_'+var, False)
+                except:
+                    pass
+
+            # assign contained objects
+            m._monitor = self._get_object(obj._monitor)
+            m._bold_pop = self._get_object(obj._bold_pop)
+            m._acc_proj = []
+            for tmp in obj._acc_proj:
+                m._acc_proj.append(self._get_object(tmp))
+
+            # need to be done manually for copied instances
+            m._initialized = True
+
+            # Add the copy to the local network (the monitor writes itself already in the right network)
+            self.extensions.append(m)
+
+        elif isinstance(obj, Monitor):
+            # Get the copied reference of the object monitored
+            # try:
+            #     obj_copy = self.get(obj.object)
+            # except:
+            #     Messages._error('Network.add(): The monitor does not exist.')
+
+            # Stop the master monitor, otherwise it gets data.
+            for var in obj.variables:
+                try:
+                    setattr(obj.cyInstance, 'record_'+var, False)
+                except:
+                    pass
+            # Create a copy of the monitor
+            m = Monitor(obj=self._get_object(obj.object), variables=obj.variables, period=obj._period, period_offset=obj._period_offset, start=obj._start, net_id=self.id)
+
+            # there is a bad mismatch between object ids:
+            #
+            # m.id     is dependent on len(_network[net_id].monitors)
+            # obj.id   is dependent on len(_network[0].monitors)
+            m.id = obj.id # TODO: check this !!!!
 
-    :param name: name of the projection.
-    :return: The requested ``Projection`` object if existing, ``None`` otherwise.
-    """
-    for proj in _network[net_id]['projections']:
-        if proj.name == name:
-            return proj
+            # Add the copy to the local network (the monitor writes itself already in the right network)
+            self.monitors.append(m)
 
-    _warning("get_projection(): the projection", name, "does not exist.")
-    return None
+    def get(self, obj):
+        """
+        Returns the local Population, Projection or Monitor corresponding to the provided argument.
 
-def populations(net_id=0):
-    """
-    Returns a list of all declared populations.
-    """
-    return _network[net_id]['populations']
+        `obj` is for example a top-level poopulation, while `net.get(pop)`is the copy local to the network.
 
-def projections(net_id=0, post=None, pre=None, target=None, suppress_error=False):
-    """
-    Returns a list of all declared populations. By default, the method returns all connections which were defined.
-    By setting *one* of the arguments, post, pre and target one can select a subset accordingly.
+        Example:
 
-    :param post: all returned projections should have this population as post.
-    :param pre: all returned projections should have this population as pre.
-    :param target: all returned projections should have this target.
-    :param suppress_error: by default, ANNarchy throws an error if the list of assigned projections is empty. If this flag is set to True, the error message is suppressed.
-    :return: A list of all assigned projections in this network. Or a subset
-    according to the arguments.
-    """
-    if post is None and pre is None and target is None:
-        return _network[net_id]['projections']
-    else:
-        res = []
-        if isinstance(post, str):
-            post = get_population(post, net_id)
-        if isinstance(pre, str):
-            pre = get_population(pre, net_id)
-
-        # post is the criteria
-        if (post is not None) and (pre is None) and (target is None) :
-            for proj in _network[net_id]['projections']:
-                if proj.post == post:
-                    res.append(proj)
-
-        # pre is the criteria
-        elif (pre is not None) and (post is None) and (target is None):
-            for proj in _network[net_id]['projections']:
-                if proj.pre == pre:
-                    res.append(proj)
-
-        # post is the criteria
-        elif target is not None and (post is None) and (pre is None):
-            for proj in _network[net_id]['projections']:
-                if proj.target == target:
-                    res.append(proj)
+        ```python
+        pop = ann.Population(100, Izhikevich)
+        net = ann.Network()
+        net.add(pop)
+        net.compile()
+        
+        print(net.get(pop).v)
+        ```
 
+        :param obj: A single object or a list of objects.
+        :returns: The corresponding object or list of objects.
+        """
+        if isinstance(obj, list):
+            return [self._get_object(o) for o in obj]
         else:
-            raise ValueError("ANNarchy.core.Global.projections(): either none or one of the arguments post, pre, target must be set.")
-
-        return res
+            return self._get_object(obj)
 
+    def _get_object(self, obj):
+        "Retrieves the corresponding object."
+        if isinstance(obj, Population):
+            for pop in self.populations:
+                if pop.id == obj.id:
+                    return pop
+        elif isinstance(obj, PopulationView):
+            for pop in self.populations:
+                if pop.id == obj.id:
+                    return PopulationView(pop, obj.ranks) # Create on the fly?
+        elif isinstance(obj, Projection):
+            for proj in self.projections:
+                if proj.id == obj.id:
+                    return proj
+        elif isinstance(obj, Monitor):
+            for m in self.monitors:
+                if m.id == obj.id:
+                    return m
+        elif isinstance(obj, BoldMonitor):
+            for m in self.extensions:
+                if m.id == obj.id:
+                    return m
+        else:
+            Messages._error('The network has no such object:', obj.name, obj)
 
-################################
-## Functions
-################################
-def add_function(function):
-    """
-    Defines a global function which can be used by all neurons and synapses.
+    def compile(self,
+                directory:str='annarchy',
+                clean:bool=False,
+                compiler:str="default",
+                compiler_flags:list[str]="default",
+                add_sources:str="",
+                extra_libs:str="",
+                cuda_config:dict={'device': 0},
+                annarchy_json:str="",
+                silent:bool=False,
+                debug_build:bool=False,
+                profile_enabled:bool=False):
+        """
+        Compiles the network.
 
-    The function must have only one return value and use only the passed arguments.
+        :param directory: name of the subdirectory where the code will be generated and compiled. Must be a relative path. Default: "annarchy/".
+        :param clean: boolean to specifying if the library should be recompiled entirely or only the changes since last compilation (default: False).
+        :param compiler: C++ compiler to use. Default: g++ on GNU/Linux, clang++ on OS X. Valid compilers are [g++, clang++].
+        :param compiler_flags: platform-specific flags to pass to the compiler. Default: "-march=native -O2". Warning: -O3 often generates slower code and can cause linking problems, so it is not recommended.
+        :param cuda_config: dictionary defining the CUDA configuration for each population and projection.
+        :param annarchy_json: compiler flags etc are stored in a .json file normally placed in the home directory. With this flag one can directly assign a file location.
+        :param silent: defines if the "Compiling... OK" should be printed.
 
-    Examples of valid functions:
+        """
+        Compiler.compile(directory=directory, clean=clean, silent=silent, debug_build=debug_build, add_sources=add_sources, extra_libs=extra_libs, compiler=compiler, compiler_flags=compiler_flags, cuda_config=cuda_config, annarchy_json=annarchy_json, profile_enabled=profile_enabled, net_id=self.id)
 
-    ```python
-    logistic(x) = 1 / (1 + exp(-x))
+    def simulate(self, duration:float, measure_time:bool=False):
+        """
+        Runs the network for the given duration in milliseconds. 
+        
+        The number of simulation steps is  computed relative to the discretization step ``dt`` declared in ``setup()`` (default: 1ms):
 
-    piecewise(x, a, b) =    if x < a:
-                                a
-                            else:
-                                if x > b :
-                                    b
-                                else:
-                                    x
-    ```
+        ```python
+        net.simulate(1000.0)
+        ```
 
-    Please refer to the manual to know the allowed mathematical functions.
-    """
-    name = function.split('(')[0]
-    _objects['functions'].append( (name, function))
+        :param duration: the duration in milliseconds.
+        :param measure_time: defines whether the simulation time should be printed (default=False).
 
+        """
+        Simulate.simulate(duration, measure_time, net_id=self.id)
 
-def functions(name, net_id=0):
-    """
-    Allows to access a global function defined with ``add_function`` and use it from Python using arrays **after compilation**.
+    def simulate_until(self, max_duration:float, population:"Population", operator:str='and', measure_time:bool=False) -> float:
+        """
+        Runs the network for the maximal duration in milliseconds. If the `stop_condition` defined in the population becomes true during the simulation, it is stopped.
 
-    The name of the function is not added to the global namespace to avoid overloading.
-    
-    ```python
-    add_function("logistic(x) = 1. / (1. + exp(-x))") 
+        One can specify several populations. If the stop condition is true for any of the populations, the simulation will stop ('or' function).
 
-    compile()  
+        Example:
 
-    result = functions('logistic')([0., 1., 2., 3., 4.])
-    ```
- 
-    Only lists or 1D Numpy arrays can be passed as arguments, not single values nor multidimensional arrays.
+        ```python
+        pop1 = ann.Population( ..., stop_condition = "r > 1.0 : any")
+        ...
+        net.compile()
+        net.simulate_until(max_duration=1000.0. population=pop1)
+        ```
+
+        :param max_duration: the maximum duration of the simulation in milliseconds.
+        :param population: the (list of) population whose ``stop_condition`` should be checked to stop the simulation.
+        :param operator: operator to be used ('and' or 'or') when multiple populations are provided (default: 'and').
+        :param measure_time: defines whether the simulation time should be printed (default=False).
+        :returns: the actual duration of the simulation in milliseconds.
+        """
+        return Simulate.simulate_until(max_duration, population, operator, measure_time, net_id=self.id)
 
-    When passing several arguments, make sure they have the same size.
+    def step(self) -> None:
+        """
+        Performs a single simulation step (duration = ``dt``).
+        """
+        Simulate.step(self.id)
 
-    """
-    try:
-        func = getattr(_network[net_id]['instance'], 'func_' + name)
-    except:
-        _error('call to', name, ': the function is not compiled yet.')
-
-    return func
-
-################################
-## Constants
-################################
-class Constant(float):
-    """
-    Constant parameter that can be used by all neurons and synapses.
+    def reset(self, populations:bool=True, projections:bool=False, monitors:bool=True, synapses:bool=False) -> None:
+        """
+        Reinitialises the network to its state before the call to compile.
 
-    The class ``Constant`` derives from ``float``, so any legal operation on floats (addition, multiplication) can be used.
+        :param populations: if True (default), the neural parameters and variables will be reset to their initial value.
+        :param projections: if True, the synaptic parameters and variables (except the connections) will be reset (default=False).
+        :param synapses: if True, the synaptic weights will be erased and recreated (default=False).
+        """
+        Global.reset(populations=populations, projections=projections, synapses=synapses, monitors=monitors, net_id=self.id)
 
-    If a Neuron/Synapse defines a parameter with the same name, the constant parameters will not be visible.
+    def get_time(self) -> float:
+        "Returns the current time in ms."
+        return Global.get_time(self.id)
 
-    Example:
+    def set_time(self, t:float, net_id=0) -> None:
+        """
+        Sets the current time in ms.
 
-    ```python
+        **Warning:** can be dangerous for some spiking models.
+        """
+        Global.set_time(t, self.id)
 
-    tau = Constant('tau', 20)
-    factor = Constant('factor', 0.1)
-    real_tau = Constant('real_tau', tau*factor)
-
-    neuron = Neuron(
-        equations='''
-            real_tau*dr/dt + r =1.0
-        '''
-    )
-    ```
+    def get_current_step(self) -> int:
+        "Returns the current simulation step."
+        return Global.get_current_step(self.id)
 
-    The value of the constant can be changed anytime with the ``set()`` method. Assignments will have no effect (e.g. ``tau = 10.0`` only creates a new float).
+    def set_current_step(self, t:int):
+        """
+        Sets the current simulation step.
 
-    The value of constants defined as combination of other constants (``real_tau``) is not updated if the value of these constants changes (changing ``tau`` with ``tau.set(10.0)`` will not modify the value of ``real_tau``).
+        **Warning:** can be dangerous for some spiking models.
+        """
+        Global.set_current_step(t, self.id)
 
-    """
-    def __new__(cls, name, value, net_id=0):
-        return float.__new__(cls, value)
-        
-    def __init__(self, name, value, net_id=0):
+    def set_seed(self, seed:int, use_seed_seq:bool=True) -> None:
         """
-        :param name: name of the constant (unique), which can be used in equations.
-        :param value: the value of the constant, which must be a float, or a combination of Constants.
+        Sets the seed of the random number generators for this network.
         """
+        Global.set_seed(seed=seed, use_seed_seq=use_seed_seq, net_id=self.id)
 
-        self.name = name
-        self.value = value
-        self.net_id = net_id
-        for obj in _objects['constants']:
-            if obj.name == name:
-                _error('the constant', name, 'is already defined.')
-        _objects['constants'].append(self)
-    def __str__(self):
-        return str(self.value)
-    def __repr__(self):
-        return self.__str__()
-    def set(self, value):
-        "Changes the value of the constant."
-        self.value = value
-        if _network[self.net_id]['compiled']:
-            getattr(_network[self.net_id]['instance'], '_set_'+self.name)(self.value)
-
-def list_constants(net_id=0):
-    """
-    Returns a list of all constants declared with ``Constant(name, value)``.
-    """
-    l = []
-    for obj in _objects['constants']:
-        l.append(obj.name)
-    return l
-
-def get_constant(name, net_id=0):
-    """
-    Returns the ``Constant`` object with the given name, ``None`` otherwise.
-    """
-    for obj in _objects['constants']:
-        if obj.name == name:
-            return obj
-    return None
-
-
-################################
-## Memory management
-################################
-def _bytes_human_readable(size_in_bytes):
-    """ Transforms given size in GB/MB/KB or bytes dependent on the value. """
-    if size_in_bytes > (1024*1024*1024):
-        return "{:.2f} GB".format(float(size_in_bytes)/(1024.0*1024.0*1024.0))
-    elif size_in_bytes > (1024*1024):
-        return "{:.2f} MB".format(float(size_in_bytes)/(1024.0*1024.0))
-    elif size_in_bytes > (1024):
-        return "{:.2f} KB".format(float(size_in_bytes)/(1024.0))
-    else:
-        return str(size_in_bytes) + " bytes"
-
-def _cpp_memory_footprint(net_id=0):
-    """
-    Print the C++ memory consumption for populations, projections on the console.
-
-    :param net_id: net_id of the requested network.
-    """
-    print("Memory consumption of C++ objects: ")
+    def enable_learning(self, projections:list=None, period:float=None, offset:float=None) -> None:
+        """
+        Enables learning for all projections.
 
-    for pop in populations(net_id):
-        print(pop.name, _bytes_human_readable(pop.size_in_bytes()))
+        :param projections: the projections whose learning should be enabled. By default, all the existing projections are disabled.
+        """
+        if not projections:
+            projections = self.projections
+        for proj in projections:
+            proj.enable_learning(period=period, offset=offset)
 
-    for proj in projections(net_id):
-        print(proj.name, _bytes_human_readable(proj.size_in_bytes()))
+    def disable_learning(self, projections:list=None) -> None:
+        """
+        Disables learning for all projections.
 
-    for mon in _network[net_id]['monitors']:
-        print(mon.name, _bytes_human_readable(mon.size_in_bytes()))
+        :param projections: the projections whose learning should be disabled. By default, all the existing projections are disabled.
+        """
+        if not projections:
+            projections = self.projections
+        for proj in projections:
+            proj.disable_learning()
 
-def _python_current_max_rusage():
-    """
-    Prints the current max residen size for the current process and the children.
-    """
-    import resource
-    size_kilobytes = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
-    print(_bytes_human_readable(size_kilobytes*1024))
-
-################################
-## Learning flags
-################################
-def enable_learning(projections=None, period=None, offset=None, net_id=0):
-    """
-    Enables learning for all projections. Optionally *period* and *offset* can be changed for all projections.
+    def get_population(self, name:str) -> "Population":
+        """
+        Returns the population with the given name.
 
-    :param projections: the projections whose learning should be enabled. By default, all the existing projections are enabled.
-    :param period: determines how often the synaptic variables will be updated.
-    :param offset: determines the offset at which the synaptic variables will be updated relative to the current time.
+        :param name: name of the population
+        :returns: The requested ``Population`` object if existing, ``None`` otherwise.
+        """
+        for pop in self.populations:
+            if pop.name == name:
+                return pop
+        Messages._print('get_population(): the population', name, 'does not exist in this network.')
+        return None
 
-    """
-    if not projections:
-        projections = _network[net_id]['projections']
-    for proj in projections:
-        proj.enable_learning(period, offset)
+    def get_projection(self, name:str) -> "Projection":
+        """
+        Returns the projection with the given name.
 
-def disable_learning(projections=None, net_id=0):
-    """
-    Disables learning for all projections.
+        :param name: name of the projection
+        :returns: The requested ``Projection`` object if existing, ``None`` otherwise.
+        """
+        for proj in self.projections:
+            if proj.name == name:
+                return proj
+        Messages._print('get_projection(): the projection', name, 'does not exist in this network.')
+        return None
 
-    :param projections: the projections whose learning should be disabled. By default, all the existing projections are disabled.
-    """
-    if not projections:
-        projections = _network[net_id]['projections']
-    for proj in projections:
-        proj.disable_learning()
-
-################################
-## Time
-################################
-def get_time(net_id=0):
-    "Returns the current time in ms."
-    try:
-        t = _network[net_id]['instance'].get_time()*config['dt']
-    except:
-        t = 0.0
-    return t
+    def get_populations(self) -> list["Population"]:
+        """
+        Returns a list of all declared populations in this network.
 
-def set_time(t, net_id=0):
-    """
-    Sets the current time in ms.
+        :returns: the list of all populations in the network.
+        """
+        if self.populations == []:
+            Messages._warning("Network.get_populations(): no populations attached to this network.")
+        return self.populations
 
-    **Warning:** can be dangerous for some spiking models.
-    """
-    try:
-        _network[net_id]['instance'].set_time(int(t/config['dt']))
-    except:
-        _warning('Time can only be set when the network is compiled.')
-
-def get_current_step(net_id=0):
-    "Returns the current simulation step."
-    try:
-        t = _network[net_id]['instance'].get_time()
-    except:
-        t = 0
-    return t
+    def get_projections(self, post=None, pre=None, target=None, suppress_error=False) -> list["Projection"]:
+        """
+        Get a list of declared projections for the current network. By default,
+        the method returns all connections within the network.
 
-def set_current_step(t, net_id=0):
-    """
-    Sets the current simulation step (integer).
+        By setting the arguments, post, pre and target one can select a subset.
 
-    **Warning:** can be dangerous for some spiking models.
-    """
-    try:
-        _network[net_id]['instance'].set_time(int(t))
-    except:
-        _warning('Time can only be set when the network is compiled.')
-
-def dt():
-    "Returns the simulation step size `dt` used in the simulation."
-    return config['dt']
-
-################################
-## Seed
-################################
-def set_seed(seed, use_seed_seq=True, net_id=0):
-    "Sets the seed of the random number generators, both in numpy.random and in the C++ library when it is created."
-    config['seed'] = seed
-    config['use_seed_seq'] = use_seed_seq
-    if seed > -1:
-        np.random.seed(seed)
-    
-    try:
-        if config['disable_parallel_rng']:
-            _network[net_id]['instance'].set_seed(seed, 1, use_seed_seq)
-        else:
-            _network[net_id]['instance'].set_seed(seed, config['num_threads'], use_seed_seq)
-    except:
-        _warning('The seed will only be set in the simulated network when it is compiled.')
+        :param post: all returned projections should have this population as post.
+        :param pre: all returned projections should have this population as pre.
+        :param target: all returned projections should have this target.
+        :param suppress_error: by default, ANNarchy throws an error if the list of assigned projections is empty. If this flag is set to True, the error message is suppressed.
+        :returns: the list of all assigned projections in this network or a subset according to the arguments.
 
+        """
+        if self.projections == []:
+            if not suppress_error:
+                Messages._error("Network.get_projections(): no projections attached to this network.")
 
-################################
-## Paradigm
-################################
-def _check_paradigm(paradigm):
-    """
-    Returns True when the provided paradigm is currently used.
+        return NetworkManager().get_projections(net_id=self.id, pre=pre, post=post, target=target, suppress_error=suppress_error)
 
-    Possible values:
+    def load(self, filename:str, populations:bool=True, projections:bool=True, pickle_encoding:str=None):
+        """
+        Loads a saved state of the current network by calling ANNarchy.core.IO.load().
 
-    1. "openmp"
-    2. "cuda"
-    """
-    try:
-        return paradigm == config['paradigm']
-    except KeyError:
-        _error("Unknown paradigm")
+        :param filename: filename, may contain relative or absolute path.
+        :param populations: if True, population data will be saved (by default True)
+        :param projections: if True, projection data will be saved (by default True)
+        :param pickle_encoding: optional parameter provided to the pickle.load() method. If set to None the default is used.
+        """
+        IO.load(filename=filename, populations=populations, projections=projections, pickle_encoding=pickle_encoding, net_id=self.id)
 
-def _check_precision(precision):
-    """
-    Returns True when the provided precision is currently used.
+    def save(self, filename:str, populations:bool=True, projections:bool=True):
+        """
+        Saves the current network by calling ANNarchy.core.IO.save().
 
-    Possible values:
+        :param filename: filename, may contain relative or absolute path.
+        :param populations: if True, population data will be saved (by default True)
+        :param projections: if True, projection data will be saved (by default True)
+        """
+        IO.save(filename, populations, projections, self.id)
 
-    1. "float"
-    2. "double"
+def parallel_run(
+        method, 
+        networks:list=None, 
+        number:int=0, 
+        max_processes:int=-1, 
+        measure_time:bool=False, 
+        sequential:bool=False, 
+        same_seed:bool=False, 
+        annarchy_json:str="", 
+        visible_cores:list=[], 
+        **args) -> list:
     """
-    try:
-        return precision == config['precision']
-    except KeyError:
-        _error("Unknown precision")
-
-
+    Allows to run multiple networks in parallel using multiprocessing.
 
-################################
-## Printing
-################################
+    If the ``networks`` argument is provided as a list of Network objects, the given method will be executed for each of these networks.
 
-def _print(*var_text, end="\n", flush=False):
-    """
-    Prints a message to standard out.
-    """
-    text = ''
-    for var in var_text:
-        text += str(var) + ' '
+    If ``number`` is given instead, the same number of networks will be created and the method is applied.
 
-    if sys.version_info.major == 3:
-        print(text, end=end, flush=flush)
-    else:
-        print(text)
+    If ``number`` is used, the created networks are not returned, you should return what you need to analyse.
 
-def _debug(*var_text):
-    """
-    Prints a message to standard out, if verbose mode set True.
-    """
-    if not config['verbose']:
-        return
+    Example:
 
-    text = ''
-    for var in var_text:
-        text += str(var) + ' '
-    print(text)
+    ```python
+    pop1 = ann.PoissonPopulation(100, rates=10.0)
+    pop2 = ann.Population(100, ann.Izhikevich)
+    proj = ann.Projection(pop1, pop2, 'exc')
+    proj.connect_fixed_probability(weights=5.0, probability=0.2)
+    m = ann.Monitor(pop2, 'spike')
+
+    ann.compile()
+
+    def simulation(idx, net):
+        net.get(pop1).rates = 10. * idx
+        net.simulate(1000.)
+        return net.get(m).raster_plot()
+
+    results = ann.parallel_run(method=simulation, number = 3)
+
+    t1, n1 = results[0]
+    t2, n2 = results[1]
+    t3, n3 = results[2]
+    ```
 
-def _warning(*var_text):
-    """
-    Prints a warning message to standard out. Can be suppressed by configuration.
-    """
-    text = 'WARNING: '
-    for var in var_text:
-        text += str(var) + ' '
-    if not config['suppress_warnings']:
-        print(text)
-    #     # Print the trace
-    #     tb = traceback.format_stack()
-    #     for line in tb:
-    #         if not '/ANNarchy/core/' in line and \
-    #            not '/ANNarchy/parser/' in line and \
-    #            not '/ANNarchy/generator/' in line :
-    #             print(line)
 
-def _info(*var_text):
-    """
-    Prints a information message to standard out. Can be suppressed by configuration.
-    """
-    text = 'INFO: '
-    for var in var_text:
-        text += str(var) + ' '
-    if not config['suppress_warnings']:
-        print(text)
-    #     # Print the trace
-    #     tb = traceback.format_stack()
-    #     for line in tb:
-    #         if not '/ANNarchy/core/' in line and \
-    #            not '/ANNarchy/parser/' in line and \
-    #            not '/ANNarchy/generator/' in line :
-    #             print(line)
+    :param method: a Python method which will be executed for each network. This function must accept an integer as first argument (id of the simulation) and a Network object as second argument.
+    :param networks: a list of networks to simulate in parallel.
+    :param number: the number of identical networks to run in parallel.
+    :param max_processes: maximal number of processes to start concurrently (default: the available number of cores on the machine).
+    :param measure_time: if the total simulation time should be printed out.
+    :param sequential: if True, runs the simulations sequentially instead of in parallel (default: False).
+    :param same_seed: if True, all networks will use the same seed. If not, the seed will be randomly initialized with time(0) for each network (default). It has no influence when the ``networks`` argument is set (the seed has to be set individually for each network using ``net.set_seed()``), only when ``number`` is used.
+    :param annarchy_json: path to a different configuration file if needed (default "").
+    :param visible_cores: a list of CPU core ids to simulate on (must have max_processes entries and max_processes must be != -1)
+    :param args: other named arguments you want to pass to the simulation method.
+    :returns: a list of the values returned by each call to `method`.
+
+    """
+    # Check inputs
+    if not networks and number < 1:
+        Messages._error('parallel_run(): the networks or number arguments must be set.', exit=True)
+
+    if len(visible_cores) > 0 and max_processes == -1:
+        Messages._error('parallel_run(): when using visible cores the number of max_processes must be set.', exit=True)
+
+    if (len(visible_cores) > 0) and (len(visible_cores) != max_processes):
+        Messages._error('parallel_run(): the number of entries in visible_cores must be equal to max_processes.', exit=True)
+
+    import types
+    if not isinstance(method, types.FunctionType):
+        Messages._error('parallel_run(): the method argument must be a method.', exit=True)
+
+    if not networks: # The magic network will run N times
+        return _parallel_multi(method, number, max_processes, measure_time, sequential, same_seed, annarchy_json, visible_cores, args)
+
+    if not isinstance(networks, list):
+        Messages._error('parallel_run(): the networks argument must be a list.', exit=True)
+
+    # Simulate the different networks
+    return _parallel_networks(method, networks, max_processes, measure_time, sequential, args)
+
+
+def _parallel_networks(method, networks, max_processes, measure_time, sequential, args):
+    " Method when different networks are provided"
+    import multiprocessing
+    from multiprocessing import Pool
+
+    # Time measurement
+    from time import time
+    if measure_time:
+        ts = time()
+
+    # Number of processes to create depends on number of
+    # available CPUs or GPUs
+    if max_processes < 0:
+        if get_global_config('paradigm') == "openmp":
+            max_processes = min(len(networks), multiprocessing.cpu_count())
+        elif get_global_config('paradigm') == "cuda":
+            Messages._warning("In the present ANNarchy version the usage of parallel networks and multi-GPUs is disabled.")
+            max_processes = 1
+        else:
+            raise NotImplementedError
 
-def _error(*var_text, **args):
-    """
-    Prints an error message to standard out and exits.
+    # Number of networks
+    number = len(networks)
 
-    When passing exit=False, the program will not exit.
-    """
-    text = ''
-    for var in var_text:
-        text += str(var) + ' '
-
-    exit = False
-    if 'exit' in args.keys():
-        if args['exit']:
-            exit = True
+    # Build arguments list
+    arguments = [[method, n, networks[n]] for n in range(number)]
+    if len(args) != method.__code__.co_argcount-2:  # idx, net are default
+        Messages._error('the method', method.__name__, 'takes', method.__code__.co_argcount-2,
+                      'arguments (in addition to idx and net) which have to be passed to parallel_run:', method.__code__.co_varnames[2:method.__code__.co_argcount])
+    for arg in range(2, method.__code__.co_argcount):
+        varname = method.__code__.co_varnames[arg]
+        data = args[varname]
+        if not len(data) == number:
+            Messages._error('parallel_run(): the argument', varname, 'must be a list of values for each of the', number, 'networks.')
+        for n in range(number):
+            arguments[n].append(data[n])
+
+    # Simulation
+    if not sequential:
+        pool = Pool(max_processes)
+        try:
+            results = pool.map(_only_run_method, arguments)
+        except Exception as e:
+            Messages._print(e)
+            Messages._error('parallel_run(): running multiple networks failed.', exit=True)
+        pool.close()
+        pool.join()
     else:
-        exit = True
+        results = []
+        for idx, net in enumerate(networks):
+            try:
+                results.append(method(*arguments[idx][1:]))
+            except Exception as e:
+                Messages._print(e)
+                Messages._error('parallel_run(): running network ' + str(net.id) + ' failed.', exit=True)
+
+    # Time measurement
+    if measure_time:
+        msg = 'Running ' + str(len(networks)) + ' networks'
+        if not sequential:
+            msg += ' in parallel '
+        else:
+            msg += ' sequentially '
+        msg += 'took: ' + str(time()-ts)
+        Messages._print(msg)
+
+    return results
+
+
+def _parallel_multi(method, number, max_processes, measure_time, sequential, same_seed, annarchy_json, visible_cores, args):
+    "Method when the same network must be simulated multiple times."
+    import multiprocessing
+    from multiprocessing import Pool
+
+    # Time measurement
+    from time import time
+    if measure_time:
+        ts = time()
+
+    # Make sure the magic network is compiled
+    if not NetworkManager().is_compiled(net_id=0):
+        Messages._warning('parallel_run(): the network is not compiled yet, doing it now...')
+        Compiler.compile(annarchy_json=annarchy_json)
+
+    # Number of processes to create
+    if max_processes < 0:
+        if get_global_config('paradigm') == "openmp":
+            max_processes = min(number, multiprocessing.cpu_count())
+        elif get_global_config('paradigm') == "cuda":
+            Messages._warning("In the present ANNarchy version the usage of parallel networks and multi-GPUs is disabled.")
+            max_processes = 1
+        else:
+            raise NotImplementedError
 
-    if exit:
-        raise ANNarchyException(text, exit)
+    # Seed
+    if same_seed and get_global_config('seed') > -1: # use the global seed
+        seed = get_global_config('seed')
+    else: # draw it everytime with time(0)
+        seed = np.random.get_state()[1][0]
+
+    # Build arguments list for each instance with the following structure:
+    # [ net_id, arguments for method, seed ]
+    arguments = [[n, method] for n in range(number)]
+    if len(args) != method.__code__.co_argcount-2:  # idx, net are default
+        Messages._error('the method', method.__name__, 'takes', method.__code__.co_argcount-2,
+                      'arguments (in addition to idx and net) which have to be passed to parallel_run:', method.__code__.co_varnames[2:method.__code__.co_argcount])
+    for arg in range(2, method.__code__.co_argcount):
+        varname = method.__code__.co_varnames[arg]
+        data = args[varname]
+        if not len(data) == number:
+            Messages._error('parallel_run(): the argument', varname, 'must be a list of values for each of the', number, 'networks.')
+        for n in range(number):
+            arguments[n].append(data[n])
+    for n in range(number): # Add the seed at the end. Increment the seed if the seeds should be different
+        arguments[n].append(seed + n if not same_seed else 0)
+
+    # Thread placement is optional
+    if len(visible_cores) == 0:
+        for n in range(number):
+            arguments[n].append([])
     else:
-        print('ERROR:' + text)
+        for n in range(number):
+            arguments[n].append([visible_cores[np.mod(n,max_processes)]])
 
-class ANNarchyException(Exception):
-    """
-    Custom exception that can be catched in some cases (IO) instead of quitting.
-    """
-    def __init__(self, message, exit):
-        super(ANNarchyException, self).__init__(message)
-
-        # # Print the error message
-        # print('ERROR: ' + message)
+    # Simulation
+    if not sequential and len(visible_cores) == 0:
+        try:
+            pool = Pool(max_processes)
+            results = pool.map(_create_and_run_method, arguments)
+            pool.close()
+            pool.join()
+        except Exception as e:
+            Messages._print(e)
+            Messages._error('parallel_run(): running ' + str(number) + ' networks failed.', exit=True)
+
+    elif not sequential and len(visible_cores) > 0:
+        # Thread placement requires some more fine-grained control
+        # on the execution
+        try:
+            n_iter = int(np.ceil(number / max_processes))
+            pool = Pool(max_processes)
+            for idx in range(n_iter):
+                beg = int(idx * max_processes)
+                end = int(min((idx+1) * max_processes, number))
+                results = pool.map(_create_and_run_method, arguments[beg:end])
+            pool.close()
+            pool.join()
+        except Exception as e:
+            Messages._print(e)
+            Messages._error('parallel_run(): running ' + str(number) + ' networks failed.', exit=True)
 
-        # # Print the trace
-        # # tb = traceback.print_stack()
-        # tb = traceback.format_stack()
-        # for line in tb:
-        #     if not '/ANNarchy/core/' in line and \
-        #        not '/ANNarchy/parser/' in line and \
-        #        not '/ANNarchy/generator/' in line :
-        #         print(line)
-
-class CodeGeneratorException(Exception):
-    def __init__(self, msg):
-        print("An error in the code generation occured:")
-        sys.exit(self)
-
-class InvalidConfiguration(Exception):
-    def __init__(self, msg):
-        print("The configuration you requested is not implemented in ANNarchy.")
-        sys.exit(self)
+    else:
+        results = []
+        try:
+            for n in range(number):
+                results.append(_create_and_run_method(arguments[0]))
+        except Exception as e:
+            Messages._print(e)
+            Messages._error('parallel_run(): running ' + str(number) + ' networks failed.', exit=True)
+
+    # Time measurement
+    if measure_time:
+        msg = 'Running ' + str(number) + ' networks'
+        if not sequential:
+            msg += ' in parallel '
+        else:
+            msg += ' sequentially '
+        msg += 'took: ' + str(time()-ts)
+        Messages._print(msg)
+
+    return results
+
+
+def _create_and_run_method(args):
+    """
+    Method called to wrap the user-defined method when different networks are created.
+    """
+    # Get arguments
+    n = args[0]
+    method = args[1]
+    visible_cores = args[-1]
+    seed = args[-2]
+    # Create and instantiate the network 0, not compile it!
+    net = Network(True)
+    Compiler._instantiate(net_id=net.id, import_id=0, core_list=visible_cores)
+    # Set the seed
+    net.set_seed(seed)
+    # Create the arguments
+    arguments = args[:-2] # all arguments except seed and visible_cores
+    arguments[1] = net # replace the second argument method with net
+    # Call the method
+    res = method(*arguments)
+    del net
+    return res
+
+
+def _only_run_method(args):
+    """
+    Method called to wrap the user-defined method when a single network is already instantiated.
+    """
+    method = args[0]
+    arguments = args[1:]
+    res = method(*arguments)
+    return res
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/IO.py` & `annarchy-4.8.0.1/ANNarchy/core/IO.py`

 * *Files 19% similar despite different names*

```diff
@@ -2,20 +2,25 @@
 Contains functions for load/save of parameters, connectivtiy and complete networks.
 
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 from ANNarchy.core import Global
+from ANNarchy.core.Constant import Constant
+from ANNarchy.intern.NetworkManager import NetworkManager
+from ANNarchy.intern.GlobalObjects import GlobalObjectManager
+from ANNarchy.intern import Messages
+
 import os
 import pickle
 import numpy as np
 
 
-def load_parameters(filename, global_only=True, verbose=False, net_id=0):
+def load_parameters(filename:str, global_only:bool=True, verbose:bool=False, net_id:int=0):
     """
     Loads the global parameters of a network (flag ``population`` for neurons, ``projection`` for synapses) from a JSON file.
 
     It is advised to generate the JSON file first with ``save_parameters()`` and later edit it manually.
 
     A strong restriction is that population/projection names cannot change between saving and loading.
     By default, they take names such as ``pop0`` or ``proj2``, we advise setting explicitly a name in their constructor for readability.
@@ -27,143 +32,141 @@
     The JSON file cannot contain arrays.
 
     If you want to save/load the value of variables after a simulation, please refer to ``save()`` or ``load()``.
 
     :param filename: path to the JSON file.
     :param global_only: True if only global parameters (flags ``population`` and ``projection``) should be loaded, the other values are ignored. (default: True)
     :param verbose: True if the old and new values of the parameters should be printed (default: False).
-    :param net_id: ID of the network (default: 0, the global network).
-    :return: a dictionary of additional parameters not related to populations or projections (keyword ``network`` in the JSON file).
+    :returns: a dictionary of additional parameters not related to populations or projections (keyword ``network`` in the JSON file).
 
     """
     import json
     try:
         with open(filename, 'r') as rfile:
             desc = json.load(rfile)
     except IOError as error:
         print(error)
-        Global._error("load_parameters(): the json file does not exist")   
+        Messages._error("load_parameters(): the json file does not exist")   
 
     if verbose:
-        Global._print('Loading parameters from file', filename)
-        Global._print('-'*40)
+        Messages._print('Loading parameters from file', filename)
+        Messages._print('-'*40)
 
     # Populations
     try:
         populations = desc['populations']
     except:
         populations = {}
         if verbose:
-            Global._print('load_parameters(): no population parameters.')
+            Messages._print('load_parameters(): no population parameters.')
     for name, parameters in populations.items():
         # Get the population
-        for pop in Global._network[net_id]['populations']:
+        for pop in NetworkManager().get_populations(net_id=net_id):
             if pop.name == name:
                 population = pop
                 break
         else:
-            Global._warning('The population', name, 'defined in the file', filename, 'does not exist in the current network.')
+            Messages._warning('The population', name, 'defined in the file', filename, 'does not exist in the current network.')
 
         if verbose:
-            Global._print('Population', name)
+            Messages._print('Population', name)
 
         # Set the parameters
         for name, val in parameters.items():
             # Check that the variable indeed exists
             if not name in population.parameters:
-                Global._print('  ', name, 'is not a global parameter of', population.name, ', skipping.')
+                Messages._print('  ', name, 'is not a global parameter of', population.name, ', skipping.')
                 continue
             if global_only and not name in population.neuron_type.description['global']:
-                Global._print('  ', name, 'is not a global parameter of', population.name, ', skipping.')
+                Messages._print('  ', name, 'is not a global parameter of', population.name, ', skipping.')
                 continue
 
             if verbose:
-                Global._print('  ', name, ':', population.get(name), '->', val)
+                Messages._print('  ', name, ':', population.get(name), '->', val)
 
             population.set({name: float(val)})
 
     # Projections
     try:
         projections = desc['projections']
     except:
         projections = {}
         if verbose:
-            Global._print('load_parameters(): no projection parameters.')
+            Messages._print('load_parameters(): no projection parameters.')
     for name, parameters in projections.items():
         # Get the projection
-        for proj in Global._network[net_id]['projections']:
+        for proj in NetworkManager().get_projections(net_id=net_id):
             if proj.name == name:
                 projection = proj
                 break
         else:
-            Global._warning('The projection', name, 'defined in the file', filename, 'does not exist in the current network.')
+            Messages._warning('The projection', name, 'defined in the file', filename, 'does not exist in the current network.')
 
         if verbose:
-            Global._print('Projection', name)
+            Messages._print('Projection', name)
 
         # Set the parameters
         for name, val in parameters.items():
             # Check that the variable indeed exists
             if not name in projection.parameters:
-                Global._print('  ', name, 'is not a global parameter of', population.name, ', skipping.')
+                Messages._print('  ', name, 'is not a global parameter of', population.name, ', skipping.')
                 continue
             if global_only and not name in projection.synapse_type.description['global']:
-                Global._print('  ', name, 'is not a global parameter of', population.name, ', skipping.')
+                Messages._print('  ', name, 'is not a global parameter of', population.name, ', skipping.')
                 continue
 
             if verbose:
-                Global._print('  ', name, ':', projection.get(name), '->', val)
+                Messages._print('  ', name, ':', projection.get(name), '->', val)
 
             projection.set({name: float(val)})
 
     # Constants
     try:
         constants = desc['constants']
     except:
         constants = {}
         if verbose:
-            Global._print('load_parameters(): no constants.')
+            Messages._print('load_parameters(): no constants.')
     for name, value in constants.items():
-        if name in Global.list_constants(): # modify it
-            Global.get_constant(name).value = value
+        if name in GlobalObjectManager().list_constants(): # modify it
+            GlobalObjectManager().get_constant(name).value = value
         else: # create it
-            _ = Global.Constant(name, value)
+            _ = Constant(name, value)
 
     # Global user-defined parameters
     try:
         network_parameters = {}
         for name, val in desc['network'].items():
             network_parameters[name] = float(val)
     except:
         network_parameters = {}
 
     return network_parameters
 
-def save_parameters(filename, net_id=0):
+def save_parameters(filename:str, net_id=0):
     """
     Saves the global parameters of a network (flag ``population`` for neurons, ``projection`` for synapses) to a JSON file.
 
     :param filename: path to the JSON file.
-    :param net_id: ID of the network (default: 0, the global network).
     """
     import json
 
     # Get the netowrk description
-    network = Global._network[net_id]
+    network = NetworkManager().get_network_dict(net_id=net_id)
 
     # Dictionary of parameters
     description = {
         'populations' : {},
         'projections' : {},
         'network' : {},
         'constants' : {},
     }
 
     # Constants
-    for constant in Global._objects['constants']:
+    for constant in GlobalObjectManager().get_constants():
         description['constants'][constant.name] = constant.value
 
     # Populations
     for pop in network['populations']:
 
         # Get the neuron description
         neuron = pop.neuron_type
@@ -189,34 +192,34 @@
         description['projections'][proj.name] = proj_description
 
     # Save the description in a json file
     try:
         with open(filename, 'w') as wfile:
             json.dump(description, wfile, indent=4)
     except IOError as error:
-        Global._error("save_parameters(): cannot write the json file. Make sure the subfolders already exist.")
+        Messages._error("save_parameters(): cannot write the json file. Make sure the subfolders already exist.")
 
 
 # Backwards compatibility with XML
 def load_parameter(in_file):
-    Global._warning('load_parameter() is deprecated. Use load_parameters() and JSON files instead.')
+    Messages._warning('load_parameter() is deprecated. Use load_parameters() and JSON files instead.')
     return _load_parameters_from_xml(in_file)
 
 def _load_parameters_from_xml(in_file):
     """
     Load parameter set from xml file.
 
     If the location of the xml file differs from the base directory, you need to provide relative or absolute path.
 
     :param in_file: either single or collection of strings.
     """
     try:
         from lxml import etree
     except:
-        Global._print('lxml is not installed. Unable to load in xml format.')
+        Messages._print('lxml is not installed. Unable to load in xml format.')
         return
     par = {}
     damaged_pars = []   # for printout
 
     files = []
     if isinstance(in_file,str):
         files.append(in_file)
@@ -224,58 +227,58 @@
         files = in_file
 
     for file in files:
         try:
             doc = etree.parse(file)
 
         except IOError:
-            Global._print('Error: file \'', file, '\' not found.')
+            Messages._print('Error: file \'', file, '\' not found.')
             continue
 
         matches = doc.findall('parameter')
 
         for parameter in matches:
             childs = parameter.getchildren()
 
             #TODO: allways correct ???
             if len(childs) != 2:
-                Global._print('Error: to much tags in parameter')
+                Messages._print('Error: to much tags in parameter')
 
             name=None
             value=None
             for child in childs:
 
                 if child.tag == 'name':
                     name = child.text
                 elif child.tag == 'value':
                     value = child.text
 
                     if value is None:
-                        Global._print('Error: no value defined for',name)
+                        Messages._print('Error: no value defined for',name)
                         damaged_pars.append(name)
                         value = 0
                     else:
                         try:
                             value = int(value)
                         except ValueError:
                             try:
                                 value = float(value)
                             except ValueError:
                                 value = value
 
                 else:
-                    Global._print('Error: unexpected xml-tag', child.tag)
+                    Messages._print('Error: unexpected xml-tag', child.tag)
 
             if name is None:
-                Global._print('Error: no name in parameter set.')
+                Messages._print('Error: no name in parameter set.')
             elif value is None:
-                Global._print('Error: no value in parameter set.')
+                Messages._print('Error: no value in parameter set.')
                 damaged_pars.append(name)
             elif name in par.keys():
-                Global._print("Error: parameter",name,"already exists.")
+                Messages._print("Error: parameter",name,"already exists.")
                 damaged_pars.append(name)
             else:
                 par[name] = value
 
     return par
 
 def _save_data(filename, data):
@@ -284,61 +287,61 @@
 
     """
     # Check if the repertory exist
     (path, fname) = os.path.split(filename)
 
     if not path == '':
         if not os.path.isdir(path):
-            Global._print('Creating folder', path)
+            Messages._print('Creating folder', path)
             os.mkdir(path)
 
     extension = os.path.splitext(fname)[1]
 
     if extension == '.mat':
-        Global._print("Saving network in Matlab format...")
+        Messages._print("Saving network in Matlab format...")
         try:
             import scipy.io as sio
             sio.savemat(filename, data)
         except Exception as e:
-            Global._error('Error while saving in Matlab format.')
-            Global._print(e)
+            Messages._error('Error while saving in Matlab format.')
+            Messages._print(e)
             return
 
     elif extension == '.gz':
-        Global._print("Saving network in gunzipped binary format...")
+        Messages._print("Saving network in gunzipped binary format...")
         try:
             import gzip
         except:
-            Global._error('gzip is not installed.')
+            Messages._error('gzip is not installed.')
             return
         with gzip.open(filename, mode = 'wb') as w_file:
             try:
                 pickle.dump(data, w_file, protocol=pickle.HIGHEST_PROTOCOL)
             except Exception as e:
-                Global._print('Error while saving in gzipped binary format.')
-                Global._print(e)
+                Messages._print('Error while saving in gzipped binary format.')
+                Messages._print(e)
                 return
 
     elif extension == '.npz':
-        Global._print("Saving network in Numpy format...")
+        Messages._print("Saving network in Numpy format...")
         np.savez_compressed(filename, allow_pickle=True, **data )
 
     else:
-        Global._print("Saving network in text format...")
+        Messages._print("Saving network in text format...")
         # save in Pythons pickle format
         with open(filename, mode = 'wb') as w_file:
             try:
                 pickle.dump(data, w_file, protocol=pickle.HIGHEST_PROTOCOL)
             except Exception as e:
-                Global._print('Error while saving in text format.')
-                Global._print(e)
+                Messages._print('Error while saving in text format.')
+                Messages._print(e)
                 return
         return
 
-def save(filename, populations=True, projections=True, net_id=0):#, pure_data=True):
+def save(filename:str, populations:bool=True, projections:bool=True, net_id=0) -> None :
     """
     Save the current network state (parameters and variables) to a file.
 
     * If the extension is '.npz', the data will be saved and compressed using `np.savez_compressed` (recommended).
 
     * If the extension is '.mat', the data will be saved as a Matlab 7.2 file. Scipy must be installed.
 
@@ -347,27 +350,26 @@
     * Otherwise, the data will be pickled into a simple binary text file using cPickle.
 
     **Warning:** The '.mat' data will not be loadable by ANNarchy, it is only for external analysis purpose.
 
     Example:
 
     ```python
-    save('results/init.npz')
+    ann.save('results/init.npz')
 
-    save('results/init.data')
+    ann.save('results/init.data')
 
-    save('results/init.txt.gz')
+    ann.save('results/init.txt.gz')
 
-    save('1000_trials.mat')
+    ann.save('1000_trials.mat')
     ```
 
     :param filename: filename, may contain relative or absolute path.
     :param populations: if True, population data will be saved (by default True)
     :param projections: if True, projection data will be saved (by default True)
-
     """
     data = _net_description(populations, projections, net_id)
     _save_data(filename, data)
 
 def _load_data(filename, pickle_encoding):
     """
     Internally loads data contained in a given file.
@@ -376,33 +378,33 @@
     :param pickle_encoding: if set to None the default is used, e.g. Python2 files ("latin1") or Python3 files ("ASCII")
     :return: A dictionary with the connectivity and synaptic variables if the file ``filename`` is available otherwise None is returned.
     """
     (_, fname) = os.path.split(filename)
     extension = os.path.splitext(fname)[1]
 
     if extension == '.mat':
-        Global._error('Unable to load Matlab format.')
+        Messages._error('Unable to load Matlab format.')
         return None
 
     elif extension == '.gz':
         try:
             import gzip
         except:
-            Global._error('gzip is not installed.')
+            Messages._error('gzip is not installed.')
             return None
         try:
             with gzip.open(filename, mode = 'rb') as r_file:
                 if pickle_encoding is None:
                     desc = pickle.load(r_file)
                 else:
                     desc = pickle.load(r_file, encoding=pickle_encoding)
             return desc
         except Exception as e:
-            Global._print('Unable to read the file ' + filename)
-            Global._print(e)
+            Messages._print('Unable to read the file ' + filename)
+            Messages._print(e)
             return None
 
     elif extension == '.npz':
         try:
             if pickle_encoding is None:
                 data = np.load(filename, allow_pickle=True)
             else:
@@ -418,61 +420,62 @@
                     desc[attribute] = data[attribute].item(0)
                 else:
                     # attribute is a scalar/array
                     desc[attribute] = data[attribute]
 
             return desc
         except Exception as e:
-            Global._print('Unable to read the file ' + filename)
-            Global._print(e)
+            Messages._print('Unable to read the file ' + filename)
+            Messages._print(e)
             return None
 
     else:
         try:
             with open(filename, mode = 'rb') as r_file:
                 if pickle_encoding is None:
                     desc = pickle.load(r_file)
                 else:
                     desc = pickle.load(r_file, encoding=pickle_encoding)
             return desc
         except Exception as e:
-            Global._print('Unable to read the file ' + filename)
-            Global._print(e)
+            Messages._print('Unable to read the file ' + filename)
+            Messages._print(e)
             return None
 
 def _load_connectivity_data(filename, pickle_encoding):
     """
     Internally loads data contained in a given file.
 
     :param filename: path to the file.
+    :param pickle_encoding: Pickle encoding.
     :return: A dictionary with the connectivity and synaptic variables if the file ``filename`` is available otherwise None is returned.
     """
     (_, fname) = os.path.split(filename)
     extension = os.path.splitext(fname)[1]
 
     if extension == '.mat':
-        Global._error('Unable to load Matlab format.')
+        Messages._error('Unable to load Matlab format.')
         return None
 
     elif extension == '.gz':
         try:
             import gzip
         except:
-            Global._error('gzip is not installed.')
+            Messages._error('gzip is not installed.')
             return None
         try:
             with gzip.open(filename, mode = 'rb') as r_file:
                 if pickle_encoding is None:
                     desc = pickle.load(r_file)
                 else:
                     desc = pickle.load(r_file, encoding=pickle_encoding)
             return desc
         except Exception as e:
-            Global._print('Unable to read the file ' + filename)
-            Global._print(e)
+            Messages._print('Unable to read the file ' + filename)
+            Messages._print(e)
             return None
 
     elif extension == '.npz':
         try:
             if pickle_encoding is None:
                 data = np.load(filename, allow_pickle=True)
             else:
@@ -483,44 +486,43 @@
                 # or 2) single pop/proj. The first case leads to a dictionary
                 # of several objects. The latter to a dictionary containing all
                 # values.
                 desc[attribute] = data[attribute]
 
             return desc
         except Exception as e:
-            Global._print('Unable to read the file ' + filename)
-            Global._print(e)
+            Messages._print('Unable to read the file ' + filename)
+            Messages._print(e)
             return None
 
     else:
         try:
             with open(filename, mode = 'rb') as r_file:
                 if pickle_encoding is None:
                     desc = pickle.load(r_file)
                 else:
                     desc = pickle.load(r_file, encoding=pickle_encoding)
             return desc
         except Exception as e:
-            Global._print('Unable to read the file ' + filename)
-            Global._print(e)
+            Messages._print('Unable to read the file ' + filename)
+            Messages._print(e)
             return None
 
-def load(filename, populations=True, projections=True, pickle_encoding=None, net_id=0):
+def load(filename:str, populations:bool=True, projections:bool=True, pickle_encoding:str=None, net_id=0):
     """
     Loads a saved state of the network.
 
     **Warning:** Matlab data can not be loaded.
 
     Example:
 
     ```python
-    load('results/network.npz')
+    ann.load('results/network.npz')
     ```
 
-
     :param filename: the filename with relative or absolute path.
     :param populations: if True, population data will be loaded (by default True)
     :param projections: if True, projection data will be loaded (by default True)
     :param pickle_encoding: optional parameter provided to the pickle.load() method. If set to None the default is used.
     """
 
     desc = _load_data(filename, pickle_encoding)
@@ -528,21 +530,21 @@
         return
 
     if 'time_step' in desc.keys():
         Global.set_current_step(desc['time_step'], net_id)
 
     if populations:
         # Over all populations
-        for pop in Global._network[net_id]['populations']:
+        for pop in NetworkManager().get_populations(net_id=net_id):
             # check if the population is contained in save file
             if pop.name in desc.keys():
                 pop._load_pop_data(desc[pop.name])
 
     if projections:
-        for proj in Global._network[net_id]['projections'] :
+        for proj in NetworkManager().get_projections(net_id=net_id):
             if proj.name in desc.keys():
                 proj._load_proj_data(desc[proj.name])
 
 
 def _net_description(populations, projections, net_id=0):
     """
     Returns a dictionary containing the requested network data.
@@ -554,20 +556,20 @@
     network_desc['time_step'] = Global.get_current_step(net_id)
     network_desc['net_id'] = net_id
 
     pop_names = []
     proj_names = []
 
     if populations:
-        for pop in Global._network[net_id]['populations']:
+        for pop in NetworkManager().get_populations(net_id=net_id):
             network_desc[pop.name] = pop._data()
             pop_names.append(pop.name)
 
     if projections:
-        for proj in Global._network[net_id]['projections']:
+        for proj in NetworkManager().get_projections(net_id=net_id):
             # Some specific projections are note saveable
             if not proj._saveable:
                 continue
             network_desc[proj.name] = proj._data()
             proj_names.append(proj.name)
 
     network_desc['obj_names'] = {
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/Monitor.py` & `annarchy-4.8.0.1/ANNarchy/core/Monitor.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,22 +1,27 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-from . import Global
-from .Population import Population
-from .PopulationView import PopulationView
-from .Projection import Projection
-from .Dendrite import Dendrite
+from ANNarchy.core.Population import Population
+from ANNarchy.core.PopulationView import PopulationView
+from ANNarchy.core.Projection import Projection
+from ANNarchy.core.Dendrite import Dendrite
+from ANNarchy.core import Global
+
+from ANNarchy.intern.NetworkManager import NetworkManager
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern import Messages
 
 import numpy as np
 import re
 import sys
 from copy import copy, deepcopy
+from typing import Any
 
 # objects/functions that should be available by "from ANNarchy import *"
 __all__ = ["Monitor", "raster_plot", "histogram", "population_rate", "smoothed_rate", "mean_fr", "inter_spike_interval", "coefficient_of_variation"]
 
 class Monitor :
     """
     Monitoring class allowing to record easily parameters or variables from Population, PopulationView, Dendrite or Projection objects.
@@ -29,126 +34,126 @@
 
     It is also possible to record the sum of inputs to each neuron in a rate-coded population:
 
     ```python
     m = Monitor(pop, ['sum(exc)', 'r'])
     ```
 
+    :param obj: object to monitor. Must be a `Population`, `PopulationView`, `Dendrite` or `Projection` object.
+    :param variables: single variable name or list of variable names to record (default: []).
+    :param period: delay in ms between two recording (default: dt). Not valid for the ``spike`` variable of a Population(View).
+    :param period_offset: determine the moment in ms of recording within the period (default 0). Must be smaller than **period**.
+    :param start: defines if the recording should start immediately (default: True). If not, you should later start the recordings with the ``start()`` method.
     """
 
-    def __init__(self, obj, variables=[], period=None, period_offset=None, start=True, net_id=0):
-        """
-        :param obj: object to monitor. Must be a Population, PopulationView, Dendrite or Projection object.
-        :param variables: single variable name or list of variable names to record (default: []).
-        :param period: delay in ms between two recording (default: dt). Not valid for the ``spike`` variable of a Population(View).
-        :param period_offset: determine the moment in ms of recording within the period (default 0). Must be smaller than **period**.
-        :param start: defines if the recording should start immediately (default: True). If not, you should later start the recordings with the ``start()`` method.
-        """
+    def __init__(self, obj: Any, variables:list=[], period:float=None, period_offset:float=None, start:bool=True, net_id:int=0):
+
+
         # Object to record (Population, PopulationView, Dendrite)
         self.object = obj
         self.cyInstance = None
         self.net_id = net_id
         self.name = 'Monitor'
 
         # Check type of the object
         if not isinstance(self.object, (Population, PopulationView, Dendrite, Projection)):
-            Global._error('Monitor: the object must be a Population, PopulationView, Dendrite or Projection object')
+            Messages._error('Monitor: the object must be a Population, PopulationView, Dendrite or Projection object')
 
         # Variables to record
         if not isinstance(variables, list):
             self._variables = [variables]
         else:
             self._variables = variables
 
         # Sanity check: we want only record variables
         for var in self._variables:
             if var == "w" and var in self.object.variables:
                 continue
 
             if var in self.object.parameters:
-                Global._error('Parameters are not recordable')
+                Messages._error('Parameters are not recordable')
 
             if not var in self.object.variables and not var in ['spike', 'axon_spike'] and not var.startswith('sum('):
-                Global._error('Monitor: the object does not have an attribute named', var)
+                Messages._error('Monitor: the object does not have an attribute named', var)
 
         # Period
         if not period:
-            self._period = Global.config['dt']
+            self._period = get_global_config('dt')
         else:
             self._period = float(period)
 
         # Period Offset
         if not period_offset:
             self._period_offset = 0
         else:
             # check validity
             if period_offset >= period:
-                Global._error("Monitor(): value of period_offset must be smaller than period.")
+                Messages._error("Monitor(): value of period_offset must be smaller than period.")
             else:
                 self._period_offset = period_offset
 
         # Warn users when recording projections
-        if isinstance(self.object, Projection) and self._period == Global.config['dt']:
-            Global._warning('Monitor(): it is a bad idea to record synaptic variables of a projection at each time step!')
+        if isinstance(self.object, Projection) and self._period == get_global_config('dt'):
+            Messages._warning('Monitor(): it is a bad idea to record synaptic variables of a projection at each time step!')
 
         # Start
         self._start = start
         self._recorded_variables = {}
         self._last_recorded_variables = {}
 
         # Add the monitor to the global variable
-        self.id = len(Global._network[self.net_id]['monitors'])
+        self.id = NetworkManager().number_monitors(net_id=self.net_id)
 
-        Global._network[self.net_id]['monitors'].append(self)
+        NetworkManager().add_monitor(self.net_id, self)
 
-        if Global._network[self.net_id]['compiled']: # Already compiled
+        if NetworkManager().is_compiled(self.net_id): # Already compiled
             self._init_monitoring()
 
     # Extend the period attribute
     @property
-    def period(self):
+    def period(self) -> float:
         "Period of recording in ms"
         if not self.cyInstance:
             return self._period
         else:
-            return self.cyInstance.period * Global.config['dt']
+            return self.cyInstance.period * get_global_config('dt')
     @period.setter
     def period(self, val):
         if not self.cyInstance:
             self._period = val
         else:
-            self.cyInstance.period = int(val/Global.config['dt'])
+            self.cyInstance.period = int(val/get_global_config('dt'))
 
     # Extend the period_offset attribute
     @property
-    def period_offset(self):
+    def period_offset(self) -> float:
         "Shift of moment of time of recording in ms within a period"
         if not self.cyInstance:
             return self._period
         else:
-            return self.cyInstance.period_offset * Global.config['dt']
+            return self.cyInstance.period_offset * get_global_config('dt')
 
     @period_offset.setter
     def period_offset(self, val):
         if not self.cyInstance:
             self._period = val
         else:
-            self.cyInstance.period_offset = int(val/Global.config['dt'])
+            self.cyInstance.period_offset = int(val/get_global_config('dt'))
 
     # Extend the variables attribute
     @property
-    def variables(self):
+    def variables(self) -> list:
         "Returns a copy of the current variable list."
         return copy(self._variables)
 
     @variables.setter
     def variables(self, val):
-        Global._error("Modifying of a Monitors variable list is not allowed")
+        Messages._error("Modifying of a Monitors variable list is not allowed")
 
-    def size_in_bytes(self):
+    def size_in_bytes(self) -> int:
         """
         Get the size of allocated memory on C++ side. Please note, this is only valid if compile() was invoked.
 
         :return: size in bytes of all allocated C++ data.
         """
         if hasattr(self.cyInstance, 'size_in_bytes'):
             return self.cyInstance.size_in_bytes()
@@ -175,15 +180,15 @@
         }
 
         self._last_recorded_variables[var] = {
             'start': [Global.get_current_step(self.net_id)],
             'stop': [None],
         }
 
-    def reset(self):
+    def reset(self) -> None:
         """
         Reset the monitor to its initial state.
         """
         for var in self._variables:
             # Flush the data
             data = self.get(var)
             del data
@@ -206,18 +211,18 @@
 
         if isinstance(self.object, PopulationView):
             self.ranks = list(self.object.ranks)
         else:
             self.ranks = [-1]
 
         # Create the wrapper
-        period = int(self._period/Global.config['dt'])
-        period_offset = int(self._period_offset/Global.config['dt'])
+        period = int(self._period/get_global_config('dt'))
+        period_offset = int(self._period_offset/get_global_config('dt'))
         offset = Global.get_current_step(self.net_id) % period
-        self.cyInstance = getattr(Global._network[self.net_id]['instance'], 'PopRecorder'+str(self.object.id)+'_wrapper')(self.ranks, period, period_offset, offset)
+        self.cyInstance = getattr(NetworkManager().cy_instance(self.net_id), 'PopRecorder'+str(self.object.id)+'_wrapper')(self.ranks, period, period_offset, offset)
 
         for var in self._variables:
             self._add_variable(var)
 
         # Start recordings if enabled
         if self._start:
             self.start()
@@ -231,30 +236,30 @@
             proj_id = self.object.proj.id
         else: # Projection
             self.ranks = [-1]
             self.idx = self.object.post_ranks
             proj_id = self.object.id
 
         # Compute the period and offset
-        period = int(self._period/Global.config['dt'])
-        period_offset = int(self._period_offset / Global.config['dt'])
+        period = int(self._period/get_global_config('dt'))
+        period_offset = int(self._period_offset / get_global_config('dt'))
         offset = Global.get_current_step(self.net_id) % period
 
         # Create the wrapper
-        self.cyInstance = getattr(Global._network[self.net_id]['instance'], 'ProjRecorder'+str(proj_id)+'_wrapper')(self.idx, period, period_offset, offset)
+        self.cyInstance = getattr(NetworkManager().cy_instance(self.net_id), 'ProjRecorder'+str(proj_id)+'_wrapper')(self.idx, period, period_offset, offset)
 
         # Add the variables
         for var in self._variables:
             self._add_variable(var)
 
         # Start recordings if enabled
         if self._start:
             self.start()
 
-    def start(self, variables=None, period=None):
+    def start(self, variables:list=None, period:float=None) -> None:
         """Starts recording the variables.
 
         It is called automatically after ``compile()`` if the flag ``start`` was not passed to the constructor.
 
         :param variables: single variable name or list of variable names to start recording (default: the ``variables`` argument passed to the constructor).
         :param period: delay in ms between two recording (default: dt). Not valid for the ``spike`` variable of a Population(View).
         """
@@ -266,15 +271,15 @@
                 for var in variables:
                     self._add_variable(var)
         else:
             variables = self.variables
 
         if period:
             self._period = period
-            self.cyInstance.period = int(self._period/Global.config['dt'])
+            self.cyInstance.period = int(self._period/get_global_config('dt'))
             self.cyInstance.offset = Global.get_current_step(self.net_id)
 
         for var in variables:
             name = var
             # Sums of inputs for rate-coded populations
             if var.startswith('sum('):
                 target = re.findall(r"\(([\w]+)\)", var)[0]
@@ -286,20 +291,20 @@
                 if isinstance(self.object, (Population, PopulationView)):
                     obj_desc = 'population ' + self.object.name
                 elif isinstance(self.object, Projection):
                     obj_desc = 'projection between '+self.object.pre.name+' and '+self.object.post.name
                 else:
                     obj_desc = 'dendrite between '+self.object.proj.pre.name+' and '+self.object.proj.post.name
                     if var in self.object.proj.parameters:
-                        Global._print('\t', var, 'is a parameter, its value is constant')
+                        Messages._print('\t', var, 'is a parameter, its value is constant')
 
-                Global._warning('Monitor: ' + var + ' can not be recorded ('+obj_desc+')')
+                Messages._warning('Monitor: ' + var + ' can not be recorded ('+obj_desc+')')
 
 
-    def pause(self):
+    def pause(self) -> None:
         "Pauses the recordings."
         # Start recording the variables
         for var in self.variables:
             name = var
             # Sums of inputs for rate-coded populations
             if var.startswith('sum('):
                 target = re.findall(r"\(([\w]+)\)", var)[0]
@@ -310,20 +315,20 @@
                 obj_desc = ''
                 if isinstance(self.object, (Population, PopulationView)):
                     obj_desc = 'population ' + self.object.name
                 elif isinstance(self.object, Projection):
                     obj_desc = 'projection between ' + self.object.pre.name+' and '+self.object.post.name
                 else:
                     obj_desc = 'dendrite between '+self.object.proj.pre.name+' and '+self.object.proj.post.name
-                Global._warning('Monitor:' + var + ' can not be recorded ('+obj_desc+')')
+                Messages._warning('Monitor:' + var + ' can not be recorded ('+obj_desc+')')
 
             self._recorded_variables[var]['stop'][-1] = Global.get_current_step(self.net_id)
 
 
-    def resume(self):
+    def resume(self) -> None:
         "Resumes the recordings."
         # Start recording the variables
         for var in self.variables:
             name = var
             # Sums of inputs for rate-coded populations
             if var.startswith('sum('):
                 target = re.findall(r"\(([\w]+)\)", var)[0]
@@ -334,20 +339,20 @@
                 obj_desc = ''
                 if isinstance(self.object, (Population, PopulationView)):
                     obj_desc = 'population '+self.object.name
                 elif isinstance(self.object, Projection):
                     obj_desc = 'projection between '+self.object.pre.name+' and '+self.object.post.name
                 else:
                     obj_desc = 'dendrite between '+self.object.proj.pre.name+' and '+self.object.proj.post.name
-                Global._warning('Monitor:' + var + ' can not be recorded ('+obj_desc+')')
+                Messages._warning('Monitor:' + var + ' can not be recorded ('+obj_desc+')')
 
             self._recorded_variables[var]['start'].append(Global.get_current_step(self.net_id))
             self._recorded_variables[var]['stop'].append(None)
 
-    def stop(self):
+    def stop(self) -> None:
         """
         Stops the recording.
 
         Warning: This will delete the content of the C++ object and all data not previously retrieved is lost.
         """
         try:
             self._variables = []
@@ -359,29 +364,31 @@
             obj_desc = ''
             if isinstance(self.object, (Population, PopulationView)):
                 obj_desc = 'population '+self.object.name
             elif isinstance(self.object, Projection):
                 obj_desc = 'projection between '+self.object.pre.name+' and '+self.object.post.name
             else:
                 obj_desc = 'dendrite between '+self.object.proj.pre.name+' and '+self.object.proj.post.name
-            Global._warning('Monitor:' + obj_desc + 'cannot be stopped')
+            Messages._warning('Monitor:' + obj_desc + 'cannot be stopped')
 
 
-    def get(self, variables=None, keep=False, reshape=False, force_dict=False):
+    def get(self, variables:str | list[str]=None, 
+            keep:bool=False, reshape:bool=False, force_dict:bool=False) -> dict:
         """
         Returns the recorded variables as a Numpy array (first dimension is time, second is neuron index).
 
         If a single variable name is provided, the recorded values for this variable are directly returned.
         If a list is provided or the argument left empty, a dictionary with all recorded variables is returned.
 
-        The ``spike`` variable of a population will be returned as a dictionary of lists, where the spike times (in steps) for each recorded neurons are returned.
+        The `spike` variable of a population will be returned as a dictionary of lists, where the spike times (in steps) for each recorded neurons are returned.
 
         :param variables: (list of) variables. By default, a dictionary with all variables is returned.
         :param keep: defines if the content in memory for each variable should be kept (default: False).
         :param reshape: transforms the second axis of the array to match the population's geometry (default: False).
+        :return: Recorded variables
         """
 
         def reshape_recording(self, data):
             if not reshape:
                 return data
             else:
                 return data.reshape((data.shape[0],) + self.object.geometry)
@@ -450,73 +457,75 @@
             data = getattr(self.cyInstance, name)
             if not keep:
                 getattr(self.cyInstance, 'clear_' + name)()
         except:
             data = []
         return np.array(data, dtype=object)
 
-    def times(self, variables=None):
+    def times(self, variables:list[str]=None) -> dict:
         """
         Returns the start and stop times (in ms) of the recorded variables.
 
         It should only be called after a call to ``get()``, so that it describes when the variables have been recorded.
 
         :param variables: (list of) variables. By default, the times for all variables is returned.
+        :returns: dictionary of start and stop times.
         """
         t = {}
         if variables:
             if not isinstance(variables, list):
                 variables = [variables]
         else:
             variables = self._variables
 
         for var in variables:
             # check for spelling mistakes
             if not var in self._variables:
-                Global._warning("Variable '"+str(var)+"' is not monitored.")
+                Messages._warning("Variable '"+str(var)+"' is not monitored.")
                 continue
 
             t[var] = deepcopy(self._last_recorded_variables[var])
 
         return t
 
     ###############################
     ### Spike visualisation stuff
     ###############################
-    def raster_plot(self, spikes=None):
+    def raster_plot(self, spikes:dict=None) -> tuple:
         """
-        Returns two vectors representing for each recorded spike 1) the spike times and 2) the ranks of the neurons.
+        Returns two numpy arrays representing for each recorded spike 1) the spike times and 2) the ranks of the neurons.
 
         Example:
 
         ```python
         m = Monitor(P[:1000], 'spike')
         simulate(1000.0)
-        spike_times, spike_ranks = m.raster_plot()
-        plt.plot(spike_times, spike_ranks, '.')
+        t, n = m.raster_plot()
+        plt.plot(t, n, '.')
         ```
 
         or:
 
         ```python
-        m = Monitor(P[:1000], 'spike')
-        simulate(1000.0)
+        m = ann.Monitor(P[:1000], 'spike')
+        ann.simulate(1000.0)
         spikes = m.get('spike')
-        spike_times, spike_ranks = m.raster_plot(spikes)
-        plt.plot(spike_times, spike_ranks, '.')
+        t, n = m.raster_plot(spikes)
+        plt.plot(t, n, '.')
         ```
 
         :param spikes: the dictionary of spikes returned by ``get('spike')``. If left empty, ``get('spike')`` will be called. Beware: this erases the data from memory.
+        :returns: spike times and neuron indices as numpy arrays..
         """
         times = []; ranks=[]
         if not 'spike' in self._variables:
-            Global._error('Monitor: spike was not recorded')
+            Messages._error('Monitor: spike was not recorded')
 
         # Get data
-        if not spikes:
+        if spikes is None:
             data = self.get('spike')
         else:
             if 'spike' in spikes.keys():
                 data = spikes['spike']
             elif 'axon_spike' in spikes.keys():
                 data = spikes['axon_spike']
             else:
@@ -533,35 +542,35 @@
     def histogram(self, spikes=None, bins=None, per_neuron=False, recording_window=None):
         """
         Returns a histogram for the recorded spikes in the population.
 
         Example:
 
         ```python
-        m = Monitor(P[:1000], 'spike')
-        simulate(1000.0)
+        m = ann.Monitor(P[:1000], 'spike')
+        ann.simulate(1000.0)
         histo = m.histogram()
         plt.plot(histo)
         ```
 
         or:
 
         ```python
-        m = Monitor(P[:1000], 'spike')
-        simulate(1000.0)
+        m = ann.Monitor(P[:1000], 'spike')
+        ann.simulate(1000.0)
         spikes = m.get('spike')
         histo = m.histogram(spikes)
         plt.plot(histo)
         ```
 
         :param spikes: the dictionary of spikes returned by ``get('spike')``. If left empty, ``get('spike')`` will be called. Beware: this erases the data from memory.
         :param bins: the bin size in ms (default: dt).
         """
         if not 'spike' in self._variables:
-            Global._error('Monitor: spike was not recorded')
+            Messages._error('Monitor: spike was not recorded')
 
         # Get data
         if not spikes:
             data = self.get('spike')
         else:
             if 'spike' in spikes.keys():
                 data = spikes['spike']
@@ -610,33 +619,33 @@
     def mean_fr(self, spikes=None):
         """
         Computes the mean firing rate in the population during the recordings.
 
         Example:
 
         ```python
-        m = Monitor(P[:1000], 'spike')
-        simulate(1000.0)
+        m = ann.Monitor(P[:1000], 'spike')
+        ann.simulate(1000.0)
         fr = m.mean_fr()
         ```
 
         or:
 
         ```python
-        m = Monitor(P[:1000], 'spike')
-        simulate(1000.0)
+        m = ann.Monitor(P[:1000], 'spike')
+        ann.simulate(1000.0)
         spikes = m.get('spike')
         fr = m.mean_fr(spikes)
         ```
 
         :param spikes: the dictionary of spikes returned by ``get('spike')``. If left empty, ``get('spike')`` will be called. Beware: this erases the data from memory.
 
         """
         if not 'spike' in self._variables:
-            Global._error('Monitor: spike was not recorded')
+            Messages._error('Monitor: spike was not recorded')
 
         # Get data
         if not spikes:
             data = self.get('spike')
         else:
             if 'spike' in spikes.keys():
                 data = spikes['spike']
@@ -664,36 +673,36 @@
         Computes the smoothed firing rate of the recorded spiking neurons.
 
         The first axis is the neuron index, the second is time.
 
         Example:
 
         ```python
-        m = Monitor(P[:1000], 'spike')
-        simulate(1000.0)
+        m = ann.Monitor(P[:1000], 'spike')
+        ann.simulate(1000.0)
         r = m.smoothed_rate(smooth=100.)
         ```
 
         :param spikes: the dictionary of spikes returned by ``get('spike')``. If left empty, ``get('spike')`` will be called. Beware: this erases the data from memory.
         :param smooth: smoothing time constant. Default: 0.0 (no smoothing).
 
         """
         if not 'spike' in self._variables:
-            Global._error('Monitor: spike was not recorded')
+            Messages._error('Monitor: spike was not recorded')
 
         # Get data
         if not spikes:
             data = self.get('spike')
         else:
             if 'spike' in spikes.keys():
                 data = spikes['spike']
             else:
                 data = spikes
 
-        import ANNarchy.core.cython_ext.Transformations as Transformations
+        import ANNarchy.cython_ext.Transformations as Transformations
         return Transformations.smoothed_rate(
             {
                 'data': data,
                 'start': self._last_recorded_variables['spike']['start'][-1],
                 'stop': self._last_recorded_variables['spike']['stop'][-1]
             },
             smooth
@@ -708,36 +717,36 @@
         The first axis is the neuron index, the second is time.
 
         If ``spikes`` is left empty, ``get('spike')`` will be called. Beware: this erases the data from memory.
 
         Example:
 
         ```python
-        m = Monitor(P[:1000], 'spike')
-        simulate(1000.0)
+        m = ann.Monitor(P[:1000], 'spike')
+        ann.simulate(1000.0)
         r = m.population_rate(smooth=100.)
         ```
 
         :param spikes: the dictionary of spikes returned by ``get('spike')``.
         :param smooth: smoothing time constant. Default: 0.0 (no smoothing).
 
         """
         if not 'spike' in self._variables:
-            Global._error('Monitor: spike was not recorded')
+            Messages._error('Monitor: spike was not recorded')
 
         # Get data
         if not spikes:
             data = self.get('spike')
         else:
             if 'spike' in spikes.keys():
                 data = spikes['spike']
             else:
                 data = spikes
 
-        import ANNarchy.core.cython_ext.Transformations as Transformations
+        import ANNarchy.cython_ext.Transformations as Transformations
         return Transformations.population_rate(
             {
                 'data': data,
                 'start': self._last_recorded_variables['spike']['start'][-1],
                 'stop': self._last_recorded_variables['spike']['stop'][-1]
             },
             smooth
@@ -775,31 +784,31 @@
         pass
 
     def print_cpp(self, net_id=0):
         """
         Print memory consumption of CPP objects. The method calls
         the size_in_bytes() methods implemented by the C++ modules.
         """
-        for pop in Global._network[net_id]['populations']:
+        for pop in NetworkManager().get_populations(net_id=net_id):
             if hasattr(pop, 'size_in_bytes'):
                 print(pop.name, ":", self._human_readable_bytes(pop.size_in_bytes()))
             else:
-                Global._warning("MemoryStats.print_cpp(): the object", pop, "does not have a size_in_bytes() function.")
+                Messages._warning("MemoryStats.print_cpp(): the object", pop, "does not have a size_in_bytes() function.")
 
-        for proj in Global._network[net_id]['projections']:
+        for proj in NetworkManager().get_projections(net_id=net_id):
             if hasattr(proj, 'size_in_bytes'):
                 print(proj.pre.name, "->", proj.post.name, "(", proj.target, "):", self._human_readable_bytes(proj.size_in_bytes()))
             else:
-                Global._warning("MemoryStats.print_cpp(): the object", proj, "does not have a size_in_bytes() function.")
+                Messages._warning("MemoryStats.print_cpp(): the object", proj, "does not have a size_in_bytes() function.")
 
-        for mon in Global._network[net_id]['monitors']:
+        for mon in NetworkManager().get_monitors(net_id=net_id):
             if hasattr(proj, 'size_in_bytes'):
                 print("Monitor on", mon.object.name, ":", self._human_readable_bytes(mon.size_in_bytes()))
             else:
-                Global._warning("MemoryStats.print_cpp(): the object", mon, "does not have a size_in_bytes() function.")
+                Messages._warning("MemoryStats.print_cpp(): the object", mon, "does not have a size_in_bytes() function.")
 
     def _human_readable_bytes(self, num):
         """
         All cpp functions return there size in bytes *num* as long int. This function
         divides this by 1024 until the result is lower than the next unit.
         """
         for x in ['bytes','KB','MB','GB']:
@@ -807,26 +816,27 @@
                 return "%3.2f %s" % (num, x)
             num /= 1024.0
         return "%3.1f%s" % (num, 'TB')
 
 ######################
 # Static methods to plot spike patterns without a Monitor (e.g. offline)
 ######################
-def raster_plot(spikes):
+def raster_plot(spikes:dict) -> tuple:
     """
     Returns two vectors representing for each recorded spike 1) the spike times and 2) the ranks of the neurons.
 
     Example:
 
     ```python
-    m = Monitor(P[:1000], 'spike')
-    simulate(1000.0)
+    m = ann.Monitor(P[:1000], 'spike')
+    ann.simulate(1000.0)
     spikes = m.get('spike')
-    spike_times, spike_ranks = raster_plot(spikes)
-    plt.plot(spike_times, spike_ranks, '.')
+    t, n = raster_plot(spikes)
+
+    plt.plot(t, n, '.')
     ```
 
     :param spikes: the dictionary of spikes returned by ``get('spike')``.
     """
     times = []; ranks=[]
 
     # Compute raster
@@ -834,35 +844,35 @@
         for t in spikes[n]:
             times.append(t)
             ranks.append(n)
 
     return Global.dt()* np.array(times), np.array(ranks)
 
 
-def histogram(spikes, bins=None, per_neuron=False, recording_window=None):
+def histogram(spikes:dict, bins:float=None, per_neuron:bool=False, recording_window:tuple=None):
     """
     Returns a histogram for the recorded spikes in the population.
 
     Example:
 
     ```python
-    m = Monitor(P[:1000], 'spike')
-    simulate(1000.0)
+    m = ann.Monitor(P[:1000], 'spike')
+    ann.simulate(1000.0)
     spikes = m.get('spike')
     histo = histogram(spikes)
     plt.plot(histo)
     ```
 
     :param spikes: the dictionary of spikes returned by ``get('spike')``.
     :param bins: the bin size in ms (default: dt).
     """
     if bins is None:
-        bins =  Global.config['dt']
+        bins =  get_global_config('dt')
 
-    bin_step = int(bins/Global.config['dt'])
+    bin_step = int(bins/get_global_config('dt'))
 
     # Compute the duration of the recordings
     t_maxes = []
     t_mines = []
     for neuron in spikes.keys():
         if len(spikes[neuron]) == 0 : continue
         t_maxes.append(np.max(spikes[neuron]))
@@ -897,17 +907,22 @@
         # Compute per step histogram
         for neuron in spikes.keys():
             for t in spikes[neuron]:
                 histo[int((t-t_min)/float(bin_step))] += 1
 
     return np.array(histo)
 
-def inter_spike_interval(spikes, ranks=None, per_neuron=False):
+def inter_spike_interval(spikes:dict, ranks:list=None, per_neuron:bool=False):
     """
-    Computes the inter-spike interval for the record spike events of a population.
+    Computes the inter-spike interval (ISI) for the recorded spike events of a population.
+
+    :param spikes: the dictionary of spikes returned by ``get('spike')``.
+    :param ranks: list of ranks.
+    :param per_neuron: if True, the ISI will be computed per neuron, not globally.
+
     """
     isi = {}
     for neuron_rank, spike_events in spikes.items():
         # ISI computation requires at least 2 events
         if len(spike_events) < 2:
             continue
 
@@ -927,17 +942,21 @@
         return isi
     else:
         res = []
         for val in isi.values():
             res.extend(val)
         return res
 
-def coefficient_of_variation(spikes, ranks=None, per_neuron=False):
+def coefficient_of_variation(spikes:dict, ranks:list=None, per_neuron:bool=False):
     """
     Computes the coefficient of variation of the inter-spike intervals for the recorded spike events of a population.
+
+    :param spikes: the dictionary of spikes returned by ``get('spike')``.
+    :param ranks: list of ranks.
+    :param per_neuron: if True, the ISI will be computed per neuron, not globally.
     """
     isi_per_neuron = inter_spike_interval(spikes, ranks=ranks, per_neuron=True)
     isi_cv = {}
     for neuron_rank, values in isi_per_neuron.items():
         if len(values) < 2:
             continue     # no meaningful mean/std possible
 
@@ -952,27 +971,27 @@
         return isi_cv
     else:
         res = []
         for val in isi_cv.values():
             res.append(val)
         return res
 
-def population_rate(spikes, smooth=0.0):
+def population_rate(spikes:dict, smooth:float=0.0):
     """
     Takes the recorded spikes of a population and returns a smoothed firing rate for the population of recorded neurons.
 
     This method is faster than calling ``smoothed_rate`` and then averaging.
 
     The first axis is the neuron index, the second is time.
 
     Example:
 
     ```python
-    m = Monitor(P[:1000], 'spike')
-    simulate(1000.0)
+    m = ann.Monitor(P[:1000], 'spike')
+    ann.simulate(1000.0)
     spikes = m.get('spike')
     r = population_rate(smooth=100.)
     ```
 
     :param spikes: the dictionary of spikes returned by ``get('spike')``.
     :param smooth: smoothing time constant. Default: 0.0 (no smoothing).
     """
@@ -983,35 +1002,35 @@
         if len(spikes[neuron]) == 0 : continue
         t_maxes.append(np.max(spikes[neuron]))
         t_mines.append(np.min(spikes[neuron]))
 
     t_max = np.max(t_maxes)
     t_min = np.min(t_mines)
 
-    import ANNarchy.core.cython_ext.Transformations as Transformations
+    import ANNarchy.cython_ext.Transformations as Transformations
     return Transformations.population_rate(
         {
             'data': spikes,
             'start':t_min,
             'stop': t_max
         },
         smooth
     )
 
-def smoothed_rate(spikes, smooth=0.):
+def smoothed_rate(spikes:dict, smooth:float=0.):
     """
     Computes the smoothed firing rate of the recorded spiking neurons.
 
     The first axis is the neuron index, the second is time.
 
     Example:
 
     ```python
-    m = Monitor(P[:1000], 'spike')
-    simulate(1000.0)
+    m = ann.Monitor(P[:1000], 'spike')
+    ann.simulate(1000.0)
     spikes = m.get('spike')
     r = smoothed_rate(smooth=100.)
     ```
 
 
     :param spikes: the dictionary of spikes returned by ``get('spike')``. If left empty, ``get('spike')`` will be called. Beware: this erases the data from memory.
     :param smooth: smoothing time constant. Default: 0.0 (no smoothing).
@@ -1023,15 +1042,15 @@
         if len(spikes[neuron]) == 0 : continue
         t_maxes.append(np.max(spikes[neuron]))
         t_mines.append(np.min(spikes[neuron]))
 
     t_max = np.max(t_maxes)
     t_min = np.min(t_mines)
 
-    import ANNarchy.core.cython_ext.Transformations as Transformations
+    import ANNarchy.cython_ext.Transformations as Transformations
     return Transformations.smoothed_rate(
         {
             'data': spikes,
             'start': t_min,
             'stop': t_max
         },
         smooth
@@ -1040,16 +1059,16 @@
 def mean_fr(spikes, duration=None):
     """
     Computes the mean firing rate in the population during the recordings.
 
     Example:
 
     ```python
-    m = Monitor(P[:1000], 'spike')
-    simulate(1000.0)
+    m = ann.Monitor(P[:1000], 'spike')
+    ann.simulate(1000.0)
     spikes = m.get('spike')
     fr = mean_fr(spikes)
     ```
 
     :param spikes: the dictionary of spikes returned by ``get('spike')``.
     :param duration: duration of the recordings. By default, the mean firing rate is computed between the first and last spikes of the recordings.
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/Network.py` & `annarchy-4.8.0.1/ANNarchy/generator/Compiler.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,848 +1,851 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-from .Population import Population
-from .PopulationView import PopulationView
-from .Projection import Projection
-from .Monitor import Monitor
-from ANNarchy.extensions.bold import BoldMonitor
-
-import ANNarchy.core.Global as Global
-import ANNarchy.core.Simulate as Simulate
-import ANNarchy.core.IO as IO
-import ANNarchy.core.SpecificPopulation as SpecificPopulation
-import ANNarchy.generator.Compiler as Compiler
+import os, sys, importlib
+import subprocess
+import shutil
+import multiprocessing
+import time
+import json
 import numpy as np
-import os
 
-class Network :
-    """
-    A network gathers already defined populations, projections and monitors in order to run them independently.
-
-    This is particularly useful when varying single parameters of a network and comparing the results (see the ``parallel_run()`` method).
-
-    Only objects declared before the creation of the network can be used. Global methods such as ``simulate()`` must be used on the network object.
-    The objects must be accessed through the ``get()`` method, as the original ones will not be part of the network (a copy is made).
-
-    Each network must be individually compiled, but it does not matter if the original objects were already compiled.
-
-    When passing ``everything=True`` to the constructor, all populations/projections/monitors already defined at the global level will be added to the network.
+# ANNarchy core informations
+import ANNarchy
 
-    If not, you can select which object will be added to network with the ``add()`` method.
+from ANNarchy.intern.NetworkManager import NetworkManager
+from ANNarchy.core import Global
+from ANNarchy.intern.Profiler import Profiler
+from ANNarchy.intern.ConfigManagement import get_global_config, _update_global_config, _check_paradigm
+from ANNarchy.intern.GlobalObjects import GlobalObjectManager
+from ANNarchy.intern import Messages
+
+from ANNarchy.extensions.bold.NormProjection import _update_num_aff_connections
+from ANNarchy.generator.Template.MakefileTemplate import *
+from ANNarchy.generator.CodeGenerator import CodeGenerator
+from ANNarchy.generator.Sanity import check_structure, check_experimental_features
+from ANNarchy.generator.Utils import check_cuda_version
+from ANNarchy.parser.report.Report import report
+
+# String containing the extra libs which can be added by extensions
+# e.g. extra_libs = ['-lopencv_core', '-lopencv_video']
+extra_libs = []
 
-    Example with ``everything=True``:
-
-    ```python
-    pop = Population(100, Izhikevich)
-    proj = Projection(pop, pop, 'exc')
-    proj.connect_all_to_all(1.0)
-    m = Monitor(pop, 'spike')
-
-    compile() # Optional
-
-    net = Network(everything=True)
-    net.get(pop).a = 0.02
-    net.compile()
-    net.simulate(1000.)
+def _folder_management(annarchy_dir, profile_enabled, clean, net_id):
+    """
+    ANNarchy is provided as a python package. For compilation a local folder
+    'annarchy' is created in the current working directory.
 
-    net2 = Network(everything=True)
-    net2.get(pop).a = 0.05
-    net2.compile()
-    net2.simulate(1000.)
+    *Parameter*:
 
-    t, n = net.get(m).raster_plot()
-    t2, n2 = net2.get(m).raster_plot()
-    ```
+    * annarchy_dir : subdirectory
+    * *profile_enabled*: copy needed data for profile extension
+    """
 
-    Example with ``everything=False`` (the default):
+    # Verbose
+    if get_global_config('verbose'):
+        Messages._print("Create subdirectory.")
+
+    if clean or profile_enabled:
+        shutil.rmtree(annarchy_dir, True)
+
+    # Create the subdirectory
+    if not os.path.exists(annarchy_dir):
+        os.makedirs(annarchy_dir)
+        os.mkdir(annarchy_dir+'/build')
+        os.mkdir(annarchy_dir+'/generate')
+
+    # Subdirectory for building networks
+    if not os.path.exists(annarchy_dir+'/build/net'+str(net_id)):
+        os.mkdir(annarchy_dir+'/build/net'+str(net_id))
+
+    # Create the generate subfolder
+    if not os.path.exists(annarchy_dir+'/generate/net'+str(net_id)):
+        os.mkdir(annarchy_dir+'/generate/net'+str(net_id))
+
+    # Save current ANNarchy version and paradigm
+    with open(annarchy_dir+'/release', 'w') as wfile:
+        wfile.write(get_global_config('paradigm')+', '+ANNarchy.__release__)
+
+    sys.path.append(annarchy_dir)
+
+def compile(
+        directory='annarchy',
+        clean=False,
+        populations=None,
+        projections=None,
+        compiler="default",
+        compiler_flags="default",
+        add_sources="",
+        extra_libs="",
+        cuda_config={'device': 0},
+        annarchy_json="",
+        silent=False,
+        debug_build=False,
+        profile_enabled=False,
+        net_id=0
+    ):
+    """
+    This method uses the network architecture to generate optimized C++ code and compile a shared library that will perform the simulation.
 
-    ```python
-    pop = Population(100, Izhikevich)
-    proj1 = Projection(pop, pop, 'exc')
-    proj1.connect_all_to_all(1.0)
-    proj2 = Projection(pop, pop, 'exc')
-    proj2.connect_all_to_all(2.0)
-    m = Monitor(pop, 'spike')
+    The ``compiler``, ``compiler_flags`` and part of ``cuda_config`` take their default value from the configuration file ``~/.config/ANNarchy/annarchy.json``.
 
-    net = Network()
-    net.add([pop, proj1, m])
-    net.compile()
-    net.simulate(1000.)
+    The following arguments are for internal development use only:
 
-    net2 = Network()
-    net2.add([pop, proj2, m])
-    net2.compile()
-    net2.simulate(1000.)
+    * **debug_build**: creates a debug version of ANNarchy, which logs the creation of objects and some other data (default: False).
+    * **profile_enabled**: creates a profilable version of ANNarchy, which logs several computation timings (default: False).
 
-    t, n = net.get(m).raster_plot()
-    t2, n2 = net2.get(m).raster_plot()
-    ```
-    
+    :param directory: name of the subdirectory where the code will be generated and compiled. Must be a relative path. Default: "annarchy/".
+    :param clean: boolean to specifying if the library should be recompiled entirely or only the changes since last compilation (default: False).
+    :param populations: list of populations which should be compiled. If set to None, all available populations will be used.
+    :param projections: list of projection which should be compiled. If set to None, all available projections will be used.
+    :param compiler: C++ compiler to use. Default: g++ on GNU/Linux, clang++ on OS X. Valid compilers are [g++, clang++].
+    :param compiler_flags: platform-specific flags to pass to the compiler. Default: "-march=native -O2". Warning: -O3 often generates slower code and can cause linking problems, so it is not recommended.
+    :param cuda_config: dictionary defining the CUDA configuration for each population and projection.
+    :param annarchy_json: compiler flags etc can be stored in a .json file normally placed in the home directory (see comment below). With this flag one can directly assign a file location.
+    :param silent: defines if status message like "Compiling... OK" should be printed.
     """
+    # Check if the network has already been compiled
+    if NetworkManager().is_compiled(net_id=net_id):
+        Messages._print("""compile(): the network has already been compiled, doing nothing.
+    If you are re-running a Jupyter notebook, you should call `clear()` right after importing ANNarchy in order to reset everything.""")
+        return
+
+    # Get command-line arguments. Note that setup() related flags has been partially parsed!
+    options, unknown = ANNarchy._arg_parser.parser.parse_known_args()
+
+    # Check for unknown flags
+    if len(unknown) > 0 and get_global_config('verbose'):
+        Messages._warning('unrecognized command-line arguments:', unknown)
+
+    # Get CUDA configuration
+    if options.gpu_device >= 0:
+        cuda_config['device'] = int(options.gpu_device)
+
+    # Check that a single backend is chosen
+    if (options.num_threads != None) and (options.gpu_device >= 0):
+        Messages._error('CUDA and openMP can not be active at the same time, please check your command line arguments.')
+
+    # check if profiling was enabled by --profile
+    if options.profile != None:
+        profile_enabled = options.profile
+        _update_global_config('profiling', options.profile)
+        _update_global_config('profile_out', options.profile_out)
+
+    # check if profiling enabled due compile()
+    if profile_enabled != False and options.profile == None:
+        _update_global_config('profiling', True)
+    # if profiling is enabled
+    if profile_enabled:
+        # this will automatically create a globally available Profiler instance
+        Profiler().enable_profiling()
+        if get_global_config('profile_out') == None:
+            _update_global_config('profile_out', '.')
+
+    # Debug
+    if not debug_build:
+        debug_build = options.debug  # debug build
+    _update_global_config('debug', debug_build)
+
+    # Clean
+    clean = options.clean or clean # enforce rebuild
+
+    # Populations to compile
+    if populations is None: # Default network
+        populations = NetworkManager().get_populations(net_id=net_id)
+
+    # Projections to compile
+    if projections is None: # Default network
+        projections = NetworkManager().get_projections(net_id=net_id)
+
+    # Compiling directory
+    annarchy_dir = os.getcwd() + '/' + directory
+    if not annarchy_dir.endswith('/'):
+        annarchy_dir += '/'
+
+    # Test if the current ANNarchy version is newer than what was used to create the subfolder
+    from pkg_resources import parse_version
+    if os.path.isfile(annarchy_dir+'/release'):
+        with open(annarchy_dir+'/release', 'r') as rfile:
+            prev_release = rfile.read().strip()
+            prev_paradigm = ''
+
+            # HD (03.08.2016):
+            # in ANNarchy 4.5.7b I added also the paradigm to the release tag.
+            # This if clause can be removed in later releases (TODO)
+            if prev_release.find(',') != -1:
+                prev_paradigm, prev_release = prev_release.split(', ')
+            else:
+                # old release tag
+                clean = True
 
-    def __init__(self, everything=False):
-        """
-        :param everything: defines if all existing populations and projections should be automatically added (default: False).
-        """
-        self.id = Global._network.add_network(self)
-        self.everything = everything
+            if parse_version(prev_release) < parse_version(ANNarchy.__release__):
+                clean = True
 
-        Simulate._callbacks.append([])
-        Simulate._callbacks_enabled.append(True)
-        self.populations = []
-        self.projections = []
-        self.monitors = []
-        self.extensions = []
-
-        if everything:
-            self.add(Global._network[0]['populations'])
-            self.add(Global._network[0]['projections'])
-            self.add(Global._network[0]['monitors'])
-            self.add(Global._network[0]['extensions'])
-
-    def __del__(self):
-        
-        # Overridden destructor for two reasons:
-        # 
-        # a) track destruction of objects
-        # b) manually deallocate C++ container data
-        # 
-        # Hint: this function can be called explicitly (which is not recommended in many cases) or as
-        #       finalizer from the garbage collection. If called explicitely, one should take in mind,
-        #       that the function will be called twice. The better approach is to trigger this function
-        #       by del on the network object.
-        for pop in self.get_populations():
-            pop._clear()
-            del pop
-
-        for proj in self.get_projections(suppress_error=True):
-            proj._clear()
-            del proj
-
-        for mon in self.monitors:
-            mon._clear()
-            del mon
-
-        for ext in self.extensions:
-            ext._clear()
-            del ext
+            elif prev_paradigm != get_global_config('paradigm'):
+                clean = True
 
-        Global._network._remove_network(self)
+    else:
+        clean = True # for very old versions
 
-    def _cpp_memory_footprint(self):
-        """
-        Print the C++ memory consumption for populations, projections on the console.
-        """
-        for pop in self.get_populations():
-            print(pop.name, pop.size_in_bytes())
+    # Check if the last compilation was successful
+    if os.path.isfile(annarchy_dir+'/compilation'):
+        with open(annarchy_dir + '/compilation', 'r') as rfile:
+            res = rfile.read()
+            if res.strip() == "0": # the last compilation failed
+                clean = True
+    else:
+        clean = True
 
-        for proj in self.get_projections():
-            print(proj.name, proj.size_in_bytes())
+    # Manage the compilation subfolder
+    _folder_management(annarchy_dir, profile_enabled, clean, net_id)
 
-        for mon in self.monitors:
-            print(type(mon), mon.size_in_bytes())
+    # Create a Compiler object
+    compiler = Compiler(
+        annarchy_dir=annarchy_dir,
+        clean=clean,
+        compiler=compiler,
+        compiler_flags=compiler_flags,
+        add_sources=add_sources,
+        extra_libs=extra_libs,
+        path_to_json=annarchy_json,
+        silent=silent,
+        cuda_config=cuda_config,
+        debug_build=debug_build,
+        profile_enabled=profile_enabled,
+        populations=populations,
+        projections=projections,
+        net_id=net_id
+    )
+
+    # Code Generation
+    compiler.generate()
+
+    if get_global_config('verbose'):
+        net_str = "" if compiler.net_id == 0 else str(compiler.net_id)+" "
+        Messages._print('Construct network '+net_str+'...', end=" ")
+
+    # Create the Python objects
+    _instantiate(compiler.net_id, cuda_config=compiler.cuda_config, user_config=compiler.user_config)
+
+    # NormProjections require an update of afferent projections
+    _update_num_aff_connections(compiler.net_id)
+
+    if get_global_config('verbose'):
+        Messages._print('OK')
+
+    # Create a report if requested
+    if options.report is not None:
+        report(options.report)
 
-    def add(self, objects):
-        """
-        Adds a Population, Projection or Monitor to the network.
+def python_environment():
+    """
+    Python environment configuration, required by Compiler.generate_makefile. Contains among others the python version, library path and cython version.
 
-        :param objects: A single object or a list to add to the network.
-        """
-        if isinstance(objects, list):
-            for item in objects:
-                self._add_object(item)
+    Warning: changes to this method should be copied to setup.py.
+    """
+    # Python version
+    py_version = "%(major)s.%(minor)s" % {'major': sys.version_info[0],
+                                          'minor': sys.version_info[1]}
+    py_major = str(sys.version_info[0])
+
+    if py_major == '2':
+        Messages._warning("Python 2 is not supported anymore, things might break.")
+
+    # Python includes and libs
+    # non-standard python installs need to tell the location of libpythonx.y.so/dylib
+    # export LD_LIBRARY_PATH=$HOME/anaconda/lib:$LD_LIBRARY_PATH
+    # export DYLD_FALLBACK_LIBRARY_PATH=$HOME/anaconda/lib:$DYLD_FALLBACK_LIBRARY_PATH
+    py_prefix = sys.base_prefix
+
+    # Search for pythonx.y-config
+    cmd = "%(py_prefix)s/bin/python%(py_version)s-config --includes > /dev/null 2> /dev/null"
+    with subprocess.Popen(cmd % {'py_version': py_version, 'py_prefix': py_prefix}, shell=True) as test:
+        if test.wait() != 0:
+            Messages._warning("Can not find python-config in the same directory as python, trying with the default path...")
+            python_config_path = "python%(py_version)s-config"% {'py_version': py_version}
         else:
-            self._add_object(objects)
-
-    def _add_object(self, obj):
-        """
-        Add the object *obj* to the network.
-
-        TODO: instead of creating copies by object construction, one should check if deepcopy works ...
-        """
-        if isinstance(obj, Population):
-            # Create a copy
-            pop = obj._copy()
-
-            # Remove the copy from the global network
-            Global._network[0]['populations'].pop(-1) # FIXME: the list is iterated from left to right and we delete from right to left???
-
-            # Copy import properties
-            pop.id = obj.id
-            pop.name = obj.name
-            pop.class_name = obj.class_name
-            pop.init = obj.init
-            pop.enabled = obj.enabled
-            if not obj.enabled: # Also copy the enabled state:
-                pop.disable()
-
-            # Add the copy to the local network
-            Global._network[self.id]['populations'].append(pop)
-            self.populations.append(pop)
-
-            # Check whether the computation of mean-firing rate is requested
-            if obj._compute_mean_fr > 0:
-                pop.compute_firing_rate(obj._compute_mean_fr)
+            python_config_path = "%(py_prefix)s/bin/python%(py_version)s-config" % {'py_version': py_version, 'py_prefix': py_prefix}
 
-        elif isinstance(obj, Projection):
-            # Check the pre- or post- populations
-            try:
-                pre_pop = self.get(obj.pre)
-                if isinstance(obj.pre, PopulationView):
-                    pre = PopulationView(population=pre_pop.population, ranks=obj.pre.ranks)
-                else:
-                    pre = pre_pop
-                post_pop = self.get(obj.post)
-                if isinstance(obj.post, PopulationView):
-                    post = PopulationView(population=post_pop.population, ranks=obj.post.ranks)
-                else:
-                    post = post_pop
-            except:
-                Global._error('Network.add(): The pre- or post-synaptic population of this projection are not in the network.')
-
-            # Create the projection
-            proj = obj._copy(pre=pre, post=post)
-            # Remove the copy from the global network
-            Global._network[0]['projections'].pop(-1)
-
-            # Copy import properties
-            proj.id = obj.id
-            proj.name = obj.name
-            proj.init = obj.init
-
-            # Copy the connectivity properties if the projection is not already set
-            if proj._connection_method is None:
-                proj._store_connectivity(method=obj._connection_method, args=obj._connection_args, delay=obj._connection_delay, storage_format=obj._storage_format, storage_order=obj._storage_order)
-
-            # Add the copy to the local network
-            Global._network[self.id]['projections'].append(proj)
-            self.projections.append(proj)
-
-        elif isinstance(obj, BoldMonitor):
-            # Create a copy of the monitor
-            m = BoldMonitor(
-                populations=obj._populations,
-                bold_model=obj._bold_model,
-                mapping=obj._mapping,
-                scale_factor=obj._scale_factor,
-                normalize_input=obj._normalize_input,
-                recorded_variables=obj._recorded_variables,
-                start=obj._start,
-                net_id=self.id,
-                copied=True
-            )
-
-            # there is a bad mismatch between object ids:
-            #
-            # m.id     is dependent on len(_network[net_id].monitors)
-            # obj.id   is dependent on len(_network[0].monitors)
-            m.id = obj.id # TODO: check this !!!!
-
-            # Stop the master monitor, otherwise it gets data.
-            for var in obj._monitor.variables:
-                try:
-                    setattr(obj._monitor.cyInstance, 'record_'+var, False)
-                except:
-                    pass
-
-            # assign contained objects
-            m._monitor = self._get_object(obj._monitor)
-            m._bold_pop = self._get_object(obj._bold_pop)
-            m._acc_proj = []
-            for tmp in obj._acc_proj:
-                m._acc_proj.append(self._get_object(tmp))
-
-            # need to be done manually for copied instances
-            m._initialized = True
-
-            # Add the copy to the local network (the monitor writes itself already in the right network)
-            self.extensions.append(m)
-
-        elif isinstance(obj, Monitor):
-            # Get the copied reference of the object monitored
-            # try:
-            #     obj_copy = self.get(obj.object)
-            # except:
-            #     Global._error('Network.add(): The monitor does not exist.')
-
-            # Stop the master monitor, otherwise it gets data.
-            for var in obj.variables:
-                try:
-                    setattr(obj.cyInstance, 'record_'+var, False)
-                except:
-                    pass
-            # Create a copy of the monitor
-            m = Monitor(obj=self._get_object(obj.object), variables=obj.variables, period=obj._period, period_offset=obj._period_offset, start=obj._start, net_id=self.id)
-
-            # there is a bad mismatch between object ids:
-            #
-            # m.id     is dependent on len(_network[net_id].monitors)
-            # obj.id   is dependent on len(_network[0].monitors)
-            m.id = obj.id # TODO: check this !!!!
-
-            # Add the copy to the local network (the monitor writes itself already in the right network)
-            self.monitors.append(m)
+    python_include = "`%(pythonconfigpath)s --includes`" % {'pythonconfigpath': python_config_path}
+    python_libpath = "-L%(py_prefix)s/lib" % {'py_prefix': py_prefix}
 
-    def get(self, obj):
-        """
-        Returns the local Population, Projection or Monitor identical to the provided argument.
-
-        Example:
-
-        ```python
-        pop = Population(100, Izhikevich)
-        net = Network()
-        net.add(pop)
-        net.compile()
-        net.simulate(100.)
-        print net.get(pop).v
-        ```
+    # Identify the -lpython flag
+    with subprocess.Popen('%(pythonconfigpath)s --ldflags' % {'pythonconfigpath': python_config_path},
+                          shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) as test:
+        flagline = str(test.stdout.read().decode('UTF-8')).strip()
+        errorline = str(test.stderr.read().decode('UTF-8'))
+        test.wait()
+
+    if len(errorline) > 0:
+        Messages._error("Unable to find python-config. Make sure you have installed the development files of Python (python-dev or -devel) and that either python-config, python2-config or python3-config are in your path.")
+    flags = flagline.split(' ')
+    for flag in flags:
+        if flag.startswith('-lpython'):
+            python_lib = flag
+            break
+    else:
+        python_lib = "-lpython" + py_version
 
-        :param obj: A single object or a list of objects.
-        :return: The corresponding object or list of objects.
-        """
-        if isinstance(obj, list):
-            return [self._get_object(o) for o in obj]
+    # Check cython version
+    with subprocess.Popen(py_prefix + "/bin/cython%(major)s -V > /dev/null 2> /dev/null" % {'major': py_major}, shell=True) as test:
+        if test.wait() != 0:
+            cython = py_prefix + "/bin/cython"
         else:
-            return self._get_object(obj)
-
-    def _get_object(self, obj):
-        "Retrieves the corresponding object."
-        if isinstance(obj, Population):
-            for pop in self.populations:
-                if pop.id == obj.id:
-                    return pop
-        elif isinstance(obj, PopulationView):
-            for pop in self.populations:
-                if pop.id == obj.id:
-                    return PopulationView(pop, obj.ranks) # Create on the fly?
-        elif isinstance(obj, Projection):
-            for proj in self.projections:
-                if proj.id == obj.id:
-                    return proj
-        elif isinstance(obj, Monitor):
-            for m in self.monitors:
-                if m.id == obj.id:
-                    return m
-        elif isinstance(obj, BoldMonitor):
-            for m in self.extensions:
-                if m.id == obj.id:
-                    return m
+            cython = py_prefix + "/bin/cython" + py_major
+    # If not in the same folder as python, use the default
+    with subprocess.Popen("%(cython)s -V > /dev/null 2> /dev/null" % {'cython': cython}, shell=True) as test:
+        if test.wait() != 0:
+            cython = shutil.which("cython"+str(py_major))
+            if cython is None:
+                cython = shutil.which("cython")
+                if cython is None:
+                    Messages._erroror("Unable to detect the path to cython.")
+
+    return py_version, py_major, python_include, python_lib, python_libpath, cython
+
+class Compiler(object):
+    " Main class to generate C++ code efficiently"
+
+    def __init__(self, annarchy_dir, clean, compiler, compiler_flags, add_sources, extra_libs, path_to_json, silent, cuda_config, debug_build,
+                 profile_enabled, populations, projections, net_id):
+
+        # Store arguments
+        self.annarchy_dir = annarchy_dir
+        self.clean = clean
+        self.compiler = compiler
+        self.compiler_flags = compiler_flags
+        self.add_sources = add_sources
+        self.extra_libs = extra_libs
+        self.silent = silent
+        self.cuda_config = cuda_config
+        self.debug_build = debug_build
+        self.profile_enabled = profile_enabled
+        self.populations = populations
+        self.projections = projections
+        self.net_id = net_id
+
+        # Get user-defined config
+        self.user_config = {
+            'openmp': {
+                'compiler': 'clang++' if sys.platform == "darwin" else 'g++',
+                'flags' : "-march=native -O2",
+            },
+            'cuda': {
+                'compiler': "nvcc",
+                'device': 0
+            }
+        }
+
+        if len(path_to_json) == 0:
+            # check homedirectory
+            if os.path.exists(os.path.expanduser('~/.config/ANNarchy/annarchy.json')):
+                with open(os.path.expanduser('~/.config/ANNarchy/annarchy.json'), 'r') as rfile:
+                    self.user_config = json.load(rfile)
         else:
-            Global._error('The network has no such object:', obj.name, obj)
-
-    def compile(self,
-                directory='annarchy',
-                clean=False,
-                compiler="default",
-                compiler_flags="default",
-                add_sources="",
-                extra_libs="",
-                cuda_config={'device': 0},
-                annarchy_json="",
-                silent=False,
-                debug_build=False,
-                profile_enabled=False):
-        """
-        Compiles the network.
-
-        :param directory: name of the subdirectory where the code will be generated and compiled. Must be a relative path. Default: "annarchy/".
-        :param clean: boolean to specifying if the library should be recompiled entirely or only the changes since last compilation (default: False).
-        :param compiler: C++ compiler to use. Default: g++ on GNU/Linux, clang++ on OS X. Valid compilers are [g++, clang++].
-        :param compiler_flags: platform-specific flags to pass to the compiler. Default: "-march=native -O2". Warning: -O3 often generates slower code and can cause linking problems, so it is not recommended.
-        :param cuda_config: dictionary defining the CUDA configuration for each population and projection.
-        :param annarchy_json: compiler flags etc are stored in a .json file normally placed in the home directory. With this flag one can directly assign a file location.
-        :param silent: defines if the "Compiling... OK" should be printed.
-
-        """
-        Compiler.compile(directory=directory, clean=clean, silent=silent, debug_build=debug_build, add_sources=add_sources, extra_libs=extra_libs, compiler=compiler, compiler_flags=compiler_flags, cuda_config=cuda_config, annarchy_json=annarchy_json, profile_enabled=profile_enabled, net_id=self.id)
-
-    def simulate(self, duration, measure_time = False):
-        """
-        Runs the network for the given duration in milliseconds. 
-        
-        The number of simulation steps is  computed relative to the discretization step ``dt`` declared in ``setup()`` (default: 1ms):
-
-        ```python
-        simulate(1000.0)
-        ```
-
-        :param duration: the duration in milliseconds.
-        :param measure_time: defines whether the simulation time should be printed (default=False).
-
-        """
-        Simulate.simulate(duration, measure_time, net_id=self.id)
-
-    def simulate_until(self, max_duration, population, operator='and', measure_time = False):
-        """
-        Runs the network for the maximal duration in milliseconds. If the ``stop_condition`` defined in the population becomes true during the simulation, it is stopped.
-
-        One can specify several populations. If the stop condition is true for any of the populations, the simulation will stop ('or' function).
-
-        Example:
-
-        ```python
-        pop1 = Population( ..., stop_condition = "r > 1.0 : any")
-        compile()
-        simulate_until(max_duration=1000.0. population=pop1)
-        ```
-
-        :param max_duration: the maximum duration of the simulation in milliseconds.
-        :param population: the (list of) population whose ``stop_condition`` should be checked to stop the simulation.
-        :param operator: operator to be used ('and' or 'or') when multiple populations are provided (default: 'and').
-        :param measure_time: defines whether the simulation time should be printed (default=False).
-        :return: the actual duration of the simulation in milliseconds.
-        """
-        return Simulate.simulate_until(max_duration, population, operator, measure_time, net_id=self.id)
-
-    def step(self):
-        """
-        Performs a single simulation step (duration = ``dt``).
-        """
-        Simulate.step(self.id)
-
-    def reset(self, populations=True, projections=False, monitors=True, synapses=False):
-        """
-        Reinitialises the network to its state before the call to compile.
-
-        :param populations: if True (default), the neural parameters and variables will be reset to their initial value.
-        :param projections: if True, the synaptic parameters and variables (except the connections) will be reset (default=False).
-        :param synapses: if True, the synaptic weights will be erased and recreated (default=False).
-        """
-        Global.reset(populations=populations, projections=projections, synapses=synapses, monitors=monitors, net_id=self.id)
-
-    def get_time(self):
-        "Returns the current time in ms."
-        return Global.get_time(self.id)
-
-    def set_time(self, t, net_id=0):
-        """
-        Sets the current time in ms.
-
-        **Warning:** can be dangerous for some spiking models.
-        """
-        Global.set_time(t, self.id)
-
-    def get_current_step(self):
-        "Returns the current simulation step."
-        return Global.get_current_step(self.id)
-
-    def set_current_step(self, t):
-        """
-        Sets the current simulation step.
-
-        **Warning:** can be dangerous for some spiking models.
-        """
-        Global.set_current_step(t, self.id)
+            with open(path_to_json, 'r') as rfile:
+                self.user_config = json.load(rfile)
 
-    def set_seed(self, seed, use_seed_seq=True):
-        """
-        Sets the seed of the random number generators for this network.
-        """
-        Global.set_seed(seed=seed, use_seed_seq=use_seed_seq, net_id=self.id)
-
-    def enable_learning(self, projections=None, period=None, offset=None):
-        """
-        Enables learning for all projections.
-
-        :param projections: the projections whose learning should be enabled. By default, all the existing projections are disabled.
-        """
-        if not projections:
-            projections = self.projections
-        for proj in projections:
-            proj.enable_learning(period=period, offset=offset)
-
-    def disable_learning(self, projections=None):
-        """
-        Disables learning for all projections.
-
-        :param projections: the projections whose learning should be disabled. By default, all the existing projections are disabled.
-        """
-        if not projections:
-            projections = self.projections
-        for proj in projections:
-            proj.disable_learning()
-
-    def get_population(self, name):
-        """
-        Returns the population with the given *name*.
-
-        :param name: name of the population
-        :return: The requested ``Population`` object if existing, ``None`` otherwise.
-        """
-        for pop in self.populations:
-            if pop.name == name:
-                return pop
-        Global._print('get_population(): the population', name, 'does not exist in this network.')
-        return None
-
-    def get_projection(self, name):
-        """
-        Returns the projection with the given *name*.
-
-        :param name: name of the projection
-        :return: The requested ``Projection`` object if existing, ``None`` otherwise.
-        """
-        for proj in self.projections:
-            if proj.name == name:
-                return proj
-        Global._print('get_projection(): the projection', name, 'does not exist in this network.')
-        return None
-
-    def get_populations(self):
-        """
-        Returns a list of all declared populations in this network.
-        """
-        if self.populations == []:
-            Global._warning("Network.get_populations(): no populations attached to this network.")
-        return self.populations
-
-    def get_projections(self, post=None, pre=None, target=None, suppress_error=False):
-        """
-        Get a list of declared projections for the current network. By default,
-        the method returns all connections within the network.
-
-        By setting the arguments, post, pre and target one can select a subset.
-
-        :param post: all returned projections should have this population as post.
-        :param pre: all returned projections should have this population as pre.
-        :param target: all returned projections should have this target.
-        :param suppress_error: by default, ANNarchy throws an error if the list of assigned projections is empty. If this flag is set to True, the error message is suppressed.
-        :return: A list of all assigned projections in this network or a subset according to the arguments.
-
-        """
-        if self.projections == []:
-            if not suppress_error:
-                Global._error("Network.get_projections(): no projections attached to this network.")
-
-        if post is None and pre is None and target is None:
-            return self.projections
+        # Sanity check if the NVCC compiler is available
+        if _check_paradigm("cuda"):
+            cmd = self.user_config['cuda']['compiler'] + " --version 1> /dev/null"
+
+            if os.system(cmd) != 0:
+                Messages._erroror("CUDA is not available on your system. Please check the CUDA installation or the annarchy.json configuration.")
+
+            self.cuda_config['cuda_version'] = check_cuda_version(self.user_config['cuda']['compiler'])
+
+    def generate(self):
+        "Perform the code generation for the C++ code and create the Makefile."
+        if Profiler().enabled or get_global_config('show_time'):
+            t0 = time.time()
+            if Profiler().enabled:
+                Profiler().add_entry(t0, t0, "overall", "compile")
+
+        if get_global_config('verbose'):
+            net_str = "" if self.net_id == 0 else str(self.net_id)+" "
+            Messages._print('Code generation '+net_str+'...', end=" ", flush=True)
+
+        # Check that everything is allright in the structure of the network.
+        check_structure(self.populations, self.projections)
+
+        # check if the user access some new features, or old ones which changed.
+        check_experimental_features(self.populations, self.projections)
+
+        # Generate the code
+        self.code_generation()
+
+        # Generate the Makefile
+        self.generate_makefile()
+
+        # Copy the files if needed
+        changed = self.copy_files()
+
+        # Code generation done
+        if get_global_config('verbose'):
+            t1 = time.time()
+            if not get_global_config('show_time'):
+                Messages._print("OK", flush=True)
+            else:
+                Messages._print("OK (took "+str(t1-t0)+" seconds)", flush=True)
+
+        # Perform compilation if something has changed
+        if changed or not os.path.isfile(self.annarchy_dir + '/ANNarchyCore' + str(self.net_id) + '.so'):
+            self.compilation()
+
+        if get_global_config('debug') or get_global_config('disable_shared_library_time_offset'):
+            # In case of debugging or high-throughput simulations we want to
+            # disable the below trick
+            NetworkManager().set_code_directory(net_id=self.net_id, directory=self.annarchy_dir)
         else:
-            res = []
-            if isinstance(post, str):
-                post = self.get_population(post)
-            if isinstance(pre, str):
-                pre = self.get_population(pre)
-
-            for proj in self.projections:
-                if post is not None:
-                    # post is exclusionary
-                    if proj.post == post:
-                        res.append(proj)
-                
-                if pre is not None:
-                    raise NotImplementedError
-
-                if target is not None:
-                    raise NotImplementedError
-
-            return res
-
-    def load(self, filename, populations=True, projections=True, pickle_encoding=None):
-        """
-        Loads a saved state of the current network by calling ANNarchy.core.IO.load().
+            # Store the library in random subfolder
+            # We circumvent with this an issue with reloading of shared libraries
+            # see PEP 489: (https://www.python.org/dev/peps/pep-0489/) for more details
+            NetworkManager().set_code_directory(net_id=self.net_id, directory=self.annarchy_dir+'/run_'+str(time.time()))
+            os.mkdir(NetworkManager().get_code_directory(net_id=self.net_id))
+            shutil.copy(self.annarchy_dir+'/ANNarchyCore' + str(self.net_id) + '.so', NetworkManager().get_code_directory(net_id=self.net_id))
+
+        NetworkManager().set_compiled(net_id=self.net_id)
+        if Profiler().enabled:
+            t1 = time.time()
+            Profiler().update_entry(t0, t1, "overall", "compile")
+
+    def copy_files(self):
+        " Copy the generated files in the build/ folder if needed."
+        changed = False
+        if self.clean:
+            for file in os.listdir(self.annarchy_dir+'/generate/net'+ str(self.net_id)):
+                if file.endswith(".log"):
+                    continue
+
+                shutil.copy(self.annarchy_dir+'/generate/net'+ str(self.net_id) + '/' + file, # src
+                            self.annarchy_dir+'/build/net'+ str(self.net_id) + '/' + file # dest
+                           )
+            changed = True
+
+        else: # only the ones which have changed
+            import filecmp
+            for file in os.listdir(self.annarchy_dir+'/generate/net'+ str(self.net_id)):
+                if file.endswith(".log"):
+                    continue
+
+                if not os.path.isfile(self.annarchy_dir+'/build/net'+ str(self.net_id) + '/' + file) or \
+                    not file == "codegen.log" and \
+                    not filecmp.cmp(self.annarchy_dir+'/generate/net' + str(self.net_id) + '/' + file,
+                                    self.annarchy_dir+'/build/net'+ str(self.net_id) + '/' + file):
+
+
+                    shutil.copy(self.annarchy_dir+'/generate//net'+ str(self.net_id) + '/' + file, # src
+                                self.annarchy_dir+'/build/net'+ str(self.net_id) + '/' +file # dest
+                               )
+                    changed = True
+
+                    if get_global_config('verbose'):
+                        print(file, 'has changed')
+                        # For debugging
+                        # with open(self.annarchy_dir+'/generate/net'+ str(self.net_id) + '/' + file, 'r') as rfile:
+                        #     text = rfile.read()
+                        #     print(text)
+
+            # Needs to check now if a file existed before in build/net but not in generate anymore
+            for file in os.listdir(self.annarchy_dir+'/build/net'+ str(self.net_id)):
+                if file == 'Makefile':
+                    continue
+                if file.endswith(".log"):
+                    continue
+                basename, extension = os.path.splitext(file)
+                if not extension in ['h', 'hpp', 'cpp', 'cu']: # ex: .o
+                    continue
+                if not os.path.isfile(self.annarchy_dir+'/generate/net'+ str(self.net_id) + '/' + file):
+                    if file.startswith('ANNarchyCore'):
+                        continue
+                    os.remove(self.annarchy_dir+'/build/net'+ str(self.net_id) + '/' + file)
+                    if os.path.isfile(self.annarchy_dir+'/build/net'+ str(self.net_id) + '/' + basename + '.o'):
+                        os.remove(self.annarchy_dir+'/build/net'+ str(self.net_id) + '/' + basename + '.o')
+                    changed = True
+
+        return changed
+
+    def compilation(self):
+        """ Create ANNarchyCore.so and py extensions if something has changed. """
+        # STDOUT
+        if not self.silent:
+            if get_global_config('verbose'):
+                msg = 'Compiling with ' + self.compiler + ' ' + self.compiler_flags
+            else:
+                msg = 'Compiling '
+            if self.net_id > 0:
+                msg += 'network ' + str(self.net_id)
+            msg += '...'
+            Messages._print(msg, end=" ", flush=True)
+            if get_global_config('show_time') or Profiler().enabled:
+                t0 = time.time()
+
+        # Switch to the build directory
+        cwd = os.getcwd()
+        os.chdir(self.annarchy_dir + '/build/net'+ str(self.net_id))
+
+        # Start the compilation
+        verbose = "> compile_stdout.log 2> compile_stderr.log" if not get_global_config('verbose') else ""
+
+        # Start the compilation process
+        make_process = subprocess.Popen("make all -j4" + verbose, shell=True)
+
+        # Check for errors
+        if make_process.wait() != 0:
+            with open('compile_stderr.log', 'r') as rfile:
+                msg = rfile.read()
+            with open(self.annarchy_dir + '/compilation', 'w') as wfile:
+                wfile.write("0")
+            Messages._print(msg)
+            try:
+                os.remove('ANNarchyCore'+str(self.net_id)+'.so')
+            except:
+                pass
+            Messages._error('Compilation failed.')
+        else: # Note that the last compilation was successful
+            with open(self.annarchy_dir + '/compilation', 'w') as wfile:
+                wfile.write("1")
+
+        # Return to the current directory
+        os.chdir(cwd)
+
+        if not self.silent:
+            t1 = time.time()
+
+            if not get_global_config('show_time'):
+                Messages._print('OK')
+            else:
+                Messages._print('OK (took '+str(t1 - t0)+'seconds.')
+
+            if Profiler().enabled:
+                Profiler().add_entry(t0, t1, "compilation", "compile")
+
+    def generate_makefile(self):
+        """
+        Generate the Makefile.
+
+        The makefile consists of two stages compile the cython wrapper and
+        compile the ANNarchy model files. Both is then linked together to
+        a shared library usable in Python.
+        """
+        # Compiler
+        if self.compiler == "default":
+            self.compiler = self.user_config['openmp']['compiler']
+        if self.compiler_flags == "default":
+            self.compiler_flags = self.user_config['openmp']['flags']
+
+        # flags are common to all platforms
+        if not self.debug_build:
+            cpu_flags = self.compiler_flags
+        else:
+            cpu_flags = "-O0 -g -D_DEBUG -march=native"
 
-        :param filename: filename, may contain relative or absolute path.
-        :param populations: if True, population data will be saved (by default True)
-        :param projections: if True, projection data will be saved (by default True)
-        :param pickle_encoding: optional parameter provided to the pickle.load() method. If set to None the default is used.
+        if self.profile_enabled:
+            cpu_flags += " -g"
+            #extra_libs.append("-lpapi")
+
+        # OpenMP flag
+        omp_flag = ""
+        if get_global_config('paradigm') == "openmp" :
+            omp_flag = "-fopenmp"
+
+        # Disable openMP parallel RNG?
+        if get_global_config('disable_parallel_rng') and _check_paradigm("openmp"):
+            cpu_flags += " -D_DISABLE_PARALLEL_RNG "
+
+        # Disable auto-vectorization
+        if get_global_config('disable_SIMD_Eq') and _check_paradigm("openmp"):
+            cpu_flags += " -fno-tree-vectorize"
+
+        # Cuda Library and Compiler
+        #
+        # hdin (22.03.2016): we should verify in the future, if compute_35 remains as best
+        # configuration for Keplar and upwards.
+        cuda_gen = ""
+        gpu_flags = ""
+        gpu_compiler = "nvcc"
+        gpu_ldpath = ""
+        xcompiler_flags = ""
+        if sys.platform.startswith('linux') and get_global_config('paradigm') == "cuda":
+            cuda_gen = "" # TODO: -arch sm_%(ver)s
+
+            if self.debug_build:
+                gpu_flags = "-g -G -D_DEBUG"
+
+            # read the config file for the cuda lib path
+            if 'cuda' in self.user_config.keys():
+                gpu_compiler = self.user_config['cuda']['compiler']
+                gpu_ldpath = '-L' + self.user_config['cuda']['path'] + '/lib'
+                gpu_flags += self.user_config['cuda']['flags']
+
+            # -Xcompiler expects the arguments seperated by ','
+            if len(cpu_flags.strip()) > 0:
+                xcompiler_flags = cpu_flags.replace(" ",",")
+                xcompiler_flags += ","
+
+        # Extra libs from extensions such as opencv
+        libs = self.extra_libs
+        for lib in extra_libs:
+            libs += str(lib) + ' '
+
+        # Python environment
+        py_version, py_major, python_include, python_lib, python_libpath, cython = python_environment()
+
+        # Include path to Numpy is not standard on all distributions
+        numpy_include = np.get_include()
+
+        # ANNarchy default header: sparse matrix formats
+        annarchy_include = ANNarchy.__path__[0]+'/include'
+
+        # Thirdparty includes (C++ files)
+        thirdparty_include = ANNarchy.__path__[0]+'/thirdparty'
+
+        # The connector module needs to reload some header files,
+        # ANNarchy.__path__ provides the installation directory
+        path_to_cython_ext = "-I "+ANNarchy.__path__[0]+'/core/cython_ext/ -I '+ANNarchy.__path__[0][:-8]
+
+
+        # Create Makefiles depending on the target platform and parallel framework
+        if sys.platform.startswith('linux'): # Linux systems
+            if get_global_config('paradigm') == "cuda":
+                makefile_template = linux_cuda_template
+            else:
+                makefile_template = linux_omp_template
+
+        elif sys.platform == "darwin":   # mac os
+            if self.compiler == 'clang++':
+                makefile_template = osx_clang_template
+                if get_global_config('num_threads') == 1: # clang should report that it does not support openmp
+                    omp_flag = ""
+            else:
+                makefile_template = osx_gcc_template
+
+        else: 
+            # Windows: to test....
+            Messages._warning("Compilation on windows is not supported yet. We recommend to use WSL on windows systems.")
+
+        # Gather all Makefile flags
+        makefile_flags = {
+            'compiler': self.compiler,
+            'add_sources': self.add_sources,
+            'cpu_flags': cpu_flags,
+            'cuda_gen': cuda_gen,
+            'gpu_compiler': gpu_compiler,
+            'gpu_flags': gpu_flags,
+            'xcompiler_flags': xcompiler_flags,
+            'gpu_ldpath': gpu_ldpath,
+            'openmp': omp_flag,
+            'extra_libs': libs,
+            'py_version': py_version,
+            'py_major': py_major,
+            'cython': cython,
+            'python_include': python_include,
+            'python_lib': python_lib,
+            'python_libpath': python_libpath,
+            'numpy_include': numpy_include,
+            'annarchy_include': annarchy_include,
+            'thirdparty_include': thirdparty_include,
+            'net_id': self.net_id,
+            'cython_ext': path_to_cython_ext
+        }
+
+        # Write the Makefile to the disk
+        with open(self.annarchy_dir + '/generate/net'+ str(self.net_id) + '/Makefile', 'w') as wfile:
+            wfile.write(makefile_template % makefile_flags)
+
+
+    def code_generation(self):
         """
-        IO.load(filename=filename, populations=populations, projections=projections, pickle_encoding=pickle_encoding, net_id=self.id)
-
-    def save(self, filename, populations=True, projections=True):
+        Code generation dependent on paradigm
         """
-        Saves the current network by calling ANNarchy.core.IO.save().
+        generator = CodeGenerator(self.annarchy_dir, self.populations, self.projections, self.net_id, self.cuda_config)
+        generator.generate()
 
-        :param filename: filename, may contain relative or absolute path.
-        :param populations: if True, population data will be saved (by default True)
-        :param projections: if True, projection data will be saved (by default True)
-        """
-        IO.save(filename, populations, projections, self.id)
 
-def parallel_run(
-        method, 
-        networks=None, 
-        number=0, 
-        max_processes=-1, 
-        measure_time=False, 
-        sequential=False, 
-        same_seed=False, 
-        annarchy_json="", 
-        visible_cores=[], 
-        **args):
+def load_cython_lib(libname, libpath):
     """
-    Allows to run multiple networks in parallel using multiprocessing.
-
-    If the ``networks`` argument is provided as a list of Network objects, the given method will be executed for each of these networks.
+    Load the shared library created by Cython using importlib. Follows the example
+    "Multiple modules in one library" in PEP 489.
 
-    If ``number`` is given instead, the same number of networks will be created and the method is applied.
+    TODO:
 
-    If ``number`` is used, the created networks are not returned, you should return what you need to analyse.
+    As described in PEP 489 "Module Reloading" a reloading of dynamic extension modules is
+    not supported. This leads to some problems for our reusage of the ANNarchyCore library ...
 
-    Example:
-
-    ```python
-    pop1 = PoissonPopulation(100, rates=10.0)
-    pop2 = Population(100, Izhikevich)
-    proj = Projection(pop1, pop2, 'exc')
-    proj.connect_fixed_probability(weights=5.0, probability=0.2)
-    m = Monitor(pop2, 'spike')
-
-    compile()
-
-    def simulation(idx, net):
-        net.get(pop1).rates = 10. * idx
-        net.simulate(1000.)
-        return net.get(m).raster_plot()
-
-    results = parallel_run(method=simulation, number = 3)
-
-    t1, n1 = results[0]
-    t2, n2 = results[1]
-    t3, n3 = results[2]
-    ```
+    Sources:
 
+    PEP 489: (https://www.python.org/dev/peps/pep-0489/)
+    """
+    # create a loader to mimic find module
+    loader = importlib.machinery.ExtensionFileLoader(libname, libpath)
+    spec = importlib.util.spec_from_loader(libname, loader)
+    module = importlib.util.module_from_spec(spec)
+
+    if get_global_config('verbose'):
+        Messages._print('Loading library...', libname, libpath)
+
+    loader.exec_module(module)
+
+    if get_global_config('verbose'):
+        Messages._print('Library loaded.')
+
+    return module
+
+def _instantiate(net_id, import_id=-1, cuda_config=None, user_config=None, core_list=None):
+    """ After every is compiled, actually create the Cython objects and
+        bind them to the Python ones."""
+    if Profiler().enabled:
+        t0 = time.time()
+        Profiler().add_entry(t0, t0, "overall", "instantiate") # placeholder, to have the correct ordering
+
+    # parallel_run(number=x) defines multiple networks (net_id) but only network0 is compiled
+    if import_id < 0:
+        import_id = net_id
+
+    # subdirectory where the library lies
+    annarchy_dir = NetworkManager().get_code_directory(net_id=import_id)
+    libname = 'ANNarchyCore' + str(import_id)
+    libpath = annarchy_dir + '/' + libname + '.so'
+
+    cython_module = load_cython_lib(libname, libpath)
+    NetworkManager().set_cy_instance(net_id=net_id, instance=cython_module)
+
+    # Set the CUDA device
+    if _check_paradigm("cuda"):
+        device = 0
+        if cuda_config:
+            device = int(cuda_config['device'])
+        elif 'cuda' in user_config['cuda']:
+            device = int(user_config['cuda']['device'])
+
+        if get_global_config('verbose'):
+            Messages._print('Setting GPU device', device)
+        cython_module.set_device(device)
+
+    # Sets the desired number of threads and execute thread placement.
+    # This must be done before any other objects are initialized.
+    if _check_paradigm("openmp"):
+        # check for global setting
+        if core_list is None:
+            core_list = get_global_config('visible_cores')
+
+        # the user configured a setup
+        if core_list != []:
+            # some sanity check
+            if len(core_list) > multiprocessing.cpu_count():
+                Messages._error("The length of core ids provided to setup() is larger than available number of cores")
+
+            if len(core_list) < get_global_config('num_threads'):
+                Messages._error("The list of visible cores should be at least the number of cores.")
 
-    :param method: a Python method which will be executed for each network. This function must accept an integer as first argument (id of the simulation) and a Network object as second argument.
-    :param networks: a list of networks to simulate in parallel.
-    :param number: the number of identical networks to run in parallel.
-    :param max_processes: maximal number of processes to start concurrently (default: the available number of cores on the machine).
-    :param measure_time: if the total simulation time should be printed out.
-    :param sequential: if True, runs the simulations sequentially instead of in parallel (default: False).
-    :param same_seed: if True, all networks will use the same seed. If not, the seed will be randomly initialized with time(0) for each network (default). It has no influence when the ``networks`` argument is set (the seed has to be set individually for each network using ``net.set_seed()``), only when ``number`` is used.
-    :param annarchy_json: path to a different configuration file if needed (default "").
-    :param visible_cores: a list of CPU core ids to simulate on (must have max_processes entries and max_processes must be != -1)
-    :param args: other named arguments you want to pass to the simulation method.
-    :returns: a list of the values returned by ``method``.
+            if np.amax(np.array(core_list)) > multiprocessing.cpu_count():
+                Messages._error("At least one of the core ids provided to setup() is larger than available number of cores")
 
-    """
-    # Check inputs
-    if not networks and number < 1:
-        Global._error('parallel_run(): the networks or number arguments must be set.', exit=True)
-
-    if len(visible_cores) > 0 and max_processes == -1:
-        Global._error('parallel_run(): when using visible cores the number of max_processes must be set.', exit=True)
-
-    if (len(visible_cores) > 0) and (len(visible_cores) != max_processes):
-        Global._error('parallel_run(): the number of entries in visible_cores must be equal to max_processes.', exit=True)
-
-    import types
-    if not isinstance(method, types.FunctionType):
-        Global._error('parallel_run(): the method argument must be a method.', exit=True)
-
-    if not networks: # The magic network will run N times
-        return _parallel_multi(method, number, max_processes, measure_time, sequential, same_seed, annarchy_json, visible_cores, args)
-
-    if not isinstance(networks, list):
-        Global._error('parallel_run(): the networks argument must be a list.', exit=True)
-
-    # Simulate the different networks
-    return _parallel_networks(method, networks, max_processes, measure_time, sequential, args)
-
-
-def _parallel_networks(method, networks, max_processes, measure_time, sequential, args):
-    " Method when different networks are provided"
-    import multiprocessing
-    from multiprocessing import Pool
-
-    # Time measurement
-    from time import time
-    if measure_time:
-        ts = time()
-
-    # Number of processes to create depends on number of
-    # available CPUs or GPUs
-    if max_processes < 0:
-        if Global.config['paradigm'] == "openmp":
-            max_processes = min(len(networks), multiprocessing.cpu_count())
-        elif Global.config['paradigm'] == "cuda":
-            Global._warning("In the present ANNarchy version the usage of parallel networks and multi-GPUs is disabled.")
-            max_processes = 1
-        else:
-            raise NotImplementedError
+            if len(core_list) != len(list(set(core_list))):
+                Messages._warning("The provided core list contains doubled entries - is this intended?")
 
-    # Number of networks
-    number = len(networks)
+            cython_module.set_number_threads(get_global_config('num_threads'), core_list)
 
-    # Build arguments list
-    arguments = [[method, n, networks[n]] for n in range(number)]
-    if len(args) != method.__code__.co_argcount-2:  # idx, net are default
-        Global._error('the method', method.__name__, 'takes', method.__code__.co_argcount-2,
-                      'arguments (in addition to idx and net) which have to be passed to parallel_run:', method.__code__.co_varnames[2:method.__code__.co_argcount])
-    for arg in range(2, method.__code__.co_argcount):
-        varname = method.__code__.co_varnames[arg]
-        data = args[varname]
-        if not len(data) == number:
-            Global._error('parallel_run(): the argument', varname, 'must be a list of values for each of the', number, 'networks.')
-        for n in range(number):
-            arguments[n].append(data[n])
-
-    # Simulation
-    if not sequential:
-        pool = Pool(max_processes)
-        try:
-            results = pool.map(_only_run_method, arguments)
-        except Exception as e:
-            Global._print(e)
-            Global._error('parallel_run(): running multiple networks failed.', exit=True)
-        pool.close()
-        pool.join()
-    else:
-        results = []
-        for idx, net in enumerate(networks):
-            try:
-                results.append(method(*arguments[idx][1:]))
-            except Exception as e:
-                Global._print(e)
-                Global._error('parallel_run(): running network ' + str(net.id) + ' failed.', exit=True)
-
-    # Time measurement
-    if measure_time:
-        msg = 'Running ' + str(len(networks)) + ' networks'
-        if not sequential:
-            msg += ' in parallel '
         else:
-            msg += ' sequentially '
-        msg += 'took: ' + str(time()-ts)
-        Global._print(msg)
-
-    return results
-
-
-def _parallel_multi(method, number, max_processes, measure_time, sequential, same_seed, annarchy_json, visible_cores, args):
-    "Method when the same network must be simulated multiple times."
-    import multiprocessing
-    from multiprocessing import Pool
-
-    # Time measurement
-    from time import time
-    if measure_time:
-        ts = time()
-
-    # Make sure the magic network is compiled
-    if not Global._network[0]['compiled']:
-        Global._warning('parallel_run(): the network is not compiled yet, doing it now...')
-        Compiler.compile(annarchy_json=annarchy_json)
-
-    # Number of processes to create
-    if max_processes < 0:
-        if Global.config['paradigm'] == "openmp":
-            max_processes = min(number, multiprocessing.cpu_count())
-        elif Global.config['paradigm'] == "cuda":
-            Global._warning("In the present ANNarchy version the usage of parallel networks and multi-GPUs is disabled.")
-            max_processes = 1
+            # HD (26th Oct 2020): the current version of psutil only consider one CPU socket
+            #                     but there is a discussion of adding multi-sockets, so we could
+            #                     re-add this code later ...
+            """
+            num_cores = psutil.cpu_count(logical=False)
+            # Check if the number of threads make sense
+            if num_cores < get_global_config('num_threads'):
+                Messages._warning("The number of threads =", get_global_config('num_threads'), "exceeds the number of available physical cores =", num_cores)
+
+            # ANNarchy should run only on physical cpu cores
+            core_list = np.arange(0, num_cores)
+            """
+            cython_module.set_number_threads(get_global_config('num_threads'), [])
+
+        if get_global_config('num_threads') > 1:
+            if get_global_config('verbose'):
+                Messages._print('Running simulation with', get_global_config('num_threads'), 'threads.')
         else:
-            raise NotImplementedError
-
-    # Seed
-    if same_seed and Global.config['seed'] > -1: # use the global seed
-        seed =  Global.config['seed']
-    else: # draw it everytime with time(0)
-        seed = np.random.get_state()[1][0]
-
-    # Build arguments list for each instance with the following structure:
-    # [ net_id, arguments for method, seed ]
-    arguments = [[n, method] for n in range(number)]
-    if len(args) != method.__code__.co_argcount-2:  # idx, net are default
-        Global._error('the method', method.__name__, 'takes', method.__code__.co_argcount-2,
-                      'arguments (in addition to idx and net) which have to be passed to parallel_run:', method.__code__.co_varnames[2:method.__code__.co_argcount])
-    for arg in range(2, method.__code__.co_argcount):
-        varname = method.__code__.co_varnames[arg]
-        data = args[varname]
-        if not len(data) == number:
-            Global._error('parallel_run(): the argument', varname, 'must be a list of values for each of the', number, 'networks.')
-        for n in range(number):
-            arguments[n].append(data[n])
-    for n in range(number): # Add the seed at the end. Increment the seed if the seeds should be different
-        arguments[n].append(seed + n if not same_seed else 0)
-
-    # Thread placement is optional
-    if len(visible_cores) == 0:
-        for n in range(number):
-            arguments[n].append([])
-    else:
-        for n in range(number):
-            arguments[n].append([visible_cores[np.mod(n,max_processes)]])
+            if get_global_config('verbose'):
+                Messages._print('Running simulation single-threaded.')
 
-    # Simulation
-    if not sequential and len(visible_cores) == 0:
-        try:
-            pool = Pool(max_processes)
-            results = pool.map(_create_and_run_method, arguments)
-            pool.close()
-            pool.join()
-        except Exception as e:
-            Global._print(e)
-            Global._error('parallel_run(): running ' + str(number) + ' networks failed.', exit=True)
-
-    elif not sequential and len(visible_cores) > 0:
-        # Thread placement requires some more fine-grained control
-        # on the execution
+    # Sets the desired computation device for CUDA
+    if _check_paradigm("cuda") and (user_config!=None):
+        # check if there is a configuration,
+        # otherwise fall back to default device
         try:
-            n_iter = int(np.ceil(number / max_processes))
-            pool = Pool(max_processes)
-            for idx in range(n_iter):
-                beg = int(idx * max_processes)
-                end = int(min((idx+1) * max_processes, number))
-                results = pool.map(_create_and_run_method, arguments[beg:end])
-            pool.close()
-            pool.join()
-        except Exception as e:
-            Global._print(e)
-            Global._error('parallel_run(): running ' + str(number) + ' networks failed.', exit=True)
-
+            dev_id = int(user_config['cuda']['device'])
+        except KeyError:
+            dev_id = 0
+
+        cython_module.set_device(dev_id)
+
+    # Instantiate CPP objects
+    cython_module.pyx_create()
+
+    # Configure seeds for random number generators
+    # Required for state updates and also (in future) construction of connectivity
+    if get_global_config('seed') == -1:
+        seed = time.time()
     else:
-        results = []
-        try:
-            for n in range(number):
-                results.append(_create_and_run_method(arguments[0]))
-        except Exception as e:
-            Global._print(e)
-            Global._error('parallel_run(): running ' + str(number) + ' networks failed.', exit=True)
-
-    # Time measurement
-    if measure_time:
-        msg = 'Running ' + str(number) + ' networks'
-        if not sequential:
-            msg += ' in parallel '
-        else:
-            msg += ' sequentially '
-        msg += 'took: ' + str(time()-ts)
-        Global._print(msg)
-
-    return results
+        seed = get_global_config('seed')
 
+    if not get_global_config('disable_parallel_rng'):
+        cython_module.set_seed(seed, get_global_config('num_threads'), get_global_config('use_seed_seq'))
+    else:
+        cython_module.set_seed(seed, 1, get_global_config('use_seed_seq'))
 
-def _create_and_run_method(args):
-    """
-    Method called to wrap the user-defined method when different networks are created.
-    """
-    # Get arguments
-    n = args[0]
-    method = args[1]
-    visible_cores = args[-1]
-    seed = args[-2]
-    # Create and instantiate the network 0, not compile it!
-    net = Network(True)
-    Compiler._instantiate(net_id=net.id, import_id=0, core_list=visible_cores)
-    # Set the seed
-    net.set_seed(seed)
-    # Create the arguments
-    arguments = args[:-2] # all arguments except seed and visible_cores
-    arguments[1] = net # replace the second argument method with net
-    # Call the method
-    res = method(*arguments)
-    del net
-    return res
-
+    # Bind the py extensions to the corresponding python objects
+    for pop in NetworkManager().get_populations(net_id=net_id):
+        if get_global_config('verbose'):
+            Messages._print('Creating population', pop.name)
+        if get_global_config('show_time'):
+            t0 = time.time()
+
+        # Instantiate the population
+        pop._instantiate(cython_module)
+
+        if get_global_config('show_time'):
+            Messages._print('Creating', pop.name, 'took', (time.time()-t0)*1000, 'milliseconds')
+
+    # Instantiate projections
+    for proj in NetworkManager().get_projections(net_id=net_id):
+        if get_global_config('verbose'):
+            Messages._print('Creating projection from', proj.pre.name, 'to', proj.post.name, 'with target="', proj.target, '"')
+        if get_global_config('show_time'):
+            t0 = time.time()
+
+        # Create the projection
+        proj._instantiate(cython_module)
+
+        if get_global_config('show_time'):
+            Messages._print('Creating the projection took', (time.time()-t0)*1000, 'milliseconds')
+
+    # Finish to initialize the network
+    cython_module.pyx_initialize(get_global_config('dt'))
+
+    # Set the user-defined constants
+    for obj in GlobalObjectManager().get_constants():
+        getattr(cython_module, '_set_'+obj.name)(obj.value)
+
+    # Transfer initial values
+    for pop in NetworkManager().get_populations(net_id=net_id):
+        if get_global_config('verbose'):
+            Messages._print('Initializing population', pop.name)
+        pop._init_attributes()
+    for proj in NetworkManager().get_projections(net_id=net_id):
+        if get_global_config('verbose'):
+            Messages._print('Initializing projection', proj.name, 'from', proj.pre.name, 'to', proj.post.name, 'with target="', proj.target, '"')
+        proj._init_attributes()
+
+    # Start the monitors
+    for monitor in NetworkManager().get_monitors(net_id=net_id):
+        monitor._init_monitoring()
+
+    if Profiler().enabled:
+        t1 = time.time()
+        Profiler().update_entry(t0, t1, "overall", "instantiate")
 
-def _only_run_method(args):
-    """
-    Method called to wrap the user-defined method when a single network is already instantiated.
-    """
-    method = args[0]
-    arguments = args[1:]
-    res = method(*arguments)
-    return res
+        # register the CPP profiling instance
+        Profiler()._cpp_profiler = NetworkManager().cy_instance(net_id=net_id).Profiling_wrapper()
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/Neuron.py` & `annarchy-4.8.0.1/ANNarchy/core/Neuron.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,38 +1,38 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-from ANNarchy.core.Global import _error, _warning, _objects, config
 from ANNarchy.parser.AnalyseNeuron import analyse_neuron
 from ANNarchy.core.PopulationView import PopulationView
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern.GlobalObjects import GlobalObjectManager
+from ANNarchy.intern import Messages
 import numpy as np
 
 class Neuron :
     """
     Base class to define a neuron.
+
+    :param parameters: parameters of the neuron and their initial value.
+    :param equations: equations defining the temporal evolution of variables.
+    :param functions: additional functions used in the variables' equations.
+    :param spike: condition to emit a spike (only for spiking neurons).
+    :param axon_spike: condition to emit an axonal spike (only for spiking neurons and optional). The axonal spike can appear additional to the spike and is independent from refractoriness of a neuron.
+    :param reset: changes to the variables after a spike (only for spiking neurons).
+    :param axon_reset: changes to the variables after an axonal spike (only for spiking neurons).
+    :param refractory: refractory period of a neuron after a spike (only for spiking neurons).
+    :param name: name of the neuron type (used for reporting only).
+    :param description: short description of the neuron type (used for reporting).
     """
     # Default name and description for reporting
     _default_names = {'rate': "Rate-coded neuron", 'spike': "Spiking neuron"}
 
-    def __init__(self, parameters="", equations="", spike=None, axon_spike=None, reset=None, axon_reset=None, refractory = None, functions=None, name="", description="", extra_values={} ):
-        """
-        :param parameters: parameters of the neuron and their initial value.
-        :param equations: equations defining the temporal evolution of variables.
-        :param functions: additional functions used in the variables' equations.
-        :param spike: condition to emit a spike (only for spiking neurons).
-        :param axon_spike: condition to emit an axonal spike (only for spiking neurons and optional). The axonal spike can appear additional to the spike and is independent from refractoriness of a neuron.
-        :param reset: changes to the variables after a spike (only for spiking neurons).
-        :param axon_reset: changes to the variables after an axonal spike (only for spiking neurons).
-        :param refractory: refractory period of a neuron after a spike (only for spiking neurons).
-        :param name: name of the neuron type (used for reporting only).
-        :param description: short description of the neuron type (used for reporting).
-
-        """
+    def __init__(self, parameters:str="", equations:str="", spike:str=None, axon_spike:str=None, reset:str=None, axon_reset:str=None, refractory:str = None, functions:str=None, name:str="", description:str="", extra_values:dict={} ):
 
         # Store the parameters and equations
         self.parameters = parameters
         self.equations = equations
         self.functions = functions
         self.spike = spike
         self.axon_spike = axon_spike
@@ -41,23 +41,23 @@
         self.refractory = refractory
         self.extra_values = extra_values
 
         # Find the type of the neuron
         self.type = 'spike' if self.spike else 'rate'
 
         # Not available by now ...
-        if axon_spike and config['paradigm'] != "openmp":
-            _error("Axonal spike conditions are only available for openMP by now.")
+        if axon_spike and get_global_config('paradigm') != "openmp":
+            Messages._error("Axonal spike conditions are only available for openMP by now.")
 
         # Reporting
         if not hasattr(self, '_instantiated') : # User-defined
-            _objects['neurons'].append(self)
+            GlobalObjectManager().add_neuron_type(self)
         elif len(self._instantiated) == 0: # First instantiated of the class
-            _objects['neurons'].append(self)
-        self._rk_neurons_type = len(_objects['neurons'])
+            GlobalObjectManager().add_neuron_type(self)
+        self._rk_neurons_type = GlobalObjectManager().num_neuron_types()
 
         if name:
             self.name = name
         else:
             self.name = self._default_names[self.type]
 
         if description:
@@ -170,9 +170,9 @@
         """Allows to join two neurons if they have the same population."""
         if other.population == self.population:
             if isinstance(other, IndividualNeuron):
                 return PopulationView(self.population, list(set([self.rank, other.rank])))
             elif isinstance(other, PopulationView):
                 return PopulationView(self.population, list(set([self.rank] + other.ranks)))
         else:
-            _error("can only add two PopulationViews of the same population.")
+            Messages._error("can only add two PopulationViews of the same population.")
             return None
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/Population.py` & `annarchy-4.8.0.1/ANNarchy/core/Population.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,54 +1,74 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-import ANNarchy.core.Global as Global
+from ANNarchy.core.Constant import Constant
+from ANNarchy.intern.NetworkManager import NetworkManager
+from ANNarchy.intern.Profiler import Profiler
+from ANNarchy.intern.ConfigManagement import get_global_config, _check_paradigm
+from ANNarchy.intern import Messages
 
 from .PopulationView import PopulationView
 from .Random import RandomDistribution
-from .Neuron import IndividualNeuron
+from .Neuron import Neuron, IndividualNeuron
 
 import numpy as np
 import copy, inspect
 
 
 class Population :
     """
-    Container for a population of homogeneous neurons.
-    """
+    Structure for a population of homogeneous neurons.
 
-    def __init__(self, geometry, neuron, name=None, stop_condition=None, storage_order='post_to_pre', copied=False):
-        """
-        :param geometry: population geometry as tuple. If an integer is given, it is the size of the population.
-        :param neuron: instance of ``ANNarchy.Neuron``. It can be user-defined or a built-in model.
-        :param name: unique name of the population (optional, it defaults to ``pop0``, ``pop1``, etc).
-        :param stop_condition: a single condition on a neural variable which can stop the simulation whenever it is true.
+    Example:
 
-        Example:
+    ```python
+    pop = ann.Population(100, neuron=ann.Izhikevich, name="Excitatory population")
+    ```
+    
+    :param geometry: population geometry as tuple. If an integer is given, it is the size of the population.
+    :param neuron: `Neuron`instance. It can be user-defined or a built-in model.
+    :param name: unique name of the population (optional, it defaults to `pop0`, `pop1`, etc).
+    :param stop_condition: a single condition on a neural variable which can stop the simulation whenever it is true.
+    """
 
-        ```python
-        pop = Population(100, neuron=Izhikevich, name="Excitatory population")
-        ```
+    def __init__(self, 
+                 geometry: tuple | int, 
+                 neuron: "Neuron", 
+                 name:str = None, 
+                 stop_condition:str = None, 
+                 storage_order:str = 'post_to_pre', 
+                 copied = False):
 
-        """
         # Check if the network has already been compiled
-        if Global._network[0]['compiled'] and not copied:
-            Global._error('You cannot add a population after the network has been compiled.')
+        if NetworkManager().is_compiled(net_id=0) and not copied:
+            Messages._error('You cannot add a population after the network has been compiled.')
+
+        # Store the provided geometry. Automatically defines w, h, d, size
+        self.geometry = geometry
+        "Geometry of the population."
+        self.width = 0
+        "Width of the population."
+        self.height = 0
+        "Height of the population."
+        self.depth = 0
+        "Depth of the population."
+        self.dimension = 0
+        "Number of dimensions of the population."
 
-        # Store the provided geometry
-        # automatically defines w, h, d, size
         if isinstance(geometry, (int, float)):
             # 1D
             self.geometry = (int(geometry), )
             self.width = int(geometry)
             self.height = int(1)
             self.depth = int(1)
             self.dimension = int(1)
+
         elif isinstance(geometry, tuple):
             # a tuple is given, can be 1 .. N dimensional
             self.geometry = ()
             for d in geometry:
                 self.geometry += (int(d),)
             self.width = int(geometry[0])
             if len(geometry)>=2:
@@ -58,66 +78,74 @@
             if len(geometry)>=3:
                 self.depth = int(geometry[2])
             else:
                 self.depth = int(1)
 
             self.dimension = len(geometry)
         else:
-            Global._error('Population(): the geometry must be either an integer or a tuple.')
+            Messages._error('Population(): the geometry must be either an integer or a tuple.')
 
         # Compute the size
         size = int(1)
         for i in range(len(self.geometry)):
             size *= int(self.geometry[i])
         self.size = int(size)
+        "Size of the population."
         self.ranks = np.arange(self.size, dtype="int32")
+        "Array of ranks in the population (between 0 and `size - 1`)."
 
         # Store the neuron type
         if inspect.isclass(neuron):
             self.neuron_type = neuron()
         else:
             self.neuron_type = copy.deepcopy(neuron)
         self.neuron_type._analyse()
 
         # Store the stop condition
         self.stop_condition = stop_condition
 
         # Attribute a name if not provided
-        self.id = len(Global._network[0]['populations'])
+        self.id = NetworkManager().number_populations(net_id=0)
         self.class_name = 'pop'+str(self.id)
 
         if name:
             self.name = name
+            "Name of the population"
         else:
             self.name = self.class_name
 
         # Add the population to the global variable
-        Global._network[0]['populations'].append(self)
+        NetworkManager().add_population(0, self)
 
         # Get a list of parameters and variables
         self.parameters = []
+        "List of parameter names."
         self.variables = []
+        "List of variable names."
         for param in self.neuron_type.description['parameters']:
             self.parameters.append(param['name'])
         for var in self.neuron_type.description['variables']:
             self.variables.append(var['name'])
         self.attributes = self.parameters + self.variables
+        "List of attribute names."
 
         # Get a list of user-defined functions
         self.functions = [func['name'] for func in self.neuron_type.description['functions']]
+        "List of declared functions."
 
         # Store initial values
         self.init = {}
         for param in self.neuron_type.description['parameters']:
             self.init[param['name']] = param['init']
         for var in self.neuron_type.description['variables']:
             self.init[var['name']] = var['init']
 
         # List of targets actually connected
         self.targets = []
+        "List of connected targets."
 
         # List of global operations needed by connected projections
         self.global_operations = []
 
         # Maximum delay of connected projections
         self.max_delay = 0
 
@@ -127,15 +155,15 @@
         # Finalize initialization
         self.initialized = False
         self.cyInstance = None
         self.enabled = True
 
         # Rank <-> Coordinates methods
         # for the one till three dimensional case we use cython optimized functions.
-        from ANNarchy.core.cython_ext import Coordinates
+        from ANNarchy.cython_ext import Coordinates
         if self.dimension==1:
             self._rank_from_coord = Coordinates.get_rank_from_1d_coord
             self._coord_from_rank = Coordinates.get_1d_coord
         elif self.dimension==2:
             self._rank_from_coord = Coordinates.get_rank_from_2d_coord
             self._coord_from_rank = Coordinates.get_2d_coord
         elif self.dimension==3:
@@ -169,37 +197,37 @@
         pass
 
     def _instantiate(self, module):
         """
         Instantiates the population after compilation of the C++ simulation core.
         The function should solely called by Compiler._instantiate().
 
-        :param:     module  cython module (ANNarchyCore instance)
+        :param module: cython module (ANNarchyCore instance)
         """
-        if Global.config["profiling"]:
+        if Profiler().enabled:
             import time
             t1 = time.time()
 
         try:
             self.cyInstance = getattr(module, self.class_name+'_wrapper')(self.size, self.max_delay)
         except:
-            Global._error('unable to instantiate the population', self.name)
+            Messages._error('unable to instantiate the population', self.name)
 
-        if Global.config["profiling"]:
+        if Profiler().enabled:
             t2 = time.time()
-            Global._profiler.add_entry(t1, t2, "pop"+str(self.id), "instantiate")
+            Profiler().add_entry(t1, t2, "pop"+str(self.id), "instantiate")
 
     def _init_attributes(self):
         """ Method used after compilation to initialize the attributes."""
         # Initialize the population
         self.initialized = True
 
         # Transfer the initial values of all attributes
         for name, value in self.init.items():
-            if isinstance(value, Global.Constant):
+            if isinstance(value, Constant):
                 self.__setattr__(name, value.value)
             else:
                 self.__setattr__(name, value)
 
 
         # Activate the population
         self.cyInstance.activate(self.enabled)
@@ -212,17 +240,19 @@
             if not isinstance(self.neuron_type.description['refractory'], str): # the variable will be used directly
                 self.refractory = self.neuron_type.description['refractory']
 
         # Spiking neurons can compute a mean FR
         if self.neuron_type.type == 'spike':
             getattr(self.cyInstance, 'compute_firing_rate')(self._compute_mean_fr)
 
-    def size_in_bytes(self):
+    def size_in_bytes(self) -> int:
         """
-        Returns the size of allocated memory on the C++ side. Please note that this does not contain monitored data and works only if compile() was invoked.
+        Returns the size of allocated memory on the C++ side. Please note that this does not contain monitored data and works only if compile() has been invoked.
+
+        :returns: Size.
         """
         if self.initialized:
             return self.cyInstance.size_in_bytes()
         else:
             return 0
 
     def _clear(self):
@@ -231,76 +261,81 @@
 
         Warning: should be only called by the net deconstruction ( in context of parallel_run() ).
         """
         if self.initialized:
             self.cyInstance.clear()
             self.initialized = False
 
-    def reset(self, attributes=-1):
+    def reset(self, attributes:list = None)  -> None:
         """
         Resets all parameters and variables of the population to the value they had before the call to compile().
 
         :param attributes: list of attributes (parameter or variable) which should be reinitialized. Default: all attributes.
         """
-        if attributes == -1:
+        if attributes is None:
             try:
                 self.set(self.init)
             except Exception as e:
-                Global._print(e)
-                Global._error("Population.reset(): something went wrong while resetting.")
+                Messages._print(e)
+                Messages._error("Population.reset(): something went wrong while resetting.")
         else: # only some of them
             for var in attributes:
                 # check it exists
                 if not var in self.attributes:
-                    Global._warning("Population.reset():", var, "is not an attribute of the population, skipping.")
+                    Messages._warning("Population.reset():", var, "is not an attribute of the population, skipping.")
                     continue
 
                 try:
                     self.__setattr__(var, self.init[var])
                 except Exception as e:
-                    Global._print(e)
-                    Global._warning("Population.reset(): something went wrong while resetting", var)
+                    Messages._print(e)
+                    Messages._warning("Population.reset(): something went wrong while resetting", var)
 
         self.cyInstance.activate(self.enabled)
         self.cyInstance.reset()
 
-    def clear(self):
+    def clear(self) -> None:
         """
         Clears all spiking events previously emitted (history of spikes, delayed spikes).
 
         Can be useful if you do not want to totally reset a population (i.e. all variables), only to clear the spiking history between two trials.
 
         Note: does nothing for rate-coded networks.
         """
         self.cyInstance.reset()
 
-    def enable(self):
+    def enable(self) -> None:
         """
-        (Re)-enables computations in this population, after they were disabled by the ``disable()`` method.
+        (Re)-enables computations in this population, after they were disabled by the `disable()` method.
 
-        The status of the population is accessible through the ``enabled`` flag.
+        The status of the population is accessible through the `enabled` flag.
         """
         if self.initialized:
             self.cyInstance.activate(True)
         self.enabled = True
 
-    def disable(self):
+    def disable(self) -> None:
         """
         Temporarily disables computations in this population (including the projections leading to it).
 
-        You can re-enable it with the ``enable()`` method.
+        You can re-enable it with the `enable()` method.
         """
         if self.initialized:
             self.cyInstance.activate(False)
         self.enabled = False
 
     def __getattr__(self, name):
         # Method called when accessing an attribute.
         if name == 'initialized' or not hasattr(self, 'initialized'): # Before the end of the constructor
             return object.__getattribute__(self, name)
+        elif name == 'spike':
+            if not self.initialized:
+                Messages._error("Accessing spike events is only valid after compile()")
+            else:
+                return self._get_cython_attribute(name)
         elif hasattr(self, 'attributes'):
             if name in self.attributes:
                 if self.initialized: # access after compile()
                     return self._get_cython_attribute(name)
                 else: # access before compile()
                     if name in self.neuron_type.description['local']:
                         if isinstance(self.init[name], np.ndarray):
@@ -335,86 +370,86 @@
 
     def _get_cython_attribute(self, attribute):
         """
         Returns the value of the given attribute for all neurons in the population,
         as a Numpy array having the same geometry as the population if it is local.
 
         :param attribute: should be a string representing the variables's name.
-
         """
         try:
-            ctype = self._get_attribute_cpp_type(attribute)
-            if attribute in self.neuron_type.description['local']:
-                data = self.cyInstance.get_local_attribute_all(attribute, ctype)
-                return data.reshape(self.geometry)
+            if attribute == 'spike':
+                return self.cyInstance.get_local_attribute_all('spiked', 'int')
             else:
-                return self.cyInstance.get_global_attribute(attribute, ctype)
+                ctype = self._get_attribute_cpp_type(attribute)
+                if attribute in self.neuron_type.description['local']:
+                    data = self.cyInstance.get_local_attribute_all(attribute, ctype)
+                    return data.reshape(self.geometry)
+                else:
+                    return self.cyInstance.get_global_attribute(attribute, ctype)
         except Exception as e:
-            Global._print(e)
-            Global._error(' the variable ' +  attribute +  ' does not exist in this population (' + self.name + ')')
+            Messages._print(e)
+            Messages._error(' the variable ' +  attribute +  ' does not exist in this population (' + self.name + ')')
 
     def _set_cython_attribute(self, attribute, value):
         """
         Sets the value of the given attribute for all neurons in the population,
         as a Numpy array having the same geometry as the population if it is local.
 
         :param attribute: should be a string representing the variables's name.
         :param value: a value or Numpy array of the right size.
-
         """
         try:
             ctype = self._get_attribute_cpp_type(attribute)
             if attribute in self.neuron_type.description['local']:
                 if isinstance(value, np.ndarray):
                     self.cyInstance.set_local_attribute_all(attribute, value.reshape(self.size), ctype)
                 elif isinstance(value, list):
                     self.cyInstance.set_local_attribute_all(attribute, np.array(value).reshape(self.size), ctype)
                 else:
                     self.cyInstance.set_local_attribute_all(attribute, value * np.ones( self.size ), ctype)
             else:
                 self.cyInstance.set_global_attribute(attribute, value, ctype)
         except Exception as e:
-            Global._debug(e)
+            Messages._debug(e)
             err_msg = """Population.set(): either the variable '%(attr)s' does not exist in the population '%(pop)s', or the provided array does not have the right size."""
-            Global._error(err_msg  % { 'attr': attribute, 'pop': self.name } )
+            Messages._error(err_msg  % { 'attr': attribute, 'pop': self.name } )
 
     def _get_attribute_cpp_type(self, attribute):
         """
-        Determine C++ data type for a given attribute
+        Determines C++ data type for a given attribute
         """
         ctype = None
         for var in self.neuron_type.description['variables']+self.neuron_type.description['parameters']:
             if var['name'] == attribute:
                 ctype = var['ctype']
                 break
 
         return ctype
 
     def __len__(self):
         # Number of neurons in the population.
         return self.size
 
 
-    def set(self, values):
+    def set(self, values:dict) -> None:
         """
         Sets the value of neural variables and parameters.
 
         Example:
 
         ```python
-        pop.set({ 'tau' : 20.0, 'r'= np.random.rand((8,8)) } )
+        pop.set({'tau': 20.0, 'r': np.random.rand((8,8)) } )
         ```
 
         :param values: dictionary of attributes to be updated.
-
         """
         for name, value in values.items():
             self.__setattr__(name, value)
 
-    def get(self, name):
+    def get(self, name:str) -> np.ndarray:
         """
         Returns the value of neural variables and parameters.
 
         :param name: attribute name as a string.
         """
         return self.__getattr__(name)
 
@@ -422,23 +457,23 @@
 
     ################################
     ## Access to functions
     ################################
     def _function(self, func):
         "Access a user defined function"
         if not self.initialized:
-            Global._warning('the network is not compiled yet, cannot access the function ' + func)
+            Messages._warning('the network is not compiled yet, cannot access the function ' + func)
             return
 
         return getattr(self.cyInstance, func)
 
     ################################
     ## Access to weighted sums
     ################################
-    def sum(self, target):
+    def sum(self, target:str):
         """
         Returns the array of weighted sums corresponding to the target:
 
         ```python
         excitatory = pop.sum('exc')
         ```
 
@@ -452,102 +487,105 @@
 
         **Note:** it is not possible to distinguish the original population when the same target is used.
 
         :param target: the desired projection target.
         """
         # Check if the network is initialized
         if not self.initialized:
-            Global._warning('sum(): the population', self.name, 'is not initialized yet.')
+            Messages._warning('sum(): the population', self.name, 'is not initialized yet.')
             return np.zeros(self.geometry)
         # Check if a projection has this type
         if not target in self.targets:
-            Global._warning('sum(): the population', self.name, 'receives no projection with the target', target)
+            Messages._warning('sum(): the population', self.name, 'receives no projection with the target', target)
             return np.zeros(self.geometry)
         # Spiking neurons already have conductances available
         if self.neuron_type.type == 'spike':
             return getattr(self, 'g_'+target)
         # Otherwise, call the Cython method
-        return self.cyInstance.get_local_attribute_all("_sum_"+target, Global.config["precision"])
+        return self.cyInstance.get_local_attribute_all("_sum_"+target, get_global_config('precision'))
 
     ################################
     ## Refractory period
     ################################
     @property
-    def refractory(self):
+    def refractory(self) -> float | str:
+        "Refractory period (in ms)."
         if self.neuron_type.description['type'] == 'spike':
             if self.initialized:
                 if not isinstance(self.neuron_type.description['refractory'], str):
-                    return Global.config['dt']*self.cyInstance.get_refractory()
+                    return get_global_config('dt')*self.cyInstance.get_refractory()
                 else:
                     return getattr(self, self.neuron_type.description['refractory'])
             else :
                 return self.neuron_type.description['refractory']
         else:
-            Global._warning('Rate-coded neurons do not have refractory periods...')
+            Messages._warning('Rate-coded neurons do not have refractory periods...')
             return None
 
     @refractory.setter
-    def refractory(self, value):
+    def refractory(self, value:float | str):
         if self.neuron_type.description['type'] == 'spike':
 
             if isinstance(self.neuron_type.description['refractory'], str):
-                Global._warning("The refractory period is linked to the neural variable", self.neuron_type.description['refractory'], ", doing nothing... Change its value instead.")
+                Messages._warning("The refractory period is linked to the neural variable", self.neuron_type.description['refractory'], ", doing nothing... Change its value instead.")
                 return
 
             if self.initialized:
                 if isinstance(value, RandomDistribution):
-                    refs = (value.get_values(self.size)/Global.config['dt']).astype(int)
+                    refs = (value.get_values(self.size)/get_global_config('dt')).astype(int)
                 elif isinstance(value, np.ndarray):
-                    refs = (value / Global.config['dt']).astype(int).reshape(self.size)
+                    refs = (value / get_global_config('dt')).astype(int).reshape(self.size)
                 else:
-                    refs = (value/ Global.config['dt']*np.ones(self.size)).astype(int)
+                    refs = (value/ get_global_config('dt')*np.ones(self.size)).astype(int)
                 # TODO cast into int
                 self.cyInstance.set_refractory(refs)
             else: # not initialized yet, saving for later
                 self.neuron_type.description['refractory'] = value
         else:
-            Global._warning('Rate-coded neurons do not have refractory periods...')
+            Messages._warning('Rate-coded neurons do not have refractory periods...')
 
     ################################
     ## Spiking neurons can compute a mean FR
     ################################
-    def compute_firing_rate(self, window):
+    def compute_firing_rate(self, window:float) -> None:
         """
         Tells spiking neurons in the population to compute their mean firing rate over the given window and store the values in the variable `r`.
 
         This method has an effect on spiking neurons only.
 
         If this method is not called, `r` will always be 0.0. `r` can of course be accessed and recorded as any other variable.
 
         :param window: window in ms over which the spikes will be counted.
         """
-        if Global._check_paradigm('cuda'):
-            Global._warning('compute_firing_rate() is currently being evaluated on the host-side, so may be slow ... ')
+        if _check_paradigm('cuda'):
+            Messages._warning('compute_firing_rate() is currently being evaluated on the host-side, so may be slow ... ')
 
         if self.neuron_type.type == 'rate':
-            Global._error('compute_firing_rate(): the neuron is already rate-coded...')
+            Messages._error('compute_firing_rate(): the neuron is already rate-coded...')
 
         self._compute_mean_fr = float(window)
 
         if self.initialized:
             getattr(self.cyInstance, 'compute_firing_rate')(self._compute_mean_fr)
 
     ################################
     ## Access to individual neurons
     ################################
-    def neuron(self, *coord):
+    def neuron(self, *coord) -> IndividualNeuron:
         """
         Returns an ``IndividualNeuron`` object wrapping the neuron with the provided rank or coordinates.
+
+        :returns: IndividualNeuron instance.
         """
         # Transform arguments
         if len(coord) == 1:
             if isinstance(coord[0], int):
                 rank = coord[0]
                 if not rank < self.size:
-                    Global._error(' when accessing neuron', str(rank), ': the population', self.name, 'has only', self.size, 'neurons (geometry '+ str(self.geometry) +').')
+                    Messages._error(' when accessing neuron', str(rank), ': the population', self.name, 'has only', self.size, 'neurons (geometry '+ str(self.geometry) +').')
             else:
                 rank = self.rank_from_coordinates( coord[0] )
                 if rank is None:
                     return None
         else: # a tuple
             rank = self.rank_from_coordinates( coord )
             if rank is None:
@@ -602,15 +640,15 @@
             indices = np.array(indices)
             return PopulationView(self, indices, geometry=(len(indices),))
 
         elif isinstance(indices, (np.ndarray)):
             # Sanity check
             if isinstance(indices, (np.ndarray)):
                 if indices.ndim != 1:
-                    Global._error('only one-dimensional lists/arrays are allowed to address a population.')
+                    Messages._error('only one-dimensional lists/arrays are allowed to address a population.')
 
             return PopulationView(self, indices, geometry=(len(indices),))
 
         elif isinstance(indices, slice): # a single slice of ranks
             start, stop, step = indices.start, indices.stop, indices.step
 
             # no value defined for a position
@@ -662,72 +700,74 @@
                 elif self.dimension == 3:
                     ranks = [self.rank_from_coordinates((x, y, z)) for x in coords[0] for y in coords[1] for z in coords[2]]
                     geometry = (len(coords[0]), len(coords[1]), len(coords[2]))
                 elif self.dimension == 4:
                     ranks = [self.rank_from_coordinates((x, y, z, k)) for x in coords[0] for y in coords[1] for z in coords[2] for k in coords[3]]
                     geometry = (len(coords[0]), len(coords[1]), len(coords[2]), len(coords[3]))
                 else:
-                    Global._error("Slicing is implemented only for population with 4 dimensions at maximum", self.geometry)
+                    Messages._error("Slicing is implemented only for population with 4 dimensions at maximum", self.geometry)
                 if not max(ranks) < self.size:
-                    Global._error("Indices do not match the geometry of the population", self.geometry)
+                    Messages._error("Indices do not match the geometry of the population", self.geometry)
                 
                 return PopulationView(self, ranks, geometry=geometry)
 
-        Global._warning('Population' + self.name + ': can not address the population with', indices)
+        Messages._warning('Population' + self.name + ': can not address the population with', indices)
         return None
 
     def __iter__(self):
         # Returns iteratively each neuron in the population in ascending rank order.
         for neur_rank in range(self.size):
             yield self.neuron(neur_rank)
 
     ################################
     ## Coordinate transformations
     ################################
-    def rank_from_coordinates(self, coord):
+    def rank_from_coordinates(self, coord:tuple) -> int:
         """
         Returns the rank of a neuron based on coordinates.
 
-        :param coord: coordinate tuple, can be multidimensional.
+        :param coord: Coordinate tuple, can be multidimensional.
+        :returns: Rank.
         """
         try:
             rank = self._rank_from_coord( coord, self.geometry )
         except:
-            Global._error('rank_from_coordinates(): There is no neuron of coordinates', coord, 'in the population', self.name, self.geometry)
+            Messages._error('rank_from_coordinates(): There is no neuron of coordinates', coord, 'in the population', self.name, self.geometry)
 
         if rank > self.size:
-            Global._error('rank_from_coordinates(), neuron', str(coord), ': the population' , self.name , 'has only', self.size, 'neurons (geometry '+ str(self.geometry) +').')
+            Messages._error('rank_from_coordinates(), neuron', str(coord), ': the population' , self.name , 'has only', self.size, 'neurons (geometry '+ str(self.geometry) +').')
         else:
             return rank
 
-    def coordinates_from_rank(self, rank):
+    def coordinates_from_rank(self, rank:int) -> tuple:
         """
         Returns the coordinates of a neuron based on its rank.
 
-        :param rank: rank of the neuron.
+        :param rank: Rank of the neuron.
+        :returns: Coordinates.
         """
         # Check the rank
         if not rank < self.size:
-            Global._error('The given rank', str(rank), 'is larger than the size of the population', str(self.size) + '.')
+            Messages._error('The given rank', str(rank), 'is larger than the size of the population', str(self.size) + '.')
 
         try:
             coord = self._coord_from_rank( rank, self.geometry )
         except:
-            Global._error('The given rank', str(rank), 'is larger than the size of the population', str(self.size) + '.')
+            Messages._error('The given rank', str(rank), 'is larger than the size of the population', str(self.size) + '.')
         else:
             return coord
 
-    def normalized_coordinates_from_rank(self, rank, norm=1.):
+    def normalized_coordinates_from_rank(self, rank:int, norm:float=1.) -> tuple:
         """
         Returns normalized coordinates of a neuron based on its rank. 
         The geometry of the population is mapped to the hypercube $[0, 1]^d$
 
-        :param rank: rank of the neuron
-        :param norm: norm of the cube (default = 1.0)
-
+        :param rank: Rank of the neuron
+        :param norm: Norm of the cube (default = 1.0)
+        :returns: Coordinates.
         """
         try:
             normal = self._norm_coord_dict[self.dimension](rank, self.geometry)
         except KeyError:
             coord = self.coordinates_from_rank(rank)
 
             normal = tuple()
@@ -760,77 +800,75 @@
                 if var in self.neuron_type.description['local']:
                     data = self.cyInstance.get_local_attribute_all(var, ctype)
                     desc[var] = data.reshape(self.geometry)
                 else:
                     desc[var] = self.cyInstance.get_global_attribute(var, ctype)
 
             except:
-                Global._warning('Can not save the attribute ' + var + ' in the population ' + self.name + '.')
+                Messages._warning('Can not save the attribute ' + var + ' in the population ' + self.name + '.')
 
         return desc
 
-    def save(self, filename):
+    def save(self, filename:str) -> None:
         """
         Saves all information about the population (structure, current value of parameters and variables) into a file.
 
         * If the file name is '.npz', the data will be saved and compressed using `np.savez_compressed` (recommended).
 
         * If the file name ends with '.gz', the data will be pickled into a binary file and compressed using gzip.
 
         * If the file name is '.mat', the data will be saved as a Matlab 7.2 file. Scipy must be installed.
 
         * Otherwise, the data will be pickled into a simple binary text file using pickle.
 
         **Warning:** The '.mat' data will not be loadable by ANNarchy, it is only for external analysis purpose.
 
-        :param filename: filename, may contain relative or absolute path.
-
         Example:
 
         ```python
         pop.save('pop1.npz')
         pop.save('pop1.txt')
         pop.save('pop1.txt.gz')
         pop.save('pop1.mat')
         ```
 
+        :param filename: Filename, may contain relative or absolute path.
         """
         from ANNarchy.core.IO import _save_data
         _save_data(filename, self._data())
 
 
-    def load(self, filename, pickle_encoding=None):
+    def load(self, filename, pickle_encoding=None) -> None:
         """
         Load the saved state of the population by `Population.save()`.
 
         Warning: Matlab data can not be loaded.
 
         Example:
 
         ```python
         pop.load('pop1.npz')
         pop.load('pop1.txt')
         pop.load('pop1.txt.gz')
         ```
 
         :param filename: the filename with relative or absolute path.
-
         """
         from ANNarchy.core.IO import _load_data
         self._load_pop_data(_load_data(filename, pickle_encoding))
 
     def _load_pop_data(self, desc):
         """
         Updates the population with the stored data set.
         """
         if not 'attributes' in desc.keys():
-            Global._error('Saved with a too old version of ANNarchy (< 4.2).', exit=True)
+            Messages._error('Saved with a too old version of ANNarchy (< 4.2).', exit=True)
 
         for var in desc['attributes']:
             try:
                 self._set_cython_attribute(var, desc[var])
 
             except Exception as e:
-                Global._print(e)
-                Global._warning('Can not load the variable ' + var + ' in the population ' + self.name)
-                Global._print('Skipping this variable.')
+                Messages._print(e)
+                Messages._warning('Can not load the variable ' + var + ' in the population ' + self.name)
+                Messages._print('Skipping this variable.')
                 continue
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/PopulationView.py` & `annarchy-4.8.0.1/ANNarchy/core/PopulationView.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,48 +1,58 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-from ANNarchy.core import Global as Global
-from .Random import RandomDistribution
 import numpy as np
 
+from ANNarchy.core.Random import RandomDistribution
+from ANNarchy.intern import Messages
+
 class PopulationView :
     """ Container representing a subset of neurons of a Population."""
 
     def __init__(self, population, ranks, geometry=None):
         """
         Create a view of a subset of neurons within the same population.
 
         :param population: population object
         :param ranks: list or numpy array containing the ranks of the selected neurons.
         :param geometry: a geometry for the Populationview (optional)
         """
         self.population = population
+        "Original (full) population."
+
         self.ranks = np.array(ranks)
+        "Array of ranks in the PopulationView."
+
         self.geometry = geometry
+        "Geometry of the population."
+
         self.size = len(self.ranks)
-        self.offsets = [np.amin(self.ranks), np.amax(self.ranks)+1]
+        "Size of the population."
+        
+        self.name = population.name
+        "Name of the population."
 
-        # For people using Individual neuron
-        if self.size == 1:
-            self.rank = self.ranks[0]
-        else:
-            self.rank = self.ranks
+        self.attributes = population.attributes
+        "List of attributes."
+        self.variables = population.variables
+        "List of variable names."
+        self.parameters = population.parameters
+        "List of parameter names."
 
+        # Internal attributes        
         self.neuron_type = self.population.neuron_type
         self.id = self.population.id
-        self.name = population.name
+        self.offsets = [np.amin(self.ranks), np.amax(self.ranks)+1]
         self.cyInstance = population.cyInstance
-        self.variables = population.variables
-        self.parameters = population.parameters
-        self.attributes = population.attributes
         self.max_delay = population.max_delay
 
+
     def _copy(self):
         "Returns a copy of the population when creating networks. Internal use only."
         return PopulationView(population=self.population, ranks=self.ranks, geometry=self.geometry)
 
     ################################
     # Indexing
     ################################
@@ -65,25 +75,25 @@
 
         :param coord: coordinate tuple, can be multidimensional.
         :param local: whther the coordinates are local to the PopulationView or not (default: False).
         """
         if not local:
             rk = self.population.rank_from_coordinates(coord)
             if not rk in self.ranks:
-                Global._error("There is no neuron of coordinates", coord, "in the PopulationView.")
+                Messages._error("There is no neuron of coordinates", coord, "in the PopulationView.")
             return rk
 
         else:
             if not self.geometry:
-                Global._error("The population view does not have a geometry, cannot use local coordinates.")
+                Messages._error("The population view does not have a geometry, cannot use local coordinates.")
             else:
                 try:
                     intern_rank = np.ravel_multi_index(coord, self.geometry)
                 except:
-                    Global._error("There is no neuron of coordinates", coord, "in a PopulationView of geometry", self.geometry)
+                    Messages._error("There is no neuron of coordinates", coord, "in a PopulationView of geometry", self.geometry)
                 return self.ranks[intern_rank]
 
     def coordinates_from_rank(self, rank, local=False):
         """
         Returns the coordinates of a neuron based on its rank.
 
         When local is False (default), the coordinates are relative to the ORIGINAL population, not the PopulationView.
@@ -95,28 +105,28 @@
         :param rank: rank of the neuron in the original population
         :param local: whether the coordinates are local to the PopulationView or not (default: False).
         """
         if not local:
             return self.population.coordinates_from_rank(rank)
         else:
             if not self.geometry:
-                Global._error("The population view does not have a geometry, cannot use local coordinates.")
+                Messages._error("The population view does not have a geometry, cannot use local coordinates.")
             else:
                 if not rank in self.ranks:
-                    Global._error("There is no neuron of rank", rank, "in the PopulationView.")
+                    Messages._error("There is no neuron of rank", rank, "in the PopulationView.")
                 intern_rk = self.ranks.index(rank)
                 coord = np.unravel_index(intern_rk, self.geometry)
                 return coord
 
 
     ################################
     # Targets must match the population, both in read and write
     ################################
     @property
-    def targets(self):
+    def targets(self) -> list[str]:
         "List of targets connected to the population."
         return self.population.targets
 
     @targets.setter
     def targets(self, value):
         self.population.targets.append(value)
 
@@ -124,14 +134,18 @@
     ## Access to attributes
     ################################
 
     def __getattr__(self, name):
         " Method called when accessing an attribute."
         if name == 'population':
             return object.__getattribute__(self, name)
+        elif name == 'spike':
+            all_events = set(self.population.spike)
+            own_ranks = set(self.ranks)
+            return list(sorted(set.intersection(all_events, own_ranks)))
         elif hasattr(self.population, 'attributes'):
             if name in self.population.attributes:
                 return self.get(name)
             else:
                 return object.__getattribute__(self, name)
         else:
             return object.__getattribute__(self, name)
@@ -154,17 +168,17 @@
 
         :param name: name of the parameter/variable.
         """
         if name in self.population.attributes:
             all_val = getattr(self.population, name).reshape(self.population.size)
             return all_val[self.ranks]
         else:
-            Global._error("Population does not have a parameter/variable called " + name + ".")
+            Messages._error("Population does not have a parameter/variable called " + name + ".")
 
-    def set(self, value):
+    def set(self, value:dict) -> None:
         """
         Updates the neurons' variable/parameter values.
 
         :param value: dictionary of parameters/variables to be updated for the corresponding subset of neurons. It can be a single value or a list/1D array of the same size as the PopulationView.
 
         .. code-block:: python
 
@@ -174,15 +188,15 @@
         .. warning::
 
             If you modify the value of a global parameter, this will be the case for ALL neurons of the population, not only the subset.
         """
         def _set_single(name, rank, value):
             if not self.population.initialized:
                 if not name in self.population.neuron_type.description['local']:
-                    Global._error('can not set the value of a global attribute from a PopulationView.')
+                    Messages._error('can not set the value of a global attribute from a PopulationView.')
                     return
 
                 if isinstance(self.population.init[name], np.ndarray):
                     if len(self.population.geometry) == 1:
                         self.population.init[name][rank] = value
                     else: # Need to access the coordinates
                         coords = self.population.coordinates_from_rank(rank)
@@ -199,39 +213,39 @@
         for val_key in value.keys():
             if hasattr(self.population, val_key):
                 # Check the value
                 if isinstance(value[val_key], RandomDistribution): # Make sure it is generated only once
                         value[val_key] = np.array(value[val_key].get_values(self.size))
                 if isinstance(value[val_key], np.ndarray): # np.array
                     if value[val_key].ndim >1 or len(value[val_key]) != self.size:
-                        Global._error("You can only provide an array of the same size as the PopulationView", self.size)
+                        Messages._error("You can only provide an array of the same size as the PopulationView", self.size)
                         return None
                     if val_key in self.population.neuron_type.description['global']:
-                        Global._error("Global attributes can only have one value in a population.")
+                        Messages._error("Global attributes can only have one value in a population.")
                         return None
                     # Assign the value
                     for idx, rk in enumerate(self.ranks):
                         _set_single(val_key, rk, value[val_key][idx])
 
                 elif isinstance(value[val_key], list): # list
                     if len(value[val_key]) != self.size:
-                        Global._error("You can only provide a list of the same size as the PopulationView", self.size)
+                        Messages._error("You can only provide a list of the same size as the PopulationView", self.size)
                         return None
                     if val_key in self.population.neuron_type.description['global']:
-                        Global._error("Global attributes can only have one value in a population.")
+                        Messages._error("Global attributes can only have one value in a population.")
                         return None
                     # Assign the value
                     for idx, rk in enumerate(self.ranks):
                         _set_single(val_key, rk, value[val_key][idx])
 
                 else: # single value
                     for rk in self.ranks:
                         _set_single(val_key, rk, value[val_key])
             else:
-                Global._error("the population has no attribute called ", val_key)
+                Messages._error("the population has no attribute called ", val_key)
                 return None
 
     ################################
     ## Access to weighted sums
     ################################
     def sum(self, target):
         """
@@ -262,15 +276,15 @@
             if isinstance(other, IndividualNeuron):
                 tmp = list(set(list(self.ranks) + [other.rank]))
                 return PopulationView(self.population, np.array(tmp))
             elif isinstance(other, PopulationView):
                 tmp = list(set(list(self.ranks) + list(other.ranks)))
                 return PopulationView(self.population, np.array(tmp))
         else:
-            Global._error("can only add two PopulationViews of the same population.")
+            Messages._error("can only add two PopulationViews of the same population.")
 
     def __repr__(self):
         """Defines the printing behaviour."""
         string ="PopulationView of " + str(self.population.name) + '\n'
         string += '  Ranks: ' +  str(self.ranks)
         string += '\n'
         for rk in self.ranks:
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/Profiler.py` & `annarchy-4.8.0.1/ANNarchy/intern/Profiler.py`

 * *Files 9% similar despite different names*

```diff
@@ -3,48 +3,71 @@
 :license: GPLv2, see LICENSE for details.
 """
 
 import time
 import csv
 import matplotlib.pylab as plt
 
-import ANNarchy.core.Global as Global
+from ANNarchy.intern.ConfigManagement import get_global_config, _update_global_config, _check_paradigm
+from ANNarchy.intern import Messages
 
 class Profiler :
     """
     The Profiler module should help to understand the performance of a simulation
     using the ANNarchy neural simulator.
 
     Therefore are functions to investigate memory consumption and timeline
     information provided.
     """
+    _instance = None
+
     _color_code = {
         "default": "blue",
         "compile": "green",
         "simulate": "red",
         "instantiate": "orange",
         # will be ignored in image
         "cpp core": "black"
     }
-
     def __init__(self):
         """
-        Initialize profiler instance and register it in Global.
+        Constructor
         """
-        Global.config["profiling"] = True   # enable c++ profiling
+        pass 
 
-        if Global._profiler is not None:
-            Global._warning("Profiling already initialized ...")
+    def __new__(cls):
+        """
+        First call construction of the NetworkManager. No additional arguments are required.
+        """
+        if cls._instance is None:
+            cls._instance = super().__new__(cls)
+        
+        return cls._instance
 
-        Global._profiler = self
+    def enable_profiling(self):
+        """
+        Initialize profiler instance and register it in Global.
+        """
+        # enable c++ profiling
+        _update_global_config('profiling', True)
+
+        # initialize measurement
         self._basetime = time.time()
         self._entries = []
         self._cpp_profiler = None       # set during Compiler._instantiate()
         self.add_entry( self._basetime, self._basetime, "initialized" )
-    
+
+    def disable_profiling(self):
+        _update_global_config('profiling', False)
+        self.clear()
+
+    @property
+    def enabled(self):
+        return get_global_config('profiling')
+
     def add_entry( self, t_entry, t_escape, label, group="default" ):
         """
         Add a function to timeline.
 
         :param t_entry: entry time point of the function
         :param t_escape: escape time point of the function
         :param label: label of the function
@@ -71,15 +94,15 @@
                 tmp = list(self._entries[idx_t])
                 tmp[0] = t_entry
                 tmp[1] = t_escape
                 self._entries[idx_t] = tuple(tmp)
                 found = True
 
         if not found:
-            Global._warning("Profiler.update_entry(): the entry was not found ...")
+            Messages._warning("Profiler.update_entry(): the entry was not found ...")
 
     def clear(self):
         """
         Clear all recorded time points.
         """
         self._entries.clear()
 
@@ -115,20 +138,20 @@
                     print("  -", label,":", t_start, "seconds (", t_end, "% )")
 
     def store_cpp_time_as_csv(self):
         """
         Store the measured timings on the C++ core as .csv to
         be further processed e. g. using pandas.
         """
-        if Global._check_paradigm("cuda"):
+        if _check_paradigm("cuda"):
             fname = "profile_cuda.csv"
         else:
-            fname = "profile_omp_"+str(Global.config["num_threads"])+"threads.csv"
+            fname = "profile_omp_"+str(get_global_config('num_threads'))+"threads.csv"
 
-        with open(Global.config["profile_out"]+'/'+fname, mode='w') as Datafile:
+        with open(get_global_config('profile_out')+'/'+fname, mode='w') as Datafile:
             csv_writer = csv.writer(Datafile, delimiter=',', quotechar=' ', quoting=csv.QUOTE_MINIMAL)
 
             for t_start, t_end, label, group in self._entries:
                 # skip Python functions
                 if group != "cpp core":
                     continue
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/Projection.py` & `annarchy-4.8.0.1/ANNarchy/core/Projection.py`

 * *Files 4% similar despite different names*

```diff
@@ -5,66 +5,89 @@
 
 import numpy as np
 import math, os
 import copy, inspect
 import pickle
 
 from ANNarchy.core import Global
+from ANNarchy.intern.NetworkManager import NetworkManager
+from ANNarchy.intern import Messages
 from ANNarchy.core.Random import RandomDistribution
+from ANNarchy.core.Population import Population
+from ANNarchy.core.Neuron import IndividualNeuron
+from ANNarchy.core.Synapse import Synapse
 from ANNarchy.core.Dendrite import Dendrite
 from ANNarchy.core.PopulationView import PopulationView
 from ANNarchy.core import ConnectorMethods
+from ANNarchy.intern.Profiler import Profiler
+from ANNarchy.intern.ConfigManagement import get_global_config, _check_paradigm
 
 class Projection :
     """
-    Container for all the synapses of the same type between two populations.
-    """
+    Structure holding all synapses of the same type between two populations.
 
-    def __init__(self, pre, post, target, synapse=None, name=None, disable_omp=True, copied=False):
-        """
-        By default, the synapse only ensures linear synaptic transmission:
+    By default, the synapse only ensures linear synaptic transmission:
 
-        * For rate-coded populations: ``psp = w * pre.r``
-        * For spiking populations: ``g_target += w``
+    * For rate-coded populations: ``psp = w * pre.r``
+    * For spiking populations: ``g_target += w``
 
-        to modify this behavior one need to provide a Synapse object.
+    To modify this behavior, a `Synapse` object can be provided.
+
+    :param pre: Pre-synaptic population (either its name or a ``Population`` object).
+    :param post: Post-synaptic population (either its name or a ``Population`` object).
+    :param target: Type of the connection.
+    :param synapse: A `Synapse` instance.
+    :param name: Unique name of the projection (optional, it defaults to ``proj0``, ``proj1``, etc).
+    :param disable_omp: Especially for small- and mid-scale sparse spiking networks, the parallelization of spike propagation is not scalable and disabled by default. It can be enabled by setting this parameter to `False`.
+    """
+
+    def __init__(self, 
+                 pre: str | Population, 
+                 post: str | Population, 
+                 target: str, 
+                 synapse: Synapse = None, 
+                 name:str = None, 
+                 disable_omp:bool = True, 
+                 copied:bool = False):
 
-        :param pre: pre-synaptic population (either its name or a ``Population`` object).
-        :param post: post-synaptic population (either its name or a ``Population`` object).
-        :param target: type of the connection.
-        :param synapse: a ``Synapse`` instance.
-        :param name: unique name of the projection (optional, it defaults to ``proj0``, ``proj1``, etc).
-        :param disable_omp: especially for small- and mid-scale sparse spiking networks the parallelization of spike propagation is not scalable. But it can be enabled by setting this parameter to `False`.
-        """
         # Check if the network has already been compiled
-        if Global._network[0]['compiled'] and not copied:
-            Global._error('you cannot add a projection after the network has been compiled.')
+        if NetworkManager().is_compiled(net_id=0) and not copied:
+            Messages._error('you cannot add a projection after the network has been compiled.')
 
         # Store the pre and post synaptic populations
         # the user provide either a string or a population object
         # in case of string, we need to search for the corresponding object
         if isinstance(pre, str):
-            for pop in Global._network[0]['populations']:
+            for pop in NetworkManager().get_populations(net_id=0):
                 if pop.name == pre:
                     self.pre = pop
         else:
-            self.pre = pre
+            if isinstance(pre, IndividualNeuron):
+                self.pre = pre.population
+            else:
+                self.pre = pre
+                "Pre-synaptic population."
 
         if isinstance(post, str):
-            for pop in Global._network[0]['populations']:
+            for pop in NetworkManager().get_populations(net_id=0):
                 if pop.name == post:
                     self.post = pop
         else:
-            self.post = post
+            if isinstance(post, IndividualNeuron):
+                self.post = post.population
+            else:
+                self.post = post
+                "Post-synaptic population."
 
         # Store the arguments
         if isinstance(target, list) and len(target) == 1:
             self.target = target[0]
         else:
             self.target = target
+            "Target."
 
         # Add the target(s) to the postsynaptic population
         if isinstance(self.target, list):
             for _target in self.target:
                 self.post.targets.append(_target)
         else:
             self.post.targets.append(self.target)
@@ -92,15 +115,15 @@
         # Disable omp for spiking networks
         self.disable_omp = disable_omp
 
         # Analyse the parameters and variables
         self.synapse_type._analyse()
 
         # Create a default name
-        self.id = len(Global._network[0]['projections'])
+        self.id = NetworkManager().number_projections(net_id=0)
         if name:
             self.name = name
         else:
             self.name = 'proj'+str(self.id)
 
         # Container for control/attribute states
         self.init = {}
@@ -109,30 +132,33 @@
         self.init["transmission"] = True
         self.init["axon_transmission"] = True
         self.init["update"] = True
         self.init["plasticity"] = True
 
         # Get a list of parameters and variables
         self.parameters = []
+        "List of parameter names."
         for param in self.synapse_type.description['parameters']:
             self.parameters.append(param['name'])
             self.init[param['name']] = param['init']
 
         self.variables = []
+        "List of variable names."
         for var in self.synapse_type.description['variables']:
             self.variables.append(var['name'])
             self.init[var['name']] = var['init']
 
         self.attributes = self.parameters + self.variables
+        "List of attribute names."
 
         # Get a list of user-defined functions
         self.functions = [func['name'] for func in self.synapse_type.description['functions']]
 
         # Add the population to the global network
-        Global._network[0]['projections'].append(self)
+        NetworkManager().add_projection(net_id=0, projection=self)
 
         # Finalize initialization
         self.initialized = False
 
         # Cython instance
         self.cyInstance = None
 
@@ -180,28 +206,28 @@
         # If set to true, the code generator is not allowed to
         # split the matrix. This will be the case for many
         # SpecificProjections defined by the user or is disabled
         # globally.
         if self.synapse_type.type == "rate":
             # Normally, the split should not be used for rate-coded models
             # but maybe there are cases where we want to enable it ...
-            self._no_split_matrix = Global.config["disable_split_matrix"]
+            self._no_split_matrix = get_global_config('disable_split_matrix')
 
             # If the number of elements is too small, the split
             # might not be efficient.
             if self.post.size < Global.OMP_MIN_NB_NEURONS:
                 self._no_split_matrix = True
 
         else:
             # If the number of elements is too small, the split
             # might not be efficient.
             if self.post.size < Global.OMP_MIN_NB_NEURONS:
                 self._no_split_matrix = True
             else:
-                self._no_split_matrix = Global.config["disable_split_matrix"]
+                self._no_split_matrix = get_global_config('disable_split_matrix')
 
         # In particular for spiking models, the parallelization on the
         # inner or outer loop can make a performance difference
         if self._no_split_matrix:
             # LIL and CSR are parallelized on inner loop
             # to prevent cost of atomic operations
             self._parallel_pattern = 'inner_loop'
@@ -267,25 +293,25 @@
         pass
 
     def _instantiate(self, module):
         """
         Instantiates the projection after compilation. The function should be
         called by Compiler._instantiate().
 
-        :param:     module  cython module (ANNarchyCore instance)
+        :param module:  cython module (ANNarchyCore instance)
         """
-        if Global.config["profiling"]:
+        if Profiler().enabled:
             import time
             t1 = time.time()
 
         self.initialized = self._connect(module)
 
-        if Global.config["profiling"]:
+        if Profiler().enabled:
             t2 = time.time()
-            Global._profiler.add_entry(t1, t2, "proj"+str(self.id), "instantiate")
+            Profiler().add_entry(t1, t2, "proj"+str(self.id), "instantiate")
 
     def _init_attributes(self):
         """
         Method used after compilation to initialize the attributes. The function
         should be called by Compiler._instantiate
         """
         for name, val in self.init.items():
@@ -293,28 +319,28 @@
             if not name in ['w']:
                 self.__setattr__(name, val)
 
     def _connect(self, module):
         """
         Builds up dendrites either from list or dictionary. Called by instantiate().
 
-        :param:     module  cython module (ANNarchyCore instance)
+        :param module:  cython module (ANNarchyCore instance)
         :return:    True, if the connector was successfully instantiated. Potential errors are kept by 
                     Python exceptions. If the Cython - connector call fails (return False) the most likely
                     reason is that there was not enough memory available.
         """
         # Local import to prevent circular import (HD: 28th June 2021)
         from ANNarchy.generator.Utils import cpp_connector_available
 
         # Sanity check
         if not self._connection_method:
-            Global._error('The projection between ' + self.pre.name + ' and ' + self.post.name + ' is declared but not connected.')
+            Messages._error('The projection between ' + self.pre.name + ' and ' + self.post.name + ' is declared but not connected.')
 
         # Debug printout
-        if Global.config["verbose"]:
+        if get_global_config('verbose'):
             print("Connectivity parameter ("+self.name+"):", self._connection_args )
 
         # Instantiate the Cython wrapper
         if not self.cyInstance:
             cy_wrapper = getattr(module, 'proj'+str(self.id)+'_wrapper')
             self.cyInstance = cy_wrapper()
 
@@ -323,15 +349,15 @@
             # No default connector -> initialize from LIL
             if self._lil_connectivity:
                 return self.cyInstance.init_from_lil_connectivity(self._lil_connectivity)
             else:
                 return self.cyInstance.init_from_lil_connectivity(self._connection_method(*((self.pre, self.post,) + self._connection_args)))
 
         else:
-            if Global.config["verbose"]:
+            if get_global_config('verbose'):
                 print("Use CPP-side implementation of", self.connector_name,"pattern for ProjStruct"+str(self.id))
 
             # all-to-all pattern
             if self.connector_name == "All-to-All":
                 if isinstance(self._connection_args[0], RandomDistribution):
                     #some kind of distribution
                     w_dist_arg1, w_dist_arg2 = self._connection_args[0].get_cpp_args()
@@ -392,43 +418,43 @@
                     d_dist_arg1 = self._connection_args[2]
                     d_dist_arg2 = self._connection_args[2]
 
                 return self.cyInstance.fixed_number_pre(self.post.ranks, self.pre.ranks, number_nonzero, w_dist_arg1, w_dist_arg2, d_dist_arg1, d_dist_arg2)
 
             else:
                 # This should never happen ...
-                Global._error("No initialization for CPP-connector defined ...")
+                Messages._error("No initialization for CPP-connector defined ...")
 
         # should be never reached ...
         return False
 
     def _store_connectivity(self, method, args, delay, storage_format, storage_order):
         """
         Store connectivity data. This function is called from cython_ext.Connectors module.
         """
         # No format specified for this projection by the user, so fall-back to Global setting
         if storage_format is None:
-            if Global.config['sparse_matrix_format'] == "default":
-                if Global._check_paradigm("openmp"):
+            if get_global_config('sparse_matrix_format') == "default":
+                if _check_paradigm("openmp"):
                     storage_format = "lil"
-                elif Global._check_paradigm("cuda"):
+                elif _check_paradigm("cuda"):
                     storage_format = "csr"
                 else:
                     raise NotImplementedError
 
             else:
-                storage_format = Global.config["sparse_matrix_format"]
+                storage_format = get_global_config('sparse_matrix_format')
 
         # No storage order specified for this projection by the user, so fall-back to Global setting
         if storage_order is None:
-            storage_order = Global.config["sparse_matrix_storage_order"]
+            storage_order = get_global_config('sparse_matrix_storage_order')
 
         # Sanity checks
         if self._connection_method != None:
-            Global._warning("Projection ", self.name, " was already connected ... data will be overwritten.")
+            Messages._warning("Projection ", self.name, " was already connected ... data will be overwritten.")
 
         # Store connectivity pattern parameters
         self._connection_method = method
         self._connection_args = args
         self._connection_delay = delay
         self._storage_format = storage_format
         self._storage_order = storage_order
@@ -446,38 +472,38 @@
         if storage_format == "auto":
             self._storage_format = self._automatic_format_selection()
         if storage_order == "auto":
             self._storage_order = self._automatic_order_selection()
 
         # Analyse the delay
         if isinstance(delay, (int, float)): # Uniform delay
-            self.max_delay = round(delay/Global.config['dt'])
-            self.uniform_delay = round(delay/Global.config['dt'])
+            self.max_delay = round(delay/get_global_config('dt'))
+            self.uniform_delay = round(delay/get_global_config('dt'))
 
         elif isinstance(delay, RandomDistribution): # Non-uniform delay
             self.uniform_delay = -1
             # Ensure no negative delays are generated
-            if delay.min is None or delay.min < Global.config['dt']:
-                delay.min = Global.config['dt']
+            if delay.min is None or delay.min < get_global_config('dt'):
+                delay.min = get_global_config('dt')
             # The user needs to provide a max in order to compute max_delay
             if delay.max is None:
-                Global._error('Projection.connect_xxx(): if you use a non-bounded random distribution for the delays (e.g. Normal), you need to set the max argument to limit the maximal delay.')
+                Messages._error('Projection.connect_xxx(): if you use a non-bounded random distribution for the delays (e.g. Normal), you need to set the max argument to limit the maximal delay.')
 
-            self.max_delay = round(delay.max/Global.config['dt'])
+            self.max_delay = round(delay.max/get_global_config('dt'))
 
         elif isinstance(delay, (list, np.ndarray)): # connect_from_matrix/sparse
             if len(delay) > 0:
                 self.uniform_delay = -1
-                self.max_delay = round(max([max(l) for l in delay])/Global.config['dt'])
+                self.max_delay = round(max([max(l) for l in delay])/get_global_config('dt'))
             else: # list is empty, no delay
                 self.max_delay = -1
                 self.uniform_delay = -1
 
         else:
-            Global._error('Projection.connect_xxx(): delays are not valid!')
+            Messages._error('Projection.connect_xxx(): delays are not valid!')
 
         # Transmit the max delay to the pre pop
         if isinstance(self.pre, PopulationView):
             self.pre.population.max_delay = max(self.max_delay, self.pre.population.max_delay)
         else:
             self.pre.max_delay = max(self.max_delay, self.pre.max_delay)
 
@@ -491,22 +517,22 @@
 
         HD (17th Jan. 2022): Currently structural plasticity is only usable with LIL. But one could also
                              apply it for dense matrices in the future. For CSR and in particular the ELL-
                              like formats the potential memory-reallocations make the structural plasticity
                              a costly operation.
         """
         # Connection pattern / Feature specific selection
-        if Global.config["structural_plasticity"]:
+        if get_global_config('structural_plasticity'):
             storage_format = "lil"
 
         elif self.connector_name == "All-to-All":
             storage_format = "dense"
 
         elif self.connector_name == "One-to-One":
-            if Global._check_paradigm("cuda"):
+            if _check_paradigm("cuda"):
                 storage_format = "csr"
             else:
                 storage_format = "lil"
 
         else:
             if self.synapse_type.type == "spike":
                 # we need to build up the matrix to analyze
@@ -521,29 +547,29 @@
 
             else:
                 # we need to build up the matrix to analyze
                 self._lil_connectivity = self._connection_method(*((self.pre, self.post,) + self._connection_args))
 
                 # get the decision parameter
                 density = float(self._lil_connectivity.nb_synapses) / float(self.pre.size * self.post.size)
-                avg_nnz_per_row, _ = self._lil_connectivity.compute_average_row_length()
+                avg_nnz_per_row, _, _, _ = self._lil_connectivity.compute_average_row_length()
 
                 # heuristic decision tree
                 if density >= 0.6:
                     storage_format = "dense"
                 else:
-                    if Global._check_paradigm("cuda"):
+                    if _check_paradigm("cuda"):
                         if avg_nnz_per_row <= 128:
                             storage_format = "ellr"
                         else:
                             storage_format = "csr"
                     else:
                         storage_format = "csr"
 
-        Global._info("Automatic format selection for", self.name, ":", storage_format)
+        Messages._info("Automatic format selection for", self.name, ":", storage_format)
         return storage_format
 
     def _automatic_order_selection(self):
         """
         Contrary to the matrix format, the decision for the matrix order is majorly dependent on
         the synapse type.
         """
@@ -552,23 +578,23 @@
         else:
             # pre-to-post is not implemented for all formats
             if self._storage_format in ["dense", "csr"]:
                 storage_order = "pre_to_post"
             else:
                 storage_order = "post_to_pre"
 
-        Global._info("Automatic matrix order selection for", self.name, ":", storage_order)
+        Messages._info("Automatic matrix order selection for", self.name, ":", storage_order)
         return storage_order
 
     def _has_single_weight(self):
         "If a single weight should be generated instead of a LIL"
-        is_cpu = Global.config['paradigm']=="openmp"
+        is_cpu = get_global_config('paradigm')=="openmp"
         has_constant_weight = self._single_constant_weight
         not_dense = not (self._storage_format == "dense")
-        no_structural_plasticity = not Global.config['structural_plasticity']
+        no_structural_plasticity = not get_global_config('structural_plasticity')
         no_synaptic_plasticity = not self.synapse_type.description['plasticity']
 
         return has_constant_weight and no_structural_plasticity and no_synaptic_plasticity and is_cpu and not_dense
 
     def reset(self, attributes=-1, synapses=False):
         """
         Resets all parameters and variables of the projection to their initial value (before the call to compile()).
@@ -587,68 +613,68 @@
 
         for var in attributes:
             # Skip w
             if var=='w':
                 continue
             # check it exists
             if not var in self.attributes:
-                Global._warning("Projection.reset():", var, "is not an attribute of the population, won't reset.")
+                Messages._warning("Projection.reset():", var, "is not an attribute of the population, won't reset.")
                 continue
             # Set the value
             try:
                 self.__setattr__(var, self.init[var])
             except Exception as e:
-                Global._print(e)
-                Global._warning("Projection.reset(): something went wrong while resetting", var)
+                Messages._print(e)
+                Messages._warning("Projection.reset(): something went wrong while resetting", var)
 
     ################################
     ## Dendrite access
     ################################
     @property
     def size(self):
         "Number of post-synaptic neurons receiving synapses."
         if self.cyInstance == None:
-            Global._warning("Access 'size or len()' attribute of a Projection is only valid after compile()")
+            Messages._warning("Access 'size or len()' attribute of a Projection is only valid after compile()")
             return 0
 
         return len(self.cyInstance.post_rank())
 
     def __len__(self):
         # Number of postsynaptic neurons receiving synapses in this projection.
         return self.size
 
     @property
     def nb_synapses(self):
         "Total number of synapses in the projection."
         if self.cyInstance is None:
-            Global._warning("Access 'nb_synapses' attribute of a Projection is only valid after compile()")
+            Messages._warning("Access 'nb_synapses' attribute of a Projection is only valid after compile()")
             return 0
         return self.cyInstance.nb_synapses()
 
     def nb_synapses_per_dendrite(self):
         "Total number of synapses for each dendrite as a list."
         if self.cyInstance is None:
-            Global._warning("Access 'nb_synapses_per_dendrite' attribute of a Projection is only valid after compile()")
+            Messages._warning("Access 'nb_synapses_per_dendrite' attribute of a Projection is only valid after compile()")
             return []
         return [self.cyInstance.dendrite_size(n) for n in range(self.size)]
 
     def nb_efferent_synapses(self):
         "Number of efferent connections. Intended only for spiking models."
         if self.cyInstance is None:
-             Global._warning("Access 'nb_efferent_synapses()' of a Projection is only valid after compile()")
+             Messages._warning("Access 'nb_efferent_synapses()' of a Projection is only valid after compile()")
              return None
         if self.synapse_type.type == "rate":
-            Global._error("Projection.nb_efferent_synapses() is not available for rate-coded projections.")
+            Messages._erroror("Projection.nb_efferent_synapses() is not available for rate-coded projections.")
 
         return self.cyInstance.nb_efferent_synapses()
 
     @property
     def post_ranks(self):
         if self.cyInstance is None:
-             Global._warning("Access 'post_ranks' attribute of a Projection is only valid after compile()")
+             Messages._warning("Access 'post_ranks' attribute of a Projection is only valid after compile()")
              return None
         
         return self.cyInstance.post_rank()
 
     @property
     def dendrites(self):
         """
@@ -660,36 +686,36 @@
     def dendrite(self, post):
         """
         Returns the dendrite of a postsynaptic neuron according to its rank.
 
         :param post: can be either the rank or the coordinates of the post-synaptic neuron.
         """
         if not self.initialized:
-            Global._error('dendrites can only be accessed after compilation.')
+            Messages._error('dendrites can only be accessed after compilation.')
 
         if isinstance(post, int):
             rank = post
         else:
             rank = self.post.rank_from_coordinates(post)
 
         if rank in self.post_ranks:
             return Dendrite(self, rank, self.post_ranks.index(rank))
         else:
-            Global._error(" The neuron of rank "+ str(rank) + " has no dendrite in this projection.", exit=True)
+            Messages._error(" The neuron of rank "+ str(rank) + " has no dendrite in this projection.", exit=True)
 
 
     def synapse(self, pre, post):
         """
         Returns the synapse between a pre- and a post-synaptic neuron if it exists, None otherwise.
 
         :param pre: rank of the pre-synaptic neuron.
         :param post: rank of the post-synaptic neuron.
         """
         if not isinstance(pre, int) or not isinstance(post, int):
-            Global._error('Projection.synapse() only accepts ranks for the pre and post neurons.')
+            Messages._error('Projection.synapse() only accepts ranks for the pre and post neurons.')
 
         return self.dendrite(post).synapse(pre)
 
 
     # Iterators
     def __getitem__(self, *args, **kwds):
         # Returns dendrite of the given position in the postsynaptic population.
@@ -830,22 +856,22 @@
 
         # A list is given
         if isinstance(value, list):
             if len(value) == len(self.post_ranks):
                 if attribute in self.synapse_type.description['local']:
                     for idx, n in enumerate(self.post_ranks):
                         if not len(value[idx]) == self.cyInstance.dendrite_size(idx):
-                            Global._error('The post-synaptic neuron ' + str(n) + ' of population ' + str(self.post.id) + ' receives '+ str(self.cyInstance.dendrite_size(idx))+ ' synapses and not ' + str(len(value[idx])) + '.')
+                            Messages._erroror('The post-synaptic neuron ' + str(n) + ' of population ' + str(self.post.id) + ' receives '+ str(self.cyInstance.dendrite_size(idx))+ ' synapses and not ' + str(len(value[idx])) + '.')
                         self.cyInstance.set_local_attribute_row(attribute, idx, value[idx], ctype)
                 elif attribute in self.synapse_type.description['semiglobal']:
                     self.cyInstance.set_semiglobal_attribute_all(attribute, value, ctype)
                 else:
-                    Global._error('The parameter', attribute, 'is global to the population, cannot assign a list.')
+                    Messages._error('The parameter', attribute, 'is global to the population, cannot assign a list.')
             else:
-                Global._error('The projection has', self.size, 'post-synaptic neurons, the list must have the same size.')
+                Messages._error('The projection has', self.size, 'post-synaptic neurons, the list must have the same size.')
 
         # A Random Distribution is given
         elif isinstance(value, RandomDistribution):
             if attribute == "w" and self._has_single_weight():
                 self.cyInstance.set_global_attribute(attribute, value.get_values(1), ctype)
             elif attribute in self.synapse_type.description['local']:
                 for idx, n in enumerate(self.post_ranks):
@@ -895,37 +921,37 @@
 
     ################################
     ## Access to delays
     ################################
     def _get_delay(self):
         if not hasattr(self.cyInstance, 'get_delay'):
             if self.max_delay <= 1 :
-                return Global.config['dt']
+                return get_global_config('dt')
         elif self.uniform_delay != -1:
-                return self.uniform_delay * Global.config['dt']
+                return self.uniform_delay * get_global_config('dt')
         else:
-            return [[pre * Global.config['dt'] for pre in post] for post in self.cyInstance.get_delay()]
+            return [[pre * get_global_config('dt') for pre in post] for post in self.cyInstance.get_delay()]
 
     def _set_delay(self, value):
 
         if self.cyInstance: # After compile()
             if not hasattr(self.cyInstance, 'get_delay'):
-                if self.max_delay <= 1 and value != Global.config['dt']:
-                    Global._error("set_delay: the projection was instantiated without delays, it is too late to create them...")
+                if self.max_delay <= 1 and value != get_global_config('dt'):
+                    Messages._error("set_delay: the projection was instantiated without delays, it is too late to create them...")
 
             elif self.uniform_delay != -1:
                 if isinstance(value, np.ndarray):
                     if value.ndim > 0:
-                        Global._error("set_delay: the projection was instantiated with uniform delays, it is too late to load non-uniform values...")
+                        Messages._error("set_delay: the projection was instantiated with uniform delays, it is too late to load non-uniform values...")
                     else:
-                        value = max(1, round(float(value)/Global.config['dt']))
+                        value = max(1, round(float(value)/get_global_config('dt')))
                 elif isinstance(value, (float, int)):
-                    value = max(1, round(float(value)/Global.config['dt']))
+                    value = max(1, round(float(value)/get_global_config('dt')))
                 else:
-                    Global._error("set_delay: only float, int or np.array values are possible.")
+                    Messages._error("set_delay: only float, int or np.array values are possible.")
 
                 # The new max_delay is higher than before
                 if value > self.max_delay:
                     self.max_delay = value
                     self.uniform_delay = value
                     self.cyInstance.set_delay(value)
                     if isinstance(self.pre, PopulationView):
@@ -937,28 +963,28 @@
                     return
                 else:
                     self.uniform_delay = value
                     self.cyInstance.set_delay(value)
 
             else: # variable delays
                 if not isinstance(value, (np.ndarray, list)):
-                    Global._error("set_delay with variable delays: you must provide a list of lists of exactly the same size as before.")
+                    Messages._error("set_delay with variable delays: you must provide a list of lists of exactly the same size as before.")
 
                 # Check the number of delays
                 nb_values = sum([len(s) for s in value])
                 if nb_values != self.nb_synapses:
-                    Global._error("set_delay with variable delays: the sizes do not match. You have to provide one value for each existing synapse.")
+                    Messages._error("set_delay with variable delays: the sizes do not match. You have to provide one value for each existing synapse.")
                 if len(value) != len(self.post_ranks):
-                    Global._error("set_delay with variable delays: the sizes do not match. You have to provide one value for each existing synapse.")
+                    Messages._error("set_delay with variable delays: the sizes do not match. You have to provide one value for each existing synapse.")
 
                 # Convert to steps
                 if isinstance(value, np.ndarray):
-                    delays = [[max(1, round(value[i, j]/Global.config['dt'])) for j in range(value.shape[1])] for i in range(value.shape[0])]
+                    delays = [[max(1, round(value[i, j]/get_global_config('dt'))) for j in range(value.shape[1])] for i in range(value.shape[0])]
                 else:
-                    delays = [[max(1, round(v/Global.config['dt'])) for v in c] for c in value]
+                    delays = [[max(1, round(v/get_global_config('dt'))) for v in c] for c in value]
 
                 # Max delay
                 max_delay = max([max(l) for l in delays])
 
                 if max_delay > self.max_delay:
                     self.max_delay = max_delay
 
@@ -973,24 +999,24 @@
                 # Send the new values to the projection
                 self.cyInstance.set_delay(delays)
 
                 # Update ring buffers (if there exist)
                 self.cyInstance.update_max_delay(self.max_delay)
 
         else: # before compile()
-            Global._error("set_delay before compile(): not implemented yet.")
+            Messages._error("set_delay before compile(): not implemented yet.")
 
 
     ################################
     ## Access to functions
     ################################
     def _function(self, func):
         "Access a user defined function"
         if not self.initialized:
-            Global._error('the network is not compiled yet, cannot access the function ' + func)
+            Messages._error('the network is not compiled yet, cannot access the function ' + func)
 
         return getattr(self.cyInstance, func)
 
     ################################
     ## Learning flags
     ################################
     def enable_learning(self, period=None, offset=None):
@@ -1010,34 +1036,34 @@
         :param period: determines how often the synaptic variables will be updated.
         :param offset: determines the offset at which the synaptic variables will be updated relative to the current time.
 
         """
         # Check arguments
         if not period is None and not offset is None:
             if offset >= period:
-                Global._error('enable_learning(): the offset must be smaller than the period.')
+                Messages._error('enable_learning(): the offset must be smaller than the period.')
 
         if period is None and not offset is None:
-            Global._error('enable_learning(): if you define an offset, you have to define a period.')
+            Messages._error('enable_learning(): if you define an offset, you have to define a period.')
 
         try:
             self.cyInstance._set_update(True)
             self.cyInstance._set_plasticity(True)
             if period != None:
-                self.cyInstance._set_update_period(int(period/Global.config['dt']))
+                self.cyInstance._set_update_period(int(period/get_global_config('dt')))
             else:
                 self.cyInstance._set_update_period(int(1))
-                period = Global.config['dt']
+                period = get_global_config('dt')
             if offset != None:
                 relative_offset = Global.get_time() % period + offset
-                self.cyInstance._set_update_offset(int(int(relative_offset%period)/Global.config['dt']))
+                self.cyInstance._set_update_offset(int(int(relative_offset%period)/get_global_config('dt')))
             else:
                 self.cyInstance._set_update_offset(int(0))
         except:
-            Global._warning('Enable_learning() is only possible after compile()')
+            Messages._warning('Enable_learning() is only possible after compile()')
 
     def disable_learning(self, update=None):
         """
         Disables learning for all synapses of this projection.
 
         The effect depends on the rate-coded or spiking nature of the projection:
 
@@ -1049,15 +1075,15 @@
         """
         try:
             if self.synapse_type.type == 'rate':
                 self.cyInstance._set_update(False)
             else:
                 self.cyInstance._set_plasticity(False)
         except:
-            Global._warning('disabling learning is only possible after compile().')
+            Messages._warning('disabling learning is only possible after compile().')
 
 
     ################################
     ## Methods on connectivity matrix
     ################################
 
     def save_connectivity(self, filename):
@@ -1081,23 +1107,23 @@
         * Otherwise, the data will be pickled into a simple binary text file using pickle.
 
         :param filename: file name, may contain relative or absolute path.
 
         """
         # Check that the network is compiled
         if not self.initialized:
-            Global._error('save_connectivity(): the network has not been compiled yet.')
+            Messages._error('save_connectivity(): the network has not been compiled yet.')
             return
 
         # Check if the repertory exist
         (path, fname) = os.path.split(filename)
 
         if not path == '':
             if not os.path.isdir(path):
-                Global._print('Creating folder', path)
+                Messages._print('Creating folder', path)
                 os.mkdir(path)
 
         extension = os.path.splitext(fname)[1]
 
         # Gathering the data
         data = {
             'name': self.name,
@@ -1109,100 +1135,100 @@
             'uniform_delay': self.uniform_delay,
             'size': self.size,
             'nb_synapses': self.cyInstance.nb_synapses()
         }
 
         # Save the data
         if extension == '.gz':
-            Global._print("Saving connectivity in gunzipped binary format...")
+            Messages._print("Saving connectivity in gunzipped binary format...")
             try:
                 import gzip
             except:
-                Global._error('gzip is not installed.')
+                Messages._error('gzip is not installed.')
                 return
             with gzip.open(filename, mode = 'wb') as w_file:
                 try:
                     pickle.dump(data, w_file, protocol=pickle.HIGHEST_PROTOCOL)
                 except Exception as e:
-                    Global._print('Error while saving in gzipped binary format.')
-                    Global._print(e)
+                    Messages._print('Error while saving in gzipped binary format.')
+                    Messages._print(e)
                     return
 
         elif extension == '.npz':
-            Global._print("Saving connectivity in Numpy format...")
+            Messages._print("Saving connectivity in Numpy format...")
             np.savez_compressed(filename, **data )
 
         elif extension == '.mat':
-            Global._print("Saving connectivity in Matlab format...")
+            Messages._print("Saving connectivity in Matlab format...")
             if data['delay'] is None:
                 data['delay'] = 0
             try:
                 import scipy.io as sio
                 sio.savemat(filename, data)
             except Exception as e:
-                Global._error('Error while saving in Matlab format.')
-                Global._print(e)
+                Messages._error('Error while saving in Matlab format.')
+                Messages._print(e)
                 return
 
         else:
-            Global._print("Saving connectivity in text format...")
+            Messages._print("Saving connectivity in text format...")
             # save in Pythons pickle format
             with open(filename, mode = 'wb') as w_file:
                 try:
                     pickle.dump(data, w_file, protocol=pickle.HIGHEST_PROTOCOL)
                 except Exception as e:
-                    Global._print('Error while saving in text format.')
-                    Global._print(e)
+                    Messages._print('Error while saving in text format.')
+                    Messages._print(e)
                     return
             return
 
-    def receptive_fields(self, variable = 'w', in_post_geometry = True):
+    def receptive_fields(self, variable:str='w', in_post_geometry:bool =True) -> np.ndarray:
         """
         Gathers all receptive fields within this projection.
 
-        :param variable: name of the variable
-        :param in_post_geometry: if False, the data will be plotted as square grid. (default = True)
+        :param variable: Name of the variable.
+        :param in_post_geometry: If False, the data will be plotted as square grid.
         """
         if in_post_geometry:
             x_size = self.post.geometry[1]
             y_size = self.post.geometry[0]
         else:
             x_size = int( math.floor(math.sqrt(self.post.size)) )
             y_size = int( math.ceil(math.sqrt(self.post.size)) )
 
 
         def get_rf(rank): # TODO: IMPROVE
             res = np.zeros( self.pre.size )
             for n in range(len(self.post_ranks)):
                 if self.post_ranks[n] == n:
                     pre_ranks = self.cyInstance.pre_rank(n)
-                    data = self.cyInstance.get_local_attribute_row(variable, rank, Global.config["precision"])
+                    data = self.cyInstance.get_local_attribute_row(variable, rank, get_global_config('precision'))
                     for j in range(len(pre_ranks)):
                         res[pre_ranks[j]] = data[j]
             return res.reshape(self.pre.geometry)
 
         res = np.zeros((1, x_size*self.pre.geometry[1]))
         for y in range ( y_size ):
             row = np.concatenate(  [ get_rf(self.post.rank_from_coordinates( (y, x) ) ) for x in range ( x_size ) ], axis = 1)
             res = np.concatenate((res, row))
 
         return res
 
-    def connectivity_matrix(self, fill=0.0):
+    def connectivity_matrix(self, fill:float=0.0):
         """
         Returns a dense connectivity matrix (2D Numpy array) representing the connections between the pre- and post-populations.
 
         The first index of the matrix represents post-synaptic neurons, the second the pre-synaptic ones.
 
         If PopulationViews were used for creating the projection, the matrix is expanded to the whole populations by default.
 
         :param fill: value to put in the matrix when there is no connection (default: 0.0).
         """
         if not self.initialized:
-            Global._error('The connectivity matrix can only be accessed after compilation')
+            Messages._error('The connectivity matrix can only be accessed after compilation')
 
         # get correct dimensions for dense matrix
         if isinstance(self.pre, PopulationView):
             size_pre = self.pre.population.size
         else:
             size_pre = self.pre.size
         if isinstance(self.post, PopulationView):
@@ -1220,32 +1246,32 @@
                 idx = rank
             else:
                 idx =  self.post_ranks.index(rank)
             # pre-ranks
             preranks = self.cyInstance.pre_rank(idx)
             # get the values
             if "w" in self.synapse_type.description['local'] and (not self._has_single_weight()):
-                w = self.cyInstance.get_local_attribute_row("w", idx, Global.config["precision"])
+                w = self.cyInstance.get_local_attribute_row("w", idx, get_global_config('precision'))
             elif "w" in self.synapse_type.description['semiglobal']:
-                w = self.cyInstance.get_semiglobal_attribute("w", idx, Global.config["precision"])*np.ones(self.cyInstance.dendrite_size(idx))
+                w = self.cyInstance.get_semiglobal_attribute("w", idx, get_global_config('precision'))*np.ones(self.cyInstance.dendrite_size(idx))
             else:
-                w = self.cyInstance.get_global_attribute("w", Global.config["precision"])*np.ones(self.cyInstance.dendrite_size(idx))
+                w = self.cyInstance.get_global_attribute("w", get_global_config('precision'))*np.ones(self.cyInstance.dendrite_size(idx))
             res[rank, preranks] = w
         return res
 
 
     ################################
     ## Save/load methods
     ################################
 
     def _data(self):
         "Method gathering all info about the projection when calling save()"
 
         if not self.initialized:
-            Global._error('save_connectivity(): the network has not been compiled yet.')
+            Messages._error('save_connectivity(): the network has not been compiled yet.')
 
         desc = {}
         desc['name'] = self.name
         desc['pre'] = self.pre.name
         desc['post'] = self.post.name
         desc['target'] = self.target
         desc['post_ranks'] = self.post_ranks
@@ -1288,62 +1314,63 @@
                     else:
                         desc[var] = self.cyInstance.get_local_attribute_all(var, ctype)
                 elif var in self.synapse_type.description['semiglobal']:
                     desc[var] = self.cyInstance.get_semiglobal_attribute_all(var, ctype)
                 else:
                     desc[var] = self.cyInstance.get_global_attribute(var, ctype) # linear array or single constant
             except:
-                Global._warning('Can not save the attribute ' + var + ' in the projection.')
+                Messages._warning('Can not save the attribute ' + var + ' in the projection.')
 
         return desc
 
-    def save(self, filename):
+    def save(self, filename:str):
         """
         Saves all information about the projection (connectivity, current value of parameters and variables) into a file.
 
         * If the file name is '.npz', the data will be saved and compressed using `np.savez_compressed` (recommended).
 
         * If the file name ends with '.gz', the data will be pickled into a binary file and compressed using gzip.
 
         * If the file name is '.mat', the data will be saved as a Matlab 7.2 file. Scipy must be installed.
 
         * Otherwise, the data will be pickled into a simple binary text file using pickle.
 
-        :param filename: file name, may contain relative or absolute path.
-
         **Warning:** the '.mat' data will not be loadable by ANNarchy, it is only for external analysis purpose.
 
         Example:
 
         ```python
         proj.save('proj1.npz')
         proj.save('proj1.txt')
         proj.save('proj1.txt.gz')
         proj.save('proj1.mat')
         ```
+
+        :param filename: file name, may contain relative or absolute path.
         """
         from ANNarchy.core.IO import _save_data
         _save_data(filename, self._data())
 
 
-    def load(self, filename, pickle_encoding=None):
+    def load(self, filename:str, pickle_encoding:str=None)  -> None:
         """
         Loads the saved state of the projection by `Projection.save()`.
 
         Warning: Matlab data can not be loaded.
 
         Example:
 
         ```python
         proj.load('proj1.npz')
         proj.load('proj1.txt')
         proj.load('proj1.txt.gz')
         ```
 
         :param filename: the file name with relative or absolute path.
+        :param pickle_encoding: What encoding to use when reading Python 2 strings. Only useful when loading Python 2 generated pickled files in Python 3, which includes npy/npz files containing object arrays. Values other than `latin1`, `ASCII`, and `bytes` are not allowed, as they can corrupt numerical data. 
         """
         from ANNarchy.core.IO import _load_connectivity_data
         self._load_proj_data(_load_connectivity_data(filename, pickle_encoding))
 
 
     def _load_proj_data(self, desc):
         """
@@ -1356,26 +1383,41 @@
 
         # If it's not saveable there is nothing to load
         if not self._saveable:
             return
 
         # Check deprecation
         if not 'attributes' in desc.keys():
-            Global._error('The file was saved using a deprecated version of ANNarchy.')
+            Messages._error('The file was saved using a deprecated version of ANNarchy.')
             return
         if 'dendrites' in desc: # Saved before 4.5.3
-            Global._error("The file was saved using a deprecated version of ANNarchy.")
+            Messages._error("The file was saved using a deprecated version of ANNarchy.")
             return
 
         # If the post ranks and/or pre-ranks have changed, overwrite
         connectivity_changed=False
+        # check the post-ranks
         if 'post_ranks' in desc and not np.all((desc['post_ranks']) == self.post_ranks):
             connectivity_changed=True
-        if 'pre_ranks' in desc and not np.all((desc['pre_ranks']) == np.array(self.cyInstance.pre_rank_all(), dtype=object)):
-            connectivity_changed=True
+        # pre-ranks are stored as two-dimensional structure, however, dependent on the length
+        # of inner vectors we have two cases: all equal-lengthed (two-dim matrix) or varying (ragged array)
+        if 'pre_ranks' in desc:
+            current_pre_ranks = np.array(self.cyInstance.pre_rank_all(), dtype=object)
+
+            # one array is ragged the other two-dimensional
+            if desc['pre_ranks'].ndim != current_pre_ranks.ndim:
+                connectivity_changed = True
+
+            # both matrices are two-dimensional
+            elif desc['pre_ranks'].shape != current_pre_ranks.shape:
+                connectivity_changed = True
+
+            # compare two ragged arrays
+            elif not np.all((desc['pre_ranks']) == current_pre_ranks):
+                connectivity_changed = True
 
         # synaptic weights
         weights = desc["w"]
 
         # Delays can be either uniform (int, float) or non-uniform (np.ndarray).
         # HD (30th May 2022):
         #   Unfortunately, the storage of constants changed over the time. At the
@@ -1405,15 +1447,17 @@
         # Some patterns like fixed_number_pre/post or fixed_probability change the
         # connectivity. If this is not the case, we can simply set the values.
         if connectivity_changed:
             # (re-)initialize connectivity
             if isinstance(delays, (float, int)):
                 delays = [[delays]] # wrapper expects list from list
 
-            self.cyInstance.init_from_lil(desc['post_ranks'], desc['pre_ranks'], weights, delays)
+            # HD (14th May 2024): we load possibly old files prior to ANNarchy 4.8.0, so for safety reasons
+            #                     I set requires_sorting to True here (should be set to false in later releases!)
+            self.cyInstance.init_from_lil(desc['post_ranks'], desc['pre_ranks'], weights, delays, True)
         else:
             # set weights
             self._set_cython_attribute("w", weights)
 
             # set delays if there were some
             self._set_delay(delays)
 
@@ -1421,128 +1465,128 @@
         for var in desc['attributes']:
             if var == "w":
                 continue # already done
 
             try:
                 self._set_cython_attribute(var, desc[var])
             except Exception as e:
-                Global._print(e)
-                Global._warning('load(): the variable', var, 'does not exist in the current version of the network, skipping it.')
+                Messages._print(e)
+                Messages._warning('load(): the variable', var, 'does not exist in the current version of the network, skipping it.')
                 continue
 
+        if connectivity_changed and not get_global_config("suppress_warnings"):
+            Messages._info("Loading connectivity was successful, note that stored in save file diverges from the initial state ... (Projection{id} - {name})".format(id = self.id, name = self.name))
+
     ################################
     ## Structural plasticity
     ################################
-    def start_pruning(self, period=None):
+    def start_pruning(self, period:float=None) -> None:
         """
         Starts pruning the synapses in the projection if the synapse defines a 'pruning' argument.
 
         'structural_plasticity' must be set to True in setup().
 
         :param period: how often pruning should be evaluated (default: dt, i.e. each step)
         """
         if not period:
-            period = Global.config['dt']
+            period = get_global_config('dt')
         if not self.cyInstance:
-            Global._error('Can not start pruning if the network is not compiled.')
+            Messages._error('Can not start pruning if the network is not compiled.')
 
-        if Global.config['structural_plasticity']:
+        if get_global_config('structural_plasticity'):
             try:
-                self.cyInstance.start_pruning(int(period/Global.config['dt']), Global.get_current_step())
+                self.cyInstance.start_pruning(int(period/get_global_config('dt')), Global.get_current_step())
             except :
-                Global._error("The synapse does not define a 'pruning' argument.")
+                Messages._error("The synapse does not define a 'pruning' argument.")
 
         else:
-            Global._error("You must set 'structural_plasticity' to True in setup() to start pruning connections.")
+            Messages._error("You must set 'structural_plasticity' to True in setup() to start pruning connections.")
 
 
-    def stop_pruning(self):
+    def stop_pruning(self) -> None:
         """
         Stops pruning the synapses in the projection if the synapse defines a 'pruning' argument.
 
-        'structural_plasticity' must be set to True in setup().
+        'structural_plasticity' must be set to True in `setup()`.
         """
         if not self.cyInstance:
-            Global._error('Can not stop pruning if the network is not compiled.')
+            Messages._error('Can not stop pruning if the network is not compiled.')
 
-        if Global.config['structural_plasticity']:
+        if get_global_config('structural_plasticity'):
             try:
                 self.cyInstance.stop_pruning()
             except:
-                Global._error("The synapse does not define a 'pruning' argument.")
+                Messages._error("The synapse does not define a 'pruning' argument.")
 
         else:
-            Global._error("You must set 'structural_plasticity' to True in setup() to start pruning connections.")
+            Messages._error("You must set 'structural_plasticity' to True in setup() to start pruning connections.")
 
-    def start_creating(self, period=None):
+    def start_creating(self, period:float=None) -> None:
         """
         Starts creating the synapses in the projection if the synapse defines a 'creating' argument.
 
         'structural_plasticity' must be set to True in setup().
 
         :param period: how often creating should be evaluated (default: dt, i.e. each step)
         """
         if not period:
-            period = Global.config['dt']
+            period = get_global_config('dt')
         if not self.cyInstance:
-            Global._error('Can not start creating if the network is not compiled.')
+            Messages._error('Can not start creating if the network is not compiled.')
 
-        if Global.config['structural_plasticity']:
+        if get_global_config('structural_plasticity'):
             try:
-                self.cyInstance.start_creating(int(period/Global.config['dt']), Global.get_current_step())
+                self.cyInstance.start_creating(int(period/get_global_config('dt')), Global.get_current_step())
             except:
-                Global._error("The synapse does not define a 'creating' argument.")
+                Messages._error("The synapse does not define a 'creating' argument.")
 
         else:
-            Global._error("You must set 'structural_plasticity' to True in setup() to start creating connections.")
+            Messages._error("You must set 'structural_plasticity' to True in setup() to start creating connections.")
 
-    def stop_creating(self):
+    def stop_creating(self) -> None:
         """
         Stops creating the synapses in the projection if the synapse defines a 'creating' argument.
 
         'structural_plasticity' must be set to True in setup().
         """
         if not self.cyInstance:
-            Global._error('Can not stop creating if the network is not compiled.')
+            Messages._error('Can not stop creating if the network is not compiled.')
 
-        if Global.config['structural_plasticity']:
+        if get_global_config('structural_plasticity'):
             try:
                 self.cyInstance.stop_creating()
             except:
-                Global._error("The synapse does not define a 'creating' argument.")
+                Messages._error("The synapse does not define a 'creating' argument.")
 
         else:
-            Global._error("You must set 'structural_plasticity' to True in setup() to start creating connections.")
+            Messages._error("You must set 'structural_plasticity' to True in setup() to start creating connections.")
 
     ################################
     # Paradigm specific functions
     ################################
-    def update_launch_config(self, nb_blocks=-1, threads_per_block=32):
+    def update_launch_config(self, nb_blocks:int=-1, threads_per_block:int=32) -> None:
         """
-        Since ANNarchy 4.7.2 we allow the adjustment of the CUDA launch config.
-
-        Parameters:
+        Allows the adjustment of the CUDA launch config (since 4.7.2).
 
-        :nb_blocks:         number of CUDA blocks which can be 65535 at maximum. If set to -1 the number
-                            of launched blocks is computed by ANNarchy.
-        :threads_per_block: number of CUDA threads for one block which can be maximum 1024.
+        :param nb_blocks: number of CUDA blocks which can be 65535 at maximum. If set to -1, the number of launched blocks is computed by ANNarchy.
+        :param threads_per_block: number of CUDA threads for one block which can be maximally 1024.
         """
-        if not Global._check_paradigm("cuda"):
-            Global._warning("Projection.update_launch_config() is intended for usage on CUDA devices")
+        if not _check_paradigm("cuda"):
+            Messages._warning("Projection.update_launch_config() is intended for usage on CUDA devices")
             return
 
         if self.initialized:
             self.cyInstance.update_launch_config(nb_blocks=nb_blocks, threads_per_block=threads_per_block)
         else:
-            Global._error("Projection.update_launch_config() should be called after compile()")
+            Messages._error("Projection.update_launch_config() should be called after compile()")
 
     ################################
     ## Memory Management
     ################################
-    def size_in_bytes(self):
+    def size_in_bytes(self) -> int:
         """
         Returns the size in bytes of the allocated memory on C++ side. Note that this does not reflect monitored data and that it only works after compile() was invoked.
         """
         if self.initialized:
             return self.cyInstance.size_in_bytes()
         else:
             return 0
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/Random.py` & `annarchy-4.8.0.1/ANNarchy/core/Random.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 import numpy as np
-from ANNarchy.core import Global
+
+from ANNarchy.intern import Messages
 
 distributions_arguments = {
     'Uniform' : 2,
     'DiscreteUniform': 2,
     'Normal' : 2,
     'LogNormal': 2,
     'Exponential': 1,
@@ -34,15 +35,15 @@
     BaseClass for random distributions.
     """
 
     def get_values(self, shape):
         """
         Returns a np.ndarray with the given shape
         """
-        Global._error('instantiated base class RandomDistribution is not allowed.')
+        Messages._error('instantiated base class RandomDistribution is not allowed.')
         return np.array([0.0])
 
     def get_list_values(self, size):
         """
         Returns a list of the given size.
         """
         return list(self.get_values(size))
@@ -60,84 +61,94 @@
         return '?'
     
     def get_cpp_args(self):
         raise NotImplementedError
 
 class Uniform(RandomDistribution):
     """
-    Random distribution object using the uniform distribution between ``min`` and ``max``.
+    Uniform distribution between ``min`` and ``max``.
 
     The returned values are floats in the range [min, max].
+
+    :param min: minimum value.
+    :param max: maximum value.
     """
-    def __init__(self, min, max):
-        """
-        :param min: minimum value.
-        :param max: maximum value.
-        """
+    def __init__(self, min: float, max:float):
+
         self.min = min
         self.max = max
 
-    def get_values(self, shape):
+    def get_values(self, shape:tuple) -> np.ndarray:
         """
         Returns a Numpy array with the given shape.
+
+        :param shape: Shape of the array.
+        :returns: Array.
         """
         return np.random.uniform(self.min, self.max, shape)
 
     def latex(self):
         return "$\\mathcal{U}$(" + str(self.min) + ', ' + str(self.max) + ')'
 
     def get_cpp_args(self):
         return self.min, self.max
 
 class DiscreteUniform(RandomDistribution):
     """
-    Random distribution object using the discrete uniform distribution between ``min`` and ``max``.
+    Discrete uniform distribution between ``min`` and ``max``.
 
     The returned values are integers in the range [min, max].
+
+    :param min: minimum value.
+    :param max: maximum value.
     """
-    def __init__(self, min, max):
-        """
-        :param min: minimum value.
-        :param max: maximum value.
-        """
+    def __init__(self, min: int, max:int):
+
         self.min = min
         self.max = max
 
-    def get_values(self, shape):
+    def get_values(self, shape:tuple) -> np.ndarray:
         """
-        Returns a np.ndarray with the given shape.
+        Returns a Numpy array with the given shape.
+
+        :param shape: Shape of the array.
+        :returns: Array.
         """
         # randint draws from half-open interval [min, max)
         return np.random.randint(self.min, self.max+1, shape)
 
     def latex(self):
         return "$\\mathcal{U}$(" + str(self.min) + ', ' + str(self.max) + ')'
 
 
 class Normal(RandomDistribution):
     """
-    Random distribution instance returning a random value based on a normal (Gaussian) distribution.
+    Normal distribution.
+
+    :param mu: Mean of the distribution.
+    :param sigma: Standard deviation of the distribution.
+    :param min: Minimum value (default: unlimited).
+    :param max: Maximum value (default: unlimited).
     """
-    def __init__(self, mu, sigma, min=None, max=None):
-        """
-        :param mu: mean of the distribution.
-        :param sigma: standard deviation of the distribution.
-        :param min: minimum value (default: unlimited).
-        :param max: maximum value (default: unlimited).
-        """
+    def __init__(self, mu:float, sigma:float, min:float=None, max:float=None) -> None:
+
         if sigma < 0.0:
-            Global._error("Normal: the standard deviation sigma should be positive.")
+            Messages._error("Normal: the standard deviation sigma should be positive.")
+        
         self.mu = mu
         self.sigma = sigma
         self.min = min
         self.max = max
 
-    def get_values(self, shape):
+    def get_values(self, shape:tuple) -> np.ndarray:
         """
-        Returns a np.ndarray with the given shape
+        Returns a Numpy array with the given shape.
+
+        :param shape: Shape of the array.
+        :returns: Array.
         """
         data = np.random.normal(self.mu, self.sigma, shape)
         if self.min != None:
             data[data<self.min] = self.min
         if self.max != None:
             data[data>self.max] = self.max
         return data
@@ -146,33 +157,36 @@
         return "$\\mathcal{N}$(" + str(self.mu) + ', ' + str(self.sigma) + ')'
 
     def get_cpp_args(self):
         return self.mu, self.sigma
 
 class LogNormal(RandomDistribution):
     """
-    Random distribution instance returning a random value based on lognormal distribution.
+    Log-normal distribution.
+
+    :param mu: Mean of the distribution.
+    :param sigma: Standard deviation of the distribution.
+    :param min: Minimum value (default: unlimited).
+    :param max: Maximum value (default: unlimited).
     """
-    def __init__(self, mu, sigma, min=None, max=None):
-        """
-        :param mu: mean of the distribution.
-        :param sigma: standard deviation of the distribution.
-        :param min: minimum value (default: unlimited).
-        :param max: maximum value (default: unlimited).
-        """
+    def __init__(self, mu:float, sigma:float, min:float=None, max:float=None):
+
         if sigma < 0.0:
-            Global._error("LogNormal: the standard deviation sigma should be positive.")
+            Messages._error("LogNormal: the standard deviation sigma should be positive.")
         self.mu = mu
         self.sigma = sigma
         self.min = min
         self.max = max
 
-    def get_values(self, shape):
+    def get_values(self, shape:tuple) -> np.ndarray:
         """
-        Returns a np.ndarray with the given shape
+        Returns a Numpy array with the given shape.
+
+        :param shape: Shape of the array.
+        :returns: Array.
         """
         data = np.random.lognormal(self.mu, self.sigma, shape)
         if self.min != None:
             data[data<self.min] = self.min
         if self.max != None:
             data[data>self.max] = self.max
         return data
@@ -181,96 +195,105 @@
         return "$\\ln\\mathcal{N}$(" + str(self.mu) + ', ' + str(self.sigma) + ')'
 
     def get_cpp_args(self):
         return self.mu, self.sigma
 
 class Exponential(RandomDistribution):
     """
-    Random distribution instance returning a random value based on exponential distribution, according the density function:
+    Exponential distribution, according to the density function:
 
     $$P(x | \\lambda) = \\lambda e^{(-\\lambda x )}$$
 
-    """
-    def __init__(self, Lambda, min=None, max=None):
-        """
-        **Note:** ``Lambda`` is capitalized, otherwise it would be a reserved Python keyword.
+    **Note:** ``Lambda`` is capitalized, otherwise it would be a reserved Python keyword.
 
-        :param Lambda: rate parameter.
-        :param min: minimum value (default: unlimited).
-        :param max: maximum value (default: unlimited).
+    :param Lambda: rate parameter.
+    :param min: minimum value (default: unlimited).
+    :param max: maximum value (default: unlimited).
+    """
+    def __init__(self, Lambda:float, min:float=None, max:float=None):
 
-        """
         if Lambda < 0.0:
-            Global._error("Exponential: the rate parameter Lambda should be positive.")
+            Messages._error("Exponential: the rate parameter Lambda should be positive.")
+        
         self.Lambda = Lambda
         self.min = min
         self.max = max
 
-    def get_values(self, shape):
+    def get_values(self, shape:tuple) -> np.ndarray:
         """
-        Returns a np.ndarray with the given shape.
+        Returns a Numpy array with the given shape.
+
+        :param shape: Shape of the array.
+        :returns: Array.
         """
         data = np.random.exponential(self.Lambda, shape)
         if self.min != None:
             data[data<self.min] = self.min
         if self.max != None:
             data[data>self.max] = self.max
         return data
 
     def latex(self):
         return "$\\exp$(" + str(self.Lambda) + ')'
 
 class Gamma(RandomDistribution):
     """
-    Random distribution instance returning a random value based on gamma distribution.
+    Gamma distribution.
+
+    :param alpha: Shape of the gamma distribution.
+    :param beta: Scale of the gamma distribution.
+    :param min: Minimum value returned (default: unlimited).
+    :param max: Maximum value returned (default: unlimited).
     """
-    def __init__(self, alpha, beta=1.0, seed=-1, min=None, max=None):
-        """
-        :param alpha: shape of the gamma distribution
-        :param beta: scale of the gamma distribution
-        :param min: minimum value returned (default: unlimited).
-        :param max: maximum value returned (default: unlimited).
-        """
+    def __init__(self, alpha:float, beta:float=1.0, seed:int=-1, min:float=None, max:float=None):
+
         self.alpha = alpha
         self.beta = beta
         self.min = min
         self.max = max
 
-    def get_values(self, shape):
+    def get_values(self, shape:tuple) -> np.ndarray:
         """
-        Returns a np.ndarray with the given shape
+        Returns a Numpy array with the given shape.
+
+        :param shape: Shape of the array.
+        :returns: Array.
         """
         data = np.random.gamma(self.alpha, self.beta, shape)
         if self.min != None:
             data[data<self.min] = self.min
         if self.max != None:
             data[data>self.max] = self.max
         return data
 
     def latex(self):
         return "$\\Gamma$(" + str(self.alpha) + ', ' + str(self.beta) + ')'
         
 class Binomial(RandomDistribution):
     """
-    Random distribution object using the binomial distribution with specified parameters, n trials and p probability of success where n an integer >= 0 and p is in the interval [0,1].
+    Binomial distribution.
+    
+    Parameters: n trials and p probability of success where n an integer >= 0 and p is in the interval [0,1].
+
+    The returned values are the number of successes over the n trials.
 
-    The returned values are number of successes over the n trials.
+    :param n: Number of trials.
+    :param p: Probability of success.
     """
 
-    def __init__(self, n, p):
-        """
-        :param n: trials.
-        :param p: probability of success.
-        """
+    def __init__(self, n:int, p:float):
         self.n = n
         self.p = p
 
-    def get_values(self, shape):
+    def get_values(self, shape:tuple) -> np.ndarray:
         """
         Returns a Numpy array with the given shape.
+
+        :param shape: Shape of the array.
+        :returns: Array.
         """
         return np.random.binomial(self.n, self.p, size=shape)
 
     def latex(self):
         return "$\\mathcal{B}$(" + str(self.n) + ", " + str(self.p) + ")"
 
     def get_cpp_args(self):
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/Simulate.py` & `annarchy-4.8.0.1/ANNarchy/core/Simulate.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,137 +1,144 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-from .Global import _network
-from .Global import get_current_step, dt
-from .Global import _error, _print
+from ANNarchy.intern.NetworkManager import NetworkManager
+from ANNarchy.core import Global
+from ANNarchy.core.Population import Population
+
+from ANNarchy.intern.Profiler import Profiler
+from ANNarchy.intern import Messages
+
+
 from math import ceil
-import ANNarchy.core.Global as Global
 import time
 import operator
 
 # Callbacks
 _callbacks = [[]]
 _callbacks_enabled = [True]
 
 
-def simulate(duration, measure_time=False, progress_bar=False, callbacks=True, net_id=0):
+def simulate(
+        duration:float, 
+        measure_time:bool=False, 
+        progress_bar:bool=False, 
+        callbacks:bool=True, 
+        net_id:int=0) -> None:
     """
     Simulates the network for the given duration in milliseconds. 
     
     The number of simulation steps is computed relative to the discretization step ``dt`` declared in ``setup()`` (default: 1ms):
 
     ```python
     simulate(1000.0)
     ```
 
     :param duration: the duration in milliseconds.
-    :param measure_time: defines whether the simulation time should be printed. Default: False.
-    :param progress_bar: defines whether a progress bar should be printed. Default: False
-    :param callbacks: defines if the callback method (decorator ``every`` should be called). Default: True.
+    :param measure_time: defines whether the simulation time should be printed. 
+    :param progress_bar: defines whether a progress bar should be printed. 
+    :param callbacks: defines if the callback method (decorator ``every`` should be called).
+    :returns:
     """
-    if Global._profiler:
+    if Profiler().enabled:
         t0 = time.time()
 
-    if not _network[net_id]['instance']:
-        _error('simulate(): the network is not compiled yet.')
+    if not NetworkManager().cy_instance(net_id=net_id):
+        Messages._error('simulate(): the network is not compiled yet.')
 
     # Compute the number of steps
-    nb_steps = ceil(float(duration) / dt())
+    nb_steps = ceil(float(duration) / Global.dt())
 
     if measure_time:
         tstart = time.time()
 
     if callbacks and _callbacks_enabled[net_id] and len(_callbacks[net_id]) > 0:
         _simulate_with_callbacks(duration, progress_bar, net_id)
     else:
-        _network[net_id]['instance'].pyx_run(nb_steps, progress_bar)
+        NetworkManager().cy_instance(net_id=net_id).pyx_run(nb_steps, progress_bar)
 
     if measure_time:
         if net_id > 0:
-            _print('Simulating', duration/1000.0, 'seconds of the network', net_id, 'took', time.time() - tstart, 'seconds.')
+            Messages._print('Simulating', duration/1000.0, 'seconds of the network', net_id, 'took', time.time() - tstart, 'seconds.')
         else:
-            _print('Simulating', duration/1000.0, 'seconds of the network took', time.time() - tstart, 'seconds.')
+            Messages._print('Simulating', duration/1000.0, 'seconds of the network took', time.time() - tstart, 'seconds.')
 
     # Store the Python and C++ timings. Please note, that the C++ core
     # measures in ms and Python measures in s
-    if Global._profiler:
+    if Profiler().enabled:
         t1 = time.time()
-        Global._profiler.add_entry( t0, t1, "simulate", "simulate")
+        Profiler().add_entry( t0, t1, "simulate", "simulate")
 
         # network single step
-        overall_avg, _ = Global._profiler._cpp_profiler.get_timing("network", "step")
-        Global._profiler.add_entry(overall_avg * nb_steps, 100.0, "overall", "cpp core")
+        overall_avg, _ = Profiler()._cpp_profiler.get_timing("network", "step")
+        Profiler().add_entry(overall_avg * nb_steps, 100.0, "overall", "cpp core")
 
         # single operations for populations
-        for pop in _network[net_id]['populations']:
+        for pop in NetworkManager().get_populations(net_id=net_id):
             for func in ["step", "rng", "delay", "spike"]:
-                avg_time, _ = Global._profiler._cpp_profiler.get_timing(pop.name, func)
-                Global._profiler.add_entry( avg_time * nb_steps, (avg_time/overall_avg)*100.0, pop.name+"_"+func, "cpp core")
+                avg_time, _ = Profiler()._cpp_profiler.get_timing(pop.name, func)
+                Profiler().add_entry( avg_time * nb_steps, (avg_time/overall_avg)*100.0, pop.name+"_"+func, "cpp core")
 
         # single operations for projections
-        for proj in _network[net_id]['projections']:
+        for proj in NetworkManager().get_projections(net_id=net_id):
             for func in ["psp", "step", "post_event"]:
-                avg_time, _ = Global._profiler._cpp_profiler.get_timing(proj.name, func)
-                Global._profiler.add_entry( avg_time * nb_steps, (avg_time/overall_avg)*100.0, proj.name+"_"+func, "cpp core")
+                avg_time, _ = Profiler()._cpp_profiler.get_timing(proj.name, func)
+                Profiler().add_entry( avg_time * nb_steps, (avg_time/overall_avg)*100.0, proj.name+"_"+func, "cpp core")
 
-        monitor_avg, _ = Global._profiler._cpp_profiler.get_timing("network", "record")
-        Global._profiler.add_entry( monitor_avg * nb_steps, (monitor_avg/overall_avg)*100.0, "record", "cpp core")
+        monitor_avg, _ = Profiler()._cpp_profiler.get_timing("network", "record")
+        Profiler().add_entry( monitor_avg * nb_steps, (monitor_avg/overall_avg)*100.0, "record", "cpp core")
 
-def simulate_until(max_duration, population, operator='and', measure_time = False, net_id=0):
+def simulate_until(max_duration:float, population: Population | list[Population], operator='and', measure_time:bool = False, net_id:int=0):
     """
     Runs the network for the maximal duration in milliseconds. If the ``stop_condition`` defined in the population becomes true during the simulation, it is stopped.
 
     One can specify several populations. If the stop condition is true for any of the populations, the simulation will stop ('or' function).
 
     Example:
 
     ```python
     pop1 = Population( ..., stop_condition = "r > 1.0 : any")
     compile()
     simulate_until(max_duration=1000.0, population=pop1)
     ```
 
-    :param max_duration: the maximum duration of the simulation in milliseconds.
-    :param population: the (list of) population whose ``stop_condition`` should be checked to stop the simulation.
-    :param operator: operator to be used ('and' or 'or') when multiple populations are provided (default: 'and').
-    :param measure_time: defines whether the simulation time should be printed (default=False).
+    :param max_duration: Maximum duration of the simulation in milliseconds.
+    :param population: (list of) population(s) whose ``stop_condition`` should be checked to stop the simulation.
+    :param operator: Operator to be used ('and' or 'or') when multiple populations are provided (default: 'and').
+    :param measure_time: Defines whether the simulation time should be printed (default=False).
     :return: the actual duration of the simulation in milliseconds.
     """
-    if not _network[net_id]['instance']:
-        _error('simulate_until(): the network is not compiled yet.')
+    if NetworkManager().cy_instance(net_id):
+        Messages._error('simulate_until(): the network is not compiled yet.')
 
-
-    nb_steps = ceil(float(max_duration) / dt())
+    nb_steps = ceil(float(max_duration) / Global.dt())
     if not isinstance(population, list):
         population = [population]
 
-
     if measure_time:
         tstart = time.time()
 
-    nb = _network[net_id]['instance'].pyx_run_until(nb_steps, [pop.id for pop in population], True if operator=='and' else False)
+    nb = NetworkManager().cy_instance(net_id).pyx_run_until(nb_steps, [pop.id for pop in population], True if operator=='and' else False)
 
-    sim_time = float(nb) / dt()
+    sim_time = float(nb) / Global.dt()
     if measure_time:
-        _print('Simulating', nb/dt()/1000.0, 'seconds of the network took', time.time() - tstart, 'seconds.')
+        Messages._print('Simulating', nb/Global.dt()/1000.0, 'seconds of the network took', time.time() - tstart, 'seconds.')
     return sim_time
 
 
 def step(net_id=0):
     """
-    Performs a single simulation step (duration = ``dt``).
+    Performs a single simulation step (duration = `dt`).
     """
-    if not _network[net_id]['instance']:
-        _error('simulate_until(): the network is not compiled yet.')
+    if not NetworkManager().cy_instance(net_id):
+        Messages._error('simulate_until(): the network is not compiled yet.')
 
-
-    _network[net_id]['instance'].pyx_step()
+    NetworkManager().cy_instance(net_id).pyx_step()
 
 
 ################################
 ## Decorators
 ################################
 
 def callbacks_enabled(net_id=0):
@@ -179,66 +186,64 @@
 
     The method must accept only ``n`` as parameter (an integer being 0 the first time the method is called, and incremented afterwards) and can not return anything.
 
     The times at which the method is called are relative to the time when ``simulate()`` is called (if ``t`` is already 150 before calling ``simulate()``, the first call will then be made at ``t=240`` with the previous example).
 
     If multiple callbacks are defined, they will be called in the order of their declaration if they occur at the same time.
 
-    """
+    ``wait`` can be combined with ``offset``, so if ``period=100.``, ``offset=50.`` and ``wait=500.``, the first call will be made 550 ms after the call to ``simulate()`
+    
+    :param period: interval in ms between two calls to the function. If less than ``dt``, will be called every step.
+    :param offset: by default, the first call to the method will be made at the start of the simulation. The offset delays the call within the period (default: 0.0). Can be negative, in which case it will be counted from the end of the period.
+    :param wait: allows to wait for a certain amount of time (in ms) before starting to call the method.
 
-    def __init__(self, period, offset=0., wait=0.0, net_id=0):
-        """
-        :param period: interval in ms between two calls to the function. If less than ``dt``, will be called every step.
-        :param offset: by default, the first call to the method will be made at the start of the simulation. The offset delays the call within the period (default: 0.0). Can be negative, in which case it will be counted from the end of the period.
-        :param wait: allows to wait for a certain amount of time (in ms) before starting to call the method.
+    """
 
-        ``wait`` can be combined with ``offset``, so if ``period=100.``, ``offset=50.`` and ``wait=500.``, the first call will be made 550 ms after the call to ``simulate()``
+    def __init__(self, period:float, offset:float=0., wait:float=0.0, net_id:int=0) -> None:
 
-        """
-        self.period = max(float(period), dt())
+        self.period = max(float(period), Global.dt())
         self.offset = min(float(offset), self.period)
         self.wait = max(float(wait), 0.0)
         _callbacks[net_id].append(self)
 
     def __call__(self, f):
         
         # If there are decorator arguments, __call__() is only called
         # once, as part of the decoration process! You can only give
         # it a single argument, which is the function object.
-        
         self.func = f
         return f
 
 
 def _simulate_with_callbacks(duration, progress_bar, net_id=0):
     """
     Replaces simulate() when call_backs are defined.
     """
-    t_start = get_current_step(net_id)
-    length = int(duration/dt())
+    t_start = Global.get_current_step(net_id)
+    length = int(duration/Global.dt())
 
     # Compute the times
     times = []
     for c in _callbacks[net_id]:
-        period = int(c.period/dt())
-        offset = int(c.offset/dt()) % period
-        wait = int(c.wait/dt())
+        period = int(c.period/Global.dt())
+        offset = int(c.offset/Global.dt()) % period
+        wait = int(c.wait/Global.dt())
 
         moments = range(t_start + wait + offset, t_start + length, period)
         n = 0
         for m in moments:
             times.append((m, c, n))
             n += 1
 
     # Sort the times to be sure they are in the right order.
     times = sorted(times, key=operator.itemgetter(0))
 
     for time, callback, n in times:
         # Advance the simulation to the desired time
-        if time != get_current_step(net_id):
-            _network[net_id]['instance'].pyx_run(time-get_current_step(net_id), progress_bar)
+        if time != Global.get_current_step(net_id):
+            NetworkManager().cy_instance(net_id).pyx_run(time-Global.get_current_step(net_id), progress_bar)
         # Call the callback
         callback.func(n)
 
     # Go to the end of the duration
-    if get_current_step(net_id) < t_start + length:
-        _network[net_id]['instance'].pyx_run(t_start + length - get_current_step(net_id), progress_bar)
+    if Global.get_current_step(net_id) < t_start + length:
+        NetworkManager().cy_instance(net_id).pyx_run(t_start + length - Global.get_current_step(net_id), progress_bar)
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/SpecificProjection.py` & `annarchy-4.8.0.1/ANNarchy/extensions/diagonal/DiagonalProjection.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,343 +1,387 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 from ANNarchy.core.Projection import Projection
-from ANNarchy.core.PopulationView import PopulationView
-
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern import Messages
 import ANNarchy.core.Global as Global
 
-class SpecificProjection(Projection):
+import numpy as np
+
+
+class DiagonalProjection(Projection):
     """
-    Interface class for user-defined definition of Projection objects. An inheriting
-    class need to override the implementor functions _generate_[paradigm], otherwise
-    a NotImplementedError exception will be thrown.
+    Diagonal projection based on shared weights.
     """
-    def __init__(self, pre, post, target, synapse=None, name=None, copied=False):
+    def __init__(self, pre, post, target, name=None, copied=False):
         """
-        Initialization, receive parameters of Projection objects.
-
-        :param pre: pre-synaptic population.
-        :param post: post-synaptic population.
+        :param pre: pre-synaptic population (either its name or a ``Population`` object).
+        :param post: post-synaptic population (either its name or a ``Population`` object).
         :param target: type of the connection.
-        :param window: duration of the time window to collect spikes (default: dt).
         """
-        Projection.__init__(self, pre=pre, post=post, target=target, synapse=synapse, name=name, copied=copied)
-
-    def _generate(self):
-        """
-        Overridden method of Population, called during the code generation process.
-        This function selects dependent on the chosen paradigm the correct implementor
-        functions defined by the user.
-        """
-        if Global.config['paradigm'] == "openmp":
-            if Global.config["num_threads"] == 1:
-                self._generate_st()
-            else:
-                self._generate_omp()
-        elif Global.config['paradigm'] == "cuda":
-            self._generate_cuda()
-        else:
-            raise NotImplementedError
+        # Create the description, but it will not be used for generation
+        Projection.__init__(
+            self, 
+            pre,
+            post,
+            target,
+            name=name,
+            copied=copied
+        )
 
-    def _generate_omp(self):
-        """
-        Intended to be overridden by child class. Implememt code adjustments intended for single thread and openMP paradigm.
-        """
-        raise NotImplementedError
+    def _copy(self, pre, post):
+        "Returns a copy of the projection when creating networks.  Internal use only."
+        return DiagonalProjection(pre=pre, post=post, target=self.target, name=self.name, copied=True)
 
-    def _generate_cuda(self):
+    def connect(self, weights, delays = get_global_config('dt'), offset=0, slope=1):
         """
-        Intended to be overridden by child class. Implememt code adjustments intended for CUDA paradigm.
-        """
-        raise NotImplementedError
-
-class DecodingProjection(SpecificProjection):
-    """
-    Decoding projection to transform spike trains into firing rates.
-
-    The pre-synaptic population must be a spiking population, while the post-synaptic one must be rate-coded.
-
-    Pre-synaptic spikes are accumulated for each post-synaptic neuron. A sliding window can be used to smoothen the results with the ``window`` parameter.
-
-    The decoded firing rate is accessible in the post-synaptic neurons with ``sum(target)``.
-
-    The projection can be connected using any method available in ``Projection`` (although all-to-all or many-to-one makes mostly sense). Delays are ignored.
+        Creates the diagonal connection pattern.
 
-    The weight value allows to scale the firing rate: if you want a pre-synaptic firing rate of 100 Hz to correspond to a post-synaptic rate of 1.0, use ``w = 1./100.``.
+        :param weights: filter to be applied on each column (list or 1D Numpy array).
+        :param delays: transmission delays in ms (default: dt)
+        :param offset: start position for the diagonal for the post-neuron of first coordinate 0 (default: 0).
+        :param slope: slope of the diagonal (default: 1).
+        """
+        self.weights = weights
+        self.delays = delays
+        self.offset = offset
+        self.slope = slope
+
+        # create a fake CSR object
+        self._create()
+        return self
 
-    Example:
-
-    ```python
-    pop1 = PoissonPopulation(1000, rates=100.)
-    pop2 = Population(1, Neuron(equations="r=sum(exc)"))
-    proj = DecodingProjection(pop1, pop2, 'exc', window=10.0)
-    proj.connect_all_to_all(1.0, force_multiple_weights=True)
-    ```
+    def _generate(self):
+        # Generate the code
+        if self.pre.dimension == 2 and self.post.dimension == 2:
+            self._generate_omp_1d()
+        elif self.pre.dimension == 4 and self.post.dimension == 4:
+            self._generate_omp_2d_gaussian()
+        else:
+            Messages._error('The diagonal projection only works when both populations have 2 or 4 dimensions.')
+            
 
-    """
-    def __init__(self, pre, post, target, window=0.0, name=None, copied=False):
+    def connect_gaussian(self, amp, sigma, min_val, max_distance=0.0):
         """
-        :param pre: pre-synaptic population.
-        :param post: post-synaptic population.
-        :param target: type of the connection.
-        :param window: duration of the time window to collect spikes (default: dt).
-        """
-        # Instantiate the projection
-        SpecificProjection.__init__(self, pre, post, target, None, name, copied)
-
-        # Check populations
-        if not self.pre.neuron_type.type == 'spike':
-            Global._error('The pre-synaptic population of a DecodingProjection must be spiking.')
-
-        if not self.post.neuron_type.type == 'rate':
-            Global._error('The post-synaptic population of a DecodingProjection must be rate-coded.')
-
-        # Process window argument
-        if window == 0.0:
-            window = Global.config['dt']
-        self.window = window
-
-        # Disable openMP post-synaptic matrix split
-        self._no_split_matrix = True
-
-        # Not on CUDA
-        if Global._check_paradigm('cuda'):
-            Global._error('DecodingProjections are not available on CUDA yet.')
-
-    def _copy(self, pre, post):
-        "Returns a copy of the population when creating networks. Internal use only."
-        copied_proj = DecodingProjection(pre=pre, post=post, target=self.target, window=self.window, name=self.name, copied=True)
-        copied_proj._no_split_matrix = True
-        return copied_proj
+        Creates the diagonal connection pattern for 4D populations and Gaussian filter..
 
-    def _generate_st(self):
-        # Generate the code
-        self._specific_template['declare_additional'] = """
-    // Window
-    int window = %(window)s;
-    std::deque< std::vector< %(float_prec)s > > rates_history ;
-""" % { 'window': int(self.window/Global.config['dt']), 'float_prec': Global.config['precision'] }
-
-        self._specific_template['init_additional'] = """
-        rates_history = std::deque< std::vector< %(float_prec)s > >(%(window)s, std::vector< %(float_prec)s >(%(post_size)s, 0.0));
-""" % { 'window': int(self.window/Global.config['dt']),'post_size': self.post.size, 'float_prec': Global.config['precision'] }
-
-        self._specific_template['psp_code'] = """
-        if (pop%(id_post)s._active) {
-            std::vector< std::pair<int, int> > inv_post;
-            std::vector< %(float_prec)s > rates = std::vector< %(float_prec)s >(%(post_size)s, 0.0);
-            // Iterate over all incoming spikes
-            for(int _idx_j = 0; _idx_j < pop%(id_pre)s.spiked.size(); _idx_j++){
-                rk_j = pop%(id_pre)s.spiked[_idx_j];
-                inv_post = inv_pre_rank[rk_j];
-                nb_post = inv_post.size();
-                // Iterate over connected post neurons
-                for(int _idx_i = 0; _idx_i < nb_post; _idx_i++){
-                    // Retrieve the correct indices
-                    i = inv_post[_idx_i].first;
-                    j = inv_post[_idx_i].second;
-
-                    // Increase the post-synaptic conductance
-                    rates[post_rank[i]] +=  %(weight)s;
+        :param amp: maximal value of the Gaussian.
+        :param sigma: width of the Gaussian.
+        :param min_val: minimal value of the weight.
+        :param max_distance: maximal distance for the Gaussian.
+
+        """
+        self.amp = amp
+        self.sigma = sigma
+        self.min_val = min_val
+        self.max_distance = max_distance
+        self.weights = {}
+
+        if not(self.pre.dimension == 4 and self.post.dimension == 4):
+            Messages._error('The diagonal projection only works when both populations have 4 dimensions.')
+            
+
+        self.offset_w = (self.pre.geometry[0]-(self.pre.geometry[0]%2))/2.0
+        self.offset_h = (self.pre.geometry[1]-(self.pre.geometry[1]%2))/2.0
+        self.sigma_w = self.sigma * (self.post.geometry[2] - self.post.geometry[2]%2 )
+        self.sigma_h = self.sigma * (self.post.geometry[3] - self.post.geometry[3]%2 )
+
+        # for post2 in range(self.post.geometry[2]):
+        #     for post3 in range(self.post.geometry[3]):
+        #         for pre0 in range(self.pre.geometry[0]):
+        #             for pre1 in range(self.pre.geometry[1]):
+        #                 for pre2 in range(self.pre.geometry[2]):
+        #                     for pre3 in range(self.pre.geometry[3]):
+        #                         dist_w = (post2 - (pre0+pre2) + self.offset_w)
+        #                         dist_h = (post3 - (pre1+pre3) + self.offset_h)
+        #                         val = self.amp * np.exp(- (dist_w*dist_w/self.sigma_w/self.sigma_w + dist_h*dist_h/self.sigma_h/self.sigma_h) )
+        #                         self.weights[(dist_w, dist_h)] = val
+
+        for dist_w in range(int(self.offset_w) - self.pre.geometry[0] - self.pre.geometry[2], int(self.offset_w) + self.post.geometry[2]):
+            for dist_h in range(int(self.offset_h) - self.pre.geometry[1] - self.pre.geometry[3], int(self.offset_h) + self.post.geometry[3]):
+                val = self.amp * np.exp(- (dist_w*dist_w/self.sigma_w/self.sigma_w + dist_h*dist_h/self.sigma_h/self.sigma_h) )
+                self.weights[(dist_w, dist_h)] = val
+        
+        # create a fake CSR object
+        self._create()
+        return self
+
+
+
+    def _create(self):
+        # create fake CSR object, just for compilation.
+        try:
+            from ANNarchy.cython_ext.Connector import CSR
+        except:
+            Messages._error('ANNarchy was not successfully installed.')
+        csr = CSR()
+        csr.max_delay = 0
+        csr.uniform_delay = 0
+        self.connector_name = "Diagonal Projection"
+        self.connector_description = "Diagonal Projection"
+        self._store_connectivity(self._load_from_csr, (csr, ), 0)
+
+
+    def _connect(self, module):
+        """
+        Builds up dendrites either from list or dictionary. Called by instantiate().
+        """        
+        if not self._connection_method:
+            Messages._error('The projection between ' + self.pre.name + ' and ' + self.post.name + ' is declared but not connected.')
+            
+        # Create the Cython instance
+        proj = getattr(module, 'proj'+str(self.id)+'_wrapper')
+        self.cyInstance = proj(self.weights)
+
+        # Define the list of postsynaptic neurons
+        self.post_ranks = list(range(self.post.size))
+
+        return True
+
+    ################################
+    ### Code generation
+    ################################
+
+    def _generate_omp_1d(self):
+        """
+        Generate openMP template code.
+        """
+        # Specific template for generation
+        self._specific_template = {
+            # Declare the connectivity matrix
+            'declare_connectivity_matrix': """
+    std::vector<int> post_rank;
+    std::vector< %(float_prec)s > w;
+""" % {'float_prec': get_global_config('precision')},
+
+            # Accessors for the connectivity matrix
+            'access_connectivity_matrix': """
+    // Accessor to connectivity data
+    std::vector<int> get_post_rank() { return post_rank; }
+    void set_post_rank(std::vector<int> ranks) { post_rank = ranks; }
+    int dendrite_size(int n) { return w.size(); }
+    // Weights w
+    std::vector< %(float_prec)s > get_w() { return w; }
+    void set_w(std::vector< %(float_prec)s > _w) { w=_w; }
+""" % {'float_prec': get_global_config('precision')},
+
+            # Export the connectivity matrix
+            'export_connectivity': """
+        # Connectivity
+        vector[int] get_post_rank()
+        vector[vector[int]] get_pre_rank()
+        void set_post_rank(vector[int])
+        void set_pre_rank(vector[vector[int]])
+        vector[%(float_prec)s] get_w()
+        void set_w(vector[%(float_prec)s])
+""" % {'float_prec': get_global_config('precision')},
+
+            # Arguments to the wrapper constructor
+            'wrapper_args': "weights",
+
+            # Initialize the wrapper connectivity matrix
+            'wrapper_init_connectivity': """
+        proj%(id_proj)s.set_post_rank(list(range(%(size_post)s)))
+        proj%(id_proj)s.set_w(weights)
+""" % {'id_proj': self.id, 'size_post': self.post.size},
+
+            # Wrapper access to connectivity matrix
+            'wrapper_access_connectivity': """
+    # Connectivity
+    def post_rank(self):
+        return proj%(id_proj)s.get_post_rank()
+    def pre_rank(self, int n):
+        return 0
+""" % {'id_proj': self.id},
+
+            # Wrapper access to variables
+            'wrapper_access_parameters_variables' : "",
+
+            # Variables for the psp code
+            'psp_prefix': """
+        %(float_prec)s sum=0.0;"""
+        } % {'float_prec': get_global_config('precision')}
+
+        # Compute sum
+        dim_post_0 = self.post.geometry[0]
+        dim_post_1 = self.post.geometry[1]
+        dim_pre_0 = self.pre.geometry[0]
+        dim_pre_1 = self.pre.geometry[1]
+
+        # Pre-defined variables
+        wsum =  """
+        int _idx_0, _idx_1, _idx_f, _start;
+        std::vector<%(float_prec)s> _w = w;
+        std::vector<%(float_prec)s> _pre_r = pop%(id_pre)s.r;
+""" % {'float_prec': get_global_config('precision')}
+
+        # OpenMP statement
+        if get_global_config('num_threads') > 1:
+            wsum += """
+        #pragma omp for private(sum, _idx_0, _idx_1, _idx_f, _start) firstprivate(_w, _pre_r)"""
+
+        # Computation Kernel
+        wsum += """
+        for(int idx = 0; idx < %(dim_post_1)s; idx++){
+            sum = 0.0;
+            _start = (idx %(inc0)s %(offset)s ) ;
+            //std::cout << "Neuron: " << idx << " : " << _start << std::endl;
+            for(int idx_1 = 0; idx_1 < %(dim_pre_1)s; idx_1++){
+                _idx_0 = idx_1;
+                _idx_1 = _start + %(inc1)s idx_1;
+                if ((_idx_1 < 0) || (_idx_1 > %(dim_pre_1)s-1))
+                    continue;
+                //std::cout << _idx_0 << " " << _idx_1 << std::endl;
+                for(int idx_f=0; idx_f < %(size_filter)s; idx_f++){
+                    _idx_f = (_idx_1 + (idx_f - %(center_filter)s) );
+                    if ((_idx_f < 0) || (_idx_f > %(dim_pre_1)s-1))
+                        continue;
+                    sum += _w[idx_f] * _pre_r[_idx_f + %(dim_pre_1)s * _idx_0];
                 }
             }
-
-            rates_history.push_front(rates);
-            rates_history.pop_back();
-            for(int i=0; i<post_rank.size(); i++){
-                sum = 0.0;
-                for(int step=0; step<window; step++){
-                    sum += rates_history[step][post_rank[i]];
-                }
-                pop%(id_post)s._sum_%(target)s[post_rank[i]] += sum / %(float_prec)s(window) * 1000. / dt / %(float_prec)s(pre_rank[i].size());
+            for(int idx_1 = 0; idx_1 < %(dim_post_0)s; idx_1++){
+                pop%(id_post)s._sum_%(target)s[idx + %(dim_post_1)s*idx_1] += sum;
             }
-        } // active
-""" % { 'id_proj': self.id, 'id_pre': self.pre.id, 'id_post': self.post.id, 'target': self.target,
-        'post_size': self.post.size, 'float_prec': Global.config['precision'],
-        'weight': "w" if self._has_single_weight() else "w[i][j]"}
-
-        self._specific_template['psp_prefix'] = """
-        int nb_post, i, j, rk_j, rk_post, rk_pre;
-        %(float_prec)s sum;
-""" % { 'float_prec': Global.config['precision'] }
-
-    def _generate_omp(self):
-        # Generate the code
-        self._specific_template['declare_additional'] = """
-    // Window
-    int window = %(window)s;
-    std::deque< std::vector< %(float_prec)s > > rates_history ;
-""" % { 'window': int(self.window/Global.config['dt']), 'float_prec': Global.config['precision'] }
-
-        self._specific_template['init_additional'] = """
-        rates_history = std::deque< std::vector< %(float_prec)s > >(%(window)s, std::vector< %(float_prec)s >(%(post_size)s, 0.0));
-""" % { 'window': int(self.window/Global.config['dt']),'post_size': self.post.size, 'float_prec': Global.config['precision'] }
-
-        self._specific_template['psp_code'] = """
-        #pragma omp single
-        {
-            if (pop%(id_post)s._active) {
-                std::vector< std::pair<int, int> > inv_post;
-                std::vector< %(float_prec)s > rates = std::vector< %(float_prec)s >(%(post_size)s, 0.0);
-                // Iterate over all incoming spikes
-                for(int _idx_j = 0; _idx_j < pop%(id_pre)s.spiked.size(); _idx_j++){
-                    rk_j = pop%(id_pre)s.spiked[_idx_j];
-                    inv_post = inv_pre_rank[rk_j];
-                    nb_post = inv_post.size();
-                    // Iterate over connected post neurons
-                    for(int _idx_i = 0; _idx_i < nb_post; _idx_i++){
-                        // Retrieve the correct indices
-                        i = inv_post[_idx_i].first;
-                        j = inv_post[_idx_i].second;
+        }
+""" 
 
-                        // Increase the post-synaptic conductance
-                        rates[post_rank[i]] +=  %(weight)s;
-                    }
-                }
+        if self.slope == 1 :
+            inc0 = "-"
+            inc1 = ""             
+        elif self.slope > 1 :
+            inc0 = " - "
+            inc1 = str(self.slope) + '*'
+        elif self.slope == 0 :
+            inc0 = "-"
+            inc1 = '0*'
+        elif self.slope == -1 :
+            inc0 = "+"
+            inc1 = '-' 
+        else:
+            inc0 = "+"
+            inc1 = ' - ' + str(-self.slope) + '*'
 
-                rates_history.push_front(rates);
-                rates_history.pop_back();
-                for(int i=0; i<post_rank.size(); i++){
-                    sum = 0.0;
-                    for(int step=0; step<window; step++){
-                        sum += rates_history[step][post_rank[i]];
+        self._specific_template['psp_code'] = wsum % {'id_proj': self.id, 
+            'target': self.target,  
+            'id_pre': self.pre.id, 'name_pre': self.pre.name, 'size_pre': self.pre.size, 
+            'id_post': self.post.id, 'name_post': self.post.name, 'size_post': self.post.size,
+            'offset': self.offset,
+            'dim_post_0': dim_post_0, 'dim_post_1': dim_post_1,
+            'dim_pre_0': dim_pre_0, 'dim_pre_1': dim_pre_1,
+            'size_filter': len(self.weights),
+            'center_filter': int(len(self.weights)/2),
+            'inc0': inc0,
+            'inc1': inc1
+          }
+
+    def _generate_omp_2d_gaussian(self):
+        # Specific template for generation
+        self._specific_template = {
+            # Declare the connectivity matrix
+            'declare_connectivity_matrix': """
+    std::vector<int> post_rank;
+    std::map<std::pair<int, int>, %(float_prec)s > w ;
+""" % {'float_prec': get_global_config('precision')},
+
+            # Accessors for the connectivity matrix
+            'access_connectivity_matrix': """
+    // Accessor to connectivity data
+    std::vector<int> get_post_rank() { return post_rank; }
+    void set_post_rank(std::vector<int> ranks) { post_rank = ranks; }
+    int dendrite_size(int n) { return w.size(); }
+    // Weights w
+    std::map<std::pair<int, int>, %(float_prec)s > get_w() { return w; }
+    void set_w(std::map<std::pair<int, int>, %(float_prec)s > _w) { w=_w; }
+""" % {'float_prec': get_global_config('precision')},
+
+            # Export the connectivity matrix
+            'export_connectivity': """
+        # Connectivity
+        vector[int] get_post_rank()
+        vector[vector[int]] get_pre_rank()
+        void set_post_rank(vector[int])
+        void set_pre_rank(vector[vector[int]])
+        map[pair[int, int], %(float_prec)s] get_w()
+        void set_w(map[pair[int, int], %(float_prec)s])
+""" % {'float_prec': get_global_config('precision')},
+
+            # Arguments to the wrapper constructor
+            'wrapper_args': "weights",
+
+            # Initialize the wrapper connectivity matrix
+            'wrapper_init_connectivity': """
+        proj%(id_proj)s.set_post_rank(list(range(%(size_post)s)))
+        proj%(id_proj)s.set_w(weights)
+""" % {'id_proj': self.id, 'size_post': self.post.size},
+
+            # Wrapper access to connectivity matrix
+            'wrapper_access_connectivity': """
+    # Connectivity
+    def post_rank(self):
+        return proj%(id_proj)s.get_post_rank()
+    def pre_rank(self, int n):
+        return 0
+            """ % {'id_proj': self.id},
+
+            # Wrapper access to variables
+            'wrapper_access_parameters_variables' : "",
+
+            # Variables for the psp code
+            'psp_prefix': """
+        %(float_prec)s sum=0.0;"""
+        } % {'float_prec': get_global_config('precision')}
+
+        # Compute sum
+        wsum =  """
+        std::vector<%(float_prec)s> result(%(postdim2)s*%(postdim3)s, 0.0);""" % {'float_prec': get_global_config('precision')}
+
+        if get_global_config('num_threads') > 1:
+            wsum += """
+        #pragma omp for"""
+    
+        wsum += """
+        for(int post2 = 0; post2 < %(postdim2)s; post2++){
+            for(int post3 = 0; post3 < %(postdim3)s; post3++){
+                %(float_prec)s sum = 0.0;
+                for(int pre0 = 0; pre0 < %(predim0)s; pre0++){
+                    for(int pre1 = 0; pre1 < %(predim1)s; pre1++){
+                        for(int pre2 = 0; pre2 < %(predim2)s; pre2++){
+                            for(int pre3 = 0; pre3 < %(predim3)s; pre3++){
+                                int dist_w = post2 - (pre0+pre2) + %(offset_w)s;
+                                int dist_h = post3 - (pre1+pre3) + %(offset_h)s;
+                                %(float_prec)s val = proj%(id_proj)s.w[std::pair<int, int>(dist_w, dist_h)];
+                                if(val > %(min_val)s%(wgd)s){
+                                    sum += val * pop%(id_pre)s.r[pre3 + %(predim3)s * (pre2 + %(predim2)s*(pre1 + %(predim1)s * pre0))];
+                                }
+                            }
+                        }
                     }
-                    pop%(id_post)s._sum_%(target)s[post_rank[i]] += sum / %(float_prec)s(window) * 1000. / dt / %(float_prec)s(pre_rank[i].size());
                 }
-            } // active
-        }
-""" % { 'id_proj': self.id, 'id_pre': self.pre.id, 'id_post': self.post.id, 'target': self.target,
-        'post_size': self.post.size, 'float_prec': Global.config['precision'],
-        'weight': "w" if self._has_single_weight() else "w[i][j]"}
-
-        self._specific_template['psp_prefix'] = """
-        int nb_post, i, j, rk_j, rk_post, rk_pre;
-        %(float_prec)s sum;
-""" % { 'float_prec': Global.config['precision'] }
-
-    def _generate_cuda(self):
-        raise Global.ANNarchyException("The DecodingProjection is not available on CUDA devices.", True)
-
-class CurrentInjection(SpecificProjection):
-    """
-    Inject current from a rate-coded population into a spiking population.
-
-    The pre-synaptic population must be be rate-coded, the post-synaptic one must be spiking, both must have the same size and no plasticity is allowed.
-
-    For each post-synaptic neuron, the current ``g_target`` will be set at each time step to the firing rate ``r`` of the pre-synaptic neuron with the same rank.
-
-    The projection must be connected with ``connect_current()``, which takes no parameter and does not accept delays. It is equivalent to ``connect_one_to_one(weights=1)``.
-
-    Example:
-
-    ```python
-    inp = Population(100, Neuron(equations="r = sin(t)"))
-
-    pop = Population(100, Izhikevich)
-
-    proj = CurrentInjection(inp, pop, 'exc')
-    proj.connect_current()
-    ```
-
-    """
-    def __init__(self, pre, post, target, name=None, copied=False):
-        """
-        :param pre: pre-synaptic population.
-        :param post: post-synaptic population.
-        :param target: type of the connection.
-        """
-        # Instantiate the projection
-        SpecificProjection.__init__(self, pre, post, target, None, name, copied)
-
-        # Check populations
-        if not self.pre.neuron_type.type == 'rate':
-            Global._error('The pre-synaptic population of a CurrentInjection must be rate-coded.')
-
-        if not self.post.neuron_type.type == 'spike':
-            Global._error('The post-synaptic population of a CurrentInjection must be spiking.')
-
-        if not self.post.size == self.pre.size:
-            Global._error('CurrentInjection: The pre- and post-synaptic populations must have the same size.')
-
-        if Global._check_paradigm("cuda") and (isinstance(pre, PopulationView) or isinstance(post, PopulationView)):
-            Global._error("CurrentInjection on GPUs is not allowed for PopulationViews")
-
-        # Prevent automatic split of matrices
-        self._no_split_matrix = True
-
-    def _copy(self, pre, post):
-        "Returns a copy of the population when creating networks. Internal use only."
-        return CurrentInjection(pre=pre, post=post, target=self.target, name=self.name, copied=True)
-
-    def _generate_st(self):
-        # Generate the code
-        self._specific_template['psp_code'] = """
-        if (pop%(id_post)s._active) {
-            for (int i=0; i<post_rank.size(); i++) {
-                pop%(id_post)s.g_%(target)s[post_rank[i]] += pop%(id_pre)s.r[pre_rank[i][0]];
+                result[post3 + %(postdim3)s * post2] = sum;
             }
-        } // active
-""" % { 'id_pre': self.pre.id, 'id_post': self.post.id, 'target': self.target}
-
-    def _generate_omp(self):
-        # Generate the code
-        self._specific_template['psp_code'] = """
-        if (pop%(id_post)s._active) {
-            #pragma omp for
-            for (int i=0; i<post_rank.size(); i++) {
-                pop%(id_post)s.g_%(target)s[post_rank[i]] += pop%(id_pre)s.r[pre_rank[i][0]];
+        }
+        // Copy the result multiple times
+        for(int i=0; i<%(postdim0)s*%(postdim1)s; i++){
+            for(int j=0; j<%(postdim2)s*%(postdim3)s; j++){
+                pop%(id_post)s._sum_%(target)s[j + i*(%(postdim2)s*%(postdim3)s)] += result[j];
             }
-        } // active
-""" % { 'id_pre': self.pre.id, 'id_post': self.post.id, 'target': self.target}
-
-    def _generate_cuda(self):
-        """
-        Generate the CUDA code.
-
-        For a first implementation we take a rather simple approach:
-
-        * We use only one block for the kernel and each thread computes
-        one synapse/post-neuron entry (which is equal as we use one2one).
-
-        * We use only the pre-synaptic firing rate, no other variables.
-
-        * We ignore the synaptic weight.
-        """
-        ids = {
-            'id_proj': self.id,
-            'id_post': self.post.id,
-            'id_pre': self.pre.id,
-            'target': self.target,
-            'float_prec': Global.config['precision']
         }
+""" % {'float_prec': get_global_config('precision')}
 
-        self._specific_template['psp_body'] = """
-__global__ void cu_proj%(id_proj)s_psp(int post_size, %(float_prec)s *pre_r, %(float_prec)s *g_%(target)s) {
-    int n = threadIdx.x;
-
-    while (n < post_size) {
-        g_%(target)s[n] += pre_r[n];
-
-        n += blockDim.x;
-    }
-}
-""" % ids
-        self._specific_template['psp_invoke'] = """
-void proj%(id_proj)s_psp(RunConfig cfg, int post_size, %(float_prec)s *pre_r, %(float_prec)s *g_%(target)s) {
-    cu_proj%(id_proj)s_psp<<< cfg.nb, cfg.tpb, cfg.smem_size, cfg.stream >>>(post_size, pre_r, g_%(target)s);
-}
-""" % ids
-        self._specific_template['psp_header'] = """void proj%(id_proj)s_psp(RunConfig cfg, int post_size, %(float_prec)s *pre_r, %(float_prec)s *g_%(target)s);""" % ids
-        self._specific_template['psp_call'] = """
-    proj%(id_proj)s_psp(
-        RunConfig(1, 192, 0, proj%(id_proj)s.stream),
-        pop%(id_post)s.size,
-        pop%(id_pre)s.gpu_r,
-        pop%(id_post)s.gpu_g_%(target)s
-    );
-""" % ids
+        if self.max_distance != 0.0:
+            wgd = "&& abs(dist_w) < %(mgd)s && abs(dist_h) < %(mgd)s" % {'mgd': self.max_distance}
+        else:
+            wgd=""
 
-    def connect_current(self):
-        return self.connect_one_to_one(weights=1.0)
+        self._specific_template['psp_code'] = wsum % {
+            'id_proj': self.id, 
+            'target': self.target,  
+            'id_pre': self.pre.id, 'name_pre': self.pre.name, 'size_pre': self.pre.size, 
+            'id_post': self.post.id, 'name_post': self.post.name, 'size_post': self.post.size,
+            'predim0': self.pre.geometry[0], 'predim1': self.pre.geometry[1], 'predim2': self.pre.geometry[2], 'predim3': self.pre.geometry[3], 
+            'postdim0': self.post.geometry[0], 'postdim1': self.post.geometry[1], 'postdim2': self.post.geometry[2], 'postdim3': self.post.geometry[3], 
+            'offset_w': self.offset_w, 'offset_h': self.offset_h,
+            'amp': self.amp, 'sigma_w': self.sigma_w, 'sigma_h': self.sigma_h, 'min_val': self.min_val, 'wgd': wgd
+          }
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/Synapse.py` & `annarchy-4.8.0.1/ANNarchy/core/Synapse.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,36 +1,50 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-import ANNarchy.core.Global as Global
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern.GlobalObjects import GlobalObjectManager
+from ANNarchy.intern import Messages
 from ANNarchy.parser.AnalyseSynapse import analyse_synapse
 
 class Synapse :
     """
     Base class to define a synapse.
+
+    :param parameters: parameters of the neuron and their initial value.
+    :param equations: equations defining the temporal evolution of variables.
+    :param psp: continuous influence of a single synapse on the post-synaptic neuron (default for rate-coded: ``w*pre.r``). Synaptic transmission in spiking synapses occurs in ``pre_spike``.
+    :param operation: operation (sum, max, min, mean) performed by the post-synaptic neuron on the individual psp (rate-coded only, default=sum).
+    :param pre_spike: updating of variables when a pre-synaptic spike is received (spiking only).
+    :param post_spike: updating of variables when a post-synaptic spike is emitted (spiking only).
+    :param pre_axon_spike: updating of variables when an axonal spike was emitted (spiking only, default None). The usage of this arguments prevents the application of learning rules.
+    :param functions: additional functions used in the equations.
+    :param name: name of the synapse type (used for reporting only).
+    :param description: short description of the synapse type (used for reporting).
     """
     # Default name and description for reporting
     _default_names = {'rate': "Rate-coded synapse", 'spike': "Spiking synapse"}
 
-    def __init__(self, parameters="", equations="", psp=None, operation='sum', pre_spike=None, post_spike=None, pre_axon_spike=None, functions=None, pruning=None, creating=None, name=None, description=None, extra_values={} ):
-        """
-        :param parameters: parameters of the neuron and their initial value.
-        :param equations: equations defining the temporal evolution of variables.
-        :param psp: continuous influence of a single synapse on the post-synaptic neuron (default for rate-coded: ``w*pre.r``). Synaptic transmission in spiking synapses occurs in ``pre_spike``.
-        :param operation: operation (sum, max, min, mean) performed by the post-synaptic neuron on the individual psp (rate-coded only, default=sum).
-        :param pre_spike: updating of variables when a pre-synaptic spike is received (spiking only).
-        :param post_spike: updating of variables when a post-synaptic spike is emitted (spiking only).
-        :param pre_axon_spike: updating of variables when an axonal spike was emitted (spiking only, default None). The usage of this arguments prevents the application of learning rules.
-        :param functions: additional functions used in the equations.
-        :param name: name of the synapse type (used for reporting only).
-        :param description: short description of the synapse type (used for reporting).
+    def __init__(self, 
+                 parameters:str="", 
+                 equations:str="", 
+                 psp:str=None, 
+                 operation:str='sum', 
+                 pre_spike:str=None, 
+                 post_spike:str=None, 
+                 pre_axon_spike:str=None, 
+                 functions:str=None, 
+                 pruning:str=None, 
+                 creating:str=None, 
+                 name:str=None, 
+                 description:str=None, 
+                 extra_values:dict={} ):
 
-        """
 
         # Store the parameters and equations
         self.parameters = parameters
         self.equations = equations
         self.functions = functions
         self.pre_spike = pre_spike
         self.post_spike = post_spike
@@ -42,35 +56,35 @@
         self.creating = creating
 
         # Type of the synapse TODO: smarter
         self.type = 'spike' if pre_spike else 'rate'
 
         # Check the operation
         if self.type == 'spike' and self.operation != 'sum':
-            Global._error('Spiking synapses can only perform a sum of presynaptic potentials.')
+            Messages._error('Spiking synapses can only perform a sum of presynaptic potentials.')
 
         if not self.operation in ['sum', 'min', 'max', 'mean']:
-            Global._error('The only operations permitted are: sum (default), min, max, mean.')
+            Messages._error('The only operations permitted are: sum (default), min, max, mean.')
 
         # Sanity check
         if self.pre_axon_spike and self.post_spike:
-            Global._error("The usage of axonal spike events is currently not allowed for plastic connections.")
+            Messages._error("The usage of axonal spike events is currently not allowed for plastic connections.")
 
-        if (self.pruning or self.creating) and not Global.config['structural_plasticity']:
-            Global._error('"structural_plasticity" has not been set to True in setup(), pruning or creating statements in Synapse() would be without effect.')
+        if (self.pruning or self.creating) and not get_global_config('structural_plasticity'):
+            Messages._error('"structural_plasticity" has not been set to True in setup(), pruning or creating statements in Synapse() would be without effect.')
 
         # Description
         self.description = None
 
         # Reporting
         if not hasattr(self, '_instantiated') : # User-defined
-            Global._objects['synapses'].append(self)
+            GlobalObjectManager().add_synapse_type(synapse=self)
         elif len(self._instantiated) == 0: # First instantiation of the class
-            Global._objects['synapses'].append(self)
-        self._rk_synapses_type = len(Global._objects['synapses'])
+            GlobalObjectManager().add_synapse_type(synapse=self)
+        self._rk_synapses_type = GlobalObjectManager().num_synapse_types()
 
         if name:
             self.name = name
         else:
             self.name = self._default_names[self.type]
 
         if description:
@@ -83,15 +97,15 @@
 
     def _analyse(self):
         # Analyse the synapse type
         if not self.description:
             self.description = analyse_synapse(self)
 
     def __add__(self, synapse):
-        Global._error('adding synapse models is not implemented yet.')
+        Messages._error('adding synapse models is not implemented yet.')
 
         #self._variables.update(synapse.variables)
 
     def __repr__(self):
         if self.type == 'rate':
             text= """Rate-coded synapse.
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/Utils.py` & `annarchy-4.8.0.1/ANNarchy/core/Utils.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,30 +1,30 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 import numpy as np
-import ANNarchy.core.Global as Global
 from ANNarchy.core.Random import RandomDistribution
+from ANNarchy.intern import Messages
 
 ######################
 # Sparse matrices
 ######################
 
 def sparse_random_matrix(pre, post, p, weight):
     """
     Returns a sparse (lil) matrix to connect the pre and post populations with the
     probability *p* and the value *weight*, either a constant or an ANNarchy random
     distribution object.
     """
     try:
         from scipy.sparse import lil_matrix
     except:
-        Global._warning("scipy is not installed, sparse matrices won't work")
+        Messages._warning("scipy is not installed, sparse matrices won't work")
         return None
     from random import sample
     W=lil_matrix((pre, post))
     for i in range(pre):
         k=np.random.binomial(post,p,1)[0]
         tmp = sample(range(post),k)
         W.rows[i]=list(np.sort(tmp))
@@ -40,15 +40,15 @@
 def sparse_delays_from_weights(weight_matrix, delay):
     """
     Generates a delay matrix corresponding to the connectivity stored *weight_matrix*.
     """
     try:
         from scipy.sparse import lil_matrix
     except:
-        Global._warning("scipy is not installed, sparse matrices won't work")
+        Messages._warning("scipy is not installed, sparse matrices won't work")
         return None
 
     delay_matrix = lil_matrix(weight_matrix.get_shape())
 
     (rows,cols) = weight_matrix.nonzero()
 
     for r, c in zip(rows, cols):
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/cython_ext/Connector.pxd` & `annarchy-4.8.0.1/ANNarchy/cython_ext/Connector.pxd`

 * *Files 12% similar despite different names*

```diff
@@ -15,25 +15,28 @@
 
     # Attributes
     cdef public int max_delay
     cdef public int uniform_delay
     cdef public int size
     cdef public int nb_synapses
     cdef public double dt
+    cdef public bool requires_sorting
+    cdef public int last_added_idx
 
     # Insert methods
     cpdef add(self, int rk, r, w, d)
     cpdef push_back(self, int rk, vector[int] r, vector[double] w, vector[double] d)
 
     # Access methods
     cpdef int get_max_delay(self)
     cpdef int get_uniform_delay(self)
 
     # Matrix characteristics (auto-tuning)
     cpdef compute_average_row_length(self)
+    cpdef compute_average_col_idx_gap(self)
 
     # Method to validate a LIL object
     cpdef validate(self)
 
     # pre-defined pattern
     cpdef all_to_all(self, pre, post, weights, delays, allow_self_connections)
     cpdef one_to_one(self, pre, post, weights, delays)
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/cython_ext/Connector.pyx` & `annarchy-4.8.0.1/ANNarchy/cython_ext/Connector.pyx`

 * *Files 3% similar despite different names*

```diff
@@ -8,16 +8,17 @@
 
 from libc.math cimport exp, fabs, ceil
 
 import ANNarchy
 from ANNarchy.core import Global
 from ANNarchy.core.Random import RandomDistribution
 from ANNarchy.core.Population import Population
+from ANNarchy.intern.ConfigManagement import get_global_config
 
-cimport ANNarchy.core.cython_ext.Coordinates as Coordinates
+cimport ANNarchy.cython_ext.Coordinates as Coordinates
 
 ##################################################
 ### Connector methods, these functions are    ####
 ### exported towards ConnectorMethods         ####
 ##################################################
 def all_to_all(pre, post, weights, delays, allow_self_connections, storage_format, storage_order):
     """ Cython implementation of the all-to-all pattern."""
@@ -81,34 +82,48 @@
 cdef class LILConnectivity:
 
     def __cinit__(self):
         self.max_delay = 0
         self.size = 0
         self.nb_synapses = 0
         self.uniform_delay = -1
-        self.dt = Global.config['dt']
+        self.dt = get_global_config('dt')
+        self.requires_sorting = False
+        self.last_added_idx = -1
 
     def __dealloc__(self):
         self.post_rank.clear()
         self.post_rank.shrink_to_fit()
         self.pre_rank.clear()
         self.pre_rank.shrink_to_fit()
         self.w.clear()
         self.w.shrink_to_fit()
         self.delay.clear()
         self.delay.shrink_to_fit()
+        # not sure, if really needed ...
+        self.requires_sorting = False
+        self.last_added_idx = -1
 
     cpdef add(self, int rk, r, w, d):
         self.push_back(rk, r, w, d)
 
     cpdef push_back(self, int rk, vector[int] r, vector[double] w, vector[double] d):
         cdef unsigned int i
         cdef vector[int] int_delays
         cdef int max_d, unif_d
 
+        # sanity check: added rows should be ascending sorted
+        if rk < self.last_added_idx:
+            if self.requires_sorting == False:
+                ANNarchy.intern.Messages._warning("LILConnectivity.add()/.push_back(): dendrites should be added in an ascending order for performance reasons.")
+                ANNarchy.intern.Messages._print("ANNarchy will sort the dendrites during compile() which increases the required time.")
+            self.requires_sorting = True
+        else:
+            self.last_added_idx = rk
+
         # Do not add empty arrays
         if r.size() == 0:
             return
 
         # Store the connectivity
         self.post_rank.push_back(rk)
         self.pre_rank.push_back(r)
@@ -147,29 +162,39 @@
     cpdef int get_uniform_delay(self):
         return self.uniform_delay
 
     cpdef compute_average_row_length(self):
         cdef vector[int] rl
         for i in range(self.pre_rank.size()):
             rl.push_back(self.pre_rank[i].size())
-        return np.mean(rl), np.std(rl)
+
+        return np.mean(rl), np.std(rl), np.amin(rl), np.amax(rl)
+
+    cpdef compute_average_col_idx_gap(self):
+        cdef vector[int] idx_gap
+
+        for i in range(self.pre_rank.size()):
+            for j in range(self.pre_rank[i].size()-1):
+                idx_gap.push_back(self.pre_rank[i][j+1]-self.pre_rank[i][j])
+
+        return np.mean(idx_gap), np.std(idx_gap)
 
     cpdef validate(self):
         cdef int idx, single, rk
         cdef vector[int] ranks
         cdef vector[double] weights
         cdef vector[int] delays
         cdef dict doubletons = {}
         cdef list postranks = list(self.post_rank)
         cdef list set_postranks = list(set(postranks))
         cdef list preranks, set_preranks, indices
 
         if len(postranks) != len(set_postranks):
-            ANNarchy.core.Global._warning('You have added several times the same post-synaptic neuron to the LIL data in your connector method.')
-            ANNarchy.core.Global._print('ANNarchy will try to sort the entries if possible, it may take some time...')
+            ANNarchy.intern.Messages._warning('You have added several times the same post-synaptic neuron to the LIL data in your connector method.')
+            ANNarchy.intern.Messages._print('ANNarchy will try to sort the entries if possible, it may take some time...')
         else:
             return
 
         # Find out which post neurons are doubled.
         for single in set_postranks:
             doubletons[single] = []
             for idx, possible_double in enumerate(postranks):
@@ -195,15 +220,15 @@
                 self.w.erase(self.w.begin()+idx)
                 self.delay.erase(self.delay.begin()+idx)
 
             # Check if no synapse is doubled
             preranks = list(ranks)
             set_preranks = list(set(preranks))
             if len(preranks) != len(set_preranks):
-                ANNarchy.core.Global._error('The same synapse has been declared multiple times! Check your code.', exit=True)
+                ANNarchy.intern.Messages._error('The same synapse has been declared multiple times! Check your code.', exit=True)
 
             # Add the new data
             self.post_rank.push_back(rk)
             self.pre_rank.push_back(ranks)
             self.w.push_back(weights)
             self.delay.push_back(delays)
 
@@ -401,15 +426,15 @@
         cdef tuple pre_geometry, post_geometry
         cdef list ranks, values
 
         cdef vector[int] r
         cdef vector[double] w, d
 
         # Retrieve simulation time step
-        dt = Global.config['dt']
+        dt = get_global_config('dt')
 
         # Population sizes
         pre_geometry = pre_pop.geometry
         post_geometry = post_pop.geometry
         if isinstance(pre_geometry, int):
             pre_size = pre_geometry
             pre_dim = 1
@@ -553,8 +578,8 @@
         w = tmp
     # Delays
     if isinstance(delays, (float, int)):
         d = vector[double](1, delays)
     elif isinstance(delays, RandomDistribution):
         d = delays.get_list_values(size)
 
-    return w, d
+    return w, d
```

### Comparing `ANNarchy-4.7.3/ANNarchy/core/cython_ext/Coordinates.pxd` & `annarchy-4.8.0.1/ANNarchy/cython_ext/Coordinates.pxd`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/core/cython_ext/Coordinates.pyx` & `annarchy-4.8.0.1/ANNarchy/cython_ext/Coordinates.pyx`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/core/cython_ext/Transformations.pyx` & `annarchy-4.8.0.1/ANNarchy/cython_ext/Transformations.pyx`

 * *Files 8% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 # distutils: language = c++
 
 import numpy as np
 cimport numpy as np
 
-import ANNarchy
+from ANNarchy.intern.ConfigManagement import get_global_config
 
 cpdef np.ndarray raster_plot(list data):
     """
     Transforms recorded spikes into a (N, 2) array to easily display the raster plot.
     """
     cdef int N, n, t
     cdef np.ndarray res
@@ -32,15 +32,15 @@
     cdef np.ndarray res
     cdef int N, d
     cdef int n, t, timing, last_spike, idx
     cdef float dt, delta
     cdef list spikes
 
     # Retrieve simulation time step
-    dt = ANNarchy.core.Global.config['dt']
+    dt = get_global_config('dt')
 
     # Number of neurons
     d = data['stop'] - data['start']
     N = len(data['data'])
 
     # Prepare the matrix
     rates = np.zeros((N, d))
@@ -77,15 +77,15 @@
     cdef np.ndarray res
     cdef int N, d
     cdef int n, t, timing, last_spike
     cdef float dt, delta
     cdef list spikes
 
     # Retrieve simulation time step
-    dt = ANNarchy.core.Global.config['dt']
+    dt = get_global_config('dt')
 
     # Number of neurons
     d = data['stop'] - data['start'] + 1
     N = len(data['data'])
 
     # Prepare the matrix
     rates = np.zeros(d)
```

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/ann_to_snn_conversion/ANNtoSNNConverter.py` & `annarchy-4.8.0.1/ANNarchy/extensions/ann_to_snn_conversion/ANNtoSNNConverter.py`

 * *Files 22% similar despite different names*

```diff
@@ -6,39 +6,137 @@
 from ANNarchy.core import Global
 from ANNarchy.core.Network import Network
 from ANNarchy.core.Population import Population
 from ANNarchy.core.Projection import Projection
 from ANNarchy.core.Monitor import Monitor
 from ANNarchy.core.Random import Uniform
 from ANNarchy.extensions.convolution import Convolution, Pooling
+from ANNarchy.intern import Messages
 
-
-import matplotlib.pylab as plt
 import numpy as np
-import h5py
-import json
-from copy import copy
 
-from .InputEncoding import *
-from .ReadOut import *
+from .InputEncoding import CPN, IB, PSO
+from .ReadOut import available_read_outs, IaF, IaF_ReadOut, IaF_TTKS, IaF_Acc
 
 class ANNtoSNNConverter :
-    """
-    Implements a conversion of a pre-trained fully-connected Keras model into a spiking model. The procedure is based on the implementation of:
-     
-    > Diehl et al. (2015) "Fast-classifying, high-accuracy spiking deep networks through weight and threshold balancing" Proceedings of IJCNN. doi: 10.1109/IJCNN.2015.7280696
+    r"""
+    Converts a pre-trained Keras model `.keras` into an ANNarchy spiking neural network. 
+
+    The implementation of the present module is inspired by the SNNToolbox (Rueckauer et al. 2017), and is largely based on the work of Diehl et al. (2015). We provide several input encodings, as suggested in the work of Park et al. (2019) and Auge et al. (2021).
+
+    **Constraints on the ANN**
+
+    It is not possible to convert any keras model into an ANNarchy SNN: some constraints ahve to be respected.
+
+    * The only allowed layers in the ANN are:
+        * `Dense`
+        * `Conv2D`
+        * `MaxPooling2D`
+        * `AveragePooling2D`
+        * as well as non-neural layers such as Dropout, Activation, BatchNorm, etc.
+
+    * The layers must **not** contain any bias, even the conv layers:
+
+    ```python
+    x = tf.keras.layers.Dense(128, use_bias=False, activation='relu')(x)
+    x = tf.keras.layers.Conv2D(64, kernel_size=(5,5), activation='relu', padding='same', use_bias=False)(x)
+    ```
+
+    * The first layer of the network must be an `Input`:
+
+    ```python
+    inputs = tf.keras.Input(shape = (28, 28, 1))
+    ```
+
+    * Pooling must explicitly be done by `MaxPooling2D`/`AveragePooling2D`, strides are ignored.
+    
+    Please be aware that the module is very experimental and the conversion may not work for many different reasons. Feel free to submit issues.
+
+    **Processing Queue**
+
+    The pre-trained ANN model to be converted should be saved in keras (extension `.keras`). The saved model is transformed layer by layer into a feed-forward ANNarchy spiking network. The structure of the network remains the same as in the original ANN, while the weights are normalised. Please note that the current implementation focuses primarily on the correctness of the conversion. Computational performance, especially of the converted CNNs, will be improved in future releases.
+
+    :::callout-note
+    
+    While the neurons are conceptually spiking neurons, there is one specialty: next to the spike event (stored automatically in ANNarchy), each event will be stored in an additional *mask* array. This *mask* value decays in absence of further spike events exponentially. The decay can be controlled by the *mask_tau* parameter of the population. The projections (either dense or convolution) will use this mask as pre-synaptic input, not the generated list of spike events.
+    :::
+
+    **Input Encoding**
+
+    * Poisson ("CPN")
+
+    This encoding uses a Poisson distribution where the pixel values of the image will be used as probability for each individual neuron.
+    
+    * Intrinsically Bursting ("IB")
+
+    This encoding is based on the Izhikevich (2003) model that comprises two ODEs:
+
+    $$
+    \begin{cases}
+    \frac{dv}{dt} = 0.04 \cdot v^2 + 5.0 \cdot v + 140.0 - u + I \\
+    \\
+    \frac{du}{dt} = a \cdot (b \cdot v - u) \\
+    \end{cases}
+    $$
+
+    The parameters for $a$ - $d$ are selected accordingly to Izhikevich (2003). The provided input images will be set as $I$.
+
+
+    * Phase Shift Oscillation ("PSO")
+
+    Based on the description by Park et al. (2019), the spiking threshold $v_\text{th}$ is modulated by a oscillation function $\Pi$, whereas the membrane potential follows simply the input current. 
+
+    $$
+    \begin{cases}
+    \Pi(t) = 2^{-(1+ \text{mod}(t,k))}\\
+    \\
+    v_\text{th}(t) = \Pi(t) \, v_\text{th}(t)\\
+    \end{cases}
+    $$
+
+    * User-defined input encodings
+
+    In addition to the pre-defined models, one can opt for individual models using the `Neuron` class of ANNarchy. Please note that a `mask` variable need to be defined, which is fed into the subsequent projections.
+
+    **Read-out Methods**
+
+    In a classification task, the neuron with the highest activity corresponds corresponds to the decision to which class the presented input belongs. However, the highest activity can be determined in different ways. We support currently three methods, defined by the `read_out` parameter of the constructor:
+
+    * Maximum Spike Count
+
+    `read_out = 'spike_count'` : the number of spikes emitted by each neuron is recorded and the index of the neuron(s) with the maximum number is returned.
 
+    * Time to Number of Spikes
+
+    `read_out = 'time_to_first_spike'` or `read_out = 'time_to_k_spikes'`: when the first or first $k$ spikes are emitted by a single neuron, the simulation is stopped and the neuron rank(s) is returned. For the second mode, an additional $k$ argument need to be also provided.
+
+    * Membrane potential
+
+    `read_out = 'membrane_potential'`:  pre-synaptic events are accumulated in the membrane potential of each output neuron. The index of the neuron(s) with the highest membrane potential is returned.
+
+    > Izhikevich (2003) Simple Model of Spiking Neurons. IEEE transactions on neural networks 14(6). doi: 10.1109/TNN.2003.820440
+
+    > Diehl PU, Neil D, Binas J,et al. (2015) Fast-classifying, high-accuracy spiking deep networks through weight and threshold balancing, 2015 International Joint Conference on Neural Networks (IJCNN), 1-8, doi: 10.1109/IJCNN.2015.7280696.
+
+    > Rueckauer B, Lungu I, Hu Y, et al. (2017) Conversion of Continuous-Valued Deep Networks to Efficient Event-Driven Networks for Image Classification., Front. Neurosci., 2017, 11. doi: 10.3389/fnins.2017.00682
+
+    > Park S, Kim S, Choe H, et al. (2019) Fast and Efficient Information Transmission with Burst Spikes in Deep Spiking Neural Networks. 
+
+    > Auge D, Hille J, Mueller E et al. (2021) A Survey of Encoding Techniques for Signal Processing in Spiking Neural Networks. Neural Processing Letters. 2021; 53:4963-4710. doi:10.1007/s11063-021-10562-2
+
+    :param input_encoding: a string representing which input encoding should be used: 'CPN', 'IB' or 'PSO'.
+    :param hidden_neuron:  neuron model used in the hidden layers. Either the default integrate-and-fire ('IaF') or an ANNarchy Neuron object.
+    :param read_out: a string which of the following read-out method should be used: `spike_count`, `time_to_first_spike`, `membrane_potential`.
     """
 
-    def __init__(self, input_encoding='poisson', hidden_neuron='IaF', read_out='spike_count', **kwargs):
-        """
-        :param input_encoding: a string representing which input encoding should be used: custom poisson, PSO, IB or CH (for more details see InputEncoding).
-        :param hidden_neuron:  neuron model used in the hidden layers. Either the default integrate-and-fire ('IaF') or an ANNarchy Neuron object.
-        :param read_out: a string which of the following read-out method should be used: spike_count, time_to_first_spike, membrane_potential (for more details see the manual).
-        """
+    def __init__(self, 
+                 input_encoding:str='CPN', 
+                 hidden_neuron:str='IaF', 
+                 read_out:str='spike_count', 
+                 **kwargs):
 
         # Neuron model
         if isinstance(hidden_neuron, str):
             if hidden_neuron == "IaF":
                 self._hidden_neuron_model = IaF
             else:
                 raise ValueError("Invalid model name for hidden neurons.")
@@ -63,459 +161,376 @@
             raise ValueError("Unknown value for read-out:", read_out)
 
         # Maximum frequency
         self._max_f = 100      # scale factor used for poisson encoding
 
         if self._read_out == "time_to_k_spikes":
             if 'k' not in kwargs.keys():
-                Global._error("When read_out is set to 'time_to_k_spikes', the k parameter need to be provided.")
+                Messages._error("When read_out is set to 'time_to_k_spikes', the k parameter need to be provided.")
             self._k_param = kwargs['k']
 
         # TODO: sanity check on key-value args
         for key, value in kwargs.items():
             if key == "max_f":
                 self._max_f = value
 
         self._snn_network = None
 
-    def init_from_keras_model(self, 
-            filename, 
-            directory="annarchy", 
-            scale_factor=None, 
-            show_info=True, 
-        ):
+    def load_keras_model(self, 
+            filename:str, 
+            directory:str="annarchy", 
+            scale_factor:float=None, 
+            show_info:bool=True, 
+        ) -> "Network":
         """
-        Loads the pre-trained model provided as a .h5 file.
+        Loads the pre-trained model provided as a .keras file.
 
         In tf.keras, the weights can be saved using:
 
         ```python
-        model.save("model.h5")
+        model.save("model.keras")
         ```
 
-        :param filename: stored model as a .h5 file.
+        :param filename: path to the `.keras` file.
         :param directory: sub-directory where the generated code should be stored (default: "annarchy")
         :param scale_factor: allows a fine-grained control of the weight scale factor. By default (None), with each layer-depth the factor increases by one. If a scalar value is provided the same value is used for each layer. Otherwise a list can be provided to assign the scale factors individually.
         :param show_info: whether the network structure should be printed on console (default: True)
-
-        :returns net: An `ANNarchy.Network` instance.
+        :returns: An `ANNarchy.Network` instance.
         """
+        description = ""
 
-        # Filename
-        if not filename.endswith(".h5"):
-            Global._error("ANNtoSNNConverter: the keras model must be provided as a .h5 file.")
-        self._filename = filename
-
-        # Extract weight matrices
-        weight_matrices, layer_order, layer_operation, input_dim = self._extract_weight_matrices(filename)
+        # Load keras model
+        import tensorflow as tf
+        model = tf.keras.models.load_model(filename)
 
         # Create spiking network
         self._snn_network = Network(everything = False)
-        input_pop = Population(name = layer_order[0], geometry=input_dim, neuron=self._input_model)
-        self._snn_network.add(input_pop)
 
-        # Hidden neuron
-        if isinstance(self._hidden_neuron_model, list):
-            hidden_type = "user-specified"
-        else:
-            hidden_type = self._hidden_neuron_model.name
-            self._hidden_neuron_model = [self._hidden_neuron_model for _ in range(len(layer_order)-2)]
-
-        description = f"""Parameters
-----------------------
-* input encoding: {self._input_encoding}
-* hidden neuron: {hidden_type}
-* read-out method: {self._read_out}
-
-Layers
-----------------------
-"""
-
-        # Create populations
-        for layer in range(len(layer_order)):
-            if 'conv' in layer_order[layer]:
-
-                geometry = input_dim + (np.shape(weight_matrices[layer])[0],)
-                conv_pop = Population(geometry = geometry, neuron=self._hidden_neuron_model[layer-1], name=layer_order[layer] ) # create convolution population
-                conv_pop.vt = conv_pop.vt - (0.05*layer) # reduce the threshold for deeper layers
-                self._snn_network.add(conv_pop)
-
-                description += f"* name={layer_order[layer]}, convolutional layer, {geometry=}\n"
-
-            elif 'pool' in layer_order[layer]:
+        # Input Population
+        if not isinstance(model.layers[0], tf.keras.layers.InputLayer):
+            Messages._error("The first layer of the network must be an Input layer.")
+        
+        input_name = model.layers[0].name
+        input_shape = get_shape(model.layers[0].output)[1:]
 
-                input_dim = (int(input_dim[0]/ 2), int(input_dim[1]/ 2))
-                l_weights = weight_matrices[layer-1] # get the weights of the previous layer (should be a conv-layer, or not?)
-                dim_0 = np.shape(l_weights)[0]
+        input_pop = Population(
+            name = input_name, 
+            geometry=input_shape, 
+            neuron=self._input_model
+        )
+        self._snn_network.add(input_pop)
 
-                geometry = input_dim # add it to the geometry
-                geometry = geometry + (dim_0,)
-                pool_pop = Population(geometry = geometry, neuron=self._hidden_neuron_model[layer-1], name=layer_order[layer])
-                pool_pop.vt = pool_pop.vt - (0.05*layer) # reduce the threshold for deeper layers
-                self._snn_network.add(pool_pop)
+        description += f"* Input layer: {input_name}, {input_shape}\n"
 
-                description += f"* name={layer_order[layer]}, pooling layer, {geometry=}\n"
+        # Iterate over layers
+        pops = [input_pop]
+        projs = []
+        weights = []
+        
+        for idx, layer in enumerate(model.layers):
 
-            elif 'dense' in layer_order[layer]:
+            # Get the name
+            name = layer.name
 
-                geometry = np.shape(weight_matrices[layer])[0]
+            # Is the layer legit in ANNarchy?
+            pop = None
 
-                # read-out layer
-                if layer == len(layer_order)-1:
+            # The only supported layers are dense, conv* and pool*
+            if isinstance(layer, tf.keras.layers.Dense):
+                
+                # Get incoming weights
+                W = layer.get_weights()[0].T
+                size = W.shape[0]
+
+                # Neuron type
+                neuron_type = self._hidden_neuron_model
+                stop_condition = None
+
+                # Readout layer can have different neurons
+                readout = False
+                if idx == len(model.layers) - 1:
+                    readout = True
                     if self._read_out == "membrane_potential":
-                        # HD (24th April 2023): instead of reading out spike events, we use the accumulated inputs
-                        #                       as decision parameter
-                        dense_pop = Population(geometry = geometry, neuron=IaF_Acc, name=layer_order[layer])
-
-                    elif self._read_out == "time_to_first_spike" and layer == len(layer_order)-1:
-                        # HD (24th April 2023): instead of reading out spike events, we simulate untile the first
-                        #                       neuron in the read-out layer spikes.
-                        dense_pop = Population(geometry = geometry, neuron=IaF, name=layer_order[layer], stop_condition="spiked: any")
-
-                    elif self._read_out == "time_to_k_spikes" and layer == len(layer_order)-1:
-                        # HD (3rd May 2023): instead of reading out spike events, we simulate untile the first
-                        #                    neuron emitted k spikes in the read-out layer.
-                        dense_pop = Population(geometry = geometry, neuron=IaF_TTKS, name=layer_order[layer], stop_condition="sc >= k: any")
-                        dense_pop.k = self._k_param
-
-                    else:
-                        dense_pop = Population(geometry = geometry, neuron=IaF_ReadOut, name=layer_order[layer])
-                        # ARK:  scaling the threshold as number of layers increases divide
-                        #       the value 1/half of the number of the network
-                        dense_pop.vt = dense_pop.vt - (0.05*layer)
-                        # HD (20th Feb. 2023): we want to generate this firing vector for a
-                        #                      single time step
-                        dense_pop.compute_firing_rate(Global.dt())
-
-                # hidden layer neurons
-                else:
-                    dense_pop = Population(geometry = geometry, neuron=self._hidden_neuron_model[layer-1], name=layer_order[layer])
-                    # ARK:  scaling the threshold as number of layers increases divide
-                    #       the value 1/half of the number of the network
-                    dense_pop.vt = dense_pop.vt - (0.05*layer)
-                    # HD (20th Feb. 2023): we want to generate this firing vector for a
-                    #                      single time step
-                    dense_pop.compute_firing_rate(Global.dt())
-
-                # Add created layer to the network
-                self._snn_network.add(dense_pop)
-
-                # Description
-                description += f"* name={layer_order[layer]}, dense layer, {geometry=}\n"
-
-
-        # Create Projections
-        description += '\nProjections\n----------------------\n'
-
-        for p in range(1,len(layer_order)):
-            if 'conv' in layer_order[p]:
-
-                post_pop = self._snn_network.get_population(layer_order[p])
-                pre_pop = self._snn_network.get_population(layer_order[p-1])
-
-                weight_m = np.squeeze(weight_matrices[p])
-
-                conv_proj = Convolution(pre = pre_pop, post=post_pop, target='exc', psp="pre.mask * w", name='conv_proj_%i'%p)
-                conv_proj.connect_filters(weights=weight_m)
-                self._snn_network.add(conv_proj)
-
-                description += f"* {layer_order[p-1]} {pre_pop.geometry} -> {layer_order[p]} {post_pop.geometry}\n"
-                description += f"    weight matrix {np.shape(weight_m)}\n"
-
-
-            elif 'pool' in layer_order[p]:
-
-                post_pop = self._snn_network.get_population(layer_order[p])
-                pre_pop = self._snn_network.get_population(layer_order[p-1])
-
-                pool_proj = Pooling(pre = pre_pop, post=post_pop, target='exc', operation=layer_operation[p], psp="pre.mask", name='pool_proj_%i'%p)
-                pool_proj.connect_pooling(extent=(2,2,1))
-                self._snn_network.add(pool_proj)
-
-                description += f"* {layer_order[p-1]} {pre_pop.geometry} -> {layer_order[p]} {post_pop.geometry}\n"
-                description += f"    pooling operation {layer_operation[p]}\n"
-
-            elif 'dense' in layer_order[p]:
-
-                post_pop = self._snn_network.get_population(layer_order[p])
-                pre_pop = self._snn_network.get_population(layer_order[p-1])
-
-                dense_proj = Projection(
-                    pre = pre_pop, post = post_pop, 
-                    target = "exc", name='dense_proj_%i'%p
+                        neuron_type = IaF_Acc 
+                        stop_condition = None
+                    elif self._read_out == "time_to_first_spike":
+                        neuron_type = IaF
+                        stop_condition="spiked: any"
+                    elif self._read_out == "time_to_k_spikes":
+                        neuron_type = IaF_TTKS 
+                        stop_condition="sc >= k: any"
+                
+                # Create the population
+                pop = Population(
+                    geometry = size, 
+                    neuron=neuron_type, 
+                    name=name,
+                    stop_condition=stop_condition
                 )
 
-                if pre_pop.neuron_type.type=="rate":
-                    dense_proj.connect_all_to_all(weights=Uniform(0,1), storage_format="dense")
-                else:
-                    dense_proj.connect_all_to_all(weights=Uniform(0,1), storage_format="dense", storage_order="pre_to_post")
-                    dense_proj._parallel_pattern = "outer_loop"
+                # Add population to the network
+                self._snn_network.add(pop)
+                pops.append(pop)
+
+                if not readout:
+                    #pop.vt = pop.vt - (0.05 * len(pops))
+                    pop.vt = pop.vt - (0.05 * idx)
+
+                description += f"* Dense layer: {name}, {size} \n"
+
+                # Create projection
+                proj = Projection(
+                    pre = pops[-2], post = pop, 
+                    target = "exc", name=f"dense_proj_{len(pops)}"
+                )
 
-                self._snn_network.add(dense_proj)
+                proj.connect_from_matrix(W, storage_format="dense")
 
-                description += f"* {layer_order[p-1]} {pre_pop.geometry} -> {layer_order[p]} {post_pop.geometry}\n"
-                description += f"    weight matrix size {np.shape(weight_matrices[p])}\n"
-                description += f"    mean {np.mean(weight_matrices[p])}, std {np.std(weight_matrices[p])}\n"
-                description += f"    min {np.min(weight_matrices[p])}, max {np.max(weight_matrices[p])}\n"
+                # Add to the network
+                self._snn_network.add(proj)
+                projs.append(proj)
+                weights.append(W)
+
+                description += f"    weights: {W.shape}\n"
+                description += f"    mean {np.mean(W)}, std {np.std(W)}\n"
+                description += f"    min {np.min(W)}, max {np.max(W)}\n"
+                
+
+            elif isinstance(layer, tf.keras.layers.Conv2D):
+                
+                geometry = get_shape(layer.output)[1:]
+
+                pop = Population(
+                    geometry = geometry, 
+                    neuron=self._hidden_neuron_model, 
+                    name=name ) 
+
+                self._snn_network.add(pop)
+                pops.append(pop)
+                
+                #pop.vt = pop.vt - (0.05 * len(pops))
+                pop.vt = pop.vt - (0.05 * idx)
+
+                description += f"* Conv2D layer: {name}, {geometry} \n"
+
+                W = layer.get_weights()[0]
+                W = np.moveaxis(W, -1, 0)
+
+                proj = Convolution(
+                    pre = pops[-2], post = pop, target='exc', 
+                    psp="pre.mask * w", 
+                    name=f'conv_proj_{len(pops)}')
+                proj.connect_filters(weights=W)
+
+                self._snn_network.add(proj)
+                projs.append(proj)
+                weights.append(W)
+
+            elif isinstance(layer, 
+                            (tf.keras.layers.MaxPooling2D,
+                             tf.keras.layers.AveragePooling2D)):
+                
+                geometry = get_shape(layer.output)[1:]
+                pool_size = layer.get_config()['pool_size'] + (1,)
+                operation = 'max' if isinstance(layer, tf.keras.layers.MaxPooling2D) else 'mean'
+
+                pop = Population(
+                    geometry = geometry, 
+                    neuron=self._hidden_neuron_model, 
+                    name=name ) 
+
+                self._snn_network.add(pop)
+                pops.append(pop)
+                
+                #pop.vt = pop.vt - (0.05 * len(pops))
+                pop.vt = pop.vt - (0.05 * idx)
+
+                description += f"* MaxPooling2D layer: {name}, {geometry} \n"
+                
+                proj = Pooling(
+                    pre = pops[-2], post = pop, target='exc', 
+                    operation=operation, psp="pre.mask", 
+                    name=f'pool_proj_{len(pops)}')
+                
+                proj.connect_pooling(extent=pool_size)
+                self._snn_network.add(proj)
+                projs.append(proj)
+                weights.append([])
+
+            # Compatible layer has not been found
+            if pop is None:
+                description += f"* {type(layer).__name__} skipped.\n"
+
+        # Record the last layer to determine prediction
+        self._monitor = Monitor(pop, ['v', 'spike'])
+        self._snn_network.add(self._monitor)
 
         # Compile the configured network
-        self._snn_network.compile(directory=directory)
-
-        # Weight normalization
-        self._apply_weight_normalization(scale_factor, show_info)
+        self._snn_network.compile(directory=directory, silent=True)
 
         if show_info:
             print(description)
 
-        return self._snn_network
-
-    def _apply_weight_normalization(self, scale_factor=None, show_info=True):
-        """
-        Apply the weight normalization as described in Diehl et. al (2015). Note that the function is automatically called by default.
-        """
-        
-        # 1st step: load original ANN
-        weight_matrices, layer_order, layer_operation, input_dim = self._extract_weight_matrices(self._filename)
-
-        # 2nd step: normalize weights
-        norm_weight_matrices = self._normalize_weights(weight_matrices, scale_factor=scale_factor)
-
-        ## go again over all dense projections to load the weight matrices ##
-        for proj in self._snn_network.get_projections():
-            
-            if 'dense' in proj.name: # find the dense projection
-                proj_name = proj.name.split('_')
-                proj_idx = int(proj_name[-1]) # get the index of the dense layer in relation to all other layers
+        # Normalize the weights
+        factors = self._normalize_weights(weights, scale_factor)
+        for i in range(len(weights)):
+            if len(weights[i]) > 0:
+                if isinstance(projs[i], (Convolution,)):
+                    self._snn_network.get(projs[i]).weights = weights[i] * float(factors[i])
+                else:
+                    self._snn_network.get(projs[i]).weights = weights[i] * float(factors[i])
 
-                ## use the not normed weights to the classification layer
-                proj.w = norm_weight_matrices[proj_idx]
+        return self._snn_network
 
 
-    def get_annarchy_network(self):
+    def get_annarchy_network(self) -> "Network":
         """
         Returns the ANNarchy.Network instance.
         """
         return self._snn_network
 
     def predict(self, 
                 samples, 
                 duration_per_sample=1000, 
-                measure_time=False,
-                ):
+                multiple=False,
+                ) -> list[int]:
         """
-        Performs the prediction for a given input series.
-
-        Parameters:
+        Performs the prediction for a given input array.
 
         :param samples: set of inputs to present to the network. The function expects a 2-dimensional array (num_samples, input_size).
         :param duration_per_sample: the number of simulation steps for one input sample (default: 1000, 1 second biological time)
-        :param measure_time: print out the computation time spent for one input sample (default: False)
-
-        :returns predictions: A list of predicted class indices. If multiple neurons fulfill the condition, all candidate indices are returned.
+        :param multiple: if several output neurons reach the criteria, return the full list instead of randomly chosing one.
+        :returns: A list of predicted class indices for each sample.
         """
 
-        predictions = [[] for _ in range(len(samples))]
+        predictions = []
 
-        # get the top-level layer
+        # Get the top-level layer
         first_layer = self._snn_network.get_populations()[0].name
         last_layer = self._snn_network.get_population(self._snn_network.get_populations()[-1].name)
 
-        # record the last layer to determine prediction
-        if self._read_out == "membrane_potential":
-            m_read_out_layer = Monitor(last_layer, ['v'])
-        else:
-            m_read_out_layer = Monitor(last_layer, ['spike'])
-        self._snn_network.add(m_read_out_layer)
-
-        class_pop_size = last_layer.size
+        nb_classes = last_layer.size
 
-        # Needed when multiple classes achieve the same ranking
-        rng = np.random.default_rng()
+        # Use the progress bar
+        try:
+            import tqdm
+        except Exception as e:
+            iterator = range(samples.shape[0])
+        else:
+            iterator = tqdm.tqdm(range(samples.shape[0]))
 
         # Iterate over all samples
-        for i in range(samples.shape[0]):
-            # Progress bar
-            if i % 100 == 0:
-                print(f"{i}/{samples.shape[0]}", end="\r")
+        for i in iterator:
 
             # Reset state variables
             self._snn_network.reset(populations=True, monitors=True, projections=False)
 
-            # set input
-            self._snn_network.get_population(first_layer).rates =  samples[i,:]*self._max_f
+            # Set input
+            self._snn_network.get_population(first_layer).rates =  samples[i,:] * self._max_f
 
             # The read-out is performed differently based on the mode selected by the user
             if self._read_out in ["time_to_first_spike", "time_to_k_spikes"]:
-                self._snn_network.simulate_until(duration_per_sample, population=last_layer, measure_time=measure_time)
+                # Simulate until the condition is met
+                self._snn_network.simulate_until(duration_per_sample, population=last_layer)
 
-                # read-out accumulated inputs
-                spk_class = self._snn_network.get(m_read_out_layer).get('spike')
-                act_pred = np.zeros(class_pop_size)
-                for neur_rank, spike_times in spk_class.items():
+                # Read-out accumulated inputs
+                data = self._snn_network.get(self._monitor).get('spike')
+                act_pred = np.zeros(nb_classes)
+                for neur_rank, spike_times in data.items():
                     act_pred[neur_rank] = len(spike_times)
 
-                # gather all neurons which fulfilled the condition
-                tmp_list = np.argwhere(act_pred == np.amax(act_pred))
-                for tmp in tmp_list:
-                    predictions[i].append(tmp[0])
+                # Gather all neurons which fulfilled the condition
+                prediction = np.argwhere(act_pred == np.amax(act_pred)).flatten()
 
             elif self._read_out == "membrane_potential":
-                # simulate 1s and record spikes in output layer
-                self._snn_network.simulate(duration_per_sample, measure_time=measure_time)
+                # Simulate 1s and record spikes in output layer
+                self._snn_network.simulate(duration_per_sample)
 
-                # read-out accumulated inputs
-                spk_class = self._snn_network.get(m_read_out_layer).get('v')
+                # Read-out accumulated inputs
+                data = self._snn_network.get(self._monitor).get('v')
 
-                # the neuron with the highest accumulated membrane potential is the selected candidate
-                # (HD: 23th May 2023: I'm not sure if it could happen that two neurons have the same mp)
-                tmp_list = np.argwhere(spk_class[-1,:] == np.amax(spk_class[-1,:]))
-                for tmp in tmp_list:
-                    predictions[i].append(tmp[0])
+                # The neuron with the highest accumulated membrane potential is the selected candidate
+                prediction = np.argwhere(data[-1,:] == np.amax(data[-1,:])).flatten()
 
             elif self._read_out == "spike_count":
-                # simulate 1s and record spikes in output layer
-                self._snn_network.simulate(duration_per_sample, measure_time=measure_time)
+                # Simulate 1s and record spikes in output layer
+                self._snn_network.simulate(duration_per_sample)
 
-                # retrieve the recorded spike events
-                spk_class = self._snn_network.get(m_read_out_layer).get('spike')
+                # Retrieve the recorded spike events
+                data = self._snn_network.get(self._monitor).get('spike')
 
                 # The predicted label is the neuron index with the highest number of spikes.
                 # Therefore, we count the number of spikes each output neuron emitted.
-                act_pred = np.zeros(class_pop_size)
-                for neur_rank, spike_times in spk_class.items():
+                act_pred = np.zeros(nb_classes)
+                for neur_rank, spike_times in data.items():
                     act_pred[neur_rank] = len(spike_times)
 
-                # gather all neurons which achieved highest number of spikes
-                tmp_list = np.argwhere(act_pred == np.amax(act_pred))
-                for tmp in tmp_list:
-                    predictions[i].append(tmp[0])
+                # Gather all neurons which achieved highest number of spikes
+                prediction = np.argwhere(act_pred == np.amax(act_pred)).flatten()
 
             else:
                 raise NotImplementedError
+            
+            # Treat ex-aequo
+            if multiple:
+                predictions.append(list(prediction))
+            else:
+                predictions.append(int(np.random.choice(prediction, 1)))
 
         return predictions
 
-    def _set_input(self, sample, encoding):
-        """
-        We will support different input encodings in the future.
-        """
-        if encoding == "poisson":
-            self._input_pop.rates = sample*self._max_f
-        else:
-            self._input_pop.rates = sample*self._max_f
-
-    def _extract_weight_matrices(self, filename):
-        """
-        Read the .h5 file and extract layer sizes as well as the
-        pre-trained weights.
-        """
-        f=h5py.File(filename,'r')
-
-        if not 'model_weights' in f.keys():
-            Global._error("Could not find weight matrices in the .h5 file.")
-
-        ## get the configuration of the Keras model
-        model_config = f.attrs.get("model_config")
-        try:
-            # h5py < 3.0 get() returns 'bytes' sequence
-            model_config = model_config.decode("utf-8")
-        except AttributeError:
-            # In h5py > 3.0 the return of get() is already decoded
-            pass
-
-        model_config = json.loads(model_config)
-
-        ## get the list with all layer names
-        model_layers = (model_config['config']['layers'])
-        model_weights = (f['model_weights'])
-
-        Global._debug("ANNtoSNNConverter: detected", len(model_layers), "layers.")
-
-        weight_matrices=[]   # array to save the weight matrices
-        layer_order = []     # additional array to save the order of the layers to know it later
-        layer_operation = [] # additional information for each layer
-
-        for layer in model_layers:
-            layer_name = layer['config']['name']
-            layer_class = layer['class_name']
-
-            if 'conv2d' in layer_name:
-                layer_w = model_weights[layer_name][layer_name]['kernel:0']
-                ## if it is a convolutional layer, reshape it to fitt to annarchy
-                dim_h, dim_w, dim_pre, dim_post = np.shape(layer_w)
-                new_w = np.zeros((dim_post, dim_h, dim_w, dim_pre))
-                for i in range(dim_post):
-                    new_w[i,:,:] = layer_w[:,:,:,i]
-                weight_matrices.append(new_w)
-                layer_order.append(layer_name)
-                layer_operation.append("") # add an empty string to pad the array
-
-            elif 'dense' in layer_name:
-                layer_w = model_weights[layer_name][layer_name]['kernel:0']
-                weight_matrices.append(np.transpose(layer_w))
-                layer_order.append(layer_name)
-                layer_operation.append("") # add an empty string to pad the array
-
-            elif 'pool' in layer_name:
-                layer_order.append(layer_name)
-                weight_matrices.append([]) # add an empty weight matrix to pad the array
-                if "AveragePooling" in layer_class:
-                    layer_operation.append("mean")
-                elif "MaxPooling" in layer_class:
-                    layer_operation.append("max")
-                else:
-                    Global._warning("The pooling class:", layer_class, "is not supported yet. Falling back to max-pooling.")
-                    layer_operation.append("max")
-
-            elif 'input' in layer_name:
-                layer_order.append(layer_name)
-                input_dim = layer['config']['batch_input_shape']
-                if len(input_dim) >2 : #probably a conv. if >2
-                    input_dim = tuple(input_dim[1:3])
-                else:           # probably a MLP
-                    input_dim = input_dim[1]
-                weight_matrices.append([]) # add an empty weight matrix to pad the array
-                layer_operation.append("")
-
-        return weight_matrices, layer_order, layer_operation, input_dim
 
     def _normalize_weights(self, weight_matrices, scale_factor=None):
         """
         Weight normalization based on the "model based normalization" from Diehl et al. (2015)
         """
-        norm_wlist=[]
 
-        ## Argument checking
+        # Scale factor increases for each layer
         if scale_factor is None:
-            scale_factor = np.arange(1, len(weight_matrices)+1)
+            scale_factor = np.arange(2, len(weight_matrices)+2)
         elif isinstance(scale_factor, (float, int)):
             scale_factor = [scale_factor] * len(weight_matrices)
-        elif isinstance(scale_factor, (list, np.array)):
+        elif isinstance(scale_factor, (list, np.ndarray)):
             if len(scale_factor) != len(weight_matrices):
-                Global._error("The length of the scale_factor list must be equal the number of projections.")
+                Messages._error("The length of the scale_factor list must be equal to the number of projections.")
             else:
                 pass # nothing to do
         else:
             raise ValueError("Invalid argument for scale_factor", type(scale_factor))
 
-        ## iterate over all weight matrices
-        for level in range(len(weight_matrices)):
-            max_pos_input = 0
-            w_matrix = copy(weight_matrices[level])
-            if len(w_matrix)> 0: # Empty weight matrix ?
-                ## each row correspnds to one post-synaptic neuron
-                for row in range (w_matrix.shape[0]):
-                    w_matrix_flat=w_matrix[row].flatten()
-                    idx=np.where(w_matrix_flat>0)
-                    input_sum=np.sum(w_matrix_flat[idx])
-                    ## save the maximum input current over all post neurons in this connection
-                    max_pos_input = max(max_pos_input, input_sum)
-
-                for row in range (w_matrix.shape[0]):
-                    ## normalize the incoming weights for each neuron, based on the maximum input
-                    ## for the complete connection
-                    ## and multiply it with the deepth of the connection to boost the input current
-                    w_matrix[row]=scale_factor[level]* w_matrix[row]/max_pos_input
+        # Iterate over all weight matrices
+        factors = []
+        for level, w_matrix in enumerate(weight_matrices):
+
+            factor = 1.0
+
+            if len(w_matrix)> 0: # Empty weight matrix is for max-pooling
+
+                # Reshape the matrix with post-neurons first
+                w = w_matrix.reshape((w_matrix.shape[0], -1))
+
+                # Maximum input current over all post neurons
+                max_val = np.sum(w * (w > 0), axis=1).max()
 
-            norm_wlist.append(w_matrix)
+                # Normalize the incoming weights for each neuron, based on the maximum input for the complete connection 
+                # and multiply it with the depth of the connection to boost the input current
+                factor = scale_factor[level]  / max_val
+
+            factors.append(factor)
+
+        return factors
+
+def get_shape(tensor) -> tuple:
+    """
+    Returns the shape of the tensorflow tensor as a tuple.
+
+    tf < 2.14 returned a TensorShape object, but now it is a tuple.
+    
+    """
+    if isinstance(tensor.shape, (tuple,)):
+        return tensor.shape
+    else:
+        try:
+            return tuple(tensor.shape.as_list())
+        except:
+            Messages._error("ANN_to_SNN: unable to estimate the layer's size.")
 
-        return norm_wlist
```

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/ann_to_snn_conversion/InputEncoding.py` & `annarchy-4.8.0.1/ANNarchy/extensions/ann_to_snn_conversion/InputEncoding.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 from ANNarchy.core.Neuron import Neuron
 
-#=====================================================ENCODING TECHNICHS =========================================================================
+#=====================================================ENCODING TECHNIQUES =========================================================================
 #
 #	The Intrinsically Bursting and Chattering type of encoding has implemented by referring to the paper "Simple Model of Spiking Neurons"
 #	by Eugene M. Izhikevich, this is achieved by manipulating the parameters of Izhikevich Neuron and the nature of the neuron activity
 #	of the these two technichs are as of Burst Coding.
 #
 #	The Phase Coding Oscillation type of encoidng has implemented by referring ot the paper "Deep neural networks with weighted spikes"
 #	by Jaehyun Kim et al., this is achieved by writing the equation of the phase(equation 6) of the referred paper and multiplying phase
-#	with the thershold(vt being constant) value to set the new dynamic thershold.
+#	with the threshold (vt being constant) value to set the new dynamic thershold.
 #
 
 __all__ = ["CPN", "IB", "PSO"]
 
 #====================================================Custom Poisson Neuron========================================================================
 
 CPN = Neuron(
```

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/ann_to_snn_conversion/ReadOut.py` & `annarchy-4.8.0.1/ANNarchy/extensions/ann_to_snn_conversion/ReadOut.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/bold/AccProjection.py` & `annarchy-4.8.0.1/ANNarchy/extensions/bold/AccProjection.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,14 +1,16 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-from ANNarchy.core.SpecificProjection import SpecificProjection
-from ANNarchy.core import Global
+from ANNarchy.intern.SpecificProjection import SpecificProjection
+from ANNarchy.intern.ConfigManagement import get_global_config
+
+from ANNarchy.intern import Messages
 
 class AccProjection(SpecificProjection):
     """
     Accumulates the values of a given variable.
     """
     def __init__(self, pre, post, target, variable, name=None, normalize_input=0, scale_factor=1.0, copied=False):
         # Instantiate the projection
@@ -16,15 +18,15 @@
         
         self._variable = variable
         self._scale_factor = scale_factor
         self._normalize_input = normalize_input
 
         # Check population type of the receiving population
         if not self.post.neuron_type.type == 'rate':
-            Global._error('The post-synaptic population of an AccProjection must be rate-coded.')
+            Messages._error('The post-synaptic population of an AccProjection must be rate-coded.')
 
         # Prevent automatic split of matrices
         self._no_split_matrix = True
 
     def _copy(self, pre, post):
         "Returns a copy of the population when creating networks. Internal use only."
         return AccProjection(pre=pre, post=post, target=self.target, variable=self._variable, name=self.name, normalize_input=self._normalize_input, scale_factor=self._scale_factor, copied=True)
@@ -36,15 +38,15 @@
         found = False
         for var in self.pre.neuron_type.description['variables']:
             if var['name'] == self._variable:
                 found = True
                 break
 
         if not found:
-            Global._warning("Variable might be invalid ...")
+            Messages._warning("Variable might be invalid ...")
 
         single_ids = {'id_pre': self.pre.id,'var': self._variable}
 
         if self._normalize_input == 0:
             # Generate Code Template
             self._specific_template['psp_prefix'] = ""
             self._specific_template['psp_code'] = """
@@ -59,15 +61,15 @@
         }
 """ % {
     'id_post': self.post.id,
     'id_pre': self.pre.id,
     'var': self._variable,
     'target': self.target,
     'scale_factor': self._scale_factor,
-    'float_prec': Global.config['precision']
+    'float_prec': get_global_config('precision')
 }
 
         else:
             # Generate Code Template
             self._specific_template['declare_additional'] = """
     std::vector<std::vector<%(float_prec)s>> baseline;
     std::vector<%(float_prec)s> baseline_mean;
@@ -77,30 +79,30 @@
     void start(int baseline_period) {
         init_baseline_period=baseline_period;
         time_for_init_baseline = t + baseline_period;
     #ifdef _DEBUG
         std::cout << "ProjStruct%(id_proj)s: set new baseline period from step " << t << " to step " << time_for_init_baseline << std::endl;
     #endif
     }
-""" % {'id_proj': self.id, 'float_prec': Global.config['precision']}
+""" % {'id_proj': self.id, 'float_prec': get_global_config('precision')}
             self._specific_template['export_additional'] = """
         void start(int)
 """
             self._specific_template['wrapper_access_additional'] = """
     def start(self, baseline_period):
         proj%(id_proj)s.start(baseline_period)
 """ % {'id_proj': self.id}
 
             self._specific_template['init_additional'] = """
         time_for_init_baseline = -1;
         init_baseline_period=1;
         baseline = std::vector<std::vector<%(float_prec)s>>(post_rank.size(), std::vector<%(float_prec)s>() );
         baseline_mean = std::vector<%(float_prec)s>(post_rank.size(), 0);
         baseline_std = std::vector<%(float_prec)s>(post_rank.size(), 1);
-""" % {'float_prec': Global.config['precision']}
+""" % {'float_prec': get_global_config('precision')}
             self._specific_template['clear_additional'] = """
         for(auto it = baseline.begin(); it != baseline.end(); it++) {
             it->clear();
             it->shrink_to_fit();
         }
         baseline.clear();
         baseline.shrink_to_fit();
@@ -161,29 +163,29 @@
         }
 """ % {
     'id_post': self.post.id,
     'id_pre': self.pre.id,
     'var': self._variable,
     'target': self.target,
     'scale_factor': self._scale_factor,
-    'float_prec': Global.config['precision']
+    'float_prec': get_global_config('precision')
 }
 
     def _generate_omp(self):
         """
         """
         # Sanity Check
         found = False
         for var in self.pre.neuron_type.description['variables']:
             if var['name'] == self._variable:
                 found = True
                 break
 
         if not found:
-            Global._warning("Variable might be invalid ...")
+            Messages._warning("Variable might be invalid ...")
 
         single_ids = {'id_pre': self.pre.id,'var': self._variable}
 
         if self._normalize_input == 0:
             # Generate Code Template
             self._specific_template['psp_prefix'] = ""
             self._specific_template['psp_code'] = """
@@ -199,15 +201,15 @@
         }
 """ % {
     'id_post': self.post.id,
     'id_pre': self.pre.id,
     'var': self._variable,
     'target': self.target,
     'scale_factor': self._scale_factor,
-    'float_prec': Global.config['precision']
+    'float_prec': get_global_config('precision')
 }
 
         else:
             # Generate Code Template
             self._specific_template['declare_additional'] = """
     std::vector<std::vector<%(float_prec)s>> baseline;
     std::vector<%(float_prec)s> baseline_mean;
@@ -217,30 +219,30 @@
     void start(int baseline_period) {
         init_baseline_period=baseline_period;
         time_for_init_baseline = t + baseline_period;
     #ifdef _DEBUG
         std::cout << "ProjStruct%(id_proj)s: set new baseline period from step " << t << " to step " << time_for_init_baseline << std::endl;
     #endif
     }
-""" % {'id_proj': self.id, 'float_prec': Global.config['precision']}
+""" % {'id_proj': self.id, 'float_prec': get_global_config('precision')}
             self._specific_template['export_additional'] = """
         void start(int)
 """
             self._specific_template['wrapper_access_additional'] = """
     def start(self, baseline_period):
         proj%(id_proj)s.start(baseline_period)
 """ % {'id_proj': self.id}
 
             self._specific_template['init_additional'] = """
         time_for_init_baseline = -1;
         init_baseline_period=1;
         baseline = std::vector<std::vector<%(float_prec)s>>(post_rank.size(), std::vector<%(float_prec)s>() );
         baseline_mean = std::vector<%(float_prec)s>(post_rank.size(), 0);
         baseline_std = std::vector<%(float_prec)s>(post_rank.size(), 1);
-""" % {'float_prec': Global.config['precision']}
+""" % {'float_prec': get_global_config('precision')}
 
             self._specific_template['psp_prefix'] = ""
             self._specific_template['psp_code'] = """
         bool compute_baseline = (t < time_for_init_baseline) ? true : false;
         bool compute_average = (t == time_for_init_baseline) ? true : false;
 
         #pragma omp for
@@ -289,12 +291,12 @@
         }
 """ % {
     'id_post': self.post.id,
     'id_pre': self.pre.id,
     'var': self._variable,
     'target': self.target,
     'scale_factor': self._scale_factor,
-    'float_prec': Global.config['precision']
+    'float_prec': get_global_config('precision')
 }
 
     def _generate_cuda(self):
         raise NotImplementedError("The AccProjection (part of the BOLD monitor) is not available for CUDA devices yet.")
```

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/bold/BoldMonitor.py` & `annarchy-4.8.0.1/ANNarchy/extensions/bold/BoldMonitor.py`

 * *Files 5% similar despite different names*

```diff
@@ -2,63 +2,69 @@
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 from ANNarchy.core.Population import Population
 from ANNarchy.core.Monitor import Monitor
 from ANNarchy.core import Global
+from ANNarchy.intern.NetworkManager import NetworkManager
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern import Messages
 
 from .PredefinedModels import balloon_RN
 from .AccProjection import AccProjection
 
 import inspect
 
 class BoldMonitor(object):
     """
     Monitors the BOLD signal for several populations using a computational model.
 
     The BOLD monitor transforms one or two input population variables (such as the mean firing rate) into a recordable BOLD signal according to a computational model (for example a variation of the Balloon model).
-    """
-    def __init__(self,
-        populations=None,
-        bold_model=balloon_RN,
-        mapping={'I_CBF': 'r'},
-        scale_factor=None,
-        normalize_input=None,
-        recorded_variables=None,
-        start=False,
-        net_id=0,
-        copied=False):
-        """
-        :param populations: list of recorded populations.
 
-        :param bold_model: computational model for BOLD signal defined as a BoldModel class/object (see ANNarchy.extensions.bold.PredefinedModels for more predefined examples). Default is `balloon_RN`.
 
-        :param mapping: mapping dictionary between the inputs of the BOLD model (`I_CBF` for single inputs, `I_CBF` and `I_CMRO2` for double inputs in the provided examples) and the variables of the input populations. By default, `{'I_CBF': 'r'}` maps the firing rate `r` of the input population(s) to the variable `I_CBF` of the BOLD model. 
+    :param populations: list of recorded populations.
 
-        :param scale_factor: list of float values to allow a weighting of signals between populations. By default, the input signal is weighted by the ratio of the population size to all populations within the recorded region.
+    :param bold_model: computational model for BOLD signal defined as a BoldModel object. Default is `balloon_RN`.
 
-        :param normalize_input: list of integer values which represent a optional baseline per population. The input signals will require an additional normalization using a baseline value. A value different from 0 represents the time period for determing this baseline in milliseconds (biological time).
+    :param mapping: mapping dictionary between the inputs of the BOLD model (`I_CBF` for single inputs, `I_CBF` and `I_CMRO2` for double inputs in the provided examples) and the variables of the input populations. By default, `{'I_CBF': 'r'}` maps the firing rate `r` of the input population(s) to the variable `I_CBF` of the BOLD model. 
 
-        :param recorded_variables: which variables of the BOLD model should be recorded? (by default, the output variable of the BOLD model is added, e.g. ["BOLD"] for the provided examples).
-        """
+    :param scale_factor: list of float values to allow a weighting of signals between populations. By default, the input signal is weighted by the ratio of the population size to all populations within the recorded region.
+
+    :param normalize_input: list of integer values which represent a optional baseline per population. The input signals will require an additional normalization using a baseline value. A value different from 0 represents the time period for determing this baseline in milliseconds (biological time).
+
+    :param recorded_variables: which variables of the BOLD model should be recorded? (by default, the output variable of the BOLD model is added, e.g. ["BOLD"] for the provided examples).
+
+    :param start: whether to start recording directly.
+    """
+    def __init__(self,
+        populations: list=None,
+        bold_model: 'BoldModel' =balloon_RN,
+        mapping: dict={'I_CBF': 'r'},
+        scale_factor: list[float]=None,
+        normalize_input: list[int]=None,
+        recorded_variables: list[str]=None,
+        start:bool=False,
+        net_id:int=0,
+        copied:bool=False):
+        
         self.net_id = net_id
 
         # instantiate if necessary, please note
         # that population will make a deepcopy on this objects
         if inspect.isclass(bold_model):
             bold_model = bold_model()
 
         # for reporting
         bold_model._model_instantiated = True
 
         # The usage of [] as default arguments in the __init__ call lead to strange side effects.
         # We decided therefore to use None as default and create the lists locally.
         if populations is None:
-            Global._error("Either a population or a list of populations must be provided to the BOLD monitor (populations=...)")
+            Messages._error("Either a population or a list of populations must be provided to the BOLD monitor (populations=...)")
         if scale_factor is None:
             scale_factor = []
         if normalize_input is None:
             normalize_input = []
         if recorded_variables is None:
             recorded_variables = []
 
@@ -70,39 +76,39 @@
         if not(isinstance(normalize_input, list)):
             normalize_input = [normalize_input]*len(populations)
         if isinstance(recorded_variables, str):
             recorded_variables = [recorded_variables]
 
         if len(scale_factor) > 0:
             if len(populations) != len(scale_factor):
-                Global._error("BoldMonitor: Length of scale_factor must be equal to number of populations")
+                Messages._error("BoldMonitor: Length of scale_factor must be equal to number of populations")
 
         if len(normalize_input) > 0:
             if len(populations) != len(normalize_input):
-                Global._error("BoldMonitor: Length of normalize_input must be equal to number of populations")
+                Messages._error("BoldMonitor: Length of normalize_input must be equal to number of populations")
 
         # Check mapping
         for target, input_var in mapping.items():
             if not target in bold_model._inputs:
-                Global._error("BoldMonitor: the key " + target + " of mapping is not part of the BOLD model.")
+                Messages._error("BoldMonitor: the key " + target + " of mapping is not part of the BOLD model.")
 
         # Check recorded variables
         if len(recorded_variables) == 0:
             recorded_variables = bold_model._output
         else:
             # Add the output variables (and remove doublons)
             l1 = bold_model._output
             l2 = [recorded_variables] if isinstance(recorded_variables, str) else recorded_variables
             recorded_variables = list(set(l2+l1))
             recorded_variables.sort()
 
         if not copied:
             # Add the container to the object management
-            Global._network[0]['extensions'].append(self)
-            self.id = len(Global._network[self.net_id]['extensions'])
+            NetworkManager().add_extension(net_id=0, extension=self)
+            self.id = NetworkManager().number_extensions(net_id=0)
 
             # create the population
             self._bold_pop = Population(1, neuron=bold_model, name= bold_model.name )
             self._bold_pop.enabled = start
 
             # create the monitor
             self._monitor = Monitor(self._bold_pop, recorded_variables, start=start)
@@ -132,16 +138,16 @@
 
                     tmp_proj.connect_all_to_all(weights= 1.0)
 
                     self._acc_proj.append(tmp_proj)
 
         else:
             # Add the container to the object management
-            Global._network[net_id]['extensions'].append(self)
-            self.id = len(Global._network[self.net_id]['extensions'])
+            NetworkManager().add_extension(net_id=self.net_id, extension=self)
+            self.id = NetworkManager().number_extensions(net_id=self.net_id)
 
             # instances are assigned by the copying instance
             self._bold_pop = None
             self._monitor = None
             self._acc_proj = []
 
         self.name = "bold_monitor"
@@ -159,38 +165,38 @@
         self._initialized = True if not copied else False
 
     #
     #   MONITOR functions
     #
     def start(self):
         """
-        Same as `ANNarchy.core.Monitor.start()`
+        Starts recording as in `ANNarchy.core.Monitor.start()`.
         """
         self._monitor.start()
 
         # enable ODEs
         self._bold_pop.cyInstance.activate(True)
 
         # check if we have projections with baseline
         for proj in self._acc_proj:
             if proj._normalize_input > 0:
-                proj.cyInstance.start(proj._normalize_input/Global.config["dt"])
+                proj.cyInstance.start(proj._normalize_input/get_global_config('dt'))
 
     def stop(self):
         """
-        Same as `ANNarchy.core.Monitor.stop()`
+        Stops recording as in `ANNarchy.core.Monitor.stop().
         """
         self._monitor.stop()
 
         # enable ODEs
         self._bold_pop.cyInstance.activate(False)
 
     def get(self, variable):
         """
-        Same as `ANNarchy.core.Monitor.get()`
+        Retrieves recordings as in `ANNarchy.core.Monitor.get()`.
         """
         return self._monitor.get(variable)
 
 
     #
     #   POPULATION functions i. e. access to model parameter
     #
@@ -200,15 +206,15 @@
     def __getattr__(self, name):
 
         if name == '_initialized' or not hasattr(self, '_initialized'): # Before the end of the constructor
             return object.__getattribute__(self, name)
 
         if self._initialized:
             if self._bold_pop.initialized == False:
-                Global._error("BoldMonitor: attributes can not modified before compile()")
+                Messages._error("BoldMonitor: attributes can not modified before compile()")
 
             if name in self._bold_pop.attributes:
                 return getattr(self._bold_pop, name)
 
         return object.__getattribute__(self, name)
 
     # Method called when accessing an attribute.
@@ -216,15 +222,15 @@
     def __setattr__(self, name, value):
 
         if name == '_initialized' or not hasattr(self, '_initialized'): # Before the end of the constructor
             return object.__setattr__(self, name, value)
 
         if self._initialized:
             if self._bold_pop.initialized == False:
-                Global._error("BoldMonitor: attributes can not modified before compile()")
+                Messages._error("BoldMonitor: attributes can not modified before compile()")
 
             if name in self._bold_pop.attributes:
                 setattr(self._bold_pop, name, value)
             else:
                 raise AttributeError("the variable '"+str(name)+ "' is not an attribute of the bold model.")
 
         else:
```

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/bold/NormProjection.py` & `annarchy-4.8.0.1/ANNarchy/extensions/bold/NormProjection.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,17 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 import numpy as np
 
-from ANNarchy.core.SpecificProjection import SpecificProjection
+from ANNarchy.intern.SpecificProjection import SpecificProjection
+from ANNarchy.intern.ConfigManagement import _check_paradigm
+from ANNarchy.intern import Messages
 from ANNarchy.core import Global
 
 class NormProjection(SpecificProjection):
     """
     Behaves like normal spike synapse but also generates a normalized conductance
     which means that the increase is normalized by the number of afferent synapses.
 
@@ -28,25 +30,25 @@
     def __init__(self, pre, post, target, variable, synapse=None, name=None, copied=False):
         # Instantiate the projection
         SpecificProjection.__init__(self, pre, post, target, synapse=synapse, name=name, copied=copied)
         self._variable = variable
 
         # Check populations
         if not self.pre.neuron_type.type == 'spike':
-            Global._error('The pre-synaptic population of an NormProjection must be spiking.')
+            Messages._error('The pre-synaptic population of an NormProjection must be spiking.')
 
         if not self.pre.neuron_type.type == 'spike':
-            Global._error('The post-synaptic population of an NormProjection must be spiking.')
+            Messages._error('The post-synaptic population of an NormProjection must be spiking.')
 
         if synapse != None and not copied:
-            Global._error('NormProjection does not allow the usage of customized spiking synapses yet.')
+            Messages._error('NormProjection does not allow the usage of customized spiking synapses yet.')
 
         # Not on CUDA
-        if Global._check_paradigm('cuda'):
-            Global._error('NormProjections are not available on CUDA yet.')
+        if _check_paradigm('cuda'):
+            Messages._error('NormProjections are not available on CUDA yet.')
 
         # Prevent automatic split of matrices
         self._no_split_matrix = True
 
     def _copy(self, pre, post):
         "Returns a copy of the population when creating networks. Internal use only."
         return NormProjection(pre=pre, post=post, target=self.target, variable=self._variable, synapse=self.synapse_type, name=self.name, copied=True)
@@ -58,15 +60,15 @@
         found = False
         for var in self.post.neuron_type.description['variables']:
             if var['name'] == self._variable:
                 found = True
                 break
 
         if not found:
-            Global._error("NormProjection: variable `"+self._variable+"` might be invalid. Please check the neuron model of population", self.post.name)
+            Messages._error("NormProjection: variable `"+self._variable+"` might be invalid. Please check the neuron model of population", self.post.name)
 
         # TODO: delays???
         if self.synapse_type.pre_axon_spike:
             pre_array = "tmp_spiked"
             pre_array_fusion = """
             std::vector<int> tmp_spiked = %(pre_array)s;
             tmp_spiked.insert( tmp_spiked.end(), pop%(id_pre)s.axonal.begin(), pop%(id_pre)s.axonal.end() );
@@ -175,15 +177,15 @@
         found = False
         for var in self.post.neuron_type.description['variables']:
             if var['name'] == self._variable:
                 found = True
                 break
 
         if not found:
-            Global._error("NormProjection: variable `"+self._variable+"` might be invalid. Please check the neuron model of population", self.post.name)
+            Messages._error("NormProjection: variable `"+self._variable+"` might be invalid. Please check the neuron model of population", self.post.name)
 
         # TODO: delays???
         if self.synapse_type.pre_axon_spike:
             pre_array = "tmp_spiked"
             pre_array_fusion = """
             std::vector<int> tmp_spiked = %(pre_array)s;
             tmp_spiked.insert( tmp_spiked.end(), pop%(id_pre)s.axonal.begin(), pop%(id_pre)s.axonal.end() );
```

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/bold/PredefinedModels.py` & `annarchy-4.8.0.1/ANNarchy/extensions/bold/PredefinedModels.py`

 * *Files 1% similar despite different names*

```diff
@@ -61,40 +61,39 @@
 
             # Non-linear equation
             BOLD           = V_0 * (k_1 * (1 - q) + k_2 * (1 - (q / v)) + k_3 * (1 - v))  : init=0
         ''',
         inputs="I_CBF",
     )
     ```
+
+    :param phi:       input coefficient
+    :param kappa:     signal decay
+    :param gamma:     feedback regulation
+    :param E_0:       oxygen extraction fraction at rest
+    :param tau:       time constant (in s!)
+    :param alpha:     vessel stiffness
+    :param V_0:       resting venous blood volume fraction
+    :param v_0:       frequency offset at the outer surface of the magnetized vessel for fully deoxygenated blood at 1.5 T
+    :param TE:        echo time
+    :param epsilon:   ratio of intra- and extravascular signal
     """
     def __init__(self,
             phi       = 1.0,
             kappa     = 1/1.54,
             gamma     = 1/2.46,
             E_0       = 0.34,
             tau       = 0.98,
             alpha     = 0.33,
             V_0       = 0.02,
             v_0       = 40.3,
             TE        = 40/1000.,
             epsilon   = 1.43,
         ):
 
-        """
-        :param phi:       input coefficient
-        :param kappa:     signal decay
-        :param gamma:     feedback regulation
-        :param E_0:       oxygen extraction fraction at rest
-        :param tau:       time constant (in s!)
-        :param alpha:     vessel stiffness
-        :param V_0:       resting venous blood volume fraction
-        :param v_0:       frequency offset at the outer surface of the magnetized vessel for fully deoxygenated blood at 1.5 T
-        :param TE:        echo time
-        :param epsilon:   ratio of intra- and extravascular signal
-        """
         parameters = """
             second    = 1000.0 : population
             phi       = %(phi)s : population
             kappa     = %(kappa)s : population
             gamma     = %(gamma)s : population
             E_0       = %(E_0)s : population
             tau       = %(tau)s : population
@@ -186,40 +185,39 @@
 
             # Linear equation
             BOLD           = V_0 * ((k_1 + k_2) * (1 - q) + (k_3 - k_2) * (1 - v))        : init=0
         ''',
         inputs="I_CBF",
     )
     ```
+
+    :param phi:       input coefficient
+    :param kappa:     signal decay
+    :param gamma:     feedback regulation
+    :param E_0:       oxygen extraction fraction at rest
+    :param tau:       time constant (in s!)
+    :param alpha:     vessel stiffness
+    :param V_0:       resting venous blood volume fraction
+    :param v_0:       frequency offset at the outer surface of the magnetized vessel for fully deoxygenated blood at 1.5 T
+    :param TE:        echo time
+    :param epsilon:   ratio of intra- and extravascular signal
     """
     def __init__(self,
             phi       = 1.0,
             kappa     = 1/1.54,
             gamma     = 1/2.46,
             E_0       = 0.34,
             tau       = 0.98,
             alpha     = 0.33,
             V_0       = 0.02,
             v_0       = 40.3,
             TE        = 40/1000.,
             epsilon   = 1.43,
         ):
 
-        """
-        :param phi:       input coefficient
-        :param kappa:     signal decay
-        :param gamma:     feedback regulation
-        :param E_0:       oxygen extraction fraction at rest
-        :param tau:       time constant (in s!)
-        :param alpha:     vessel stiffness
-        :param V_0:       resting venous blood volume fraction
-        :param v_0:       frequency offset at the outer surface of the magnetized vessel for fully deoxygenated blood at 1.5 T
-        :param TE:        echo time
-        :param epsilon:   ratio of intra- and extravascular signal
-        """
         parameters = """
             second    = 1000.0 : population
             phi       = %(phi)s : population
             kappa     = %(kappa)s : population
             gamma     = %(gamma)s : population
             E_0       = %(E_0)s : population
             tau       = %(tau)s : population
@@ -311,14 +309,26 @@
 
             # Non-linear equation
             BOLD           = V_0 * (k_1 * (1 - q) + k_2 * (1 - (q / v)) + k_3 * (1 - v))  : init=0
         ''',
         inputs="I_CBF",
     )
     ```
+
+    :param phi:       input coefficient
+    :param kappa:     signal decay
+    :param gamma:     feedback regulation
+    :param E_0:       oxygen extraction fraction at rest
+    :param tau:       time constant (in s!)
+    :param alpha:     vessel stiffness
+    :param V_0:       resting venous blood volume fraction
+    :param v_0:       frequency offset at the outer surface of the magnetized vessel for fully deoxygenated blood at 1.5 T
+    :param TE:        echo time
+    :param epsilon:   ratio of intra- and extravascular signal
+    :param r_0:       slope of the relation between the intravascular relaxation rate and oxygen saturation
     """
     def __init__(self,
             phi       = 1.0,
             kappa     = 1/1.54,
             gamma     = 1/2.46,
             E_0       = 0.34,
             tau       = 0.98,
@@ -326,27 +336,14 @@
             V_0       = 0.02,
             v_0       = 40.3,
             TE        = 40/1000.,
             epsilon   = 1.43,
             r_0       = 25,
         ):
 
-        """
-        :param phi:       input coefficient
-        :param kappa:     signal decay
-        :param gamma:     feedback regulation
-        :param E_0:       oxygen extraction fraction at rest
-        :param tau:       time constant (in s!)
-        :param alpha:     vessel stiffness
-        :param V_0:       resting venous blood volume fraction
-        :param v_0:       frequency offset at the outer surface of the magnetized vessel for fully deoxygenated blood at 1.5 T
-        :param TE:        echo time
-        :param epsilon:   ratio of intra- and extravascular signal
-        :param r_0:       slope of the relation between the intravascular relaxation rate and oxygen saturation
-        """
         parameters = """
             second    = 1000.0 : population
             phi       = %(phi)s : population
             kappa     = %(kappa)s : population
             gamma     = %(gamma)s : population
             E_0       = %(E_0)s : population
             tau       = %(tau)s : population
@@ -440,14 +437,27 @@
 
             # Linear equation
             BOLD           = V_0 * ((k_1 + k_2) * (1 - q) + (k_3 - k_2) * (1 - v))         : init=0
         ''',
         inputs="I_CBF",
     )
     ```
+
+    :param phi:       input coefficient
+    :param kappa:     signal decay
+    :param gamma:     feedback regulation
+    :param E_0:       oxygen extraction fraction at rest
+    :param tau:       time constant (in s!)
+    :param alpha:     vessel stiffness
+    :param V_0:       resting venous blood volume fraction
+    :param v_0:       frequency offset at the outer surface of the magnetized vessel for fully deoxygenated blood at 1.5 T
+    :param TE:        echo time
+    :param epsilon:   ratio of intra- and extravascular signal
+    :param r_0:       slope of the relation between the intravascular relaxation rate and oxygen saturation
+
     """
     def __init__(self,
             phi       = 1.0,
             kappa     = 1/1.54,
             gamma     = 1/2.46,
             E_0       = 0.34,
             tau       = 0.98,
@@ -455,28 +465,14 @@
             V_0       = 0.02,
             v_0       = 40.3,
             TE        = 40/1000.,
             epsilon   = 1.43,
             r_0       = 25,
         ):
 
-        """
-        :param phi:       input coefficient
-        :param kappa:     signal decay
-        :param gamma:     feedback regulation
-        :param E_0:       oxygen extraction fraction at rest
-        :param tau:       time constant (in s!)
-        :param alpha:     vessel stiffness
-        :param V_0:       resting venous blood volume fraction
-        :param v_0:       frequency offset at the outer surface of the magnetized vessel for fully deoxygenated blood at 1.5 T
-        :param TE:        echo time
-        :param epsilon:   ratio of intra- and extravascular signal
-        :param r_0:       slope of the relation between the intravascular relaxation rate and oxygen saturation
-        """
-
         parameters = """
             second    = 1000.0 : population
             phi       = %(phi)s : population
             kappa     = %(kappa)s : population
             gamma     = %(gamma)s : population
             E_0       = %(E_0)s : population
             tau       = %(tau)s : population
```

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/convolution/Convolve.py` & `annarchy-4.8.0.1/ANNarchy/extensions/convolution/Convolve.py`

 * *Files 5% similar despite different names*

```diff
@@ -4,36 +4,39 @@
 """
 
 from __future__ import print_function
 import numpy as np
 from copy import deepcopy
 
 from ANNarchy.core import Global
-from ANNarchy.core.SpecificProjection import SpecificProjection
+from ANNarchy.intern.SpecificProjection import SpecificProjection
+from ANNarchy.intern.ConfigManagement import get_global_config, _check_paradigm
+from ANNarchy.intern import Messages
 
 from ANNarchy.generator.Utils import tabify, remove_trailing_spaces
 from .ConvolveTemplate import *
 from .Utils import SharedSynapse
 
 # Indices used for each dimension
 indices = ['i', 'j', 'k', 'l', 'm', 'n']
 
 class Convolution(SpecificProjection):
-    """
+    r"""
     Performs a convolution of a weight kernel on the pre-synaptic population.
 
     Despite its name, the operation performed is actually a cross-correlation, as is usual in computer vision and convolutional neural networks:
 
     $$g(x) = \sum_{k=-n}^n h(k) \, f(x + k)$$
 
     The convolution operation benefits from giving a multi-dimensional geometry to the populations and filters, for example in 2D:
 
     ```python
-    inp = Population(geometry=(100, 100), neuron=Neuron(parameters="r = 0.0"))
-    pop = Population(geometry=(100, 100), neuron=Neuron(equations="r = sum(exc)"))
+    inp = ann.Population(geometry=(100, 100), neuron=ann.Neuron(parameters="r = 0.0"))
+    pop = ann.Population(geometry=(100, 100), neuron=ann.Neuron(equations="r = sum(exc)"))
+    
     proj = Convolution(inp, pop, 'exc')
     proj.connect_filter(
         [
             [-1., 0., 1.],
             [-1., 0., 1.],
             [-1., 0., 1.]
         ])
@@ -66,24 +69,24 @@
     The convolution **always** uses padding for elements that would be outside the array (no equivalent of ``valid`` in tensorflow). It is 0.0 by default, but can be changed using the ``padding`` argument. Setting ``padding`` to the string ``border`` will repeat the value of the border elements.
 
     Sub-sampling will be automatically performed according to the populations' geometry. If these geometries do not match, an error will be thrown. Example:
 
         (100, 100) * (3, 3) -> (50, 50)
 
     You can redefine the sub-sampling by providing a list ``subsampling`` as argument, defining for each post-synaptic neuron the coordinates of the pre-synaptic neuron which will be the center of the filter/kernel.
+
+    :param pre: pre-synaptic population (either its name or a ``Population`` object).
+    :param post: post-synaptic population (either its name or a ``Population`` object).
+    :param target: type of the connection
+    :param psp: continuous influence of a single synapse on the post-synaptic neuron (default for rate-coded: ``w*pre.r``).
+    :param operation: operation (sum, max, min, mean) performed by the kernel (default: sum).
     """
 
     def __init__(self, pre, post, target, psp="pre.r * w", operation="sum", name=None, copied=False):
-        """
-        :param pre: pre-synaptic population (either its name or a ``Population`` object).
-        :param post: post-synaptic population (either its name or a ``Population`` object).
-        :param target: type of the connection
-        :param psp: continuous influence of a single synapse on the post-synaptic neuron (default for rate-coded: ``w*pre.r``).
-        :param operation: operation (sum, max, min, mean) performed by the kernel (default: sum).
-        """
+
         # Create the description, but it will not be used for generation
         SpecificProjection.__init__(
             self,
             pre,
             post,
             target,
             synapse=SharedSynapse(psp=psp, operation=operation, name="Convolution operation", description="Convoluted kernel over the pre-synaptic population."),
@@ -129,58 +132,58 @@
 
         # Process the weights
         self.weights = np.array(weights)
 
         # Process the delays
         self.delays = float(delays)
         if not isinstance(delays, (int, float)):
-            Global._error('Convolutions can only have constant delays.')
+            Messages._error('Convolutions can only have constant delays.')
 
         self.subsampling = subsampling
         self.keep_last_dimension = keep_last_dimension
         self.padding = padding
         self.multiple = False
 
         # Check dimensions of populations and weight matrix
         self.dim_kernel = self.weights.ndim
         self.dim_pre = self.pre.dimension
         self.dim_post = self.post.dimension
 
         if self.dim_post > 4:
             print("Convolution:", self.dim_pre, '*', self.dim_kernel, '->', self.dim_post)
-            Global._error('Convolution: Too many dimensions for the post-synaptic population (maximum 4).')
+            Messages._error('Convolution: Too many dimensions for the post-synaptic population (maximum 4).')
 
         if self.dim_pre > 4:
             print("Convolution:", self.dim_pre, '*', self.dim_kernel, '->', self.dim_post)
-            Global._error('Convolution: Too many dimensions for the pre-synaptic population (maximum 4).')
+            Messages._error('Convolution: Too many dimensions for the pre-synaptic population (maximum 4).')
 
         if self.dim_kernel > 5  or (not self.multiple and self.dim_kernel > 4):
             print("Convolution:", self.dim_pre, '*', self.dim_kernel, '->', self.dim_post)
-            Global._error('Convolution: Too many dimensions for the kernel (maximum 4).')
+            Messages._error('Convolution: Too many dimensions for the kernel (maximum 4).')
 
         # Check if the last axes match for parallel convolution (e.g. 3-2-3)
         if self.dim_kernel < self.dim_pre:
             if not self.keep_last_dimension:
                 print("Convolution:", self.dim_pre, '*', self.dim_kernel, '->', self.dim_post)
-                Global._error('Convolution: If the kernel has less dimensions than the pre-synaptic population, you need to set the flag keep_last_dimension to True.')
+                Messages._error('Convolution: If the kernel has less dimensions than the pre-synaptic population, you need to set the flag keep_last_dimension to True.')
 
             if self.pre.geometry[-1] != self.post.geometry[-1]:
                 print("Convolution:", self.dim_pre, '*', self.dim_kernel, '->', self.dim_post)
-                Global._error('Convolution: If the kernel has fewer dimensions than the two populations (keep_last_dimension=True), these must have the same number of neurons in the last dimension.')
+                Messages._error('Convolution: If the kernel has fewer dimensions than the two populations (keep_last_dimension=True), these must have the same number of neurons in the last dimension.')
 
         # If the last dim of the kernel matches the last dim of the pre-pop, the last pop can have one dimension less.
         if self.dim_post < self.dim_pre: # OK, but check the last dimension of the kernel has the same size as the post-population
             if self.weights.shape[-1] != self.pre.geometry[-1]:
                 print("Convolution:", self.dim_pre, '*', self.dim_kernel, '->', self.dim_post)
-                Global._error('Convolution: If the post-synaptic population has less dimensions than the pre-synaptic one, the last dimension of the filter must be equal to the last of the pre-synaptic population.')
+                Messages._error('Convolution: If the post-synaptic population has less dimensions than the pre-synaptic one, the last dimension of the filter must be equal to the last of the pre-synaptic population.')
 
         # Check if it is a bank of filters
         if self.dim_kernel > self.dim_pre:
             print("Convolution:", self.dim_pre, '*', self.dim_kernel, '->', self.dim_post)
-            Global._error('Convolution: If the kernel has more dimensions than the pre-synaptic population, you need to use the connect_filters() method.')
+            Messages._error('Convolution: If the kernel has more dimensions than the pre-synaptic population, you need to use the connect_filters() method.')
 
 
         # Generate the pre-synaptic coordinates
         self._generate_pre_coordinates()
 
         # Finish building the synapses
         self._create()
@@ -207,59 +210,59 @@
 
         # Process the weights
         self.weights = np.array(weights)
 
         # Process the delays
         self.delays = float(delays)
         if not isinstance(delays, (int, float)):
-            Global._error('Convolutions can only have constant delays.')
+            Messages._error('Convolutions can only have constant delays.')
 
         self.subsampling = subsampling
         self.keep_last_dimension = keep_last_dimension
         self.padding = padding
         self.multiple = True
 
         # Check dimensions of populations and weight matrix
         self.dim_kernel = self.weights.ndim
         self.dim_pre = self.pre.dimension
         self.dim_post = self.post.dimension
 
 
         if self.dim_post > 4:
             print("Convolution:", self.dim_pre, '*', self.dim_kernel, '->', self.dim_post)
-            Global._error('Convolution: Too many dimensions for the post-synaptic population (maximum 4).')
+            Messages._error('Convolution: Too many dimensions for the post-synaptic population (maximum 4).')
 
         if self.dim_pre > 4:
             print("Convolution:", self.dim_pre, '*', self.dim_kernel, '->', self.dim_post)
-            Global._error('Convolution: Too many dimensions for the pre-synaptic population (maximum 4).')
+            Messages._error('Convolution: Too many dimensions for the pre-synaptic population (maximum 4).')
 
         if self.dim_kernel > 5  or (not self.multiple and self.dim_kernel > 4):
             print("Convolution:", self.dim_pre, '*', self.dim_kernel, '->', self.dim_post)
-            Global._error('Convolution: Too many dimensions for the kernel (maximum 4).')
+            Messages._error('Convolution: Too many dimensions for the kernel (maximum 4).')
 
         # Check if the last axes match for parallel convolution (e.g. 3-2-3)
         if self.dim_kernel < self.dim_pre:
             if not self.keep_last_dimension:
                 print("Convolution:", self.dim_pre, '*', self.dim_kernel, '->', self.dim_post)
-                Global._error('Convolution: If the kernel has less dimensions than the pre-synaptic population, you need to set the flag keep_last_dimension to True.')
+                Messages._error('Convolution: If the kernel has less dimensions than the pre-synaptic population, you need to set the flag keep_last_dimension to True.')
 
             if self.pre.geometry[-1] != self.post.geometry[-1]:
                 print("Convolution:", self.dim_pre, '*', self.dim_kernel, '->', self.dim_post)
-                Global._error('Convolution: If the kernel has fewer dimensions than the two populations (keep_last_dimension=True), these must have the same number of neurons in the last dimension.')
+                Messages._error('Convolution: If the kernel has fewer dimensions than the two populations (keep_last_dimension=True), these must have the same number of neurons in the last dimension.')
 
         # If the last dim of the kernel matches the last dim of the pre-pop, the last pop can have one dimension less.
         if self.dim_post < self.dim_pre: # OK, but check the last dimension of the kernel has the same size as the post-population
             if self.weights.shape[-1] != self.pre.geometry[-1]:
                 print("Convolution:", self.dim_pre, '*', self.dim_kernel, '->', self.dim_post)
-                Global._error('Convolution: If the post-synaptic population has less dimensions than the pre-synaptic one, the last dimension of the filter must be equal to the last of the pre-synaptic population.')
+                Messages._error('Convolution: If the post-synaptic population has less dimensions than the pre-synaptic one, the last dimension of the filter must be equal to the last of the pre-synaptic population.')
 
         # The last dimension of the post population must correspond to the number of filters
         if self.weights.shape[0] != self.post.geometry[-1]:
             print("Convolution:", self.dim_pre, '*', self.dim_kernel, '->', self.dim_post)
-            Global._error('Convolution: For multiple filters, the last dimension of the post-synaptic population must have as many neurons as there are filters.')
+            Messages._error('Convolution: For multiple filters, the last dimension of the post-synaptic population must have as many neurons as there are filters.')
 
         # Generate the pre-synaptic coordinates
         self._generate_pre_coordinates_bank()
 
         # Finish building the synapses
         self._create()
 
@@ -298,18 +301,18 @@
         copied_proj._connection_delay = self._connection_delay
         copied_proj._storage_format = self._storage_format
         return copied_proj
 
     def _create(self):
         # create fake LIL object, just for compilation.
         try:
-            from ANNarchy.core.cython_ext.Connector import LILConnectivity
+            from ANNarchy.cython_ext.Connector import LILConnectivity
         except Exception as e:
-            Global._print(e)
-            Global._error('ANNarchy was not successfully installed.')
+            Messages._print(e)
+            Messages._error('ANNarchy was not successfully installed.')
 
         lil = LILConnectivity()
         lil.max_delay = self.delays
         lil.uniform_delay = self.delays
         self.connector_name = "Convolution"
         self.connector_description = "Convolution"
         self._store_connectivity(self._load_from_lil, (lil, ), self.delays, storage_format="lil", storage_order="post_to_pre")
@@ -318,38 +321,38 @@
     ### Create connection pattern
     ################################
     def _connect(self, module):
         """
         Builds up dendrites either from list or dictionary. Called by instantiate().
         """
         if not self._connection_method:
-            Global._error('Convolution: The projection between ' + self.pre.name + ' and ' + self.post.name + ' is declared but not connected.')
+            Messages._error('Convolution: The projection between ' + self.pre.name + ' and ' + self.post.name + ' is declared but not connected.')
 
         # Create the Cython instance
         proj = getattr(module, 'proj'+str(self.id)+'_wrapper')
         self.cyInstance = proj(self.pre_coordinates, self.weights)
 
         # Set delays after instantiation
         if self.delays > 0.0:
-            self.cyInstance.set_delay(self.delays/Global.config['dt'])
+            self.cyInstance.set_delay(self.delays/get_global_config('dt'))
 
         return True
 
     def _generate_pre_coordinates(self):
         " Returns a list for each post neuron of the corresponding center coordinates."
 
         # Check if the list is already defined:
         if self.subsampling:
             try:
                 shape = np.array(self.subsampling).shape
             except:
-                Global._error('Convolution: The sub-sampling list must have', self.post.size, 'elements of size', self.pre.dimension)
+                Messages._error('Convolution: The sub-sampling list must have', self.post.size, 'elements of size', self.pre.dimension)
                 return
             if shape != (self.post.size, self.pre.dimension):
-                Global._error('Convolution: The sub-sampling list must have', self.post.size, 'elements of size', self.pre.dimension)
+                Messages._error('Convolution: The sub-sampling list must have', self.post.size, 'elements of size', self.pre.dimension)
                 return
             self.pre_coordinates = self.subsampling
             return
 
         # Otherwise create it, possibly with sub-sampling
         coords = [[] for i in range(self.post.size)]
 
@@ -357,15 +360,15 @@
         idx_range= []
         for dim in range(self.dim_pre):
             if dim < self.dim_post:
                 pre_size = int(self.pre.geometry[dim])
                 post_size = int(self.post.geometry[dim])
                 sample = int(pre_size/post_size)
                 if post_size * sample != pre_size:
-                    Global._error('Convolution: The pre-synaptic dimensions must be a multiple of the post-synaptic ones for down-sampling to work.')
+                    Messages._error('Convolution: The pre-synaptic dimensions must be a multiple of the post-synaptic ones for down-sampling to work.')
 
                 idx_range.append([int((sample-1)/2) + sample * i for i in range(post_size)])
             else: # extra dimension
                 if self.keep_last_dimension:
                     idx_range.append(range(self.post.geometry[dim]))
                 else:
                     idx_range.append([self._center_filter(self.weights.shape[dim])])
@@ -408,18 +411,18 @@
         self.dim_single_filter = self.weights.shape[1:]
 
         # Check if the list is already defined:
         if self.subsampling:
             try:
                 shape = np.array(self.subsampling).shape
             except:
-                Global._error('Convolution: The sub-sampling list must have', self.post.size / self.post.geometry[-1], 'elements of size', self.pre.dimension)
+                Messages._error('Convolution: The sub-sampling list must have', self.post.size / self.post.geometry[-1], 'elements of size', self.pre.dimension)
                 return
             if shape != (self.post.size/ self.post.geometry[-1], self.pre.dimension):
-                Global._error('Convolution: The sub-sampling list must have', self.post.size/ self.post.geometry[-1], 'elements of size', self.pre.dimension)
+                Messages._error('Convolution: The sub-sampling list must have', self.post.size/ self.post.geometry[-1], 'elements of size', self.pre.dimension)
                 return
             self.pre_coordinates = [c + [d] for c in self.subsampling  for d  in range(self.nb_filters)]
             return
 
         # Otherwise create it, possibly with sub-sampling
         coords = [[] for i in range(self.post.size)]
 
@@ -427,15 +430,15 @@
         idx_range= []
         for dim in range(self.dim_pre):
             if dim < self.dim_post -1:
                 pre_size = self.pre.geometry[dim]
                 post_size = self.post.geometry[dim]
                 sample = int(pre_size/post_size)
                 if post_size * sample != pre_size:
-                    Global._error('Convolution: The pre-synaptic dimensions must be a multiple of the post-synaptic ones for down-sampling to work.')
+                    Messages._error('Convolution: The pre-synaptic dimensions must be a multiple of the post-synaptic ones for down-sampling to work.')
 
                 idx_range.append([int((sample-1)/2) + sample * i for i in range(post_size)])
             else: # extra dimension
                 if self.keep_last_dimension:
                     idx_range.append(range(self.post.geometry[dim]))
                 else:
                     idx_range.append([self._center_filter(self.weights.shape[dim+1])])
@@ -483,38 +486,38 @@
         """
         Overrides default code generation. This function is called during the code generation procedure.
         """
         # Filter definition
         filter_definition, filter_pyx_definition = self._filter_definition()
 
         # On CPUs we have a pre-load on the inner-most sub-vector
-        use_inner_line = Global._check_paradigm("openmp")
+        use_inner_line = _check_paradigm("openmp")
 
         # Convolve_code
         if not self.multiple:
             convolve_code, sum_code = self._generate_convolve_code(pre_load_inner_line=use_inner_line)
         else:
             convolve_code, sum_code = self._generate_bank_code(pre_load_inner_line=use_inner_line)
 
-        if Global._check_paradigm("openmp"):
+        if _check_paradigm("openmp"):
             self._generate_omp(filter_definition, filter_pyx_definition, convolve_code, sum_code)
-        elif Global._check_paradigm("cuda"):
+        elif _check_paradigm("cuda"):
             self._generate_cuda(filter_definition, filter_pyx_definition, convolve_code, sum_code)
         else:
             raise NotImplementedError
 
     def _generate_omp(self, filter_definition, filter_pyx_definition, convolve_code, sum_code, kernel=True):
         """
         OpenMP code generation.
         """
         # Basic ids
         base_ids = {
             'id_proj': self.id,
             'size_post': self.post.size,
-            'float_prec': Global.config['precision']
+            'float_prec': get_global_config('precision')
         }
 
         # Fill the basic definitions
         conv_dict = deepcopy(convolve_template_omp)
         for key, value in conv_dict.items():
             value = value % base_ids
             conv_dict[key] = value
@@ -529,36 +532,36 @@
             # Fill the code templates
             self._specific_template['declare_parameters_variables'] = tabify(filter_definition.strip(), 1)
             self._specific_template['export_parameters_variables'] = ""
             self._specific_template['access_parameters_variables'] = conv_filter_template["openmp"]["access"] % {'type_w': cpp_type_w}
             self._specific_template['export_connectivity'] += conv_filter_template["pyx_wrapper"]["export"] % {'type_w': pyx_type_w}
             self._specific_template['wrapper_args'] += conv_filter_template["pyx_wrapper"]["args"]
             self._specific_template['wrapper_init_connectivity'] += conv_filter_template["pyx_wrapper"]["init"] % {'id_proj': self.id}
-            self._specific_template['wrapper_access_connectivity'] += conv_filter_template["pyx_wrapper"]["access"] % {'id_proj': self.id, 'float_prec': Global.config['precision']}
+            self._specific_template['wrapper_access_connectivity'] += conv_filter_template["pyx_wrapper"]["access"] % {'id_proj': self.id, 'float_prec': get_global_config('precision')}
 
         # Override the monitor to avoid recording the weights
         self._specific_template['monitor_class'] = ""
         self._specific_template['monitor_export'] = ""
         self._specific_template['monitor_wrapper'] = ""
 
         # Clean-up
         self._specific_template['clear_container'] = convolve_template_omp["clear"]
 
         # OMP code
         omp_code = ""
-        if Global.config['num_threads'] > 1:
+        if get_global_config('num_threads') > 1:
             omp_code = """
         #pragma omp for private(sum, rk_pre, coord) %(psp_schedule)s""" % {'psp_schedule': "" if not 'psp_schedule' in self._omp_config.keys() else self._omp_config['psp_schedule']}
 
         # HD ( 16.10.2015 ):
         # pre-load delayed firing rate in a local array, so we
         # prevent multiple accesses to pop%(id_pre)s._delayed_r[delay-1]
         # wheareas delay is set available as variable
         # TODO HD: wouldn't it be much better to reduce delay globaly, instead of the substraction here???
-        if self.delays > Global.config['dt']:
+        if self.delays > get_global_config('dt'):
             pre_load_r = """
         // pre-load delayed firing rate
         auto delayed_r = pop%(id_pre)s._delayed_r[delay-1];
         """% {'id_pre': self.pre.id}
         else:
             pre_load_r = ""
 
@@ -598,15 +601,15 @@
         """
         CUDA code generation.
         """
         # Basic ids
         base_ids = {
             'id_proj': self.id,
             'size_post': self.post.size,
-            'float_prec': Global.config['precision']
+            'float_prec': get_global_config('precision')
         }
 
         # Fill the basic definitions
         conv_dict = deepcopy(convolve_template_cuda)
         for key, value in conv_dict.items():
             value = value % base_ids
             conv_dict[key] = value
@@ -615,27 +618,27 @@
         # Kernel-based method: specify w with the correct dimension
         if kernel:
             # The number of dimension influences the type
             cpp_type_w = filter_definition.replace(' w;', '')
             pyx_type_w = filter_pyx_definition.replace(' w', '')
 
             # Fill the code templates
-            self._specific_template['declare_parameters_variables'] = conv_filter_template["cuda"]["declare"] % {'cpu_side_filter': filter_definition.strip(), 'float_prec': Global.config["precision"]}
+            self._specific_template['declare_parameters_variables'] = conv_filter_template["cuda"]["declare"] % {'cpu_side_filter': filter_definition.strip(), 'float_prec': get_global_config('precision')}
             self._specific_template['export_parameters_variables'] = ""
             self._specific_template['access_parameters_variables'] = conv_filter_template["cuda"]["access"] % {'type_w': cpp_type_w, 'id_proj': self.id}
             self._specific_template['export_connectivity'] += conv_filter_template["pyx_wrapper"]["export"] % {'type_w': pyx_type_w}
             self._specific_template['wrapper_args'] += conv_filter_template["pyx_wrapper"]["args"]
             self._specific_template['wrapper_init_connectivity'] += conv_filter_template["pyx_wrapper"]["init"] % {'id_proj': self.id}
-            self._specific_template['wrapper_access_connectivity'] += conv_filter_template["pyx_wrapper"]["access"] % {'id_proj': self.id, 'float_prec': Global.config['precision']}
+            self._specific_template['wrapper_access_connectivity'] += conv_filter_template["pyx_wrapper"]["access"] % {'id_proj': self.id, 'float_prec': get_global_config('precision')}
 
             # Memory transfer of variables
             dim_pre = self.dim_pre
             if self.multiple:
                dim_pre += 1
-            self._specific_template['host_device_transfer'] += conv_filter_template["cuda"]["host_device_transfer"] % {'ctype': Global.config["precision"], 'id_proj': self.id, 'pre_dim': dim_pre}
+            self._specific_template['host_device_transfer'] += conv_filter_template["cuda"]["host_device_transfer"] % {'ctype': get_global_config('precision'), 'id_proj': self.id, 'pre_dim': dim_pre}
 
             # Other fields
             self._specific_template['size_in_bytes'] = ""
 
         # Override the monitor to avoid recording the weights
         self._specific_template['monitor_class'] = ""
         self._specific_template['monitor_export'] = ""
@@ -650,28 +653,28 @@
         pre_variables_call = ""
         for pre_dep in self.synapse_type.description['dependencies']['pre']:
             # HD (TODO): the type to float precision works for now, but one should
             #            look up the type in the pre-synaptic neuron type...
             pre_id_dict = {
                 'id_pre': self.pre.id,
                 'name': pre_dep,
-                'type': Global.config["precision"]
+                'type': get_global_config('precision')
             }
             pre_variables_header += ", const %(type)s* __restrict__ pre_%(name)s" % pre_id_dict
             pre_variables_invoke += ", pre_%(name)s" % pre_id_dict
             pre_variables_call += ", pop%(id_pre)s.gpu_%(name)s" % pre_id_dict
 
         # Finalize code templates
         code_ids = {
             'id_proj': self.id,
             'target': self.target,
             'id_post': self.post.id,
             'pre_dim': self.dim_pre,
             'convolve_code': convolve_code,
-            'float_prec': Global.config["precision"],
+            'float_prec': get_global_config('precision'),
             'pre_variables_header': pre_variables_header,
             'pre_variables_invoke': pre_variables_invoke,
             'pre_variables_call': pre_variables_call,
             'pre_variable': "pre_%(name)s" % pre_id_dict,
             'convolve_code': convolve_code
         }
 
@@ -746,16 +749,16 @@
     ### Utilities
     ################################
     def _center_filter(self, i):
         return int(i/2) if i%2==1 else int(i/2)-1
 
     def _filter_definition(self):
         dim = self.dim_kernel
-        cpp = Global.config['precision']
-        pyx = Global.config['precision']
+        cpp = get_global_config('precision')
+        pyx = get_global_config('precision')
         for d in range(dim):
             cpp = 'std::vector< ' + cpp + ' >'
             pyx = 'vector[' + pyx + ']'
         cpp += ' w;'
         pyx += ' w'
         return cpp, pyx
 
@@ -877,24 +880,24 @@
             index += '[' + indices[dim] + '_w]'
 
         # Indices etc. depends on the target platform
         inc_dict = {
             'id_pre': self.pre.id,
             'id_post': self.post.id,
         }
-        if Global._check_paradigm("openmp"):
+        if _check_paradigm("openmp"):
             inc_dict.update({
                 'global_index': '[i]',
                 'local_index': index,
                 'pre_index': '[rk_pre]',
                 'post_index': '[rk_post]',
                 'pre_prefix': 'pop'+str(self.pre.id)+'.',
                 'post_prefix': 'pop'+str(self.post.id)+'.'
             })
-        elif Global._check_paradigm("cuda"):
+        elif _check_paradigm("cuda"):
             inc_dict.update({
                 'global_index': '',
                 'local_index': '[w_idx]',
                 'pre_index': '[rk_pre]',
                 'post_index': '',
                 'pre_prefix': 'pre_',
                 'post_prefix': 'post_'
@@ -902,15 +905,15 @@
         else:
             raise NotImplementedError
 
         # Fill the code template
         increment = self.synapse_type.description['psp']['cpp'] % inc_dict
 
         # Delays
-        if self.delays > Global.config['dt']:
+        if self.delays > get_global_config('dt'):
             increment = increment.replace(
                 'pop%(id_pre)s.r[rk_pre]' % {'id_pre': self.pre.id},
                 'delayed_r[rk_pre]'
             )
 
         # Apply the operation
         if operation == "sum":
@@ -923,24 +926,24 @@
                     sum += %(increment)s""" % {'increment': increment.replace('w'+inner_idx, 'inner_line')}, dim)
                 else:
                     code += tabify("""
                     sum += %(increment)s""" % {'increment': increment}, dim)
         elif operation == "max":
             code += tabify("""
                 %(float_prec)s _psp = %(increment)s
-                if(_psp > sum) sum = _psp;""" % {'increment': increment, 'float_prec': Global.config['precision']}, dim)
+                if(_psp > sum) sum = _psp;""" % {'increment': increment, 'float_prec': get_global_config('precision')}, dim)
         elif operation == "min":
             code += tabify("""
                 %(float_prec)s _psp = %(increment)s
-                if(_psp < sum) sum = _psp;""" % {'increment': increment, 'float_prec': Global.config['precision']}, dim)
+                if(_psp < sum) sum = _psp;""" % {'increment': increment, 'float_prec': get_global_config('precision')}, dim)
         elif operation == "mean":
             code += tabify("""
                 sum += %(increment)s""" % {'increment': increment}, dim)
         else:
-            Global._error('Convolution: Operation', operation, 'is not implemented yet for shared projections.')
+            Messages._error('Convolution: Operation', operation, 'is not implemented yet for shared projections.')
 
         # Close for loops
         for dim in range(self.dim_kernel):
             code += tabify("""
             }""", self.dim_kernel-1-dim)
 
         impl_code = code % {'id_proj': self.id,
@@ -982,15 +985,15 @@
             if pre_load_inner_line:
                 if dim == self.dim_kernel-2:
                     inner_idx = ""
                     for i in range(self.dim_kernel-2):
                         inner_idx += "["+indices[i]+"_w]"
                     code += tabify("""
                 const %(float_prec)s* w_inner_line = w[coord[%(dim_pre)s]]%(inner_idx)s.data();
-    """ % {'float_prec': Global.config["precision"], 'inner_idx': inner_idx, 'dim_pre': self.dim_pre}, dim)
+    """ % {'float_prec': get_global_config('precision'), 'inner_idx': inner_idx, 'dim_pre': self.dim_pre}, dim)
 
             code += tabify("""
             for (int %(index)s_w = 0; %(index)s_w < %(size)s;%(index)s_w++) {
             """ % { 'index': indices[dim], 'size': self.weights.shape[dim+1]}, dim)
 
             # Compute indices
             if dim < self.dim_kernel:
@@ -1050,65 +1053,65 @@
                 index += '[' + indices[dim] + '_w]'
 
         # Indices etc. depend on target platform
         inc_dict = {
             'id_pre': self.pre.id,
             'id_post': self.post.id,
         }
-        if Global._check_paradigm("openmp"):
+        if _check_paradigm("openmp"):
             inc_dict.update({
                 'local_index': index,
                 'global_index': '[i]',
                 'pre_index': '[rk_pre]',
                 'post_index': '[rk_post]',
                 'pre_prefix': 'pop'+str(self.pre.id)+'.',
                 'post_prefix': 'pop'+str(self.post.id)+'.'
             })
-        elif Global._check_paradigm("cuda"):
+        elif _check_paradigm("cuda"):
             inc_dict.update({
                 'local_index': "[w_idx]",
                 'global_index': '[bIdx]',
                 'pre_index': '[rk_pre]',
                 'post_index': '[bIdx]',
                 'pre_prefix': 'pre_',
                 'post_prefix': 'post_'
             })
         else:
             raise NotImplementedError
 
         # Pixel-wise applied operation
         increment = self.synapse_type.description['psp']['cpp']
-        if Global._check_paradigm("cuda"):
+        if _check_paradigm("cuda"):
             increment = increment.replace("w%(local_index)s", "w_bank%(local_index)s")
         increment %= inc_dict
 
         # Delays
-        if self.delays > Global.config['dt']:
+        if self.delays > get_global_config('dt'):
             increment = increment.replace(
                 'pop%(id_pre)s.r[rk_pre]' % {'id_pre': self.pre.id},
                 'delayed_r[rk_pre]'
             )
 
         # Apply the operation
         if operation == "sum":
             code += tabify("""
             sum += %(increment)s""" % {'increment': increment}, 1+dim)
         elif operation == "max":
             code += tabify("""
             %(float_prec)s _psp = %(increment)s
-            if(_psp > sum) sum = _psp;""" % {'increment': increment, 'float_prec': Global.config['precision']}, 1+dim)
+            if(_psp > sum) sum = _psp;""" % {'increment': increment, 'float_prec': get_global_config('precision')}, 1+dim)
         elif operation == "min":
             code += tabify("""
             %(float_prec)s _psp = %(increment)s
-            if(_psp < sum) sum = _psp;""" % {'increment': increment, 'float_prec': Global.config['precision']}, 1+dim)
+            if(_psp < sum) sum = _psp;""" % {'increment': increment, 'float_prec': get_global_config('precision')}, 1+dim)
         elif operation == "mean":
             code += tabify("""
             sum += %(increment)s""" % {'increment': increment}, 1+dim)
         else:
-            Global._error('SharedProjection: Operation', operation, 'is not implemented yet for shared projections.')
+            Messages._error('SharedProjection: Operation', operation, 'is not implemented yet for shared projections.')
 
         # Close for loops
         for dim in range(self.dim_kernel-1):
             code += tabify("""
         }""", self.dim_kernel-1-dim)
 
         impl_code = code % {'id_proj': self.id,
@@ -1138,21 +1141,21 @@
 
         desc['dendrites'] = []
         desc['number_of_synapses'] = 0
         return desc
 
     def save_connectivity(self, filename):
         "Not available."
-        Global._warning('Convolutional projections can not be saved.')
+        Messages._warning('Convolutional projections can not be saved.')
     def save(self, filename):
         "Not available."
-        Global._warning('Convolutional projections can not be saved.')
+        Messages._warning('Convolutional projections can not be saved.')
     def load(self, filename):
         "Not available."
-        Global._warning('Convolutional projections can not be loaded.')
+        Messages._warning('Convolutional projections can not be loaded.')
     def receptive_fields(self, variable = 'w', in_post_geometry = True):
         "Not available."
-        Global._warning('Convolutional projections can not display receptive fields.')
+        Messages._warning('Convolutional projections can not display receptive fields.')
     def connectivity_matrix(self, fill=0.0):
         "Not available."
-        Global._warning('Convolutional projections can not display connectivity matrices.')
+        Messages._warning('Convolutional projections can not display connectivity matrices.')
```

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/convolution/ConvolveTemplate.py` & `annarchy-4.8.0.1/ANNarchy/extensions/convolution/ConvolveTemplate.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/convolution/Copy.py` & `annarchy-4.8.0.1/ANNarchy/extensions/convolution/Copy.py`

 * *Files 8% similar despite different names*

```diff
@@ -2,15 +2,17 @@
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 from copy import deepcopy
 
 from ANNarchy.core import Global
-from ANNarchy.core.SpecificProjection import SpecificProjection
+from ANNarchy.intern.SpecificProjection import SpecificProjection
+from ANNarchy.intern.ConfigManagement import get_global_config, _check_paradigm
+from ANNarchy.intern import Messages
 from ANNarchy.core.Projection import Projection
 from ANNarchy.extensions.convolution import Convolution, Pooling
 
 from .CopyTemplate import copy_proj_template, copy_sum_template
 from .Utils import SharedSynapse
 
 class Copy(SpecificProjection):
@@ -20,30 +22,29 @@
     Although the original projection can be learnable, this one can not. Changes in the original weights will be reflected in this projection. The only possible modifications are ``psp`` and ``operation``.
 
     The pre- and post-synaptic populations of both projections must have the same geometry.
 
     Example:
 
     ```python
-    proj = Projection(pop1, pop2, "exc")
+    proj = ann.Projection(pop1, pop2, "exc")
     proj.connect_fixed_probability(0.1, 0.5)
 
     copy_proj = Copy(pop1, pop3, "exc")
     copy_proj.connect_copy(proj)
     ```
 
+    :param pre: pre-synaptic population (either its name or a ``Population`` object).
+    :param post: post-synaptic population (either its name or a ``Population`` object).
+    :param target: type of the connection
+    :param psp: continuous influence of a single synapse on the post-synaptic neuron (default for rate-coded: ``w*pre.r``).
+    :param operation: operation (sum, max, min, mean) performed by the kernel (default: sum).
+
     """
     def __init__(self, pre, post, target, psp="pre.r * w", operation="sum", name=None, copied=False):
-        """
-        :param pre: pre-synaptic population (either its name or a ``Population`` object).
-        :param post: post-synaptic population (either its name or a ``Population`` object).
-        :param target: type of the connection
-        :param psp: continuous influence of a single synapse on the post-synaptic neuron (default for rate-coded: ``w*pre.r``).
-        :param operation: operation (sum, max, min, mean) performed by the kernel (default: sum).
-        """
 
         # Create the description, but it will not be used for generation
         SpecificProjection.__init__(
             self,
             pre=pre,
             post=post,
             target=target,
@@ -56,21 +57,21 @@
         """
         :param projection: Existing projection to copy.
         """
         self.projection = projection
 
         # Sanity checks
         if not isinstance(self.projection, Projection):
-            Global._error('Copy: You must provide an existing projection to copy().')
+            Messages._error('Copy: You must provide an existing projection to copy().')
 
         if isinstance(self.projection, (Convolution, Pooling)):
-            Global._error('Copy: You can only copy regular projections, not shared projections.')
+            Messages._error('Copy: You can only copy regular projections, not shared projections.')
 
         if not self.pre.geometry == self.projection.pre.geometry or not self.post.geometry == self.projection.post.geometry:
-            Global._error('Copy: When copying a projection, the geometries must be the same.')
+            Messages._error('Copy: When copying a projection, the geometries must be the same.')
 
         # Dummy weights
         self.weights = None
         self.pre_coordinates = []
 
         # Finish building the synapses
         self._create()
@@ -80,76 +81,76 @@
     def _copy(self, pre, post):
         "Returns a copy of the projection when creating networks. Internal use only."
         raise NotImplementedError
 
     def _create(self):
         # create fake LIL object, just for compilation.
         try:
-            from ANNarchy.core.cython_ext.Connector import LILConnectivity
+            from ANNarchy.cython_ext.Connector import LILConnectivity
         except Exception as e:
-            Global._print(e)
-            Global._error('ANNarchy was not successfully installed.')
+            Messages._print(e)
+            Messages._error('ANNarchy was not successfully installed.')
 
         lil = LILConnectivity()
         lil.max_delay = self.delays
         lil.uniform_delay = self.delays
         self.connector_name = "Copy"
         self.connector_description = "Copy projection"
         self._store_connectivity(self._load_from_lil, (lil, ), self.delays)
 
     def _connect(self, module):
         """
         Builds up dendrites either from list or dictionary. Called by instantiate().
         """
         if not self._connection_method:
-            Global._error('Copy: The projection between ' + self.pre.name + ' and ' + self.post.name + ' is declared but not connected.')
+            Messages._error('Copy: The projection between ' + self.pre.name + ' and ' + self.post.name + ' is declared but not connected.')
 
         # Create the Cython instance
         proj = getattr(module, 'proj'+str(self.id)+'_wrapper')
         self.cyInstance = proj(self.weights, self.pre_coordinates)
 
         # Define the list of postsynaptic neurons
         self.post_ranks = list(range(self.post.size))
 
         # Set delays after instantiation
         if self.delays > 0.0:
-            self.cyInstance.set_delay(self.delays/Global.config['dt'])
+            self.cyInstance.set_delay(self.delays/get_global_config('dt'))
 
         return True
 
     def _generate(self):
         """
         Overrides default code generation. This function is called during the code generation procedure.
         """
-        if Global._check_paradigm("openmp"):
+        if _check_paradigm("openmp"):
             self._generate_omp()
-        elif Global._check_paradigm("cuda"):
+        elif _check_paradigm("cuda"):
             self._generate_cuda()
         else:
             raise NotImplementedError
 
     def generate_omp(self):
         """
         Code generation of CopyProjection object for the openMP paradigm.
         """
         # Set the projection specific parameters
         copy_proj_dict = deepcopy(copy_proj_template)
         for key, value in copy_proj_dict.items():
             value = value % {
                 'id_proj': self.id,
                 'id_copy': self.projection.id,
-                'float_prec': Global.config['precision']
+                'float_prec': get_global_config('precision')
             }
             copy_proj_dict[key] = value
 
         # Update specific template
         self._specific_template.update(copy_proj_dict)
 
         # OMP code if more then one thread
-        if Global.config['num_threads'] > 1:
+        if get_global_config('num_threads') > 1:
             omp_code = '#pragma omp for private(sum)' if self.post.size > Global.OMP_MIN_NB_NEURONS else ''
         else:
             omp_code = ""
 
         # PSP
         psp = self.synapse_type.description['psp']['cpp']  % {
             'id_pre': self.pre.id,
@@ -159,34 +160,34 @@
             'pre_index': '[pre_rank[i][j]]',
             'post_index': '[post_rank[i]]',
             'pre_prefix': 'pop'+str(self.pre.id)+'.',
             'post_prefix': 'pop'+str(self.post.id)+'.'}
         psp = psp.replace('rk_pre', 'pre_rank[i][j]').replace(';', '')
 
         # Take delays into account if any
-        if self.delays > Global.config['dt']:
+        if self.delays > get_global_config('dt'):
             psp = psp.replace(
                 'pop%(id_pre)s.r[rk_pre]' % {'id_pre': self.pre.id},
                 'pop%(id_pre)s._delayed_r[delay-1][rk_pre]' % {'id_pre': self.pre.id}
                 # TODO HD: wouldn't it be much better to reduce delay globaly, instead of the substraction here???
             )
 
         # Select template for operation to be performed: sum, max, min, mean
         try:
             sum_code = copy_sum_template[self.synapse_type.operation]
         except KeyError:
-            Global._error("CopyProjection: the operation ", self.synapse_type.operation, ' is not available.')
+            Messages._error("CopyProjection: the operation ", self.synapse_type.operation, ' is not available.')
 
         # Finalize code
         self.generator['omp']['body_compute_psp'] = sum_code % {
             'id_proj': self.id, 'target': self.target,
             'id_pre': self.pre.id, 'name_pre': self.pre.name,
             'id_post': self.post.id, 'name_post': self.post.name,
             'id': self.projection.id,
-            'float_prec': Global.config['precision'],
+            'float_prec': get_global_config('precision'),
             'omp_code': omp_code,
             'psp': psp
         }
 
     def _generate_cuda(self):
         """
         Code generation of CopyProjection object for the CUDA paradigm.
@@ -208,20 +209,20 @@
 
         desc['dendrites'] = []
         desc['number_of_synapses'] = 0
         return desc
 
     def save_connectivity(self, filename):
         "Not available."
-        Global._warning('Copied projections can not be saved.')
+        Messages._warning('Copied projections can not be saved.')
     def save(self, filename):
         "Not available."
-        Global._warning('Copied projections can not be saved.')
+        Messages._warning('Copied projections can not be saved.')
     def load(self, filename):
         "Not available."
-        Global._warning('Copied projections can not be loaded.')
+        Messages._warning('Copied projections can not be loaded.')
     def receptive_fields(self, variable = 'w', in_post_geometry = True):
         "Not available."
-        Global._warning('Copied projections can not display receptive fields.')
+        Messages._warning('Copied projections can not display receptive fields.')
     def connectivity_matrix(self, fill=0.0):
         "Not available."
-        Global._warning('Copied projections can not display connectivity matrices.')
+        Messages._warning('Copied projections can not display connectivity matrices.')
```

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/convolution/CopyTemplate.py` & `annarchy-4.8.0.1/ANNarchy/extensions/convolution/CopyTemplate.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/convolution/Pooling.py` & `annarchy-4.8.0.1/ANNarchy/extensions/convolution/Pooling.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,14 +1,16 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-from ANNarchy.core.SpecificProjection import SpecificProjection
-from ANNarchy.core import Global
+from ANNarchy.intern.SpecificProjection import SpecificProjection
+from ANNarchy.intern.ConfigManagement import get_global_config, _check_paradigm
+from ANNarchy.intern import Messages
+
 from ANNarchy.generator.Utils import tabify, remove_trailing_spaces
 
 from copy import deepcopy
 
 from .PoolingTemplate import *
 from .Utils import SharedSynapse
 
@@ -24,84 +26,90 @@
     assigned to sum(target).
 
     The extent is automatically computed using the geometry of the populations, but can be specified in the `connect_pooling()`` methods.
 
     Example:
 
     ```python
-    inp = Population(geometry=(100, 100), neuron=Neuron(parameters="r = 0.0"))
-    pop = Population(geometry=(50, 50), neuron=Neuron(equations="r = sum(exc)"))
+    inp = ann.Population(geometry=(100, 100), neuron=ann.Neuron(parameters="r = 0.0"))
+    pop = ann.Population(geometry=(50, 50), neuron=ann.Neuron(equations="r = sum(exc)"))
+    
     proj = Pooling(inp, pop, 'exc', operation='max') # max-pooling
     proj.connect_pooling() # extent=(2, 2) is implicit
     ```
+
+    :param pre: pre-synaptic population (either its name or a ``Population`` object).
+    :param post: post-synaptic population (either its name or a ``Population`` object).
+    :param target: type of the connection
+    :param operation: pooling function to be applied ("max", "min", "mean")
     """
     def __init__(self, pre, post, target, psp="pre.r", operation="max", name=None, copied=False):
-        """
-        :param pre: pre-synaptic population (either its name or a ``Population`` object).
-        :param post: post-synaptic population (either its name or a ``Population`` object).
-        :param target: type of the connection
-        :param operation: pooling function to be applied ("max", "min", "mean")
-        """
+
         # Sanity check
         if not operation in ["max", "mean", "min"]:
-            Global._error("Pooling: the operation must be either 'max', 'mean' or 'min'.")
+            Messages._error("Pooling: the operation must be either 'max', 'mean' or 'min'.")
         self.operation = operation
 
         # Store for _copy
         self.psp = psp
 
         SpecificProjection.__init__(
             self,
             pre,
             post,
             target,
-            synapse=SharedSynapse(psp=psp, operation=operation, name="Pooling operation", description=operation+"-pooling operation over the pre-synaptic population."),
+            synapse=SharedSynapse(
+                psp=psp, 
+                operation=operation, 
+                name="Pooling operation", 
+                description=operation+"-pooling operation over the pre-synaptic population."
+            ),
             name=name,
             copied=copied
         )
 
         # check dimensions of populations, should not exceed 4
         self.dim_pre = self.pre.dimension
         self.dim_post = self.post.dimension
         if self.dim_post > 4:
-            Global._error('Pooling: Too many dimensions for the post-synaptic population (maximum 4).')
+            Messages._error('Pooling: Too many dimensions for the post-synaptic population (maximum 4).')
         if self.dim_pre > 4:
-            Global._error('Pooling: Too many dimensions for the pre-synaptic population (maximum 4).')
+            Messages._error('Pooling: Too many dimensions for the pre-synaptic population (maximum 4).')
 
         # Disable saving
         self._saveable = False
 
 
 
-    def connect_pooling(self, extent=None, delays=0.0):
+    def connect_pooling(self, extent:tuple=None, delays:float=0.0):
         """
         :param extent: extent of the pooling area expressed in the geometry of the pre-synaptic population (e.g ``(2, 2)``). In each dimension, the product of this extent with the number of neurons in the post-synaptic population must be equal to the number of pre-synaptic neurons. Default: None.
         :param delays: synaptic delay in ms
         """
 
         # process extent
         self.extent_init = extent
         if extent is None:  # compute the extent automatically
             if self.pre.dimension != self.post.dimension:
-                Global._error(
+                Messages._erroror(
                     'Pooling: If you do not provide the extent parameter, the two populations must have the same number of dimensions.')
 
             extent = list(self.pre.geometry)
             for dim in range(self.pre.dimension):
                 extent[dim] /= self.post.geometry[dim]
                 if self.pre.geometry[dim] != extent[dim] * self.post.geometry[dim]:
-                    Global._error(
+                    Messages._error(
                         'Pooling: Unable to compute the extent of the pooling area: the number of neurons do not match.')
 
         elif not isinstance(extent, tuple):
-            Global._error('Pooling: You must provide a tuple for the extent of the pooling operation.')
+            Messages._error('Pooling: You must provide a tuple for the extent of the pooling operation.')
 
         self.extent = list(extent)
         if len(self.extent) < self.pre.dimension:
-            Global._error('Pooling: You must provide a tuple for the extent of the pooling operation.')
+            Messages._error('Pooling: You must provide a tuple for the extent of the pooling operation.')
 
         # process delays
         self.delays = delays
 
         # Generate the pre-synaptic coordinates
         self._generate_extent_coordinates()
 
@@ -130,32 +138,32 @@
     def _create(self):
         """
         create fake LIL object, just for compilation process
 
         :return: no return value
         """
         try:
-            from ANNarchy.core.cython_ext.Connector import LILConnectivity
+            from ANNarchy.cython_ext.Connector import LILConnectivity
         except Exception as e:
-            Global._print(e)
-            Global._error('ANNarchy was not successfully installed.')
+            Messages._print(e)
+            Messages._error('ANNarchy was not successfully installed.')
 
         lil = LILConnectivity()
         lil.max_delay = self.delays
         lil.uniform_delay = self.delays
         self.connector_name = "Pooling"
         self.connector_description = "Pooling"
         self._store_connectivity(self._load_from_lil, (lil, ), self.delays, storage_format="lil", storage_order="post_to_pre")
 
     def _connect(self, module):
         """
         Builds up dendrites either from list or dictionary. Called by instantiate().
         """
         if not self._connection_method:
-            Global._error(
+            Messages._error(
                 'Pooling: The projection between ' + self.pre.name + ' and ' + self.post.name + ' is declared but not connected.')
 
         # Create the Cython instance
         proj = getattr(module, 'proj' + str(self.id) + '_wrapper')
         self.cyInstance = proj(self.pre_coordinates)
 
         return True
@@ -211,35 +219,35 @@
         """
         Overrides the default code generation.
         """
         # Convolve_code
         convolve_code, sum_code = self._generate_pooling_code()
 
         # Generate the code
-        if Global._check_paradigm("openmp"):
+        if _check_paradigm("openmp"):
             self._generate_omp(convolve_code, sum_code)
-        elif Global._check_paradigm("cuda"):
+        elif _check_paradigm("cuda"):
             self._generate_cuda()
         else:
-            Global._error("Pooling: not implemented for the configured paradigm")
+            Messages._error("Pooling: not implemented for the configured paradigm")
 
     def _generate_pooling_code(self):
         """
         Generate loop statements for the desired pooling operation.
         """
         # Operation to be performed: sum, max, min, mean
         operation = self.synapse_type.operation
 
         # Main code
         # default value for sum in code depends on operation
         sum_default = "0.0"
         if self.synapse_type.operation == "min":
-            sum_default = "std::numeric_limits<%(float_prec)s>::max()" % {'float_prec': Global.config['precision']}
+            sum_default = "std::numeric_limits<%(float_prec)s>::max()" % {'float_prec': get_global_config('precision')}
         elif self.synapse_type.operation == "max":
-            sum_default = "std::numeric_limits<%(float_prec)s>::min()" % {'float_prec': Global.config['precision']}
+            sum_default = "std::numeric_limits<%(float_prec)s>::min()" % {'float_prec': get_global_config('precision')}
 
         code = """
             sum = %(sum_default)s;
 """ % {'sum_default': sum_default}
 
         # Generate for loops
         for dim in range(self.dim_pre):
@@ -289,18 +297,18 @@
             'pre_index': '[rk_pre]',
             'post_index': '[rk_post]',
             'pre_prefix': 'pop'+str(self.pre.id)+'.',
             'post_prefix': 'pop'+str(self.post.id)+'.'
         }
 
         # Delays
-        if self.delays > Global.config['dt']:
+        if self.delays > get_global_config('dt'):
             psp = psp.replace(
                 'pop%(id_pre)s.r[rk_pre]' % {'id_pre': self.pre.id},
-                'pop%(id_pre)s._delayed_r[%(delay)s][rk_pre]' % {'id_pre': self.pre.id, 'delay': str(int(self.delays/Global.config['dt'])-1)}
+                'pop%(id_pre)s._delayed_r[%(delay)s][rk_pre]' % {'id_pre': self.pre.id, 'delay': str(int(self.delays/get_global_config('dt'))-1)}
             )
 
         # Apply the operation
         if operation == "max":
             code += """
                 %(float_prec)s _psp = %(psp)s;
                 if(_psp > sum) sum = _psp;"""
@@ -311,29 +319,29 @@
         elif operation == "sum":
             code += """
                 sum += %(psp)s;"""
         elif operation == "mean":
             code += """
                 sum += %(psp)s;"""
         else:
-            Global._error('SharedProjection: Operation', operation, 'is not implemented yet for shared projections with pooling.')
+            Messages._error('SharedProjection: Operation', operation, 'is not implemented yet for shared projections with pooling.')
 
         # Close for loops
         for dim in range(self.dim_pre):
             if self.extent[dim] > 1:
                 code += """
             }"""
 
         impl_code = code % {
             'id_proj': self.id,
             'target': self.target,
             'id_pre': self.pre.id, 'name_pre': self.pre.name, 'size_pre': self.pre.size,
             'id_post': self.post.id, 'name_post': self.post.name, 'size_post': self.post.size,
             'psp': psp,
-            'float_prec': Global.config['precision']
+            'float_prec': get_global_config('precision')
         }
 
         if operation == "mean":
             size = 1
             for dim in range(self.pre.dimension):
                 size *= self.extent[dim]
             sum_code = "sum/" + str(size)
@@ -348,46 +356,46 @@
 
         :param convolve_code:
         :param sum_code:
         """
         # default value for sum in code depends on operation
         sum_default = "0.0"
         if self.synapse_type.operation == "min":
-            sum_default = "std::numeric_limits<%(float_prec)s>::max()" % {'float_prec': Global.config['precision']}
+            sum_default = "std::numeric_limits<%(float_prec)s>::max()" % {'float_prec': get_global_config('precision')}
         elif self.synapse_type.operation == "max":
-            sum_default = "std::numeric_limits<%(float_prec)s>::min()" % {'float_prec': Global.config['precision']}
+            sum_default = "std::numeric_limits<%(float_prec)s>::min()" % {'float_prec': get_global_config('precision')}
 
         # Specific template for generation
         pool_dict = deepcopy(pooling_template_omp)
         for key, value in pool_dict.items():
             value = value % {
                 'id_proj': self.id,
                 'size_post': self.post.size,
                 'sum_default': sum_default,
-                'float_prec': Global.config['precision']
+                'float_prec': get_global_config('precision')
             }
             pool_dict[key] = value
         self._specific_template.update(pool_dict)
 
         # OMP code
         omp_code = ""
-        if Global.config['num_threads'] > 1:
+        if get_global_config('num_threads') > 1:
             omp_code = """
         #pragma omp for private(sum, rk_pre, coord) %(psp_schedule)s""" % {
                 'psp_schedule': "" if not 'psp_schedule' in self._omp_config.keys() else self._omp_config[
                     'psp_schedule']}
 
         # HD ( 16.10.2015 ):
         # pre-load delayed firing rate in a local array, so we
         # prevent multiple accesses to pop%(id_pre)s._delayed_r[%(delay)s]
-        if self.delays > Global.config['dt']:
+        if self.delays > get_global_config('dt'):
             pre_load_r = """
         // pre-load delayed firing rate
         auto delayed_r = pop%(id_pre)s._delayed_r[%(delay)s];
-        """ % {'id_pre': self.pre.id, 'delay': str(int(self.delays / Global.config['dt']) - 1)}
+        """ % {'id_pre': self.pre.id, 'delay': str(int(self.delays / get_global_config('dt')) - 1)}
         else:
             pre_load_r = ""
 
         # Target variable depends on neuron type
         target_code = "_sum_%(target)s" if self.post.neuron_type.type=="rate" else "g_%(target)s"
         target_code %= {'target': self.target}
 
@@ -449,15 +457,15 @@
         sum_default = "0.0"
         if pool_operation == "min":
             sum_default = "FLT_MAX"
         elif pool_operation == "max":
             sum_default = "FLT_MIN"
 
         # operation to perform
-        pool_op_code = cuda_op_code[pool_operation] % {'float_prec': Global.config['precision']}
+        pool_op_code = cuda_op_code[pool_operation] % {'float_prec': get_global_config('precision')}
 
         # mean operation requires one additional computation
         if pool_operation == "mean":
             size = 1
             for dim in range(self.pre.dimension):
                 size *= self.extent[dim]
             final_result = "psp[bIdx] += local_res/" + str(size) + ";"
@@ -468,27 +476,27 @@
         # body, call and header
         pool_template = {}
         base_ids = {
             'id_proj': self.id,
             'id_pre': self.pre.id,
             'id_post': self.post.id,
             'target': self.target,
-            'float_prec': Global.config['precision'],
+            'float_prec': get_global_config('precision'),
             'size_post': self.post.size # TODO: population views?
         }
 
         # The correct templates depends on both
         # kernel-geometry and extent
         if len(self.pre.geometry) == 2:
             # For small extents, we compute multiple coords within one warp. If one extent can fill alone
             # a half-warp we switch to the other implementation.
             if self.extent[0] < 6:
 
                 pool_op_reduce_code = cuda_pooling_code_2d_small_extent['reduce_code'][pool_operation] % {
-                    'float_prec': Global.config['precision'],
+                    'float_prec': get_global_config('precision'),
                     'row_extent': int(self.extent[0]),
                     'col_extent': int(self.extent[1])
                 }
 
                 pool_dict = deepcopy(base_ids)
                 pool_dict.update({
                     'sum_default': sum_default,
@@ -504,15 +512,15 @@
                 pool_template['psp_body'] = cuda_pooling_code_2d_small_extent['psp_body'] % pool_dict
                 pool_template['psp_invoke'] = cuda_pooling_code_2d_small_extent['psp_invoke'] % pool_dict
                 pool_template['psp_header'] = cuda_pooling_code_2d_small_extent['psp_header'] % pool_dict
                 pool_template['psp_call'] = cuda_pooling_code_2d_small_extent['psp_call'] % pool_dict
 
             else:
                 pool_op_reduce_code = cuda_pooling_code_2d['reduce_code'][pool_operation] % {
-                    'float_prec': Global.config['precision'],
+                    'float_prec': get_global_config('precision'),
                     'row_extent': int(self.extent[0]),
                     'col_extent': int(self.extent[1])
                 }
 
                 pool_dict = deepcopy(base_ids)
                 pool_dict.update({
                     'sum_default': sum_default,
@@ -607,20 +615,20 @@
 
         desc['dendrites'] = []
         desc['number_of_synapses'] = 0
         return desc
 
     def save_connectivity(self, filename):
         "Not available."
-        Global._warning('Pooling projections can not be saved.')
+        Messages._warning('Pooling projections can not be saved.')
     def save(self, filename):
         "Not available."
-        Global._warning('Pooling projections can not be saved.')
+        Messages._warning('Pooling projections can not be saved.')
     def load(self, filename):
         "Not available."
-        Global._warning('Pooling projections can not be loaded.')
+        Messages._warning('Pooling projections can not be loaded.')
     def receptive_fields(self, variable = 'w', in_post_geometry = True):
         "Not available."
-        Global._warning('Pooling projections can not display receptive fields.')
+        Messages._warning('Pooling projections can not display receptive fields.')
     def connectivity_matrix(self, fill=0.0):
         "Not available."
-        Global._warning('Pooling projections can not display connectivity matrices.')
+        Messages._warning('Pooling projections can not display connectivity matrices.')
```

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/convolution/PoolingTemplate.py` & `annarchy-4.8.0.1/ANNarchy/extensions/convolution/PoolingTemplate.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/convolution/Transpose.py` & `annarchy-4.8.0.1/ANNarchy/extensions/convolution/Transpose.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,37 +1,42 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 from ANNarchy.core import Global
-from ANNarchy.core.SpecificProjection import SpecificProjection
+from ANNarchy.intern.SpecificProjection import SpecificProjection
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern import Messages
 from ANNarchy.models.Synapses import DefaultRateCodedSynapse, DefaultSpikingSynapse
 
 class Transpose(SpecificProjection):
     """
-    Creates a transposed projection reusing the weights of an already-defined rate-coded projection. Even though the
-    original projection can be learnable, this one can not. The computed post-synaptic potential is the default case
-    for rate-coded projections: w * pre.r
+    Transposed projection reusing the weights of an already-defined rate-coded projection. 
+    
+    Even though the original projection can be learnable, this one can not. The computed post-synaptic potential is the default case for rate-coded projections: "w * pre.r"
 
-    The proposed *target* can differ from the target of the forward projection.
+    The proposed `target` can differ from the target of the forward projection.
 
     Example:
 
-        proj_ff = Projection( input, output, target="exc" )
-        proj_ff.connect_all_to_all(weights=Uniform(0,1)
+    ```python
+    proj_ff = ann.Projection( input, output, target="exc" )
+    proj_ff.connect_all_to_all(weights=Uniform(0,1)
+
+    proj_fb = Transpose(proj_ff, target="inh")
+    proj_fb.connect()
+    ````
+    
+    :param proj: original projection.
+    :param target: type of the connection (can differ from the original one).
 
-        proj_fb = Transpose(proj_ff, target="inh")
-        proj_fb.connect()
     """
     def __init__(self, proj, target):
-        """
-        :param proj: original projection
-        :param target: type of the connection (can differ from the original one)
-        """
+
         # Transpose is not intended for hybrid projections
         if proj.pre.neuron_type.type == "rate" and proj.post.neuron_type.type == "rate":
             SpecificProjection.__init__(
                 self,
                 pre = proj.post,
                 post = proj.pre,
                 target = target,
@@ -42,23 +47,23 @@
                 self,
                 pre = proj.post,
                 post = proj.pre,
                 target = target,
                 synapse = DefaultSpikingSynapse
             )
         else:
-            Global._error('TransposeProjection are not applyable on hybrid projections ...')
+            Messages._error('TransposeProjection are not applyable on hybrid projections ...')
 
         # in the code generation we directly access properties of the
         # forward projection. Therefore we store the link here to have access in
         # self._generate()
         self.fwd_proj = proj
 
         if (proj._connection_delay > 0.0):
-            Global._error('TransposeProjection can not be applied on delayed projections yet ...')
+            Messages._error('TransposeProjection can not be applied on delayed projections yet ...')
 
         # simply copy from the forward view
         self.delays = proj._connection_delay
         self.max_delay = proj.max_delay
         self.uniform_delay = proj.uniform_delay
 
     def _copy(self):
@@ -66,18 +71,18 @@
 
     def _create(self):
         pass
 
     def connect(self):
         # create fake LIL object to have the forward view in C++
         try:
-            from ANNarchy.core.cython_ext.Connector import LILConnectivity
+            from ANNarchy.cython_ext.Connector import LILConnectivity
         except Exception as e:
-            Global._print(e)
-            Global._error('ANNarchy was not successfully installed.')
+            Messages._print(e)
+            Messages._error('ANNarchy was not successfully installed.')
 
         lil = LILConnectivity()
         lil.max_delay = self.max_delay
         lil.uniform_delay = self.uniform_delay
         self.connector_name = "Transpose"
         self.connector_description = "Transpose"
 
@@ -106,15 +111,15 @@
 extern ProjStruct%(fwd_id_proj)s proj%(fwd_id_proj)s;    // Forward projection
 """ % { 'fwd_id_proj': self.fwd_proj.id }
 
         self._specific_template['declare_connectivity_matrix'] = """
     // LIL connectivity (inverse of proj%(id)s)
     std::vector< int > inv_post_rank ;
     std::vector< std::vector< std::pair< int, int > > > inv_pre_rank ;
-""" % {'float_prec': Global.config['precision'], 'id': self.fwd_proj.id}
+""" % {'float_prec': get_global_config('precision'), 'id': self.fwd_proj.id}
         self._specific_template['export_connector_call'] = ""
 
         # TODO: error message on setter?
         self._specific_template['access_connectivity_matrix'] = """
     // Accessor to connectivity data
     std::vector<int> get_post_rank() {
         return inv_post_rank;
@@ -208,31 +213,31 @@
                     auto pre_idx = it->second;
 
                     sum += pop%(id_pre)s.r[proj%(fwd_id_proj)s.post_rank[post_idx]] * proj%(fwd_id_proj)s.w%(index)s;
                 }
                 pop%(id_post)s._sum_%(target)s[inv_post_rank[i]] += sum;
             }
         }
-""" % { 'float_prec': Global.config['precision'],
+""" % { 'float_prec': get_global_config('precision'),
         'target': self.target,
         'id_pre': self.pre.id,
         'id_post': self.post.id,
         'fwd_id_proj': self.fwd_proj.id,
         'index': weight_index,
-        'omp_code': "" if Global.config["num_threads"] == 1 else "#pragma omp for"
+        'omp_code': "" if get_global_config('num_threads') == 1 else "#pragma omp for"
 }
 
     def _generate_spiking(self):
         """
         Generates the transpose projection for spiking models.
 
         TODO: openMP
         """
-        if Global.config["num_threads"] > 1:
-            Global._error('TransposeProjection for spiking projections is only available for single-thread yet ...')
+        if get_global_config('num_threads') > 1:
+            Messages._error('TransposeProjection for spiking projections is only available for single-thread yet ...')
 
         # Which projection is transposed
         self._specific_template['struct_additional'] = """
 extern ProjStruct%(fwd_id_proj)s proj%(fwd_id_proj)s;    // Forward projection
 """ % { 'fwd_id_proj': self.fwd_proj.id }
 
         # Connectivity
@@ -335,24 +340,24 @@
 
         desc['dendrites'] = []
         desc['number_of_synapses'] = 0
         return desc
 
     def save_connectivity(self, filename):
         "Not available."
-        Global._warning('Transposed projections can not be saved.')
+        Messages._warning('Transposed projections can not be saved.')
     def save(self, filename):
         "Not available."
-        Global._warning('Transposed projections can not be saved.')
+        Messages._warning('Transposed projections can not be saved.')
     def load(self, filename):
         "Not available."
-        Global._warning('Transposed projections can not be loaded.')
+        Messages._warning('Transposed projections can not be loaded.')
 
     # TODO: maybe this functions would be helpful for debugging. Even though
     #       they will be time consuming as the matrix need to be constructed.
     #       (HD, 9th July 2020)
     def receptive_fields(self, variable = 'w', in_post_geometry = True):
         "Not available."
-        Global._warning('Transposed projections can not display receptive fields.')
+        Messages._warning('Transposed projections can not display receptive fields.')
     def connectivity_matrix(self, fill=0.0):
         "Not available."
-        Global._warning('Transposed projections can not display connectivity matrices.')
+        Messages._warning('Transposed projections can not display connectivity matrices.')
```

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/convolution/Utils.py` & `annarchy-4.8.0.1/ANNarchy/extensions/convolution/Utils.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/convolution/__init__.py` & `annarchy-4.8.0.1/ANNarchy/extensions/convolution/__init__.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/hybrid/HybridPopulation.py` & `annarchy-4.8.0.1/ANNarchy/extensions/hybrid/HybridPopulation.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,18 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 from ANNarchy.core.Population import Population
 from ANNarchy.core.Neuron import Neuron
-import ANNarchy.core.Global as Global
+from ANNarchy.core import Global
+
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern import Messages
 
 class Spike2RatePopulation(Population):
     """
     Converts a population of spiking neurons into a population of rate-coded neurons.
 
     When building a hybrid network, one may need to convert spike trains into an instantaneous firing. Creating a ``Spike2RatePopulation`` allows to get a rate-coded population of the same size as the spiking population.
 
@@ -52,24 +55,24 @@
         self.scaling = scaling
         self.window = window
         self.smooth = smooth
         self.cut = cut
         self.copied = copied
 
         if not self.population.neuron_type.description['type'] == 'spike':
-            Global._error('the population ' + self.population.name + ' must contain spiking neurons.')
+            Messages._error('the population ' + self.population.name + ' must contain spiking neurons.')
             
         if self.mode == 'window':
             self._code = self._create_window()
         elif self.mode == 'adaptive':
             self._code = self._create_adaptive()
         elif self.mode == 'isi':
             self._code = self._create_isi()
         else:
-            Global._error('Spike2RatePopulation: Unknown method ' + self.mode)
+            Messages._error('Spike2RatePopulation: Unknown method ' + self.mode)
             
 
         self._specific = True
 
     def _copy(self):
         "Returns a copy of the population when creating networks. Internal use only."
         return Spike2RatePopulation(population=self.population, name=self.name, mode=self.mode, window=self.window, scaling=self.scaling, smooth=self.smooth, cut=self.cut, copied=True)
@@ -95,15 +98,15 @@
                 """ % {'cut': self.cut, 'scaling': self.scaling, 'smooth': self.smooth} ,
                 equations="r = 0.0"
             ),
             copied=self.copied
         )
 
         # Generate specific code
-        omp_code = "#pragma omp for" if Global.config['num_threads'] > 1 else ""
+        omp_code = "#pragma omp for" if get_global_config('num_threads') > 1 else ""
         code = """#pragma once
 
 #include "pop%(id_pre)s.hpp"
 extern PopStruct%(id_pre)s pop%(id_pre)s;
 
 struct PopStruct%(id)s{
     // Number of neurons
@@ -182,15 +185,15 @@
                 }
 
                 r[i] += dt*(1000.0/scaling/support[i]/dt - r[i])/smooth;
             }
         }
     }
 };
-""" % {'id' : self.id, 'id_pre': self.population.id, 'omp_code': omp_code, 'size': self.size, 'float_prec': Global.config['precision'] }
+""" % {'id' : self.id, 'id_pre': self.population.id, 'omp_code': omp_code, 'size': self.size, 'float_prec': get_global_config('precision') }
 
         return code
 
     def _create_window(self):
 
         # Create the description, but it will not be used for generation
         Population.__init__(
@@ -205,15 +208,15 @@
                 """ % {'window': self.window, 'scaling': self.scaling, 'smooth': self.smooth} ,
                 equations="r = 0.0"
             ) ,
             copied=self.copied
         )
 
         # Generate specific code
-        omp_code = "#pragma omp for" if Global.config['num_threads'] > 1 else ""
+        omp_code = "#pragma omp for" if get_global_config('num_threads') > 1 else ""
         code = """#pragma once
 
 #include "pop%(id_pre)s.hpp"
 extern PopStruct%(id_pre)s pop%(id_pre)s;
 
 struct PopStruct%(id)s{
     // Number of neurons
@@ -292,15 +295,15 @@
                 }
 
                 r[i] += dt*(1000.0/scaling / window * %(float_prec)s(pop%(id)s_nb) - r[i] ) / smooth;
             }
         }
     }
 };
-""" % {'id' : self.id, 'id_pre': self.population.id, 'omp_code': omp_code, 'size': self.size, 'float_prec': Global.config['precision']}
+""" % {'id' : self.id, 'id_pre': self.population.id, 'omp_code': omp_code, 'size': self.size, 'float_prec': get_global_config('precision')}
 
         return code
 
     def _create_adaptive(self):
 
         # Create the description, but it will not be used for generation
         Population.__init__(
@@ -315,15 +318,15 @@
                 """ % {'window': self.window, 'scaling': self.scaling, 'smooth': self.smooth} ,
                 equations="r = 0.0"
             ) ,
             copied=self.copied
         )
 
         # Generate specific code
-        omp_code = "#pragma omp for private(pop%(id)s_nb, pop%(id)s_out)" if Global.config['num_threads'] > 1 else ""
+        omp_code = "#pragma omp for private(pop%(id)s_nb, pop%(id)s_out)" if get_global_config('num_threads') > 1 else ""
         code = """#pragma once
 
 #include "pop%(id_pre)s.hpp"
 extern PopStruct%(id_pre)s pop%(id_pre)s;
 
 struct PopStruct%(id)s{
     // Number of neurons
@@ -417,15 +420,15 @@
                 ad_window[i] += dt * (clip(5.0*isi[i], 20.0*dt, window) - ad_window[i])/100.0;
                 if (i==0)
                     std::cout << ad_window[i] << " " << isi[i] << std::endl;
             }
         }
     }
 };
-""" % {'id' : self.id, 'id_pre': self.population.id, 'omp_code': omp_code, 'size': self.size, 'float_prec': Global.config['precision']}
+""" % {'id' : self.id, 'id_pre': self.population.id, 'omp_code': omp_code, 'size': self.size, 'float_prec': get_global_config('precision')}
 
         return code
 
 class Rate2SpikePopulation(Population):
     """
     Converts a population of rate-coded neurons into a population of spiking neurons.
 
@@ -449,15 +452,15 @@
         :param scaling: the scaling of the firing rate. Defines what a rate ``r`` of 1.0 means in Hz (default: 1.0).
         :param refractory: a refractory period in ms to ensure the ISI is not too high (default: None)
         """
         self.population = population
         self.refractory_init = refractory
 
         if not self.population.neuron_type.description['type'] == 'rate':
-            Global._error('the population ' + self.population.name + ' must contain rate-coded neurons.')
+            Messages._error('the population ' + self.population.name + ' must contain rate-coded neurons.')
             
 
         # Create the description, but it will not be used for generation
         Population.__init__(
             self, 
             geometry = self.population.geometry, 
             name=name, 
@@ -478,16 +481,16 @@
         self._specific = True
 
     def _copy(self):
         "Returns a copy of the population when creating networks. Internal use only."
         return Rate2SpikePopulation(population=self.population, name=self.name, scaling=self.scaling, refractory=self.refractory_init, copied=True)
 
     def generate(self):
-        omp_code = "#pragma omp for" if Global.config['num_threads'] > 1 else ""
-        omp_critical = "#pragma omp critical" if Global.config['num_threads'] > 1 else ""
+        omp_code = "#pragma omp for" if get_global_config('num_threads') > 1 else ""
+        omp_critical = "#pragma omp critical" if get_global_config('num_threads') > 1 else ""
 
         # Generate the code
         code = """#pragma once
 
 #include "pop%(id_pre)s.hpp"
 extern PopStruct%(id_pre)s pop%(id_pre)s;
 
@@ -576,10 +579,10 @@
                     last_spike[i] = t;
                     refractory_remaining[i] = refractory[i];
                 }
             }
         }
     }
 };
-""" % {'id' : self.id, 'id_pre': self.population.id, 'omp_code': omp_code, 'omp_critical': omp_critical, 'size': self.size, 'float_prec': Global.config['precision'] }
+""" % {'id' : self.id, 'id_pre': self.population.id, 'omp_code': omp_code, 'omp_critical': omp_critical, 'size': self.size, 'float_prec': get_global_config('precision') }
 
         return code
```

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/image/ImagePopulation.py` & `annarchy-4.8.0.1/ANNarchy/extensions/image/ImagePopulation.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,108 +1,109 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 from ANNarchy.core.Population import Population
 from ANNarchy.core.Neuron import Neuron
-import ANNarchy.core.Global as Global
+from ANNarchy.intern.ConfigManagement import get_global_config
 from ANNarchy.generator.Compiler import extra_libs 
+from ANNarchy.intern import Messages
 
 try:
     from PIL import Image
 except:
-    Global._warning('The Python Image Library (pillow) is not installed on your system, unable to create ImagePopulations.')
+    Messages._warning('The Python Image Library (pillow) is not installed on your system, unable to create ImagePopulations.')
     
 import numpy as np
 
 class ImagePopulation(Population):
     """ 
-    Specific rate-coded Population allowing to represent images (png, jpg...) as the firing rate of a population (each neuron represents one pixel).
+    Rate-coded Population allowing to represent images (png, jpg...) as the firing rate of a population (each neuron represents one pixel).
     
     This extension requires the Python Image Library (pip install Pillow).
     
-    Usage:
+    The extensions has to be explicitly imported:
  
     ```python
-    from ANNarchy import *
+    import ANNarchy as ann
     from ANNarchy.extensions.image import ImagePopulation
 
     pop = ImagePopulation(geometry=(480, 640))
     pop.set_image('image.jpg')
     ```
 
     About the geometry:
     
     * If the geometry is 2D, it corresponds to the (height, width) of the image. Only the luminance of the pixels will be represented (grayscale image).
     * If the geometry is 3D, the third dimension can be either 1 (grayscale) or 3 (color).
     
     If the third dimension is 3, each will correspond to the RGB values of the pixels.
     
     **Warning:** due to the indexing system of Numpy, a 640*480 image should be fed into a (480, 640) or (480, 640, 3) population.
+
+    :param geometry: population geometry as tuple. It must correspond to the image size and be fixed through the whole simulation.
+    :param name: unique name of the population (optional).  
     """
     
-    def __init__(self, geometry, name=None, copied=False):
-        """            
-        :param geometry: population geometry as tuple. It must correspond to the image size and be fixed through the whole simulation.
-        :param name: unique name of the population (optional).     
-        """   
+    def __init__(self, geometry:tuple, name:str=None, copied:bool=False):
+ 
         # Check geometry
         if isinstance(geometry, int) or len(geometry)==1:
-            Global._error('The geometry of an ImagePopulation should be 2D (grayscale) or 3D (color).')
+            Messages._error('The geometry of an ImagePopulation should be 2D (grayscale) or 3D (color).')
             
         if len(geometry)==3 and (geometry[2]!=3 and geometry[2]!=1):
-            Global._error('The third dimension of an ImagePopulation should be either 1 (grayscale) or 3 (color).') 
+            Messages._error('The third dimension of an ImagePopulation should be either 1 (grayscale) or 3 (color).') 
                         
         if len(geometry)==3 and geometry[2]==1:
             geometry = (int(geometry[0]), int(geometry[1]))
             
         # Create the population     
         Population.__init__(self, geometry = geometry, name=name, neuron = Neuron(parameters="r = 0.0"), copied=copied)
     
     def _copy(self):
         "Returns a copy of the population when creating networks. Internal use only."
         return ImagePopulation(geometry=self.geometry, name=self.name, copied=True)
 
-    def set_image(self, image_name):
+    def set_image(self, image_name:str):
         """ 
         Sets an image (.png, .jpg or whatever is supported by PIL) into the firing rate of the population.
         
         If the image has a different size from the population, it will be resized.
         
         """
         try:
             im = Image.open(image_name)
         except : # image does not exist
-            Global._error('The image ' + image_name + ' does not exist.')
+            Messages._error('The image ' + image_name + ' does not exist.')
             
         # Resize the image if needed
         (width, height) = (self.geometry[1], self.geometry[0])
         if im.size != (width, height):
-            Global._warning('The image ' + image_name + ' does not have the same size '+str(im.size)+' as the population ' + str((width, height)) + '. It will be resized.')
+            Messages._warning('The image ' + image_name + ' does not have the same size '+str(im.size)+' as the population ' + str((width, height)) + '. It will be resized.')
             im = im.resize((width, height))
         
         # Check if only the luminance should be extracted
         if self.dimension == 2 or self.geometry[2] == 1:
             im=im.convert("L")
         
         # Set the rate of the population
         self.r = np.array(im).reshape(self.size)/255.
 
 
 class VideoPopulation(ImagePopulation):
     """ 
-    Specific rate-coded Population allowing to feed a webcam input into the firing rate of a population (each neuron represents one pixel).
+    Rate-coded Population allowing to feed a webcam input into the firing rate of a population (each neuron represents one pixel).
     
     This extension requires the C++ library OpenCV >= 4.0 (apt-get/yum install opencv). ``pkg-config opencv4 --cflags --libs`` should not return an error. `vtk` might additionally have to be installed.
     
-    Usage:
+    The extensions has to be explicitly imported:
 
     ```python
-    from ANNarchy import *
+    import ANNarchy as ann
     from ANNarchy.extensions.image import VideoPopulation
     
     pop = VideoPopulation(geometry=(480, 640))
     
     compile()
     
     pop.start_camera(0)
@@ -117,22 +118,21 @@
     * If the geometry is 2D, it corresponds to the (height, width) of the image. Only the luminance of the pixels will be represented (grayscale image).
     * If the geometry is 3D, the third dimension can be either 1 (grayscale) or 3 (color).
     
     If the third dimension is 3, each will correspond to the RGB values of the pixels.
     
     **Warning:** due to the indexing system of Numpy, a 640*480 image should be fed into a (480, 640) or (480, 640, 3) population.
 
+    :param geometry: population geometry as tuple. It must be fixed through the whole simulation. If the camera provides images of a different size, it will be resized.
+    :param opencv_version: OpenCV version (default=4).
+    :param name: unique name of the population (optional). 
     """
     
-    def __init__(self, geometry, opencv_version="4", name=None, copied=False):
-        """        
-        :param geometry: population geometry as tuple. It must be fixed through the whole simulation. If the camera provides images of a different size, it will be resized.
-        :param opencv_version: OpenCV version (default=4).
-        :param name: unique name of the population (optional).       
-        """         
+    def __init__(self, geometry:tuple, opencv_version:str="4", name:str=None, copied:bool=False):
+        
         # Create the population     
         ImagePopulation.__init__(self, geometry = geometry, name=name, copied=copied)
 
         self.opencv_version = opencv_version
 
     def _copy(self):
         "Returns a copy of the population when creating networks. Internal use only."
@@ -192,15 +192,15 @@
 
 protected:
     // Width and height of the image, depth_ is 1 (grayscale) or 3 (RGB)
     int width_, height_, depth_;
     // Vector of floats for the returned image
     std::vector<%(float_prec)s> img_;
 };
-""" % {'float_prec': Global.config['precision']}
+""" % {'float_prec': get_global_config('precision')}
 
         self._specific_template['declare_additional'] = """
     // Camera
     CameraDeviceCPP* camera_;
     void StartCamera(int id, int width, int height, int depth){
         camera_ = new CameraDeviceCPP(id, width, height, depth);
         if(!camera_->isOpened()){
```

### Comparing `ANNarchy-4.7.3/ANNarchy/extensions/tensorboard/Logger.py` & `annarchy-4.8.0.1/ANNarchy/extensions/tensorboard/Logger.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,18 +1,21 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 import ANNarchy.core.Global as Global
+
+from ANNarchy.intern import Messages
+
 try:
     from tensorboardX import SummaryWriter
 except Exception as e:
     print(e)
-    Global._error("tensorboard extension: please install tensorboardX (pip install tensorboardX).")
+    Messages._error("tensorboard extension: please install tensorboardX (pip install tensorboardX).")
 
 import os
 import socket
 from datetime import datetime
 import numpy as np
 
 
@@ -64,21 +67,20 @@
 
     TensorboardX enqueues the data in memory before writing to disk. You can force flushing with:
 
     ```python
     logger.flush()
     ```
 
+    :param logdir: path (absolute or relative) to the logging directory. Subfolders will be created for each individual run. The default is "runs/"
+    :param experiment: name of the subfolder for the current run. By default, it is a combination of the current time and the hostname (e.g. Apr22_12-11-22_machine). If you reuse an experiment name, the data will be appended.
     """
     
-    def __init__(self, logdir="runs/", experiment=None):
-        """
-        :param logdir: path (absolute or relative) to the logging directory. Subfolders will be created for each individual run. The default is "runs/"
-        :param experiment: name of the subfolder for the current run. By default, it is a combination of the current time and the hostname (e.g. Apr22_12-11-22_machine). If you reuse an experiment name, the data will be appended.
-        """
+    def __init__(self, logdir:str="runs/", experiment:str=None):
+
         self.logdir = logdir
         self.experiment = experiment
 
         # Create the logdir if it does not exist
         if not os.path.exists(self.logdir):
             os.makedirs(self.logdir)
 
@@ -95,15 +97,15 @@
 
     def _create_summary_writer(self):
 
          self._summary = SummaryWriter(self.currentlogdir, comment="", purge_step=None, max_queue=10, flush_secs=10, filename_suffix='', write_to_disk=True)
 
     # Logging methods
         
-    def add_scalar(self, tag, value, step=None):
+    def add_scalar(self, tag:str, value:float, step:int=None):
         """
         Logs a single scalar value, e.g. a success rate at various stages of learning.
 
         Example:
 
         ```python
         with Logger() as logger:
@@ -116,15 +118,15 @@
         :param tag: name of the figure in tensorboard.
         :param value: value.
         :param step: time index.
         """
         
         self._summary.add_scalar(tag=tag, scalar_value=value, global_step=step, walltime=None)
         
-    def add_scalars(self, tag, value, step=None):
+    def add_scalars(self, tag:str, value:dict, step:int=None):
         """
         Logs multiple scalar values to be displayed in the same figure, e.g. several metrics or neural activities.
 
         Example:
 
         ```python
         with Logger() as logger:
@@ -141,15 +143,15 @@
         :param tag: name of the figure in tensorboard.
         :param value: dictionary of values.
         :param step: time index.
         """
         
         self._summary.add_scalars(main_tag=tag, tag_scalar_dict=value, global_step=step, walltime=None)
         
-    def add_image(self, tag, img, step=None, equalize=False):
+    def add_image(self, tag:str, img: np.ndarray, step:int=None, equalize:bool=False):
         """
         Logs an image.
         
         The image must be a numpy array of size (height, width) for monochrome images or (height, width, 3) for colored images. The values should either be integers between 0 and 255 or floats between 0 and 1. The parameter ``equalize`` forces the values to be between 0 and 1 by equalizing using the min/max values.
 
         Example::
 
@@ -171,26 +173,26 @@
                 img = img.astype(np.float)              
                 img = (img - img.min())/(img.max() - img.min())
 
             self._summary.add_image(tag=tag, img_tensor=img, global_step=step, walltime=None, dataformats='HW')
         
         elif img.ndim == 3:
             if not img.shape[2] == 3:
-                Global._error("Logger.add_image: color images must be of shape (H, W, 3).")
+                Messages._error("Logger.add_image: color images must be of shape (H, W, 3).")
             
             if equalize:   
                 img = np.array(img).astype(np.float)         
                 img = (img - img.min())/(img.max() - img.min())
 
             self._summary.add_image(tag=tag, img_tensor=img, global_step=step, walltime=None, dataformats='HWC')
 
         else:
-            Global._error("Logger.add_image: images must be of shape (H, W) or (H, W, 3).")
+            Messages._error("Logger.add_image: images must be of shape (H, W) or (H, W, 3).")
         
-    def add_images(self, tag, img, step=None, equalize=False, equalize_per_image=False):
+    def add_images(self, tag:str, img:np.array, step:int=None, equalize:bool=False, equalize_per_image:bool=False):
         """
         Logs a set of images (e.g. receptive fields).
        
         The numpy array must be of size (number, height, width) for monochrome images or (number, height, width, 3) for colored images. The values should either be integers between 0 and 255 or floats between 0 and 1. The parameter ``equalize`` forces the values to be between 0 and 1 by equalizing using the min/max values.
 
         Example:
 
@@ -218,15 +220,15 @@
                 img = (img - img.min())/(img.max() - img.min())
             else:
                 for i in range(img.shape[0]):
                     img[i,...] = (img[i,...] - img[i,...].min())/(img[i,...].max() - img[i,...].min())
         
         self._summary.add_images(tag=tag, img_tensor=img, global_step=step, walltime=None, dataformats='NHWC')
         
-    def add_parameters(self, params, metrics):
+    def add_parameters(self, params:dict, metrics:dict):
         """
         Logs parameters of a simulation.
 
         This should be run only once per simulation, generally at the end. 
         This allows to compare different runs of the same network using 
         different parameter values and study how they influence the global output metrics, 
         such as accuracy, error rate, reaction speed, etc.
@@ -241,15 +243,15 @@
 
         :param params: dictionary of parameters.
         :param metrics: dictionary of metrics.
         """
         
         self._summary.add_hparams(params, metrics)
 
-    def add_histogram(self, tag, hist, step=None):
+    def add_histogram(self, tag:str, hist: list | np.ndarray, step:int=None):
         """
         Logs an histogram.
 
         Example:
 
         ```python
         with Logger() as logger:
@@ -263,15 +265,15 @@
         :param tag: name of the figure in tensorboard.
         :param hist: a list or 1D numpy array of values.
         :param step: time index.
         """
 
         self._summary.add_histogram(tag, hist, step)
 
-    def add_figure(self, tag, figure, step=None, close=True):
+    def add_figure(self, tag:str, figure: list | np.ndarray, step:int=None, close:bool=True):
         """
         Logs a Matplotlib figure.
 
         Example:
 
         ```python
         with Logger() as logger:
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/CmdLineArgParser.py` & `annarchy-4.8.0.1/ANNarchy/generator/CmdLineArgParser.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 import argparse
-from ANNarchy.core import Global
+from ANNarchy.intern import Messages
+from ANNarchy.intern import ConfigManagement
 
 class CmdLineArgParser(object):
     """
     ANNarchy scripts can be run by several command line arguments. These are
     checked with the ArgumentParser provided by Python.
 
     Generally, we have a group of flags which should be set before *compile()*
@@ -51,31 +52,33 @@
         """
         We already parse some arguments which should be known before **any** other ANNarchy call has happened.
         """
         options, _ = self.parser.parse_known_args()
 
         # if the parameters set on command-line they overwrite Global.config
         if options.num_threads is not None:
-            Global.config['num_threads'] = options.num_threads
+            ConfigManagement._update_global_config('num_threads', options.num_threads)
+
         if options.visible_cores is not None:
             try:
                 core_list = [int(x) for x in options.visible_cores.split(",")]
-                Global.config['visible_cores'] = core_list
+                ConfigManagement._update_global_config('visible_cores', core_list)
             except:
-                Global._error("As argument for 'visible_cores' a comma-seperated list of integers is expected.")
+                Messages._error("As argument for 'visible_cores' a comma-seperated list of integers is expected.")
 
         # Get Performance-related flags
         if options.auto_tuning:
-            Global._info("Automatic format selection is an experimental feature. We greatly appreciate bug reports.")
-            Global.setup(sparse_matrix_format="auto", sparse_matrix_storage_order="auto")
+            Messages._info("Automatic format selection is an experimental feature. We greatly appreciate bug reports.")
+            ConfigManagement.setup(sparse_matrix_format="auto", sparse_matrix_storage_order="auto")
 
         # Get CUDA configuration
         if options.gpu_device >= 0:
-            Global.config['paradigm'] = "cuda"
+            ConfigManagement._update_global_config('paradigm', 'cuda')
 
         # Verbose
         if options.verbose is not None:
-            Global.config['verbose'] = options.verbose
+            ConfigManagement.setup(verbose = options.verbose)
 
         # Precision
         if options.precision is not None:
-            Global.config['precision'] = options.precision
+            ConfigManagement._update_global_config('precision', options.precision)
+
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/CodeGenerator.py` & `annarchy-4.8.0.1/ANNarchy/generator/CodeGenerator.py`

 * *Files 6% similar despite different names*

```diff
@@ -2,14 +2,18 @@
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 import time
 import ANNarchy.core.Global as Global
 from ANNarchy.core.PopulationView import PopulationView
+from ANNarchy.intern.Profiler import Profiler
+from ANNarchy.intern.ConfigManagement import get_global_config, _check_paradigm
+from ANNarchy.intern.GlobalObjects import GlobalObjectManager
+from ANNarchy.intern import Messages
 from ANNarchy.parser.Extraction import extract_functions
 
 from ANNarchy.generator.PyxGenerator import PyxGenerator
 from ANNarchy.generator.MonitorGenerator import MonitorGenerator
 from ANNarchy.generator.Population import SingleThreadGenerator, OpenMPGenerator, CUDAGenerator
 from ANNarchy.generator.Projection import SingleThreadProjectionGenerator, OpenMPProjectionGenerator, CUDAProjectionGenerator
 from ANNarchy.generator.Template.GlobalOperationTemplate import global_operation_templates_st, global_operation_templates_openmp, global_operation_templates_cuda
@@ -46,40 +50,40 @@
         self._annarchy_dir = annarchy_dir
         self._populations = populations
         self._projections = projections
         self._cuda_config = cuda_config
 
         # Profiling is optional, but if either Global.config["profiling"] set to True
         # or --profile was added on command line.
-        if Global.config['profiling']:
-            if Global.config['paradigm'] == "openmp":
+        if get_global_config('profiling'):
+            if get_global_config('paradigm') == "openmp":
                 self._profgen = Profile.CPP11Profile(self._annarchy_dir, net_id)
                 self._profgen.generate()
-            elif Global.config['paradigm'] == "cuda":
+            elif get_global_config('paradigm') == "cuda":
                 self._profgen = Profile.CUDAProfile(self._annarchy_dir, net_id)
                 self._profgen.generate()
             else:
-                Global._error('No ProfileGenerator available for '
-                              + Global.config['paradigm'])
+                Messages._error('No ProfileGenerator available for '
+                              + get_global_config('paradigm'))
         else:
             self._profgen = None
 
         # Instantiate code generator based on the target platform
-        if Global.config['paradigm'] == "openmp":
-            if Global.config['num_threads'] == 1:
+        if get_global_config('paradigm') == "openmp":
+            if get_global_config('num_threads') == 1:
                 self._popgen = SingleThreadGenerator(self._profgen, net_id)
                 self._projgen = SingleThreadProjectionGenerator(self._profgen, net_id)
             else:
                 self._popgen = OpenMPGenerator(self._profgen, net_id)
                 self._projgen = OpenMPProjectionGenerator(self._profgen, net_id)
-        elif Global.config['paradigm'] == "cuda":
-            self._popgen = CUDAGenerator(self._profgen, net_id)
-            self._projgen = CUDAProjectionGenerator(self._profgen, net_id)
+        elif get_global_config('paradigm') == "cuda":
+            self._popgen = CUDAGenerator(self._cuda_config['cuda_version'], self._profgen, net_id)
+            self._projgen = CUDAProjectionGenerator(self._cuda_config['cuda_version'], self._profgen, net_id)
         else:
-            Global._error("No PopulationGenerator for " + Global.config['paradigm'])
+            Messages._error("No PopulationGenerator for " + get_global_config('paradigm'))
 
         # Py-extenstion and RecordGenerator are commonly defined
         self._pyxgen = PyxGenerator(annarchy_dir, populations, projections, net_id)
         self._recordgen = MonitorGenerator(annarchy_dir, populations, projections, net_id)
 
         # Target container for the generated code snippets
         self._pop_desc = []
@@ -99,24 +103,24 @@
             * for each population a seperate header file, contain semantic
               logic of a population respectively neuron object (filename:
               pop<id>).
             * for each projection a seperate header file, contain semantic
               logic of a projection respectively synapse object (filename:
               proj<id>)
         """
-        if Global._profiler:
+        if Profiler().enabled:
             t0 = time.time()
 
-        if Global.config['verbose']:
-            if Global.config['paradigm'] == "openmp":
-                if Global.config['num_threads'] > 1:
-                    Global._print('\nGenerate code for OpenMP ...')
+        if get_global_config('verbose'):
+            if get_global_config('paradigm') == "openmp":
+                if get_global_config('num_threads') > 1:
+                    Messages._print('\nGenerate code for OpenMP ...')
                 else:
-                    Global._print('\nGenerate sequential code ...')
-            elif Global.config['paradigm'] == "cuda":
+                    Messages._print('\nGenerate sequential code ...')
+            elif get_global_config('paradigm') == "cuda":
                 print('\nGenerate CUDA code ...')
             else:
                 raise NotImplementedError
 
         # Specific populations/projections have an overwritten _generate()
         # method which will populate the self._specific_template dictionary
         for pop in self._populations:
@@ -136,37 +140,37 @@
         for proj in self._projections:
             self._proj_desc.append(self._projgen.header_struct(proj, self._annarchy_dir))
 
         # where all source files should take place
         source_dest = self._annarchy_dir+'/generate/net'+str(self._net_id)+'/'
 
         # Generate header code for the analysed pops and projs
-        if Global.config['paradigm'] == "openmp":
+        if get_global_config('paradigm') == "openmp":
             with open(source_dest+'ANNarchy.h', 'w') as ofile:
                 ofile.write(self._generate_header())
 
-        elif Global.config['paradigm'] == "cuda":
+        elif get_global_config('paradigm') == "cuda":
             invoke_header, host_header = self._generate_header()
             with open(source_dest+'ANNarchyKernel.cuh', 'w') as ofile:
                 ofile.write(invoke_header)
             with open(source_dest+'ANNarchy.h', 'w') as ofile:
                 ofile.write(host_header)
 
         else:
             raise NotImplementedError
 
         # Generate monitor code for the analysed pops and projs
         self._recordgen.generate()
 
         # Generate cpp code for the analysed pops and projs
-        if Global.config['paradigm'] == "openmp":
+        if get_global_config('paradigm') == "openmp":
             with open(source_dest+'ANNarchy.cpp', 'w') as ofile:
                 ofile.write(self._generate_body())
 
-        elif Global.config['paradigm'] == "cuda":
+        elif get_global_config('paradigm') == "cuda":
             device_code, host_code = self._generate_body()
             with open(source_dest+'ANNarchy.cpp', 'w') as ofile:
                 ofile.write(host_code)
             with open(source_dest+'ANNarchyKernel.cu', 'w') as ofile:
                 ofile.write(device_code)
 
         else:
@@ -174,17 +178,17 @@
 
         # Generate cython code for the analysed pops and projs
         with open(source_dest+'ANNarchyCore'+str(self._net_id)+'.pyx', 'w') as ofile:
             ofile.write(self._pyxgen.generate())
 
         self._generate_file_overview(source_dest)
 
-        if Global._profiler:
+        if Profiler().enabled:
             t1 = time.time()
-            Global._profiler.add_entry(t0, t1, "generate", "compile")
+            Profiler().add_entry(t0, t1, "generate", "compile")
 
     def _generate_file_overview(self, source_dest):
         """
         Generate a logfile, where we log which Population/Projection object is stored in
         which file.
 
         Parameters:
@@ -209,15 +213,15 @@
                     'pre_name': proj.pre.name,
                     'post_name': proj.post.name,
                     'target': proj.target,
                     'name': proj.name
                 }
 
                 # In case of debug, we print the parameters otherwise not
-                if Global.config['debug']:
+                if get_global_config('debug'):
                     desc_dict.update({'pattern': proj.connector_description})
                 else:
                     desc_dict.update({'pattern': proj.connector_description.split(',')[0]})
 
                 desc = desc = """proj%(id_proj)s, %(type_proj)s( pre = %(pre_name)s, post = %(post_name)s, target = %(target)s, name = %(name)s ) using connector: %(pattern)s \n""" % desc_dict
                 ofile.write(desc)
 
@@ -288,48 +292,48 @@
         custom_func = self._header_custom_functions()
 
         # Custom constants
         custom_constant = self._header_custom_constants()
 
         # Final code
         header_code = ""
-        if Global.config['paradigm'] == "openmp":
+        if get_global_config('paradigm') == "openmp":
             header_code = BaseTemplate.omp_header_template % {
-                'float_prec': Global.config['precision'],
+                'float_prec': get_global_config('precision'),
                 'pop_struct': pop_struct,
                 'proj_struct': proj_struct,
                 'pop_ptr': pop_ptr,
                 'proj_ptr': proj_ptr,
                 'custom_func': custom_func,
                 'custom_constant': custom_constant,
-                'built_in': BaseTemplate.built_in_functions + BaseTemplate.integer_power_cpu % {'float_prec': Global.config['precision']},
+                'built_in': BaseTemplate.built_in_functions + BaseTemplate.integer_power_cpu % {'float_prec': get_global_config('precision')},
             }
             return header_code
 
-        elif Global.config['paradigm'] == "cuda":
+        elif get_global_config('paradigm') == "cuda":
             # kernel declaration
             invoke_kernel_def = ""
             for pop in self._pop_desc:
                 invoke_kernel_def += pop['update_header']
 
             for proj in self._proj_desc:
                 invoke_kernel_def += proj['psp_kernel_decl']
                 invoke_kernel_def += proj['update_synapse_header']
                 invoke_kernel_def += proj['postevent_header']
 
             glob_ops_header, _, _ = self._body_def_glops()
             invoke_kernel_def += glob_ops_header
 
             device_invoke_header = BaseTemplate.cuda_device_invoke_header % {
-                'float_prec': Global.config['precision'],
+                'float_prec': get_global_config('precision'),
                 'invoke_kernel_def': invoke_kernel_def
             }
 
             host_header_code = BaseTemplate.cuda_header_template % {
-                'float_prec': Global.config['precision'],
+                'float_prec': get_global_config('precision'),
                 'pop_struct': pop_struct,
                 'proj_struct': proj_struct,
                 'pop_ptr': pop_ptr,
                 'proj_ptr': proj_ptr,
                 'custom_func': custom_func,
                 'built_in': BaseTemplate.built_in_functions,
                 'custom_constant': custom_constant
@@ -341,42 +345,42 @@
 
     def _header_custom_functions(self):
         """
         Generate code for custom functions defined globally and are usable
         witihn neuron or synapse descriptions. These functions can only rely on
         provided arguments.
         """
-        if len(Global._objects['functions']) == 0:
+        if GlobalObjectManager().number_functions() == 0:
             return ""
 
         # Attention CUDA: this definition will work only on host side.
         code = ""
-        for _, func in Global._objects['functions']:
+        for _, func in GlobalObjectManager().get_functions():
             code += extract_functions(func, local_global=True)[0]['cpp'] + '\n'
 
         return code
 
     def _header_custom_constants(self):
         """
         Generate code for custom constants
         """
-        if len(Global._objects['constants']) == 0:
+        if GlobalObjectManager().number_constants() == 0:
             return ""
 
         code = ""
-        for obj in Global._objects['constants']:
+        for obj in GlobalObjectManager().get_constants():
             obj_str = {
                 'name': obj.name,
-                'float_prec': Global.config['precision']
+                'float_prec': get_global_config('precision')
             }
-            if Global._check_paradigm("openmp"):
+            if _check_paradigm("openmp"):
                 code += """
 extern %(float_prec)s %(name)s;
 void set_%(name)s(%(float_prec)s value);""" % obj_str
-            elif Global._check_paradigm("cuda"):
+            elif _check_paradigm("cuda"):
                 code += """
 void set_%(name)s(%(float_prec)s value);""" % obj_str
             else:
                 raise NotImplementedError
 
         return code
 
@@ -392,45 +396,45 @@
 
         Returns (CUDA):
 
         * device_decl_code: declarations in header file (device side)
         * host_init_code: initialization code (host side)
 
         """
-        if Global._check_paradigm("openmp"):
-            if len(Global._objects['constants']) == 0:
+        if _check_paradigm("openmp"):
+            if GlobalObjectManager().number_constants() == 0:
                 return "", ""
 
             decl_code = ""
             init_code = ""
-            for obj in Global._objects['constants']:
+            for obj in GlobalObjectManager().get_constants():
                 obj_str = {
                     'name': obj.name,
                     'value': obj.value,
-                    'float_prec': Global.config['precision']
+                    'float_prec': get_global_config('precision')
                 }
                 decl_code += """
 %(float_prec)s %(name)s;
 void set_%(name)s(%(float_prec)s value){%(name)s = value;};""" % obj_str
                 init_code += """
         %(name)s = 0.0;""" % obj_str
 
             return decl_code, init_code
 
-        elif Global._check_paradigm("cuda"):
-            if len(Global._objects['constants']) == 0:
+        elif _check_paradigm("cuda"):
+            if GlobalObjectManager().number_constants() == 0:
                 return "", ""
 
             host_init_code = ""
             device_decl_code = ""
-            for obj in Global._objects['constants']:
+            for obj in GlobalObjectManager().get_constants():
                 obj_str = {
                     'name': obj.name,
                     'value': obj.value,
-                    'float_prec': Global.config['precision']
+                    'float_prec': get_global_config('precision')
                 }
                 device_decl_code += """__device__ __constant__ %(float_prec)s %(name)s;
 void set_%(name)s(%(float_prec)s value) {
     cudaError_t err = cudaMemcpyToSymbol(%(name)s, &value, sizeof(%(float_prec)s), 0, cudaMemcpyHostToDevice);
 #ifdef _DEBUG
     std::cout << "set global constant %(name)s = " << value << std::endl;
     if ( err != cudaSuccess )
@@ -475,15 +479,15 @@
 
         # Reset presynaptic sums
         reset_sums = self._body_resetcomputesum_pop()
 
         # Compute presynaptic sums
         compute_sums = ""
         # Sum over all synapses
-        if Global._check_paradigm("openmp"):
+        if _check_paradigm("openmp"):
             for proj in self._proj_desc:
                 compute_sums += proj["compute_psp"]
 
         # Update random distributions
         rd_update_code = ""
         for desc in self._pop_desc + self._proj_desc:
             if 'rng_update' in desc.keys():
@@ -510,15 +514,15 @@
         # Equations for the post-events
         post_event = ""
         for proj in self._proj_desc:
             if 'post_event' in proj.keys():
                 post_event += proj['post_event']
 
         # Structural plasticity
-        structural_plasticity = self._body_structural_plasticity()
+        structural_plasticity, sp_spike_backward_view_update = self._body_structural_plasticity()
 
         # Early stopping
         run_until = self._body_run_until()
 
         #Profiling
         if self._profgen:
             prof_dict = self._profgen.generate_body_dict()
@@ -526,21 +530,21 @@
             prof_dict = Profile.ProfileGenerator(self._annarchy_dir, self._net_id).generate_body_dict()
 
         #
         # Generate the ANNarchy.cpp code, the corrsponding template differs
         # greatly. For further information take a look into the corresponding
         # branches.
         #
-        if Global.config['paradigm'] == "openmp":
+        if get_global_config('paradigm') == "openmp":
             # custom constants
             custom_constant, _ = self._body_custom_constants()
 
             # code fields for openMP/single thread template
             base_dict = {
-                'float_prec': Global.config['precision'],
+                'float_prec': get_global_config('precision'),
                 'pop_ptr': pop_ptr,
                 'proj_ptr': proj_ptr,
                 'glops_def': glop_definition,
                 'initialize': self._body_initialize(),
                 'run_until': run_until,
                 'compute_sums' : compute_sums,
                 'reset_sums' : reset_sums,
@@ -548,26 +552,27 @@
                 'update_globalops' : update_globalops,
                 'update_synapse' : update_synapse,
                 'random_dist_update' : rd_update_code,
                 'delay_code' : delay_code,
                 'post_event' : post_event,
                 'structural_plasticity': structural_plasticity,
                 'custom_constant': custom_constant,
+                'sp_spike_backward_view_update': sp_spike_backward_view_update
             }
 
             # profiling
             base_dict.update(prof_dict)
 
             # complete code template
-            if Global.config["num_threads"] == 1:
+            if get_global_config('num_threads') == 1:
                 return BaseTemplate.st_body_template % base_dict
             else:
                 return BaseTemplate.omp_body_template % base_dict
 
-        elif Global.config['paradigm'] == "cuda":
+        elif get_global_config('paradigm') == "cuda":
             # Implementation notice ( HD: 10. June, 2015 )
             #
             # The CUDA linking process is a big problem for object oriented approaches
             # and the seperation of implementation codes into several files. Even in the
             # current SDK 5.0 this problem is not fully solved. Linking is available, but
             # only for small, independent code pieces, by far not sufficient for full
             # object-oriented approaches ...
@@ -592,15 +597,15 @@
 
             # custom functions
             custom_func = ""
             for pop in self._pop_desc:
                 custom_func += pop['custom_func']
             for proj in self._proj_desc:
                 custom_func += proj['custom_func']
-            for _, func in Global._objects['functions']:
+            for _, func in GlobalObjectManager().get_functions():
                 custom_func += extract_functions(func, local_global=True)[0]['cpp'].replace("inline", "__device__") + '\n'
 
             # pre-defined/common available kernel
             common_kernel = self._cuda_common_kernel(self._projections)
 
             pop_kernel = ""
             pop_invoke_kernel = ""
@@ -676,21 +681,21 @@
                 'syn_invoke_kernel': syn_invoke_kernel,
                 'glob_ops_kernel': glob_ops_body,
                 'glob_ops_invoke_kernel': glob_ops_invoke,
                 'postevent_kernel': postevent_device_kernel,
                 'postevent_invoke_kernel': postevent_invoke_kernel,
                 'custom_func': custom_func,
                 'custom_constant': device_custom_constant,
-                'built_in': BaseTemplate.built_in_functions + BaseTemplate.integer_power_cuda % {'float_prec': Global.config['precision']},
-                'float_prec': Global.config['precision']
+                'built_in': BaseTemplate.built_in_functions + BaseTemplate.integer_power_cuda % {'float_prec': get_global_config('precision')},
+                'float_prec': get_global_config('precision')
             }
 
             base_dict = {
                 # network definitions
-                'float_prec': Global.config['precision'],
+                'float_prec': get_global_config('precision'),
                 'pop_ptr': pop_ptr,
                 'proj_ptr': proj_ptr,
                 'run_until': run_until,
                 'clear_sums': clear_sums,
                 'compute_sums' : psp_call,
                 'update_neuron' : update_neuron,
                 'update_FR': pop_update_fr,
@@ -701,47 +706,48 @@
                 'initialize' : self._body_initialize(),
                 'structural_plasticity': structural_plasticity,
 
                 # cuda host specific
                 'stream_setup': stream_setup,
                 'host_device_transfer': host_device_transfer,
                 'device_host_transfer': device_host_transfer,
-                'kernel_config': threads_per_kernel
+                'kernel_config': threads_per_kernel,
+                'sp_spike_backward_view_update': ""
             }
             base_dict.update(prof_dict)
             host_code = BaseTemplate.cuda_host_body_template % base_dict    # Target: ANNarchy.cpp
 
             return device_code, host_code
         else:
             raise NotImplementedError
 
     def _body_initialize(self):
         """
         Define codes for the method initialize(), comprising of population and projection
         initializations, optionally profiling class.
         """
-        profiling_init = "" if not Global.config['profiling'] else self._profgen.generate_init_network()
+        profiling_init = "" if not get_global_config('profiling') else self._profgen.generate_init_network()
 
         # Initialize populations
         population_init = "    // Initialize populations\n"
         for pop in self._pop_desc:
             population_init += pop['init']
 
         # Initialize projections
         projection_init = "    // Initialize projections\n"
         for proj in self._proj_desc:
             projection_init += proj['init']
 
         # Initialize custom constants
-        if Global.config['paradigm'] == "openmp":
+        if get_global_config('paradigm') == "openmp":
             # Custom  constants
             _, custom_constant = self._body_custom_constants()
 
             init_tpl = BaseTemplate.omp_initialize_template
-        elif Global.config['paradigm'] == "cuda":
+        elif get_global_config('paradigm') == "cuda":
             # Custom  constants
             _, custom_constant = self._body_custom_constants()
 
             init_tpl = BaseTemplate.cuda_initialize_template
         else:
             raise NotImplementedError
 
@@ -763,26 +769,43 @@
                 code += self._popgen.reset_computesum(pop)
 
         return code
 
     def _body_structural_plasticity(self):
         """
         Call of pruning or creating methods if necessary.
+
+        Returns two strings:
+            * call statements called within singleStep()
+            * call statements called at begin of simulation loop
         """
         # Pruning if any
         pruning = ""
         creating = ""
-        if Global.config['structural_plasticity']:
+        rebuild_in_cpp = ""
+        rebuild_out_cpp = ""
+
+        if get_global_config('structural_plasticity'):
             for proj in self._projections:
+                rebuild_needed = False
                 if 'pruning' in proj.synapse_type.description.keys():
-                    pruning += tabify("proj%(id)s.pruning();" % {'id': proj.id}, 1)
+                    pruning += tabify("proj%(id)s.pruning();\n" % {'id': proj.id}, 1)
+                    rebuild_needed = True
                 if 'creating' in proj.synapse_type.description.keys():
-                    creating += tabify("proj%(id)s.creating();" % {'id': proj.id}, 1)
+                    creating += tabify("proj%(id)s.creating();\n" % {'id': proj.id}, 1)
+                    rebuild_needed = True
+                # we only check those projections which are possibly modified
+                if rebuild_needed and proj.synapse_type.type == 'spike':
+                    rebuild_in_cpp += tabify("proj%(id)s.check_and_rebuild_inverse_connectivity();\n" % {'id': proj.id}, 1)
+
+                # we don't know which projection the user modifies, so we need to check all
+                if proj.synapse_type.type == 'spike':
+                    rebuild_out_cpp += tabify("proj%(id)s.check_and_rebuild_inverse_connectivity();\n" % {'id': proj.id}, 1)
 
-        return creating + pruning
+        return creating + pruning + rebuild_in_cpp, rebuild_out_cpp
 
     def _body_def_glops(self):
         """
         Dependent on the used global operations we add pre-defined templates
         to the ANNarchy body file.
 
         Return:
@@ -793,51 +816,51 @@
         ops = []
         for pop in self._populations:
             for op in pop.global_operations:
                 ops.append(op['function'])
 
         # no global operations
         if ops == []:
-            if Global._check_paradigm("openmp"):
+            if _check_paradigm("openmp"):
                 return ""
-            elif Global._check_paradigm("cuda"):
+            elif _check_paradigm("cuda"):
                 return "", "", ""
             else:
-                raise NotImplementedError("CodeGenerator._body_def_glops(): no implementation for "+Global.config["paradigm"])
+                raise NotImplementedError("CodeGenerator._body_def_glops(): no implementation for "+get_global_config('paradigm'))
 
         type_def = {
-            'type': Global.config['precision']
+            'type': get_global_config('precision')
         }
 
         # the computation kernel depends on the paradigm
-        if Global._check_paradigm("openmp"):
-            if Global.config["num_threads"] == 1:
+        if _check_paradigm("openmp"):
+            if get_global_config('num_threads') == 1:
                 global_op_template = global_operation_templates_st
             else:
                 global_op_template = global_operation_templates_openmp
 
             code = ""
             for op in sorted(list(set(ops))):
                 code += global_op_template[op] % type_def
 
             return code
 
-        elif Global._check_paradigm("cuda"):
+        elif _check_paradigm("cuda"):
             header = ""
             invoke = ""
             body = ""
 
             for op in sorted(list(set(ops))):
                 header += global_operation_templates_cuda[op]['header'] % type_def
                 invoke += global_operation_templates_cuda[op]['invoke'] % type_def
                 body += global_operation_templates_cuda[op]['body'] % type_def
 
             return header, invoke, body
         else:
-            raise NotImplementedError("CodeGenerator._body_def_glops(): no implementation for "+Global.config["paradigm"])
+            raise NotImplementedError("CodeGenerator._body_def_glops(): no implementation for "+get_global_config('paradigm'))
 
     def _body_run_until(self):
         """
         Generate the code for conditioned stop of simulation
         """
         tpl = BaseTemplate.omp_run_until_template
 
@@ -897,16 +920,16 @@
 """
                 configuration += cfg % {
                     'id': pop.id,
                     'nr': num_threads,
                     'nb': num_blocks
                 }
 
-                if Global.config['verbose']:
-                    Global._print('population', pop.id, ' - kernel config: (', num_blocks, ',', num_threads, ')')
+                if get_global_config('verbose'):
+                    Messages._print('population', pop.id, ' - kernel config: (', num_blocks, ',', num_threads, ')')
 
         # Projection config - adjust psp, synapse_local_update, synapse_global_update
         configuration += "\n// Projections\n"
         for proj in self._projections:
             if proj in self._cuda_config.keys():
                 if 'num_threads' in self._cuda_config[proj].keys():
                     num_threads = self._cuda_config[proj]['num_threads']
@@ -924,16 +947,16 @@
                     configuration += cfg % {
                         'id_proj': proj.id,
                         'target': target,
                         'nr': num_threads,
                         'nb': num_blocks
                     }
 
-                    if Global.config['verbose']:
-                        Global._print('projection', proj.id, 'with target', target, ' - kernel config: (', num_blocks, ',', num_threads, ')')
+                    if get_global_config('verbose'):
+                        Messages._print('projection', proj.id, 'with target', target, ' - kernel config: (', num_blocks, ',', num_threads, ')')
 
         return configuration
 
     def _cuda_stream_config(self):
         """
         With Fermi Nvidia introduced multiple streams respectively concurrent
         kernel execution (requires device with compute compability > 2.x).
@@ -1039,16 +1062,16 @@
         for i in range(len(pow_of_2)):
             if pow_of_2[i] < num_neur:
                 continue
             else:
                 guess = pow_of_2[i]
                 break
 
-        if Global.config['verbose']:
-            Global._print('projection', proj.id, ' - kernel size:', guess)
+        if get_global_config('verbose'):
+            Messages._print('projection', proj.id, ' - kernel size:', guess)
 
         return guess
 
     def _cuda_common_kernel(self, projections):
         """
         Some sparse matrix formats require additional functions. Which we need to
         define only once.
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/MonitorGenerator.py` & `annarchy-4.8.0.1/ANNarchy/generator/MonitorGenerator.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,15 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 from ANNarchy.core import Global
+from ANNarchy.intern.NetworkManager import NetworkManager
+from ANNarchy.intern.ConfigManagement import get_global_config
 from ANNarchy.generator.Template import MonitorTemplate as RecTemplate
 from ANNarchy.generator.Utils import tabify
 from ANNarchy.extensions.bold import BoldMonitor
 
 class MonitorGenerator(object):
     """
     Creates the required codes for recording population
@@ -51,21 +53,21 @@
         for proj in self._projections:
             record_class += self._proj_recorder_class(proj)
 
         code = RecTemplate.record_base_class % {'record_classes': record_class}
 
         # The approach for default populations/projections is not
         # feasible for specific monitors, so we handle them extra
-        for mon in Global._network[self._net_id]['monitors']:
+        for mon in NetworkManager().get_monitors(net_id=self._net_id):
             if isinstance(mon, BoldMonitor):
                 mon_dict = {
                     'pop_id': mon.object.id,
                     'pop_name': mon.object.name,
                     'mon_id': mon.id,
-                    'float_prec': Global.config['precision'],
+                    'float_prec': get_global_config('precision'),
                     'var_name': mon.variables[0],
                 }
                 code += mon._specific_template['cpp'] % mon_dict
 
         # Generate header code for the analysed pops and projs
         with open(self._annarchy_dir+'/generate/net'+str(self._net_id)+'/Recorder.h', 'w') as ofile:
             ofile.write(code)
@@ -78,17 +80,17 @@
 
             * complete code as string
 
         Templates:
 
             omp_population, cuda_population
         """
-        if Global.config['paradigm'] == "openmp":
+        if get_global_config('paradigm') == "openmp":
             template = RecTemplate.omp_population
-        elif Global.config['paradigm'] == "cuda":
+        elif get_global_config('paradigm') == "cuda":
             template = RecTemplate.cuda_population
         else:
             raise NotImplementedError
 
         tpl_code = template['template']
 
         init_code = ""
@@ -114,22 +116,22 @@
                     targets.append(t2)
             else:
                 targets.append(t)
         targets = sorted(list(set(targets)))
 
         if pop.neuron_type.type == 'rate':
             for target in targets:
-                tar_dict = {'id': pop.id, 'type' : Global.config['precision'], 'name': '_sum_'+target}
+                tar_dict = {'id': pop.id, 'type' : get_global_config('precision'), 'name': '_sum_'+target}
                 struct_code += template['local']['struct'] % tar_dict
                 init_code += template['local']['init'] % tar_dict
                 recording_target_code += template['local']['recording'] % tar_dict
                 clear_code += template['local']['clear'] % tar_dict
         else:
             for target in targets:
-                tar_dict = {'id': pop.id, 'type' : Global.config['precision'], 'name': 'g_'+target}
+                tar_dict = {'id': pop.id, 'type' : get_global_config('precision'), 'name': 'g_'+target}
                 struct_code += template['local']['struct'] % tar_dict
                 init_code += template['local']['init'] % tar_dict
                 recording_target_code += template['local']['recording'] % tar_dict
                 clear_code += template['local']['clear'] % tar_dict
 
                 # to skip this entry in the following loop
                 target_list.append('g_'+target)
@@ -165,30 +167,30 @@
                 'type' : 'long int',
                 'name': 'spike',
                 'rec_target': 'spiked'
             }
 
             struct_code += base_tpl['struct'] % rec_dict
             init_code += base_tpl['init'] % rec_dict
-            recording_code += base_tpl['record'][Global.config['paradigm']] % rec_dict
-            size_in_bytes += base_tpl['size_in_bytes'][Global.config['paradigm']] % rec_dict
-            clear_code += base_tpl['clear'][Global.config['paradigm']] % rec_dict
+            recording_code += base_tpl['record'][get_global_config('paradigm')] % rec_dict
+            size_in_bytes += base_tpl['size_in_bytes'][get_global_config('paradigm')] % rec_dict
+            clear_code += base_tpl['clear'][get_global_config('paradigm')] % rec_dict
 
             # Record axon spike events
             if pop.neuron_type.axon_spike:
                 rec_dict = {
                     'id': pop.id,
                     'type' : 'long int',
                     'name': 'axon_spike',
                     'rec_target': 'axonal'
                 }
 
                 struct_code += base_tpl['struct'] % rec_dict
                 init_code += base_tpl['init'] % rec_dict
-                recording_code += base_tpl['record'][Global.config['paradigm']] % rec_dict
+                recording_code += base_tpl['record'][get_global_config('paradigm')] % rec_dict
 
         ids = {
             'id': pop.id,
             'init_code': init_code,
             'struct_code': struct_code,
             'recording_code': recording_code,
             'recording_target_code': recording_target_code,
@@ -205,17 +207,17 @@
 
             * complete code as string
 
         Templates:
 
             record
         """
-        if Global.config['paradigm'] == "openmp":
+        if get_global_config('paradigm') == "openmp":
             template = RecTemplate.omp_projection
-        elif Global.config['paradigm'] == "cuda":
+        elif get_global_config('paradigm') == "cuda":
             template = RecTemplate.cuda_projection
         else:
             raise NotImplementedError
 
         # Specific template
         if 'monitor_class' in proj._specific_template.keys():
             return proj._specific_template['monitor_class']
@@ -253,15 +255,15 @@
             size_in_bytes_code += template[locality]['size_in_bytes'] % {'type' : var['ctype'], 'name': var['name']}
 
             # Get the recording code
             recording_code += template[locality]['recording'] % {
                 'id': proj.id,
                 'type' : var['ctype'],
                 'name': var['name'],
-                'float_prec': Global.config["precision"]
+                'float_prec': get_global_config('precision')
             }
 
         final_dict = {
             'id': proj.id,
             'init_code': init_code,
             'recording_code': recording_code,
             'size_in_bytes_code': size_in_bytes_code,
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Population/CUDAGenerator.py` & `annarchy-4.8.0.1/ANNarchy/generator/Population/CUDAGenerator.py`

 * *Files 4% similar despite different names*

```diff
@@ -5,28 +5,29 @@
 
 import re
 from math import ceil
 from copy import deepcopy
 
 import ANNarchy
 
-from ANNarchy.core import Global
 from ANNarchy.generator.Template.GlobalOperationTemplate import global_operation_templates_cuda as global_op_template
 from ANNarchy.generator.Population import CUDATemplates
 from ANNarchy.generator.Utils import generate_equation_code, tabify, check_and_apply_pow_fix
-
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern import Messages
 from .PopulationGenerator import PopulationGenerator
 from .CUDATemplates import cuda_templates
 
 class CUDAGenerator(PopulationGenerator):
     """
     Generate the header for a Population object to use on CUDA devices.
     """
-    def __init__(self, profile_generator, net_id):
+    def __init__(self, cuda_version, profile_generator, net_id):
         super(CUDAGenerator, self).__init__(profile_generator, net_id)
+        self._cuda_version = cuda_version
 
     def header_struct(self, pop, annarchy_dir):
         """
         Specialized implementation of PopulationGenerator.header_struct() for
         generation of a CUDA header.
         """
         self._templates = deepcopy(cuda_templates)
@@ -172,15 +173,15 @@
             update_global_ops = pop._specific_template['update_global_ops']
 
         # Fill the template
         code = self._templates['population_header'] % {
             # version tag
             'annarchy_version': ANNarchy.__release__,
             # fill code templates
-            'float_prec': Global.config['precision'],
+            'float_prec': get_global_config('precision'),
             'id': pop.id,
             'name': pop.name,
             'size': pop.size,
             'include_additional': include_additional,
             'include_profile': include_profile,
             'struct_additional': struct_additional,
             'extern_global_operations': "", # CPU side global ops
@@ -426,15 +427,15 @@
                 // events
                 cudaMalloc((void**)&dev_spiked, size * sizeof(int));
                 gpu_delayed_spiked.push_front(dev_spiked);
 
                 // event counter
                 host_delayed_num_events.push_front(static_cast<unsigned int>(0));
             }
-            """ % {'max_delay': int(ceil(pop.max_delay/Global.config['dt']))}
+            """ % {'max_delay': int(ceil(pop.max_delay/get_global_config('dt')))}
             update_code += """
             int* last_spiked = gpu_delayed_spiked.back();
             gpu_delayed_spiked.pop_back();
             gpu_delayed_spiked.push_front(last_spiked);
 
             // do not copy empty vectors!
             if (spike_count > 0) {
@@ -485,15 +486,15 @@
     void compute_firing_rate( %(float_prec)s window){
         if(window>0.0){
             _mean_fr_window = int(window/dt);
             _mean_fr_rate = %(float_prec)s(1000./%(float_prec)s(window));
             if (_spike_history.empty())
                 _spike_history = std::vector< std::queue<long int> >(size, std::queue<long int>());
         }
-    };""" % {'float_prec': Global.config['precision']}
+    };""" % {'float_prec': get_global_config('precision')}
             init_FR = """
         // Mean Firing Rate
         _spike_history = std::vector< std::queue<long int> >();
         _mean_fr_window = 0;
         _mean_fr_rate = 1.0;"""
             reset_FR = """
         // Mean Firing Rate
@@ -509,15 +510,15 @@
 
     def _gen_kernel_args(self, pop, locality):
         """
         Generate the argument and call statemen for neural variables
         used in equations as well as there dependencies.
         """
         # Gather all variable names
-        add_args_header = "const long int t, const %(type)s dt" % {'type':Global.config['precision']}
+        add_args_header = "const long int t, const %(type)s dt" % {'type':get_global_config('precision')}
         add_args_invoke = "t, dt"
         add_args_call = "t, dt"
 
         deps = []
 
         # Variables
         for var in pop.neuron_type.description['variables']:
@@ -589,20 +590,20 @@
         host_code = ""
         device_code = ""
         for func in pop.neuron_type.description['functions']:
             cpp_func = func['cpp'] + '\n'
 
             host_code += cpp_func
             # TODO: improve code
-            if (Global.config["precision"] == "float"):
+            if (get_global_config('precision') == "float"):
                 device_code += cpp_func.replace('float ' + func['name'], '__device__ float pop%(id)s_%(func)s' % {'id': pop.id, 'func': func['name']})
             else:
                 device_code += cpp_func.replace('double ' + func['name'], '__device__ double pop%(id)s_%(func)s' % {'id': pop.id, 'func': func['name']})
 
-        return host_code, check_and_apply_pow_fix(device_code)
+        return host_code, check_and_apply_pow_fix(device_code, self._cuda_version)
 
     def _replace_local_funcs(self, pop, glob_eqs, loc_eqs):
         """
         As the local functions can be occur repeatadly in the same file,
         there are modified with pop[id]_ to unique them. Now we need
         to adjust the call accordingly.
 
@@ -627,52 +628,52 @@
 
         Update (ANNarchy 4.6.10.1):
 
             Further we need to ensure to draw the variables before solving the ODEs, otherwise we obtain wrong results for
             higher order solving methods.
         """
         # double precision methods have a postfix
-        prec_extension = "" if Global.config['precision'] == "float" else "_double"
+        prec_extension = "" if get_global_config('precision') == "float" else "_double"
 
         loc_pre = ""
         glob_pre = ""
         for rd in random_distributions:
             if rd['locality'] == "local":
                 term = ""
                 if rd['dist'] == "Uniform":
                     term = """( curand_uniform%(postfix)s( &state_%(rd)s%(idx)s ) * (%(max)s - %(min)s) + %(min)s )""" % {'postfix': prec_extension, 'rd': rd['name'], 'min': rd['args'].split(',')[0], 'max': rd['args'].split(',')[1], 'idx': "%(local_index)s"}
                 elif rd['dist'] == "Normal":
                     term = """( curand_normal%(postfix)s( &state_%(rd)s%(idx)s ) * %(sigma)s + %(mean)s )""" % {'postfix': prec_extension, 'rd': rd['name'], 'mean': rd['args'].split(",")[0], 'sigma': rd['args'].split(",")[1], 'idx': "%(local_index)s"}
                 elif rd['dist'] == "LogNormal":
                     term = """( curand_log_normal%(postfix)s( &state_%(rd)s%(idx)s, %(mean)s, %(std_dev)s) )""" % {'postfix': prec_extension, 'rd': rd['name'], 'mean': rd['args'].split(',')[0], 'std_dev': rd['args'].split(',')[1], 'idx': "%(local_index)s"}
                 else:
-                    Global._error("Unsupported random distribution on GPUs: " + rd['dist'])
+                    Messages._error("Unsupported random distribution on GPUs: " + rd['dist'])
 
                 # suppress local index
                 loc_eqs = loc_eqs.replace(rd['name']+"%(local_index)s", rd['name'])
 
                 # add the init
-                loc_pre += "%(prec)s %(name)s = %(term)s;" % {'prec': Global.config['precision'], 'name': rd['name'], 'term': term}
+                loc_pre += "%(prec)s %(name)s = %(term)s;" % {'prec': get_global_config('precision'), 'name': rd['name'], 'term': term}
 
             else:
                 term = ""
                 if rd['dist'] == "Uniform":
                     term = """( curand_uniform%(postfix)s( &state_%(rd)s%(idx)s ) * (%(max)s - %(min)s) + %(min)s )""" % {'postfix': prec_extension, 'rd': rd['name'], 'min': rd['args'].split(',')[0], 'max': rd['args'].split(',')[1], 'idx': "%(global_index)s"}
                 elif rd['dist'] == "Normal":
                     term = """( curand_normal%(postfix)s( &state_%(rd)s%(idx)s ) * %(sigma)s + %(mean)s )""" % {'postfix': prec_extension, 'rd': rd['name'], 'mean': rd['args'].split(",")[0], 'sigma': rd['args'].split(",")[1], 'idx': "%(global_index)s"}
                 elif rd['dist'] == "LogNormal":
                     term = """( curand_log_normal%(postfix)s( &state_%(rd)s%(idx)s, %(mean)s, %(std_dev)s) )""" % {'postfix': prec_extension, 'rd': rd['name'], 'mean': rd['args'].split(',')[0], 'std_dev': rd['args'].split(',')[1], 'idx': "%(global_index)s"}
                 else:
-                    Global._error("Unsupported random distribution on GPUs: " + rd['dist'])
+                    Messages._error("Unsupported random distribution on GPUs: " + rd['dist'])
 
                 # suppress global index
                 glob_eqs = glob_eqs.replace(rd['name']+"%(global_index)s", rd['name'])
 
                 # add the init
-                glob_pre += "%(prec)s %(name)s = %(term)s;" % {'prec': Global.config['precision'], 'name': rd['name'], 'term': term}
+                glob_pre += "%(prec)s %(name)s = %(term)s;" % {'prec': get_global_config('precision'), 'name': rd['name'], 'term': term}
 
         # check which equation blocks we need to extend
         if len(loc_pre) > 0:
             loc_eqs = tabify(loc_pre, 2) + "\n" + loc_eqs
         if len(glob_pre) > 0:
             glob_eqs = tabify(glob_pre, 1) + "\n" + glob_eqs
 
@@ -793,29 +794,29 @@
             // transfer to device
             if ( r_host_to_device ) {
                 cudaMemcpy(gpu_r, r.data(), size * sizeof(%(float_prec)s), cudaMemcpyHostToDevice);
                 r_host_to_device = false;
             }
         }
 """
-        return mean_FR_update % {'float_prec': Global.config['precision']}
+        return mean_FR_update % {'float_prec': get_global_config('precision')}
 
     def _update_globalops(self, pop):
         """
         Update of global functions is a call of pre-implemented
         functions defined in GlobalOperationTemplate. In case of
         CUDA the call semantic will be placed in ANNarchy.cu
         file as part of the host section.
         """
         if len(pop.global_operations) == 0:
             return ""
 
         code = ""
         for op in pop.global_operations:
-            code += global_op_template[op['function']]['call'] % {'id': pop.id, 'type': Global.config['precision'], 'op': op['function'], 'var': op['variable']}
+            code += global_op_template[op['function']]['call'] % {'id': pop.id, 'type': get_global_config('precision'), 'op': op['function'], 'var': op['variable']}
 
         return code
 
     def _update_random_distributions(self, pop):
         # HD (27.04.2016):
         # we dont need an update code here, as the drawing of random numbers is done in the Population::step()
         return ""
@@ -833,15 +834,15 @@
 
         """
         # Use pre-defined code template
         if 'update_variables' in pop._specific_template.keys():
             try:
                 return pop._specific_template['update_variable_body'], pop._specific_template['update_variable_invoke'], pop._specific_template['update_variable_header'], pop._specific_template['update_variable_call']
             except KeyError:
-                Global._error("\nCode generation error: if one attempts to override the population update on CUDA devices, one need to define all of the following fields of _specific_template dictionary:\n\tupdate_variables, update_variable_call, update_variable_header, update_variable_invoke, update_variable_body")
+                Messages._error("\nCode generation error: if one attempts to override the population update on CUDA devices, one need to define all of the following fields of _specific_template dictionary:\n\tupdate_variables, update_variable_call, update_variable_header, update_variable_invoke, update_variable_body")
 
         # Is there any variable?
         if len(pop.neuron_type.description['variables']) == 0:
             return "", "", "", ""
 
         device_kernel = ""
         kernel_invoke = ""
@@ -866,15 +867,15 @@
                 glob_eqs = glob_eqs.replace(par['name']+"%(global_index)s", par['name'])
                 loc_eqs = loc_eqs.replace(par['name']+"%(global_index)s", par['name'])
 
         # Gather pre-loop declaration (dt/tau for ODEs)
         pre_loop = ""
         for var in pop.neuron_type.description['variables']:
             if 'pre_loop' in var.keys() and len(var['pre_loop']) > 0:
-                pre_loop += Global.config['precision'] + ' ' + var['pre_loop']['name'] + ' = ' + var['pre_loop']['value'] + ';\n'
+                pre_loop += get_global_config('precision') + ' ' + var['pre_loop']['name'] + ' = ' + var['pre_loop']['value'] + ';\n'
         if pre_loop.strip() != '':
             pre_loop = """
 // Updating the step sizes
 """ + pre_loop
 
         # sum() must generate _sum___all__[i] = _sum_exc[i] + sum_inh[i] + ... at the beginning of local equations
         if '__all__' in pop.neuron_type.description['targets']:
@@ -883,16 +884,16 @@
             for target in pop.targets:
                 eqs += "_sum_" + target + '[i] + '
             eqs = eqs[:-2]
             eqs += ';\n\n'
             loc_eqs = eqs + loc_eqs
 
         # replace pow() for SDK < 6.5
-        loc_eqs = check_and_apply_pow_fix(loc_eqs)
-        glob_eqs = check_and_apply_pow_fix(glob_eqs)
+        loc_eqs = check_and_apply_pow_fix(loc_eqs, self._cuda_version)
+        glob_eqs = check_and_apply_pow_fix(glob_eqs, self._cuda_version)
 
         # replace the random distributions
         loc_eqs, glob_eqs = self._replace_random(loc_eqs, glob_eqs, pop.neuron_type.description['random_distributions'])
 
         # Replace %(global_idx)s for global parameters
         for var in pop.neuron_type.description["global"]:
             attr_type, attr_dict = self._get_attr_and_type(pop, var)
@@ -916,15 +917,15 @@
         # Global operations
         if glob_eqs.strip() != '':
             add_args_header, add_args_invoke, add_args_call = self._gen_kernel_args(pop, 'global')
 
             for op in pop.global_operations:
                 ids = {
                     'id': pop.id,
-                    'type': Global.config['precision'],
+                    'type': get_global_config('precision'),
                     'op': op['function'],
                     'var': op['variable']
                 }
                 add_args_header += """, %(type)s _%(op)s_%(var)s """ % ids
                 add_args_call += """, pop%(id)s._%(op)s_%(var)s""" % ids
 
             # finalize code templates
@@ -948,23 +949,23 @@
 
         # Local variables
         if loc_eqs.strip() != '':
             add_args_header, add_args_invoke, add_args_call = self._gen_kernel_args(pop, 'local')
 
             # targets
             for target in sorted(list(set(pop.neuron_type.description['targets'] + pop.targets))):
-                add_args_header += """, %(type)s* _sum_%(target)s""" % {'type': Global.config['precision'], 'target' : target}
+                add_args_header += """, %(type)s* _sum_%(target)s""" % {'type': get_global_config('precision'), 'target' : target}
                 add_args_invoke += """, _sum_%(target)s""" % {'target' : target}
                 add_args_call += """, pop%(id)s.gpu__sum_%(target)s""" % {'id': pop.id, 'target' : target}
 
             # global operations
             for op in pop.global_operations:
                 ids = {
                     'id': pop.id,
-                    'type': Global.config['precision'],
+                    'type': get_global_config('precision'),
                     'op': op['function'],
                     'var': op['variable']
                 }
                 add_args_header += """, %(type)s _%(op)s_%(var)s """ % ids
                 add_args_invoke += """, _%(op)s_%(var)s """ % ids
                 add_args_call += """, pop%(id)s._%(op)s_%(var)s""" % ids
 
@@ -1019,15 +1020,15 @@
             * tuple of four code snippets (device_kernel, device_invoke, kernel_decl, host_call)
         """
         # Use pre-defined code template
         if 'update_variables' in pop._specific_template.keys():
             try:
                 return pop._specific_template['update_variable_body'], pop._specific_template['update_variable_invoke'], pop._specific_template['update_variable_header'], pop._specific_template['update_variable_call']
             except KeyError:
-                Global._error("\nCode generation error: if one attempts to override the population update on CUDA devices, one need to define all of the following fields of _specific_template dictionary:\n\tupdate_variables, update_variable_call, update_variable_header, update_variable_invoke, update_variable_body")
+                Messages._error("\nCode generation error: if one attempts to override the population update on CUDA devices, one need to define all of the following fields of _specific_template dictionary:\n\tupdate_variables, update_variable_call, update_variable_header, update_variable_invoke, update_variable_body")
 
         # Is there any variable?
         if len(pop.neuron_type.description['variables']) == 0:
             return "", "", "", ""
 
         kernel_decl = ""
         device_kernel = ""
@@ -1051,23 +1052,23 @@
         loc_eqs = generate_equation_code(pop.id, pop.neuron_type.description, locality='local', padding=2)
 
         # Gather pre-loop declaration (dt/tau for ODEs) and
         # update the related kernels
         pre_code = ""
         for var in pop.neuron_type.description['variables']:
             if 'pre_loop' in var.keys() and len(var['pre_loop']) > 0:
-                pre_code += Global.config['precision'] + ' ' + var['pre_loop']['name'] + ' = ' + var['pre_loop']['value'] + ';\n'
+                pre_code += get_global_config('precision') + ' ' + var['pre_loop']['name'] + ' = ' + var['pre_loop']['value'] + ';\n'
         if pre_code.strip() != '':
             pre_code = """
     // Updating the step sizes
 """ + tabify(pre_code, 1)
 
         # replace pow() for SDK < 6.5
-        loc_eqs = check_and_apply_pow_fix(loc_eqs)
-        glob_eqs = check_and_apply_pow_fix(glob_eqs)
+        loc_eqs = check_and_apply_pow_fix(loc_eqs, self._cuda_version)
+        glob_eqs = check_and_apply_pow_fix(glob_eqs, self._cuda_version)
 
         # replace the random distributions
         loc_eqs, glob_eqs = self._replace_random(loc_eqs, glob_eqs, pop.neuron_type.description['random_distributions'])
 
         # within refractory perid, only conductance variables
         if pop.neuron_type.refractory or pop.refractory:
             refr_eqs = generate_equation_code(pop.id, pop.neuron_type.description, 'local', conductance_only=True, padding=3)
@@ -1102,15 +1103,15 @@
         if glob_eqs.strip() != '':
             add_args_header, add_args_invoke, add_args_call = self._gen_kernel_args(pop, 'global')
 
             # global operations
             for op in pop.global_operations:
                 ids = {
                     'id': pop.id,
-                    'type': Global.config['precision'],
+                    'type': get_global_config('precision'),
                     'op': op['function'],
                     'var': op['variable']
                 }
                 add_args_header += """, %(type)s _%(op)s_%(var)s """ % ids
                 add_args_invoke += """, _%(op)s_%(var)s """ % ids
                 add_args_call += """, pop%(id)s._%(op)s_%(var)s""" % ids
 
@@ -1132,15 +1133,15 @@
         if loc_eqs.strip() != '':
             add_args_header, add_args_invoke, add_args_call = self._gen_kernel_args(pop, 'local')
 
             # global operations
             for op in pop.global_operations:
                 ids = {
                     'id': pop.id,
-                    'type': Global.config['precision'],
+                    'type': get_global_config('precision'),
                     'op': op['function'],
                     'var': op['variable']
                 }
                 add_args_header += """, %(type)s _%(op)s_%(var)s """ % ids
                 add_args_invoke += """, _%(op)s_%(var)s """ % ids
                 add_args_call += """, pop%(id)s._%(op)s_%(var)s""" % ids
 
@@ -1209,15 +1210,15 @@
             'global_index': "[0]"
         }
 
         if 'spike_gather_body' in pop._specific_template.keys():
             try:
                 return pop._specific_template['spike_gather_body'], pop._specific_template['spike_gather_invoke'], pop._specific_template['spike_gather_header'], pop._specific_template['spike_gather_call']
             except KeyError:
-                Global._error("\nCode generation error: if one attempts to override the spike gathering on CUDA devices, one need to define all of the following fields of _specific_template dictionary: spike_gather_call, spike_gather_header, spike_gather_body")
+                Messages._error("\nCode generation error: if one attempts to override the spike gathering on CUDA devices, one need to define all of the following fields of _specific_template dictionary: spike_gather_call, spike_gather_header, spike_gather_body")
 
         cond = pop.neuron_type.description['spike']['spike_cond']
         reset = ""
         for eq in pop.neuron_type.description['spike']['spike_reset']:
             reset += """
             %(reset)s
 """ % {'reset': eq['cpp']}
@@ -1271,15 +1272,15 @@
                         if param['locality'] == 'local':
                             refrac_var = "int(" + pop.neuron_type.refractory + "[i]/dt)"
                         else:
                             refrac_var = "int(" + pop.neuron_type.refractory + "/dt)"
                         found = True
                         break
                 if not found:
-                    Global._error("refractory = "+ pop.neuron_type.refractory + ": parameter or variable does not exist.")
+                    Messages._error("refractory = "+ pop.neuron_type.refractory + ": parameter or variable does not exist.")
 
                 refrac_inc = "refractory_remaining[i] = %(refrac_var)s;" % {'refrac_var': refrac_var}
                 header_args += ", %(type)s *%(name)s, int* refractory_remaining" % {'type': param['ctype'], 'name': param['name']}
                 header_invoke += ", %(name)s, refractory_remaining" % {'name': param['name']}
                 call_args += ", pop%(id)s.gpu_%(name)s, pop%(id)s.gpu_refractory_remaining" %{'id':pop.id, 'name': param['name']}
 
             else: # default case
@@ -1298,31 +1299,31 @@
         else:
             launch_config = """int tpb = 32;\nint nb_blocks = %(nb)s;\n""" % {'nb': int(min(65535, float(pop.size)/32.0))}
         launch_config = tabify(launch_config, 2)
 
         device_kernel = CUDATemplates.spike_gather_kernel['device_kernel'] % {
             'id': pop.id,
             'pop_size': str(pop.size),
-            'float_prec': Global.config['precision'],
+            'float_prec': get_global_config('precision'),
             'args': header_args,
             'cond': cond,
             'reset': reset,
             'refrac_inc': refrac_inc
         }
 
         invoke_kernel = CUDATemplates.spike_gather_kernel['invoke_kernel'] % {
             'id': pop.id,
-            'float_prec': Global.config['precision'],
+            'float_prec': get_global_config('precision'),
             'args': header_args,
             'args_call': header_invoke
         }
 
         kernel_decl = CUDATemplates.spike_gather_kernel['kernel_decl'] % {
             'id': pop.id,
-            'default': 'const long int t, const %(float_prec)s dt, int* spiked, long int* last_spike' % {'float_prec': Global.config['precision']},
+            'default': 'const long int t, const %(float_prec)s dt, int* spiked, long int* last_spike' % {'float_prec': get_global_config('precision')},
             'args': header_args
         }
 
         if pop.max_delay > 1:
             default_args = 't, dt, pop%(id)s.gpu_delayed_spiked.front(), pop%(id)s.gpu_last_spike' % {'id': pop.id}
         else: # no_delay
             default_args = 't, dt, pop%(id)s.gpu_spiked, pop%(id)s.gpu_last_spike' % {'id': pop.id}
@@ -1373,15 +1374,15 @@
             else:
                 # nothing to do for global parameter
                 continue
 
         # Rate-coded targets
         if pop.neuron_type.type == "rate":
             for target in sorted(list(set(pop.neuron_type.description['targets'] + pop.targets))):
-                ids = {'attr_name': "_sum_"+target, 'type': Global.config["precision"], 'id': pop.id}
+                ids = {'attr_name': "_sum_"+target, 'type': get_global_config('precision'), 'id': pop.id}
                 host_device_transfer += self._templates['attribute_transfer']['HtoD_local'] % ids
 
         # Refractoriness
         if pop.neuron_type.type == "spike":
             if pop.neuron_type.refractory or pop.refractory:
                 host_device_transfer += """
         // refractory
@@ -1410,15 +1411,15 @@
                 device_host_transfer += self._templates['attribute_transfer']['DtoH_local'] % ids
             else:
                 device_host_transfer += self._templates['attribute_transfer']['DtoH_global'] % ids
 
         # Write back rate-coded targets
         if pop.neuron_type.type == "rate":
             for target in sorted(list(set(pop.neuron_type.description['targets'] + pop.targets))):
-                ids = {'attr_name': "_sum_"+target, 'type': Global.config["precision"], 'id': pop.id}
+                ids = {'attr_name': "_sum_"+target, 'type': get_global_config('precision'), 'id': pop.id}
                 device_host_transfer += self._templates['attribute_transfer']['DtoH_local'] % ids
 
         if 'host_device_transfer' in pop._specific_template.keys():
             host_device_transfer = pop._specific_template['host_device_transfer']
         if 'device_host_transfer' in pop._specific_template.keys():
             device_host_transfer = pop._specific_template['device_host_transfer']
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Population/CUDATemplates.py` & `annarchy-4.8.0.1/ANNarchy/generator/Population/CUDATemplates.py`

 * *Files 1% similar despite different names*

```diff
@@ -610,18 +610,15 @@
     # Refractory period
     cpdef np.ndarray get_refractory(self):
         return np.array(pop%(id)s.refractory)
     cpdef set_refractory(self, np.ndarray value):
         pop%(id)s.refractory = value
         pop%(id)s.refractory_dirty = True
 """
-    },
-    'init_event-driven': """
-        last_spike = std::vector<long int>(size, -10000L);
-"""
+    }
 }
 
 # Contains all codes related to the population update
 #
 # 1st level distinguish 'local' and 'global' update
 # 2nd level distinguish 'device_kernel', 'invoke_kernel', 'header' and 'host_call' template
 population_update_kernel = {
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Population/OpenMPGenerator.py` & `annarchy-4.8.0.1/ANNarchy/generator/Population/OpenMPGenerator.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,14 +6,16 @@
 from copy import deepcopy
 
 import ANNarchy
 
 from ANNarchy.generator.Template.GlobalOperationTemplate import global_operation_templates_omp_extern as global_op_extern_dict
 from ANNarchy.generator.Utils import generate_equation_code, tabify, remove_trailing_spaces
 from ANNarchy.core import Global
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern import Messages
 
 from ANNarchy.generator.Population.PopulationGenerator import PopulationGenerator
 from ANNarchy.generator.Population.OpenMPTemplates import openmp_templates
 
 class OpenMPGenerator(PopulationGenerator):
     """
     Generate the header for a Population object to run either on single core
@@ -47,15 +49,15 @@
         declare_additional = ""
         init_additional = ""
         reset_additional = ""
 
         # Declare global operations as extern at the beginning of the file
         extern_global_operations = ""
         for op in pop.global_operations:
-            extern_global_operations += global_op_extern_dict[op['function']] % {'type': Global.config['precision']}
+            extern_global_operations += global_op_extern_dict[op['function']] % {'type': get_global_config('precision')}
 
         # Initialize parameters and variables
         init_parameters_variables = self._init_population(pop)
 
         # Spike-specific stuff
         reset_spike = ""; declare_spike = ""; init_spike = ""
         if pop.neuron_type.description['type'] == 'spike':
@@ -172,15 +174,15 @@
             update_global_ops = pop._specific_template['update_global_ops']
 
         # Fill the template
         code = self._templates['population_header'] % {
             # version tag
             'annarchy_version': ANNarchy.__release__,
             # fill code templates
-            'float_prec': Global.config['precision'],
+            'float_prec': get_global_config('precision'),
             'id': pop.id,
             'name': pop.name,
             'size': pop.size,
             'include_additional': include_additional,
             'include_profile': include_profile,
             'struct_additional': struct_additional,
             'extern_global_operations': extern_global_operations,
@@ -265,15 +267,15 @@
 
         # HD: use set to remove doublons
         for target in sorted(set(pop.targets)):
             code += self._templates['rate_psp']['reset'] % {
                 'id': pop.id,
                 'name': pop.name,
                 'target': target,
-                'float_prec': Global.config['precision']
+                'float_prec': get_global_config('precision')
             }
 
         # we need to sync the memsets
         if len(code) > 1:
             code += tabify("#pragma omp barrier\n", 1)
 
         return code
@@ -488,15 +490,15 @@
     void compute_firing_rate(%(float_prec)s window){
         if(window>0.0){
             _mean_fr_window = int(window/dt);
             _mean_fr_rate = 1000./window;
             if (_spike_history.empty())
                 _spike_history = std::vector< std::queue<long int> >(size, std::queue<long int>());
         }
-    };""" % {'float_prec': Global.config['precision']}
+    };""" % {'float_prec': get_global_config('precision')}
             init_FR = """
         // Mean Firing Rate
         _spike_history = std::vector< std::queue<long int> >();
         _mean_fr_window = 0;
         _mean_fr_rate = 1.0;"""
             reset_FR = """
         // Mean Firing Rate
@@ -523,15 +525,15 @@
             #pragma omp for
             for (int i = 0; i < size; i++) {
                 while((_spike_history[i].size() != 0)&&(_spike_history[i].front() <= t - _mean_fr_window)){
                     _spike_history[i].pop(); // Suppress spikes outside the window
                 }
                 r[i] = _mean_fr_rate * %(float_prec)s(_spike_history[i].size());
             }
-        } """ % {'float_prec': Global.config['precision']}
+        } """ % {'float_prec': get_global_config('precision')}
 
         return mean_FR_push, mean_FR_update
 
     ##################################################
     # Global operations
     ##################################################
     def _update_globalops(self, pop):
@@ -584,15 +586,15 @@
         """
         Generate the C++ for drawing pseudo-random numbers in each step.
         The random variables are drawn sequentially from the same source.
         """
         if len(pop.neuron_type.description['random_distributions']) == 0:
             return ""
 
-        if Global.config['disable_parallel_rng']:
+        if get_global_config('disable_parallel_rng'):
             use_parallel_rng = False
         else:
             use_parallel_rng = True
 
         rng_code = self._templates['rng']['omp_code_seq'] if not use_parallel_rng else self._templates['rng']['omp_code_par']
 
         local_code = ""
@@ -600,15 +602,15 @@
         rng_dist_code = ""
         for rd in pop.neuron_type.description['random_distributions']:
 
             rng_dist_code += self._templates['rng']['dist_decl'] % {
                 'rd_name': rd['name'],
                 'rd_init': rd['definition'] % {
                     'id': pop.id,
-                    'float_prec': Global.config['precision'],
+                    'float_prec': get_global_config('precision'),
                     'global_index': ''
                 }
             }
 
             if rd['locality'] == 'local':
                 if not use_parallel_rng:
                     local_code += self._templates['rng'][rd['locality']]['update'] % {'id': pop.id, 'rd_name': rd['name'], 'index': 0}
@@ -720,15 +722,15 @@
             code += """
             // Updating the local variables
             %(omp_code)s
             for (int i = 0; i < size; i++) {
 %(eqs)s
             }
 """ % {
-    'omp_code': "#pragma omp for simd" if not Global.config["disable_SIMD_Eq"] else "#pragma omp for",
+    'omp_code': "#pragma omp for simd" if not get_global_config('disable_SIMD_Eq') else "#pragma omp for",
     'eqs': eqs
 }
 
         # finish code
         final_code = """
         if( _active ) {
 %(code)s
@@ -824,15 +826,15 @@
             %(omp_code)s
             for (int i = 0; i < size; i++) {
 %(local_code)s
             }
 
         } // active
 """ % {
-    'omp_code': "#pragma omp for simd" if not Global.config["disable_SIMD_Eq"] else "#pragma omp for",
+    'omp_code': "#pragma omp for simd" if not get_global_config('disable_SIMD_Eq') else "#pragma omp for",
     'comp_inref': comp_inref,
     'local_code': local_code,
     'global_code': global_code,
     }
 
         # if profiling enabled, annotate with profiling code
         if self._prof_gen:
@@ -910,15 +912,15 @@
                         if param['locality'] == 'local':
                             refrac_var = "int(" + pop.neuron_type.refractory + "[i]/dt)"
                         else:
                             refrac_var = "int(" + pop.neuron_type.refractory + "/dt)"
                         found = True
                         break
                 if not found:
-                    Global._error("refractory = "+ pop.neuron_type.refractory + ": parameter or variable does not exist.")
+                    Messages._error("refractory = "+ pop.neuron_type.refractory + ": parameter or variable does not exist.")
 
             refrac_inc = "refractory_remaining[i] = %(refrac_var)s;"%{'refrac_var': refrac_var}
             omp_code = "#pragma omp for" if pop.size > Global.OMP_MIN_NB_NEURONS else ""
 
         else:
             refrac_inc = ""
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Population/OpenMPTemplates.py` & `annarchy-4.8.0.1/ANNarchy/generator/Population/OpenMPTemplates.py`

 * *Files 1% similar despite different names*

```diff
@@ -476,18 +476,15 @@
         'pyx_wrapper': """
     # Refractory period
     cpdef np.ndarray get_refractory(self):
         return np.array(pop%(id)s.refractory)
     cpdef set_refractory(self, np.ndarray value):
         pop%(id)s.refractory = value
 """
-    },
-    'init_event-driven': """
-        last_spike = std::vector<long int>(size, -10000L);
-""",
+    }
 }
 
 #
 # Final dictionary
 openmp_templates = {
     'population_header': population_header,
     'attr_decl': attribute_decl,
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Population/PopulationGenerator.py` & `annarchy-4.8.0.1/ANNarchy/generator/Population/PopulationGenerator.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-from ANNarchy.core import Global
+from ANNarchy.intern.ConfigManagement import get_global_config, _check_paradigm
 from ANNarchy.generator.Utils import tabify
 
 class PopulationGenerator(object):
     """
     Base class for population generators in ANNarchy. Inherited by
 
     * OpenMPGenerator: single-thread and multi-core implementation
@@ -72,37 +72,37 @@
                 all_targets = set(pop.neuron_type.description['targets'] + pop.targets[0])
 
             for target in sorted(list(all_targets)):
                 attr_name = 'g_'+target
                 if attr_name not in already_processed:
                     # we assume here, that targets are local variables
                     id_dict = {
-                        'type' : Global.config['precision'],
+                        'type' : get_global_config('precision'),
                         'name': attr_name,
                         'attr_type': 'variable'
                     }
                     declaration += self._templates['attr_decl']['local'] % id_dict
                     already_processed.append(attr_name)
 
         # Global operations
         if len(pop.global_operations) != 0:
             declaration += """
     // Global operations
 """
             for op in pop.global_operations:
                 op_dict = {
-                    'type': Global.config['precision'],
+                    'type': get_global_config('precision'),
                     'op': op['function'],
                     'var': op['variable']
                 }
                 
-                if Global._check_paradigm("openmp"):
+                if _check_paradigm("openmp"):
                     declaration += """    %(type)s _%(op)s_%(var)s;
 """ % op_dict
-                elif Global._check_paradigm("cuda"):
+                elif _check_paradigm("cuda"):
                     declaration += """
     %(type)s _%(op)s_%(var)s;
     %(type)s* _gpu_%(op)s_%(var)s;
 """ % op_dict
                 else:
                     raise NotImplementedError
 
@@ -110,15 +110,15 @@
         declaration += """
     // Random numbers
 """
         for rd in pop.neuron_type.description['random_distributions']:
             declaration += self._templates['rng'][rd['locality']]['decl'] % {
                 'rd_name' : rd['name'],
                 'type': rd['ctype'],
-                'template': rd['template'] % {'float_prec':Global.config['precision']}
+                'template': rd['template'] % {'float_prec':get_global_config('precision')}
             }
 
         return declaration, accessors
 
     @staticmethod
     def _get_attr(pop, name):
         """
@@ -151,15 +151,15 @@
             if attr['name'] == name:
                 return 'rand', attr
 
         # the given name wasn't either an attribute nor a random distribution,
         # lets test if it was a psp
         for target in sorted(list(set(pop.neuron_type.description['targets'] + pop.targets))):
             if name == "sum("+target+")":
-                return 'psp', { 'ctype': Global.config['precision'], 'name': '_sum_'+target }
+                return 'psp', { 'ctype': get_global_config('precision'), 'name': '_sum_'+target }
 
         return None, None
 
     def _init_fr(self, pop):
         "Implemented by child class"
         raise NotImplementedError
 
@@ -172,22 +172,22 @@
             return ""
 
         code = "\n// Initialize global operations\n"
         for op in pop.global_operations:
             ids = {
                 'op': op['function'],
                 'var': op['variable'],
-                'type': Global.config['precision']
+                'type': get_global_config('precision')
             }
 
-            if Global._check_paradigm("openmp"):
+            if _check_paradigm("openmp"):
                 code += """_%(op)s_%(var)s = 0.0;
 """ % ids
 
-            elif Global._check_paradigm("cuda"):
+            elif _check_paradigm("cuda"):
                 code += """_%(op)s_%(var)s = 0.0;
 cudaMalloc((void**)&_gpu_%(op)s_%(var)s, sizeof(%(type)s));
 """ % ids
 
             else:
                 raise NotImplementedError
 
@@ -203,15 +203,15 @@
 
         # Parameters
         for var in pop.neuron_type.description['parameters']:
             # Avoid doublons
             if var['name'] in already_processed:
                 continue
 
-            if Global._check_paradigm("cuda") and var['locality'] == "global":
+            if _check_paradigm("cuda") and var['locality'] == "global":
                 code += attr_tpl[var['locality']]['parameter'] % {'name': var['name']}
             else:
                 init = 'false' if var['ctype'] == 'bool' else ('0' if var['ctype'] == 'int' else '0.0')
                 var_ids = {'id': pop.id, 'name': var['name'], 'type': var['ctype'],
                         'init': init, 'attr_type': 'parameter'}
                 code += attr_tpl[var['locality']] % var_ids
 
@@ -223,23 +223,23 @@
             if var['name'] in already_processed:
                 continue
 
             init = 'false' if var['ctype'] == 'bool' else ('0' if var['ctype'] == 'int' else '0.0')
             var_ids = {'id': pop.id, 'name': var['name'], 'type': var['ctype'],
                        'init': init, 'attr_type': 'variable'}
 
-            if Global._check_paradigm("cuda") and var['locality'] == "global":
+            if _check_paradigm("cuda") and var['locality'] == "global":
                 code += attr_tpl[var['locality']]['variable'] % var_ids
             else:
                 code += attr_tpl[var['locality']] % var_ids
 
             already_processed.append(var['name'])
 
         # Random numbers 
-        if Global._check_paradigm("openmp"):
+        if _check_paradigm("openmp"):
             if len(pop.neuron_type.description['random_distributions']) > 0:
                 rng_code = "\n// Random numbers\n"
                 for rd in pop.neuron_type.description['random_distributions']:
                     rng_ids = {
                         'id': pop.id,
                         'rd_name': rd['name'],
                         'type': rd['ctype'],
@@ -265,15 +265,15 @@
         # rate-coded targets
         if pop.neuron_type.type == 'rate':
             for target in sorted(list(set(pop.neuron_type.description['targets'] + pop.targets))):
                 ids = {
                     'id': pop.id,
                     'name': "_sum_"+target,
                     'attr_type': 'psp',
-                    'type': Global.config['precision'],
+                    'type': get_global_config('precision'),
                     'init': 0.0
                 }
                 code += attr_tpl['local'] % ids
 
         # or unused synaptic spiking targets
         else:
             try:
@@ -282,15 +282,15 @@
                 # The projection has multiple targets
                 all_targets = set(pop.neuron_type.description['targets'] + pop.targets[0])
 
             for target in sorted(list(all_targets)):
                 attr_name = 'g_'+target
                 if attr_name not in already_processed:
                     id_dict = {
-                        'type' : Global.config['precision'],
+                        'type' : get_global_config('precision'),
                         'name': attr_name,
                         'attr_type': 'variable',
                         'init': 0.0
                     }
                     code += self._templates['attribute_cpp_init']['local'] % id_dict
                     already_processed.append(attr_name)
                     
@@ -420,15 +420,15 @@
             if attr['locality'] == "global":
                 code += "size_in_bytes += sizeof(%(ctype)s);\t// %(name)s\n" % ids
             else:
                 code += "size_in_bytes += sizeof(std::vector<%(ctype)s>) + sizeof(%(ctype)s) * %(name)s.capacity();\t// %(name)s\n" % ids
 
         # Random variables
         code +="// RNGs\n"
-        if Global._check_paradigm("openmp"):
+        if _check_paradigm("openmp"):
             for dist in pop.neuron_type.description['random_distributions']:
                 ids = {
                     'ctype': dist['ctype'],
                     'name': dist['name']
                 }
                 if dist['locality'] == "local":
                     code += "size_in_bytes += sizeof(std::vector<%(ctype)s>) + sizeof(%(ctype)s) * %(name)s.capacity();\t// %(name)s\n" % ids
@@ -441,18 +441,14 @@
         code = tabify(code, 2)
         return code
 
     def _generate_default_get_set(self, pop):
         """
         Generate a get/set template for all attributes in the given population
         """
-        # Pick basic template based on neuron type
-        attr_template = self._templates['attr_decl']
-        acc_template = self._templates['attr_acc']
-
         declaration = "" # member declarations
         accessors = "" # export member functions
         already_processed = []
         code_ids_per_type = {}
 
         # Sort the parameters/variables per type
         for var in pop.neuron_type.description['parameters'] + pop.neuron_type.description['variables']:
@@ -465,15 +461,15 @@
                 code_ids_per_type[var['ctype']] = []
 
             # Important which template to choose
             locality = var['locality']
             attr_type = 'parameter' if var in pop.neuron_type.description['parameters'] else 'variable'
 
             # For GPUs we need to tell the host that this variable need to be updated
-            if Global._check_paradigm("cuda"):
+            if _check_paradigm("cuda"):
                 if attr_type == "parameter" and locality == "global":
                     read_dirty_flag = ""
                     write_dirty_flag = ""
                 else:
                     write_dirty_flag = "%(name)s_host_to_device = true;" % {'name': var['name']}
                     read_dirty_flag = "if ( %(name)s_device_to_host < t ) device_to_host();" % {'name': var['name']}
             else:
@@ -491,54 +487,75 @@
             })
 
             already_processed.append(var['name'])
 
         # For rate-coded models add _sum_target
         if pop.neuron_type.type == "rate":
             for target in sorted(list(set(pop.neuron_type.description['targets'] + pop.targets))):
-                prec_type = Global.config['precision']
+                prec_type = get_global_config('precision')
 
                 # add to the processing list
                 code_ids_per_type[prec_type].append({
                     'type' : prec_type,
                     'name': "_sum_"+target,
                     'locality': 'local',
                     'attr_type': 'psp',
                     'write_dirty_flag': "_sum_"+target+"_host_to_device = true;",
                     'read_dirty_flag': "if ( _sum_"+target+"_device_to_host < t ) device_to_host();"
                 })
 
+        # For spiking models we add spike vector
+        if pop.neuron_type.type == "spike":
+            # create new type category if needed
+            if "int" not in code_ids_per_type.keys():
+                code_ids_per_type["int"] = []
+
+            # add to the processing list
+            code_ids_per_type["int"].append({
+                'type' : "int",
+                'name': "spiked",
+                'locality': 'local',
+                'attr_type': 'spike',
+                'write_dirty_flag': "",
+                'read_dirty_flag': ""
+            })
+
         # Final code, can contain of multiple sets of accessor functions
         accessors = ""
+
         for ctype in code_ids_per_type.keys():
             local_attribute_get1 = ""
             local_attribute_get2 = ""
             local_attribute_set1 = ""
             local_attribute_set2 = ""
             global_attribute_get = ""
             global_attribute_set = ""
 
             for ids in code_ids_per_type[ctype]:
                 locality = ids['locality']
 
+                # Accessor codes
                 if locality == "local":
                     local_attribute_get1 += self._templates["attr_acc"]["local_get_all"] % ids
                     local_attribute_get2 += self._templates["attr_acc"]["local_get_single"] % ids
 
                     local_attribute_set1 += self._templates["attr_acc"]["local_set_all"] % ids
                     local_attribute_set2 += self._templates["attr_acc"]["local_set_single"] % ids
 
                 elif locality == "global":
                     global_attribute_get += self._templates["attr_acc"]["global_get"] % ids
                     global_attribute_set += self._templates["attr_acc"]["global_set"] % ids
 
                 else:
                     raise ValueError("PopulationGenerator: invalild locality type for attribute")
 
-                if Global._check_paradigm("cuda") and locality == "global":
+                # Declaration codes
+                if ids['name'] == "spiked":
+                    declaration += ""   # already declared
+                elif _check_paradigm("cuda") and locality == "global":
                     declaration += self._templates['attr_decl'][locality][ids['attr_type']] % ids
                 else:
                     declaration += self._templates['attr_decl'][locality] % ids
 
             # build up the final codes
             if local_attribute_get1 != "":
                 accessors += self._templates["accessor_template"]["local"] % {
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Population/SingleThreadGenerator.py` & `annarchy-4.8.0.1/ANNarchy/generator/Population/SingleThreadGenerator.py`

 * *Files 3% similar despite different names*

```diff
@@ -6,14 +6,16 @@
 from copy import deepcopy
 
 import ANNarchy
 
 from ANNarchy.generator.Template.GlobalOperationTemplate import global_operation_templates_st_extern as global_op_extern_dict
 from ANNarchy.generator.Utils import generate_equation_code, tabify, remove_trailing_spaces
 from ANNarchy.core import Global
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern import Messages
 
 from ANNarchy.generator.Population.PopulationGenerator import PopulationGenerator
 from ANNarchy.generator.Population.SingleThreadTemplates import single_thread_templates
 
 class SingleThreadGenerator(PopulationGenerator):
     """
     Generate the header for a Population object to run either on single core
@@ -47,15 +49,15 @@
         declare_additional = ""
         init_additional = ""
         reset_additional = ""
 
         # Declare global operations as extern at the beginning of the file
         extern_global_operations = ""
         for op in pop.global_operations:
-            extern_global_operations += global_op_extern_dict[op['function']] % {'type': Global.config['precision']}
+            extern_global_operations += global_op_extern_dict[op['function']] % {'type': get_global_config('precision')}
 
         # Initialize parameters and variables
         init_parameters_variables = self._init_population(pop)
 
         # Spike-specific stuff
         reset_spike = ""; declare_spike = ""; init_spike = ""
         if pop.neuron_type.description['type'] == 'spike':
@@ -172,15 +174,15 @@
             update_global_ops = pop._specific_template['update_global_ops']
 
         # Fill the template
         code = self._templates['population_header'] % {
             # version tag
             'annarchy_version': ANNarchy.__release__,
             # fill code templates
-            'float_prec': Global.config['precision'],
+            'float_prec': get_global_config('precision'),
             'id': pop.id,
             'name': pop.name,
             'size': pop.size,
             'include_additional': include_additional,
             'include_profile': include_profile,
             'struct_additional': struct_additional,
             'extern_global_operations': extern_global_operations,
@@ -264,15 +266,15 @@
 
         # HD: use set to remove doublons
         for target in sorted(set(pop.targets)):
             code += self._templates['rate_psp']['reset'] % {
                 'id': pop.id,
                 'name': pop.name,
                 'target': target,
-                'float_prec': Global.config['precision']
+                'float_prec': get_global_config('precision')
             }
 
         return code
 
     ##################################################
     # Delays
     ##################################################
@@ -480,15 +482,15 @@
     void compute_firing_rate(%(float_prec)s window){
         if(window>0.0){
             _mean_fr_window = int(window/dt);
             _mean_fr_rate = 1000./window;
             if (_spike_history.empty())
                 _spike_history = std::vector< std::queue<long int> >(size, std::queue<long int>());
         }
-    };""" % {'float_prec': Global.config['precision']}
+    };""" % {'float_prec': get_global_config('precision')}
             init_FR = """
         // Mean Firing Rate
         _spike_history = std::vector< std::queue<long int> >();
         _mean_fr_window = 0;
         _mean_fr_rate = 1.0;"""
             reset_FR = """
         // Mean Firing Rate
@@ -514,15 +516,15 @@
             mean_FR_update = """if (_mean_fr_window > 0) {
                 for (int i = 0; i < size; i++) {
                     while((_spike_history[i].size() != 0)&&(_spike_history[i].front() <= t - _mean_fr_window)){
                         _spike_history[i].pop(); // Suppress spikes outside the window
                     }
                     r[i] = _mean_fr_rate * %(float_prec)s(_spike_history[i].size());
                 }
-            } """ % {'float_prec': Global.config['precision']}
+            } """ % {'float_prec': get_global_config('precision')}
 
         return mean_FR_push, mean_FR_update
 
     ##################################################
     # Global operations
     ##################################################
     def _update_globalops(self, pop):
@@ -559,15 +561,15 @@
         global_code = ""
         rng_dist_code = ""
         for rd in pop.neuron_type.description['random_distributions']:
             rng_dist_code += self._templates['rng']['dist_decl'] % {
                 'rd_name': rd['name'],
                 'rd_init': rd['definition'] % {
                     'id': pop.id,
-                    'float_prec': Global.config['precision'],
+                    'float_prec': get_global_config('precision'),
                     'global_index': ''
                 }
             }
 
             if rd['locality'] == 'local':
                 local_code += self._templates['rng'][rd['locality']]['update'] % {'id': pop.id, 'rd_name': rd['name'], 'index': 0}
             else:
@@ -648,15 +650,15 @@
             pop.id, pop.neuron_type.description, 'local', padding=4)
         eqs = eqs % id_dict
 
         if eqs.strip() != "":
             code_dict = {
                 'eqs': eqs,
                 'id': pop.id,
-                'omp_simd': "#pragma omp simd" if not Global.config["disable_SIMD_Eq"] else ""
+                'omp_simd': "#pragma omp simd" if not get_global_config('disable_SIMD_Eq') else ""
             }
             code += """
         if( _active ) {
         #ifdef _TRACE_SIMULATION_STEPS
             std::cout << "    PopStruct%(id)s::update()" << std::endl;
         #endif
 
@@ -752,15 +754,15 @@
             // Updating local variables
             %(omp_simd)s
             for(int i = 0; i < size; i++){
 %(local_code)s
             }
         } // active
 """ % {
-    'omp_simd': "#pragma omp simd" if not Global.config["disable_SIMD_Eq"] else "",
+    'omp_simd': "#pragma omp simd" if not get_global_config('disable_SIMD_Eq') else "",
     'comp_inref': comp_inref,
     'local_code': local_code,
     'global_code': global_code
     }
 
         # if profiling enabled, annotate with profiling code
         if self._prof_gen:
@@ -835,15 +837,15 @@
                         if param['locality'] == 'local':
                             refrac_var = "int(" + pop.neuron_type.refractory + "[i]/dt)"
                         else:
                             refrac_var = "int(" + pop.neuron_type.refractory + "/dt)"
                         found = True
                         break
                 if not found:
-                    Global._error("refractory = "+ pop.neuron_type.refractory + ": parameter or variable does not exist.")
+                    Messages._error("refractory = "+ pop.neuron_type.refractory + ": parameter or variable does not exist.")
 
             # set the refractory value
             refrac_inc = "refractory_remaining[i] = %(refrac_var)s;"%{'refrac_var': refrac_var}
         else:
             refrac_inc = ""
 
         # Mean Firing rate
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Population/SingleThreadTemplates.py` & `annarchy-4.8.0.1/ANNarchy/generator/Population/SingleThreadTemplates.py`

 * *Files 1% similar despite different names*

```diff
@@ -441,18 +441,15 @@
         'pyx_wrapper': """
     # Refractory period
     cpdef np.ndarray get_refractory(self):
         return np.array(pop%(id)s.refractory)
     cpdef set_refractory(self, np.ndarray value):
         pop%(id)s.refractory = value
 """
-    },
-    'init_event-driven': """
-        last_spike = std::vector<long int>(size, -10000L);
-""",
+    }
 }
 
 #
 # Final dictionary
 single_thread_templates = {
     'population_header': population_header,
     'attr_decl': attribute_decl,
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Profile/CPP11Profile.py` & `annarchy-4.8.0.1/ANNarchy/generator/Profile/CPP11Profile.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-from ANNarchy.core import Global
 from ANNarchy.generator.Utils import tabify
+from ANNarchy.intern.ConfigManagement import get_global_config
 
 from .ProfileGenerator import ProfileGenerator
 from .ProfileTemplate import profile_base_template, cpp11_profile_template, cpp11_omp_profile_template, cpp11_profile_header
 
 class CPP11Profile(ProfileGenerator):
     """
     Extent the generated code by profiling annotations using the C++11
@@ -25,15 +25,15 @@
         with open(self.annarchy_dir+'/generate/net'+str(self._net_id)+'/Profiling.h', 'w') as ofile:
             ofile.write(self._generate_header())
 
     def generate_body_dict(self):
         """
         Creates a dictionary, contain profile code snippets.
         """
-        if Global.config["num_threads"] == 1:
+        if get_global_config('num_threads') == 1:
             body_dict = {
                 'prof_include': cpp11_profile_template['include'],
                 'prof_step_pre': cpp11_profile_template['step_pre'],
                 'prof_step_post': cpp11_profile_template['step_post'],
                 'prof_run_pre': cpp11_profile_template['run_pre'],
                 'prof_run_post': cpp11_profile_template['run_post'],
                 'prof_proj_psp_pre': cpp11_profile_template['proj_psp_pre'],
@@ -73,15 +73,15 @@
                 'prof_global_ops_pre': cpp11_omp_profile_template['global_op_pre'],
                 'prof_global_ops_post': cpp11_omp_profile_template['global_op_post']
             }
 
         return body_dict
 
     def generate_init_network(self):
-        if Global.config["num_threads"] == 1:
+        if get_global_config('num_threads') == 1:
             return cpp11_profile_template['init']
         else:
             return cpp11_omp_profile_template['init']
 
     def generate_init_population(self, pop):
         """
         Generate initialization code for population
@@ -126,15 +126,15 @@
 
         return declare, init
 
     def annotate_computesum_rate(self, proj, code):
         """
         annotate the computesum compuation code
         """
-        if Global.config["num_threads"] == 1:
+        if get_global_config('num_threads') == 1:
             prof_begin = cpp11_profile_template['compute_psp']['before']
             prof_end = cpp11_profile_template['compute_psp']['after']
         else:
             prof_begin = cpp11_omp_profile_template['compute_psp']['before']
             prof_end = cpp11_omp_profile_template['compute_psp']['after']
 
         prof_code = """
@@ -150,15 +150,15 @@
 
         return prof_code
 
     def annotate_computesum_spiking(self, proj, code):
         """
         annotate the computesum compuation code
         """
-        if Global.config["num_threads"] == 1:
+        if get_global_config('num_threads') == 1:
             prof_begin = cpp11_profile_template['compute_psp']['before'] % {'name': 'proj'+str(proj.id)}
             prof_end = cpp11_profile_template['compute_psp']['after'] % {'name': 'proj'+str(proj.id)}
         else:
             prof_begin = cpp11_omp_profile_template['compute_psp']['before'] % {'name': 'proj'+str(proj.id)}
             prof_end = cpp11_omp_profile_template['compute_psp']['after'] % {'name': 'proj'+str(proj.id)}
 
         prof_code = """
@@ -172,15 +172,15 @@
        }
         return prof_code
 
     def annotate_update_synapse(self, proj, code):
         """
         annotate the update synapse code, generated by ProjectionGenerator.update_synapse()
         """
-        if Global.config["num_threads"] == 1:        
+        if get_global_config('num_threads') == 1:        
             prof_begin = cpp11_profile_template['update_synapse']['before']
             prof_end = cpp11_profile_template['update_synapse']['after']
         else:
             prof_begin = cpp11_omp_profile_template['update_synapse']['before']
             prof_end = cpp11_omp_profile_template['update_synapse']['after']
 
         prof_code = """
@@ -195,15 +195,15 @@
 
         return prof_code
 
     def annotate_post_event(self, proj, code):
         """
         annotate the post-event code
         """
-        if Global.config["num_threads"] == 1:
+        if get_global_config('num_threads') == 1:
             prof_begin = cpp11_profile_template['post_event']['before']
             prof_end = cpp11_profile_template['post_event']['after']
         else:
             prof_begin = cpp11_omp_profile_template['post_event']['before']
             prof_end = cpp11_omp_profile_template['post_event']['after']
 
         prof_dict = {
@@ -219,15 +219,15 @@
 
         return prof_code
 
     def annotate_update_neuron(self, pop, code):
         """
         annotate the update neuron code
         """
-        if Global.config["num_threads"] == 1:        
+        if get_global_config('num_threads') == 1:        
             prof_begin = cpp11_profile_template['update_neuron']['before'] % {'name': pop.name}
             prof_end = cpp11_profile_template['update_neuron']['after'] % {'name': pop.name}
         else:
             prof_begin = cpp11_omp_profile_template['update_neuron']['before'] % {'name': pop.name}
             prof_end = cpp11_omp_profile_template['update_neuron']['after'] % {'name': pop.name}
 
         prof_code = """
@@ -241,15 +241,15 @@
        }
         return prof_code
 
     def annotate_spike_cond(self, pop, code):
         """
         annotate the spike condition code
         """
-        if Global.config["num_threads"] == 1:
+        if get_global_config('num_threads') == 1:
             prof_begin = cpp11_profile_template['spike_gather']['before'] % {'name': pop.name}
             prof_end = cpp11_profile_template['spike_gather']['after'] % {'name': pop.name}
         else:
             prof_begin = cpp11_omp_profile_template['spike_gather']['before'] % {'name': pop.name}
             prof_end = cpp11_omp_profile_template['spike_gather']['after'] % {'name': pop.name}
 
         prof_dict = {
@@ -265,15 +265,15 @@
 
         return prof_code
 
     def annotate_update_rng(self, pop, code):
         """
         annotate update rng kernel (only for CPUs available)
         """
-        if Global.config["num_threads"] == 1:
+        if get_global_config('num_threads') == 1:
             prof_begin = cpp11_profile_template['update_rng']['before'] % {'name': pop.name}
             prof_end = cpp11_profile_template['update_rng']['after'] % {'name': pop.name}
         else:
             prof_begin = cpp11_omp_profile_template['update_rng']['before'] % {'name': pop.name}
             prof_end = cpp11_omp_profile_template['update_rng']['after'] % {'name': pop.name}
 
         prof_dict = {
@@ -288,15 +288,15 @@
 """
         return prof_code % prof_dict
 
     def annotate_update_delay(self, pop, code):
         """
         annotate update delay kernel (only for CPUs available)
         """
-        if Global.config["num_threads"] == 1:
+        if get_global_config('num_threads') == 1:
             prof_begin = cpp11_profile_template['update_delay']['before'] % {'name': pop.name}
             prof_end = cpp11_profile_template['update_delay']['after'] % {'name': pop.name}
         else:
             prof_begin = cpp11_omp_profile_template['update_delay']['before'] % {'name': pop.name}
             prof_end = cpp11_omp_profile_template['update_delay']['after'] % {'name': pop.name}
 
         prof_dict = {
@@ -317,24 +317,24 @@
         """
         config_xml = """
         _out_file << "  <config>" << std::endl;
         _out_file << "    <paradigm>%(paradigm)s</paradigm>" << std::endl;
         _out_file << "    <num_threads>%(num_threads)s</num_threads>" << std::endl;
         _out_file << "  </config>" << std::endl;
         """ % {
-            'paradigm': Global.config["paradigm"],
-            'num_threads': Global.config["num_threads"]
+            'paradigm': get_global_config('paradigm'),
+            'num_threads': get_global_config('num_threads')
         }
-        config = Global.config["paradigm"] + '_'  + str(Global.config["num_threads"]) + 'threads'
+        config = get_global_config('paradigm') + '_'  + str(get_global_config('num_threads')) + 'threads'
 
         timer_import = "#include <chrono>"
         timer_start = "std::chrono::time_point<std::chrono::steady_clock> _profiler_start;"
         timer_init = "_profiler_start = std::chrono::steady_clock::now();"
         return profile_base_template % {
             'timer_import': timer_import,
             'timer_start_decl': timer_start,
             'timer_init': timer_init,
             'config': config,
-            'result_file': "results_%(config)s.xml" % {'config':config} if Global.config['profile_out'] == None else Global.config['profile_out'],
+            'result_file': "results_%(config)s.xml" % {'config':config} if get_global_config('profile_out') == None else get_global_config('profile_out'),
             'config_xml': config_xml,
             'measurement_class': cpp11_profile_header
         }
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Profile/CUDAProfile.py` & `annarchy-4.8.0.1/ANNarchy/generator/Profile/CUDAProfile.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-from ANNarchy.core import Global
+from ANNarchy.intern.ConfigManagement import get_global_config
 
 from .ProfileGenerator import ProfileGenerator
 from .ProfileTemplate import profile_base_template, cuda_profile_template, cuda_profile_header
 
 class CUDAProfile(ProfileGenerator):
 
     def __init__(self, annarchy_dir, net_id):
@@ -195,24 +195,24 @@
         """
         generate Profiling.h
         """
         config_xml = """
         _out_file << "  <config>" << std::endl;
         _out_file << "    <paradigm>%(paradigm)s</paradigm>" << std::endl;
         _out_file << "  </config>" << std::endl;
-        """ % {'paradigm': Global.config["paradigm"]}
+        """ % {'paradigm': get_global_config('paradigm')}
 
         timer_import = "#include <cuda_runtime_api.h>"
         timer_start = "cudaEvent_t _profiler_start;"
         timer_init = """
         cudaEventCreate(&_profiler_start);
         cudaEventRecord(_profiler_start);
 """
 
-        config = Global.config["paradigm"]
+        config = get_global_config('paradigm')
         return profile_base_template % {
             'timer_import': timer_import,
             'timer_start_decl': timer_start,
             'timer_init': timer_init,
             'config': config,
             'config_xml': config_xml,
             'measurement_class': cuda_profile_header
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Profile/PAPIProfile.py` & `annarchy-4.8.0.1/ANNarchy/generator/Profile/PAPIProfile.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,25 +1,26 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-from ANNarchy.core import Global
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern import Messages
 
 from .ProfileGenerator import ProfileGenerator
 from .ProfileTemplate import profile_base_template, papi_profile_template, papi_profile_header
 
 class PAPIProfile(ProfileGenerator):
     """
     Extent the generated code by profiling annotations.
     """
     def __init__(self, annarchy_dir, net_id):
         ProfileGenerator.__init__(self, annarchy_dir, net_id)
 
-        Global._warning("The PAPI profiling is deprecated. Please use the CPP11Profile instead.")
+        Messages._warning("The PAPI profiling is deprecated. Please use the CPP11Profile instead.")
 
     def generate(self):
         """
         Generate Profiling class code, called from Generator instance.
         """
         # Generate header for profiling
         with open(self.annarchy_dir+'/generate/net'+str(self._net_id)+'/Profiling.h', 'w') as ofile:
@@ -151,31 +152,31 @@
         """
         config_xml = """
         _out_file << "  <config>" << std::endl;
         _out_file << "    <paradigm>%(paradigm)s</paradigm>" << std::endl;
         _out_file << "    <num_threads>%(num_threads)s</num_threads>" << std::endl;
         _out_file << "  </config>" << std::endl;
         """ % {
-            'paradigm': Global.config["paradigm"],
-            'num_threads': Global.config["num_threads"]
+            'paradigm': get_global_config('paradigm'),
+            'num_threads': get_global_config('num_threads')
         }
 
         timer_import = "#include <papi.h>"
         timer_start = "long_long _profiler_start;"
         timer_init = """
         // initialize PAPI
         if (PAPI_library_init(PAPI_VER_CURRENT) != PAPI_VER_CURRENT)
             exit(1);
 
         _profiler_start = PAPI_get_real_usec();
 """
 
-        config = Global.config["paradigm"] + '_'  + str(Global.config["num_threads"]) + 'threads'
+        config = get_global_config('paradigm') + '_'  + str(get_global_config('num_threads')) + 'threads'
         return profile_base_template % {
             'timer_import': timer_import,
             'timer_start_decl': timer_start,
             'timer_init': timer_init,
             'config': config,
-            'result_file': "results_%(config)s.xml" % {'config':config} if Global.config['profile_out'] == None else Global.config['profile_out'],
+            'result_file': "results_%(config)s.xml" % {'config':config} if get_global_config('profile_out') == None else get_global_config('profile_out'),
             'config_xml': config_xml,
             'measurement_class': papi_profile_header
         }
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Profile/ProfileGenerator.py` & `annarchy-4.8.0.1/ANNarchy/generator/Profile/ProfileGenerator.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Profile/ProfileTemplate.py` & `annarchy-4.8.0.1/ANNarchy/generator/Profile/ProfileTemplate.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/BSR.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/BSR.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/BaseTemplates.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/BaseTemplates.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/COO.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/COO.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/CSR.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/CSR.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/CSR_Scalar.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/CSR_Scalar.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/CSR_T.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/CSR_T.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/CSR_Vector.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/CSR_Vector.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/Dense.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/Dense.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/Dense_T.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/Dense_T.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/ELL.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/ELL.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/ELLR.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/ELLR.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/HYB.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/HYB.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/SELL.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/SELL.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDA/__init__.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDA/__init__.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/CUDAGenerator.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/CUDAGenerator.py`

 * *Files 6% similar despite different names*

```diff
@@ -10,31 +10,34 @@
 import ANNarchy
 
 from copy import deepcopy
 
 from ANNarchy.core import Global
 from ANNarchy.core.Population import Population
 from ANNarchy.core.PopulationView import PopulationView
-from ANNarchy.core.SpecificProjection import SpecificProjection
-from ANNarchy.generator.Utils import generate_equation_code, tabify, check_and_apply_pow_fix, determine_idx_type_for_projection
 
-from ANNarchy.generator.Population.PopulationGenerator import PopulationGenerator
+from ANNarchy.intern.SpecificProjection import SpecificProjection
+from ANNarchy.intern.ConfigManagement import get_global_config, _check_precision
+from ANNarchy.intern import Messages
 
+from ANNarchy.generator.Utils import generate_equation_code, tabify, check_and_apply_pow_fix, determine_idx_type_for_projection
+from ANNarchy.generator.Population.PopulationGenerator import PopulationGenerator
 from ANNarchy.generator.Projection.ProjectionGenerator import ProjectionGenerator, get_bounds
 from ANNarchy.generator.Projection.CUDA import *
 
 class CUDAGenerator(ProjectionGenerator):
     """
     As stated in module description, inherits from ProjectionGenerator
     and implements abstract functions.
     """
-    def __init__(self, profile_generator, net_id):
+    def __init__(self, cuda_version, profile_generator, net_id):
         # The super here calls all the base classes, so first
         # ProjectionGenerator and afterwards CUDAConnectivity
         super(CUDAGenerator, self).__init__(profile_generator, net_id)
+        self._cuda_version = cuda_version
 
     def header_struct(self, proj, annarchy_dir):
         """
         Generate the codes for the pop[id].hpp file. This file contains
         the c-style structure with all data members and equation codes (in
         case of openMP).
         """
@@ -86,15 +89,15 @@
             connector_call = self._connectivity_init(proj, sparse_matrix_format, sparse_matrix_args) % {
                 'sparse_format': sparse_matrix_format,
                 'init_weights': init_weights,
                 'init_delays': init_delays,
                 'rng_idx': "[0]" if single_matrix else "",
                 'add_args': "",
                 'num_threads': "",
-                'float_prec': Global.config["precision"],
+                'float_prec': get_global_config('precision'),
                 'idx_type': determine_idx_type_for_projection(proj)[0]
             }
             declare_connectivity_matrix = ""
             access_connectivity_matrix = ""
         else:
             sparse_matrix_format = "SpecificConnectivity"
             sparse_matrix_args = ""
@@ -144,15 +147,15 @@
             # fill code templates
             'id_pre': proj.pre.id,
             'id_post': proj.post.id,
             'id_proj': proj.id,
             'name_pre': proj.pre.name,
             'name_post': proj.post.name,
             'target': proj.target,
-            'float_prec': Global.config['precision'],
+            'float_prec': get_global_config('precision'),
             'sparse_matrix_include': sparse_matrix_include,
             'sparse_format': sparse_matrix_format,
             'sparse_format_args': sparse_matrix_args,
             'include_additional': include_additional,
             'include_profile': include_profile,
             'struct_additional': struct_additional,
             'declare_connectivity_matrix': declare_connectivity_matrix,
@@ -230,15 +233,15 @@
         self._template_ids.update({
             'id_proj' : proj.id,
             'target': proj.target,
             'id_post': proj.post.id,
             'id_pre': proj.pre.id,
             'idx_type': idx_type,
             'size_type': size_type,
-            'float_prec': Global.config["precision"],
+            'float_prec': get_global_config('precision'),
             'pre_prefix': 'pre_',
             'post_prefix': 'post_',
             'host_pre_prefix': 'pop'+ str(proj.pre.id) + '.',
             'host_post_prefix': 'pop'+ str(proj.post.id) + '.'
         })
 
         # Indices to access data depend on the storage format/storage order
@@ -312,15 +315,15 @@
                 self._templates.update(Dense_CUDA.conn_templates)
                 self._template_ids.update(Dense_CUDA.conn_ids)
             else:
                 self._templates.update(Dense_T_CUDA.conn_templates)
                 self._template_ids.update(Dense_T_CUDA.conn_ids)
 
         else:
-            raise Global.InvalidConfiguration("   The storage_format="+str(proj._storage_format)+" is not available on CUDA devices")
+            raise Messages.InvalidConfiguration("   The storage_format="+str(proj._storage_format)+" is not available on CUDA devices")
 
     def _generate_launch_config(self, proj):
         """
         TODO: multiple targets???
         """
         if isinstance(proj, SpecificProjection):
             # HD (24th Feb. 2023): user-defined codes has their own kernel-call statements,
@@ -351,15 +354,15 @@
 
             try:
                 device_kernel_header = proj._specific_template['psp_header']
                 kernel_invoke = proj._specific_template['psp_invoke']
                 device_kernel = proj._specific_template['psp_body']
                 host_call = proj._specific_template['psp_call']
             except KeyError:
-                Global._error('At least one of the following fields is missing for psp: header, invoke, body or call')
+                Messages._error('At least one of the following fields is missing for psp: header, invoke, body or call')
 
             if self._prof_gen:
                 host_call = self._prof_gen.annotate_computesum_rate(proj, host_call)
 
             return device_kernel, kernel_invoke, device_kernel_header, host_call
 
         # Dictionary of keywords to transform the parsed equations
@@ -379,15 +382,15 @@
         #
         # Retrieve the PSP
         add_args_header = ""
         add_args_call = ""
         add_args_kernel = ""
         if not 'psp' in  proj.synapse_type.description.keys(): # default
             psp = """%(preprefix)sr%(pre_index)s * w%(local_index)s;"""
-            add_args_header += "const %(float_prec)s* __restrict__ pre_r, const %(float_prec)s* __restrict__ w" % {'float_prec': Global.config['precision']}
+            add_args_header += "const %(float_prec)s* __restrict__ pre_r, const %(float_prec)s* __restrict__ w" % {'float_prec': get_global_config('precision')}
             add_args_call = "pop%(id_pre)s.gpu_r, proj%(id_proj)s.gpu_w " % {'id_proj': proj.id, 'id_pre': proj.pre.id}
             add_args_kernel = "pre_r, w"
 
         else: # custom psp
             psp = (proj.synapse_type.description['psp']['cpp'])
 
             # update dependencies
@@ -445,29 +448,29 @@
             body_dict = deepcopy(ids)
             body_dict.update({
                 # device function
                 'conn_args': conn_header,
                 'target_arg': "sum_"+proj.target,
                 'add_args': add_args_header,
                 'psp': psp  % ids,
-                'thread_init': self._templates['rate_psp']['thread_init'][Global.config['precision']][operation],
+                'thread_init': self._templates['rate_psp']['thread_init'][get_global_config('precision')][operation],
                 # call function
                 'conn_args_call': conn_kernel,
                 'target_arg_call': ", sum_%(target)s" % {'id_post': proj.post.id, 'target': proj.target},
                 'add_args_call': add_args_kernel,
             })
             device_kernel = self._templates['rate_psp']['device_kernel'][operation] % body_dict
 
             if 'invoke_kernel' in self._templates['rate_psp'].keys():
                 invoke_kernel = self._templates['rate_psp']['invoke_kernel'] % body_dict
                 kernel_decl = self._templates['rate_psp']['kernel_decl'] % body_dict
             else:
                 invoke_kernel = ""
                 kernel_decl = self._templates['rate_psp']['kernel_decl'] % {
-                    'float_prec': Global.config['precision'],
+                    'float_prec': get_global_config('precision'),
                     'id': proj.id,
                     'conn_args': conn_header,
                     'target_arg': "sum_"+proj.target,
                     'add_args': add_args_header
                 }
 
             host_call_dict = deepcopy(ids)
@@ -501,26 +504,26 @@
                 'pre_index': '[rank_pre[j*post_size+i]]',
                 'post_index': '[rank_post[i]]',
                 'pre_prefix': 'pre_',
                 'post_prefix': 'post_'
             }
             body_code = ELL_CUDA.conn_templates['rate_psp']['body'][operation] % {
                 'idx_type': idx_type,
-                'float_prec': Global.config['precision'],
+                'float_prec': get_global_config('precision'),
                 'id_proj': proj.id,
                 'conn_args': conn_header,
                 'target_arg': "sum_"+proj.target,
                 'add_args': add_args_header,
                 'psp': psp  % ell_ids,
-                'thread_init': ELLR_CUDA.conn_templates['rate_psp']['thread_init'][Global.config['precision']][operation],
+                'thread_init': ELLR_CUDA.conn_templates['rate_psp']['thread_init'][get_global_config('precision')][operation],
                 'post_index': ell_ids['post_index']
             }
             header_code = ELL_CUDA.conn_templates['rate_psp']['header'] % {
                 'idx_type': idx_type,
-                'float_prec': Global.config['precision'],
+                'float_prec': get_global_config('precision'),
                 'id': proj.id,
                 'conn_args': conn_header,
                 'target_arg': "sum_"+proj.target,
                 'add_args': add_args_header
             }
 
             #
@@ -533,27 +536,27 @@
                 'global_index': '[0]',
                 'pre_index': '[column_indices[j]]',
                 'post_index': '[row_indices[j]]',
                 'pre_prefix': 'pre_',
                 'post_prefix': 'post_',
             }
             body_code += COO_CUDA.conn_templates['rate_psp']['body'][operation] % {
-                'float_prec': Global.config['precision'],
+                'float_prec': get_global_config('precision'),
                 'idx_type': idx_type,
                 'size_type': size_type,
                 'id_proj': proj.id,
                 'conn_args': conn_header,
                 'target_arg': "sum_"+proj.target,
                 'add_args': add_args_header,
                 'psp': psp  % coo_ids,
-                'thread_init': COO_CUDA.conn_templates['rate_psp']['thread_init'][Global.config['precision']][operation],
+                'thread_init': COO_CUDA.conn_templates['rate_psp']['thread_init'][get_global_config('precision')][operation],
                 'post_index': coo_ids['post_index']
             }
             header_code += COO_CUDA.conn_templates['rate_psp']['header'] % {
-                'float_prec': Global.config['precision'],
+                'float_prec': get_global_config('precision'),
                 'id': proj.id,
                 'conn_args': conn_header,
                 'target_arg': "sum_"+proj.target,
                 'add_args': add_args_header
             }
 
             # update dependencies
@@ -568,15 +571,15 @@
                 'id_pre': proj.pre.id,
                 'id_post': proj.post.id,
                 'conn_args': conn_call,
                 'target': proj.target,
                 'target_arg': ", pop%(id_post)s.gpu__sum_%(target)s" % {'id_post': proj.post.id, 'target': proj.target},
                 'add_args_coo': add_args_call_coo,
                 'add_args_ell': add_args_call_ell,
-                'float_prec': Global.config['precision']
+                'float_prec': get_global_config('precision')
             }
 
         # Take delays into account if any
         if proj.max_delay > 1:
             # Delayed variables
             if isinstance(proj.pre, PopulationView):
                 delayed_variables = proj.pre.population.delayed_variables
@@ -610,15 +613,15 @@
 
             try:
                 device_kernel_header = proj._specific_template['psp_header']
                 kernel_invoke = proj._specific_template['psp_invoke']
                 device_kernel = proj._specific_template['psp_body']
                 host_call = proj._specific_template['psp_call']
             except KeyError:
-                Global._error('At least one of the following fields is missing for psp: header, invoke, body or call')
+                Messages._error('At least one of the following fields is missing for psp: header, invoke, body or call')
 
             if self._prof_gen:
                 host_call = self._prof_gen.annotate_computesum_rate(proj, host_call)
 
             return device_kernel, kernel_invoke, device_kernel_header, host_call
 
         # some variables needed for the final templates
@@ -627,15 +630,15 @@
         kernel_args_invoke = ""
         kernel_args_call = ""
 
         pre_spike_code = ""
         kernel_deps = []
 
         if proj.max_delay > 1 and proj.uniform_delay == -1:
-            Global._error("Non-uniform delays are not supported yet on GPUs.")
+            Messages._error("Non-uniform delays are not supported yet on GPUs.")
 
         # Basic tags, dependent on storage format are assuming a feedforward
         # transmission.
         ids = deepcopy(self._template_ids)
 
         # The spike transmission is triggered from pre-synaptic side
         # and the indices need to be changed.
@@ -644,15 +647,15 @@
         #                      set of conn ids? (TODO - HD/JV)
         if proj._storage_format == "csr":
             if proj._storage_order == "post_to_pre":
                 ids.update({
                     'local_index': "[syn_idx]",
                     'semiglobal_index': '[post_rank]',
                     'global_index': '[0]',
-                    'float_prec': Global.config['precision'],
+                    'float_prec': get_global_config('precision'),
                     'pre_index': '[row_idx[syn_idx]]',
                     'post_index': '[post_rank]',
                 })
             else:
                 ids.update({
                     'local_index': "[syn_idx]"
                 })
@@ -663,45 +666,45 @@
             if proj._storage_order == "post_to_pre":
                 pass
             else:
                 pass
 
         else:
             # just a reminder to check indices for new formats
-            raise Global.CodeGeneratorException("\tno indices defined for spiking psp_template and storage_format = "+ proj._storage_format)
+            raise Messages.CodeGeneratorException("\tno indices defined for spiking psp_template and storage_format = "+ proj._storage_format)
 
         #
         # All statements in the 'pre_spike' field of synapse description
         #
         for var in proj.synapse_type.description['pre_spike']:
             if var['name'] == "g_target":   # synaptic transmission
                 # compute psp
                 psp_code += "%(float_prec)s tmp = %(psp)s\n" % {
                     'psp': var['cpp'].split('=')[1] % ids,
-                    'float_prec': Global.config['precision']
+                    'float_prec': get_global_config('precision')
                 }
                 # Operation (g_target is replaced by sum in 'cpp')
                 operation = re.search(r'sum (.*?)=', var['cpp']).group(1).strip() + "="
                 if operation == "+=":
                     ids.update({'atomicOp': "atomicAdd"})
                 elif operation == "-=":
                     ids.update({'atomicOp': "atomicSub"})
                 elif operation == "=":
                     ids.update({'atomicOp': "atomicExch"})
                 else:
-                    Global._error("The operator '"+operation+"' is not supported in psp-statements on CUDA devices yet.")
+                    Messages._error("The operator '"+operation+"' is not supported in psp-statements on CUDA devices yet.")
 
                 # apply to all targets
                 target_list = proj.target if isinstance(proj.target, list) else [proj.target]
                 for target in sorted(list(set(target_list))):
                     # multiple targets
                     ids['target'] = target
 
                     # Check for special cases
-                    if ids['atomicOp'] == "atomicExch" and Global._check_precision("double"):
+                    if ids['atomicOp'] == "atomicExch" and _check_precision("double"):
                         # HD (12th April 2023): atomicExch is not defined for double, so we need to use the long long type-cast version
                         psp_code += "atomicExch((unsigned long long int*)&g_%(target)s%(post_index)s, __double_as_longlong(tmp));\n" % ids
                     else:
                         psp_code += "%(atomicOp)s(&g_%(target)s%(post_index)s, tmp);\n" % ids
 
                     # Boundary code is optional
                     bound_code = get_bounds(var)
@@ -825,15 +828,15 @@
         targets_call = ""
         targets_invoke = ""
         targets_header = ""
         target_list = proj.target if isinstance(proj.target, list) else [proj.target]
         for target in target_list:
             targets_call += ", pop%(id_post)s.gpu_g_"+target
             targets_invoke += ", g_"+target
-            targets_header += (", %(float_prec)s* g_"+target) % {'float_prec': Global.config['precision']}
+            targets_header += (", %(float_prec)s* g_"+target) % {'float_prec': get_global_config('precision')}
 
         # Construct code for event-driven transmission
         #
         if len(pre_spike_code) == 0 and len(psp_code) == 0:
             # no event-driven component detected
             device_kernel = ""
             invoke_kernel = ""
@@ -877,37 +880,37 @@
             else:
                 pre_spike_events = "pop%(id_pre)s.gpu_spiked" % {'id_pre': proj.pre.id}
                 pre_spike_count = "pop%(id_pre)s.spike_count" % {'id_pre': proj.pre.id}
 
             # Finalize event-driven part
             device_kernel = template['device_kernel'] % {
                 'id_proj': proj.id,
-                'float_prec': Global.config['precision'],
+                'float_prec': get_global_config('precision'),
                 'conn_args_header': conn_args_header + targets_header,
                 'kernel_args_header': kernel_args_header,
                 'event_driven': tabify(event_driven_code % ids, 2),
                 'psp': tabify(psp_code, 3),
                 'pre_event': tabify(pre_spike_code % ids, 3),
                 'pre_size': pre_size,
                 'post_size': post_size,
                 'target': target_list[0]  # only for dense!
             }
             invoke_kernel = template['invoke_kernel'] % {
                 'id_proj': proj.id,
-                'float_prec': Global.config['precision'],
+                'float_prec': get_global_config('precision'),
                 'conn_args_header': conn_args_header + targets_header,
                 'conn_args_invoke': conn_args_invoke + targets_invoke,
                 'kernel_args_header': kernel_args_header,
                 'kernel_args_invoke': kernel_args_invoke,
                 'pre_spike_events': pre_spike_events.replace("pop"+str(proj.pre.id)+".gpu_", ""),
                 'pre_spike_count': pre_spike_count.replace("pop"+str(proj.pre.id)+".", ""),
             }
             kernel_decl = template['kernel_decl'] % {
                 'id_proj': proj.id,
-                'float_prec': Global.config['precision'],
+                'float_prec': get_global_config('precision'),
                 'conn_args_header': conn_args_header + targets_header,
                 'kernel_args_header': kernel_args_header
             }
             host_call = template['host_call'] % {
                 'id_proj': proj.id,
                 'id_pre': proj.pre.id,
                 'id_post': proj.post.id,
@@ -958,38 +961,38 @@
             host_call += template['host_call'] % {
                 'id_proj': proj.id,
                 'id_pre': proj.pre.id,
                 'id_post': proj.post.id,
                 'target_arg': targets_call % {'id_post': proj.post.id},
                 'target': proj.target,
                 'kernel_args': kernel_args_call,
-                'float_prec': Global.config['precision']
+                'float_prec': get_global_config('precision')
             }
             device_kernel += template['device_kernel'] % {
                 'id_proj': proj.id,
                 'target_arg': target_list[0],
                 'kernel_args': kernel_args_header,
                 'psp': psp_code,
                 'pre_code': tabify(pre_spike_code % ids, 3),
-                'float_prec': Global.config['precision']
+                'float_prec': get_global_config('precision')
             }
             invoke_kernel += template['invoke_kernel'] % {
                 'id_proj': proj.id,
                 'target_arg': proj.target,
                 'kernel_args': kernel_args_header,
                 'kernel_args_invoke': kernel_args_invoke,
                 'target_arg': targets_header,
                 'target_arg_invoke': targets_invoke,
-                'float_prec': Global.config['precision']
+                'float_prec': get_global_config('precision')
             }
             kernel_decl += template['kernel_decl'] % {
                 'id_proj': proj.id,
                 'kernel_args': kernel_args_header,
                 'target_arg': targets_header,
-                'float_prec': Global.config['precision']
+                'float_prec': get_global_config('precision')
             }
 
         # Annotate code
         if self._prof_gen:
             host_call = self._prof_gen.annotate_computesum_spiking(proj, host_call)
 
         return device_kernel, invoke_kernel, kernel_decl, host_call
@@ -1163,15 +1166,15 @@
             kernel_args_decl = ", long int* pre_last_spike, long int* post_last_spike" + kernel_args_decl
             kernel_args_invoke = ", pre_last_spike, post_last_spike" + kernel_args_invoke
             kernel_args_call = ", pop%(id_pre)s.gpu_last_spike, pop%(id_post)s.gpu_last_spike" % {'id_pre': proj.pre.id, 'id_post': proj.post.id} + kernel_args_call
 
         return kernel_args_decl, kernel_args_invoke, kernel_args_call
 
     def _header_structural_plasticity(self, proj):
-        Global._error("Structural Plasticity is not supported on GPUs yet.")
+        Messages._error("Structural Plasticity is not supported on GPUs yet.")
 
     def _local_functions(self, proj):
         """
         Definition of user-defined local functions attached to
         a neuron. These functions will take place in the
         ANNarchyDevice.cu file.
 
@@ -1189,20 +1192,20 @@
         host_code = ""
         device_code = ""
         for func in proj.synapse_type.description['functions']:
             cpp_func = func['cpp'] + '\n'
 
             host_code += cpp_func
             # TODO: improve code
-            if (Global.config["precision"]=="float"):
+            if _check_precision('float'):
                 device_code += cpp_func.replace('float' + func['name'], '__device__ float proj%(id)s_%(func)s' % {'id': proj.id, 'func': func['name']})
             else:
                 device_code += cpp_func.replace('double '+ func['name'], '__device__ double proj%(id)s_%(func)s' % {'id': proj.id, 'func':func['name']})
 
-        return host_code, check_and_apply_pow_fix(device_code)
+        return host_code, check_and_apply_pow_fix(device_code, self._cuda_version)
 
     def _replace_local_funcs(self, proj, glob_eqs, semiglobal_eqs, loc_eqs):
         """
         As the local functions can be occur repeatadly in the same file,
         there are modified with proj[id]_ to unique them. Now we need
         to adjust the call accordingly.
         """
@@ -1225,15 +1228,15 @@
 
     def _replace_random(self, loc_eqs, loc_idx, glob_eqs, random_distributions):
         """
         This method replace the variables rand_%(id)s in the parsed equations
         by the corresponding curand... term.
         """
         # double precision methods have a postfix
-        prec_extension = "" if Global.config['precision'] == "float" else "_double"
+        prec_extension = "" if _check_precision('float') else "_double"
 
         loc_pre = ""
         semi_pre = ""
         glob_pre = ""
 
         for dist in random_distributions:
             print(dist)
@@ -1245,15 +1248,15 @@
                     'min': dist['args'].split(',')[0],
                     'max': dist['args'].split(',')[1],
                     'local_index': loc_idx
                 }
 
                 if dist["locality"] == "local":
                     term = """( curand_uniform%(postfix)s( &state_%(rd)s%(local_index)s ) * (%(max)s - %(min)s) + %(min)s )""" % dist_ids
-                    loc_pre += "%(prec)s %(name)s = %(term)s;" % {'prec': Global.config['precision'], 'name': dist['name'], 'term': term}
+                    loc_pre += "%(prec)s %(name)s = %(term)s;" % {'prec': get_global_config('precision'), 'name': dist['name'], 'term': term}
 
                     # suppress local index
                     loc_eqs = loc_eqs.replace(dist['name']+loc_idx, dist['name'])
                 else:
                     # HD (17th May 2021): this path can not be reached as the parser rejects equations like:
                     # dw/dt = -w * Uniform(0,.1) : init=1, midpoint
                     raise NotImplementedError
@@ -1263,15 +1266,15 @@
                     'postfix': prec_extension, 'rd': dist['name'],
                     'mean': dist['args'].split(",")[0],
                     'sigma': dist['args'].split(",")[1]
                 }
 
                 if dist["locality"] == "local":
                     term = """( curand_normal%(postfix)s( &state_%(rd)s[j] ) * %(sigma)s + %(mean)s )""" % dist_ids
-                    loc_pre += "%(prec)s %(name)s = %(term)s;" % {'prec': Global.config['precision'], 'name': dist['name'], 'term': term}
+                    loc_pre += "%(prec)s %(name)s = %(term)s;" % {'prec': get_global_config('precision'), 'name': dist['name'], 'term': term}
 
                     # suppress local index
                     loc_eqs = loc_eqs.replace(dist['name']+"[j]", dist['name'])
                 else:
                     # HD (17th May 2021): this path can not be reached as the parser rejects equations like:
                     # dw/dt = -w * Uniform(0,.1) : init=1, midpoint
                     raise NotImplementedError
@@ -1281,25 +1284,25 @@
                     'postfix': prec_extension, 'rd': dist['name'],
                     'mean': dist['args'].split(',')[0],
                     'std_dev': dist['args'].split(',')[1]
                 }
 
                 if dist["locality"] == "local":
                     term = """( curand_log_normal%(postfix)s( &state_%(rd)s[j], %(mean)s, %(std_dev)s) )""" % dist_ids
-                    loc_pre += "%(prec)s %(name)s = %(term)s;" % {'prec': Global.config['precision'], 'name': dist['name'], 'term': term}
+                    loc_pre += "%(prec)s %(name)s = %(term)s;" % {'prec': get_global_config('precision'), 'name': dist['name'], 'term': term}
 
                     # suppress local index
                     loc_eqs = loc_eqs.replace(dist['name']+"[j]", dist['name'])
                 else:
                     # HD (17th May 2021): this path can not be reached as the parser rejects equations like:
                     # dw/dt = -w * Uniform(0,.1) : init=1, midpoint
                     raise NotImplementedError
 
             else:
-                Global._error("Unsupported random distribution on GPUs: " + dist['dist'])
+                Messages._error("Unsupported random distribution on GPUs: " + dist['dist'])
 
         # check which equation blocks we need to extend
         if len(loc_pre) > 0:
             loc_eqs = tabify(loc_pre, 2) + "\n" + loc_eqs
         if len(glob_pre) > 0:
             glob_eqs = tabify(glob_pre, 1) + "\n" + glob_eqs
 
@@ -1411,40 +1414,40 @@
                 add_args_call += ', pop%(id)s.gpu_%(name)s' % attr_ids
 
         # select code template
         try:
             templates = self._templates['post_event']
 
         except KeyError:
-            raise Global._error("No CUDA code template for post_event ( format =", proj._storage_format, " and order =", proj._storage_order,")")
+            raise Messages._erroror("No CUDA code template for post_event ( format =", proj._storage_format, " and order =", proj._storage_order,")")
 
         # Fill code templates
         postevent_body = templates['device_kernel'] % {
             'id_proj': proj.id,
             'conn_args': self._templates['conn_header'] % ids,
             'add_args': add_args_header,
             'event_driven': tabify(event_driven_code % ids, 2),
             'post_code': tabify(post_code % ids, 2),
-            'float_prec': Global.config['precision'],
+            'float_prec': get_global_config('precision'),
         }
 
         postevent_invoke = templates['invoke_kernel'] % {
             'id_proj': proj.id,
             'conn_args': self._templates['conn_header'] % ids,
             'conn_args_invoke': self._templates['conn_kernel'],
             'add_args': add_args_header,
             'add_args_invoke': add_args_invoke,
-            'float_prec': Global.config['precision']
+            'float_prec': get_global_config('precision')
         }
 
         postevent_header = templates['kernel_decl'] % {
             'id_proj': proj.id,
             'conn_args': self._templates['conn_header']% ids,
             'add_args': add_args_header,
-            'float_prec': Global.config['precision']
+            'float_prec': get_global_config('precision')
         }
 
         postevent_call = templates['host_call'] % {
             'id_proj': proj.id,
             'id_pre': proj.pre.id,
             'id_post': proj.post.id,
             'target': proj.target[0] if isinstance(proj.target, list) else proj.target,
@@ -1555,15 +1558,15 @@
         rk_assign = tabify(rk_assign, 2 if proj._storage_format == "csr" else 3)
 
         # Gather pre-loop declaration (dt/tau for ODEs)
         pre_loop = ""
         for var in proj.synapse_type.description['variables']:
             if var['locality'] == locality:
                 if 'pre_loop' in var.keys() and len(var['pre_loop']) > 0:
-                    pre_loop += Global.config['precision'] + ' ' + var['pre_loop']['name'] + ' = ' + var['pre_loop']['value'] + ';\n'
+                    pre_loop += get_global_config('precision') + ' ' + var['pre_loop']['name'] + ' = ' + var['pre_loop']['value'] + ';\n'
             else:
                 continue
 
         # Global parameters have no index
         for syn_dep in syn_deps:
             attr_type, attr_dict = self._get_attr_and_type(proj, syn_dep)
 
@@ -1618,15 +1621,15 @@
         idx_type, _, size_type, _ = determine_idx_type_for_projection(proj)
 
         # some commonly needed ids
         ids.update({
             'id_proj': proj.id,
             'id_pre': proj.pre.id,
             'id_post': proj.post.id,
-            'float_prec': Global.config['precision'],
+            'float_prec': get_global_config('precision'),
             'idx_type': idx_type,
             'size_type': size_type
         })
 
         # generate the code
         device_kernel = ""
         invoke_kernel = ""
@@ -1761,15 +1764,15 @@
             'id_proj': proj.id,
             'post': proj.post.id,
             'pre': proj.pre.id,
             'target': proj.target[0] if isinstance(proj.target, list) else proj.target,
             'global_call': global_call,
             'semiglobal_call': semiglobal_call,
             'local_call': local_call,
-            'float_prec': Global.config['precision']
+            'float_prec': get_global_config('precision')
         }
 
         # Profiling
         if self._prof_gen:
             call = self._prof_gen.annotate_update_synapse(proj, call)
 
         return device_kernel, invoke_kernel, kernel_header, call
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/BSR.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/BSR.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/BaseTemplates.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/BaseTemplates.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/COO.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/COO.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/CSR.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/CSR.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/CSR_P.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/CSR_P.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/CSR_T.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/CSR_T.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/CSR_T_P.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/CSR_T_P.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/Dense.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/Dense.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/Dense_T.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/Dense_PV.py`

 * *Files 12% similar despite different names*

```diff
@@ -22,14 +22,16 @@
 }
 
 attribute_cpp_init = {
     'local':
 """
         // Local %(attr_type)s %(name)s
         %(name)s = init_matrix_variable<%(type)s>(static_cast<%(type)s>(%(init)s));
+        if(%(name)s.empty())
+            return false;
 """,
     'semiglobal':
 """
         // Semiglobal %(attr_type)s %(name)s
         %(name)s = init_vector_variable<%(type)s>(static_cast<%(type)s>(%(init)s));
 """,
     'global':
@@ -95,35 +97,26 @@
         return proj%(id_proj)s.delay
     def set_delay(self, value):
         proj%(id_proj)s.delay = value
 """
     }
 }
 
-spiking_summation_fixed_delay_outer_loop = """// Event-based summation
-if (_transmission && %(post_prefix)s_active) {
-    const int mat_slice_beg_ = mat_slices_[tid];
-    const int mat_slice_end_ = mat_slices_[tid+1];
-#ifdef _DEBUG
-    #pragma omp critical
-    {
-        std::cout << "thread " << tid << ": " << mat_slice_beg_ << " - " << mat_slice_end_ << std::endl;
-    }
-#endif
+spiking_summation_fixed_delay = """// Event-based summation
+if (_transmission && %(post_prefix)s_active){
+
+    for (%(idx_type)s rk_post = 0; rk_post < num_rows(); rk_post++) {
+        // Iterate over all spiking neurons
+        for (auto it = %(pre_prefix)sspiked.cbegin(); it != %(pre_prefix)sspiked.cend(); it++) {
+            %(idx_type)s rk_pre = (*it);
+            if ((rk_pre < this->low_column_rank_) || (rk_pre >= this->high_column_rank_))
+                continue;
+
+            %(size_type)s j = rk_post*this->num_columns_ + *it;
 
-    // Iterate over all spiking neurons
-    for (auto it = %(pre_prefix)sspiked.cbegin(); it != %(pre_prefix)sspiked.cend(); it++) {
-        %(idx_type)s rk_pre = (*it);
-        %(size_type)s beg = rk_pre * this->num_rows_;
-        %(size_type)s end = (rk_pre+1) * this->num_rows_;
-
-        // Iterate over columns
-        for (%(idx_type)s rk_post = mat_slice_beg_; rk_post < mat_slice_end_; rk_post++) {
-            %(size_type)s j = beg + rk_post;
-            
             %(g_target)s
 
             if (mask_[j]) {
                 %(event_driven)s
                 %(pre_event)s
             }
         }
@@ -136,24 +129,21 @@
     'attribute_decl': attribute_decl,
     'attribute_cpp_init': attribute_cpp_init,
     'attribute_cpp_size': attribute_cpp_size,
     'attribute_cpp_delete': attribute_cpp_delete,
     'delay': delay,
 
     #operations
-    'rate_coded_sum': "",
-    'vectorized_default_psp': {},
-    'spiking_sum_fixed_delay': {
-        'inner_loop': None,
-        'outer_loop': spiking_summation_fixed_delay_outer_loop
-    },
-    'update_variables': "",
+    'rate_coded_sum': None,
+    'vectorized_default_psp': None,
+    'spiking_sum_fixed_delay': spiking_summation_fixed_delay,
+    'update_variables': None,
 }
 
 conn_ids = {
     'local_index': '[j]',
-    'semiglobal_index': '[i]',
+    'semiglobal_index': '[rk_post]',
     'global_index': '',
     'post_index': '[rk_post]',
     'pre_index': '[rk_pre]',
     'delay_u' : '[delay-1]' # uniform delay
-}
+}
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/ELL.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/ELL.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/ELLR.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/ELLR.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/LIL.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/LIL.py`

 * *Files 3% similar despite different names*

```diff
@@ -1194,15 +1194,16 @@
             if(pre_rank[post][i] == pre){
                 idx = i;
                 break;
             }
         }
         return idx;
     }
-    void addSynapse(int post, int pre, double weight, int _delay=0%(extra_args)s){
+%(inverse_connectivity_rebuild)s
+    void addSynapse(int post, int pre, double weight, int _delay=0%(extra_args)s) {
         // Find where to put the synapse
         int idx = pre_rank[post].size();
         for(int i=0; i<pre_rank[post].size(); i++){
             if(pre_rank[post][i] > pre){
                 idx = i;
                 break;
             }
@@ -1214,17 +1215,20 @@
 
         // Update additional fields
 %(delay_code)s
 %(add_code)s
 %(spike_add)s
 %(rd_add)s
     };
-    void removeSynapse(int post, int idx){
+    void removeSynapse(int post, int idx) {
+        // Update connectivty
         pre_rank[post].erase(pre_rank[post].begin() + idx);
         w[post].erase(w[post].begin() + idx);
+
+        // Update additional fields
 %(delay_remove)s
 %(add_remove)s
 %(spike_remove)s
 %(rd_remove)s
     };
 """,
         'pruning': """
@@ -1244,25 +1248,46 @@
         int idx_post = 0;
         for(int i=0; i<post_rank.size(); i++){
             if(post_rank[i] == post){
                 idx_post = i;
                 break;
             }
         }
-        inv_pre_rank[pre].push_back(std::pair<int, int>(idx_post, idx));
+
+        // we parallelize over post, therefore it could occur that two threads access the same pre-neuron
+        #pragma omp critical
+        {
+            inv_pre_rank[pre].push_back(std::pair<int, int>(idx_post, idx));
+        }
 """,
         'spiking_removecode': """
         // Remove the corresponding pair in inv_pre_rank
         int pre = pre_rank[post][idx];
         for(int i=0; i<inv_pre_rank[pre].size(); i++){
             if(inv_pre_rank[pre][i].second == idx){
-                inv_pre_rank[pre].erase(inv_pre_rank[pre].begin() + i);
+                // we parallelize over post, therefore it could occur that two threads access the same pre-neuron
+                #pragma omp critical
+                {
+                    inv_pre_rank[pre].erase(inv_pre_rank[pre].begin() + i);
+                    _dirty_connectivity = true;
+                }
                 break;
             }
         }
+""",
+        'spiking_rebuild_backwardview': """    bool _dirty_connectivity = false;
+    void check_and_rebuild_inverse_connectivity() {
+    #ifdef _TRACE_SIMULATION_STEPS
+        std::cout << "ProjStruct::check_and_rebuild_inverse_connectivity() called at time t = " << t / dt << " ms." << std::endl;
+    #endif
+        if (this->_dirty_connectivity) {
+            inverse_connectivity_matrix();
+            _dirty_connectivity = false;
+        }
+    }
 """
     },
     'pyx_struct': {
         'pruning':
 """
         # Pruning
         bool _pruning
@@ -1318,14 +1343,20 @@
     },
 
     # Structural plasticity during the simulate() call
     'create': """
     // proj%(id_proj)s creating: %(eq)s
     void creating() {
         if((_creating)&&((t - _creating_offset) %% _creating_period == 0)){
+        #ifdef _TRACE_SIMULATION_STEPS
+            #pragma omp master
+            {
+            std::cout << "ProjStruct%(id_proj)s::creating() executed at time t = " << t / dt << " ms." << std::endl;
+            }
+        #endif
             %(proba_init)s
 
             #pragma omp for
             for(int i = 0; i < post_rank.size(); i++){
                 int rk_post = post_rank[i];
                 for(int rk_pre = 0; rk_pre < %(pre_prefix)ssize; rk_pre++){
                     if(%(condition)s){
@@ -1348,23 +1379,28 @@
         }
     }
 """,
     'prune': """
     // proj%(id_proj)s pruning: %(eq)s
     void pruning() {
         if((_pruning)&&((t - _pruning_offset) %% _pruning_period == 0)){
+        #ifdef _TRACE_SIMULATION_STEPS
+            std::cout << "ProjStruct%(id_proj)s::pruning() executed at time t = " << t / dt << " ms." << std::endl;
+        #endif
             %(proba_init)s
 
             #pragma omp for
             for(int i = 0; i < post_rank.size(); i++){
                 int rk_post = post_rank[i];
-                for(int j = 0; j < pre_rank[i].size(); j++){
+                for(int j = 0; j < pre_rank[i].size();){
                     int rk_pre = pre_rank[i][j];
                     if((%(condition)s)%(proba)s){
                         removeSynapse(i, j);
+                    }else{
+                        ++j;
                     }
                 }
             }
         }
     }
 """
 }
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/LIL_P.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/LIL_P.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/SELL.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/SELL.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMP/__init__.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -24,14 +24,15 @@
         * CSR_T: compressed sparse row (transposed)
         * Dense_T: dense (transposed)
         * LIL_P: a partitioned LIL representation
 """
 from . import LIL as LIL_OpenMP
 from . import LIL_P as LIL_Sliced_OpenMP
 from . import COO as COO_OpenMP
+from . import DIA as DIA_OpenMP
 from . import BSR as BSR_OpenMP
 from . import CSR as CSR_OpenMP
 from . import CSR_P as CSR_Sliced_OpenMP
 from . import CSR_T as CSR_T_OpenMP
 from . import CSR_T_P as CSR_T_Sliced_OpenMP
 from . import ELL as ELL_OpenMP
 from . import ELLR as ELLR_OpenMP
@@ -40,13 +41,14 @@
 from . import Dense_T as Dense_T_OpenMP
 
 __all__ = [
     "BaseTemplates",
     "LIL_OpenMP", "LIL_Sliced_OpenMP",
     "BSR_OpenMP",
     "COO_OpenMP",
+    "DIA_OpenMP",
     "CSR_OpenMP", "CSR_Sliced_OpenMP", "CSR_T_OpenMP", "CSR_T_Sliced_OpenMP",
     "ELL_OpenMP",
     "ELLR_OpenMP",
     "SELL_OpenMP",
     "Dense_OpenMP", "Dense_T_OpenMP"
 ]
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/OpenMPGenerator.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMPGenerator.py`

 * *Files 3% similar despite different names*

```diff
@@ -5,14 +5,16 @@
 
 import ANNarchy
 
 # ANNarchy objects
 from ANNarchy.core import Global
 from ANNarchy.core.PopulationView import PopulationView
 from ANNarchy.models.Synapses import DefaultRateCodedSynapse
+from ANNarchy.intern.ConfigManagement import get_global_config, _check_precision
+from ANNarchy.intern import Messages
 
 # Code templates
 from ANNarchy.generator.Projection.ProjectionGenerator import ProjectionGenerator, get_bounds
 from ANNarchy.generator.Projection.OpenMP import *
 
 # Useful functions
 from ANNarchy.generator.Utils import generate_equation_code, tabify, remove_trailing_spaces, check_avx_instructions, determine_idx_type_for_projection
@@ -86,15 +88,15 @@
         if has_delay:
             update_max_delay, reset_ring_buffer = self._update_max_delay(proj)
         else:
             update_max_delay = ""
             reset_ring_buffer = ""
 
         # Some Connectivity implementations requires the number of threads in constructor
-        if Global.config['num_threads'] > 1:
+        if get_global_config('num_threads') > 1:
             if proj._storage_format == "lil":
                 if single_matrix or proj._no_split_matrix:
                     num_threads_acc = ""
                 else:
                     num_threads_acc = ", global_num_threads"
             elif proj._storage_format == "csr":
                 if proj._no_split_matrix or single_matrix:
@@ -111,15 +113,15 @@
             connector_call = self._connectivity_init(proj, sparse_matrix_format, sparse_matrix_args) % {
                 'sparse_format': sparse_matrix_format,
                 'init_weights': init_weights,
                 'init_delays': init_delays,
                 'rng_idx': "[0]" if single_matrix else "",
                 'add_args': "",
                 'num_threads': num_threads_acc,
-                'float_prec': Global.config["precision"],
+                'float_prec': get_global_config('precision'),
                 'idx_type': self._template_ids['idx_type']
             }
             declare_connectivity_matrix = ""
             access_connectivity_matrix = ""
         else:
             sparse_matrix_format = "SpecificConnectivity"
             sparse_matrix_args = ""
@@ -150,21 +152,21 @@
 
         # Sparse matrix format specific
         # HD (20th May 2022): this is probably not the best way to do it ...
         declare_additional=decl['additional']
         init_additional = ""
         if proj._storage_format == "dense" and proj._storage_order == "pre_to_post":
             declare_additional += """\t// dense matrix - static schedule
-    std::vector<int> mat_slices_;
+    std::vector<int> post_slices_;
         """
             init_additional += """\t// static distribution across threads
-    int chunk_size = static_cast<int>(ceil(static_cast<double>(this->num_rows_) / static_cast<double>(global_num_threads)));
-    mat_slices_ = std::vector<int>(1, 0);
-    for (int t = 1; t <= global_num_threads; t++)
-        mat_slices_.push_back(std::min<int>(t*chunk_size, this->num_rows_));
+        int chunk_size = static_cast<int>(ceil(static_cast<double>(this->num_rows_) / static_cast<double>(global_num_threads)));
+        post_slices_ = std::vector<int>(1, 0);
+        for (int t = 1; t <= global_num_threads; t++)
+            post_slices_.push_back(std::min<int>(t*chunk_size, this->num_rows_));
 """
 
         # Additional info (overwritten)
         include_additional = ""
         struct_additional = ""
         access_additional = ""
         if 'include_additional' in proj._specific_template.keys():
@@ -215,15 +217,15 @@
             'post_event': post_event,
             'access_parameters_variables': accessor,
             'access_additional': access_additional,
             'size_in_bytes': size_in_bytes,
             'clear_container': clear_container,
             'sparse_format': sparse_matrix_format,
             'sparse_format_args': sparse_matrix_args,
-            'float_prec': Global.config['precision'],
+            'float_prec': get_global_config('precision'),
             'creating': creating,
             'pruning': pruning
         }
 
         final_code = self._templates['projection_header'] % final_code_dict
 
         # remove right-trailing white spaces
@@ -260,15 +262,15 @@
         idx_type, _, size_type, _ = determine_idx_type_for_projection(proj)
 
         self._template_ids.update({
             'id_proj' : proj.id,
             'target': proj.target,
             'id_post': proj.post.id,
             'id_pre': proj.pre.id,
-            'float_prec': Global.config["precision"],
+            'float_prec': get_global_config('precision'),
             'pre_prefix': 'pop'+ str(proj.pre.id) + '.',
             'post_prefix': 'pop'+ str(proj.post.id) + '.',
             'idx_type': idx_type,
             'size_type': size_type
         })
 
         if proj._storage_format == "lil":
@@ -331,14 +333,27 @@
             if proj.synapse_type.type == "rate":
                 # Rate-coded models coordinate format
                 if single_matrix:
                     self._templates.update(COO_OpenMP.conn_templates)
                     self._template_ids.update(COO_OpenMP.conn_ids)
                 else:
                     raise NotImplementedError
+            else:
+                raise NotImplementedError
+
+        elif proj._storage_format == "dia":
+            if proj.synapse_type.type == "rate":
+                # Rate-coded models coordinate format
+                if single_matrix:
+                    self._templates.update(DIA_OpenMP.conn_templates)
+                    self._template_ids.update(DIA_OpenMP.conn_ids)
+                else:
+                    raise NotImplementedError
+            else:
+                raise NotImplementedError
 
         elif proj._storage_format == "ellr":
             if proj.synapse_type.type == "rate":
                 # Rate-coded models ELLPACK-R format
                 if single_matrix:
                     self._templates.update(ELLR_OpenMP.conn_templates)
                     self._template_ids.update(ELLR_OpenMP.conn_ids)
@@ -406,23 +421,23 @@
             proba_init += "std::uniform_real_distribution<double> unif(0.0, 1.0);"
         if  creating_structure['rd']:
             proba_init += "\n        " +  creating_structure['rd']['template'] + ' rd(' + creating_structure['rd']['args'] + ');'
 
         # delays
         delay = ""
         if 'd' in creating_structure['bounds'].keys():
-            d = int(creating_structure['bounds']['delay']/Global.config['dt'])
+            d = int(creating_structure['bounds']['delay']/get_global_config('dt'))
             if proj.max_delay > 1 and proj.uniform_delay == -1:
                 if d > proj.max_delay:
-                    Global._error('creating: you can not add a delay higher than the maximum of existing delays')
+                    Messages._error('creating: you can not add a delay higher than the maximum of existing delays')
 
                 delay = ", " + str(d)
             else:
                 if d != proj.uniform_delay:
-                    Global._error('creating: you can not add a delay different from the others if they were constant.')
+                    Messages._error('creating: you can not add a delay different from the others if they were constant.')
 
         creation_ids = deepcopy(self._template_ids)
         creation_ids.update({
             'pre_index': '[rk_pre]',
             'post_index': '[rk_post]'
         })
         creating_condition = creating_structure['cpp'] % creation_ids
@@ -527,42 +542,42 @@
 
                     # the access to pre-synaptic firing depends on the delay
                     if proj.max_delay <= 1:
                         # no synaptic delay
                         ids.update({
                             'get_r': ids['pre_prefix']+"r.data()"
                         })
-                        psp_code = template["sum"][Global.config["precision"]] % ids
+                        psp_code = template["sum"][get_global_config('precision')] % ids
 
                         if self._prof_gen:
                             psp_code = self._prof_gen.annotate_computesum_rate(proj, psp_code)
 
                         return "", psp_code
 
                     elif proj.uniform_delay != -1 and proj.max_delay > 1:
                         # Uniform delay
                         ids.update({
                             'get_r': ids['pre_prefix']+"_delayed_r[delay-1].data()",
                         })
-                        psp_code = template["sum"][Global.config["precision"]] % ids
+                        psp_code = template["sum"][get_global_config('precision')] % ids
 
                         if self._prof_gen:
                             psp_code = self._prof_gen.annotate_computesum_rate(proj, psp_code)
 
                         return "", psp_code
 
                     else:
                         # HD (3rd June 2021): for non-uniform delays I doubt that it's worth the effort, so we proceed with
                         #                     general code generation
                         pass
 
                 except KeyError:
                     # No fitting code found, so we fall back to normal code generation
                     # TODO: add internal error log, which key was missing?
-                    Global._debug("No SIMD implementation found, fallback to non-SIMD code")
+                    Messages._debug("No SIMD implementation found, fallback to non-SIMD code")
                     template = ""
 
             else:
                 # Other optimizations like loop unroll etc?
                 if proj._storage_format == "bsr":
                     try:
                         # not yet implemented
@@ -576,15 +591,15 @@
                             blockDim = determine_bsr_blocksize(proj.pre.population.size if isinstance(proj.pre, PopulationView) else proj.pre.size, proj.post.population.size if isinstance(proj.post, PopulationView) else proj.post.size)
 
                         # Loop unroll depends on the block-size
                         unrolled_template = template = self._templates["unrolled_default_psp"][blockDim]
 
                         # Check if we implemented a SIMD version
                         if simd_type in unrolled_template.keys():
-                            template = unrolled_template[simd_type]['multi_w']['sum'][Global.config["precision"]]
+                            template = unrolled_template[simd_type]['multi_w']['sum'][get_global_config('precision')]
                         else:
                             template = unrolled_template['none']['multi_w']["sum"]
 
                         # the access to pre-synaptic firing depends on the delay
                         if proj.max_delay <= 1:
                             # no synaptic delay
                             ids.update({
@@ -602,22 +617,22 @@
                             #                     experimental feature. I will implement the delay case if we
                             #                     are sure that we really use this.
                             pass
 
                     except KeyError:
                         # No fitting code found, so we fall back to normal code generation
                         # TODO: add internal error log, which key was missing?
-                        Global._debug("No SIMD implementation found, fallback to non-SIMD code")
+                        Messages._debug("No SIMD implementation found, fallback to non-SIMD code")
                         template = ""
 
         # Choose the relevant summation template
         try:
             template = self._templates['rate_coded_sum']
         except:
-            Global._error("OpenMPGenerator: no template for storage_format = "+proj._storage_format+" configuration available")
+            Messages._error("OpenMPGenerator: no template for storage_format = "+proj._storage_format+" configuration available")
 
         # Dictionary of keywords to transform the parsed equations
         ids = self._template_ids
 
         # Dependencies
         dependencies = list(set(proj.synapse_type.description['dependencies']['pre']))
 
@@ -652,16 +667,16 @@
                 for var in delayed_variables:
                     if var in proj.pre.neuron_type.description['local']:
                         psp = psp.replace(
                             '%(pre_prefix)s'+var+'%(pre_index)s',
                             '%(pre_prefix)s_delayed_'+var+'%(delay_nu)s%(pre_index)s'
                         )
                     else:
-                        Global._print(proj.synapse_type.description['psp']['eq'])
-                        Global._error('The psp accesses a global variable with a non-uniform delay!')
+                        Messages._print(proj.synapse_type.description['psp']['eq'])
+                        Messages._error('The psp accesses a global variable with a non-uniform delay!')
 
 
             else: # Uniform delays
                 for var in delayed_variables:
                     if var in proj.pre.neuron_type.description['local']:
                         psp = psp.replace(
                             '%(pre_prefix)s'+var+'%(pre_index)s',
@@ -687,23 +702,27 @@
                     pre_copy += "std::vector<%(float_prec)s> _pre_" + var + " = %(pre_prefix)s_delayed_" + var + "%(delay_u)s;"
                     psp = psp.replace(
                         '%(pre_prefix)s_delayed_'+var+'%(delay_u)s%(pre_index)s',
                         '_pre_'+var+'%(pre_index)s'
                     )
                     first_privates += '_pre_%(var)s, ' % {'var': var}
 
+        # Special case for diagonal format
+        if proj._storage_format == "dia":
+            ids.update({'omp_simd': '#pragma omp for' if get_global_config('disable_SIMD_SpMV') else '#pragma omp for simd'})
+
         # Finalize the psp with the correct ids
         psp = psp % ids
         pre_copy = pre_copy % ids
 
         ids.update({
             'pre_copy': pre_copy,
             'schedule': schedule,
             'psp': psp.replace(';', ''),
-            'simd_len': str(4) if Global.config['precision']=="double" else str(8),
+            'simd_len': str(4) if _check_precision('double') else str(8),
         })
         # Generate the code depending on the operation
         sum_code = template[proj.synapse_type.operation] % ids
 
         # Default variables needed in psp_code
         if proj._storage_format == "lil":
             psp_prefix = """
@@ -717,17 +736,18 @@
             psp_prefix = ""
 
         # Finish the code
         final_code = """
         if (_transmission && %(post_prefix)s_active){
 %(code)s
         } // active
-        """ % {'post_prefix': ids['post_prefix'],
-               'code': tabify(sum_code, 3),
-              }
+        """ % {
+            'post_prefix': ids['post_prefix'],
+            'code': tabify(sum_code, 3),
+        }
 
         if self._prof_gen:
             final_code = self._prof_gen.annotate_computesum_rate(proj, final_code)
 
         return psp_prefix, final_code
 
     def _computesum_spiking(self, proj, single_matrix):
@@ -785,15 +805,15 @@
         # Basic tags, dependent on storage format are assuming a feedforward
         # transmission.
         ids = deepcopy(self._template_ids)
 
         # The psp kernel sometimes use diverging indices
         # HD (10th April 2022): maybe I should remove this in future (TODO)
         if proj._storage_format == "lil":
-            if Global.config['num_threads'] == 1 or single_matrix:
+            if get_global_config('num_threads') == 1 or single_matrix:
                 ids.update({
                     'pre_index': '[rk_j]',
                 })
             else:
                 ids.update({
                     'pre_index': '[rk_j]',
                 })
@@ -894,15 +914,15 @@
 
                     # access to post variable migth require atomic
                     # operation ( added later if needed )
                     if proj.max_delay > 1 and proj.uniform_delay == -1: # TODO: openMP is switched off for non uniform delays
                         g_target_code += """
             %(post_prefix)sg_%(target)s%(post_index)s %(operation)s %(g_target)s
 """% target_dict
-                    elif proj.disable_omp or Global.config['num_threads'] == 1:
+                    elif proj.disable_omp or get_global_config('num_threads') == 1:
                         g_target_code += """
             %(post_prefix)sg_%(target)s%(post_index)s %(operation)s %(g_target)s
 """% target_dict
                     else:
                         raise NotImplementedError
 
                     # Determine bounds
@@ -1018,26 +1038,26 @@
                 )
 
         # Choose correct template based on connectivity
         # and take delays into account if any
         pre_array = ""
         if proj.max_delay > 1:
             if proj.uniform_delay == -1: # Non-uniform delays
-                Global._warning('Variable delays for spiking networks is experimental and slow...')
+                Messages._warning('Variable delays for spiking networks is experimental and slow...')
                 template = self._templates['spiking_sum_variable_delay']
             else: # Uniform delays
                 template = self._templates['spiking_sum_fixed_delay'][proj._parallel_pattern]
                 pre_array = "%(pre_prefix)s_delayed_spike[delay-1]" % ids
         else:
             pre_array = "%(pre_prefix)sspiked" % ids
             template = self._templates['spiking_sum_fixed_delay'][proj._parallel_pattern]
 
         # sanity check
         if template == None:
-            Global._error("Code generation error for proj%(id)s: no template available " % {'id': proj.id})
+            raise Messages.CodeGeneratorException("\tproj{}: no template available (Configuration: format={}, order={}, single_matrix={}, pattern={})".format(proj.id, proj._storage_format, proj._storage_order, single_matrix, proj._parallel_pattern))
 
         # Axonal spike events
         spiked_array_fusion_code = ""
         if proj.synapse_type.pre_axon_spike:
             spiked_array_fusion_code = """
     std::vector<int> tmp_spiked = %(pre_array)s;
     if (_axon_transmission) {
@@ -1065,15 +1085,15 @@
         ####################################################
         # Not even-driven summation of psp: like rate-coded
         ####################################################
         if 'psp' in  proj.synapse_type.description.keys(): # not event-based
             # Compute it as if it were rate-coded
             _, psp_code = self._computesum_rate(proj, single_matrix)
             
-            psp_prefix = tabify("%(float_prec)s sum; int nb_pre, nb_post;" % {'float_prec': Global.config["precision"]}, 2)
+            psp_prefix = tabify("%(float_prec)s sum; int nb_pre, nb_post;" % {'float_prec': get_global_config('precision')}, 2)
 
             # Change _sum_target into g_target (TODO: handling of PopulationViews???)
             psp_code = psp_code.replace(
                 '%(post_prefix)s_sum_%(target)s' % ids,
                 '%(post_prefix)sg_%(target)s' % ids
             )
 
@@ -1130,33 +1150,37 @@
             delay_code = ' '*8 + "delay[post].insert(delay[post].begin() + idx, _delay);"
             delay_remove = ' '*8 + "delay[post].erase(delay[post].begin() + idx);"
 
         # Spiking networks must update the inv_pre_rank array
         spiking_addcode = "" if proj.synapse_type.type == 'rate' else header_tpl['spiking_addcode']
         spiking_removecode = "" if proj.synapse_type.type == 'rate' else header_tpl['spiking_removecode']
 
-        # Randomdistributions
+        # Random distributions
         rd_addcode = ""
         rd_removecode = ""
         for rd in proj.synapse_type.description['random_distributions']:
             rd_addcode += """
         %(name)s[post].insert(%(name)s[post].begin() + idx, 0.0);
 """ % {'name': rd['name']}
 
             rd_removecode += """
         %(name)s[post].erase(%(name)s[post].begin() + idx);
 """ % {'name': rd['name']}
 
+        # For spiking models, we need to rebuild the backward view, if synapses are removed/added
+        inverse_connectivity_code = '' if proj.synapse_type.type == 'rate' else header_tpl['spiking_rebuild_backwardview']
+
         # Generate the code
         code += header_tpl['header'] % {
             'extra_args': extra_args,
             'delay_code': delay_code, 'delay_remove': delay_remove,
             'add_code': add_var_code, 'add_remove': add_var_remove,
             'spike_add': spiking_addcode, 'spike_remove': spiking_removecode,
-            'rd_add': rd_addcode, 'rd_remove': rd_removecode
+            'rd_add': rd_addcode, 'rd_remove': rd_removecode,
+            'inverse_connectivity_rebuild': inverse_connectivity_code
         }
 
         return code
 
     def _init_random_distributions(self, proj):
         # Is it a specific population?
         if 'init_rng' in proj._specific_template.keys():
@@ -1232,25 +1256,42 @@
                         'local_index': "[tid][inv_idx_[j]]",
                         'semiglobal_index': "[tid][*it]",
                         'global_index': "",
                         'pre_index': "[row_idx_[j]]",
                         'post_index': "",
                     })
 
+        elif proj._storage_format == "dense":
+            if proj._storage_order == "post_to_pre":
+                if single_matrix:
+                    raise NotImplementedError
+                else:
+                    raise NotImplementedError
+            else:
+                if single_matrix:
+                    pass    # currently working on
+                else:
+                    raise NotImplementedError
+
         else:
+            # Sanity: this should not reached
             raise NotImplementedError
 
         # Definition of format-specific local variables.
         if proj._storage_format == "lil":
             post_event_prefix = ""
         elif proj._storage_format == "csr":
             post_event_prefix = """
         int rk_post;
         std::vector<int>::iterator it;
         """
+        elif proj._storage_format == "dense":
+            post_event_prefix = """
+        int rk_post;
+"""
         else:
             raise NotImplementedError
 
         # Event-driven integration
         has_event_driven = False
         for var in proj.synapse_type.description['variables']:
             if var['method'] == 'event-driven':
@@ -1286,15 +1327,15 @@
                 'post_event': post_code,
                 'event_driven': event_driven_code
             })
             code = self._templates['post_event'] % ids
 
         except KeyError:
             # Template does not exist
-            raise KeyError("No template for spiking neurons post event (format = " + proj._storage_format + " and order = " + proj._storage_order+ ")")
+            Messages._error("No template for spiking neurons post event (format = {}, order = {}, and single_matrix = {})".format(proj._storage_format, proj._storage_order, single_matrix))
 
         # Annotate code
         if self._prof_gen:
             code = self._prof_gen.annotate_post_event(proj, code)
 
         return post_event_prefix, tabify(code, 2)
 
@@ -1423,15 +1464,15 @@
 
         # Choose the template
         try:
             template = self._templates['update_variables']
 
         except KeyError:
             # either no template code at all, or no 'update_variables' field.
-            Global._error("No synaptic plasticity template found for format = " + proj._storage_format, " and order = " + proj._storage_order)
+            Messages._error("No synaptic plasticity template found for format = " + proj._storage_format, ", order = " + proj._storage_order, " and single_matrix =", single_matrix)
 
         ids = deepcopy(self._template_ids)
 
         # Fill the code template
         if local_eq.strip() != "": # local synapses are updated
             ids.update({
                 'global': global_eq % self._template_ids,
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/ProjectionGenerator.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/ProjectionGenerator.py`

 * *Files 10% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 :license: GPLv2, see LICENSE for details.
 """
 
 from ANNarchy.core import Global
 from ANNarchy.core.PopulationView import PopulationView
 from ANNarchy.core import Random as ANNRandom
 from ANNarchy.extensions.convolution import Transpose
+from ANNarchy.intern.ConfigManagement import get_global_config, _check_paradigm, _check_precision
 
 # Useful functions
 from ANNarchy.generator.Utils import tabify, determine_idx_type_for_projection, cpp_connector_available
 
 class ProjectionGenerator(object):
     """
     Abstract definition of a ProjectionGenerator.
@@ -81,15 +82,15 @@
 
         Returns (str1, str2, bool):
 
             * str1:     sparse matrix format declaration
             * str2:     sparse matrix format arguments if needed (e. g. sizes)
             * bool:     if the matrix is a complete (True) or sliced matrix (False)
         """
-        if Global.config["structural_plasticity"] and proj._storage_format != "lil":
+        if get_global_config('structural_plasticity') and proj._storage_format != "lil":
             raise Global.InvalidConfiguration("Structural plasticity is only allowed for LIL format.")
 
         # get preferred index type
         idx_type, _, size_type, _ = determine_idx_type_for_projection(proj)
 
         # ANNarchy supports a list of different formats to encode projections.
         # The general structure of the decision tree is:
@@ -104,131 +105,143 @@
         if proj.synapse_type.type == "rate":
             # Sanity check
             if proj._storage_order == "pre_to_post":
                 Global.CodeGeneratorException("    The storage_order 'pre_to_post' is invalid for rate-coded synapses (Projection: "+proj.name+")")
 
             # Check for the provided format + paradigm combination if a suitable implementation is available.
             if proj._storage_format == "lil":
-                if Global._check_paradigm("openmp"):
-                    if Global.config['num_threads'] == 1:
+                if _check_paradigm("openmp"):
+                    if get_global_config('num_threads') == 1:
                         sparse_matrix_format = "LILMatrix<"+idx_type+", "+size_type+">"
                         sparse_matrix_include = "#include \"LILMatrix.hpp\"\n"
                         single_matrix = True
                     else:
                         if proj._no_split_matrix:
                             sparse_matrix_format = "LILMatrix<"+idx_type+", "+size_type+">"
                             sparse_matrix_include = "#include \"LILMatrix.hpp\"\n"
                             single_matrix = True
                         else:
                             sparse_matrix_format = "PartitionedMatrix< LILMatrix<"+idx_type+", "+size_type+">, "+idx_type+", "+size_type+">"
                             sparse_matrix_include = "#include \"PartitionedMatrix.hpp\"\n#include \"LILMatrix.hpp\"\n"
                             single_matrix = False
                 else:
-                    Global.CodeGeneratorException("    No implementation assigned for rate-coded synapses using LIL and paradigm="+str(Global.config['paradigm'])+" (Projection: "+proj.name+")")
+                    Global.CodeGeneratorException("    No implementation assigned for rate-coded synapses using LIL and paradigm="+str(get_global_config('paradigm'))+" (Projection: "+proj.name+")")
 
             elif proj._storage_format == "coo":
-                if Global._check_paradigm("openmp"):
+                if _check_paradigm("openmp"):
                     sparse_matrix_format = "COOMatrix<"+idx_type+", "+size_type+">"
                     sparse_matrix_include = "#include \"COOMatrix.hpp\"\n"
                     single_matrix = True
 
-                elif Global._check_paradigm("cuda"):
+                elif _check_paradigm("cuda"):
                     sparse_matrix_format = "COOMatrixCUDA<"+idx_type+", "+size_type+">"
                     sparse_matrix_include = "#include \"COOMatrixCUDA.hpp\"\n"
                     single_matrix = True
 
                 else:
-                    Global.CodeGeneratorException("    No implementation assigned for rate-coded synapses using COO and paradigm="+str(Global.config['paradigm'])+" (Projection: "+proj.name+")")
+                    Global.CodeGeneratorException("    No implementation assigned for rate-coded synapses using COO and paradigm="+str(get_global_config('paradigm'))+" (Projection: "+proj.name+")")
+
+            elif proj._storage_format == "dia":
+                if _check_paradigm("openmp"):
+                    sparse_matrix_format = "DiaMatrix<"+idx_type+", "+size_type+", char>"
+                    sparse_matrix_include = "#include \"DiaMatrix.hpp\"\n"
+                    single_matrix = True
+
+                elif _check_paradigm("cuda"):
+                    Global.CodeGeneratorException("    Diagonal format is not available for CUDA devices.")
+
+                else:
+                    Global.CodeGeneratorException("    No implementation assigned for rate-coded synapses using DIA and paradigm="+str(Global.config['paradigm'])+" (Projection: "+proj.name+")")
 
             elif proj._storage_format == "bsr":
-                if Global._check_paradigm("openmp"):
+                if _check_paradigm("openmp"):
                     sparse_matrix_format = "BSRMatrix<"+idx_type+", "+size_type+", true>"
                     sparse_matrix_include = "#include \"BSRMatrix.hpp\"\n"
                     single_matrix = True
 
-                elif Global._check_paradigm("cuda"):
+                elif _check_paradigm("cuda"):
                     sparse_matrix_format = "BSRMatrixCUDA<"+idx_type+", "+size_type+">"
                     sparse_matrix_include = "#include \"BSRMatrixCUDA.hpp\"\n"
                     single_matrix = True
 
                 else:
-                    Global.CodeGeneratorException("    No implementation assigned for rate-coded synapses using BSR and paradigm="+str(Global.config['paradigm'])+" (Projection: "+proj.name+")")
+                    Global.CodeGeneratorException("    No implementation assigned for rate-coded synapses using BSR and paradigm="+str(get_global_config('paradigm'))+" (Projection: "+proj.name+")")
 
             elif proj._storage_format in ["csr", "csr_scalar", "csr_vector"]:
-                if Global._check_paradigm("openmp"):
+                if _check_paradigm("openmp"):
                     sparse_matrix_format = "CSRMatrix<"+idx_type+", "+size_type+">"
                     sparse_matrix_include = "#include \"CSRMatrix.hpp\"\n"
                     single_matrix = True
 
-                elif Global._check_paradigm("cuda"):
+                elif _check_paradigm("cuda"):
                     sparse_matrix_format = "CSRMatrixCUDA<"+idx_type+", "+size_type+">"
                     sparse_matrix_include = "#include \"CSRMatrixCUDA.hpp\"\n"
                     single_matrix = True
 
                 else:
-                    Global.CodeGeneratorException("    No implementation assigned for rate-coded synapses using CSR and paradigm="+str(Global.config['paradigm'])+" (Projection: "+proj.name+")")
+                    Global.CodeGeneratorException("    No implementation assigned for rate-coded synapses using CSR and paradigm="+str(get_global_config('paradigm'))+" (Projection: "+proj.name+")")
 
             elif proj._storage_format == "ellr":
-                if Global._check_paradigm("openmp"):
+                if _check_paradigm("openmp"):
                     sparse_matrix_format = "ELLRMatrix<"+idx_type+", "+size_type+">"
                     sparse_matrix_include = "#include \"ELLRMatrix.hpp\"\n"
                     single_matrix = True
 
-                elif Global._check_paradigm("cuda"):
+                elif _check_paradigm("cuda"):
                     sparse_matrix_format = "ELLRMatrixCUDA<"+idx_type+", "+size_type+">"
                     sparse_matrix_include = "#include \"ELLRMatrixCUDA.hpp\"\n"
                     single_matrix = True
 
                 else:
-                    Global.CodeGeneratorException("    No implementation assigned for rate-coded synapses using ELLPACK-R and paradigm="+str(Global.config['paradigm'])+" (Projection: "+proj.name+")")
+                    Global.CodeGeneratorException("    No implementation assigned for rate-coded synapses using ELLPACK-R and paradigm="+str(get_global_config('paradigm'))+" (Projection: "+proj.name+")")
 
             elif proj._storage_format == "sell":
-                if Global._check_paradigm("openmp"):
+                if _check_paradigm("openmp"):
                     sparse_matrix_format = "SELLMatrix<"+idx_type+", "+size_type+", true>"
                     sparse_matrix_include = "#include \"SELLMatrix.hpp\"\n"
                     single_matrix = True
 
-                elif Global._check_paradigm("cuda"):
+                elif _check_paradigm("cuda"):
                     sparse_matrix_format = "SELLMatrixCUDA<"+idx_type+", "+size_type+">"
                     sparse_matrix_include = "#include \"SELLMatrixCUDA.hpp\"\n"
                     single_matrix = True
 
                 else:
-                    Global.CodeGeneratorException("    No implementation assigned for rate-coded synapses using sliced ELLPACK and paradigm="+str(Global.config['paradigm'])+" (Projection: "+proj.name+")")
+                    Global.CodeGeneratorException("    No implementation assigned for rate-coded synapses using sliced ELLPACK and paradigm="+str(get_global_config('paradigm'))+" (Projection: "+proj.name+")")
 
             elif proj._storage_format == "ell":
-                if Global._check_paradigm("openmp"):
+                if _check_paradigm("openmp"):
                     sparse_matrix_format = "ELLMatrix<"+idx_type+", "+size_type+">"
                     sparse_matrix_include = "#include \"ELLMatrix.hpp\"\n"
                     single_matrix = True
 
-                elif Global._check_paradigm("cuda"):
+                elif _check_paradigm("cuda"):
                     sparse_matrix_format = "ELLMatrixCUDA<"+idx_type+", "+size_type+">"
                     sparse_matrix_include = "#include \"ELLMatrixCUDA.hpp\"\n"
                     single_matrix = True
 
                 else:
-                    Global.CodeGeneratorException("    No implementation assigned for rate-coded synapses using ELLPACK and paradigm="+str(Global.config['paradigm'])+" (Projection: "+proj.name+")")
+                    Global.CodeGeneratorException("    No implementation assigned for rate-coded synapses using ELLPACK and paradigm="+str(get_global_config('paradigm'))+" (Projection: "+proj.name+")")
 
             elif proj._storage_format == "hyb":
-                if Global._check_paradigm("openmp"):
+                if _check_paradigm("openmp"):
                     sparse_matrix_format = "HYBMatrix<"+idx_type+", "+size_type+", true>"
                     sparse_matrix_include = "#include \"HYBMatrix.hpp\"\n"
                     single_matrix = True
 
-                elif Global._check_paradigm("cuda"):
+                elif _check_paradigm("cuda"):
                     sparse_matrix_format = "HYBMatrixCUDA<"+idx_type+", "+size_type+">"
                     sparse_matrix_include = "#include \"HYBMatrixCUDA.hpp\"\n"
                     single_matrix = True
 
                 else:
-                    Global.CodeGeneratorException("    No implementation assigned for rate-coded synapses using Hybrid (COO+ELL) and paradigm="+str(Global.config['paradigm'])+" (Projection: "+proj.name+")")
+                    Global.CodeGeneratorException("    No implementation assigned for rate-coded synapses using Hybrid (COO+ELL) and paradigm="+str(get_global_config('paradigm'))+" (Projection: "+proj.name+")")
 
             elif proj._storage_format == "dense":
-                if Global._check_paradigm("openmp"):
+                if _check_paradigm("openmp"):
                     sparse_matrix_format = "DenseMatrix<"+idx_type+", "+size_type+", char, true>"
                     sparse_matrix_include = "#include \"DenseMatrix.hpp\"\n"
                     single_matrix = True
 
                 else:
                     sparse_matrix_format = "DenseMatrixCUDA<"+idx_type+", "+size_type+", char, true>"
                     sparse_matrix_include = "#include \"DenseMatrixCUDA.hpp\"\n"
@@ -240,50 +253,50 @@
         elif proj.synapse_type.type == "spike":
             # Check for the provided format + paradigm
             # combination if it's availability
             if proj._storage_format == "lil":
                 if proj._storage_order == "pre_to_post":
                     Global.CodeGeneratorException("    The storage_order 'pre_to_post' is invalid for LIL representations (Projection: "+proj.name+")")
 
-                if Global._check_paradigm("openmp"):
-                    if Global.config['num_threads'] == 1 or proj._no_split_matrix:
+                if _check_paradigm("openmp"):
+                    if get_global_config('num_threads') == 1 or proj._no_split_matrix:
                         sparse_matrix_format = "LILInvMatrix<"+idx_type+", "+size_type+">"
                         sparse_matrix_include = "#include \"LILInvMatrix.hpp\"\n"
                         single_matrix = True
                     else:
                         sparse_matrix_format = "PartitionedMatrix<LILInvMatrix<"+idx_type+", "+size_type+">, "+idx_type+", "+size_type+">"
                         sparse_matrix_include = "#include \"PartitionedMatrix.hpp\"\n#include \"LILInvMatrix.hpp\"\n"
                         single_matrix = False
 
                 else:
-                    Global.CodeGeneratorException("    No implementation assigned for spiking synapses using LIL and paradigm="+str(Global.config['paradigm'])+ " (Projection: "+proj.name+")")
+                    Global.CodeGeneratorException("    No implementation assigned for spiking synapses using LIL and paradigm="+str(get_global_config('paradigm'))+ " (Projection: "+proj.name+")")
 
             elif proj._storage_format == "csr":
                 if proj._storage_order == "post_to_pre":
-                    if Global._check_paradigm("openmp"):
-                        if Global.config['num_threads'] == 1 or proj._no_split_matrix:
+                    if _check_paradigm("openmp"):
+                        if get_global_config('num_threads') == 1 or proj._no_split_matrix:
                             sparse_matrix_format = "CSRCMatrix<"+idx_type+", "+size_type+">"
                             sparse_matrix_include = "#include \"CSRCMatrix.hpp\"\n"
                             single_matrix = True
                         else:
                             sparse_matrix_format = "PartitionedMatrix<CSRCMatrix<"+idx_type+", "+size_type+">, "+idx_type+", "+size_type+">"
                             sparse_matrix_include = "#include \"PartitionedMatrix.hpp\"\n#include \"CSRCMatrix.hpp\"\n"
                             single_matrix = False
 
-                    elif Global._check_paradigm("cuda"):
+                    elif _check_paradigm("cuda"):
                         sparse_matrix_format = "CSRCMatrixCUDA<"+idx_type+", "+size_type+">"
                         sparse_matrix_include = "#include \"CSRCMatrixCUDA.hpp\"\n"
                         single_matrix = True
 
                     else:
                         raise NotImplementedError
 
                 else:
-                    if Global._check_paradigm("openmp"):
-                        if Global.config['num_threads'] == 1 or proj._no_split_matrix:
+                    if _check_paradigm("openmp"):
+                        if get_global_config('num_threads') == 1 or proj._no_split_matrix:
                             sparse_matrix_format = "CSRCMatrixT<"+idx_type+", "+size_type+">"
                             sparse_matrix_include = "#include \"CSRCMatrixT.hpp\"\n"
                             single_matrix = True
                         else:
                             sparse_matrix_format = "PartitionedMatrix<CSRCMatrixT<"+idx_type+", "+size_type+">, "+idx_type+", "+size_type+">"
                             sparse_matrix_include = "#include \"PartitionedMatrix.hpp\"\n#include \"CSRCMatrixT.hpp\"\n"
                             single_matrix = False
@@ -291,29 +304,29 @@
                     else:
                         sparse_matrix_format = "CSRCMatrixCUDAT<"+idx_type+", "+size_type+">"
                         sparse_matrix_include = "#include \"CSRCMatrixCUDAT.hpp\"\n"
                         single_matrix = True
 
             elif proj._storage_format == "bsr":
                 if proj._storage_order == "post_to_pre":
-                    if Global._check_paradigm("openmp"):
+                    if _check_paradigm("openmp"):
                         sparse_matrix_format = "BSRInvMatrix<"+idx_type+", "+size_type+", false>"
                         sparse_matrix_include = "#include \"BSRInvMatrix.hpp\"\n"
                         single_matrix = True
 
                     else:
                         raise NotImplementedError
 
                 else:
                     raise NotImplementedError
 
             elif proj._storage_format == "dense":
                 if proj._storage_order == "post_to_pre":
-                    if Global._check_paradigm("openmp"):
-                        if proj._has_pop_view and Global.config["num_threads"] == 1:
+                    if _check_paradigm("openmp"):
+                        if proj._has_pop_view and get_global_config('num_threads') == 1:
                             sparse_matrix_format = "DenseMatrixOffsets<"+idx_type+", "+size_type+", char, false>"
                             sparse_matrix_include = "#include \"DenseMatrixOffsets.hpp\"\n"
                             single_matrix = True
 
                         else:
                             sparse_matrix_format = "DenseMatrix<"+idx_type+", "+size_type+", char, true>"
                             sparse_matrix_include = "#include \"DenseMatrix.hpp\"\n"
@@ -321,16 +334,16 @@
 
                     else:
                         sparse_matrix_format = "DenseMatrixCUDA<"+idx_type+", "+size_type+", char, true>"
                         sparse_matrix_include = "#include \"DenseMatrixCUDA.hpp\"\n"
                         single_matrix = True
 
                 else:
-                    if Global._check_paradigm("openmp"):
-                        if proj._has_pop_view and Global.config["num_threads"] == 1:
+                    if _check_paradigm("openmp"):
+                        if proj._has_pop_view and get_global_config('num_threads') == 1:
                             sparse_matrix_format = "DenseMatrixOffsets<"+idx_type+", "+size_type+", char, false>"
                             sparse_matrix_include = "#include \"DenseMatrixOffsets.hpp\"\n"
                             single_matrix = True
 
                         else:
                             sparse_matrix_format = "DenseMatrix<"+idx_type+", "+size_type+", char, false>"
                             sparse_matrix_include = "#include \"DenseMatrix.hpp\"\n"
@@ -363,37 +376,37 @@
                 sparse_matrix_args += ", " + str(determine_bsr_blocksize(proj.pre.population.size if isinstance(proj.pre, PopulationView) else proj.pre.size, proj.post.population.size if isinstance(proj.post, PopulationView) else proj.post.size))
 
         elif proj._storage_format == "sell":
             if hasattr(proj, "_block_size"):
                 sparse_matrix_args += ", " + str(proj._block_size)
             else:
                 # TODO (QT/HD): what is a good default value?
-                if Global._check_paradigm("openmp"):
+                if _check_paradigm("openmp"):
                     # HD (7th Feb. 2022): the block size is chosen according to the write-access pattern to psp
-                    block_size = 4 if Global.config["precision"]=="double" else 8
+                    block_size = 4 if _check_precision('double') else 8
                 else:
                     # HD (19th Mar. 2022): the block size should be at least one warp
                     block_size = 32
                 sparse_matrix_args += ", " + str(block_size)
 
-        elif proj._storage_format == "dense" and proj._has_pop_view and Global.config["num_threads"] == 1:
+        elif proj._storage_format == "dense" and proj._has_pop_view and get_global_config('num_threads') == 1:
             # We use a dense matrix where we try to cut off not needed parts but then we need to provide
             # begin and end of the matrix.
             sparse_matrix_args = ""
             if isinstance(proj.post, PopulationView):
                 sparse_matrix_args += str(proj.post.offsets[0]) +", " + str(proj.post.offsets[1]) + ", "
             else:
                 sparse_matrix_args += "0, " + str(proj.post.size) + ", "
 
             if isinstance(proj.pre, PopulationView):
                 sparse_matrix_args += str(proj.pre.offsets[0]) +", " + str(proj.pre.offsets[1])
             else:
                 sparse_matrix_args += "0, " + str(proj.pre.size)
 
-        if Global.config['verbose']:
+        if get_global_config('verbose'):
             print("Selected", sparse_matrix_format, "(", sparse_matrix_args, ")", "for projection ", proj.name, "and single_matrix =", single_matrix )
 
         return sparse_matrix_include, sparse_matrix_format, sparse_matrix_args, single_matrix
 
     def _connectivity_init(self, proj, sparse_matrix_format, sparse_matrix_args):
         """
         Each of the pre-defined pattern requires probably different initialization values.
@@ -438,16 +451,17 @@
     }
 """
         else:
             connector_call = """
     bool init_from_lil( std::vector<%(idx_type)s> row_indices,
                         std::vector< std::vector<%(idx_type)s> > column_indices,
                         std::vector< std::vector<%(float_prec)s> > values,
-                        std::vector< std::vector<int> > delays) {
-        bool success = static_cast<%(sparse_format)s*>(this)->init_matrix_from_lil(row_indices, column_indices%(add_args)s%(num_threads)s);
+                        std::vector< std::vector<int> > delays,
+                        bool requires_sorting) {
+        bool success = static_cast<%(sparse_format)s*>(this)->init_matrix_from_lil(row_indices, column_indices, requires_sorting%(add_args)s%(num_threads)s);
         if (!success)
             return false;
 
 %(init_weights)s
 %(init_delays)s
 
         // init other variables than 'w' or delay
@@ -480,15 +494,15 @@
         declare_additional = ""
 
         # Delays
         if proj.max_delay > 1:
             if proj.uniform_delay > 1 :
                 key_delay = "uniform"
             else:
-                if Global._check_paradigm("cuda"):
+                if _check_paradigm("cuda"):
                     Global.CodeGeneratorException("Non-uniform delays on rate-coded or spiking synapses are not available for CUDA devices.")
 
                 if proj.synapse_type.type == "rate":
                     key_delay = "nonuniform_rate_coded"
                 else:
                     key_delay = "nonuniform_spiking"
 
@@ -521,20 +535,20 @@
             declare_rng += """
     // Random numbers
 """
             for rd in proj.synapse_type.description['random_distributions']:
                 declare_rng += self._templates['rng'][rd['locality']]['decl'] % {
                     'rd_name' : rd['name'],
                     'type': rd['ctype'],
-                    'float_prec': Global.config['precision'],
-                    'template': rd['template'] % {'float_prec':Global.config['precision']}
+                    'float_prec': get_global_config('precision'),
+                    'template': rd['template'] % {'float_prec':get_global_config('precision')}
                 }
 
         # Structural plasticity
-        if Global.config['structural_plasticity']:
+        if get_global_config('structural_plasticity'):
             declare_parameters_variables += self._header_structural_plasticity(proj)
 
         # Specific projections can overwrite
         if 'declare_parameters_variables' in proj._specific_template.keys():
             declare_parameters_variables = proj._specific_template['declare_parameters_variables']
         if 'access_parameters_variables' in proj._specific_template.keys():
             accessor = proj._specific_template['access_parameters_variables']
@@ -589,15 +603,15 @@
             attr_type = 'parameter' if var in proj.synapse_type.description['parameters'] else 'variable'
 
             # Special case for single weights
             if var['name'] == "w" and proj._has_single_weight():
                 locality = 'global'
 
             # For GPUs we need to tell the host that this variable need to be updated
-            if Global._check_paradigm("cuda"):
+            if _check_paradigm("cuda"):
                 if locality == "global" and attr_type=="parameter":
                     write_dirty_flag = ""
                     read_dirty_flag = ""
                 else:
                     write_dirty_flag = "%(name)s_host_to_device = true;" % {'name': var['name']}
                     read_dirty_flag = "if ( %(name)s_device_to_host < t ) device_to_host();" % {'name': var['name']}
             else:
@@ -661,15 +675,15 @@
 
                 #
                 # Global variables are only d
                 else:
                     global_attribute_get += self._templates["attr_acc"]["global_get"] % ids
                     global_attribute_set += self._templates["attr_acc"]["global_set"] % ids
 
-                if Global._check_paradigm("cuda") and locality=="global":
+                if _check_paradigm("cuda") and locality=="global":
                     declare_parameters_variables += decl_template[locality][attr_type] % ids
                 else:
                     declare_parameters_variables += decl_template[locality] % ids
                 attributes.append(var['name'])
 
             # build up the final codes
             if local_attribute_get1 != "":
@@ -822,36 +836,36 @@
                                     init_code = "w = init_matrix_variable_log_normal_clip<%(float_prec)s>(w_dist_arg1, w_dist_arg2, rng[0], "+min_code+", "+max_code+");"
                                 else:
                                     init_code = "w = init_matrix_variable_log_normal_clip<%(float_prec)s>(w_dist_arg1, w_dist_arg2, rng, "+min_code+", "+max_code+");"
 
                         else:
                             raise NotImplementedError( str(type(proj.connector_weight_dist)) + " is not available for CPP-side connection patterns.")
 
-                        if Global._check_paradigm("cuda"):
+                        if _check_paradigm("cuda"):
                             init_code += "\ngpu_w = init_matrix_variable_gpu<%(float_prec)s>(w);"
 
-                        weight_code = tabify(init_code % {'float_prec': Global.config['precision']}, 2)
+                        weight_code = tabify(init_code % {'float_prec': get_global_config('precision')}, 2)
 
                     # Init_from_lil
                     else:
                         init = 'false' if var['ctype'] == 'bool' else ('0' if var['ctype'] == 'int' else '0.0')
                         weight_code = attr_init_tpl[locality] % {
                             'id': proj.id,
                             'id_post': proj.post.id,
                             'name': var['name'],
                             'type': var['ctype'],
                             'init': init,
                             'attr_type': attr_type,
-                            'float_prec': Global.config['precision']
+                            'float_prec': get_global_config('precision')
                         }
                         if proj._storage_format=="dense":
-                            weight_code += tabify("for (%(idx_type)s row_idx = 0; row_idx < row_indices.size(); row_idx++) {\n\tupdate_matrix_variable_row<%(float_prec)s>(w, row_indices[row_idx], values[row_idx]);\n}" % {'idx_type': 'int', 'float_prec': Global.config['precision']}, 2)
+                            weight_code += tabify("for (%(idx_type)s row_idx = 0; row_idx < row_indices.size(); row_idx++) {\n\tupdate_matrix_variable_row<%(float_prec)s>(w, row_indices[row_idx], values[row_idx]);\n}" % {'idx_type': 'int', 'float_prec': get_global_config('precision')}, 2)
                         else:
-                            weight_code += tabify("update_matrix_variable_all<%(float_prec)s>(w, values);" % {'float_prec': Global.config['precision']}, 2)
-                        if Global._check_paradigm("cuda"):
+                            weight_code += tabify("update_matrix_variable_all<%(float_prec)s>(w, values);" % {'float_prec': get_global_config('precision')}, 2)
+                        if _check_paradigm("cuda"):
                             weight_code += tabify("\nw_host_to_device = true;", 2)
 
                 else:
                     raise NotImplementedError
 
             # All other variables
             else:
@@ -859,17 +873,17 @@
                 var_ids = {
                     'id': proj.id,
                     'id_post': proj.post.id,
                     'name': var['name'],
                     'type': var['ctype'],
                     'init': init,
                     'attr_type': attr_type,
-                    'float_prec': Global.config['precision']
+                    'float_prec': get_global_config('precision')
                 }
-                if Global._check_paradigm("cuda") and locality == "global":
+                if _check_paradigm("cuda") and locality == "global":
                     code += attr_init_tpl[locality][attr_type] % var_ids
                 else:
                     code += attr_init_tpl[locality] % var_ids
 
             attributes.append(var['name'])
 
         # Initialize delays differs for construction from LIL or CPP inited patterns
@@ -919,15 +933,15 @@
             if var['method'] == 'event-driven':
                 has_event_driven = True
                 break
         if has_event_driven:
             code += self._templates['event_driven']['cpp_init']
 
         # Pruning
-        if Global.config['structural_plasticity']:
+        if get_global_config('structural_plasticity'):
             if 'pruning' in proj.synapse_type.description.keys():
                 code += """
         // Pruning
         _pruning = false;
         _pruning_period = 1;
         _pruning_offset = 0;
 """
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/BSR.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/BSR.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/BaseTemplates.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/BaseTemplates.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/COO.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/COO.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/CSR.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/CSR.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/CSR_T.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/CSR_T.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/Dense.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/Dense.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/Dense_PV.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/Dense_PV_T.py`

 * *Files 5% similar despite different names*

```diff
@@ -100,25 +100,32 @@
 """
     }
 }
 
 spiking_summation_fixed_delay = """// Event-based summation
 if (_transmission && %(post_prefix)s_active){
 
-    for (%(idx_type)s rk_post = 0; rk_post < num_rows(); rk_post++) {
-        // Iterate over all spiking neurons
-        for (auto it = %(pre_prefix)sspiked.cbegin(); it != %(pre_prefix)sspiked.cend(); it++) {
-            %(idx_type)s rk_pre = (*it);
-            if ((rk_pre < this->low_column_rank_) || (rk_pre >= this->high_column_rank_))
-                continue;
-
-            %(size_type)s j = rk_post*this->num_columns_ + *it;
-
+    // Iterate over all spiking neurons
+    for (auto it = %(pre_prefix)sspiked.cbegin(); it != %(pre_prefix)sspiked.cend(); it++) {
+        %(idx_type)s rk_pre = (*it);
+        if ((rk_pre < this->low_column_rank_) || (rk_pre >= this->high_column_rank_))
+            continue;
+
+        %(size_type)s beg = (rk_pre - this->low_column_rank_) * this->num_rows_;
+        %(size_type)s end = ((rk_pre+1) - this->low_column_rank_) * this->num_rows_;
+
+        // Post-synaptic potential
+        %(idx_type)s rk_post = this->low_row_rank_;
+        for (%(size_type)s j = beg; j < end; j++, rk_post++) {
             %(g_target)s
+        }
 
+        // 'on-pre' events
+        rk_post = 0;
+        for (%(size_type)s j = beg; j < end; j++, rk_post++) {
             if (mask_[j]) {
                 %(event_driven)s
                 %(pre_event)s
             }
         }
     }
 } // active
@@ -129,18 +136,18 @@
     'attribute_decl': attribute_decl,
     'attribute_cpp_init': attribute_cpp_init,
     'attribute_cpp_size': attribute_cpp_size,
     'attribute_cpp_delete': attribute_cpp_delete,
     'delay': delay,
 
     #operations
-    'rate_coded_sum': None,
-    'vectorized_default_psp': None,
+    'rate_coded_sum': "",
+    'vectorized_default_psp': {},
     'spiking_sum_fixed_delay': spiking_summation_fixed_delay,
-    'update_variables': None,
+    'update_variables': "",
 }
 
 conn_ids = {
     'local_index': '[j]',
     'semiglobal_index': '[rk_post]',
     'global_index': '',
     'post_index': '[rk_post]',
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/Dense_PV_T.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/OpenMP/DIA.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,17 +1,12 @@
-"""
-:copyright: Copyright 2013 - now, see AUTHORS.
-:license: GPLv2, see LICENSE for details.
-"""
-
 attribute_decl = {
     'local':
 """
     // Local %(attr_type)s %(name)s
-    std::vector< %(type)s > %(name)s;
+    std::vector<std::vector< %(type)s >> %(name)s;
 """,
     'semiglobal':
 """
     // Semiglobal %(attr_type)s %(name)s
     std::vector< %(type)s >  %(name)s ;
 """,
     'global':
@@ -22,16 +17,14 @@
 }
 
 attribute_cpp_init = {
     'local':
 """
         // Local %(attr_type)s %(name)s
         %(name)s = init_matrix_variable<%(type)s>(static_cast<%(type)s>(%(init)s));
-        if(%(name)s.empty())
-            return false;
 """,
     'semiglobal':
 """
         // Semiglobal %(attr_type)s %(name)s
         %(name)s = init_vector_variable<%(type)s>(static_cast<%(type)s>(%(init)s));
 """,
     'global':
@@ -40,31 +33,37 @@
         %(name)s = %(init)s;
 """
 }
 
 attribute_cpp_size = {
     'local': """
         // Local %(attr_type)s %(name)s
-        size_in_bytes += sizeof(std::vector<%(ctype)s>);
-        size_in_bytes += sizeof(%(ctype)s) * %(name)s.capacity();
+        size_in_bytes += sizeof(std::vector<std::vector<%(ctype)s>>);
+        size_in_bytes += sizeof(std::vector<%(ctype)s>) * %(name)s.capacity();
+        for(auto it = %(name)s.cbegin(); it != %(name)s.cend(); it++)
+            size_in_bytes += (it->capacity()) * sizeof(%(ctype)s);
 """,
     'semiglobal': """
         // Semiglobal %(attr_type)s %(name)s
         size_in_bytes += sizeof(std::vector<%(ctype)s>);
         size_in_bytes += sizeof(%(ctype)s) * %(name)s.capacity();
 """,
     'global': """
-        // Global %(attr_type)s %(name)s
+        // Global
         size_in_bytes += sizeof(%(ctype)s);
 """
 }
 
 attribute_cpp_delete = {
     'local': """
         // %(name)s
+        for (auto it = %(name)s.begin(); it != %(name)s.end(); it++) {
+            it->clear();
+            it->shrink_to_fit();
+        };
         %(name)s.clear();
         %(name)s.shrink_to_fit();
 """,
     'semiglobal': """
         // %(name)s
         %(name)s.clear();
         %(name)s.shrink_to_fit();
@@ -73,15 +72,15 @@
 }
 
 delay = {
     'uniform': {
         'declare': """
     // Uniform delay
     int delay ;""",
-        
+
         'pyx_struct':
 """
         # Uniform delay
         int delay""",
         'init': """
     delay = delays[0][0];
 """,
@@ -94,63 +93,57 @@
     def get_delay(self):
         return proj%(id_proj)s.delay
     def get_dendrite_delay(self, idx):
         return proj%(id_proj)s.delay
     def set_delay(self, value):
         proj%(id_proj)s.delay = value
 """
+    },
+    'nonuniform_rate_coded': {
+    },
+    'nonuniform_spiking': {
     }
 }
 
-spiking_summation_fixed_delay = """// Event-based summation
-if (_transmission && %(post_prefix)s_active){
-
-    // Iterate over all spiking neurons
-    for (auto it = %(pre_prefix)sspiked.cbegin(); it != %(pre_prefix)sspiked.cend(); it++) {
-        %(idx_type)s rk_pre = (*it);
-        if ((rk_pre < this->low_column_rank_) || (rk_pre >= this->high_column_rank_))
-            continue;
-
-        %(size_type)s beg = (rk_pre - this->low_column_rank_) * this->num_rows_;
-        %(size_type)s end = ((rk_pre+1) - this->low_column_rank_) * this->num_rows_;
-
-        // Post-synaptic potential
-        %(idx_type)s rk_post = this->low_row_rank_;
-        for (%(size_type)s j = beg; j < end; j++, rk_post++) {
-            %(g_target)s
-        }
-
-        // 'on-pre' events
-        rk_post = 0;
-        for (%(size_type)s j = beg; j < end; j++, rk_post++) {
-            if (mask_[j]) {
-                %(event_driven)s
-                %(pre_event)s
-            }
-        }
+continuous_transmission = {
+    'sum': """
+%(pre_copy)s
+
+%(idx_type)s off, i, is, ie, j;
+for (auto map_it = offsets_.begin(); map_it != offsets_.end(); map_it++) {
+
+    off = map_it->first;
+    is = std::max<int>(0, -off);
+    ie = std::min<int>(num_columns_, num_columns_-off);
+
+    %(float_prec)s* __restrict__ target_ptr = %(post_prefix)s_sum_%(target)s.data();
+
+    %(omp_simd)s
+    for(i=is; i < ie; i++) {
+        target_ptr%(post_index)s += %(psp)s;
     }
-} // active
+}
 """
+}
 
 conn_templates = {
     # accessors
     'attribute_decl': attribute_decl,
     'attribute_cpp_init': attribute_cpp_init,
     'attribute_cpp_size': attribute_cpp_size,
     'attribute_cpp_delete': attribute_cpp_delete,
     'delay': delay,
 
-    #operations
-    'rate_coded_sum': "",
+    'rate_coded_sum': continuous_transmission,
     'vectorized_default_psp': {},
-    'spiking_sum_fixed_delay': spiking_summation_fixed_delay,
-    'update_variables': "",
+    'update_variables': ""
 }
 
 conn_ids = {
-    'local_index': '[j]',
-    'semiglobal_index': '[rk_post]',
+    'local_index': '[map_it->second][i]',
+    'semiglobal_index': '[i]',
     'global_index': '',
-    'post_index': '[rk_post]',
-    'pre_index': '[rk_pre]',
-    'delay_u' : '[delay-1]' # uniform delay
-}
+    'post_index': '[i]',
+    'pre_index': '[i+off]',
+    'delay_u' : '[delay-1]', # uniform delay
+    'delay_nu' : '[delay[j]-1]' # nonuniform delay
+}
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/Dense_T.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/Dense_T.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/ELL.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/ELL.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/ELLR.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/ELLR.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/HYB.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/HYB.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/LIL.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/LIL.py`

 * *Files 2% similar despite different names*

```diff
@@ -1038,14 +1038,15 @@
             if(pre_rank[post][i] == pre){
                 idx = i;
                 break;
             }
         }
         return idx;
     }
+%(inverse_connectivity_rebuild)s
     void addSynapse(int post, int pre, double weight, int _delay=0%(extra_args)s) {
         // Find where to put the synapse
         int idx = pre_rank[post].size();
         for(int i=0; i<pre_rank[post].size(); i++){
             if(pre_rank[post][i] > pre){
                 idx = i;
                 break;
@@ -1059,16 +1060,19 @@
         // Update additional fields
 %(delay_code)s
 %(add_code)s
 %(spike_add)s
 %(rd_add)s
     };
     void removeSynapse(int post, int idx){
+        // Update connectivty
         pre_rank[post].erase(pre_rank[post].begin() + idx);
         w[post].erase(w[post].begin() + idx);
+
+        // Update additional fields
 %(delay_remove)s
 %(add_remove)s
 %(spike_remove)s
 %(rd_remove)s
     };
 """,
         'pruning': """
@@ -1085,28 +1089,41 @@
 """,
         'spiking_addcode': """
         // Add the corresponding pair in inv_pre_rank
         int idx_post = 0;
         for(int i=0; i<post_rank.size(); i++){
             if(post_rank[i] == post){
                 idx_post = i;
+                _dirty_connectivity = true;
                 break;
             }
         }
         inv_pre_rank[pre].push_back(std::pair<int, int>(idx_post, idx));
 """,
         'spiking_removecode': """
         // Remove the corresponding pair in inv_pre_rank
         int pre = pre_rank[post][idx];
         for(int i=0; i<inv_pre_rank[pre].size(); i++){
             if(inv_pre_rank[pre][i].second == idx){
                 inv_pre_rank[pre].erase(inv_pre_rank[pre].begin() + i);
+                _dirty_connectivity = true;
                 break;
             }
         }
+""",
+        'spiking_rebuild_backwardview': """    bool _dirty_connectivity = false;
+    void check_and_rebuild_inverse_connectivity() {
+    #ifdef _TRACE_SIMULATION_STEPS
+        std::cout << "ProjStruct::check_and_rebuild_inverse_connectivity() called at time t = " << t / dt << " ms." << std::endl;
+    #endif
+        if (this->_dirty_connectivity) {
+            inverse_connectivity_matrix();
+            _dirty_connectivity = false;
+        }
+    }
 """
     },
     'pyx_struct': {
         'pruning':
 """
         # Pruning
         bool _pruning
@@ -1162,15 +1179,19 @@
     },
 
     # Structural plasticity during the simulate() call
     'create': """
         // proj%(id_proj)s creating: %(eq)s
         void creating() {
             if((_creating)&&((t - _creating_offset) %% _creating_period == 0)){
+            #ifdef _TRACE_SIMULATION_STEPS
+                std::cout << "ProjStruct%(id_proj)s::creating() executed at time t = " << t / dt << " ms." << std::endl;
+            #endif
                 %(proba_init)s
+
                 for(int i = 0; i < post_rank.size(); i++){
                     int rk_post = post_rank[i];
                     for(int rk_pre = 0; rk_pre < %(pre_prefix)ssize; rk_pre++){
                         if(%(condition)s){
                             // Check if the synapse exists
                             bool _exists = false;
                             for(int k=0; k<pre_rank[i].size(); k++){
@@ -1189,21 +1210,27 @@
             }
         }
     """,
     'prune': """
         // proj%(id_proj)s pruning: %(eq)s
         void pruning() {
             if((_pruning)&&((t - _pruning_offset) %% _pruning_period == 0)){
+            #ifdef _TRACE_SIMULATION_STEPS
+                std::cout << "ProjStruct%(id_proj)s::pruning() executed at time t = " << t / dt << " ms." << std::endl;
+            #endif
                 %(proba_init)s
+
                 for(int i = 0; i < post_rank.size(); i++){
                     int rk_post = post_rank[i];
-                    for(int j = 0; j < pre_rank[i].size(); j++){
+                    for(int j = 0; j < pre_rank[i].size();){
                         int rk_pre = pre_rank[i][j];
                         if((%(condition)s)%(proba)s){
                             removeSynapse(i, j);
+                        }else{
+                            ++j;
                         }
                     }
                 }
             }
         }
     """
 }
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/SELL.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/SELL.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThread/__init__.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThread/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -8,14 +8,15 @@
 
 [FORMAT]_SingleThread:
 
     defines the format specific defintions for the currently available formats:
 
         * LIL: list-in-list
         * COO: coordinate
+        * DIA: diagonal format
         * BSR: blocked compressed row
         * CSR: compressed sparse row
         * ELL: ELLPACK/ITPACK
         * ELLR: ELLPACK with row-length array
         * SELLR: sliced ELLPACK
         * HYB: hybrid format comprising of ELLPACK and coordinate
         * Dense: a full matrix representation
@@ -24,14 +25,15 @@
 
         * _T suffix: a transposed implementation
         * _PV suffix: a specialized implementation for PopulationViews
 
 """
 from . import LIL as LIL_SingleThread
 from . import COO as COO_SingleThread
+from . import DIA as DIA_SingleThread
 from . import BSR as BSR_SingleThread
 from . import CSR as CSR_SingleThread
 from . import CSR_T as CSR_T_SingleThread
 from . import ELL as ELL_SingleThread
 from . import ELLR as ELLR_SingleThread
 from . import SELL as SELL_SingleThread
 from . import HYB as HYB_SingleThread
@@ -39,13 +41,14 @@
 from . import Dense_T as Dense_T_SingleThread
 from . import Dense_PV as Dense_PV_SingleThread
 
 __all__ = [
     "BaseTemplates",
     "LIL_SingleThread",
     "COO_SingleThread",
+    "DIA_SingleThread",
     "BSR_SingleThread",
     "CSR_SingleThread", "CSR_T_SingleThread",
     "ELL_SingleThread", "ELLR_SingleThread", "SELL_SingleThread",
     "HYB_SingleThread",
     "Dense_SingleThread", "Dense_PV_SingleThread", "Dense_T_SingleThread"
 ]
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Projection/SingleThreadGenerator.py` & `annarchy-4.8.0.1/ANNarchy/generator/Projection/SingleThreadGenerator.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,14 +5,16 @@
 
 import ANNarchy
 
 # ANNarchy objects
 from ANNarchy.core import Global
 from ANNarchy.core.PopulationView import PopulationView
 from ANNarchy.models.Synapses import DefaultRateCodedSynapse
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern import Messages
 
 # Code templates
 from ANNarchy.generator.Projection.ProjectionGenerator import ProjectionGenerator, get_bounds
 from ANNarchy.generator.Projection.SingleThread import *
 
 # Useful functions
 from ANNarchy.generator.Utils import generate_equation_code, tabify, remove_trailing_spaces, check_avx_instructions, determine_idx_type_for_projection
@@ -33,15 +35,15 @@
 
     def header_struct(self, proj, annarchy_dir):
         """
         Generate the projection header for a given projection. The resulting
         code will be stored in a file called proj<unique_id>.hpp in the
         directory indicated by annarchy_dir.
 
-        This function is called from the CodeGenerator if Global.config['num_threads']
+        This function is called from the CodeGenerator if get_global_config('num_threads')
         was set to 1.
 
         Returns:
 
         * proj_desc: a dictionary with all call statements for the required
                      operations (i. e. compute_psp, update_synapse, etc.)
         """
@@ -106,15 +108,15 @@
             connector_call = self._connectivity_init(proj, sparse_matrix_format, sparse_matrix_args) % {
                 'sparse_format': sparse_matrix_format,
                 'init_weights': init_weights,
                 'init_delays': init_delays,
                 'rng_idx': "[0]",
                 'add_args': add_args,
                 'num_threads': "",
-                'float_prec': Global.config["precision"],
+                'float_prec': get_global_config('precision'),
                 'idx_type': determine_idx_type_for_projection(proj)[0]
             }
             declare_connectivity_matrix = ""
             access_connectivity_matrix = ""
         else:
             # The user is responsible to define the connectivity related variables
             sparse_matrix_format = "SpecificConnectivity"
@@ -197,15 +199,15 @@
             'update_max_delay': update_max_delay,
             'reset_ring_buffer': reset_ring_buffer,
             'post_event': post_event,
             'access_parameters_variables': accessor,
             'access_additional': access_additional,
             'size_in_bytes': size_in_bytes,
             'clear_container': clear_container,
-            'float_prec': Global.config['precision'],
+            'float_prec': get_global_config('precision'),
             'creating': creating,
             'pruning': pruning
         }
 
         # Generate the final code
         final_code = self._templates['projection_header'] % final_code_dict
 
@@ -255,15 +257,15 @@
         self._template_ids.update({
             'id_proj' : proj.id,
             'target': proj.target,
             'id_post': proj.post.id,
             'id_pre': proj.pre.id,
             'idx_type': idx_type,
             'size_type': size_type,
-            'float_prec': Global.config["precision"],
+            'float_prec': get_global_config('precision'),
             'pre_prefix': 'pop'+ str(proj.pre.id) + '.',
             'post_prefix': 'pop'+ str(proj.post.id) + '.',
         })
 
         # The variable fields and indices depends on matrix format
         # as well as the matrix orientation.
         if proj._storage_format == "lil":
@@ -276,14 +278,21 @@
         elif proj._storage_format == "coo":
             if proj._storage_order == "post_to_pre":
                 self._templates.update(COO_SingleThread.conn_templates)
                 self._template_ids.update(COO_SingleThread.conn_ids)
             else:
                 raise Global.InvalidConfiguration("    "+proj.name+": storage_format = " + proj._storage_format + " and storage_order = " + proj._storage_order )
 
+        elif proj._storage_format == "dia":
+            if proj._storage_order == "post_to_pre":
+                self._templates.update(DIA_SingleThread.conn_templates)
+                self._template_ids.update(DIA_SingleThread.conn_ids)
+            else:
+                raise Global.InvalidConfiguration("    "+proj.name+": storage_format = " + proj._storage_format + " and storage_order = " + proj._storage_order )
+
         elif proj._storage_format == "bsr":
             if proj._storage_order == "post_to_pre":
                 self._templates.update(BSR_SingleThread.conn_templates)
                 self._template_ids.update(BSR_SingleThread.conn_ids)
             else:
                 raise Global.InvalidConfiguration("    "+proj.name+": storage_format = " + proj._storage_format + " and storage_order = " + proj._storage_order )
 
@@ -364,23 +373,23 @@
             proba_init += "std::uniform_real_distribution<double> unif(0.0, 1.0);"
         if  creating_structure['rd']:
             proba_init += "\n        " +  creating_structure['rd']['template'] + ' rd(' + creating_structure['rd']['args'] + ');'
 
         # delays
         delay = ""
         if 'd' in creating_structure['bounds'].keys():
-            d = int(creating_structure['bounds']['delay']/Global.config['dt'])
+            d = int(creating_structure['bounds']['delay']/get_global_config('dt'))
             if proj.max_delay > 1 and proj.uniform_delay == -1:
                 if d > proj.max_delay:
-                    Global._error('creating: you can not add a delay higher than the maximum of existing delays')
+                    Messages._error('creating: you can not add a delay higher than the maximum of existing delays')
 
                 delay = ", " + str(d)
             else:
                 if d != proj.uniform_delay:
-                    Global._error('creating: you can not add a delay different from the others if they were constant.')
+                    Messages._error('creating: you can not add a delay different from the others if they were constant.')
 
         creation_ids = deepcopy(self._template_ids)
         creating_condition = creating_structure['cpp'] % creation_ids
 
         creation_ids.update({
             'eq': creating_structure['eq'],
             'condition': creating_condition,
@@ -478,43 +487,43 @@
                     # the access to pre-synaptic firing depends on the delay
                     if proj.max_delay <= 1:
                         # no synaptic delay
                         ids.update({
                             'get_r': ids['pre_prefix']+"r.data()",
                         })
 
-                        psp_code = template["sum"][Global.config["precision"]] % ids
+                        psp_code = template["sum"][get_global_config('precision')] % ids
 
                         if self._prof_gen:
                             psp_code = self._prof_gen.annotate_computesum_rate(proj, psp_code)
 
                         return "", psp_code
 
                     elif proj.uniform_delay != -1 and proj.max_delay > 1:
                         # Uniform delay
                         ids.update({
                             'get_r': ids['pre_prefix']+"_delayed_r[delay-1].data()",
                         })
 
-                        psp_code = template["sum"][Global.config["precision"]] % ids
+                        psp_code = template["sum"][get_global_config('precision')] % ids
 
                         if self._prof_gen:
                             psp_code = self._prof_gen.annotate_computesum_rate(proj, psp_code)
 
                         return "", psp_code
 
                     else:
                         # HD (3rd June 2021): for non-uniform delays I doubt that it's worth the effort, so we proceed with
                         #                     general code generation
                         pass
 
                 except KeyError:
                     # No fitting code found, so we fall back to normal code generation
                     # TODO: add internal error log, which key was missing?
-                    Global._debug("No SIMD implementation found, fallback to non-SIMD code")
+                    Messages._debug("No SIMD implementation found, fallback to non-SIMD code")
                     template = ""
 
             else:
                 # Other optimizations like loop unroll etc?
                 if proj._storage_format == "bsr":
                     try:
                         # not yet implemented
@@ -528,15 +537,15 @@
                             blockDim = determine_bsr_blocksize(proj.pre.population.size if isinstance(proj.pre, PopulationView) else proj.pre.size, proj.post.population.size if isinstance(proj.post, PopulationView) else proj.post.size)
 
                         # Loop unroll depends on the block-size
                         unrolled_template = self._templates["unrolled_default_psp"][blockDim]
 
                         # Check if we implemented a SIMD version
                         if simd_type in unrolled_template.keys():
-                            template = unrolled_template[simd_type]['multi_w']['sum'][Global.config["precision"]]
+                            template = unrolled_template[simd_type]['multi_w']['sum'][get_global_config('precision')]
                         else:
                             template = unrolled_template['none']['multi_w']["sum"]
 
                         # the access to pre-synaptic firing depends on the delay
                         if proj.max_delay <= 1:
                             # no synaptic delay
                             ids.update({
@@ -554,19 +563,19 @@
                             #                     experimental feature. I will implement the delay case if we
                             #                     are sure that we really use this.
                             raise KeyError
 
                     except KeyError:
                         # No fitting code found, so we fall back to normal code generation
                         # TODO: add internal error log, which key was missing?
-                        Global._debug("No SIMD implementation found, fallback to non-SIMD code")
+                        Messages._debug("No SIMD implementation found, fallback to non-SIMD code")
                         template = ""
 
         # Default variables needed in psp_code
-        psp_prefix = tabify("%(float_prec)s sum;" % {'float_prec': Global.config['precision']}, 2)
+        psp_prefix = tabify("%(float_prec)s sum;" % {'float_prec': get_global_config('precision')}, 2)
 
         # Choose the corresponding summation template
         try:
             template = self._templates['rate_coded_sum']
         except KeyError:
            Global.CodeGeneratorException("    SingleThreadGenerator: no template for this configuration available")
 
@@ -612,16 +621,16 @@
                 for var in delayed_variables:
                     if var in proj.pre.neuron_type.description['local']:
                         psp = psp.replace(
                             '%(pre_prefix)s'+var+'%(pre_index)s',
                             '%(pre_prefix)s_delayed_'+var+'%(delay_nu)s%(pre_index)s'
                         )
                     else:
-                        Global._print(proj.synapse_type.description['psp']['eq'])
-                        Global._error('The psp accesses a global variable with a non-uniform delay!')
+                        Messages._print(proj.synapse_type.description['psp']['eq'])
+                        Messages._error('The psp accesses a global variable with a non-uniform delay!')
 
 
             else: # Uniform delays
                 for var in delayed_variables:
                     if var in proj.pre.neuron_type.description['local']:
                         psp = psp.replace(
                             '%(pre_prefix)s'+var+'%(pre_index)s',
@@ -641,14 +650,18 @@
                 if var in proj.pre.neuron_type.description['local']:
                     pre_copy += "std::vector<%(float_prec)s> _pre_" + var + " = %(pre_prefix)s_delayed_" + var + "%(delay_u)s;"
                     psp = psp.replace(
                         '%(pre_prefix)s_delayed_'+var+'%(delay_u)s%(pre_index)s',
                         '_pre_'+var+'%(pre_index)s'
                     )
 
+        # Special case for diagonal format
+        if proj._storage_format == "dia":
+            ids.update({'omp_simd': '' if get_global_config('disable_SIMD_SpMV') else '#pragma omp simd'})
+
         # The hybrid format needs to be handled seperately
         # as its composed of two parts
         sum_code = ""
         if proj._storage_format != "hyb":
             # Finalize the psp with the correct ids
             psp = psp % ids
 
@@ -961,25 +974,25 @@
                 )
 
         # Choose correct template based on connectivity
         # and take delays into account if any
         pre_array = ""
         if proj.max_delay > 1:
             if proj.uniform_delay == -1: # Non-uniform delays
-                Global._warning('Variable delays for spiking networks is experimental and slow...')
+                Messages._warning('Variable delays for spiking networks is experimental and slow...')
                 template = self._templates['spiking_sum_variable_delay']
             else: # Uniform delays
                 pre_array = "%(pre_prefix)s_delayed_spike[delay-1]" % ids
                 template = self._templates['spiking_sum_fixed_delay']
         else:
             pre_array = "%(pre_prefix)sspiked" % ids
             template = self._templates['spiking_sum_fixed_delay']
 
         if template == None:
-            Global._error("Code generation error: no template available")
+            Messages._erroror("Code generation error: no template available")
 
         complete_code = ""
 
         # Axonal spike events
         spiked_array_fusion_code = ""
         if proj.synapse_type.pre_axon_spike:
             if proj.synapse_type.description['raw_pre_spike'] == proj.synapse_type.description['raw_axon_spike']:
@@ -1095,47 +1108,51 @@
             delay_code = ' '*8 + "delay[post].insert(delay[post].begin() + idx, _delay);"
             delay_remove = ' '*8 + "delay[post].erase(delay[post].begin() + idx);"
 
         # Spiking networks must update the inv_pre_rank array
         spiking_addcode = "" if proj.synapse_type.type == 'rate' else header_tpl['spiking_addcode']
         spiking_removecode = "" if proj.synapse_type.type == 'rate' else header_tpl['spiking_removecode']
 
-        # Randomdistributions
+        # Random distributions
         rd_addcode = ""
         rd_removecode = ""
         for rd in proj.synapse_type.description['random_distributions']:
             rd_addcode += """
         %(name)s[post].insert(%(name)s[post].begin() + idx, 0.0);
 """ % {'name': rd['name']}
 
             rd_removecode += """
         %(name)s[post].erase(%(name)s[post].begin() + idx);
 """ % {'name': rd['name']}
 
+        # For spiking models, we need to rebuild the backward view, if synapses are removed/added
+        inverse_connectivity_code = '' if proj.synapse_type.type == 'rate' else header_tpl['spiking_rebuild_backwardview']
+
         # Generate the code
         code += header_tpl['header'] % {
             'extra_args': extra_args,
             'delay_code': delay_code, 'delay_remove': delay_remove,
             'add_code': add_var_code, 'add_remove': add_var_remove,
             'spike_add': spiking_addcode, 'spike_remove': spiking_removecode,
-            'rd_add': rd_addcode, 'rd_remove': rd_removecode
+            'rd_add': rd_addcode, 'rd_remove': rd_removecode,
+            'inverse_connectivity_rebuild': inverse_connectivity_code
         }
 
         return code
 
     def _init_random_distributions(self, proj):
         # Is it a specific population?
         if 'init_rng' in proj._specific_template.keys():
             return proj._specific_template['init_rng']
 
         code = ""
         for rd in proj.synapse_type.description['random_distributions']:
             ids = {
                 'id': proj.id,
-                'float_prec': Global.config['precision'],
+                'float_prec': get_global_config('precision'),
                 'global_index': ''
             }
             rd_init = rd['definition'] % ids
             code += """    %(rd_name)s = std::vector< std::vector<double> >(post_rank.size(), std::vector<double>());
     for(int i=0; i<post_rank.size(); i++){
         %(rd_name)s[i] = std::vector<double>(pre_rank[i].size(), 0.0);
     }
@@ -1244,15 +1261,15 @@
 
     def _update_synapse(self, proj):
         """
         Generates the code for the continuous update of synaptic variables of the given projection *proj*.
         """
         prefix = """
         %(idx_type)s rk_post, rk_pre;
-        %(float_prec)s _dt = dt * _update_period;""" % {'idx_type': determine_idx_type_for_projection(proj)[0], 'float_prec': Global.config["precision"]}
+        %(float_prec)s _dt = dt * _update_period;""" % {'idx_type': determine_idx_type_for_projection(proj)[0], 'float_prec': get_global_config('precision')}
 
         # Global variables
         global_eq = generate_equation_code(proj.id, proj.synapse_type.description, 'global', 'proj', padding=2, wrap_w="_plasticity")
 
         # Semiglobal variables
         semiglobal_eq = generate_equation_code(proj.id, proj.synapse_type.description, 'semiglobal', 'proj', padding=2, wrap_w="_plasticity")
 
@@ -1339,15 +1356,15 @@
 
         # Choose the template
         try:
             template = self._templates['update_variables']
 
         except KeyError:
             # either no template code at all, or no 'update_variables' field.
-            Global._error("No synaptic plasticity template found for format = " + proj._storage_format, " and order = " + proj._storage_order)
+            Messages._erroror("No synaptic plasticity template found for format = " + proj._storage_format, " and order = " + proj._storage_order)
 
         template_ids = deepcopy(self._template_ids) # will be extended at the end of this function
         template_ids.update({
             'global': global_eq % self._template_ids,
             'semiglobal': semiglobal_eq % self._template_ids,
             'local': local_eq % self._template_ids,
         })
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/PyxGenerator.py` & `annarchy-4.8.0.1/ANNarchy/generator/PyxGenerator.py`

 * *Files 3% similar despite different names*

```diff
@@ -3,23 +3,26 @@
 :license: GPLv2, see LICENSE for details.
 """
 
 from ANNarchy.core import Global
 from ANNarchy.core.PopulationView import PopulationView
 from ANNarchy.core.Population import Population
 from ANNarchy.core.Projection import Projection
-from ANNarchy.core.SpecificProjection import SpecificProjection
+
 from ANNarchy.extensions.bold import BoldMonitor
 from ANNarchy.extensions.convolution import Transpose
 
-from ANNarchy.generator.Template import PyxTemplate
+from ANNarchy.intern.NetworkManager import NetworkManager
+from ANNarchy.intern.ConfigManagement import get_global_config, _check_paradigm
+from ANNarchy.intern.GlobalObjects import GlobalObjectManager
+from ANNarchy.intern.Profiler import Profiler
 
+from ANNarchy.generator.Template import PyxTemplate
 from ANNarchy.generator.Population import OpenMPTemplates as omp_templates
 from ANNarchy.generator.Population import CUDATemplates as cuda_templates
-
 from ANNarchy.generator.Projection.SingleThread import *
 from ANNarchy.generator.Projection.OpenMP import *
 from ANNarchy.generator.Projection.CUDA import *
 from ANNarchy.generator.Utils import tabify, determine_idx_type_for_projection, cpp_connector_available
 
 class PyxGenerator(object):
     """
@@ -95,21 +98,21 @@
 
         # struct declaration for each monitor
         monitor_struct = "" #self._pyx_struct_monitor()
         for pop in self._populations:
             monitor_struct += self._pop_monitor_struct(pop)
         for proj in self._projections:
             monitor_struct += self._proj_monitor_struct(proj)
-        for mon in Global._network[self._net_id]['monitors']:
+        for mon in NetworkManager().get_monitors(net_id=self._net_id):
             if isinstance(mon, BoldMonitor):
                 mon_dict = {
                     'pop_id': mon.object.id,
                     'pop_name': mon.object.name,
                     'mon_id': mon.id,
-                    'float_prec': Global.config['precision']
+                    'float_prec': get_global_config('precision')
                 }
                 monitor_struct += mon._specific_template['pyx_struct'] % mon_dict
 
         # Cython wrappers for the populations
         pop_class = ""
         for pop in self._populations:
             pop_class += self._pop_wrapper(pop)
@@ -121,25 +124,25 @@
 
         # Cython wrappers for the monitors
         monitor_class = ""
         for pop in self._populations:
             monitor_class += self._pop_monitor_wrapper(pop)
         for proj in self._projections:
             monitor_class += self._proj_monitor_wrapper(proj)
-        for mon in Global._network[self._net_id]['monitors']:
+        for mon in NetworkManager().get_monitors(net_id=self._net_id):
             if isinstance(mon, BoldMonitor):
                 mon_dict = {
                     'pop_id': mon.object.id,
                     'pop_name': mon.object.name,
                     'mon_id': mon.id,
-                    'float_prec': Global.config['precision']
+                    'float_prec': get_global_config('precision')
                 }
                 monitor_class += mon._specific_template['pyx_wrapper'] % mon_dict
 
-        if Global._profiler:
+        if Profiler().enabled:
             prof_class = PyxTemplate.pyx_profiler_template
         else:
             prof_class = ""
 
         from .Template.PyxTemplate import pyx_template
         return pyx_template % {
             'custom_functions_export': custom_functions_export,
@@ -151,88 +154,94 @@
             'proj_ptr': proj_ptr,
             'pop_class' : pop_class,
             'proj_class': proj_class,
             'monitor_struct': monitor_struct,
             'monitor_wrapper': monitor_class,
             'functions_wrapper': functions_wrapper,
             'constants_wrapper': constants_wrapper,
-            'float_prec': Global.config['precision'],
-            'device_specific_export': PyxTemplate.pyx_device_specific[Global.config['paradigm']]['export'],
-            'device_specific_wrapper': PyxTemplate.pyx_device_specific[Global.config['paradigm']]['wrapper'],
+            'float_prec': get_global_config('precision'),
+            'device_specific_export': PyxTemplate.pyx_device_specific[get_global_config('paradigm')]['export'],
+            'device_specific_wrapper': PyxTemplate.pyx_device_specific[get_global_config('paradigm')]['wrapper'],
         }
 
     @staticmethod
     def _get_proj_template(proj):
         """
         Choose the correct template collection dependent on target platform and storage formate.
 
         For example the export of delay related variables.
         """
-        if Global.config['paradigm'] == "openmp":
+        if get_global_config('paradigm') == "openmp":
             if proj._storage_format == "lil":
-                if Global.config['num_threads'] == 1:
+                if get_global_config('num_threads') == 1:
                     return LIL_SingleThread.conn_templates
                 else:
                     if proj._no_split_matrix:
                         return LIL_OpenMP.conn_templates
                     else:
                         return LIL_Sliced_OpenMP.conn_templates
 
             elif proj._storage_format == "coo":
-                if Global.config['num_threads'] == 1:
+                if get_global_config('num_threads') == 1:
                     return COO_SingleThread.conn_templates
                 else:
                     return COO_OpenMP.conn_templates
 
+            elif proj._storage_format == "dia":
+                if get_global_config('num_threads') == 1:
+                    return DIA_SingleThread.conn_templates
+                else:
+                    return DIA_OpenMP.conn_templates
+
             elif proj._storage_format == "bsr":
-                if Global.config['num_threads'] == 1:
+                if get_global_config('num_threads') == 1:
                     return BSR_SingleThread.conn_templates
                 else:
                     return BSR_OpenMP.conn_templates
 
             elif proj._storage_format == "csr":
-                if Global.config['num_threads'] == 1:
+                if get_global_config('num_threads') == 1:
                     return CSR_SingleThread.conn_templates
                 else:
                     return CSR_OpenMP.conn_templates
 
             elif proj._storage_format == "ellr":
-                if Global.config['num_threads'] == 1:
+                if get_global_config('num_threads') == 1:
                     return ELLR_SingleThread.conn_templates
                 else:
                     return ELLR_OpenMP.conn_templates
 
             elif proj._storage_format == "sell":
-                if Global.config['num_threads'] == 1:
+                if get_global_config('num_threads') == 1:
                     return SELL_SingleThread.conn_templates
                 else:
                     return SELL_OpenMP.conn_templates
 
             elif proj._storage_format == "ell":
-                if Global.config['num_threads'] == 1:
+                if get_global_config('num_threads') == 1:
                     return ELL_SingleThread.conn_templates
                 else:
                     return ELL_OpenMP.conn_templates
 
             elif proj._storage_format == "hyb":
-                if Global.config['num_threads'] == 1:
+                if get_global_config('num_threads') == 1:
                     return HYB_SingleThread.conn_templates
                 else:
                     raise NotImplementedError
 
             elif proj._storage_format == "dense":
-                if Global.config['num_threads'] == 1:
+                if get_global_config('num_threads') == 1:
                     return Dense_SingleThread.conn_templates
                 else:
                     return Dense_OpenMP.conn_templates
 
             else:
                 raise Global.InvalidConfiguration("    No python extension definition available for format = "+str(proj._storage_format)+" on CPUs")
 
-        elif Global.config['paradigm'] == "cuda":
+        elif get_global_config('paradigm') == "cuda":
             if proj._storage_format == "bsr":
                 return BSR_CUDA.conn_templates
             elif proj._storage_format == "csr":
                 return CSR_CUDA.conn_templates
             elif proj._storage_format == "csr_scalar":
                 return CSR_SCALAR_CUDA.conn_templates
             elif proj._storage_format == "csr_vector":
@@ -264,19 +273,19 @@
         Generate the Python extension code (export and the wrapper code) dependent
         on the type provided in *obj*.
         """
         desc_list = []
 
         # Check if there are functions where code must be generated
         if obj is None:
-            if (len(Global._objects['functions']) == 0):
+            if GlobalObjectManager().number_functions() == 0:
                 return "", ""
 
             from ANNarchy.parser.Extraction import extract_functions
-            for _, func in Global._objects['functions']:
+            for _, func in GlobalObjectManager().get_functions():
                 desc_list.append(extract_functions(func, local_global=True)[0])
             wrapper_prefix = ""
             export_prefix = "func_"
 
         elif isinstance(obj, Population):
             if (len(obj.neuron_type.description['functions']) == 0):
                 return "", ""
@@ -331,25 +340,25 @@
 
         return export, wrapper
 
 #######################################################################
 ############## Constants  #############################################
 #######################################################################
     def _custom_constants(self):
-        if len(Global._objects['constants']) == 0:
+        if GlobalObjectManager().number_constants() == 0:
             return "", ""
 
         export = ""
         wrapper = ""
-        for obj in Global._objects['constants']:
+        for obj in GlobalObjectManager().get_constants():
             export += """
-    void set_%(name)s(%(float_prec)s)""" % {'name': obj.name, 'float_prec': Global.config['precision']}
+    void set_%(name)s(%(float_prec)s)""" % {'name': obj.name, 'float_prec': get_global_config('precision')}
             wrapper += """
 def _set_%(name)s(%(float_prec)s value):
-    set_%(name)s(value)""" % {'name': obj.name, 'float_prec': Global.config['precision']}
+    set_%(name)s(value)""" % {'name': obj.name, 'float_prec': get_global_config('precision')}
 
         return export, wrapper
 
 
 #######################################################################
 ############## Population #############################################
 #######################################################################
@@ -359,17 +368,17 @@
         Generate population struct definition, mimics the c++ class.
         """
 
         # Spiking neurons have additional data
         export_refractory = ""
         if pop.neuron_type.type == 'spike':
             if pop.neuron_type.refractory or pop.refractory:
-                if Global.config['paradigm'] == "openmp":
+                if get_global_config('paradigm') == "openmp":
                     export_refractory = omp_templates.spike_specific["refractory"]["pyx_export"]
-                elif Global.config['paradigm'] == "cuda":
+                elif get_global_config('paradigm') == "cuda":
                     export_refractory = cuda_templates.spike_specific["refractory"]["pyx_export"]
                 else:
                     raise NotImplementedError
 
         export_parameters_variables = ""
         datatypes = PyxGenerator._get_datatypes(pop)
         # Local parameters and variables
@@ -393,15 +402,15 @@
         export_functions, _ = PyxGenerator._custom_functions(pop)
 
         # Mean firing rate
         export_mean_fr = ""
         if pop.neuron_type.type == 'spike':
             export_mean_fr = """
         # Compute firing rate
-        void compute_firing_rate(%(float_prec)s window)""" %{'float_prec': Global.config['precision']}
+        void compute_firing_rate(%(float_prec)s window)""" %{'float_prec': get_global_config('precision')}
 
         # Additional exports
         export_additional = ""
         if 'export_additional' in pop._specific_template.keys():
             export_additional = pop._specific_template['export_additional']
 
         # Finalize the code
@@ -428,17 +437,17 @@
         wrapper_access_refractory = ""
         wrapper_access_additional = ""
 
 
         # Spiking neurons have aditional data
         if pop.neuron_type.type == 'spike':
             if pop.neuron_type.refractory or pop.refractory:
-                if Global.config['paradigm'] == "openmp":
+                if get_global_config('paradigm') == "openmp":
                     wrapper_access_refractory += omp_templates.spike_specific['refractory']['pyx_wrapper'] % {'id': pop.id}
-                elif Global.config['paradigm'] == "cuda":
+                elif get_global_config('paradigm') == "cuda":
                     wrapper_access_refractory += cuda_templates.spike_specific['refractory']['pyx_wrapper'] % {'id': pop.id}
                 else:
                     raise NotImplementedError
 
         # Attributes
         wrapper_access_parameters_variables = PyxGenerator._pop_generate_default_wrapper(pop)
 
@@ -578,15 +587,15 @@
             if var['method'] == 'event-driven':
                 has_event_driven = True
                 break
 
         # basic
         ids = {
             'id': proj.id,
-            'float_prec': Global.config['precision']
+            'float_prec': get_global_config('precision')
         }
 
         # Check if we need delay code
         has_delay = (proj.max_delay > 1)
         if proj.uniform_delay > 1 :
             key_delay = "uniform"
         else:
@@ -597,27 +606,27 @@
 
         # get the base templates
         template_dict = PyxGenerator._get_proj_template(proj)
 
         # Delay
         export_delay = ""
         if has_delay:
-            if Global.config['paradigm'] == "openmp":
+            if get_global_config('paradigm') == "openmp":
                 export_delay = template_dict['delay'][key_delay]['pyx_struct'] % ids
-            elif Global.config['paradigm'] == "cuda":
+            elif get_global_config('paradigm') == "cuda":
                 export_delay = template_dict['delay'][key_delay]['pyx_struct'] % ids
             else:
                 raise NotImplementedError
 
         # Event-driven
         export_event_driven = ""
         if has_event_driven:
-            if Global.config['paradigm'] == "openmp":
+            if get_global_config('paradigm') == "openmp":
                 export_event_driven = template_dict['event_driven']['pyx_struct']
-            elif Global.config['paradigm'] == "cuda":
+            elif get_global_config('paradigm') == "cuda":
                 export_event_driven = template_dict['event_driven']['pyx_struct']
             else:
                 raise NotImplementedError
 
         # Determine all export methods
         export_parameters_variables = ""
 
@@ -650,15 +659,15 @@
                 }
 
         # Local functions
         export_functions, _ = PyxGenerator._custom_functions(proj)
 
         # Structural plasticity
         structural_plasticity = ""
-        if Global.config['structural_plasticity']:
+        if get_global_config('structural_plasticity'):
             sp_tpl = template_dict['structural_plasticity']['pyx_struct']
 
             # Pruning in the synapse
             if 'pruning' in proj.synapse_type.description.keys():
                 structural_plasticity += sp_tpl['pruning']
             if 'creating' in proj.synapse_type.description.keys():
                 structural_plasticity += sp_tpl['creating']
@@ -666,30 +675,32 @@
             # Retrieve the names of extra attributes
             extra_args = ""
             for var in proj.synapse_type.description['parameters'] + proj.synapse_type.description['variables']:
                 if not var['name'] in ['w', 'delay'] and  var['name'] in proj.synapse_type.description['local']:
                     extra_args += ', ' + var['ctype'] + ' ' +  var['name']
             # Generate the code
             structural_plasticity += sp_tpl['func'] % {'extra_args': extra_args}
+            if proj.synapse_type.type == "spike":
+                structural_plasticity += " "*8 + "void check_and_rebuild_inverse_connectivity()\n"
 
         # Check if either a custom definition or a CPP side init
         # is available otherwise fall back to init from LIL
         if proj.connector_name == "All-to-All" and cpp_connector_available("All-to-All", proj._storage_format, proj._storage_order):
             export_connector = tabify("bool all_to_all_pattern(vector[%(idx_type)s], vector[%(idx_type)s], %(float_prec)s, %(float_prec)s, %(float_prec)s, %(float_prec)s, bool)", 2)
         elif proj.connector_name == "Random" and cpp_connector_available("Random", proj._storage_format, proj._storage_order):
             export_connector = tabify("bool fixed_probability_pattern(vector[%(idx_type)s], vector[%(idx_type)s], %(float_prec)s, %(float_prec)s, %(float_prec)s, %(float_prec)s, %(float_prec)s, bool)", 2)
         elif proj.connector_name == "Random Convergent" and cpp_connector_available("Random Convergent", proj._storage_format, proj._storage_order):
             export_connector = tabify("bool fixed_number_pre_pattern(vector[%(idx_type)s], vector[%(idx_type)s], %(idx_type)s, %(float_prec)s, %(float_prec)s, %(float_prec)s, %(float_prec)s)", 2)
         else:
-            export_connector = tabify("bool init_from_lil(vector[%(idx_type)s], vector[vector[%(idx_type)s]], vector[vector[%(float_prec)s]], vector[vector[int]])", 2)
+            export_connector = tabify("bool init_from_lil(vector[%(idx_type)s], vector[vector[%(idx_type)s]], vector[vector[%(float_prec)s]], vector[vector[int]], bool)", 2)
 
-        # Data types, only of interest if Global.config["only_int_idx_type"] is false
+        # Data types, only of interest if "only_int_idx_type" configuration flag is false
         idx_types = determine_idx_type_for_projection(proj)
         idx_type_dict = {
-            'float_prec': Global.config["precision"],
+            'float_prec': get_global_config('precision'),
             'idx_type': idx_types[1],
             'size_type': idx_types[3]
         }
 
         # Default LIL Definition/ Accessors
         # with an additional accessor spike
         default_conn_export = PyxTemplate.pyx_default_conn_export
@@ -710,15 +721,15 @@
         if 'export_event_driven' in proj._specific_template.keys() and has_event_driven:
             export_event_driven = proj._specific_template['export_event_driven']
         if 'export_parameters_variables' in proj._specific_template.keys():
             export_parameters_variables = proj._specific_template['export_parameters_variables']
 
         # CUDA configuration update
         export_cuda_launch_config = ""
-        if Global._check_paradigm("cuda"):
+        if _check_paradigm("cuda"):
             export_cuda_launch_config = tabify("void update_launch_config(int, int)", 2)
 
         return PyxTemplate.proj_pyx_struct % {
             'id_proj': proj.id,
             'export_connectivity': export_connector+export_connector_access,
             'export_delay': export_delay,
             'export_event_driven': export_event_driven,
@@ -751,15 +762,15 @@
             if var['method'] == 'event-driven':
                 has_event_driven = True
                 break
 
         # basic
         ids = {
             'id_proj': proj.id,
-            'float_prec': Global.config['precision']
+            'float_prec': get_global_config('precision')
         }
 
         # Check if we need delay code
         has_delay = (proj.max_delay > 1)
         if proj.uniform_delay > 1 :
             key_delay = "uniform"
         else:
@@ -789,16 +800,16 @@
 
 
         # Additional declarations
         additional_declarations = ""
 
         # Structural plasticity
         structural_plasticity = ""
-        if Global.config['structural_plasticity']:
-            if Global.config['paradigm'] == "openmp":
+        if get_global_config('structural_plasticity'):
+            if get_global_config('paradigm') == "openmp":
                 sp_tpl = template_dict['structural_plasticity']['pyx_wrapper']
             else:
                 sp_tpl = {}
 
             # Pruning in the synapse
             if 'pruning' in proj.synapse_type.description.keys():
                 structural_plasticity += sp_tpl['pruning'] % {'id' : proj.id}
@@ -813,14 +824,18 @@
             for var in proj.synapse_type.description['parameters'] + proj.synapse_type.description['variables']:
                 if not var['name'] in ['w', 'delay'] and  var['name'] in proj.synapse_type.description['local']:
                     extra_args += ', ' + var['ctype'] + ' ' +  var['name']
                     extra_values += ', ' +  var['name']
 
             # Generate the code
             structural_plasticity += sp_tpl['func'] % {'id' : proj.id, 'extra_args': extra_args, 'extra_values': extra_values}
+            if proj.synapse_type.type == 'spike':
+                structural_plasticity += """    def check_and_rebuild_inverse_connectivity(self):
+        proj%(id_proj)s.check_and_rebuild_inverse_connectivity()
+""" % {'id_proj': proj.id}
 
         # Check if either a custom definition or a CPP side init
         # is available otherwise fall back to init from LIL
         if proj.connector_name == "All-to-All" and cpp_connector_available("All-to-All", proj._storage_format, proj._storage_order):
             wrapper_connector_call = """
     def all_to_all(self, post_ranks, pre_ranks, w_dist_arg1, w_dist_arg2, d_dist_arg1, d_dist_arg2, allow_self_connections):
         return proj%(id_proj)s.all_to_all_pattern(post_ranks, pre_ranks, w_dist_arg1, w_dist_arg2, d_dist_arg1, d_dist_arg2, allow_self_connections)
@@ -835,18 +850,18 @@
     def fixed_number_pre(self, post_ranks, pre_ranks, number_synapses_per_row, w_dist_arg1, w_dist_arg2, d_dist_arg1, d_dist_arg2):
         return proj%(id_proj)s.fixed_number_pre_pattern(post_ranks, pre_ranks, number_synapses_per_row, w_dist_arg1, w_dist_arg2, d_dist_arg1, d_dist_arg2)
 """ % {'id_proj': proj.id}
         else:
             wrapper_connector_call = """
     def init_from_lil_connectivity(self, synapses):
         " synapses is an instance of LILConnectivity "
-        return proj%(id_proj)s.init_from_lil(synapses.post_rank, synapses.pre_rank, synapses.w, synapses.delay)
+        return proj%(id_proj)s.init_from_lil(synapses.post_rank, synapses.pre_rank, synapses.w, synapses.delay, synapses.requires_sorting)
 
-    def init_from_lil(self, post_rank, pre_rank, w, delay):
-        return proj%(id_proj)s.init_from_lil(post_rank, pre_rank, w, delay)
+    def init_from_lil(self, post_rank, pre_rank, w, delay, requires_sorting):
+        return proj%(id_proj)s.init_from_lil(post_rank, pre_rank, w, delay, requires_sorting)
 """ % {'id_proj': proj.id}
 
         wrapper_args = ""
         wrapper_init = tabify("pass",3)
         wrapper_access_connectivity = PyxTemplate.pyx_default_conn_wrapper 
         if proj.synapse_type.type == "spike":   # additional for spike
             wrapper_access_connectivity += """
@@ -871,15 +886,15 @@
         if 'wrapper_access_parameters_variables' in proj._specific_template.keys():
             wrapper_access_parameters_variables = proj._specific_template['wrapper_access_parameters_variables']
         if 'wrapper_access_additional' in proj._specific_template.keys():
             additional_declarations = proj._specific_template['wrapper_access_additional']
 
         # CUDA configuration update
         wrapper_cuda_launch_config = ""
-        if Global._check_paradigm("cuda"):
+        if _check_paradigm("cuda"):
             wrapper_cuda_launch_config = """
     def update_launch_config(self, nb_blocks=-1, threads_per_block=32):
         proj%(id_proj)s.update_launch_config(nb_blocks, threads_per_block)
 """ % {'id_proj': proj.id}
 
         return PyxTemplate.proj_pyx_wrapper % {
             'id_proj': proj.id,
@@ -1079,15 +1094,15 @@
         if pop.neuron_type.type == 'rate':
             tpl_code += """
         # Targets"""
             for target in sorted(list(set(pop.neuron_type.description['targets'] + pop.targets))):
                 tpl_code += """
         vector[vector[%(float_prec)s]] _sum_%(target)s
         bool record__sum_%(target)s
-""" % {'target': target, 'float_prec': Global.config['precision']}
+""" % {'target': target, 'float_prec': get_global_config('precision')}
 
         return tpl_code % {'id' : pop.id, 'name': pop.name}
 
     @staticmethod
     def _pop_monitor_wrapper(pop):
         """
         Generate recorder wrapper.
@@ -1291,14 +1306,18 @@
 
         elif isinstance(obj, Population):
             datatypes = {
                 'local': [],
                 'global': []
             }
 
+            if obj.neuron_type.type == 'spike':
+                if 'int' not in datatypes['local']:
+                    datatypes['local'].append('int')
+
             for var in obj.neuron_type.description['parameters'] + obj.neuron_type.description['variables']:
                 locality = var['locality']
                 if var['ctype'] not in datatypes[locality]:
                     datatypes[locality].append(var['ctype'])
 
         else:
             ValueError("PyxGenerator._get_datatypes() expects either Population or Projection instance.")
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Sanity.py` & `annarchy-4.8.0.1/ANNarchy/generator/Sanity.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 import re
 
-from ANNarchy.core import Global
-from ANNarchy.core.PopulationView import PopulationView
-from ANNarchy.core.SpecificProjection import SpecificProjection
+from ANNarchy.intern.SpecificProjection import SpecificProjection
+from ANNarchy.intern.ConfigManagement import get_global_config, _check_paradigm
+from ANNarchy.intern import Messages
 from ANNarchy.models.Synapses import DefaultSpikingSynapse, DefaultRateCodedSynapse
 
 # No variable can have these names
 reserved_variables = [
     't',
     'dt',
     't_pre',
@@ -38,15 +38,15 @@
 
     # Check that projections are created before compile
     for proj in projections:
         if isinstance(proj, Transpose):
             continue
 
         if not proj._connection_method:
-            Global._error('The projection between populations', proj.pre.id, 'and', proj.post.id, 'has not been connected.',
+            Messages._error('The projection between populations', proj.pre.id, 'and', proj.post.id, 'has not been connected.',
                             ' Call a connector method before compiling the network.')
 
     # Check if the storage formats are valid for the selected paradigm
     _check_storage_formats(projections)
 
     # Check that synapses access existing variables in the pre or post neurons
     _check_prepost(populations, projections)
@@ -56,234 +56,246 @@
 
 def check_experimental_features(populations, projections):
     """
     The idea behind this method, is to check if new experimental features are used. This
     should help also the user to be aware of changes.
     """
     # CPU-related formats
-    if Global.config['paradigm'] == "openmp":
+    if get_global_config('paradigm') == "openmp":
         for proj in projections:
             if proj._storage_format == "csr" and proj._storage_order == "pre_to_post":
-                Global._warning("Compressed sparse row (CSR) and pre_to_post ordering representation is an experimental feature, we greatly appreciate bug reports.")
+                Messages._warning("Compressed sparse row (CSR) and pre_to_post ordering representation is an experimental feature, we greatly appreciate bug reports.")
                 break
 
         for proj in projections:
             if proj._storage_format == "bsr":
-                Global._warning("Blocked sparse row (BSR) representation is an experimental feature, we greatly appreciate bug reports.")
+                Messages._warning("Blocked sparse row (BSR) representation is an experimental feature, we greatly appreciate bug reports.")
                 break
 
         for proj in projections:
             if proj._storage_format == "coo":
-                Global._warning("Coordinate (COO) representation is an experimental feature, we greatly appreciate bug reports.")
+                Messages._warning("Coordinate (COO) representation is an experimental feature, we greatly appreciate bug reports.")
+                break
+
+        for proj in projections:
+            if proj._storage_format == "dia":
+                Messages._warning("Diagonal (dia) representation is an experimental feature, we greatly appreciate bug reports.")
                 break
 
         for proj in projections:
             if proj._storage_format == "ellr":
-                Global._warning("ELLPACK-R (ELLR) representation is an experimental feature, we greatly appreciate bug reports.")
+                Messages._warning("ELLPACK-R (ELLR) representation is an experimental feature, we greatly appreciate bug reports.")
                 break
 
         for proj in projections:
             if proj._storage_format == "sell":
-                Global._warning("Sliced ELLPACK (SELL) representation is an experimental feature, we greatly appreciate bug reports.")
+                Messages._warning("Sliced ELLPACK (SELL) representation is an experimental feature, we greatly appreciate bug reports.")
                 break
 
         for proj in projections:
             if proj._storage_format == "ell":
-                Global._warning("ELLPACK (ELL) representation is an experimental feature, we greatly appreciate bug reports.")
+                Messages._warning("ELLPACK (ELL) representation is an experimental feature, we greatly appreciate bug reports.")
                 break
 
         for proj in projections:
             if proj._storage_format == "hyb":
-                Global._warning("Hybrid (ELL + COO) representation is an experimental feature, we greatly appreciate bug reports.")
+                Messages._warning("Hybrid (ELL + COO) representation is an experimental feature, we greatly appreciate bug reports.")
                 break
 
         for proj in projections:
             if proj._storage_format == "dense" and proj.synapse_type.type=="spike":
-                Global._warning("Dense representation is an experimental feature for spiking models, we greatly appreciate bug reports.")
+                Messages._warning("Dense representation is an experimental feature for spiking models, we greatly appreciate bug reports.")
                 break
 
     # GPU-related formats
-    elif Global.config['paradigm'] == "cuda":
+    elif get_global_config('paradigm') == "cuda":
         for pop in populations:
             if pop.neuron_type.description['type'] == "spike":
-                Global._warning('Spiking neurons on GPUs is an experimental feature. We greatly appreciate bug reports.')
+                Messages._warning('Spiking neurons on GPUs is an experimental feature. We greatly appreciate bug reports.')
                 break
 
         for proj in projections:
             if proj._storage_format == "dense":
-                Global._warning("Dense representation is an experimental feature, we greatly appreciate bug reports.")
+                Messages._warning("Dense representation is an experimental feature, we greatly appreciate bug reports.")
                 break
 
         for proj in projections:
             if proj._storage_format == "sell":
-                Global._warning("Sliced ELLPACK representation is an experimental feature, we greatly appreciate bug reports.")
+                Messages._warning("Sliced ELLPACK representation is an experimental feature, we greatly appreciate bug reports.")
                 break
 
         for proj in projections:
             if proj._storage_format == "ellr":
-                Global._warning("ELLPACK-R (ELLR) representation is an experimental feature, we greatly appreciate bug reports.")
+                Messages._warning("ELLPACK-R (ELLR) representation is an experimental feature, we greatly appreciate bug reports.")
                 break
 
         for proj in projections:
             if proj._storage_format == "bsr":
-                Global._warning("Blocked sparse row (BSR) representation is an experimental feature, we greatly appreciate bug reports.")
+                Messages._warning("Blocked sparse row (BSR) representation is an experimental feature, we greatly appreciate bug reports.")
                 break
 
         for proj in projections:
             if proj._storage_format == "coo":
-                Global._warning("Coordinate (COO) representation is an experimental feature, we greatly appreciate bug reports.")
+                Messages._warning("Coordinate (COO) representation is an experimental feature, we greatly appreciate bug reports.")
                 break
 
         for proj in projections:
             if proj._storage_format == "hyb":
-                Global._warning("Hybrid (ELL + COO) representation is an experimental feature, we greatly appreciate bug reports.")
+                Messages._warning("Hybrid (ELL + COO) representation is an experimental feature, we greatly appreciate bug reports.")
                 break
 
     else:
         pass
 
 def _check_reserved_names(populations, projections):
     """
     Checks no reserved variable names is redefined
     """
     # Check populations
     for pop in populations:
         # Reserved variable names
         for term in reserved_variables:
             if term in pop.attributes:
-                Global._print(pop.neuron_type.parameters)
-                Global._print(pop.neuron_type.equations)
-                Global._error(term + ' is a reserved variable name')
+                Messages._print(pop.neuron_type.parameters)
+                Messages._print(pop.neuron_type.equations)
+                Messages._error(term + ' is a reserved variable name')
 
     # Check projections
     for proj in projections:
         # Reserved variable names
         for term in reserved_variables:
             if term in proj.attributes:
-                Global._print(proj.synapse_type.parameters)
-                Global._print(proj.synapse_type.equations)
-                Global._error(term + ' is a reserved variable name')
+                Messages._print(proj.synapse_type.parameters)
+                Messages._print(proj.synapse_type.equations)
+                Messages._error(term + ' is a reserved variable name')
 
 def _check_storage_formats(projections):
     """
     ANNarchy 4.7 introduced a set of sparse matrix formats. Some of them are not implemented for
     all paradigms or might not support specific optimizations.
     """
     for proj in projections:
         # Most of the sparse matrix formats are not trivially invertable and therefore we can not implement
         # spiking models with them
-        if proj.synapse_type.type == "spike" and proj._storage_format in ["csr_vector", "csr_scalar", "ell", "ellr", "coo", "hyb"]:
-            raise Global.ANNarchyException("Using 'storage_format="+ proj._storage_format + "' is not allowed for spiking synapses.", True)
+        if proj.synapse_type.type == "spike" and proj._storage_format in ["csr_vector", "csr_scalar", "ell", "ellr", "coo", "hyb", "dia"]:
+            raise Messages.ANNarchyException("Using 'storage_format="+ proj._storage_format + "' is not allowed for spiking synapses.", True)
 
         # For some of the sparse matrix formats we don't implemented plasticity yet.
         if proj.synapse_type.type == "spike":
-            if Global._check_paradigm("cuda") and proj._storage_format in ["csr"] and proj._storage_order=="pre_to_post" and not isinstance(proj.synapse_type, DefaultSpikingSynapse):
-                raise Global.ANNarchyException("Using 'storage_format="+ proj._storage_format + "' and 'storage_order="+ proj._storage_order + "' is on GPUs only allowed for default spiking synapses yet.", True)
+            if _check_paradigm("cuda") and proj._storage_format in ["csr"] and proj._storage_order=="pre_to_post" and not isinstance(proj.synapse_type, DefaultSpikingSynapse):
+                raise Messages.ANNarchyException("Using 'storage_format="+ proj._storage_format + "' and 'storage_order="+ proj._storage_order + "' is on GPUs only allowed for default spiking synapses yet.", True)
 
             # Continous transmission, e.g. gap junctions, should not be combined with pre-to-post
             if 'psp' in  proj.synapse_type.description.keys() and proj._storage_order=="pre_to_post":
-                raise Global.ANNarchyException("Using continuous transmission within a spiking synapse prevents the application of pre-to-post matrix ordering", True)
+                raise Messages.ANNarchyException("Using continuous transmission within a spiking synapse prevents the application of pre-to-post matrix ordering", True)
 
         # For some of the sparse matrix formats we don't implemented plasticity for rate-coded models yet.
         if proj.synapse_type.type == "rate":
-            if Global._check_paradigm("openmp"):
-                if proj._storage_format in ["coo", "hyb", "bsr", "sell"] and not isinstance(proj.synapse_type, DefaultRateCodedSynapse):
-                    raise Global.ANNarchyException("Using 'storage_format="+ proj._storage_format + "' is only allowed for default rate-coded synapses yet.", True)
-            elif Global._check_paradigm("cuda"):
+            if _check_paradigm("openmp"):
+                if proj._storage_format in ["coo", "hyb", "bsr", "sell", "dia"] and not isinstance(proj.synapse_type, DefaultRateCodedSynapse):
+                    raise Messages.ANNarchyException("Using 'storage_format="+ proj._storage_format + "' is only allowed for default rate-coded synapses yet.", True)
+            elif _check_paradigm("cuda"):
                 if proj._storage_format in ["coo", "hyb", "bsr", "ell", "sell", "csr_vector", "csr_scalar"] and not isinstance(proj.synapse_type, DefaultRateCodedSynapse):
-                    raise Global.ANNarchyException("Using 'storage_format="+ proj._storage_format + "' is only allowed for default rate-coded synapses yet.", True)
+                    raise Messages.ANNarchyException("Using 'storage_format="+ proj._storage_format + "' is only allowed for default rate-coded synapses yet.", True)
 
         # Single weight optimization available?
         if proj._has_single_weight() and proj._storage_format in ["dense", "bsr"]:
-            raise Global.ANNarchyException("Using 'storage_format="+ proj._storage_format + "' is not allowed for single weight projections.", True)
+            raise Messages.ANNarchyException("Using 'storage_format="+ proj._storage_format + "' is not allowed for single weight projections.", True)
 
         # In some cases we don't allow the usage of non-unifom delay
         if (proj.max_delay > 1 and proj.uniform_delay == -1):
-            if Global._check_paradigm("cuda"):
-                raise Global.ANNarchyException("Using non-uniform delays is not available for CUDA devices.", True)
+            if _check_paradigm("cuda"):
+                raise Messages.ANNarchyException("Using non-uniform delays is not available for CUDA devices.", True)
 
             else:
                 if proj._storage_format == "ellr":
-                    raise Global.ANNarchyException("Using 'storage_format="+ proj._storage_format + "' is and non-uniform delays is not implemented.", True)
+                    raise Messages.ANNarchyException("Using 'storage_format="+ proj._storage_format + "' is and non-uniform delays is not implemented.", True)
 
-        if not Global._check_paradigm("cuda") and (proj._storage_format in ["csr_scalar", "csr_vector"]):
-            Global._error("The CSR variants csr_scalar/csr_vector are only intended for GPUs.")
+        if proj._storage_format == "dia":
+            if _check_paradigm("cuda"):
+                raise Messages.ANNarchyException('Using diagonal format is limited to CPUs yet.')
 
-        if Global._check_paradigm("cuda") and proj._storage_format == "lil":
+            if proj.pre.size < proj.post.size:
+                raise Messages.ANNarchyException('Using diagonal format is not implemented for projections where the post-synaptic layer is smaller than the pre-synaptic one.')
+
+        if not _check_paradigm("cuda") and (proj._storage_format in ["csr_scalar", "csr_vector"]):
+            Messages._error("The CSR variants csr_scalar/csr_vector are only intended for GPUs.")
+
+        if _check_paradigm("cuda") and proj._storage_format == "lil":
             proj._storage_format = "csr"
             if not isinstance(proj, SpecificProjection):
-                Global._info("LIL-type projections are not available for GPU devices ... default to CSR")
-
-        if Global._check_paradigm("cuda") and proj._storage_format == "ell":
-            Global._info("We would recommend to use ELLPACK-R (format=ellr) on GPUs.")
+                Messages._info("LIL-type projections are not available for GPU devices ... default to CSR")
 
+        if _check_paradigm("cuda") and proj._storage_format == "ell":
+            Messages._info("We would recommend to use ELLPACK-R (format=ellr) on GPUs.")
+        
 def _check_prepost(populations, projections):
     """
     Checks that when a synapse uses pre.x r post.x, the variable x exists in the corresponding neuron
     """
     for proj in projections:
 
         for dep in  proj.synapse_type.description['dependencies']['pre']:
             if dep.startswith('sum('):
                 target = re.findall(r'\(([\s\w]+)\)', dep)[0].strip()
                 if not target in proj.pre.targets:
-                    Global._print(proj.synapse_type.equations)
-                    Global._error('The pre-synaptic population ' + proj.pre.name + ' receives no projection with the type ' + target)
+                    Messages._print(proj.synapse_type.equations)
+                    Messages._error('The pre-synaptic population ' + proj.pre.name + ' receives no projection with the type ' + target)
                 continue
 
             if not dep in proj.pre.attributes:
-                Global._print(proj.synapse_type.equations)
-                Global._error('The pre-synaptic population ' + proj.pre.name + ' has no variable called ' + dep)
+                Messages._print(proj.synapse_type.equations)
+                Messages._error('The pre-synaptic population ' + proj.pre.name + ' has no variable called ' + dep)
 
         for dep in proj.synapse_type.description['dependencies']['post']:
             if dep.startswith('sum('):
                 target = re.findall(r'\(([\s\w]+)\)', dep)[0].strip()
                 if not target in proj.post.targets:
-                    Global._print(proj.synapse_type.equations)
-                    Global._error('The post-synaptic population ' + proj.post.name + ' receives no projection with the type ' + target)
+                    Messages._print(proj.synapse_type.equations)
+                    Messages._error('The post-synaptic population ' + proj.post.name + ' receives no projection with the type ' + target)
                 continue
 
             if not dep in proj.post.attributes:
-                Global._print(proj.synapse_type.equations)
-                Global._error('The post-synaptic population ' + proj.post.name + ' has no variable called ' + dep)
+                Messages._print(proj.synapse_type.equations)
+                Messages._error('The post-synaptic population ' + proj.post.name + ' has no variable called ' + dep)
 
 
 def _check_locality(populations, projections):
     """
     Checks that a global variable does not depend on local ones.
     """
     for proj in projections:
 
         for var in proj.synapse_type.description['variables']:
 
             if var['locality'] == 'global': # cannot depend on local or semiglobal variables
                 # Inside the equation
                 for v in var['dependencies']:
                     if _get_locality(v, proj.synapse_type.description) in ['local', 'semiglobal']:
-                        Global._print(var['eq'])
-                        Global._error('The global variable', var['name'], 'cannot depend on a synapse-specific/post-synaptic one:', v)
+                        Messages._print(var['eq'])
+                        Messages._error('The global variable', var['name'], 'cannot depend on a synapse-specific/post-synaptic one:', v)
 
                 # As pre/post dependencies
                 deps = var['prepost_dependencies']
                 if len(deps['pre']) > 0 or len(deps['post']) > 0 : 
-                    Global._print(proj.synapse_type.equations)
-                    Global._error('The global variable', var['name'], 'cannot depend on pre- or post-synaptic variables.')
+                    Messages._print(proj.synapse_type.equations)
+                    Messages._error('The global variable', var['name'], 'cannot depend on pre- or post-synaptic variables.')
 
             if var['locality'] == 'semiglobal': # cannot depend on pre-synaptic variables
                 # Inside the equation
                 for v in var['dependencies']:
                     if _get_locality(v, proj.synapse_type.description) == 'local':
-                        Global._print(var['eq'])
-                        Global._error('The postsynaptic variable', var['name'], 'cannot depend on a synapse-specific one:', v)
+                        Messages._print(var['eq'])
+                        Messages._error('The postsynaptic variable', var['name'], 'cannot depend on a synapse-specific one:', v)
 
                 # As pre/post dependencies
                 deps = var['prepost_dependencies']
                 if len(deps['pre']) > 0  : 
-                    Global._print(proj.synapse_type.equations)
-                    Global._error('The postsynaptic variable', var['name'], 'cannot depend on pre-synaptic ones (e.g. pre.r).')
+                    Messages._print(proj.synapse_type.equations)
+                    Messages._error('The postsynaptic variable', var['name'], 'cannot depend on pre-synaptic ones (e.g. pre.r).')
 
 
 def _get_locality(name, description):
     "Returns the locality of an attribute based on its name"
     for var in description['variables'] + description['parameters']:
         if var['name'] == name:
             return var['locality']
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Template/BaseTemplate.py` & `annarchy-4.8.0.1/ANNarchy/generator/Template/BaseTemplate.py`

 * *Files 2% similar despite different names*

```diff
@@ -301,33 +301,43 @@
 // Simulate the network for the given number of steps,
 // called from python
 void run(const int nbSteps) {
 #ifdef _TRACE_SIMULATION_STEPS
     std::cout << "Perform simulation for " << nbSteps << " steps." << std::endl;
 #endif
 %(prof_run_pre)s
+    // apply changes implied by structural plasticity (spike only)
+%(sp_spike_backward_view_update)s
+
+    // perform the simulation
     for(int i=0; i<nbSteps; i++) {
         singleStep();
     }
 %(prof_run_post)s
 }
 
 // Simulate the network for a single steps,
 // called from python
 void step() {
 %(prof_run_pre)s
+    // apply changes implied by structural plasticity (spike only)
+%(sp_spike_backward_view_update)s
+
+    // perform a single step (size dt)
     singleStep();
 %(prof_run_post)s
 }
 
 int run_until(const int steps, std::vector<int> populations, bool or_and)
 {
+    // apply changes implied by structural plasticity (spike only)
+%(sp_spike_backward_view_update)s
 
+    // perform the simulation until the condition is satisfied
 %(run_until)s
-
 }
 
 /*
  *  Initialization methods
  */
 // Initialize the internal data and the random numbers generator
 void initialize(const %(float_prec)s _dt) {
@@ -637,15 +647,22 @@
     }
 #endif
 }
 
 // Simulate the network for the given number of steps,
 // called from python
 void run(const int nbSteps) {
+#ifdef _TRACE_SIMULATION_STEPS
+    std::cout << "Perform simulation for " << nbSteps << " steps." << std::endl;
+#endif
 %(prof_run_pre)s
+    // apply changes implied by structural plasticity (spike only)
+%(sp_spike_backward_view_update)s
+
+    // perform the simulation
     #pragma omp parallel num_threads(global_num_threads)
     {
         int tid = omp_get_thread_num();
 
         for (int i=0; i<nbSteps; i++) {
             singleStep(tid, global_num_threads);
         }
@@ -654,28 +671,34 @@
 %(prof_run_post)s
 }
 
 // Simulate the network for a single steps,
 // called from python
 void step() {
 %(prof_run_pre)s
+    // apply changes implied by structural plasticity (spike only)
+%(sp_spike_backward_view_update)s
+
+    // perform a single step (size dt)
     #pragma omp parallel num_threads(global_num_threads)
     {
         int tid = omp_get_thread_num();
 
         singleStep(tid, global_num_threads);
     }
 %(prof_run_post)s
 }
 
 int run_until(const int steps, std::vector<int> populations, bool or_and)
 {
+    // apply changes implied by structural plasticity (spike only)
+%(sp_spike_backward_view_update)s
 
+    // perform the simulation until the condition is satisfied
 %(run_until)s
-
 }
 
 /*
  *  Initialization methods
  */
 // Initialize the internal data and the random numbers generator
 void initialize(const %(float_prec)s _dt) {
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Template/GlobalOperationTemplate.py` & `annarchy-4.8.0.1/ANNarchy/generator/Template/GlobalOperationTemplate.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Template/MakefileTemplate.py` & `annarchy-4.8.0.1/ANNarchy/generator/Template/MakefileTemplate.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Template/MonitorTemplate.py` & `annarchy-4.8.0.1/ANNarchy/generator/Template/MonitorTemplate.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Template/PyxTemplate.py` & `annarchy-4.8.0.1/ANNarchy/generator/Template/PyxTemplate.py`

 * *Files 11% similar despite different names*

```diff
@@ -8,25 +8,26 @@
 from libcpp.vector cimport vector
 from libcpp.map cimport map, pair
 from libcpp cimport bool
 from libcpp.string cimport string
 from math import ceil
 import numpy as np
 import sys
+from tqdm import tqdm
 cimport numpy as np
 cimport cython
 
 # Short names for unsigned integer types
 ctypedef unsigned char _ann_uint8
 ctypedef unsigned short _ann_uint16
 ctypedef unsigned int _ann_uint32
 ctypedef unsigned long _ann_uint64
 
 import ANNarchy
-from ANNarchy.core.cython_ext.Connector cimport LILConnectivity as LIL
+from ANNarchy.cython_ext.Connector cimport LILConnectivity as LIL
 
 cdef extern from "ANNarchy.h":
 
     # User-defined functions
 %(custom_functions_export)s
 
     # User-defined constants
@@ -91,55 +92,39 @@
 def pyx_create():
     create_cpp_instances()
 def pyx_initialize(%(float_prec)s dt):
     initialize(dt)
 def pyx_destroy():
     destroy_cpp_instances()
 
-# Simple progressbar on the command line
-def progress(count, total, status=''):
-    """
-    Prints a progress bar on the command line.
-
-    adapted from: https://gist.github.com/vladignatyev/06860ec2040cb497f0f3
-
-    Modification: The original code set the '\\r' at the end, so the bar disappears when finished.
-    I moved it to the front, so the last status remains.
-    """
-    bar_len = 60
-    filled_len = int(round(bar_len * count / float(total)))
-
-    percents = round(100.0 * count / float(total), 1)
-    bar = '=' * filled_len + '-' * (bar_len - filled_len)
-
-    sys.stdout.write('\\r[%%s] %%s%%s ...%%s' %% (bar, percents, '%%', status))
-    sys.stdout.flush()
-
 # Simulation for the given number of steps
 def pyx_run(int nb_steps, progress_bar):
     cdef int nb, rest
     cdef int batch = 1000
     if nb_steps < batch:
         with nogil:
             run(nb_steps)
     else:
         nb = int(nb_steps/batch)
         rest = nb_steps %% batch
+
+        if progress_bar:
+            pbar = tqdm(total=nb_steps*getDt())
         for i in range(nb):
             with nogil:
                 run(batch)
             PyErr_CheckSignals()
-            if nb > 1 and progress_bar:
-                progress(i+1, nb, 'simulate()')
+            if progress_bar:
+                pbar.update(batch*getDt())
+        if progress_bar:
+            pbar.close()
+
         if rest > 0:
             run(rest)
 
-        if (progress_bar):
-            print('\\n')
-
 # Simulation for the given number of steps except if a criterion is reached
 def pyx_run_until(int nb_steps, list populations, bool mode):
     cdef int nb
     nb = run_until(nb_steps, populations, mode)
     return nb
 
 # Simulate for one step
```

### Comparing `ANNarchy-4.7.3/ANNarchy/generator/Utils.py` & `annarchy-4.8.0.1/ANNarchy/generator/Utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -2,14 +2,17 @@
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 from ANNarchy.core import Global
 from ANNarchy.core.PopulationView import PopulationView
 
+from ANNarchy.intern.ConfigManagement import get_global_config, _check_paradigm
+from ANNarchy.intern import Messages
+
 import re
 import subprocess
 import sys
 
 def sort_odes(desc, locality='local'):
     equations = []
     is_ode = False
@@ -210,26 +213,26 @@
     It appears to a problem for the current Cython version to handle
     datatypes like "unsigned int". So I decided to replace the unsigned
     datatypes by an own definition. These definitions are placed in
 
     *ANNarchy/generator/Template/PyxTemplate.py*
     """
     # The user disabled this optimization.
-    if Global.config["only_int_idx_type"]:
+    if get_global_config('only_int_idx_type'):
         return "int", "int", "int", "int"
 
     # Currently only implemented for some cases,
     # the others default to "old" configuration
     if proj.synapse_type.type == "spike":
         return "int", "int", "int", "int"
 
-    if Global._check_paradigm("cuda"):
+    if _check_paradigm("cuda"):
         return "int", "int", "int", "int"
 
-    if proj._storage_format != "lil" and Global.config["num_threads"]>1:
+    if proj._storage_format != "lil" and get_global_config('num_threads')>1:
         return "int", "int", "int", "int"
 
     # max_size is related to the population sizes. As we use one type for
     # both dimension we need to determine the maximum
     pre_size = proj.pre.population.size if isinstance(proj.pre, PopulationView) else proj.pre.size
     post_size = proj.post.population.size if isinstance(proj.post, PopulationView) else proj.post.size
     max_size_one_dim = max(pre_size, post_size)
@@ -284,15 +287,15 @@
 def cpp_connector_available(connector_name, desired_format, storage_order):
     """
     Checks if a CPP implementation is available for the desired connection pattern
     (*connector_name*) and the target sparse matrix format (*desired_format*). Please
     note that not all formats are available for *pre_to_post* storage order.
     """
     # The user disabled this feature
-    if not Global.config["use_cpp_connectors"]:
+    if not get_global_config('use_cpp_connectors'):
         return False
 
     cpp_patterns = {
         'st': {
             'post_to_pre': {
                 "lil": ["Random", "Random Convergent", "All-to-All"],
                 "csr": ["Random", "Random Convergent"],
@@ -322,16 +325,16 @@
                 "coo": [],
                 "ellr": ["Random", "Random Convergent"],
                 "dense": ["Random"]
             }
         }
     }
 
-    if Global._check_paradigm("openmp"):
-        paradigm = "st" if Global.config["num_threads"] == 1 else "omp"
+    if _check_paradigm("openmp"):
+        paradigm = "st" if get_global_config('num_threads') == 1 else "omp"
     else:
         paradigm = "cuda"
 
     try:
         return connector_name in cpp_patterns[paradigm][storage_order][desired_format]
 
     except KeyError:
@@ -375,37 +378,37 @@
     version_str = str(subprocess.check_output([nvcc_executable, "--version"]))
     try:
         version = float(version_str.split("\\")[-2].split(",")[1].split(" ")[2])
     except:
         try:
             version = float(version_str.split("\\")[-3].split(",")[1].split(" ")[2])
         except:
-            Global._error("Could not detect CUDA version: please check the CUDA installation or the configuration in annarchy.json")
+            Messages._error("Could not detect CUDA version: please check the CUDA installation or the configuration in annarchy.json")
 
     return version
 
-def check_and_apply_pow_fix(eqs):
+def check_and_apply_pow_fix(eqs, cuda_version):
     """
     CUDA SDKs before 7.5 had an error if std=c++11 is enabled related
     to pow(double, int). Only pow(double, double) was detected as
     device function, the pow(double, int) will be detected as host
     function. (This was fixed within SDK 7.5)
 
     To support also earlier versions, we simply add a double type cast.
     """
     if eqs.strip() == "":
         # nothing to do
         return eqs
 
-    if Global.config['cuda_version'] > 7.0:
+    if cuda_version > 7.0:
         # nothing to do, is working in higher SDKs
         return eqs
 
-    if Global.config['verbose']:
-        Global._print('occurance of pow() and SDK below 7.5 detected, apply fix.')
+    if get_global_config('verbose'):
+        Messages._print('occurance of pow() and SDK below 7.5 detected, apply fix.')
 
     # detect all pow statements
     pow_occur = re.findall(r"pow[\( [\S\s]*?\)*?, \d+\)]*?", eqs)
     for term in pow_occur:
         eqs = eqs.replace(term, term.replace(', ', ', (double)'))
 
     return eqs
@@ -430,15 +433,15 @@
     True, if the specified flag was found, in any other cases it defaults to False.
 
     Remark (31th May 2021):
 
     This is a rather simple approach to detect the AVX capability of a CPU. If it fails, one can
     still hope for the auto-vectorization.
     """
-    if Global.config["disable_SIMD_SpMV"]:
+    if get_global_config('disable_SIMD_SpMV'):
         return False
 
     # The hand-written codes are only validated
     # with g++ as target compiler
     if not sys.platform.startswith('linux'):
         return False
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/BSRInvMatrix.hpp` & `annarchy-4.8.0.1/ANNarchy/include/BSRInvMatrix.hpp`

 * *Files 3% similar despite different names*

```diff
@@ -125,22 +125,22 @@
     //  Accessors for the computation
     //
 
     //
     //  Initialization methods
     //
 
-    bool init_matrix_from_lil(std::vector<IT> row_indices, std::vector<std::vector<IT>> column_indices) {
+    bool init_matrix_from_lil(std::vector<IT> row_indices, std::vector<std::vector<IT>> column_indices, bool requires_sorting) {
     #ifdef _DEBUG
         std::cout << "BSRInvMatrix::init_matrix_from_lil()" << std::endl;
     #endif
         clear();
 
         // Construct forward view
-        bool success = static_cast<BSRMatrix<IT, ST, row_major>*>(this)->init_matrix_from_lil(row_indices, column_indices);
+        bool success = static_cast<BSRMatrix<IT, ST, row_major>*>(this)->init_matrix_from_lil(row_indices, column_indices, requires_sorting);
         if (!success)
             return false;
 
         // Construct inverse view
         success = inverse_connectivity_matrix();
 
         // Debug
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/BSRMatrix.hpp` & `annarchy-4.8.0.1/ANNarchy/include/BSRMatrix.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -16,14 +16,16 @@
  *    GNU General Public License for more details.
  *
  *    You should have received a copy of the GNU General Public License
  *    along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 #pragma once
 
+#include "helper_functions.hpp"
+
 /**
  *	\brief		Implementation of a blocked compressed sparse row (BSR) format.
  *	\details	A blocked variant of the classic compressed sparse row matrix format. It is basically
  *              the idea of a compressed sparse row, but instead of single values we encode a dense block.
  *              The format has been described in detail, e.g. in:
  * 
  *              * Eberhardt & Hoemmen (2016): Optimization of block sparse matrix-vector multiplication on shared-memory parallel architectures
@@ -171,20 +173,30 @@
         return tile_size_;
     }
 
     //
     //  Initialization methods
     //
 
-    bool init_matrix_from_lil(std::vector<IT> row_indices, std::vector<std::vector<IT>> column_indices) {
+    bool init_matrix_from_lil(std::vector<IT> row_indices, std::vector<std::vector<IT>> column_indices, bool requires_sorting) {
     #ifdef _DEBUG
         std::cout << "BSRMatrix::init_matrix_from_lil()" << std::endl;
     #endif
+        // clear previously instantiated matrix
         clear();
 
+        // The LIL entries are not sorted which might lead to worse psp access patterns
+        if (requires_sorting) {
+        #ifdef _DEBUG
+            std::cout << "   ... sort the LIL entries by row index ..." << std::endl;
+        #endif
+            pairsort<IT, std::vector<IT>>(row_indices.data(), column_indices.data(), row_indices.size());
+        }
+
+        // Construct the BSR format from LIL
         post_ranks_ = row_indices;
 
         // sanity checks
         assert( (row_indices.size() == column_indices.size()) );
 
         // data vector = vec[row_block][col_block]
         IT nb_block_rows = IT(ceil(double(this->num_rows_) / double(this->tile_size_)));
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/BSRMatrixCUDA.hpp` & `annarchy-4.8.0.1/ANNarchy/include/BSRMatrixCUDA.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -131,20 +131,20 @@
         return gpu_block_row_pointer_;
     }
 
     inline IT* gpu_block_column_index() {
         return gpu_block_column_index_;
     }
 
-    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks) {
+    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks, bool requires_sorting) {
     #ifdef _DEBUG
         std::cout << "BSRMatrixCUDA::init_matrix_from_lil()" << std::endl;
     #endif
 
-        bool success = static_cast<BSRMatrix<IT, ST, false>*>(this)->init_matrix_from_lil(post_ranks, pre_ranks);
+        bool success = static_cast<BSRMatrix<IT, ST, false>*>(this)->init_matrix_from_lil(post_ranks, pre_ranks, requires_sorting);
         if (!success)
             return false;
 
         size_t required = this->block_row_pointer_.size() * sizeof(IT) + this->block_column_index_.size() * sizeof(IT) + this->tile_data_.size()*sizeof(char);
         if( !check_free_memory(required) )
             return false;
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/COOMatrix.hpp` & `annarchy-4.8.0.1/ANNarchy/include/COOMatrix.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -169,21 +169,30 @@
         return count;
     }
 
     /**
      *  @brief      initialize connectivity based on a provided LIL representation.
      *  @details    simply sets the post_rank and pre_rank arrays without further sanity checking.
      */
-    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks) {
+    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks, bool requires_sorting) {
     #ifdef _DEBUG
         std::cout << "COOMatrix::init_matrix_from_lil()" << std::endl;
     #endif
         assert( (post_ranks.size() == pre_ranks.size()) );
+
         clear();
 
+        // The LIL entries are not sorted which might lead to worse psp access patterns
+        if (requires_sorting) {
+        #ifdef _DEBUG
+            std::cout << "   ... sort the LIL entries by row index ..." << std::endl;
+        #endif
+            pairsort<IT, std::vector<IT>>(row_indices.data(), column_indices.data(), row_indices.size());
+        }
+
         post_ranks_ = post_ranks;
 
         auto post_it = post_ranks.begin();
         auto pre_it = pre_ranks.begin();
 
         for( ; post_it != post_ranks.end(); post_it++, pre_it++) {
             // #elements in this row we need the post index
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/COOMatrixCUDA.hpp` & `annarchy-4.8.0.1/ANNarchy/include/COOMatrixCUDA.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -179,20 +179,20 @@
         return this->gpu_segments_;
     }
 
     IT segment_size() {
         return SEGMENT_SIZE;
     }
 
-    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks) {
+    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks, bool requires_sorting) {
     #ifdef _DEBUG
         std::cout << "COOMatrixCUDA::init_matrix_from_lil()" << std::endl;
     #endif
 
-        bool success = static_cast<COOMatrix<IT, ST>*>(this)->init_matrix_from_lil(post_ranks, pre_ranks);
+        bool success = static_cast<COOMatrix<IT, ST>*>(this)->init_matrix_from_lil(post_ranks, pre_ranks, requires_sorting);
         if (!success)
             return false;
 
         compute_segments();
 
         return host_to_device_transfer();
     }
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/CSRCMatrix.hpp` & `annarchy-4.8.0.1/ANNarchy/include/CSRCMatrix.hpp`

 * *Files 0% similar despite different names*

```diff
@@ -89,20 +89,20 @@
         return _inv_idx.data();
     }
 
     /**
      *  @brief      initialize from LIL representation.
      *  @see        LILMatrix::init_matrix_from_lil(), CSRMatrix::init_matrix_from_lil()
      */
-    bool init_matrix_from_lil(std::vector<IT> row_indices, std::vector< std::vector<IT> > column_indices) {
+    bool init_matrix_from_lil(std::vector<IT> row_indices, std::vector< std::vector<IT> > column_indices, bool requires_sorting) {
     #ifdef _DEBUG
         std::cout << "CSRCMatrix::init_matrix_from_lil():" << std::endl;
     #endif
         // create forward view
-        bool success = static_cast<CSRMatrix<IT, ST>*>(this)->init_matrix_from_lil(row_indices, column_indices);
+        bool success = static_cast<CSRMatrix<IT, ST>*>(this)->init_matrix_from_lil(row_indices, column_indices, requires_sorting);
         if (!success)
             return false;
 
         // compute backward view
         inverse_connectivity_matrix();
 
         return true;
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/CSRCMatrixCUDA.hpp` & `annarchy-4.8.0.1/ANNarchy/include/CSRCMatrixCUDA.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -159,20 +159,20 @@
         // clear host
         static_cast<CSRCMatrix<IT, ST>*>(this)->clear();
 
         // clear device
         free_device_memory();
     }
 
-    bool init_matrix_from_lil(std::vector<IT> &row_indices, std::vector< std::vector<IT> > &column_indices) {
+    bool init_matrix_from_lil(std::vector<IT> &row_indices, std::vector< std::vector<IT> > &column_indices, bool requires_sorting) {
     #ifdef _DEBUG
         std::cout << "CSRCMatrixCUDA::init_matrix_from_lil() " << std::endl;
     #endif
         // host side
-        bool success = static_cast<CSRCMatrix<IT, ST>*>(this)->init_matrix_from_lil(row_indices, column_indices);
+        bool success = static_cast<CSRCMatrix<IT, ST>*>(this)->init_matrix_from_lil(row_indices, column_indices, requires_sorting);
         if (!success)
             return false;
 
         // copy to gpu
         return host_to_device_transfer();
     }
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/CSRCMatrixCUDAT.hpp` & `annarchy-4.8.0.1/ANNarchy/include/CSRCMatrixCUDAT.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -167,20 +167,20 @@
         // clear host
         static_cast<CSRCMatrixT<IT, ST>*>(this)->clear();
 
         // clear device
         free_device_memory();
     }
 
-    bool init_matrix_from_lil(std::vector<IT> &row_indices, std::vector< std::vector<IT> > &column_indices) {
+    bool init_matrix_from_lil(std::vector<IT> &row_indices, std::vector< std::vector<IT> > &column_indices, bool requires_sorting) {
     #ifdef _DEBUG
         std::cout << "CSRCMatrixCUDAT::init_matrix_from_lil() " << std::endl;
     #endif
         // host side
-        bool success = static_cast<CSRCMatrixT<IT, ST>*>(this)->init_matrix_from_lil(row_indices, column_indices);
+        bool success = static_cast<CSRCMatrixT<IT, ST>*>(this)->init_matrix_from_lil(row_indices, column_indices, requires_sorting);
         if (!success)
             return false;
 
         // copy to gpu
         return host_to_device_transfer();
     }
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/CSRCMatrixT.hpp` & `annarchy-4.8.0.1/ANNarchy/include/CSRCMatrixT.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -145,23 +145,23 @@
     inline IT* inverse_indices() {
         return inv_idx_.data();
     }
 
     /*
      *  Create CSRC_T from LIL while ensuring an ascending index in rows. This function is called from Python.
      */
-    bool init_matrix_from_lil(std::vector<IT> post_ranks, std::vector< std::vector<IT> > pre_ranks) {
+    bool init_matrix_from_lil(std::vector<IT> post_ranks, std::vector< std::vector<IT> > pre_ranks, bool requires_sorting) {
     #ifdef _DEBUG
         std::cout << "CSRCMatrixT::init_matrix_from_lil()" << std::endl;
     #endif
         clear();
 
         // post_to_pre LIL
         auto lil_mat = new LILMatrix<IT>(num_rows_, num_columns_);
-        lil_mat->init_matrix_from_lil(post_ranks, pre_ranks);
+        lil_mat->init_matrix_from_lil(post_ranks, pre_ranks, requires_sorting);
 
         // switch dimensions
         auto lil_mat_t = lil_mat->transpose();
 
         // sanity check
         if (lil_mat->nb_synapses() != lil_mat_t->nb_synapses())
             std::cerr << "Transpose of the LIL matrix went possibly wrong ..." << std::endl;
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/CSRMatrix.hpp` & `annarchy-4.8.0.1/ANNarchy/include/CSRMatrix.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -18,14 +18,15 @@
  *
  *    You should have received a copy of the GNU General Public License
  *    along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 #pragma once
 
 #include "LILMatrix.hpp"
+#include "helper_functions.hpp"
 
 /**
  *  @brief      Implementation of a *compressed sparse row* (CSR) format.
  *  @details    Probably the most common sparse matrix format in computer science. The major idea is that only nonzeros are
  *              stored in a long continuous array and a second array provides a lookup, which slice in this array contains
  *              to a row.
  *
@@ -131,24 +132,36 @@
         return row_begin_;
     }
 
     /**
      *  @brief      Initialize CSR based on a LIL representation.
      *  @see        LILMatrix::init_matrix_from_lil()
      */
-    bool init_matrix_from_lil(std::vector<IT> row_indices, std::vector< std::vector<IT> > column_indices) {
+    bool init_matrix_from_lil(std::vector<IT> row_indices, std::vector< std::vector<IT> > column_indices, bool requires_sorting) {
     #ifdef _DEBUG
         std::cout << "CSRMatrix::init_matrix_from_lil()" << std::endl;
     #endif
         // sanity check of inputs
         assert( (row_indices.size() == column_indices.size()) );
         assert( (row_indices.size() < std::numeric_limits<IT>::max()) );
         assert( (row_indices.size() <= num_rows_) );
 
+        clear();
+
+        // The LIL entries are not sorted, consequently our present conversion routine will create errors ... (HD: 24 April 24)
+        if (requires_sorting) {
+        #ifdef _DEBUG
+            std::cout << "Sort the LIL entries by row index ..." << std::endl;
+        #endif
+            pairsort<IT, std::vector<IT>>(row_indices.data(), column_indices.data(), row_indices.size());
+        }
+
+        // construct the CSR from LIL
         post_ranks_ = row_indices;
+
         IT lil_row_idx = 0;
         for (IT r = 0; r < num_rows_; r++) {
             row_begin_[r] = col_idx_.size();
 
             // We are already done with the LIL matrix
             if (lil_row_idx == row_indices.size()) {
                 // HD (1st Sep. 2022):
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/CSRMatrixCUDA.hpp` & `annarchy-4.8.0.1/ANNarchy/include/CSRMatrixCUDA.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -128,20 +128,20 @@
         // clear host
         static_cast<CSRMatrix<IT, ST>*>(this)->clear();
 
         // clear device
         free_device_memory();
     }
 
-    bool init_matrix_from_lil(std::vector<IT> &row_indices, std::vector< std::vector<IT> > &column_indices) {
+    bool init_matrix_from_lil(std::vector<IT> &row_indices, std::vector< std::vector<IT> > &column_indices, bool requires_sorting) {
     #ifdef _DEBUG
         std::cout << "CSRMatrixCUDA::init_matrix_from_lil() " << std::endl;
     #endif
         // Initialization on host side
-        bool success = static_cast<CSRMatrix<IT, ST>*>(this)->init_matrix_from_lil(row_indices, column_indices);
+        bool success = static_cast<CSRMatrix<IT, ST>*>(this)->init_matrix_from_lil(row_indices, column_indices, requires_sorting);
         if (!success)
             return false;
 
         // transfer to GPU
         return host_to_device();
     }
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/DenseMatrix.hpp` & `annarchy-4.8.0.1/ANNarchy/include/DenseMatrix.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -272,16 +272,19 @@
 
         return num_efferents;
     }
 
     /**
      *  @brief      initialize connectivity based on a provided LIL representation.
      *  @details    simply sets the post_rank and pre_rank arrays without further sanity checking.
+     *  @param      post_ranks          contains row indices
+     *  @param      pre_ranks           contains for each row the corresponding column indices
+     *  @param      requires_sorting    if true, the rows are sorted. However, this argument exists only for interface reasons ... it has no effect on the data storage.
      */
-    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks) {
+    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks, bool requires_sorting) {
     #ifdef _DEBUG
         std::cout << "DenseMatrix::init_matrix_from_lil()" << std::endl;
     #endif
         // Sanity checks
         assert ( (post_ranks.size() == pre_ranks.size()) );
         assert ( (static_cast<unsigned long int>(post_ranks.size()) <= static_cast<unsigned long int>(std::numeric_limits<IT>::max())) );
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/DenseMatrixCUDA.hpp` & `annarchy-4.8.0.1/ANNarchy/include/DenseMatrixCUDA.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -125,20 +125,20 @@
      */
     void clear() {
     #ifdef _DEBUG
         std::cout << "DenseMatrixCUDA::clear()" << std::endl;
     #endif
     }
 
-    bool init_matrix_from_lil(std::vector<IT> &row_indices, std::vector< std::vector<IT> > &column_indices) {
+    bool init_matrix_from_lil(std::vector<IT> &row_indices, std::vector< std::vector<IT> > &column_indices, bool requires_sorting) {
     #ifdef _DEBUG
         std::cout << "DenseMatrixCUDA::init_matrix_from_lil() " << std::endl;
     #endif
         // Initialization on host side
-        bool success = static_cast<DenseMatrix<IT, ST, MT, row_major>*>(this)->init_matrix_from_lil(row_indices, column_indices);
+        bool success = static_cast<DenseMatrix<IT, ST, MT, row_major>*>(this)->init_matrix_from_lil(row_indices, column_indices, requires_sorting);
         if (!success)
             return false;
 
         // transfer to GPU
         return host_to_device();
     }
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/DenseMatrixOffsets.hpp` & `annarchy-4.8.0.1/ANNarchy/include/DenseMatrixOffsets.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -140,15 +140,15 @@
     }
 
     /**
      *  @brief      initialize connectivity based on a provided LIL representation.
      *  @details    simply sets the post_rank and pre_rank arrays without further sanity checking.
      *  @todo       Instead of duplicating the code, one might transform the post_ranks/pre_ranks array and then call the DenseMatrix::init_matrix_from_lil()
      */
-    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks) {
+    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks, bool requires_sorting) {
     #ifdef _DEBUG
         std::cout << "DenseMatrixOffsets::init_matrix_from_lil()" << std::endl;
     #endif
         // Sanity checks
         assert ( (post_ranks.size() == pre_ranks.size()) );
         assert ( (static_cast<unsigned long int>(post_ranks.size()) <= static_cast<unsigned long int>(std::numeric_limits<IT>::max())) );
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/ELLMatrix.hpp` & `annarchy-4.8.0.1/ANNarchy/include/ELLMatrix.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -16,14 +16,16 @@
  *    GNU General Public License for more details.
  *
  *    You should have received a copy of the GNU General Public License
  *    along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 #pragma once
 
+#include "helper_functions.hpp"
+
 /**
  *  @brief      ELLPACK sparse matrix representation according to Kincaid et al. (1989) with some
  *              minor modifications as described below.
  * 
  *              Format description by Kincaid et al. (1989):
  *
  *                  https://web.ma.utexas.edu/CNA/ITPACK/manuals/userv2d/node3.html
@@ -328,22 +330,30 @@
     }
 
     /**
      *  @brief      initialize connectivity based on a provided LIL representation.
      *  @details    First we scan *pre_ranks* to determine the value maxnzr_. Then we convert pre_ranks.
      *  @todo       Currently we ignore post_ranks ...
      */
-    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks) {
+    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks, bool requires_sorting) {
     #ifdef _DEBUG
         std::cout << "ELLMatrix::init_matrix_from_lil()" << std::endl;
         std::cout << "received " << post_ranks.size() << " rows." << std::endl;
     #endif
         assert( (post_ranks.size() == pre_ranks.size()) );
         assert( (post_ranks.size() <= num_rows_) );
 
+        // The LIL entries are not sorted which could lead to increased number of irregular memory accesses
+        if (requires_sorting) {
+        #ifdef _DEBUG
+            std::cout << "Sort the LIL entries by row index ..." << std::endl;
+        #endif
+            pairsort<IT, std::vector<IT>>(post_ranks.data(), pre_ranks.data(), post_ranks.size());
+        }
+
         //
         // 1st step:    iterate across the LIL to identify maximum
         //              row length
         post_ranks_ = post_ranks;
         maxnzr_ = std::numeric_limits<IT>::min();
         for(auto pre_it = pre_ranks.begin(); pre_it != pre_ranks.end(); pre_it++) {
             if ( maxnzr_ < static_cast<IT>(pre_it->size()) ) {
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/ELLMatrixCUDA.hpp` & `annarchy-4.8.0.1/ANNarchy/include/ELLMatrixCUDA.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -122,23 +122,23 @@
         // clear host
         static_cast<ELLMatrix<IT, ST, false>*>(this)->clear();
 
         // clear device
         free_device_memory();
     }
 
-    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks) {
+    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks, bool requires_sorting) {
         assert( (post_ranks.size() == pre_ranks.size()) );
         assert( (post_ranks.size() > 0) );
 
     #ifdef _DEBUG
         std::cout << "ELLMatrixCUDA::init_matrix_from_lil()" << std::endl;
     #endif
         // Initialize on host
-        bool success = static_cast<ELLMatrix<IT, ST, false>*>(this)->init_matrix_from_lil(post_ranks, pre_ranks);
+        bool success = static_cast<ELLMatrix<IT, ST, false>*>(this)->init_matrix_from_lil(post_ranks, pre_ranks, requires_sorting);
         if(!success)
             return false;
 
         // Initialize on device and transfer data
         return host_to_device_transfer();
     }
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/ELLRMatrix.hpp` & `annarchy-4.8.0.1/ANNarchy/include/ELLRMatrix.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -264,20 +264,28 @@
     }
 
     /**
      *  @brief      initialize connectivity based on a provided LIL representation.
      *  @details    First we scan *pre_ranks* to determine the value maxnzr_. Then we convert pre_ranks.
      *  @todo       Currently we ignore post_ranks ...
      */
-    bool init_matrix_from_lil(std::vector<IT> post_ranks, std::vector< std::vector<IT> > pre_ranks) {
+    bool init_matrix_from_lil(std::vector<IT> post_ranks, std::vector< std::vector<IT> > pre_ranks, bool requires_sorting) {
     #ifdef _DEBUG
         std::cout << "ELLRMatrix::init_matrix_from_lil()" << std::endl;
     #endif
         assert( (post_ranks.size() == pre_ranks.size()) );
 
+        // The LIL entries are not sorted the access to psp will be impaired
+        if (requires_sorting) {
+        #ifdef _DEBUG
+            std::cout << "Sort the LIL entries by row index ..." << std::endl;
+        #endif
+            pairsort<IT, std::vector<IT>>(post_ranks.data(), pre_ranks.data(), post_ranks.size());
+        }
+
         //
         // Store the LIL ranks
         post_ranks_ = post_ranks;
 
         //
         // 1st step:    iterate across the LIL to identify maximum
         //              row length
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/ELLRMatrixCUDA.hpp` & `annarchy-4.8.0.1/ANNarchy/include/ELLRMatrixCUDA.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -139,22 +139,22 @@
         // clear host
         static_cast<ELLRMatrix<IT, ST, false>*>(this)->clear();
 
         // clear device
         free_device_memory();
     }
 
-    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks) {
+    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks, bool requires_sorting) {
         assert( (post_ranks.size() == pre_ranks.size()) );
         assert( (post_ranks.size() > 0) );
 
     #ifdef _DEBUG
         std::cout << "ELLRMatrixCUDA::init_matrix_from_lil()" << std::endl;
     #endif
-        bool success = static_cast<ELLRMatrix<IT, ST, false>*>(this)->init_matrix_from_lil(post_ranks, pre_ranks);
+        bool success = static_cast<ELLRMatrix<IT, ST, false>*>(this)->init_matrix_from_lil(post_ranks, pre_ranks, requires_sorting);
         if (!success) {
             std::cerr << "ELLRMatrixCUDA::init_matrix_from_lil(): host side construction failed." << std::endl;
             return false;
         }
 
         return host_to_device_transfer();
     }
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/HYBMatrix.hpp` & `annarchy-4.8.0.1/ANNarchy/include/HYBMatrix.hpp`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/include/HYBMatrixCUDA.hpp` & `annarchy-4.8.0.1/ANNarchy/include/HYBMatrixCUDA.hpp`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/include/LILInvMatrix.hpp` & `annarchy-4.8.0.1/ANNarchy/include/LILInvMatrix.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -135,20 +135,21 @@
         inv_post_rank.clear();
         inv_post_rank.shrink_to_fit();
     }
 
     /**
      *  @see    LILMatrix::init_matrix_from_lil()
      */
-    bool init_matrix_from_lil(std::vector<IT> &row_indices, std::vector< std::vector<IT> > &column_indices) {
+    bool init_matrix_from_lil(std::vector<IT> &row_indices, std::vector< std::vector<IT> > &column_indices, bool requires_sorting) {
     #ifdef _DEBUG
         std::cout << "LILInvMatrix::init_matrix_from_lil():" << std::endl;
     #endif
+
         // create forward view
-        bool success = static_cast<LILMatrix<IT, ST>*>(this)->init_matrix_from_lil(row_indices, column_indices);
+        bool success = static_cast<LILMatrix<IT, ST>*>(this)->init_matrix_from_lil(row_indices, column_indices, requires_sorting);
         if (!success)
             return false;
 
         // compute backward view
         inverse_connectivity_matrix();
 
         // done
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/LILMatrix.hpp` & `annarchy-4.8.0.1/ANNarchy/include/LILMatrix.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -19,14 +19,16 @@
  *
  *    You should have received a copy of the GNU General Public License
  *    along with this program.  If not, see <http://www.gnu.org/licenses/>.
  *
  */
 #pragma once
 
+#include "helper_functions.hpp"
+
 /**
  *  @brief      Implementation of the *list-in-list* (LIL) sparse matrix format.
  *  @details    The LIL format comprises of a nested vector *pre_rank*, where the top-level indicates a row and the sub-level vector
  *              the column indices. To consider the existance of empty-rows, we have an additional array *post_rank* who assigns the
  *              row index to the entry in the *pre_rank* structure.
  *
  *              Let's consider the following example matrix
@@ -208,22 +210,30 @@
         return static_cast<IT>(post_rank.size());
     }
 
     /**
      *  @brief      initialize connectivity based on a provided LIL representation.
      *  @details    simply sets the post_rank and pre_rank arrays without further sanity checking.
      */
-    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks) {
+    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks, bool requires_sorting) {
     #ifdef _DEBUG
         std::cout << "LILMatrix::init_matrix_from_lil()" << std::endl;
     #endif
         // Sanity checks
         assert ( (post_ranks.size() == pre_ranks.size()) );
         assert ( (post_ranks.size() <= num_rows_) );
 
+        // The LIL entries are not sorted the access to psp will be impaired
+        if (requires_sorting) {
+        #ifdef _DEBUG
+            std::cout << "Sort the LIL entries by row index ..." << std::endl;
+        #endif
+            pairsort<IT, std::vector<IT>>(post_ranks.data(), pre_ranks.data(), post_ranks.size());
+        }
+
         // store the data
         this->post_rank = post_ranks;
         this->pre_rank = pre_ranks;
 
     #ifdef _DEBUG
         print_matrix_statistics();
     #endif
@@ -807,22 +817,37 @@
     /**
      *  @brief      print the matrix representation to the standard out (i. e. command-line)
      */
     void print_data_representation() {
         std::cout << "LILMatrix instance at " << this << std::endl;
         print_matrix_statistics();
 
-        std::cout << "post_ranks = [ ";
+        std::cout << "  post_ranks = [ ";
         for (auto it = post_rank.begin(); it != post_rank.end(); it++) {
             std::cout << *it << " ";
         }
         std::cout << "]" << std::endl;
-        std::cout << "pre_ranks = [ ";
+        std::cout << "  pre_ranks = [ ";
         for (auto it = pre_rank.begin(); it != pre_rank.end(); it++) {
             std::cout << "[ ";
             for( auto it2 = it->begin(); it2 != it->end(); it2++)
                 std::cout << *it2 << " ";
             std::cout << "], ";
         }
         std::cout << "]" << std::endl;
     }
+
+    template<typename VT>
+    void print_variable(const std::vector<std::vector<VT>> &variable) {
+        std::cout << "LILMatrix variable instance: " << this << std::endl;
+        // for each diagonal depict: offset/bool mask
+        std::cout << "[ ";
+        for (IT i = 0; i < variable.size(); i++) {
+            std::cout << "[";
+            for (auto col_it = variable[i].begin(); col_it != variable[i].end(); col_it++) {
+                std::cout << *col_it << ",";
+            }
+            std::cout << "] ";
+        }
+        std::cout << "]" << std::endl;
+    }
 };
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/PartitionedMatrix.hpp` & `annarchy-4.8.0.1/ANNarchy/include/PartitionedMatrix.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -17,14 +17,16 @@
  *    GNU General Public License for more details.
  *
  *    You should have received a copy of the GNU General Public License
  *    along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 #pragma once
 
+#include "helper_functions.hpp"
+
 /**
  *  @brief      Wrapper class for handling multiple instances of SPARSE_MATRIX_TYPE.
  *  @details    In order to support the parallel evaluation of expecially spiking networks
  *              we divide the whole matrix into as many as threads parts.
  *  @tparam     SPARSE_MATRIX_TYPE  sparse matrix class, most likely a LILMatrix, LILInvMatrix or CSRCMatrix
  *  @tparam     IT                  index type which should be the same as used in the SPARSE_MATRIX_TYPE declaration
  *  @tparam     ST                  size type which should be the same as used in the SPARSE_MATRIX_TYPE declaration
@@ -164,30 +166,40 @@
         for(auto it = sub_matrices_.begin(); it != sub_matrices_.end(); it++) {
             auto sliced_efferents = (*it)->nb_efferent_synapses();
             efferents.insert(sliced_efferents.begin(), sliced_efferents.end());
         }
         return efferents;
     }
 
-    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks, const IT num_partitions) {
+    bool init_matrix_from_lil(std::vector<IT> &post_ranks, std::vector< std::vector<IT> > &pre_ranks, bool requires_sorting, const IT num_partitions) {
         assert ( (post_ranks.size() == pre_ranks.size()) );
     #ifdef _DEBUG
         std::cout << "PartitionedMatrix::init_matrix_from_lil():" << std::endl;
     #endif
+
+        // The LIL entries are not sorted the access to psp will be impaired
+        if (requires_sorting) {
+        #ifdef _DEBUG
+            std::cout << "Sort the LIL entries by row index ..." << std::endl;
+        #endif
+            pairsort<IT, std::vector<IT>>(post_ranks.data(), pre_ranks.data(), post_ranks.size());
+        }
+
         // determine partitions
         divide_post_ranks(post_ranks, num_partitions);
 
         auto slice_it = slices_.begin();
         int part_idx = 0;
         for(; slice_it != slices_.end(); slice_it++, part_idx++) {
             // create sub matrix with the previously determined slices
             auto post_rank_slice = std::vector<IT>(post_ranks.begin()+slice_it->first, post_ranks.begin()+slice_it->second);
             auto pre_rank_slice = std::vector< std::vector<IT> >(pre_ranks.begin()+slice_it->first, pre_ranks.begin()+slice_it->second);
 
-            bool success = sub_matrices_[part_idx]->init_matrix_from_lil(post_rank_slice, pre_rank_slice);
+            // we already sorted the ranks, therefore requires_sorting is set to false
+            bool success = sub_matrices_[part_idx]->init_matrix_from_lil(post_rank_slice, pre_rank_slice, false);
             if (!success) {
                 std::cerr << "Failed to initialize partition " << part_idx << std::endl;
                 return false;
             }
         }
 
     #ifdef _DEBUG
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/SELLMatrix.hpp` & `annarchy-4.8.0.1/ANNarchy/include/SELLMatrix.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -16,15 +16,17 @@
  *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  *    GNU General Public License for more details.
  *
  *    You should have received a copy of the GNU General Public License
  *    along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 #pragma once
+
 #include "LILMatrix.hpp"
+#include "helper_functions.hpp"
 
 /*
  *   \brief     sliced ELLPACK sparse matrix representation according to Alexander Monakov et al. (2010) 
  *              and Moritz Kreutzer et al. (2013) with some minor modifications as described below.
 
  *   \details   more details can be found in the paper:
  *              Automatically tuning sparse matrix-vector multiplication for GPU architectures by Alexander Monakov et al. (2010)
@@ -155,15 +157,23 @@
 
     //
     // INITIALIZATION METHODS
     //
     /**
      *  @brief      initialize connectivity based on a provided LIL representation.        
      */
-    bool init_matrix_from_lil(std::vector<IT> row_indices, std::vector<std::vector<IT>> column_indices) {
+    bool init_matrix_from_lil(std::vector<IT> row_indices, std::vector<std::vector<IT>> column_indices, bool requires_sorting) {
+
+        // The LIL entries are not sorted the access to psp will be impaired
+        if (requires_sorting) {
+        #ifdef _DEBUG
+            std::cout << "Sort the LIL entries by row index ..." << std::endl;
+        #endif
+            pairsort<IT, std::vector<IT>>(row_indices.data(), column_indices.data(), row_indices.size());
+        }
 
         post_ranks_ = row_indices;
         auto lil_row_idx = 0;        
 
         //compute number of blocks
         unsigned int num_blocks = num_rows_ / block_size_;
         if (num_rows_ % block_size_)num_blocks++;
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/SELLMatrixCUDA.hpp` & `annarchy-4.8.0.1/ANNarchy/include/SELLMatrixCUDA.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -121,22 +121,22 @@
         free_device_memory();
     }
 
 
     /*
     *   init matrix from lil format  
     */
-    bool init_matrix_from_lil(std::vector<IT>& post_ranks, std::vector< std::vector<IT> >& pre_ranks) {
+    bool init_matrix_from_lil(std::vector<IT>& post_ranks, std::vector< std::vector<IT> >& pre_ranks, bool requires_sorting) {
         assert((post_ranks.size() == pre_ranks.size()));
         assert((post_ranks.size() > 0));
 
     #ifdef _DEBUG
             std::cout << "SELLMatrixCUDA::init_matrix_from_lil()" << std::endl;
     #endif
-        static_cast<SELLMatrix<IT, ST, false>*>(this)->init_matrix_from_lil(post_ranks, pre_ranks);
+        static_cast<SELLMatrix<IT, ST, false>*>(this)->init_matrix_from_lil(post_ranks, pre_ranks, requires_sorting);
 
         host_to_device_transfer();
 
         return true;
     }
 
     bool fixed_number_pre_pattern(std::vector<IT> post_ranks, std::vector<IT> pre_ranks, IT nnz_per_row, std::mt19937& rng) {
```

### Comparing `ANNarchy-4.7.3/ANNarchy/include/Specific.hpp` & `annarchy-4.8.0.1/ANNarchy/include/Specific.hpp`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/include/VecTransformation.hpp` & `annarchy-4.8.0.1/ANNarchy/include/VecTransformation.hpp`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/include/helper_functions.hpp` & `annarchy-4.8.0.1/ANNarchy/include/helper_functions.hpp`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy/models/Neurons.py` & `annarchy-4.8.0.1/ANNarchy/models/Neurons.py`

 * *Files 2% similar despite different names*

```diff
@@ -38,21 +38,21 @@
 
     $$r(t) = (v(t) - T)^+$$
 
     By default, the input $I(t)$ to this neuron is "sum(exc) - sum(inh)", but this can be changed by 
     setting the ``sum`` argument:
 
     ```python
-    neuron = LeakyIntegrator(sum="sum('exc')")
+    neuron = ann.LeakyIntegrator(sum="sum('exc')")
     ```
 
     By default, there is no additive noise, but the ``noise`` argument can be passed with a specific distribution:
 
     ```python
-    neuron = LeakyIntegrator(noise="Normal(0.0, 1.0)")
+    neuron = ann.LeakyIntegrator(noise="Normal(0.0, 1.0)")
     ```
 
     Parameters:
 
     * tau = 10.0 : Time constant in ms of the neuron.
     * B = 0.0 : Baseline value for v.
     * T = 0.0 : Threshold for the positive transfer function.
@@ -80,20 +80,31 @@
         ''', 
         equations='''
             tau * dv/dt + v = sum(exc) - sum(inh) + B : exponential
             r = pos(v - T)
         '''
     )
     ```
+
+    :param tau: Time constant.
+    :param B: Baseline.
+    :param T: Threshold.
+    :param sum: Input sums.
     """
 
     # For reporting
     _instantiated = []
 
-    def __init__(self, tau=10.0, B=0.0, T=0.0, sum='sum(exc) - sum(inh)', noise=None):
+    def __init__(self, 
+                 tau:float=10.0, 
+                 B:float=0.0, 
+                 T:float=0.0, 
+                 sum:str='sum(exc) - sum(inh)', 
+                 noise:str=None) -> None:
+        
         # Create the arguments
         parameters = """
             tau = %(tau)s : population
             B = %(B)s
             T = %(T)s : population
         """ % {'tau': tau, 'B': B, 'T': T}
 
@@ -117,28 +128,28 @@
         self._instantiated.append(True)
 
 ##################
 ### Izhikevich
 ##################
 class Izhikevich(Neuron):
     '''
-    Izhikevich neuron as proposed in:
+    Izhikevich quadratic spiking neuron.
 
     > Izhikevich, E.M. (2003). *Simple Model of Spiking Neurons, IEEE Transaction on Neural Networks*, 14:6. <http://dx.doi.org/10.1109/TNN.2003.820440>
     
-    The equations are:
+    The neural equations are:
 
     $$\\frac{dv}{dt} = 0.04 * v^2 + 5.0 * v + 140.0 - u + I$$
 
     $$\\frac{du}{dt} = a * (b * v - u)$$
 
     By default, the conductance is "g_exc - g_inh", but this can be changed by setting the ``conductance`` argument:
 
     ```python
-    neuron = Izhikevich(conductance='g_ampa * (1 + g_nmda) - g_gaba')
+    neuron = ann.Izhikevich(conductance='g_ampa * (1 + g_nmda) - g_gaba')
     ```
 
     The synapses are instantaneous, i.e the corresponding conductance is increased from the synaptic efficiency w at the time step when a spike is received.
 
     Parameters:
 
     * a = 0.02 : Speed of the recovery variable
@@ -175,15 +186,15 @@
 
     The ODEs are solved using the explicit Euler method.
 
     Equivalent code:
 
     ```python
 
-        Izhikevich = Neuron(
+        Izhikevich = ann.Neuron(
             parameters = """
                 noise = 0.0
                 a = 0.02
                 b = 0.2
                 c = -65.0
                 d = 8.0
                 v_thresh = 30.0
@@ -197,29 +208,39 @@
             spike = "v > v_thresh",
             reset = "v = c; u += d",
             refractory = 0.0
         )
     ```
 
     The default parameters are for a regular spiking (RS) neuron derived from the above mentioned article.
+
+    :param a: Speed of the recovery variable
+    :param b: Scaling of the recovery variable
+    :param c: Reset potential.
+    :param d: Increment of the recovery variable after a spike.
+    :param v_thresh: Spike threshold (mV).
+    :param i_offset: external current (nA).
+    :param noise: Amplitude of the normal additive noise.
+    :param tau_refrac: Duration of refractory period (ms).
+    :param conductance: Conductances used as inputs.
     '''
 
     # For reporting
     _instantiated = []
     
     def __init__(self, 
-        a=0.02, 
-        b=0.2, 
-        c=-65.0, 
-        d=8.0, 
-        v_thresh=30.0, 
-        i_offset=0.0, 
-        noise=0.0, 
-        tau_refrac=0.0, 
-        conductance="g_exc - g_inh"):
+        a:float=0.02, 
+        b:float=0.2, 
+        c:float=-65.0, 
+        d:float=8.0, 
+        v_thresh:float=30.0, 
+        i_offset:float=0.0, 
+        noise:float=0.0, 
+        tau_refrac:float=0.0, 
+        conductance:str="g_exc - g_inh") -> None:
         
         # Extract which targets are defined in the conductance
         #import re
         #targets = re.findall(r'g_([\w]+)', conductance)
         
         # Create the arguments
         parameters = """
@@ -256,17 +277,17 @@
 
 
 ##################
 ### IF neurons
 ##################
 class IF_curr_exp(Neuron):
     '''
-    IF_curr_exp neuron.
-
-    Leaky integrate-and-fire model with fixed threshold and decaying-exponential post-synaptic current. (Separate synaptic currents for excitatory and inhibitory synapses).
+    Leaky integrate-and-fire model with fixed threshold and decaying-exponential post-synaptic current. 
+    
+    (Separate synaptic currents for excitatory and inhibitory synapses).
 
     Parameters:
 
     * v_rest = -65.0 :  Resting membrane potential (mV)
     * cm  = 1.0 : Capacity of the membrane (nF)
     * tau_m  = 20.0 : Membrane time constant (ms)
     * tau_refrac = 0.0 : Duration of refractory period (ms)
@@ -322,21 +343,34 @@
             tau_syn_I * dg_inh/dt = - g_inh : exponential
         """,
         spike = "v > v_thresh",
         reset = "v = v_reset",
         refractory = 0.0
     )
     ```
+    :param v_rest:  Resting membrane potential (mV)
+    :param cm: Capacity of the membrane (nF)
+    :param tau_m: Membrane time constant (ms)
+    :param tau_refrac: Duration of refractory period (ms)
+    :param tau_syn_E: Decay time of excitatory synaptic current (ms)
+    :param tau_syn_I: Decay time of inhibitory synaptic current (ms)
+    :param i_offset: Offset current (nA)
+    :param v_reset: Reset potential after a spike (mV)
+    :param v_thresh: Spike threshold (mV)
 
     '''
     # For reporting
     _instantiated = []
     
-    def __init__(self, v_rest=-65.0, cm=1.0, tau_m=20.0, tau_refrac=0.0, 
-                tau_syn_E=5.0, tau_syn_I=5.0, v_thresh=-50.0, v_reset=-65.0, i_offset=0.0):
+    def __init__(self, 
+                 v_rest:float=-65.0, cm:float=1.0, 
+                 tau_m:float=20.0, tau_refrac:float=0.0, 
+                 tau_syn_E:float=5.0, tau_syn_I:float=5.0, 
+                 v_thresh:float=-50.0, v_reset:float=-65.0, 
+                 i_offset:float=0.0):
         
         # Create the arguments
         parameters = """
             v_rest = %(v_rest)s
             cm  = %(cm)s
             tau_m  = %(tau_m)s
             tau_refrac = %(tau_refrac)s
@@ -368,16 +402,14 @@
             description="Leaky integrate-and-fire model with fixed threshold and decaying-exponential post-synaptic current.")
 
         # For reporting
         self._instantiated.append(True)
 
 class IF_cond_exp(Neuron):
     '''
-    IF_cond_exp neuron.
-
     Leaky integrate-and-fire model with fixed threshold and decaying-exponential post-synaptic conductance.
 
     Parameters:
 
     * v_rest = -65.0 :  Resting membrane potential (mV)
     * cm  = 1.0 : Capacity of the membrane (nF)
     * tau_m  = 20.0 : Membrane time constant (ms)
@@ -488,17 +520,17 @@
 
         # For reporting
         self._instantiated.append(True)
 
 # Alpha conductances
 class IF_curr_alpha(Neuron):
     '''
-    IF_curr_alpha neuron.
-
-    Leaky integrate-and-fire model with fixed threshold and alpha post-synaptic currents. (Separate synaptic currents for excitatory and inhibitory synapses).
+    Leaky integrate-and-fire model with fixed threshold and alpha post-synaptic currents. 
+    
+    Separate synaptic currents for excitatory and inhibitory synapses.
 
     The alpha currents are calculated through a system of two linears ODEs. After a spike is received at t_spike, it peaks at t_spike + tau_syn_X, with a maximum equal to the synaptic efficiency.
 
     Parameters:
 
     * v_rest = -65.0 :  Resting membrane potential (mV)
     * cm  = 1.0 : Capacity of the membrane (nF)
@@ -618,16 +650,14 @@
 
         # For reporting
         self._instantiated.append(True)
 
 
 class IF_cond_alpha(Neuron):
     '''
-    IF_cond_exp neuron.
-
     Leaky integrate-and-fire model with fixed threshold and alpha post-synaptic conductance.
 
     Parameters:
 
     * v_rest = -65.0 :  Resting membrane potential (mV)
     * cm  = 1.0 : Capacity of the membrane (nF)
     * tau_m  = 20.0 : Membrane time constant (ms)
@@ -756,19 +786,19 @@
 
 ##################
 ### EIF neurons
 ##################
 
 class EIF_cond_exp_isfa_ista(Neuron):
     '''
-    EIF_cond_exp neuron.
+    Exponential integrate-and-fire neuron with spike triggered and sub-threshold adaptation currents (isfa, ista reps.).
+     
+    Definition according to:
 
-    Exponential integrate-and-fire neuron with spike triggered and sub-threshold adaptation currents (isfa, ista reps.) according to:
-
-    Brette R and Gerstner W (2005) Adaptive Exponential Integrate-and-Fire Model as an Effective Description of Neuronal Activity. J Neurophysiol 94:3637-3642
+    > Brette R and Gerstner W (2005) Adaptive Exponential Integrate-and-Fire Model as an Effective Description of Neuronal Activity. J Neurophysiol 94:3637-3642
 
     Parameters:
 
     * v_rest = -70.6 :  Resting membrane potential (mV)
     * cm = 0.281 : Capacity of the membrane (nF)
     * tau_m = 9.3667 : Membrane time constant (ms)
     * tau_refrac = 0.1 : Duration of refractory period (ms)
@@ -929,19 +959,19 @@
             description="Exponential integrate-and-fire neuron with spike triggered and sub-threshold adaptation currents (isfa, ista reps.).")
 
         # For reporting
         self._instantiated.append(True)
 
 class EIF_cond_alpha_isfa_ista(Neuron):
     ''' 
-    EIF_cond_alpha neuron.
-
-    Exponential integrate-and-fire neuron with spike triggered and sub-threshold adaptation conductances (isfa, ista reps.) according to:
+    Exponential integrate-and-fire neuron with spike triggered and sub-threshold adaptation conductances (isfa, ista reps.).
+     
+    Definition according to:
 
-    Brette R and Gerstner W (2005) Adaptive Exponential Integrate-and-Fire Model as an Effective Description of Neuronal Activity. J Neurophysiol 94:3637-3642
+    > Brette R and Gerstner W (2005) Adaptive Exponential Integrate-and-Fire Model as an Effective Description of Neuronal Activity. J Neurophysiol 94:3637-3642
 
     Parameters:
 
     * v_rest = -70.6 :  Resting membrane potential (mV)
     * cm = 0.281 : Capacity of the membrane (nF)
     * tau_m = 9.3667 : Membrane time constant (ms)
     * tau_refrac = 0.1 : Duration of refractory period (ms)
@@ -1122,16 +1152,14 @@
         self._instantiated.append(True)
 
 ##################
 ### HH
 ##################
 class HH_cond_exp(Neuron):
     '''
-    HH_cond_exp neuron.
-
     Single-compartment Hodgkin-Huxley-type neuron with transient sodium and delayed-rectifier potassium currents using the ion channel models from Traub.
 
     Parameters:
 
     * gbar_Na = 20.0 : Maximal conductance of the Sodium current.
     * gbar_K = 6.0 : Maximal conductance of the Potassium current. 
     * gleak = 0.01 : Conductance of the leak current (nF)
```

### Comparing `ANNarchy-4.7.3/ANNarchy/models/Synapses.py` & `annarchy-4.8.0.1/ANNarchy/models/Synapses.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 from ANNarchy.core.Synapse import Synapse
-from ANNarchy.core.Global import _error
+from ANNarchy.intern import Messages
 
 
 def list_standard_synapses():
     "Returns a list of standard neuron models available."
     return [STP, STDP, Hebb, Oja, IBCM]
 
 
@@ -61,15 +61,15 @@
     ```
     dw/dt = eta * pre.r * post.r
     ```
 
     Equivalent code:
 
     ```python
-    Hebb = Synapse(
+    Hebb = ann.Synapse(
         parameters = """
             eta = 0.01 : projection
         """,
         equations = """
             dw/dt = eta * pre.r * post.r : min=0.0
         """
     )
@@ -114,15 +114,15 @@
     ```
     dw/dt = eta * ( pre.r * post.r - alpha * post.r^2 * w )
     ```
     
     Equivalent code:
 
     ```python
-    Oja = Synapse(
+    Oja = ann.Synapse(
         parameters = """
             eta = 0.01 : projection
             alpha = 1.0 : projection
         """,
         equations = """
             dw/dt = eta * ( pre.r * post.r - alpha * post.r^2 * w ) : min=0.0
         """
@@ -175,15 +175,15 @@
     ```
     dw/dt = eta * post.r * (post.r - theta) * pre.r 
     ```
     
     Equivalent code:
 
     ```python
-    IBCM = Synapse(
+    IBCM = ann.Synapse(
         parameters = """
             eta = 0.01 : projection
             tau = 2000.0 : projection
         """,
         equations = """
             tau * dtheta/dt + theta = post.r^2 : postsynaptic, exponential
             dw/dt = eta * post.r * (post.r - theta) * pre.r : min=0.0, explicit
@@ -213,17 +213,19 @@
         self._instantiated.append(True)
 
 ##################
 ### STP
 ##################
 class STP(Synapse):
     '''
-    Synapse exhibiting short-term facilitation and depression, implemented using the model of Tsodyks, Markram et al.:
+    Synapse exhibiting short-term facilitation and depression.
+    
+    Implemented using the model of Tsodyks, Markram et al.:
 
-    Tsodyks, Uziel and Markram (2000) Synchrony Generation in Recurrent Networks with Frequency-Dependent Synapses. Journal of Neuroscience 20:RC50
+    > Tsodyks, Uziel and Markram (2000) Synchrony Generation in Recurrent Networks with Frequency-Dependent Synapses. Journal of Neuroscience 20:RC50
 
     Note that the time constant of the post-synaptic current is set in the neuron model, not here.
 
     **Parameters (global)**:
 
     * tau_rec = 100.0 : depression time constant (ms).
     * tau_facil = 0.01 : facilitation time constant (ms).
@@ -252,15 +254,15 @@
     x *= (1 - u)
     u += U * (1 - u)
     ```
     
     Equivalent code:
 
     ```python
-    STP = Synapse(
+    STP = ann.Synapse(
         parameters = """
             tau_rec = 100.0 : projection
             tau_facil = 0.01 : projection
             U = 0.5
         """,
         equations = """
             dx/dt = (1 - x)/tau_rec : init = 1.0, event-driven
@@ -277,15 +279,15 @@
     '''
     # For reporting
     _instantiated = []
 
     def __init__(self, tau_rec=100.0, tau_facil=0.01, U=0.5):
 
         if tau_facil<= 0.0:
-            _error('STP: tau_facil must be positive. Choose a very small value if you have to, or derive a new synapse.')
+            Messages._error('STP: tau_facil must be positive. Choose a very small value if you have to, or derive a new synapse.')
             
         parameters = """
             tau_rec = %(tau_rec)s : projection
             tau_facil = %(tau_facil)s : projection
             U = %(U)s
         """ % {'tau_rec': tau_rec, 'tau_facil': tau_facil, 'U': U}
         equations = """
@@ -305,19 +307,17 @@
         
 
 ##################
 ### STDP
 ##################
 class STDP(Synapse):
     '''
-    Spike-timing dependent plasticity.
-
-    This is the online version of the STDP rule.
+    Spike-timing dependent plasticity, online version.
 
-    Song, S., and Abbott, L.F. (2001). Cortical development and remapping through spike timing-dependent plasticity. Neuron 32, 339-350. 
+    > Song, S., and Abbott, L.F. (2001). Cortical development and remapping through spike timing-dependent plasticity. Neuron 32, 339-350. 
 
     **Parameters (global)**:
 
     * tau_plus = 20.0 : time constant of the pre-synaptic trace (ms)
     * tau_minus = 20.0 : time constant of the pre-synaptic trace (ms)
     * A_plus = 0.01 : increase of the pre-synaptic trace after a spike.
     * A_minus = 0.01 : decrease of the post-synaptic trace after a spike. 
@@ -358,15 +358,15 @@
     w = clip(w + x, w_min , w_max)
     ```
     
     Equivalent code:
 
     ```python
 
-    STDP = Synapse(
+    STDP = ann.Synapse(
         parameters = """
             tau_plus = 20.0 : projection
             tau_minus = 20.0 : projection
             A_plus = 0.01 : projection
             A_minus = 0.01 : projection
             w_min = 0.0 : projection
             w_max = 1.0 : projection
```

### Comparing `ANNarchy-4.7.3/ANNarchy/parser/AnalyseNeuron.py` & `annarchy-4.8.0.1/ANNarchy/parser/AnalyseNeuron.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,19 +1,20 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-from ANNarchy.core.Global import _error, _warning, config
 from ANNarchy.core.Random import available_distributions, distributions_arguments, distributions_equivalents
 from ANNarchy.parser.Equation import Equation
 from ANNarchy.parser.StringManipulation import *
 from ANNarchy.parser.ITE import *
 from ANNarchy.parser.Extraction import *
 from ANNarchy.parser.CoupledEquations import CoupledEquations
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern import Messages
 
 def analyse_neuron(neuron):
     """
     Parses the structure and generates code snippets for the neuron type.
 
     It returns a ``description`` dictionary with the following fields:
 
@@ -105,47 +106,47 @@
         found = False
         for var in description['parameters'] + description['variables']:
             if var['name'] == 'r':
                 found = True
         if not found:
             description['variables'].append(
                 {
-                    'name': 'r', 'locality': 'local', 'bounds': {}, 'ctype': config['precision'],
+                    'name': 'r', 'locality': 'local', 'bounds': {}, 'ctype': get_global_config('precision'),
                     'init': 0.0, 'flags': [], 'eq': '', 'cpp': ""
                 }
             )
     elif neuron.type == 'rate':
         for var in description['parameters'] + description['variables']:
             if var['name'] == 'r':
                 break
         else:
-            _error('Rate-coded neurons must define the variable "r".')
+            Messages._error('Rate-coded neurons must define the variable "r".')
 
     else: # spiking neurons define r by default, it contains the average FR if enabled
         for var in description['parameters'] + description['variables']:
             if var['name'] == 'r':
-                _error('Spiking neurons use the variable "r" for the average FR, use another name.')
+                Messages._error('Spiking neurons use the variable "r" for the average FR, use another name.')
 
         description['variables'].append(
             {
-                'name': 'r', 'locality': 'local', 'bounds': {}, 'ctype': config['precision'],
+                'name': 'r', 'locality': 'local', 'bounds': {}, 'ctype': get_global_config('precision'),
                 'init': 0.0, 'flags': [], 'eq': '', 'cpp': ""
             }
         )
 
     # Extract functions
     functions = extract_functions(neuron.functions, False)
     description['functions'] = functions
 
     # Build lists of all attributes (param + var), which are local or global
     attributes, local_var, global_var, _ = get_attributes(parameters, variables, neuron=True)
 
     # Test if attributes are declared only once
     if len(attributes) != len(list(set(attributes))):
-        _error('Attributes must be declared only once.', attributes)
+        Messages._error('Attributes must be declared only once.', attributes)
 
     # Store the attributes
     description['attributes'] = attributes
     description['local'] = local_var
     description['semiglobal'] = [] # only for projections
     description['global'] = global_var
 
@@ -158,15 +159,15 @@
             for var in description['variables']:
                 if var['name'] == 'g_' + target:
                     found = True
                     break
             if not found:
                 description['variables'].append(
                     {
-                        'name': 'g_'+target, 'locality': 'local', 'bounds': {}, 'ctype': config['precision'],
+                        'name': 'g_'+target, 'locality': 'local', 'bounds': {}, 'ctype': get_global_config('precision'),
                         'init': 0.0, 'flags': [], 'eq': 'g_' + target+ ' = 0.0'
                     }
                 )
                 description['attributes'].append('g_'+target)
                 description['local'].append('g_'+target)
 
     # Extract RandomDistribution objects
@@ -201,15 +202,15 @@
         dependencies = []
 
         # Replace sum(target) with _sum_exc__[i]
         for target in description['targets']:
             # sum() is valid for all targets
             eq = re.sub(r'(?P<pre>[^\w.])sum\(\)', r'\1sum(__all__)', eq)
             # Replace sum(target) with __sum_target__
-            eq = re.sub('sum\(\s*'+target+'\s*\)', '__sum_'+target+'__', eq)
+            eq = re.sub(r'sum\(\s*'+target+r'\s*\)', r'__sum_'+target+'__', eq)
             untouched['__sum_'+target+'__'] = '_sum_' + target + '%(local_index)s'
 
         # Extract global operations
         eq, untouched_globs, global_ops = extract_globalops_neuron(variable['name'], eq, description)
 
         # Add the untouched variables to the global list
         for name, val in untouched_globs.items():
@@ -297,15 +298,15 @@
                 if len(pre_loop) > 0:
                     pre_loop['value'] = re.sub(prev, new, pre_loop['value'])
                 if switch:
                     switch = re.sub(prev, new, switch)
 
         # Replace local functions
         for f in description['functions']:
-            cpp_eq = re.sub(r'([^\w]*)'+f['name']+'\(',
+            cpp_eq = re.sub(r'([^\w]*)'+f['name']+r'\(',
                             r'\1'+f['name'] + '(', ' ' + cpp_eq).strip()
 
         # Store the result
         variable['pre_loop'] = pre_loop # Things to be declared before the for loop (eg. dt)
         variable['cpp'] = cpp_eq # the C++ equation
         variable['switch'] = switch # switch value of ODE
         variable['transformed_eq'] = eq # the equation with untouched terms
```

### Comparing `ANNarchy-4.7.3/ANNarchy/parser/AnalyseSynapse.py` & `annarchy-4.8.0.1/ANNarchy/parser/AnalyseSynapse.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,19 +1,20 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-from ANNarchy.core.Global import _error, _warning, config
 from ANNarchy.core.Random import available_distributions, distributions_arguments, distributions_equivalents
 from ANNarchy.parser.Equation import Equation
 from ANNarchy.parser.StringManipulation import *
 from ANNarchy.parser.ITE import *
 from ANNarchy.parser.Extraction import *
 from ANNarchy.parser.CoupledEquations import CoupledEquations
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern import Messages
 
 def analyse_synapse(synapse):
     """
     Parses the structure and generates code snippets for the synapse type.
 
     It returns a ``description`` dictionary with the following fields:
 
@@ -104,15 +105,15 @@
     description['plasticity'] = False
     for var in parameters + variables:
         if var['name'] == 'w':
             break
     else:
         parameters.append(
             {
-                'name': 'w', 'bounds': {}, 'ctype': config['precision'],
+                'name': 'w', 'bounds': {}, 'ctype': get_global_config('precision'),
                 'init': 0.0, 'flags': [], 'eq': 'w=0.0', 'locality': 'local'
             }
         )
 
     # Find out a plasticity rule
     for var in variables:
         if var['name'] == 'w':
@@ -120,15 +121,15 @@
             break
 
     # Build lists of all attributes (param+var), which are local or global
     attributes, local_var, global_var, semiglobal_var = get_attributes(parameters, variables, neuron=False)
 
     # Test if attributes are declared only once
     if len(attributes) != len(list(set(attributes))):
-        _error('Attributes must be declared only once.', attributes)
+        Messages._error('Attributes must be declared only once.', attributes)
 
 
     # Add this info to the description
     description['parameters'] = parameters
     description['variables'] = variables
     description['functions'] = functions
     description['attributes'] = attributes
@@ -300,15 +301,17 @@
 
         # Replace untouched variables with their original name}
         for prev, new in sorted(list(untouched.items()), key = lambda key : len(key[0]), reverse=True):
             cpp_eq = cpp_eq.replace(prev, new)
 
         # Replace local functions
         for f in description['functions']:
-            cpp_eq = re.sub(r'([^\w]*)'+f['name']+'\(', r'\1'+ f['name'] + '(', ' ' + cpp_eq).strip()
+            cpp_eq = re.sub(
+                r'([^\w]*)' + f['name'] + r'\(', 
+                r'\1'+ f['name'] + '(', ' ' + cpp_eq).strip()
 
         # Store the result
         variable['pre_loop'] = pre_loop # Things to be declared before the for loop (eg. dt)
         variable['cpp'] = cpp_eq # the C++ equation
         variable['switch'] = switch # switch value id ODE
         variable['transformed_eq'] = eq # the equation with untouched terms
         variable['untouched'] = untouched # may be needed later
@@ -403,21 +406,21 @@
                 code = translator.parse()
                 dependencies += translator.dependencies()
             else:
                 code, deps = translate_ITE(variable['name'], eq, condition, description, untouched)
                 dependencies += deps
 
             if isinstance(code, list): # an ode in a pre/post statement
-                Global._print(eq)
+                Messages._print(eq)
                 if variable in description['pre_spike']:
-                    Global._error('It is forbidden to use ODEs in a pre_spike term.')
+                    Messages._error('It is forbidden to use ODEs in a pre_spike term.')
                 elif variable in description['posz_spike']:
-                    Global._error('It is forbidden to use ODEs in a post_spike term.')
+                    Messages._error('It is forbidden to use ODEs in a post_spike term.')
                 else:
-                    Global._error('It is forbidden to use ODEs here.')
+                    Messages._erroror('It is forbidden to use ODEs here.')
 
             # Replace untouched variables with their original name
             for prev, new in sorted(list(untouched.items()), key = lambda key : len(key[0]), reverse=True):
                 code = code.replace(prev, new)
 
             # Process the bounds
             if 'min' in variable['bounds'].keys():
```

### Comparing `ANNarchy-4.7.3/ANNarchy/parser/CoupledEquations.py` & `annarchy-4.8.0.1/ANNarchy/parser/CoupledEquations.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,15 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-import ANNarchy.core.Global as Global
+from ANNarchy.intern.ConfigManagement import get_global_config, _check_precision
+from ANNarchy.intern import Messages
+
 from .Equation import Equation
 from .ParserTemplate import create_local_dict, user_functions
 
 from sympy import *
 
 import re
 
@@ -55,16 +57,16 @@
     def parse(self):
         "Main method called after creating the object."
         # Check if the numerical method is the same for all ODEs
         methods = []
         for var in self.variables:
             methods.append(var['method'])
         if len(list(set(methods))) > 1: # mixture of methods
-            Global._print(methods)
-            Global._error('Can not mix different numerical methods when solving a coupled system of equations.')
+            Messages._print(methods)
+            Messages._erroror('Can not mix different numerical methods when solving a coupled system of equations.')
             
         else:
             method = methods[0]
 
         if method == 'implicit' or method == 'semiimplicit':
             return self.solve_implicit(self.expression_list)
         elif method == 'midpoint': 
@@ -106,23 +108,23 @@
                 local_dict = self.local_dict
             )
             equations[name] = analysed
 
         try:
             solution = solve(list(equations.values()), list(new_vars.keys()))
         except Exception as e:
-            Global._print(expression_list)
-            Global._error('The multiple ODEs can not be solved together using the implicit Euler method.')     
+            Messages._print(expression_list)
+            Messages._error('The multiple ODEs can not be solved together using the implicit Euler method.')     
 
         for var, sol in solution.items():
             # simplify the solution
             sol  = collect( sol, self.local_dict['dt'])
 
             # Generate the code
-            cpp_eq = Global.config['precision'] + ' _' + new_vars[var] + ' = ' + ccode(sol) + ';'
+            cpp_eq = get_global_config('precision') + ' _' + new_vars[var] + ' = ' + ccode(sol) + ';'
             switch = ccode(self.local_dict[new_vars[var]] ) + ' = _' + new_vars[var] + ';'
 
             # Replace untouched variables with their original name
             for prev, new in sorted(list(self.untouched.items()), key = lambda key : len(key[0]), reverse=True):
                 cpp_eq = re.sub(prev, new, cpp_eq)
                 switch = re.sub(prev, new, switch)
 
@@ -168,15 +170,15 @@
             )
             equations[name] = analysed
             evaluations[name] = solve(analysed, self.local_dict['_grad_var_'+name])
 
         # Compute the k = f(x, t)
         ks = {}
         for name, evaluation in evaluations.items():
-            ks[name] = Global.config['precision'] + ' _k_' + name + ' = ' + self.c_code(evaluation[0]) + ';'
+            ks[name] = get_global_config('precision') + ' _k_' + name + ' = ' + self.c_code(evaluation[0]) + ';'
 
         # New dictionary replacing x by x+dt/2*k)
         tmp_dict = {}
         for name, val in self.local_dict.items():
             tmp_dict[name] = val
         for name, evaluation in evaluations.items():
             tmp_dict[name] = Symbol('(' + ccode(self.local_dict[name]) + ' + 0.5 * dt * _k_' + name + ' )')
@@ -184,15 +186,15 @@
         # Compute the new values _x_new = f(x + dt/2*_k)
         news = {}
         for name, expression in expression_list.items():
             tmp_analysed = self.parse_expression(expression,
                 local_dict = tmp_dict
             )
             solved = solve(tmp_analysed, self.local_dict['_grad_var_'+name])
-            news[name] = Global.config['precision'] + ' _' + name + ' = ' + self.c_code(solved[0]) + ';'
+            news[name] = get_global_config('precision') + ' _' + name + ' = ' + self.c_code(solved[0]) + ';'
 
         # Compute the switches
         switches = {}
         for name, expression in expression_list.items():
             switches[name] = ccode(self.local_dict[name]) + ' += dt * _' + name + ' ;'
 
         # Store the generated code in the variables
@@ -241,15 +243,15 @@
             )
             equations[name] = analysed
             evaluations[name] = solve(analysed, self.local_dict['_gradient_'+name])
 
         # Compute the k1 = f(x, t)
         k1_dict = {}
         for name, evaluation in evaluations.items():
-            k1_dict[name] = Global.config['precision'] + ' _k1_' + name + ' = ' + self.c_code(evaluation[0]) + ';'
+            k1_dict[name] = get_global_config('precision') + ' _k1_' + name + ' = ' + self.c_code(evaluation[0]) + ';'
 
         # New dictionary replacing x by x+dt/2*k1)
         k2_dict = {}
         tmp_dict_k2 = {}
         for name, val in self.local_dict.items():
             tmp_dict_k2[name] = val
         for name, evaluation in evaluations.items():
@@ -258,15 +260,15 @@
         # Compute the values _k2_x = f(x + dt/2*_k1)
         for name, expression in expression_list.items():
             tmp_analysed = self.parse_expression(expression,
                 local_dict = tmp_dict_k2
             )
 
             solved = solve(tmp_analysed, self.local_dict['_gradient_'+name])
-            k2_dict[name] = Global.config['precision'] + ' _k2_' + name + ' = ' + self.c_code(solved[0]) + ';'
+            k2_dict[name] = get_global_config('precision') + ' _k2_' + name + ' = ' + self.c_code(solved[0]) + ';'
 
         # New dictionary replacing x by x+dt/2*k2)
         k3_dict = {}
         tmp_dict_k3 = {}
         for name, val in self.local_dict.items():
             tmp_dict_k3[name] = val
         for name, evaluation in evaluations.items():
@@ -275,15 +277,15 @@
         # Compute the values _k3_x = f(x + dt/2*_k2_x)
         for name, expression in expression_list.items():
             tmp_analysed = self.parse_expression(expression,
                 local_dict = tmp_dict_k3
             )
 
             solved = solve(tmp_analysed, self.local_dict['_gradient_'+name])
-            k3_dict[name] = Global.config['precision'] + ' _k3_' + name + ' = ' + self.c_code(solved[0]) + ';'
+            k3_dict[name] = get_global_config('precision') + ' _k3_' + name + ' = ' + self.c_code(solved[0]) + ';'
 
         # New dictionary replacing x by x+dt*k3)
         k4_dict = {}
         tmp_dict_k4 = {}
         for name, val in self.local_dict.items():
             tmp_dict_k4[name] = val
         for name, evaluation in evaluations.items():
@@ -292,18 +294,18 @@
         # Compute the values _k4_x = f(x + dt*_k3_x)
         for name, expression in expression_list.items():
             tmp_analysed = self.parse_expression(expression,
                 local_dict = tmp_dict_k4
             )
 
             solved = solve(tmp_analysed, self.local_dict['_gradient_'+name])
-            k4_dict[name] = Global.config['precision'] + ' _k4_' + name + ' = ' + self.c_code(solved[0]) + ';'
+            k4_dict[name] = get_global_config('precision') + ' _k4_' + name + ' = ' + self.c_code(solved[0]) + ';'
 
         # accumulate _k1 - _k4 within the switch step
-        dt_code = "dt/6.0f" if Global.config["precision"]=="float" else "dt/6.0"
+        dt_code = "dt/6.0f" if _check_precision('float') else "dt/6.0"
         switches = {}
         for name, expression in expression_list.items():
             switches[name] = ccode(self.local_dict[name]) + ' += '+dt_code+' * (_k1_'+name+' + (_k2_'+name+' + _k2_'+name+') + (_k3_'+name+' + _k3_'+name+') + _k4_'+name+');'
 
         # Store the generated code in the variables
         for name in self.names:
             k1 = k1_dict[name]
```

### Comparing `ANNarchy-4.7.3/ANNarchy/parser/Equation.py` & `annarchy-4.8.0.1/ANNarchy/parser/Equation.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-import ANNarchy.core.Global as Global
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern import Messages
 from .ParserTemplate import create_local_dict, user_functions
 
 import sympy as sp
 import re
 from copy import deepcopy
 
 def transform_condition(expr):
@@ -94,16 +95,16 @@
             elif self.type == 'inc':
                 code = self.analyse_increment(self.expression)
             elif self.type == 'return':
                 code = self.analyse_return(self.expression)
             elif self.type == 'simple':
                 code = self.analyse_assignment(self.expression)
         except Exception as e:
-            Global._print(e)
-            Global._error('Parser: cannot analyse', self.expression)
+            Messages._print(e)
+            Messages._error('Parser: cannot analyse', self.expression)
         return code
 
     def identify_type(self):
         """
         Identifies which type has the equation:
 
         * inc for "a += 0.2"
@@ -152,15 +153,15 @@
         """
         c_code = sp.ccode(
             equation,
             precision=8,
             user_functions=self.user_functions
         )
 
-        if Global.config["precision"]=="float":
+        if get_global_config('precision')=="float":
             #
             # Add the f-suffix to floating value constants
             matches = re.findall(r"[-]?[0-9]+\.[0-9]+", c_code)
             matches = sorted(list(set(matches)))    # remove doublons, e. g. 0.5*dt
 
             for m in matches:
                 fval = float(m)
@@ -195,16 +196,16 @@
             res =  parse_expr(
                 expression,
                 local_dict = local_dict,
                 transformations = (standard_transformations + (convert_xor, )),
                 evaluate=False
             )
         except Exception as e:
-            Global._print(e)
-            Global._error('Can not analyse the expression :' +  str(expression))
+            Messages._print(e)
+            Messages._error('Can not analyse the expression :' +  str(expression))
 
         return res
 
     def _count_ops(self, equation):
         """
         Count the number of numeric operations to approximate the number of required
         floating point operations.
@@ -265,15 +266,15 @@
 
         self.analysed = analysed
         variable_name = self.local_dict[self.name]
 
         equation = sp.solve(analysed, new_var, check=False, rational=False)[0]
         equation = sp.simplify(equation, ratio=1.0)
 
-        explicit_code = Global.config['precision'] + ' _' + self.name + ' = ' + self.c_code(equation) + ';'
+        explicit_code = get_global_config('precision') + ' _' + self.name + ' = ' + self.c_code(equation) + ';'
 
         switch = self.c_code(variable_name) + ' += dt*_' + self.name + ' ;'
 
         # compute required number of operations
         self.num_flops = self._count_ops(equation)    # compute increment
         self.num_flops += 2                          # apply increment
 
@@ -297,24 +298,24 @@
         variable_name = self.local_dict[self.name]
 
         # equation = sp.simplify(sp.collect( sp.solve(analysed, new_var, check=False)[0], self.local_dict['dt']))
         equation = sp.solve(analysed, new_var, check=False, rational=False)[0]
         equation = sp.collect(equation, self.local_dict['dt'])
         equation = sp.simplify(equation, ratio=1.0)
 
-        explicit_code = Global.config['precision'] + ' _k_' + self.name + ' = dt*(' + self.c_code(equation) + ');'
+        explicit_code = get_global_config('precision') + ' _k_' + self.name + ' = dt*(' + self.c_code(equation) + ');'
         # Midpoint method:
         # Replace the variable x by x+_x/2
         tmp_dict = self.local_dict
         tmp_dict[self.name] = sp.Symbol('(' + self.c_code(variable_name) + ' + 0.5*_k_' + self.name + ' )')
         tmp_analysed = self.parse_expression(expression,
             local_dict = self.local_dict
         )
         tmp_equation = sp.solve(tmp_analysed, new_var, check=False, rational=False)[0]
-        explicit_code += '\n' + Global.config['precision'] + ' _' + self.name + ' = ' + self.c_code(tmp_equation) + ';'
+        explicit_code += '\n' + get_global_config('precision') + ' _' + self.name + ' = ' + self.c_code(tmp_equation) + ';'
 
         switch = self.c_code(variable_name) + ' += dt*_' + self.name + ' ;'
 
         # compute required number of operations
         self.num_flops = self._count_ops(equation)        # compute increment (explicit)
         self.num_flops += self._count_ops(tmp_equation)   # compute increment (dt/2.0)
         self.num_flops += 2                              # apply increment
@@ -337,42 +338,42 @@
 
         variable_name = self.local_dict[self.name]
 
         # k1 = f(x)
         equation = sp.solve(analysed, new_var, check=False, rational=False)[0]
         equation = sp.collect(equation, self.local_dict['dt'])
         equation = sp.simplify(equation, ratio=1.0)
-        explicit_code = Global.config['precision'] + ' _k1_' + self.name + ' = (' + self.c_code(equation) + ');\n'
+        explicit_code = get_global_config('precision') + ' _k1_' + self.name + ' = (' + self.c_code(equation) + ');\n'
 
         # k2 = f(x+dt/2*k)
         tmp_dict = deepcopy(self.local_dict)
         tmp_dict[self.name] = sp.Symbol('(' + self.c_code(variable_name) + ' + 0.5 * dt * _k1_' + self.name + ' )')
         tmp_analysed = self.parse_expression(expression,
             local_dict = tmp_dict
         )
         tmp_equation_k2 = sp.solve(tmp_analysed, new_var, check=False, rational=False)[0]
-        explicit_code += Global.config['precision'] + ' _k2_' + self.name + ' = (' + self.c_code(tmp_equation_k2) + ');\n'
+        explicit_code += get_global_config('precision') + ' _k2_' + self.name + ' = (' + self.c_code(tmp_equation_k2) + ');\n'
 
         # k3 = f(x+dt/2*k2)
         tmp_dict = deepcopy(self.local_dict)
         tmp_dict[self.name] = sp.Symbol('(' + self.c_code(variable_name) + ' + 0.5 * dt * _k2_' + self.name + ' )')
         tmp_analysed = self.parse_expression(expression,
             local_dict = tmp_dict
         )
         tmp_equation_k3 = sp.solve(tmp_analysed, new_var, check=False, rational=False)[0]
-        explicit_code += Global.config['precision'] + ' _k3_' + self.name + ' = (' + self.c_code(tmp_equation_k3) + ');\n'
+        explicit_code += get_global_config('precision') + ' _k3_' + self.name + ' = (' + self.c_code(tmp_equation_k3) + ');\n'
 
         # k4 = f(x+dt*k3)
         tmp_dict = deepcopy(self.local_dict)
         tmp_dict[self.name] = sp.Symbol('(' + self.c_code(variable_name) + ' + dt * _k3_' + self.name + ' )')
         tmp_analysed = self.parse_expression(expression,
             local_dict = tmp_dict
         )
         tmp_equation_k4 = sp.solve(tmp_analysed, new_var, check=False, rational=False)[0]
-        explicit_code += Global.config['precision'] + ' _k4_' + self.name + ' = (' + self.c_code(tmp_equation_k4) + ');\n'
+        explicit_code += get_global_config('precision') + ' _k4_' + self.name + ' = (' + self.c_code(tmp_equation_k4) + ');\n'
 
         # final x is part of k1 .. k4
         switch = self.c_code(variable_name) + ' += dt/6.0 * ( _k1_' + self.name + ' + (_k2_' + self.name + '+_k2_' + self.name + ') + (_k3_' + self.name + '+_k3_' + self.name + ') + _k4_' + self.name + ');'
 
         # compute required number of operations
         self.num_flops = self._count_ops(equation)            # compute increment (explicit)
         self.num_flops += self._count_ops(tmp_equation_k2)    # compute increment (k2)
@@ -405,48 +406,48 @@
         self.analysed = analysed
         # print('Analysed', analysed)
 
         # Solve the equation for delta_mp
         solved = sp.solve(analysed, new_var, check=False, rational=False)
         # print('Solved', solved)
         if len(solved) > 1:
-            Global._print(self.expression)
-            Global._error('Parser: the ODE is not linear, can not use the implicit method.')
+            Messages._print(self.expression)
+            Messages._error('Parser: the ODE is not linear, can not use the implicit method.')
 
         else:
             solved = solved[0]
 
         equation = sp.simplify(sp.collect( solved, self.local_dict['dt']))
 
         # Obtain C code
         variable_name = self.c_code(self.local_dict[self.name])
 
-        explicit_code = Global.config['precision'] + ' _' + self.name + ' = '\
+        explicit_code = get_global_config('precision') + ' _' + self.name + ' = '\
                         +  self.c_code(equation) + ';'
         switch = variable_name + ' = _' + self.name + ' ;'
 
         # Return result
         return [{}, explicit_code, switch]
 
     def semiimplicit(self, expression):
         " Implicit or forward Euler numerical method, but only for the linear part of the equation."
         # Standardize the equation
         real_tau, stepsize, steadystate = self.standardize_ODE(expression)
 
         if real_tau is None: # the equation can not be standardized
-            Global._print(expression)
-            Global._warning('The implicit Euler method can not be applied to this equation (must be linear), applying explicit Euler instead.')
+            Messages._print(expression)
+            Messages._warning('The implicit Euler method can not be applied to this equation (must be linear), applying explicit Euler instead.')
             return self.explicit(expression)
 
         instepsize = sp.together( stepsize / (stepsize + sp.S(1.0)) )
 
         # Obtain C code
         variable_name = self.c_code(self.local_dict[self.name])
 
-        explicit_code = Global.config['precision'] + ' _' + self.name + ' = ('\
+        explicit_code = get_global_config('precision') + ' _' + self.name + ' = ('\
                         +  self.c_code(instepsize) + ')*(' \
                         + self.c_code(steadystate)+ ' - ' + variable_name +');'
         switch = variable_name + ' += _' + self.name + ' ;'
 
         # Return result
         return [{}, explicit_code, switch]
 
@@ -474,15 +475,15 @@
             pre_loop['value'] = '1.0 - exp( ' + self.c_code(-stepsize) + ')'
             step_size_code = "__stepsize_" + self.name
 
 
         # Obtain C code
         variable_name = self.c_code(self.local_dict[self.name])
 
-        explicit_code = Global.config['precision'] + ' _' + self.name + ' =  ' \
+        explicit_code = get_global_config('precision') + ' _' + self.name + ' =  ' \
                         + step_size_code \
                         + '*(' \
                         + self.c_code(steadystate) \
                         + ' - ' \
                         + self.c_code(self.local_dict[self.name]) \
                         +');'
 
@@ -492,23 +493,23 @@
         return [pre_loop, explicit_code, switch]
 
     def eventdriven(self, expression):
         # Standardize the equation
         real_tau, _, steadystate = self.standardize_ODE(expression)
 
         if real_tau is None: # the equation can not be standardized
-            Global._print(self.expression)
-            Global._error('The equation is not a linear ODE and can not be evaluated exactly.')
+            Messages._print(self.expression)
+            Messages._error('The equation is not a linear ODE and can not be evaluated exactly.')
 
 
         # Check the steady state is not dependent on other variables
         for var in self.variables:
             if self.local_dict[var] in steadystate.atoms():
-                Global._print(self.expression)
-                Global._error('The equation can not depend on other variables ('+var+') to be evaluated exactly.')
+                Messages._print(self.expression)
+                Messages._error('The equation can not depend on other variables ('+var+') to be evaluated exactly.')
 
 
         # Obtain C code
         variable_name = self.c_code(self.local_dict[self.name])
         steady = self.c_code(steadystate)
         if steady == '0':
             code = variable_name + ' *= exp(dt*(_last_event%(local_index)s - (t))/(' + self.c_code(real_tau) + '));'
@@ -551,17 +552,17 @@
 
         # Make sure the expansion went well
         collected_var = sp.collect(expanded, self.local_dict[self.name], evaluate=False, exact=False)
 
         if not self.local_dict[self.name] in collected_var.keys() or len(collected_var)>2:
             collected_var = sp.collect(sp.simplify(expanded), self.local_dict[self.name], evaluate=False, exact=False)
             if not self.local_dict[self.name] in collected_var.keys() or len(collected_var)>2:
-                Global._print(self.expression)
+                Messages._print(self.expression)
                 print(collected_var)
-                Global._error('The exponential and event-driven methods are reserved for linear first-order ODEs of the type tau*d'+ self.name+'/dt + '+self.name+' = f(t). Use the explicit method instead.')
+                Messages._error('The exponential and event-driven methods are reserved for linear first-order ODEs of the type tau*d'+ self.name+'/dt + '+self.name+' = f(t). Use the explicit method instead.')
 
         factor_var = collected_var[self.local_dict[self.name]]
 
         collected_gradient = sp.collect(sp.expand(analysed, grad_var), grad_var, evaluate=False, exact=False)
         if grad_var in collected_gradient.keys():
             factor_gradient = collected_gradient[grad_var]
         else:
```

### Comparing `ANNarchy-4.7.3/ANNarchy/parser/Extraction.py` & `annarchy-4.8.0.1/ANNarchy/parser/Extraction.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,18 +1,20 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-import ANNarchy.core.Global as Global
 from ANNarchy.core.Random import available_distributions, distributions_arguments, distributions_equivalents
 from ANNarchy.parser.Equation import Equation
 from ANNarchy.parser.Function import FunctionParser
 from ANNarchy.parser.StringManipulation import *
 from ANNarchy.parser.ITE import *
+from ANNarchy.intern.ConfigManagement import get_global_config, _check_paradigm
+from ANNarchy.intern.GlobalObjects import GlobalObjectManager
+from ANNarchy.intern import Messages
 
 import re
 
 
 def extract_randomdist(description):
     " Extracts RandomDistribution objects from all variables"
     rk_rand = 0
@@ -20,41 +22,41 @@
     for variable in description['variables']:
         # Equation
         eq = variable['eq']
         # Dependencies
         dependencies = []
         # Search for all distributions
         for dist in available_distributions:
-            matches = re.findall('(?P<pre>[^\w.])'+dist+'\(([^()]+)\)', eq)
+            matches = re.findall(r'(?P<pre>[^\w.])'+dist+r'\(([^()]+)\)', eq)
             if matches == ' ':
                 continue
             for l, v in matches:
 
                 # Check the arguments
                 arguments = v.split(',')
 
                 # Check the number of provided arguments
                 if len(arguments) < distributions_arguments[dist]:
-                    Global._print(eq)
-                    Global._error('The distribution ' + dist + ' requires ' + str(distributions_arguments[dist]) + 'parameters')
+                    Messages._print(eq)
+                    Messages._error('The distribution ' + dist + ' requires ' + str(distributions_arguments[dist]) + 'parameters')
                 elif len(arguments) > distributions_arguments[dist]:
-                    Global._print(eq)
-                    Global._error('Too many parameters provided to the distribution ' + dist)
+                    Messages._print(eq)
+                    Messages._error('Too many parameters provided to the distribution ' + dist)
 
                 # Process the arguments
                 processed_arguments = ""
                 for idx in range(len(arguments)):
                     try:
                         arg = float(arguments[idx])
                     except: # A global parameter
                         if arguments[idx].strip() in description['global']:
                             arg = arguments[idx].strip() + "%(global_index)s"
                             dependencies.append(arguments[idx].strip())
                         else:
-                            Global._error(arguments[idx] + ' is not a global parameter of the neuron/synapse. It can not be used as an argument to the random distribution ' + dist + '(' + v + ')')
+                            Messages._error(arguments[idx] + ' is not a global parameter of the neuron/synapse. It can not be used as an argument to the random distribution ' + dist + '(' + v + ')')
 
                     processed_arguments += str(arg)
                     if idx != len(arguments)-1: # not the last one
                         processed_arguments += ', '
 
                 definition = distributions_equivalents[dist] + '(' + processed_arguments + ')'
 
@@ -93,52 +95,52 @@
     returns a dictionary of changes.
     """
     untouched = {}
     globs = []
     # Global ops
     glop_names = ['min', 'max', 'mean', 'norm1', 'norm2']
     for op in glop_names:
-        matches = re.findall('([^\w]*)'+op+'\(([\s\w]*)\)', eq)
+        matches = re.findall(r'([^\w]*)' + op + r'\(([\s\w]*)\)', eq)
         for pre, var in matches:
             if var.strip() in description['local']:
                 globs.append({'function': op, 'variable': var.strip()})
                 oldname = op + '(' + var + ')'
                 newname = '_' + op + '_' + var.strip()
                 eq = eq.replace(oldname, newname)
                 untouched[newname] = '_' + op + '_' + var.strip()
             else:
-                Global._print(eq)
-                Global._error('There is no local attribute '+var+'.')
+                Messages._print(eq)
+                Messages._error('There is no local attribute '+var+'.')
 
     return eq, untouched, globs
 
 def extract_globalops_synapse(name, eq, desc):
     """
     Replaces global operations (mean(pre.r), etc)  with arbitrary names and
     returns a dictionary of changes.
     """
     untouched = {}
     globs = {'pre' : [],
              'post' : [] }
     glop_names = ['min', 'max', 'mean', 'norm1', 'norm2']
 
     for op in glop_names:
-        pre_matches = re.findall('([^\w.])'+op+'\(\s*pre\.([\w]+)\s*\)', eq)
-        post_matches = re.findall('([^\w.])'+op+'\(\s*post\.([\w]+)\s*\)', eq)
+        pre_matches = re.findall(r'([^\w.])' + op + r'\(\s*pre\.([\w]+)\s*\)', eq)
+        post_matches = re.findall(r'([^\w.])' + op + r'\(\s*post\.([\w]+)\s*\)', eq)
 
         for pre, var in pre_matches:
             globs['pre'].append({'function': op, 'variable': var.strip()})
             newname =  '__pre_' + op + '_' + var.strip()
-            eq = re.sub(op+'\(\s*pre\.([\w]+)\s*\)', newname, eq)
+            eq = re.sub(op+r'\(\s*pre\.([\w]+)\s*\)', newname, eq)
             untouched[newname] = '%(pre_prefix)s_' + op + '_' + var
 
         for pre, var in post_matches:
             globs['post'].append({'function': op, 'variable': var.strip()})
             newname = '__post_' + op + '_' + var.strip()
-            eq = re.sub(op+'\(\s*post\.([\w]+)\s*\)', newname, eq)
+            eq = re.sub(op+r'\(\s*post\.([\w]+)\s*\)', newname, eq)
             untouched[newname] = '%(post_prefix)s_' + op + '_' + var
 
     return eq, untouched, globs
 
 def extract_prepost(name, eq, description):
     " Replaces pre.var and post.var with arbitrary names and returns a dictionary of changes."
 
@@ -150,46 +152,46 @@
     untouched = {}
     # Replace all pre.* occurences with a temporary variable
     for var in list(set(pre_matches)):
         if var == 'sum': # pre.sum(exc)
             def idx_target(val):
                 target = val.group(1).strip()
                 if target == '':
-                    Global._print(eq)
-                    Global._error('pre.sum() requires one argument.')
+                    Messages._print(eq)
+                    Messages._error('pre.sum() requires one argument.')
 
                 rep = '_pre_sum_' + target.strip()
                 dependencies['pre'].append('sum('+target+')')
                 untouched[rep] = '%(pre_prefix)s_sum_' +target+ '%(pre_index)s'
                 return rep
 
             eq = re.sub(r'pre\.sum\(([\s\w]+)\)', idx_target, eq)
         else:
             dependencies['pre'].append(var)
-            eq = re.sub("pre."+var+"([^_\w]+)", "_pre_"+var+"__\g<1>", eq+" ")
+            eq = re.sub(r"pre." + var + r"([^_\w]+)", "_pre_" + var + r"__\g<1>", eq + " ")
             # eq = eq.replace(target, ' _pre_'+var)
             untouched['_pre_'+var+'__'] = '%(pre_prefix)s' + var + '%(pre_index)s'
 
     # Replace all post.* occurences with a temporary variable
     for var in list(set(post_matches)):
         if var == 'sum': # post.sum(exc)
             def idx_target(val):
                 target = val.group(1).strip()
                 if target == '':
-                    Global._print(eq)
-                    Global._error('post.sum() requires one argument.')
+                    Messages._print(eq)
+                    Messages._error('post.sum() requires one argument.')
 
                 dependencies['post'].append('sum('+target+')')
                 rep = '_post_sum_' + target.strip()
                 untouched[rep] = '%(post_prefix)s_sum_' + target + '%(post_index)s'
                 return rep
             eq = re.sub(r'post\.sum\(([\s\w]+)\)', idx_target, eq)
         else:
             dependencies['post'].append(var)
-            eq = re.sub("post."+var+"([^_\w]+)", "_post_"+var+"__\g<1>", eq+" ")
+            eq = re.sub(r"post." + var + r"([^_\w]+)", r"_post_" + var + r"__\g<1>", eq + " ")
             # eq = eq.replace(target, ' _post_'+var+'__')
             untouched['_post_'+var+'__'] = '%(post_prefix)s' + var +'%(post_index)s'
 
     return eq, untouched, dependencies
 
 
 def extract_parameters(description, extra_values={}):
@@ -201,15 +203,15 @@
     # Analyse all variables
     for definition in parameter_list:
         # Check if there are flags after the : symbol
         equation, constraint = split_equation(definition)
         # Extract the name of the variable
         name = extract_name(equation)
         if name in ['_undefined', ""]:
-            Global._error("Definition can not be analysed: " + equation)
+            Messages._error("Definition can not be analysed: " + equation)
 
 
         # Process constraint
         bounds, flags, ctype, init = extract_boundsflags(constraint, equation, extra_values)
 
         # Determine locality
         for f in ['population', 'postsynaptic', 'projection']:
@@ -242,15 +244,15 @@
     # Analyse all variables
     for definition in variable_list:
         # Retrieve the name, equation and constraints for the variable
         equation = definition['eq']
         constraint = definition['constraint']
         name = definition['name']
         if name == '_undefined':
-            Global._error('The variable', name, 'can not be analysed.')
+            Messages._error('The variable', name, 'can not be analysed.')
 
         # Check the validity of the equation
         check_equation(equation)
 
         # Process constraint
         bounds, flags, ctype, init = extract_boundsflags(constraint)
 
@@ -281,64 +283,64 @@
         # Process the flags if any
         bounds, flags = extract_flags(constraint)
 
         # Get the type of the variable (float/int/bool)
         if 'int' in flags:
             ctype = 'int'
         elif 'bool' in flags:
-            ctype = 'bool' if Global._check_paradigm("openmp") else 'char'
+            ctype = 'bool' if _check_paradigm("openmp") else 'char'
         else:
-            ctype = Global.config['precision']
+            ctype = get_global_config('precision')
 
         # Get the init value if declared
         if 'init' in bounds.keys(): # Variables: explicitely set in init=xx
             init = bounds['init']
             if ctype == 'bool':
                 if init in ['false', 'False', '0']:
                     init = False
                 elif init in ['true', 'True', '1']:
                     init = True
-            elif init in Global.list_constants():
-                init = Global.get_constant(init)
+            elif init in GlobalObjectManager().list_constants():
+                init = GlobalObjectManager().get_constant(init)
             elif ctype == 'int':
                 init = int(init)
             else:
                 init = float(init)
 
         elif '=' in equation: # Parameters: the value is in the equation
             init = equation.split('=')[1].strip()
 
             # Boolean
             if init in ['false', 'False']:
                 init = False
-                ctype = 'bool' if Global._check_paradigm("openmp") else 'char'
+                ctype = 'bool' if _check_paradigm("openmp") else 'char'
             elif init in ['true', 'True']:
                 init = True
-                ctype = 'bool' if Global._check_paradigm("openmp") else 'char'
+                ctype = 'bool' if _check_paradigm("openmp") else 'char'
             # Constants
-            elif init in Global.list_constants():
-                init = Global.get_constant(init)
+            elif init in GlobalObjectManager().list_constants():
+                init = GlobalObjectManager().get_constant(init)
             # Extra-args (obsolete)
             elif init.strip().startswith("'"):
                 var = init.replace("'","")
                 init = extra_values[var]
             # Integers
             elif ctype == 'int':
                 try:
                     init = eval('int(' + init + ')')
                 except:
-                    Global._print(equation)
-                    Global._error('The value of the parameter is not an integer.')
+                    Messages._print(equation)
+                    Messages._error('The value of the parameter is not an integer.')
             # Floats
             else:
                 try:
                     init = eval('float(' + init + ')')
                 except:
-                    Global._print(equation)
-                    Global._error('The value of the parameter is not a float.')
+                    Messages._print(equation)
+                    Messages._error('The value of the parameter is not a float.')
 
         else: # Default = 0 according to ctype
             if ctype == 'bool':
                 init = False
             elif ctype == 'int':
                 init = 0
             elif ctype == 'double' or ctype == 'float':
@@ -367,27 +369,27 @@
         arguments = [arg.strip() for arg in arguments]
 
         # Check the function name is not reserved by Sympy
         from inspect import getmembers
         import sympy
         functions_list = [o[0] for o in getmembers(sympy)]
         if func_name in functions_list:
-            Global._error('The function name', func_name, 'is reserved by sympy. Use another one.')
+            Messages._error('The function name', func_name, 'is reserved by sympy. Use another one.')
 
         # Extract their types
         types = f['constraint']
         if types == '':
-            return_type = Global.config['precision']
-            arg_types = [Global.config['precision'] for a in arguments]
+            return_type = get_global_config('precision')
+            arg_types = [get_global_config('precision') for a in arguments]
         else:
             types = types.split(',')
             return_type = types[0].strip()
             arg_types = [arg.strip() for arg in types[1:]]
         if not len(arg_types) == len(arguments):
-            Global._error('You must specify exactly the types of return value and arguments in ' + eq)
+            Messages._error('You must specify exactly the types of return value and arguments in ' + eq)
 
         arg_line = ""
         for i in range(len(arguments)):
             arg_line += arg_types[i] + " " + arguments[i]
             if not i == len(arguments) -1:
                 arg_line += ', '
 
@@ -419,55 +421,55 @@
     attributes = []; local_var = []; global_var = []; semiglobal_var = []
     for p in parameters + variables:
         attributes.append(p['name'])
         if neuron:
             if 'population' in p['flags']:
                 global_var.append(p['name'])
             elif 'projection' in p['flags']:
-                Global._error('The attribute', p['name'], 'belongs to a neuron, the flag "projection" is forbidden.')
+                Messages._error('The attribute', p['name'], 'belongs to a neuron, the flag "projection" is forbidden.')
             elif 'postsynaptic' in p['flags']:
-                Global._error('The attribute', p['name'], 'belongs to a neuron, the flag "postsynaptic" is forbidden.')
+                Messages._error('The attribute', p['name'], 'belongs to a neuron, the flag "postsynaptic" is forbidden.')
             else:
                 local_var.append(p['name'])
         else:
             if 'population' in p['flags']:
-                Global._error('The attribute', p['name'], 'belongs to a synapse, the flag "population" is forbidden.')
+                Messages._error('The attribute', p['name'], 'belongs to a synapse, the flag "population" is forbidden.')
             elif 'projection' in p['flags']:
                 global_var.append(p['name'])
             elif 'postsynaptic' in p['flags']:
                 semiglobal_var.append(p['name'])
             else:
                 local_var.append(p['name'])
 
     return attributes, local_var, global_var, semiglobal_var
 
 def extract_targets(variables):
     targets = []
     for var in variables:
         # Rate-coded neurons
-        code = re.findall('(?P<pre>[^\w.])sum\(\s*([^()]+)\s*\)', var['eq'])
+        code = re.findall(r'(?P<pre>[^\w.])sum\(\s*([^()]+)\s*\)', var['eq'])
         for l, t in code:
             targets.append(t.strip())
         # Special case for sum()
-        if len(re.findall('([^\w.])sum\(\)', var['eq'])) > 0:
+        if len(re.findall(r'([^\w.])sum\(\)', var['eq'])) > 0:
             targets.append('__all__')
 
         # Spiking neurons
-        code = re.findall('([^\w.])g_([\w]+)', var['eq'])
+        code = re.findall(r'([^\w.])g_([\w]+)', var['eq'])
         for l, t in code:
             targets.append(t.strip())
 
     return list(set(targets))
 
 def extract_spike_variable(description):
 
     cond = prepare_string(description['raw_spike'])
     if len(cond) > 1:
-        Global._print(description['raw_spike'])
-        Global._error('The spike condition must be a single expression')
+        Messages._print(description['raw_spike'])
+        Messages._error('The spike condition must be a single expression')
 
     translator = Equation('raw_spike_cond',
                             cond[0].strip(),
                             description)
     raw_spike_code = translator.parse()
     # Also store the variables used in the condition, as it may be needed for CUDA generation
     spike_code_dependencies = translator.dependencies()
@@ -491,16 +493,16 @@
     the reset after the event is returned.
     """
     if description['raw_axon_spike'] == None:
         return None
 
     cond = prepare_string(description['raw_axon_spike'])
     if len(cond) > 1:
-        Global._print(description['raw_axon_spike'])
-        Global._error('The spike condition must be a single expression')
+        Messages._print(description['raw_axon_spike'])
+        Messages._error('The spike condition must be a single expression')
 
     translator = Equation('raw_axon_spike_cond',
                             cond[0].strip(),
                             description)
     raw_spike_code = translator.parse()
     # Also store the variables used in the condition, as it may be needed for CUDA generation
     spike_code_dependencies = translator.dependencies()
@@ -618,51 +620,53 @@
         eq = statement.strip()
         bounds = {}
         flags = []
 
     # Extract RD
     rd = None
     for dist in available_distributions:
-        matches = re.findall('(?P<pre>[^\w.])'+dist+'\(([^()]+)\)', eq)
+        matches = re.findall(r'(?P<pre>[^\w.])' + dist + r'\(([^()]+)\)', eq)
         for l, v in matches:
             # Check the arguments
             arguments = v.split(',')
             # Check the number of provided arguments
             if len(arguments) < distributions_arguments[dist]:
-                Global._print(eq)
-                Global._error('The distribution ' + dist + ' requires ' + str(distributions_arguments[dist]) + 'parameters')
+                Messages._print(eq)
+                Messages._error('The distribution ' + dist + ' requires ' + str(distributions_arguments[dist]) + 'parameters')
             elif len(arguments) > distributions_arguments[dist]:
-                Global._print(eq)
-                Global._error('Too many parameters provided to the distribution ' + dist)
+                Messages._print(eq)
+                Messages._error('Too many parameters provided to the distribution ' + dist)
             # Process the arguments
             processed_arguments = ""
             for idx in range(len(arguments)):
                 try:
                     arg = float(arguments[idx])
                 except: # A global parameter
-                    Global._print(eq)
-                    Global._error('Random distributions for creating/pruning synapses must use foxed values.')
+                    Messages._print(eq)
+                    Messages._error('Random distributions for creating/pruning synapses must use foxed values.')
 
                 processed_arguments += str(arg)
                 if idx != len(arguments)-1: # not the last one
                     processed_arguments += ', '
             definition = distributions_equivalents[dist] + '(' + processed_arguments + ')'
 
             # Store its definition
             if rd:
-                Global._print(eq)
-                Global._error('Only one random distribution per equation is allowed.')
+                Messages._print(eq)
+                Messages._error('Only one random distribution per equation is allowed.')
 
 
-            rd = {'name': 'rand_' + str(0) ,
-                    'origin': dist+'('+v+')',
-                    'dist': dist,
-                    'definition': definition,
-                    'args' : processed_arguments,
-                    'template': distributions_equivalents[dist]}
+            rd = {
+                'name': 'rand_' + str(0) ,
+                'origin': dist+'('+v+')',
+                'dist': dist,
+                'definition': definition,
+                'args' : processed_arguments,
+                'template': distributions_equivalents[dist]
+            }
 
     if rd:
         eq = eq.replace(rd['origin'], 'rd(rng)')
 
     # Extract pre/post dependencies
     eq, untouched, dependencies = extract_prepost('test', eq, description)
 
@@ -701,24 +705,24 @@
     elif 'runge-kutta4' in variable['flags']: # old name, backward compatibility
         method = 'rk4'
     elif 'rk4' in variable['flags']:
         method = 'rk4'
     elif 'explicit' in variable['flags']:
         method = 'explicit'
     elif 'exact' in variable['flags']:
-        Global._warning('The "exact" flag should now be replaced by "event-driven". It will stop being valid in a future release.')
+        Messages._warning('The "exact" flag should now be replaced by "event-driven". It will stop being valid in a future release.')
         method = 'event-driven'
     elif 'event-driven' in variable['flags']:
         method = 'event-driven'
     else:
-        method = Global.config['method']
+        method = get_global_config('method')
         if method == "runge-kutta4": # old name, backward compatibility
             method = 'rk4'
 
     return method
 
 def check_equation(equation):
     "Makes a formal check on the equation (matching parentheses, etc)"
     # Matching parentheses
     if equation.count('(') != equation.count(')'):
-        Global._print(equation)
-        Global._error('The number of parentheses does not match.')
+        Messages._print(equation)
+        Messages._error('The number of parentheses does not match.')
```

### Comparing `ANNarchy-4.7.3/ANNarchy/parser/Function.py` & `annarchy-4.8.0.1/ANNarchy/parser/Function.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,19 +1,21 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-import ANNarchy.core.Global as Global
+from ANNarchy.intern.GlobalObjects import GlobalObjectManager
+from ANNarchy.intern import Messages
 from ANNarchy.parser.Equation import transform_condition
-from .ParserTemplate import parser_dict, functions_dict, user_functions
+from ANNarchy.parser.ParserTemplate import functions_dict, user_functions
+from ANNarchy.core import Global
 
-import sympy as sp
-from sympy.parsing.sympy_parser import parse_expr, standard_transformations, convert_xor, auto_number
 import re
+import sympy as sp
+from sympy.parsing.sympy_parser import parse_expr, convert_xor, auto_number
 
 class FunctionParser(object):
     '''
     Class to analyse one equation.
     '''
     def __init__(self, 
                  name, 
@@ -40,22 +42,21 @@
 
         # Copy the default functions dictionary
         self.local_dict = functions_dict.copy()
         # Add the arguments to the dictionary
         for arg in self.args:
             self.local_dict[arg] = sp.Symbol(arg)
 
-
         # Add custom constants
-        for obj in Global._objects['constants']:
+        for obj in GlobalObjectManager().get_constants():
             self.local_dict[obj.name] = sp.Symbol(obj.name)
 
         # Add other functions    
         self.user_functions = user_functions.copy()
-        for func in [func[0] for func in Global._objects['functions']]:
+        for func in [func[0] for func in GlobalObjectManager().get_functions()]:
             self.user_functions[func] = func
             self.local_dict[func] = sp.Function(func)
 
         # Possibly conditionals (up to 10 per equation... dirty!)
         for i in range(10):
             self.local_dict['__conditional__'+str(i)] = sp.Symbol('__conditional__'+str(i))
 
@@ -85,16 +86,16 @@
 
         try:
             eq = parse_expr(expression,
                 local_dict = self.local_dict,
                 transformations = ((auto_number, convert_xor,))
             )
         except:
-            Global._print(expression)
-            Global._error('The function depends on unknown variables.')
+            Messages._print(expression)
+            Messages._erroror('The function depends on unknown variables.')
 
         return sp.ccode(eq, precision=8,
             user_functions=self.user_functions)
 
     def dependencies(self):
         "For compatibility with Equation."
         return self.args
```

### Comparing `ANNarchy-4.7.3/ANNarchy/parser/ITE.py` & `annarchy-4.8.0.1/ANNarchy/parser/ITE.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
-from ANNarchy.core.Global import _error, _print
+from ANNarchy.intern import Messages
 from ANNarchy.parser.Equation import Equation
 from ANNarchy.parser.Function import FunctionParser
 from ANNarchy.parser.StringManipulation import *
 
 
 def translate_ITE(name, eq, condition, description, untouched, function=False):
     " Recursively processes the different parts of an ITE statement"
@@ -128,31 +128,31 @@
     # Eventually split around =
     if split:
         left, right =  eq.split('=', 1)
     else:
         left = ''
         right = eq
 
-    nb_then = len(re.findall(':', right))
-    nb_else = len(re.findall('else', right))
+    nb_then = len(re.findall(r':', right))
+    nb_else = len(re.findall(r'else', right))
     # The equation contains a conditional statement
     if nb_then > 0:
         # A if must be right after the equal sign
         if not right.strip().startswith('if'):
-            _error(eq, '\nThe right term must directly start with a if statement.')
+            Messages._error(eq, '\nThe right term must directly start with a if statement.')
 
         # It must have the same number of : and of else
         if not nb_then == 2*nb_else:
-            _error(eq, '\nConditional statements must use both : and else.')
+            Messages._error(eq, '\nConditional statements must use both : and else.')
 
         multilined = transform(right)
         condition = parse(multilined)
         right = ' __conditional__0 ' # only one conditional allowed in that case
         if split:
             eq = left + '=' + right
         else:
             eq = right
     else:
-        _print(eq)
-        _error('Conditional statements must define "then" and "else" values.\n var = if condition: a else: b')
+        Messages._print(eq)
+        Messages._error('Conditional statements must define "then" and "else" values.\n var = if condition: a else: b')
 
     return eq, [condition]
```

### Comparing `ANNarchy-4.7.3/ANNarchy/parser/ParserTemplate.py` & `annarchy-4.8.0.1/ANNarchy/parser/ParserTemplate.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
 from sympy import Symbol, Function
-import ANNarchy.core.Global as Global
+from ANNarchy.intern.GlobalObjects import GlobalObjectManager
+from ANNarchy.intern import Messages
 
 # Dictionary of default elements for the C++ generation
 parser_dict = {
     'dt' : Symbol('dt'),
     't' : Symbol('(double(t)*dt)'),
     'w' : Symbol('w%(local_index)s'),
     'g_target': Symbol('sum'), # TODO: still useful?
@@ -63,27 +64,27 @@
     # Copy the default dictionary of built-in symbols or functions
     local_dict = parser_dict.copy()
     local_dict.update(functions_dict)
 
     # Add each variable of the neuron depending on its locality
     for var in local_attributes:
         if var in functions_dict.keys():
-            Global._error(var, "is a reserved keyword in ANNarchy.")
+            Messages._error(var, "is a reserved keyword in ANNarchy.")
         local_dict[var] = Symbol(var + '%(local_index)s')
     for var in semiglobal_attributes:
         if var in functions_dict.keys():
-            Global._error(var, "is a reserved keyword in ANNarchy.")
+            Messages._error(var, "is a reserved keyword in ANNarchy.")
         local_dict[var] = Symbol(var + '%(semiglobal_index)s')
     for var in global_attributes:
         if var in functions_dict.keys():
-            Global._error(var, "is a reserved keyword in ANNarchy.")
+            Messages._error(var, "is a reserved keyword in ANNarchy.")
         local_dict[var] = Symbol(var + '%(global_index)s')
 
     # Add custom constants
-    for obj in Global._objects['constants']:
+    for obj in GlobalObjectManager().get_constants():
         if obj.name in local_dict.keys():
             continue
         local_dict[obj.name] = Symbol(obj.name)
 
     # Add each untouched variable
     for var in untouched:
         local_dict[var] = Symbol(var)
```

### Comparing `ANNarchy-4.7.3/ANNarchy/parser/StringManipulation.py` & `annarchy-4.8.0.1/ANNarchy/parser/StringManipulation.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,48 @@
 """
 :copyright: Copyright 2013 - now, see AUTHORS.
 :license: GPLv2, see LICENSE for details.
 """
 
+# Authorized keywork for attributes
+authorized_keywords = [
+    # Init
+    'init',
+    # Bounds
+    'min',
+    'max',
+    # Locality
+    'population',
+    'postsynaptic',
+    'projection',
+    # Numerical methods
+    'explicit',
+    'implicit',
+    'semiimplicit',
+    'exponential',
+    'midpoint',
+    'rk4',
+    'runge-kutta4', # backward compatibility
+    'exact',
+    'event-driven',
+    # Refractory
+    'unless_refractory',
+    # Type
+    'int',
+    'bool',
+    'float',
+    # Event-based
+    'unless_post',
+]
+
 ####################################
 # Functions for string manipulation
 ####################################
 import re
-from ANNarchy.core.Global import _error, _warning, _print, authorized_keywords
+from ANNarchy.intern import Messages
 
 def split_equation(definition):
     " Splits a description into equation and flags."
     try:
         equation, constraint = definition.rsplit(':', 1)
     except ValueError:
         equation = definition.strip() # there are no constraints
@@ -32,16 +63,16 @@
 
 def prepare_string(stream):
     """ Splits up a multiline equation, remove comments and unneeded spaces or tabs."""
     expr_set = []
     # replace ; with new line and split the result up
     tmp_set = stream.replace(';', '\n').split('\n')
     for expr in tmp_set:
-        expr = re.sub('\#[\s\S]+', ' ', expr)   # remove comments
-        expr = re.sub('\s+', ' ', expr)     # remove additional tabs etc.
+        expr = re.sub(r'\#[\s\S]+', ' ', expr)   # remove comments
+        expr = re.sub(r'\s+', ' ', expr)     # remove additional tabs etc.
         if expr.strip() == '' or len(expr)==0: # through beginning line breaks or something similar empty strings are contained in the set
             continue
         expr_set.append(''.join(expr))
     return expr_set
 
 def extract_name(equation, left=False):
     " Extracts the name of a parameter/variable by looking the left term of an equation."
@@ -62,26 +93,26 @@
         # Search for increments
         operators = ['+', '-', '*', '/']
         for op in operators:
             if equation.endswith(op):
                 return equation.split(op)[0]
     # Check for error
     if name.strip() == "":
-        _error('the variable name can not be extracted from ' + equation)
+        Messages._error('the variable name can not be extracted from ' + equation)
 
     # Search for any operation in the left side
     operators = ['+', '-', '*', '/']
     ode = False
     for op in operators:
         if not name.find(op) == -1:
             ode = True
     if not ode: # variable name is alone on the left side
         return name
     # ODE: the variable name is between d and /dt
-    name = re.findall("d([\w]+)/dt", name)
+    name = re.findall(r"d([\w]+)/dt", name)
     if len(name) == 1:
         return name[0].strip()
     else:
         return '_undefined'
 
 
 def extract_flags(constraint):
@@ -161,29 +192,29 @@
                 equation = equation.strip()
                 constraint = constraint.strip()
             else:
                 equation = definition.strip() # there are no constraints
                 constraint = ''
 
         # Split the equation around operators = += -= *= /=, but not ==
-        split_operators = re.findall('([\s\w\+\-\*\/\)]+)=([^=])', equation)
+        split_operators = re.findall(r'([\s\w\+\-\*\/\)]+)=([^=])', equation)
         if len(split_operators) == 1: # definition of a new variable
             # Retrieve the name
             eq = split_operators[0][0]
             if eq.strip() == "":
-                _print(equation)
-                _error('The equation can not be analysed, check the syntax.')
+                Messages._print(equation)
+                Messages._error('The equation can not be analysed, check the syntax.')
 
             name = extract_name(eq, left=True)
             if name in ['_undefined', '']:
-                _error('No variable name can be found in ' + equation)
+                Messages._error('No variable name can be found in ' + equation)
 
             # Append the result
             variables.append({'name': name, 'eq': equation.strip(), 'constraint': constraint.strip()})
         elif len(split_operators) == 0:
             # Continuation of the equation on a new line: append the equation to the previous variable
             variables[-1]['eq'] += ' ' + equation.strip()
             variables[-1]['constraint'] += constraint
         else:
-            _error('Only one assignement operator is allowed per equation.')
+            Messages._error('Only one assignement operator is allowed per equation.')
 
     return variables
```

### Comparing `ANNarchy-4.7.3/ANNarchy/parser/report/LatexParser.py` & `annarchy-4.8.0.1/ANNarchy/parser/report/LatexParser.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-from sympy import *
+import sympy as sp
 from sympy.parsing.sympy_parser import parse_expr, standard_transformations, convert_xor, auto_number
 from sympy.printing.latex import LatexPrinter
 import re
 
-import ANNarchy.core.Global as Global
+from ANNarchy.intern import Messages
 from ANNarchy.core.Random import RandomDistribution
 from ..Extraction import *
 from ANNarchy.parser.AnalyseSynapse import analyse_synapse
 
 
 ##################################
 ### Process individual equations
@@ -43,63 +43,70 @@
     parameters = extract_parameters(neuron.parameters, neuron.extra_values)
     variables = extract_variables(neuron.equations)
     variable_names = [var['name'] for var in variables]
     attributes, local_var, semiglobal_var, global_var = get_attributes(parameters, variables, neuron=True)
 
     # Create a dictionary for parsing
     local_dict = {
-        'g_target': Symbol('g_{\\text{target}}'),
-        'dt': Symbol('\Delta t'),
-        't_pre': Symbol('t_{\\text{pre}}'),
-        't_post': Symbol('t_{\\text{pos}}'),
-        'Uniform': Function('\mathcal{U}'),
-        'Normal': Function('\mathcal{N}'),
-        'ite': Function('ite', nargs=3)
+        'g_target': sp.Symbol(r'g_{\text{target}}'),
+        'dt': sp.Symbol(r'\Delta t'),
+        't_pre': sp.Symbol(r't_{\text{pre}}'),
+        't_post': sp.Symbol(r't_{\text{pos}}'),
+        'Uniform': sp.Function(r'\mathcal{U}'),
+        'Normal': sp.Function(r'\mathcal{N}'),
+        'ite': sp.Function(r'ite', nargs=3)
     }
 
     for att in attributes:
-        local_dict[att] = Symbol(_latexify_name(att, variable_names))
+        local_dict[att] = sp.Symbol(_latexify_name(att, variable_names))
 
     tex_dict = {}
     for key, val in local_dict.items():
         tex_dict[val] = str(val)
 
     for var in variables:
         # Retrieve the equation
         eq = var['eq']
 
         # Extract sum(target)
         targets = []
-        target_list = re.findall('(?P<pre>[^\w.])sum\(\s*([^()]+)\s*\)', eq)
+        target_list = re.findall(r'(?P<pre>[^\w.])sum\(\s*([^()]+)\s*\)', eq)
         for l, t in target_list:
             if t.strip() == '':
                 continue
             replacement = target_replacements[len(targets)]
             targets.append((t.strip(), replacement))
-            local_dict[replacement] = Symbol(replacement)
+            local_dict[replacement] = sp.Symbol(replacement)
             tex_dict[replacement] = replacement
 
         for target, repl in targets:
             eq = eq.replace('sum('+target+')', repl)
 
         # Parse the equation
         ode = re.findall(r'([^\w]*)d([\w]+)/dt', eq)
         if len(ode) > 0:
             name = ode[0][1]
+            
             eq = eq.replace('d'+name+'/dt', '_grad_'+name)
-            grad_symbol = Symbol('\\frac{d'+_latexify_name(name, variable_names)+'}{dt}')
+            
+            grad_symbol = sp.Symbol(r'\frac{d'+_latexify_name(name, variable_names)+'}{dt}')
+            
             local_dict['_grad_'+name] = grad_symbol
-            tex_dict[grad_symbol] = '\\frac{d'+_latexify_name(name, variable_names)+'}{dt}'
+            
+            tex_dict[grad_symbol] = r'\frac{d'+_latexify_name(name, variable_names)+'}{dt}'
 
         var_code = _analyse_equation(var['eq'], eq, local_dict, tex_dict)
 
         # Replace the targets
         for target, repl in targets:
-            target = target.replace("_","\_")
-            var_code = var_code.replace(repl, '\\sum_{\\text{'+target+'}} w \cdot r^{\\text{pre}}(t-d)')
+            target = target.replace("_", r"\_")
+            var_code = var_code.replace(
+                repl, 
+                r'\sum_{\text{'+target+r'}} w \cdot r^{\text{pre}}(t-d)'
+            )
 
         # Add the code
         var['latex'] = var_code
         var['ode'] = len(ode) > 0
 
     if not neuron.spike: # rate-code, no spike
         return variables, "", []
@@ -127,46 +134,46 @@
     parameters = extract_parameters(synapse.parameters)
     variables = extract_variables(synapse.equations)
     variable_names = [var['name'] for var in variables]
     attributes, local_var, semiglobal_var, global_var = get_attributes(parameters, variables, neuron=False)
 
     # Create a dictionary for parsing
     local_dict = {
-        'w': Symbol('w(t)'),
-        'dt': Symbol('\Delta t'),
-        'g_target': Symbol('g_{\\text{target}(t)}'),
-        't_pre': Symbol('t_{\\text{pre}}'),
-        't_post': Symbol('t_{\\text{pos}}'),
-        'Uniform': Function('\mathcal{U}'),
-        'Normal': Function('\mathcal{N}'),
-        'ite': Function('ite', nargs=3)
+        'w': sp.Symbol(r'w(t)'),
+        'dt': sp.Symbol(r'\Delta t'),
+        'g_target': sp.Symbol(r'g_{\text{target}(t)}'),
+        't_pre': sp.Symbol(r't_{\text{pre}}'),
+        't_post': sp.Symbol(r't_{\text{pos}}'),
+        'Uniform': sp.Function(r'\mathcal{U}'),
+        'Normal': sp.Function(r'\mathcal{N}'),
+        'ite': sp.Function(r'ite', nargs=3)
     }
 
     for att in attributes:
-        local_dict[att] = Symbol(_latexify_name(att, variable_names))
+        local_dict[att] = sp.Symbol(_latexify_name(att, variable_names))
 
     tex_dict = {}
     for key, val in local_dict.items():
         tex_dict[val] = str(val)
 
 
     # PSP
     if synapse.psp:
         psp, untouched_var, dependencies = extract_prepost('psp', synapse.psp.strip(), synapse.description)
         for dep in dependencies['post']:
-            local_dict['_post_'+dep+'__'] = Symbol("{" + dep + "^{\\text{post}}}(t)")
+            local_dict['_post_'+dep+'__'] = sp.Symbol(r"{" + dep + r"^{\text{post}}}(t)")
         for dep in dependencies['pre']:
-            local_dict['_pre_'+dep+'__'] = Symbol("{" + dep + "^{\\text{pre}}}(t-d)")
+            local_dict['_pre_'+dep+'__'] = sp.Symbol(r"{" + dep + r"^{\text{pre}}}(t-d)")
         if synapse.type == 'rate':  
             psp = _analyse_part(psp, local_dict, tex_dict)
         else:  
-            psp = "g_\\text{target}(t) \mathrel{+}= " + _analyse_part(psp, local_dict, tex_dict)
+            psp = r"g_\text{target}(t) \mathrel{+}= " + _analyse_part(psp, local_dict, tex_dict)
     else:
         if synapse.type == 'rate':
-            psp = "w(t) \cdot r^{\\text{pre}}(t)"
+            psp = r"w(t) \cdot r^{\text{pre}}(t)"
         else:
             psp = ""
 
 
     # Variables
     for var in variables:
         # Retrieve the equation
@@ -176,70 +183,77 @@
         targets=[]
         eq, untouched_var, dependencies = extract_prepost(var['name'], eq, synapse.description)
 
         for dep in dependencies['post']:
             if dep.startswith('sum('):
                 target = re.findall(r'sum\(([\w]+)\)', dep)[0]
                 targets.append(target)
-                local_dict['_post_sum_'+target] = Symbol('PostSum'+target)
+                local_dict['_post_sum_'+target] = sp.Symbol('PostSum'+target)
             else:
-                local_dict['_post_'+dep+'__'] = Symbol("{{" + _latexify_name(dep, variable_names) + "}^{\\text{post}}}(t)")
+                content = r"{" + _latexify_name(dep, variable_names) + r"^{\text{post}}}(t)"
+                local_dict['_post_'+dep+'__'] = sp.Symbol(content)
 
         for dep in dependencies['pre']:
             if dep.startswith('sum('):
                 target = re.findall(r'sum\(([\w]+)\)', dep)[0]
                 targets.append(target)
-                local_dict['_pre_sum_'+target] = Symbol('PreSum'+target)
+                local_dict['_pre_sum_'+target] = sp.Symbol('PreSum'+target)
             else:
-                local_dict['_pre_'+dep+'__'] = Symbol("{" + dep + "^{\\text{pre}}}(t-d)")
+                local_dict['_pre_'+dep+'__'] = sp.Symbol("{" + dep + r"^{\text{pre}}}(t-d)")
 
         # Parse the equation
         #eq = eq.replace(' ', '') # supress spaces
         ode = re.findall(r'([^\w]*)d([\w]+)/dt', eq)
         if len(ode) > 0:
+            
             name = ode[0][1]
             eq = eq.replace('d'+name+'/dt', '_grad_'+name)
-            grad_symbol = Symbol('\\frac{d'+_latexify_name(name, variable_names)+'}{dt}')
+            
+            grad_symbol = sp.Symbol(r'\frac{d'+_latexify_name(name, variable_names)+r'}{dt}')
+            
             local_dict['_grad_'+name] = grad_symbol
-            tex_dict[grad_symbol] = '\\frac{d'+_latexify_name(name, variable_names)+'}{dt}'
+            
+            tex_dict[grad_symbol] = r'\frac{d'+_latexify_name(name, variable_names)+r'}{dt}'
 
         # Analyse
         var_code = _analyse_equation(var['eq'], eq, local_dict, tex_dict)
 
         # replace targets
         for target in targets:
-            var_code = var_code.replace('PostSum'+target, "(\\sum_{\\text{" + target + "}} \\text{psp}(t))^{\\text{post}}")
-            var_code = var_code.replace('PreSum'+target,  "(\\sum_{\\text{" + target + "}} \\text{psp}(t))^{\\text{pre}}")
+            
+            var_code = var_code.replace('PostSum'+target, r"(\sum_{\text{" + target + r"}} \text{psp}(t))^{\text{post}}")
+            
+            var_code = var_code.replace('PreSum'+target,  r"(\sum_{\text{" + target + r"}} \text{psp}(t))^{\text{pre}}")
 
         # Add the code
         var['latex'] = var_code
         var['ode'] = len(ode) > 0
 
     # Pre-event
     if synapse.type == 'spike':
         desc = analyse_synapse(synapse)
         for var in extract_pre_spike_variable(desc):
             eq = var['eq']
             # pre/post variables
             eq, untouched_var, dependencies = extract_prepost(var['name'], eq, desc)
             for dep in dependencies['post']:
-                local_dict['_post_'+dep+'__'] = Symbol("{" + dep + "^{\\text{post}}}(t)")
+                local_dict['_post_'+dep+'__'] = sp.Symbol(r"{" + dep + r"^{\text{post}}}(t)")
             for dep in dependencies['pre']:
-                local_dict['_pre_'+dep+'__'] = Symbol("{" + dep + "^{\\text{pre}}}(t)")
+                local_dict['_pre_'+dep+'__'] = sp.Symbol(r"{" + dep + r"^{\text{pre}}}(t)")
 
             pre_event.append(_analyse_equation(var['eq'], eq, local_dict, tex_dict))
 
         for var in extract_post_spike_variable(desc):
             eq = var['eq']
             # pre/post variables
             eq, untouched_var, dependencies = extract_prepost(var['name'], eq, desc)
             for dep in dependencies['post']:
-                local_dict['_post_'+dep+'__'] = Symbol("{" + dep + "^{\\text{post}}}(t)")
+                local_dict['_post_'+dep+'__'] = sp.Symbol(r"{" + dep + r"^{\text{post}}}(t)")
             for dep in dependencies['pre']:
-                local_dict['_pre_'+dep+'__'] = Symbol("{" + dep + "^{\\text{pre}}}(t)")
+                local_dict['_pre_'+dep+'__'] = sp.Symbol(r"{" + dep + r"^{\text{pre}}}(t)")
 
             post_event.append(_analyse_equation(var['eq'], eq, local_dict, tex_dict))
 
     return psp, variables, pre_event, post_event
 
 
 def _process_functions(functions, begin="\\begin{dmath*}\n", end="\n\\end{dmath*}"):
@@ -254,15 +268,15 @@
         for arg in args:
             args_list += _latexify_name(arg, []) + ", "
         args_list = args_list[:-2]
 
         # local dict
         local_dict = {}
         for att in args:
-            local_dict[att] = Symbol(_latexify_name(att, []))
+            local_dict[att] = sp.Symbol(_latexify_name(att, []))
         tex_dict = {}
         for key, val in local_dict.items():
             tex_dict[val] = str(val)
 
         # parse the content
         content = _analyse_part(func['content'], local_dict, tex_dict)
 
@@ -285,55 +299,58 @@
     left = eq.split('=')[0]
     split_idx = len(left)
     if left[-1] in ['+', '-', '*', '/']:
         op = left[-1]
         try:
             left = _analyse_part(left[:-1], local_dict, tex_dict)
         except Exception as e:
-            Global._print(e)
-            Global._warning('can not transform the left side of ' + orig +' to LaTeX, you have to do it by hand...')
+            Messages._print(e)
+            Messages._warning('can not transform the left side of ' + orig +' to LaTeX, you have to do it by hand...')
             left = left[:-1]
         operator = " = " + left +  " " + op + (" (" if op != '+' else '')
-        operator = " \mathrel{" + op + "}= " 
+        operator = r" \mathrel{" + op + r"}= " 
     else:
         try:
             left = _analyse_part(left, local_dict, tex_dict)
         except Exception as e:
-            Global._print(e)
-            Global._warning('can not transform the left side of ' + orig +' to LaTeX, you have to do it by hand...')
+            Messages._print(e)
+            Messages._warning('can not transform the left side of ' + orig +' to LaTeX, you have to do it by hand...')
         operator = " = "
 
     # Analyse the right part
     try:
         right = _analyse_part(eq[split_idx+1:], local_dict, tex_dict)
     except Exception as e:
-        Global._print(e)
-        Global._warning('can not transform the right side of ' + orig +' to LaTeX, you have to do it by hand...')
-        right = "\\textbf{TODO} %%" + eq[split_idx+1:]
+        Messages._print(e)
+        Messages._warning('can not transform the right side of ' + orig +' to LaTeX, you have to do it by hand...')
+        right = r"\textbf{TODO} %%" + eq[split_idx+1:]
 
     return left + operator + right + (" )" if operator.strip().endswith('(') else "")
 
 class CustomLatexPrinter(LatexPrinter):
     def _print_Function(self, expr, exp=None):
         '''
-        For ite() only
+        For ite(), pos() and neg() only.
         '''
         func = expr.func.__name__
         args = [ str(self._print(arg)) for arg in expr.args ]
         
         if func == 'ite':
-            return """\\begin{cases}
-%(then_code)s \qquad \\text{if} \quad %(if_code)s \\\\ 
-%(else_code)s \qquad \\text{otherwise.} 
+            return r"""
+\begin{cases}
+    %(then_code)s \qquad \text{if} \quad %(if_code)s \\
+    \\
+    %(else_code)s \qquad \text{otherwise.} 
 \end{cases}""" % {'if_code': args[0], 'then_code': args[1], 'else_code': args[2]}
 
         elif func in ['positive', 'pos']:
-            return "\left(" + str(self._print(args[0])) + "\\right)^+"
+            return r"(" + args[0] + r")^+"
+        
         elif func in ['negative', 'neg']:
-            return "(" + str(self._print(args[0])) + ")^-"
+            return r"(" + args[0] + r")^-"
 
         return LatexPrinter._print_Function(self, expr, exp)
 
 # Analyses and transform to latex a single part of an equation
 def _analyse_part(expr, local_dict, tex_dict):
 
     def regular_expr(expr):
@@ -361,15 +378,15 @@
         else:
             then_code = regular_expr(then_statement)
         # ELSE
         if isinstance(else_statement, list): # nested conditional
             else_code =  _extract_conditional(else_statement)
         else:
             else_code = regular_expr(else_statement)
-        return "\\begin{cases}" + then_code + "\qquad \\text{if} \quad " + if_code + "\\\\ "+ else_code +" \qquad \\text{otherwise.} \end{cases}"
+        return r"\begin{cases}" + then_code + r"\qquad \text{if} \quad " + if_code + r"\\ "+ else_code + r" \qquad \text{otherwise.} \end{cases}"
 
     # Replace and/or with sympy relationals
     expr = transform_condition(expr)
 
     # Extract if/then/else
     if 'else' in expr:
         ite_code = extract_ite(expr)
@@ -434,40 +451,40 @@
     parts = name.split('_')
     if len(parts) == 1:
         if len(name) == 1:
             equiv = name
         elif name in greek:
             equiv = '\\' + name
         else:
-            equiv = '{\\text{' + name + '}}'
+            equiv = r'{\text{' + name + '}}'
         if name in local:
             equiv = '{' + equiv + '}(t)'
         return equiv
     elif len(parts) == 2:
         equiv = ""
         for p in parts:
             if len(p) == 1:
                 equiv += '' + p + '_'
             elif p in greek:
                 equiv += '\\' + p + '_'
             else:
-                equiv += '{\\text{' + p + '}}' + '_'
+                equiv += r'{\text{' + p + '}}' + '_'
         equiv = equiv[:-1]
         if name in local:
             equiv = '{' + equiv + '}(t)'
         return equiv
     else:
-        equiv = '{\\text{' + name + '}}'
+        equiv = r'{\text{' + name + '}}'
         equiv = equiv.replace('_', '-')
         if name in local:
             equiv = equiv + '(t)'
         return equiv
 
 def pop_name(name):
-    return name.replace('_', '\_')
+    return name.replace('_', r'\_')
 
 
 def _format_list(l, sep):
     if not isinstance(l, list):
         return l
     target_list = ""
     for t in l:
```

### Comparing `ANNarchy-4.7.3/ANNarchy/parser/report/LatexReport.py` & `annarchy-4.8.0.1/ANNarchy/parser/report/LatexReport.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,22 +1,24 @@
-import ANNarchy.core.Global as Global
 import ANNarchy.parser.report.LatexParser as LatexParser
-from ANNarchy.core.Neuron import Neuron
+from ANNarchy.intern.NetworkManager import NetworkManager
+from ANNarchy.intern.GlobalObjects import GlobalObjectManager
+from ANNarchy.intern import Messages
 from ANNarchy.extensions.bold.BoldModel import BoldModel
 
 from ANNarchy.core.Synapse import Synapse
+from ANNarchy.core.Neuron import Neuron
 
 import numpy as np
 import os
 
 ##################################
 ### Templates
 ##################################
 
-header = """
+header = r"""
 %  LaTeX file for generating the Model Description Table in Fig. 5 of
 %
 %  Nordlie E, Gewaltig M-O, Plesser HE (2009)
 %  Towards Reproducible Descriptions of Neuronal Network Models.
 %  PLoS Comput Biol 5(8): e1000456.
 %
 %  Paper URL : http://dx.doi.org/10.1371/journal.pcbi.1000456
@@ -35,169 +37,167 @@
 %  2. The non-commercial clause applies only to the distribution of THIS FILE
 %     and LaTeX source code files derived from it. You may commercially publish
 %     documents generated using this file and derivatived versions of this file.
 %
 %  Contact: Hans Ekkehard Plesser, UMB (hans.ekkehard.plesser at umb.no)
 """
 
-preamble = """
-\\documentclass{article}
-\\usepackage[margin=1in]{geometry}
-\\usepackage{tabularx}
-\\usepackage{multirow}
-\\usepackage{colortbl}
-
-\\usepackage[fleqn]{amsmath}
-\\setlength{\\mathindent}{0em}
-%%\\usepackage{mathpazo}
-\\usepackage{breqn}
-
-\\usepackage[scaled=.95]{helvet}
-\\renewcommand\\familydefault{\\sfdefault}
-
-\\renewcommand\\arraystretch{1.2}
-\\pagestyle{empty}
-
-\\newcommand{\hdr}[3]{
-    \\multicolumn{#1}{|l|}{
-        \\color{white}\\cellcolor[gray]{0.0}
-        \\textbf{\makebox[0pt]{#2}\\hspace{0.5\\linewidth}\\makebox[0pt][c]{#3}}
+preamble = r"""
+\documentclass{article}
+\usepackage[margin=1in]{geometry}
+\usepackage{tabularx}
+\usepackage{multirow}
+\usepackage{colortbl}
+
+\usepackage[fleqn]{amsmath}
+\setlength{\mathindent}{0em}
+%%\usepackage{mathpazo}
+\usepackage{breqn}
+
+\usepackage[scaled=.95]{helvet}
+\renewcommand\familydefault{\sfdefault}
+
+\renewcommand\arraystretch{1.2}
+\pagestyle{empty}
+
+\newcommand{\hdr}[3]{
+    \multicolumn{#1}{|l|}{
+        \color{white}\cellcolor[gray]{0.0}
+        \textbf{\makebox[0pt]{#2}\hspace{0.5\linewidth}\makebox[0pt][c]{#3}}
     }
 }
 
-\\begin{document}
+\begin{document}
 """
 
-summary_template="""
-\\noindent
-\\begin{tabularx}{\\linewidth}{|l|X|}\\hline
-\\hdr{2}{A}{Model Summary}\\\\ \\hline
-\\textbf{Populations}     & %(population_names)s \\\\ \\hline
-\\textbf{Topology}        & --- \\\\ \\hline
-\\textbf{Connectivity}    & %(connectivity)s \\\\ \\hline
-\\textbf{Neuron models}   & %(neuron_models)s \\\\ \\hline
-\\textbf{Channel models}  & --- \\\\ \\hline
-\\textbf{Synapse models}  & --- \\\\ \\hline
-\\textbf{Plasticity}      & %(synapse_models)s\\\\ \\hline
-\\textbf{Input}           & --- \\\\ \\hline
-\\textbf{Measurements}    & %(measurements)s \\\\ \\hline
-\\end{tabularx}
-
-\\vspace{2ex}
-"""
-
-populations_template = """
-\\noindent
-\\begin{tabularx}{\\linewidth}{|l|l|X|}\\hline
-\\hdr{3}{B}{Populations}\\\\ \\hline
-    \\textbf{Name}   & \\textbf{Elements} & \\textbf{Size} \\\\ \\hline
+summary_template = r"""
+\noindent
+\begin{tabularx}{\linewidth}{|l|X|}\hline
+\hdr{2}{A}{Model Summary}\\ \hline
+\textbf{Populations}     & %(population_names)s \\ \hline
+\textbf{Topology}        & --- \\ \hline
+\textbf{Connectivity}    & %(connectivity)s \\ \hline
+\textbf{Neuron models}   & %(neuron_models)s \\ \hline
+\textbf{Channel models}  & --- \\ \hline
+\textbf{Synapse models}  & --- \\ \hline
+\textbf{Plasticity}      & %(synapse_models)s\\ \hline
+\textbf{Input}           & --- \\ \hline
+\textbf{Measurements}    & %(measurements)s \\ \hline
+\end{tabularx}
+
+\vspace{2ex}
+"""
+
+populations_template = r"""
+\noindent
+\begin{tabularx}{\linewidth}{|l|l|X|}\hline
+\hdr{3}{B}{Populations}\\ \hline
+    \textbf{Name}   & \textbf{Elements} & \textbf{Size} \\ \hline
 %(populations_description)s
-\\end{tabularx}
+\end{tabularx}
 
-\\vspace{2ex}
+\vspace{2ex}
 """
 
-connectivity_template = """
-\\noindent
-\\begin{tabularx}{\\linewidth}{|l|l|l|X|X|}\\hline
-\\hdr{5}{C}{Connectivity}\\\\ \\hline
-\\textbf{Source} & \\textbf{Destination} & \\textbf{Target} & \\textbf{Synapse} & \\textbf{Pattern} \\\\ \\hline
+connectivity_template = r"""
+\noindent
+\begin{tabularx}{\linewidth}{|l|l|l|X|X|}\hline
+\hdr{5}{C}{Connectivity}\\ \hline
+\textbf{Source} & \textbf{Destination} & \textbf{Target} & \textbf{Synapse} & \textbf{Pattern} \\ \hline
 %(projections_description)s
-\\end{tabularx}
+\end{tabularx}
 
-\\vspace{2ex}
+\vspace{2ex}
 """
 
 
-parameters_template = """
-\\noindent
-\\begin{tabularx}{\\linewidth}{|X|}\\hline
-\hdr{1}{F}{Parameters}\\\\ \\hline
-\\\\ \\hline
-\\end{tabularx}
-\\vspace{2ex}
+parameters_template = r"""
+\noindent
+\begin{tabularx}{\linewidth}{|X|}\hline
+\hdr{1}{F}{Parameters}\\ \hline
+\\ \hline
+\end{tabularx}
+\vspace{2ex}
 """
 
-constants_template = """
-\\noindent
-\\begin{tabularx}{\\linewidth}{|p{0.25\\linewidth}|p{0.25\\linewidth}|X|}\\hline
-\\textbf{Constants} &\\textbf{Name} & \\textbf{Value}   \\\\ \\hline
+constants_template = r"""
+\noindent
+\begin{tabularx}{\linewidth}{|p{0.25\linewidth}|p{0.25\linewidth}|X|}\hline
+\textbf{Constants} &\textbf{Name} & \textbf{Value}   \\ \hline
 %(parameters)s
-\\end{tabularx}
+\end{tabularx}
 
-\\vspace{2ex}
+\vspace{2ex}
 """
 
-functions_template = """
-\\noindent
-\\begin{tabularx}{\\linewidth}{|p{0.25\\linewidth}|X|}\\hline
-\\textbf{Functions} &  
+functions_template = r"""
+\noindent
+\begin{tabularx}{\linewidth}{|p{0.25\linewidth}|X|}\hline
+\textbf{Functions} &  
 %(parameters)s
-\\\\ \\hline
-\\end{tabularx}
+\\ \hline
+\end{tabularx}
 
-\\vspace{2ex}
+\vspace{2ex}
 """
 
-popparameters_template = """
-\\noindent
-\\begin{tabularx}{\\linewidth}{|p{0.25\\linewidth}|p{0.25\\linewidth}|X|}\\hline
-\\textbf{Population} & \\textbf{Parameter} & \\textbf{Value}   \\\\ \\hline
+popparameters_template = r"""
+\noindent
+\begin{tabularx}{\linewidth}{|p{0.25\linewidth}|p{0.25\linewidth}|X|}\hline
+\textbf{Population} & \textbf{Parameter} & \textbf{Value}   \\ \hline
 %(parameters)s
-\\end{tabularx}
+\end{tabularx}
 
-\\vspace{2ex}
+\vspace{2ex}
 """
 
-projparameters_template = """
-\\noindent
-\\begin{tabularx}{\\linewidth}{|p{0.25\\linewidth}|p{0.25\\linewidth}|X|}\\hline
-\\textbf{Projection} & \\textbf{Parameter} & \\textbf{Value}   \\\\ \\hline
+projparameters_template = r"""
+\noindent
+\begin{tabularx}{\linewidth}{|p{0.25\linewidth}|p{0.25\linewidth}|X|}\hline
+\textbf{Projection} & \textbf{Parameter} & \textbf{Value}   \\ \hline
 %(parameters)s
-\\end{tabularx}
+\end{tabularx}
 
-\\vspace{2ex}
+\vspace{2ex}
 """
 
-input_template = """
-\\noindent
-\\begin{tabularx}{\\linewidth}{|l|X|}\\hline
-\\hdr{2}{G}{Input}\\\\ \\hline
-\\textbf{Type} & \\textbf{Description} \\\\ \\hline
+input_template = r"""
+\noindent
+\begin{tabularx}{\linewidth}{|l|X|}\hline
+\hdr{2}{G}{Input}\\ \hline
+\textbf{Type} & \textbf{Description} \\ \hline
 ---
-\\\\ \\hline
-\\end{tabularx}
+\\ \hline
+\end{tabularx}
 
-\\vspace{2ex}
+\vspace{2ex}
 
 """
 
-footer = """
-\\end{document}
+footer = r"""
+\end{document}
 """
 
 ##################################
 ### Main method
 ##################################
 
 def report_latex(filename="./report.tex", standalone=True, gather_subprojections=False, net_id=0):
-    """ Generates a .tex file describing the network according to:
+    """   
+    Generates a .tex file describing the network according to:
 
-    Nordlie E, Gewaltig M-O, Plesser HE (2009). Towards Reproducible Descriptions of Neuronal Network Models. PLoS Comput Biol 5(8): e1000456.
+    > Nordlie E, Gewaltig M-O, Plesser HE (2009). Towards Reproducible Descriptions of Neuronal Network Models. PLoS Comput Biol 5(8): e1000456.
 
-    **Parameters:**
-
-    * *filename*: name of the .tex file where the report will be written (default: "./report.tex")
-    * *standalone*: tells if the generated file should be directly compilable or only includable (default: True)
-    * *gather_subprojections*: if a projection between two populations has been implemented as a multiple of projections between sub-populations, this flag allows to group them in the summary (default: False).
-    * *net_id*: id of the network to be used for reporting (default: 0, everything that was declared)
+    :param filename: name of the .tex file where the report will be written (default: "./report.tex")
+    :param standalone: tells if the generated file should be directly compilable or only includable (default: True)
+    :param gather_subprojections: if a projection between two populations has been implemented as a multiple of projections between sub-populations, this flag allows to group them in the summary (default: False).
     """
 
     # stdout
-    Global._print('Generating report in', filename)
+    Messages._print('Generating report in', filename)
 
     # Generate the summary
     summary = _generate_summary(net_id)
     # Generate the populations
     populations = _generate_populations(net_id)
     # Generate the projections
     projections = _generate_projections(net_id, gather_subprojections)
@@ -244,31 +244,31 @@
 ##################################
 ### Process major fields
 ##################################
 
 def _generate_summary(net_id):
     "part A"
 
-    population_names = str(len(Global._network[net_id]['populations'])) + ': '
+    population_names = str(NetworkManager().number_populations(net_id=net_id)) + ': '
     connectivity = ""
     neuron_models = ""
     synapse_models = ""
 
     # List the names of all populations
-    for pop in Global._network[net_id]['populations']:
+    for pop in NetworkManager().get_populations(net_id=net_id):
         # population name
         population_names += LatexParser.pop_name(pop.name) + ", "
     population_names = population_names[:-2] # suppress the last ,
 
     # List all BOLD recordings
     measurements = ""
 
     # List all neuron types
     neuron_model_names = []
-    for neur in Global._objects['neurons']:
+    for neur in GlobalObjectManager().get_neuron_types():
         # bold models sorted in measurements
         if isinstance(neur, BoldModel):
             if neur._model_instantiated:
                 measurements += neur.name + ', '
         # neuron model
         else:
             neuron_model_names.append(neur.name)
@@ -276,15 +276,15 @@
         neuron_models += neur + ', '
     # suppress the last ,
     measurements = measurements[:-2]
     neuron_models = neuron_models[:-2]
 
     list_connectivity = []
     list_synapse_models = []
-    for proj in Global._network[net_id]['projections']:
+    for proj in NetworkManager().get_projections(net_id=net_id):
         list_connectivity.append(proj.connector_name)
         if not proj.synapse_type.name in list(Synapse._default_names.values()) + ['-']:
             list_synapse_models.append(proj.synapse_type.name)
     for con in list(set(list_connectivity)):
         connectivity += con + ', '
     for syn in list(set(list_synapse_models)):
         synapse_models += syn + ', '
@@ -308,92 +308,94 @@
             size += ' ('
             for d in range(pop.dimension):
                 size += str(pop.geometry[d]) + '*'
             size = size.rsplit('*', 1)[0] + ')'
         return size
 
     txt = ""
-    pop_tpl = """
-    %(pop_name)s             & %(neuron_type)s        & $N_{\\text{%(pop_name)s}}$ = %(size)s  \\\\ \\hline
+    pop_tpl = r"""
+    %(pop_name)s             & %(neuron_type)s        & $N_{\text{%(pop_name)s}}$ = %(size)s  \\ \hline
 """
-    for pop in Global._network[net_id]['populations']:
+    for pop in NetworkManager().get_populations(net_id=net_id):
         # Find a name for the neuron
         if pop.neuron_type.name in Neuron._default_names.values(): # name not set
             neuron_name = "Neuron " + str(pop.neuron_type._rk_neurons_type)
         else:
             neuron_name = pop.neuron_type.name
 
         txt += pop_tpl % {
             'pop_name': LatexParser.pop_name(pop.name), 
             'neuron_type': neuron_name, 
             'size': format_size(pop)}
 
     return populations_template % {'populations_description': txt}
 
 def _generate_constants(net_id):
-    cst_tpl = """
+    cst_tpl = r"""
     & $%(param)s$        & %(value)s  \\\\ \\hline
 """
     parameters = ""
-    if len(Global._objects['constants']) == 0:
+    if GlobalObjectManager().number_constants() == 0:
         return ""
 
-    for constant in Global._objects['constants']:
+    for constant in GlobalObjectManager().get_constants():
         parameters += cst_tpl % {'param': LatexParser._latexify_name(constant.name, []), 'value': constant.value}
 
     txt = constants_template % {'parameters': parameters}
 
     return txt
 
 
 def _generate_functions(net_id):
 
     functions = ""
-    if len(Global._objects['functions']) == 0:
+    if GlobalObjectManager().number_functions() == 0:
         return functions
 
-    for name, func in Global._objects['functions']:
+    for _, func in GlobalObjectManager().get_functions():
         functions += LatexParser._process_functions(func) + "\n"
 
-    return functions_template % {'parameters': functions, 'firstfunction': "\hdr{1}{G}{Functions}\\\\ \\hline"}
+    return functions_template % {
+        'parameters': functions, 
+        'firstfunction': r"\hdr{1}{G}{Functions}\\ \hline"}
 
 def _generate_population_parameters(net_id):
     txt = ""
-    pop_tpl = """
-    %(name)s             & $%(param)s$        & %(value)s  \\\\ \\hline
+    pop_tpl = r"""
+    %(name)s             & $%(param)s$        & %(value)s  \\ \hline
 """
-    for rk, pop in enumerate(Global._network[net_id]['populations']):
+    for rk, pop in enumerate(NetworkManager().get_populations(net_id=net_id)):
         parameters = ""
         for idx, param in enumerate(pop.parameters):
             val = pop.init[param]
             if isinstance(val, (list, np.ndarray)):
                 val = "$[" + str(np.array(val).min()) + ", " + str(np.array(val).max()) + "]$"
             parameters += pop_tpl % {'name': LatexParser.pop_name(pop.name) if idx==0 else "", 'param': LatexParser._latexify_name(param, []), 'value': val}
 
         if parameters != "":
-            txt += popparameters_template % {'parameters': parameters, 'firstpopulation': "\hdr{3}{H}{Population parameters}\\\\ \\hline" if rk==0 else ""}
+            txt += popparameters_template % {'parameters': parameters, 'firstpopulation': r"\hdr{3}{H}{Population parameters}\\ \hline" if rk==0 else ""}
 
     return txt
 
 def _generate_projections(net_id, gather_subprojections):
-    txt = ""
-    proj_tpl = """
+    txt = r""
+    proj_tpl = r"""
     %(pre)s & %(post)s & %(target)s & %(synapse)s &
-    %(description)s \\\\ \\hline
+    %(description)s \\ \hline
 """
     if gather_subprojections:
         projections = []
-        for proj in Global._network[net_id]['projections']:
+        for proj in NetworkManager().get_projections(net_id=net_id):
             for existing_proj in projections:
                 if proj.pre.name == existing_proj.pre.name and proj.post.name == existing_proj.post.name and proj.target == existing_proj.target : # TODO
                     break
             else:
                 projections.append(proj)
     else:
-        projections = Global._network[net_id]['projections']
+        projections = NetworkManager().get_projections(net_id=net_id)
 
     for proj in projections:
         # Find a name for the synapse
         if proj.synapse_type.name in Synapse._default_names.values(): # name not set
             synapse_name = "Synapse " + str(proj.synapse_type._rk_synapses_type)
         else:
             synapse_name = proj.synapse_type.name
@@ -404,27 +406,27 @@
                             'synapse': synapse_name,
                             'description': proj.connector_description}
 
     return connectivity_template % {'projections_description': txt}
 
 def _generate_projection_parameters(net_id, gather_subprojections):
     txt = ""
-    proj_tpl = """
-    %(name)s & $%(param)s$        & %(value)s  \\\\ \\hline
+    proj_tpl = r"""
+    %(name)s & $%(param)s$        & %(value)s  \\ \hline
 """
     if gather_subprojections:
         projections = []
-        for proj in Global._network[net_id]['projections']:
+        for proj in NetworkManager().get_projections(net_id=net_id):
             for existing_proj in projections:
                 if proj.pre.name == existing_proj.pre.name and proj.post.name == existing_proj.post.name and proj.target == existing_proj.target : # TODO
                     break
             else:
                 projections.append(proj)
     else:
-        projections = Global._network[net_id]['projections']
+        projections = NetworkManager().get_projections(net_id=net_id)
 
     first = True
     for rk, proj in enumerate(projections):
         parameters = ""
         for idx, param in enumerate(proj.parameters):
             if param == 'w':
                 continue
@@ -438,40 +440,42 @@
             val = proj.init[param]
             
             if isinstance(val, (list, np.ndarray)):
                 val = "$[" + str(np.min(val)) + ", " + str(np.max(val)) + "]$"
             parameters += proj_tpl % {'name': proj_name, 'param': LatexParser._latexify_name(param, []), 'value': val}
 
         if parameters != "":
-            txt += projparameters_template % {'parameters': parameters, 'firstprojection': "\hdr{3}{H}{Projection parameters}\\\\ \\hline" if first else ""}
+            txt += projparameters_template % {
+                'parameters': parameters, 
+                'firstprojection': r"\hdr{3}{H}{Projection parameters}\\ \hline" if first else ""}
             first = False
 
     return txt
 
 def _generate_neuron_models(net_id):
     neurons = ""
 
-    firstneuron = "\\hdr{2}{D}{Neuron Models}\\\\ \\hline"
+    firstneuron = r"\hdr{2}{D}{Neuron Models}\\ \hline"
 
-    neuron_tpl = """
-\\noindent
-\\begin{tabularx}{\\linewidth}{|p{0.15\\linewidth}|X|}\\hline
+    neuron_tpl = r"""
+\noindent
+\begin{tabularx}{\linewidth}{|p{0.15\linewidth}|X|}\hline
 %(firstneuron)s
-\\textbf{Name} & %(name)s \\\\ \\hline
-\\textbf{Type} & %(description)s\\\\ \\hline
-\\textbf{%(equation_type)s} &
+\textbf{Name} & %(name)s \\ \hline
+\textbf{Type} & %(description)s\\ \hline
+\textbf{%(equation_type)s} &
 %(variables)s
 %(spike)s
 %(functions)s
-\\end{tabularx}
-\\vspace{2ex}
+\end{tabularx}
+\vspace{2ex}
 """
 
     first_neuron = True
-    for neuron in Global._objects['neurons']:
+    for neuron in GlobalObjectManager().get_neuron_types():
 
         # skip bold models
         if isinstance(neuron, BoldModel):
             continue
 
         # Name
         if neuron.name in Neuron._default_names.values(): # name not set
@@ -480,56 +484,56 @@
             neuron_name = neuron.name
 
         # Generate the code for the equations
         variables, spike_condition, spike_reset = LatexParser._process_neuron_equations(neuron)
 
         eqs = ""
         for var in variables:
-            eqs += """
-\\begin{dmath*}
+            eqs += r"""
+\begin{dmath*}
 %(eq)s
-\\end{dmath*}
+\end{dmath*}
 """ % {'eq': var['latex']}
 
-        variables_eqs = """
+        variables_eqs = r"""
 %(eqs)s
-\\\\ \\hline
+\\ \hline
 """ % {'eqs': eqs}
 
         # Spiking neurons have an extra field for the spike condition
         spike_extra = ""
         if neuron.type == 'spike':
-            spike_code = "If $" + spike_condition + "$ or $t \leq t^* + t_{\\text{refractory}}$:"
+            spike_code = "If $" + spike_condition + r"$ or $t \leq t^* + t_{\text{refractory}}$:"
 
             # Reset
-            spike_code += """
-            \\begin{enumerate}
-                \\item Emit a spike at time $t^*$"""
+            spike_code += r"""
+            \begin{enumerate}
+                \item Emit a spike at time $t^*$"""
 
             for var in spike_reset:
-                spike_code += """
-            \\item $""" + var + "$"
+                spike_code += r"""
+            \item $""" + var + "$"
 
-            spike_code += """
-        \\end{enumerate}"""
+            spike_code += r"""
+        \end{enumerate}"""
 
 
-            spike_extra = """
-\\textbf{Spiking} &
+            spike_extra = r"""
+\textbf{Spiking} &
 %(spike)s
-\\\\ \\hline
+\\ \hline
 """ % {'spike': spike_code}
 
         # Possible function
         functions = ""
         if not neuron.functions == None:
-            functions = """
-\\textbf{Functions} &
+            functions = r"""
+\textbf{Functions} &
 %(functions)s
-\\\\ \\hline
+\\ \hline
 """ % {'functions': LatexParser._process_functions(neuron.functions)}
 
         # Build the dictionary
         desc = {
             'name': neuron_name,
             'description': neuron.short_description,
             'firstneuron': firstneuron if first_neuron else "",
@@ -547,31 +551,31 @@
 
     return neurons
 
 def _generate_synapse_models(net_id):
     firstsynapse = ""
     synapses = ""
 
-    firstsynapse = "\\hdr{2}{E}{Synapse Models}\\\\ \\hline"
+    firstsynapse = r"\hdr{2}{E}{Synapse Models}\\ \hline"
 
-    synapse_tpl = """
-\\noindent
-\\begin{tabularx}{\\linewidth}{|p{0.15\\linewidth}|X|}\\hline
+    synapse_tpl = r"""
+\noindent
+\begin{tabularx}{\linewidth}{|p{0.15\linewidth}|X|}\hline
 %(firstsynapse)s
-\\textbf{Name} & %(name)s \\\\ \\hline
-\\textbf{Type} & %(description)s\\\\ \\hline
+\textbf{Name} & %(name)s \\ \hline
+\textbf{Type} & %(description)s\\ \hline
 %(psp)s
 %(variables)s
 %(preevent)s
 %(postevent)s
 %(functions)s
-\\end{tabularx}
-\\vspace{2ex}
+\end{tabularx}
+\vspace{2ex}
 """
-    for idx, synapse in enumerate(Global._objects['synapses']):
+    for idx, synapse in enumerate(GlobalObjectManager().get_synapse_types()):
         # Do not document default synapses
         if synapse.name == "-":
             continue
 
         # Find a name for the synapse
         if synapse.name in Synapse._default_names.values(): # name not set
             synapse_name = "Synapse " + str(synapse._rk_synapses_type)
@@ -579,84 +583,84 @@
             synapse_name = synapse.name
 
         # Generate the code for the equations
         psp, variables, pre_desc, post_desc = LatexParser._process_synapse_equations(synapse)
 
         eqs = ""
         for var in variables:
-            eqs += """
-\\begin{dmath*}
+            eqs += r"""
+\begin{dmath*}
 %(eq)s
-\\end{dmath*}
+\end{dmath*}
 """ % {'eq': var['latex']}
 
-        variables_eqs = """
+        variables_eqs = r"""
 %(eqs)s
-\\\\ \\hline
+\\ \hline
 """ % {'eqs': eqs}
 
         # Synaptic variables
-        variables = """
-\\textbf{Equations} & %(variables)s  
-\\\\ \\hline""" % {'variables':eqs} if eqs != "" else ""
+        variables = r"""
+\textbf{Equations} & %(variables)s  
+\\ \hline""" % {'variables':eqs} if eqs != "" else ""
 
         # PSP
         if psp != "":
-            psp_code = """
-\\textbf{PSP} & \\begin{dmath*}
+            psp_code = r"""
+\textbf{PSP} & \begin{dmath*}
 %(psp)s
-\\end{dmath*}
-\\\\ \\hline""" % {'psp': psp}
+\end{dmath*}
+\\ \hline""" % {'psp': psp}
         else:
             psp_code = ""
 
         # Spiking neurons have extra fields for the event-driven
         if synapse.type == 'spike':
             if len(pre_desc) > 0:
                 txt_pre = ""
                 for l in pre_desc:
-                    txt_pre += """
-\\begin{dmath*}
+                    txt_pre += r"""
+\begin{dmath*}
 %(eq)s
-\\end{dmath*}
+\end{dmath*}
 """ % {'eq': l}
-                preevent = """
-\\textbf{Pre-synaptic event} &
+                preevent = r"""
+\textbf{Pre-synaptic event} &
 %(preevent)s
-\\\\ \\hline
+\\ \hline
 """ % {'preevent': txt_pre}
             else:
                 preevent = ""
 
             if len(post_desc) > 0:
                 txt_post = ""
                 for l in post_desc:
-                    txt_post += """
-\\begin{dmath*}
+                    txt_post += r"""
+\begin{dmath*}
 %(eq)s
-\\end{dmath*}
+\end{dmath*}
 """ % {'eq': l}
-                postevent = """
-\\textbf{Post-synaptic event} &
+                postevent = r"""
+\textbf{Post-synaptic event} &
 %(postevent)s
-\\\\ \\hline
+\\ \hline
 """ % {'postevent': txt_post}
             else:
                 postevent = ""
         else:
             preevent = ""
             postevent = ""
 
         # Possible functions
         functions = ""
         if not synapse.functions == None:
-            functions = """
-\\textbf{Functions} &
+            functions = r"""
+\textbf{Functions} &
 %(functions)s
-\\\\ \\hline
+\\ \hline
 """ % {'functions': LatexParser._process_functions(synapse.functions)}
 
         # Build the dictionary
         desc = {
             'name': synapse_name,
             'description': synapse.short_description,
             'firstsynapse': firstsynapse if idx == 0 else "",
@@ -671,30 +675,30 @@
         synapses += synapse_tpl % desc
 
     return synapses
 
 def _generate_measurements(net_id):
     measurements = ""
 
-    header = "\\hdr{2}{D}{Bold Measurement Models}\\\\ \\hline"
+    header = r"\hdr{2}{D}{Bold Measurement Models}\\ \hline"
 
-    measurements_template = """
-\\noindent
-\\begin{tabularx}{\\linewidth}{|p{0.15\\linewidth}|X|}\\hline
+    measurements_template = r"""
+\noindent
+\begin{tabularx}{\linewidth}{|p{0.15\linewidth}|X|}\hline
 %(header)s
-\\textbf{Name} & %(name)s \\\\ \\hline
-\\textbf{Type} & %(description)s\\\\ \\hline
-\\textbf{%(equation_type)s} &
+\textbf{Name} & %(name)s \\ \hline
+\textbf{Type} & %(description)s\\ \hline
+\textbf{%(equation_type)s} &
 %(variables)s
-\\end{tabularx}
-\\vspace{2ex}
+\end{tabularx}
+\vspace{2ex}
 """
 
     first_define = True
-    for neuron in Global._objects['neurons']:
+    for neuron in GlobalObjectManager().get_neuron_types():
 
         # skip non-bold models
         if not isinstance(neuron, BoldModel):
             continue
 
         # the model is not used
         if not neuron._model_instantiated:
@@ -707,23 +711,23 @@
             neuron_name = neuron.name
 
         # Generate the code for the equations
         variables, _, _ = LatexParser._process_neuron_equations(neuron)
 
         eqs = ""
         for var in variables:
-            eqs += """
-\\begin{dmath*}
+            eqs += r"""
+\begin{dmath*}
 %(eq)s
-\\end{dmath*}
+\end{dmath*}
 """ % {'eq': var['latex']}
 
-        variables_eqs = """
+        variables_eqs = r"""
 %(eqs)s
-\\\\ \\hline
+\\ \hline
 """ % {'eqs': eqs}
 
         # Build the dictionary
         desc = {
             'name': neuron_name,
             'description': neuron.short_description,
             'header': header if first_define else "",
@@ -735,19 +739,19 @@
         measurements += measurements_template % desc
 
         # first_define disable to prevent multiple table header
         first_define = False
 
     # no models were processed
     if len(measurements) == 0:
-        measurements = """
-\\noindent
-\\begin{tabularx}{\\linewidth}{|l|X|}\\hline
-\\hdr{2}{H}{Measurement}\\\\ \\hline
-\\textbf{Type} & \\textbf{Description} \\\\ \\hline
+        measurements = r"""
+\noindent
+\begin{tabularx}{\linewidth}{|l|X|}\hline
+\hdr{2}{H}{Measurement}\\ \hline
+\textbf{Type} & \textbf{Description} \\ \hline
 ---
-\\\\ \\hline
-\\end{tabularx}
+\\ \hline
+\end{tabularx}
 """
 
 
     return measurements
```

### Comparing `ANNarchy-4.7.3/ANNarchy/parser/report/MarkdownReport.py` & `annarchy-4.8.0.1/ANNarchy/parser/report/MarkdownReport.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,9 +1,12 @@
 import ANNarchy
-import ANNarchy.core.Global as Global
+from ANNarchy.intern.NetworkManager import NetworkManager
+from ANNarchy.intern.ConfigManagement import get_global_config
+from ANNarchy.intern.GlobalObjects import GlobalObjectManager
+from ANNarchy.intern import Messages
 from ANNarchy.core.Neuron import Neuron
 from ANNarchy.core.Synapse import Synapse
 from ANNarchy.core.PopulationView import PopulationView
 import ANNarchy.parser.report.LatexParser as LatexParser
 from ANNarchy.parser.AnalyseNeuron import analyse_neuron
 from ANNarchy.parser.AnalyseSynapse import analyse_synapse
 from ..Extraction import *
@@ -11,30 +14,30 @@
 import numpy as np
 import os
 
 ##################################
 ### Main method
 ##################################
 
-def report_markdown(filename="./report.tex", standalone=True, gather_subprojections=False, title=None, author=None, date=None, net_id=0):
+def report_markdown(filename:str="./report.tex", standalone:bool=True, gather_subprojections:bool=False, title:str=None, author:str=None, date:str=None, net_id:int=0):
     """ Generates a .md file describing the network.
 
     *Parameters:*
 
     * **filename**: name of the .tex file where the report will be written (default: "./report.tex")
     * **standalone**: tells if the generated file should be directly compilable or only includable (ignored)
     * **gather_subprojections**: if a projection between two populations has been implemented as a multiple of projections between sub-populations, this flag allows to group them in the summary (default: False).
     * **net_id**: id of the network to be used for reporting (default: 0, everything that was declared)
     * **title**: title of the document (default: "Network description")
     * **author**: author of the document (default: "ANNarchy (Artificial Neural Networks architect)")
     * **date**: date of the document (default: empty)
     """
 
     # stdout
-    Global._print('Generating report in', filename)
+    Messages._print('Generating report in', filename)
 
     # Header
     if title == None:
         title = "Network description"
     if author == None:
         author = "ANNarchy (Artificial Neural Networks architect)"
     if date == None:
@@ -76,28 +79,28 @@
 
     txt = """
 # Structure of the network
 """
 
     # General information
     backend = 'default'
-    if Global.config['paradigm'] == 'cuda':
+    if get_global_config('paradigm') == 'cuda':
         backend = "CUDA"
-    elif Global.config['paradigm'] == "openmp" and Global.config['num_threads'] > 1:
+    elif get_global_config('paradigm') == "openmp" and get_global_config('num_threads') > 1:
         backend = "OpenMP"
     txt +="""
 * ANNarchy %(version)s using the %(backend)s backend.
 * Numerical step size: %(dt)s ms.
-""" % {'version': ANNarchy.__release__, 'backend': backend, 'dt': Global.config['dt']}
+""" % {'version': ANNarchy.__release__, 'backend': backend, 'dt': get_global_config('dt')}
 
     # Populations
-    if len(Global._network[net_id]['populations']) > 0:
+    if NetworkManager().number_populations(net_id=net_id) > 0:
         headers = ["Population", "Size", "Neuron type"]
         populations = []
-        for pop in Global._network[net_id]['populations']:
+        for pop in NetworkManager().get_populations(net_id=net_id):
             # Find a name for the neuron
             neuron_name = "Neuron " + str(pop.neuron_type._rk_neurons_type) if pop.neuron_type.name in Neuron._default_names.values() \
                 else pop.neuron_type.name
 
             populations.append([
                 pop.name, 
                 pop.geometry if len(pop.geometry)>1 else pop.size, 
@@ -107,18 +110,18 @@
 ## Populations
 
 """
         txt += _make_table(headers, populations)
 
 
     # Projections
-    if len(Global._network[net_id]['projections']) > 0 :
+    if NetworkManager().number_projections(net_id=net_id) > 0 :
         headers = ["Source", "Destination", "Target", "Synapse type", "Pattern"]
         projections = []
-        for proj in Global._network[net_id]['projections']:
+        for proj in NetworkManager().get_projections(net_id=net_id):
             # Find a name for the synapse
             synapse_name = "Synapse " + str(proj.synapse_type._rk_synapses_type) if proj.synapse_type.name in Synapse._default_names.values() \
                 else proj.synapse_type.name
 
             projections.append([
                 proj.pre.name, 
                 proj.post.name, 
@@ -130,36 +133,36 @@
         txt += """
 ## Projections
 
 """
         txt += _make_table(headers, projections)
 
     # Monitors
-    if len(Global._network[net_id]['monitors']) > 0:
+    if NetworkManager().number_monitors(net_id=net_id) > 0:
         headers = ["Object", "Variables", "Period"]
         monitors = []
-        for monitor in Global._network[net_id]['monitors']:
+        for monitor in NetworkManager().get_monitors(net_id=net_id):
             monitors.append([
                 monitor.object.name + (" (subset)" if isinstance(monitor.object, PopulationView) else ""), 
                 LatexParser._format_list(monitor.variables, ', '),
                 monitor.period
                 ])
 
         txt += """
 ## Monitors
 
 """
         txt += _make_table(headers, monitors)
 
     # Functions
-    if len(Global._objects['functions']) > 0 :
+    if GlobalObjectManager().number_functions() > 0 :
         txt += """## Functions
 
 """
-        for name, func in Global._objects['functions']:
+        for _, func in GlobalObjectManager().get_functions():
             txt += LatexParser._process_functions(func, begin="$$", end="$$\n\n")
 
     return txt
 
 
 # Neuron template
 neuron_tpl = """
@@ -175,15 +178,15 @@
 
 %(eqs)s
 """
 def _generate_neuron_models(net_id):
     txt = """
 # Neuron models
 """
-    for idx, neuron in enumerate(Global._objects['neurons']):
+    for idx, neuron in enumerate(GlobalObjectManager().get_neuron_types()):
 
         # Name
         if neuron.name in Neuron._default_names.values(): # name not set
             neuron_name = "Neuron " + str(neuron._rk_neurons_type)
         else:
             neuron_name = neuron.name
 
@@ -266,15 +269,15 @@
 %(psp)s
 """
 def _generate_synapse_models(net_id):
     txt = """
 # Synapse models
 """
 
-    for idx, synapse in enumerate(Global._objects['synapses']):
+    for idx, synapse in enumerate(GlobalObjectManager().get_synapse_types()):
 
         # Do not document default synapses
         if synapse.name == "-":
             continue
 
         # Find a name for the synapse
         synapse_name = "Synapse " + str(synapse._rk_synapses_type) if synapse.name in Synapse._default_names.values() else synapse.name
@@ -352,33 +355,33 @@
 
 def _generate_parameters(net_id, gather_subprojections):
     txt = """
 # Parameters
 """
 
     # Constants
-    if len(Global._objects['constants']) > 0:
+    if GlobalObjectManager().number_constants() > 0:
         txt += """
 ## Constants
 
 """
         constants_list = [
             ["$" + LatexParser._latexify_name(constant.name, []) + "$",  constant.value]
-                for constant in Global._objects['constants']]
+                for constant in GlobalObjectManager().get_constants()]
 
         constants_headers = ["Name", "Value"]
         txt += _make_table(constants_headers, constants_list)
 
     # Population parameters
     txt += """
 ## Population parameters
 
 """
     parameters_list = []
-    for rk, pop in enumerate(Global._network[net_id]['populations']):    
+    for rk, pop in enumerate(NetworkManager().get_populations(net_id=net_id)):    
         neuron_name = "Neuron " + str(pop.neuron_type._rk_neurons_type) if pop.neuron_type.name in Neuron._default_names.values() \
             else pop.neuron_type.name
 
         for idx, param in enumerate(pop.parameters):
             val = pop.init[param]
             if isinstance(val, (list, np.ndarray)):
                 val = "$[" + str(np.array(val).min()) + ", " + str(np.array(val).max()) + "]$"
@@ -394,23 +397,23 @@
     # Projection parameters
     txt += """
 ## Projection parameters
 
 """
     if gather_subprojections:
         projections = []
-        for proj in Global._network[net_id]['projections']:
+        for proj in NetworkManager().get_projections(net_id=net_id):
             for existing_proj in projections:
                 if proj.pre.name == existing_proj.pre.name and proj.post.name == existing_proj.post.name \
                     and proj.target == existing_proj.target : # TODO
                     break
             else:
                 projections.append(proj)
     else:
-        projections = Global._network[net_id]['projections']
+        projections = NetworkManager().get_projections(net_id=net_id)
 
     parameters_list = []
     for rk, proj in enumerate(projections):
         for idx, param in enumerate(proj.parameters):
             if param == 'w':
                 continue
             if idx == 0:
```

### Comparing `ANNarchy-4.7.3/ANNarchy/parser/report/Report.py` & `annarchy-4.8.0.1/ANNarchy/parser/report/Report.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,38 +1,37 @@
-from ANNarchy.core.Global import _network, _objects, _warning, _error, _print
+from ANNarchy.intern import Messages
 
 ##################################
 ### Main method
 ##################################
 
-def report(filename="./report.tex", standalone=True, gather_subprojections=False, title=None, author=None, date=None, net_id=0):
+def report(filename:str="./report.tex", standalone:bool=True, gather_subprojections:bool=False, title:str=None, author:str=None, date:str=None, net_id:int=0):
     """ 
     Generates a report describing the network.
 
     If the filename ends with ``.tex``, the TeX file is generated according to:
 
-    Nordlie E, Gewaltig M-O, Plesser HE (2009). Towards Reproducible Descriptions of Neuronal Network Models. PLoS Comput Biol 5(8): e1000456.
+    > Nordlie E, Gewaltig M-O, Plesser HE (2009). Towards Reproducible Descriptions of Neuronal Network Models. PLoS Comput Biol 5(8): e1000456.
 
     If the filename ends with ``.md``, a (more complete) Markdown file is generated, which can be converted to pdf or html by ``pandoc``::
 
-        pandoc report.md  -sSN -V geometry:margin=1in -o report.pdf
-        pandoc report.md  -sSN -o report.html
+        pandoc report.md -o report.pdf
+        pandoc report.md -o report.html
 
-    :param filename: name of the file where the report will be written (default: "./report.tex")
+    :param filename: name of the file where the report will be written.
     :param standalone: tells if the generated TeX file should be directly compilable or only includable (default: True). Ignored for Markdown.
-    :param gather_subprojections: if a projection between two populations has been implemented as a multiple of projections between sub-populations, this flag allows to group them in the summary (default: False).
-    :param title: title of the document (Markdown only)
-    :param author: author of the document (Markdown only)
-    :param date: date of the document (Markdown only)
-    :param net_id: id of the network to be used for reporting (default: 0, everything that was declared)
+    :param gather_subprojections: if a projection between two populations has been implemented as a multiple of projections between sub-populations, this flag allows to group them in the summary.
+    :param title: title of the document (Markdown only).
+    :param author: author of the document (Markdown only).
+    :param date: date of the document (Markdown only).
     """
 
     if filename.endswith('.tex'):
         from .LatexReport import report_latex
         report_latex(filename, standalone, gather_subprojections, net_id)
 
     elif filename.endswith('.md'):
         from .MarkdownReport import report_markdown
         report_markdown(filename, standalone, gather_subprojections, title, author, date, net_id)
 
     else:
-        _error('report(): the filename must end with .tex or .md.')
+        Messages._error('report(): the filename must end with .tex or .md.')
```

### Comparing `ANNarchy-4.7.3/ANNarchy/thirdparty/randutils.hpp` & `annarchy-4.8.0.1/ANNarchy/thirdparty/randutils.hpp`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/ANNarchy.egg-info/PKG-INFO` & `annarchy-4.8.0.1/ANNarchy.egg-info/PKG-INFO`

 * *Files 27% similar despite different names*

```diff
@@ -1,90 +1,88 @@
 Metadata-Version: 2.1
 Name: ANNarchy
-Version: 4.7.3
+Version: 4.8.0.1
 Summary: Artificial Neural Networks architect
 Author-email: Julien Vitay <julien.vitay@informatik.tu-chemnitz.de>, Helge Dinkelbach <helge-uelo.dinkelbach@informatik.tu-chemnitz.de>, Fred Hamker <fred.hamker@informatik.tu-chemnitz.de>
 License: GPLv2+
 Project-URL: Documentation, https://annarchy.github.io
 Project-URL: Issues, https://github.com/ANNarchy/ANNarchy/issues
 Project-URL: Source, https://github.com/ANNarchy/ANNarchy
 Keywords: neural simulator
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Environment :: Console
 Classifier: Intended Audience :: Science/Research
 Classifier: Programming Language :: Python
-Classifier: Programming Language :: Python :: 3.7
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
+Classifier: Programming Language :: Python :: 3.12
 Classifier: Programming Language :: Python :: Implementation :: CPython
-Classifier: Programming Language :: Python :: Implementation :: PyPy
-Requires-Python: >=3.7
+Requires-Python: >=3.10
 Description-Content-Type: text/markdown
 License-File: LICENSE
 License-File: AUTHORS
+Requires-Dist: setuptools
+Requires-Dist: cython
+Requires-Dist: numpy
+Requires-Dist: sympy
+Requires-Dist: scipy
+Requires-Dist: matplotlib
 
 # ANNarchy 
 
 [![DOI](https://zenodo.org/badge/57382690.svg)](https://zenodo.org/badge/latestdoi/57382690)
 
 
 ANNarchy (Artificial Neural Networks architect) is a parallel and hybrid simulator for distributed rate-coded or spiking neural networks. The core of the library is written in C++ and distributed using openMP or CUDA. It provides an interface in Python for the definition of the networks. It is released under the [GNU GPL v2 or later](http://www.gnu.org/licenses/gpl.html).
 
-The source code is available at:
-
-<https://github.com/ANNarchy/ANNarchy>
-
-The documentation is available online at:
-
-<https://annarchy.github.io/>
-
-A forum for discussion is set at:
-
-<https://groups.google.com/forum/#!forum/annarchy>
-
-Bug reports should be done through the [Issue Tracker](https://github.com/ANNarchy/ANNarchy/issues) of ANNarchy on Github.
+* Source code: [github.com/ANNarchy/ANNarchy](https://github.com/ANNarchy/ANNarchy)
+* Documentation: [annarchy.github.io](https://annarchy.github.io)
+* Forum: [google forum](https://groups.google.com/forum/#!forum/annarchy)
+* Bug reports and feature requests: [Issue Tracker](https://github.com/ANNarchy/ANNarchy/issues).
 
 ### Citation
 
 If you use ANNarchy for your research, we would appreciate if you cite the following paper:
 
 > Vitay J, Dinkelbach H and Hamker FH (2015). ANNarchy: a code generation approach to neural simulations on parallel hardware. *Frontiers in Neuroinformatics* 9:19. [doi:10.3389/fninf.2015.00019](http://dx.doi.org/10.3389/fninf.2015.00019)
 
 ### Authors
 
 * Julien Vitay (julien.vitay@informatik.tu-chemnitz.de).
 * Helge lo Dinkelbach (helge-uelo.dinkelbach@informatik.tu-chemnitz.de).
 * Fred Hamker (fred.hamker@informatik.tu-chemnitz.de).
 
-
 ## Installation
 
 Using pip, you can install the latest stable release:
 
-```
+```bash
 pip install ANNarchy
 ```
 
+See <https://annarchy.github.io/Installation> for further instructions.
+
 ## Platforms
 
 * GNU/Linux
 * MacOS X
+* Windows (inside WSL2)
 
 ## Dependencies
 
-* g++ >= 6.1 ( >= 7.4 recommended ) or clang++ >= 3.4
-* python >= 3.7 with development files
-* cython >= 0.20
-* setuptools >= 40.0
-* numpy >= 1.13
-* sympy >= 1.6
-* scipy >= 0.19
+* `python` >= 3.10 (with the development files, e.g. `python-dev` or `python-devel`)
+* `g++` >= 7.4 or `clang++` >= 3.4
+* `make` >= 3.0
+* `setuptools` >= 65.0
+* `cython` >= 3.0
+* `numpy` >= 1.21
+* `sympy` >= 1.11
+* `scipy` >= 1.9
+* `matplotlib` >= 3.0
 
 Recommended:
 
-* matplotlib
-* lxml 
-* PyQtGraph 
-* pandoc 
-* tensorboardX
+* `lxml` (to save the networks in `.xml` format).
+* `pandoc` (for `report()`).
+* `tensorflow` (for the `ann_to_snn_conversion` extension)
+* `tensorboardX` (for the `logging` extension).
+* `tqdm` (to display progress bars)
```

### Comparing `ANNarchy-4.7.3/LICENSE` & `annarchy-4.8.0.1/LICENSE`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/PKG-INFO` & `annarchy-4.8.0.1/PKG-INFO`

 * *Files 27% similar despite different names*

```diff
@@ -1,90 +1,88 @@
 Metadata-Version: 2.1
 Name: ANNarchy
-Version: 4.7.3
+Version: 4.8.0.1
 Summary: Artificial Neural Networks architect
 Author-email: Julien Vitay <julien.vitay@informatik.tu-chemnitz.de>, Helge Dinkelbach <helge-uelo.dinkelbach@informatik.tu-chemnitz.de>, Fred Hamker <fred.hamker@informatik.tu-chemnitz.de>
 License: GPLv2+
 Project-URL: Documentation, https://annarchy.github.io
 Project-URL: Issues, https://github.com/ANNarchy/ANNarchy/issues
 Project-URL: Source, https://github.com/ANNarchy/ANNarchy
 Keywords: neural simulator
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Environment :: Console
 Classifier: Intended Audience :: Science/Research
 Classifier: Programming Language :: Python
-Classifier: Programming Language :: Python :: 3.7
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
+Classifier: Programming Language :: Python :: 3.12
 Classifier: Programming Language :: Python :: Implementation :: CPython
-Classifier: Programming Language :: Python :: Implementation :: PyPy
-Requires-Python: >=3.7
+Requires-Python: >=3.10
 Description-Content-Type: text/markdown
 License-File: LICENSE
 License-File: AUTHORS
+Requires-Dist: setuptools
+Requires-Dist: cython
+Requires-Dist: numpy
+Requires-Dist: sympy
+Requires-Dist: scipy
+Requires-Dist: matplotlib
 
 # ANNarchy 
 
 [![DOI](https://zenodo.org/badge/57382690.svg)](https://zenodo.org/badge/latestdoi/57382690)
 
 
 ANNarchy (Artificial Neural Networks architect) is a parallel and hybrid simulator for distributed rate-coded or spiking neural networks. The core of the library is written in C++ and distributed using openMP or CUDA. It provides an interface in Python for the definition of the networks. It is released under the [GNU GPL v2 or later](http://www.gnu.org/licenses/gpl.html).
 
-The source code is available at:
-
-<https://github.com/ANNarchy/ANNarchy>
-
-The documentation is available online at:
-
-<https://annarchy.github.io/>
-
-A forum for discussion is set at:
-
-<https://groups.google.com/forum/#!forum/annarchy>
-
-Bug reports should be done through the [Issue Tracker](https://github.com/ANNarchy/ANNarchy/issues) of ANNarchy on Github.
+* Source code: [github.com/ANNarchy/ANNarchy](https://github.com/ANNarchy/ANNarchy)
+* Documentation: [annarchy.github.io](https://annarchy.github.io)
+* Forum: [google forum](https://groups.google.com/forum/#!forum/annarchy)
+* Bug reports and feature requests: [Issue Tracker](https://github.com/ANNarchy/ANNarchy/issues).
 
 ### Citation
 
 If you use ANNarchy for your research, we would appreciate if you cite the following paper:
 
 > Vitay J, Dinkelbach H and Hamker FH (2015). ANNarchy: a code generation approach to neural simulations on parallel hardware. *Frontiers in Neuroinformatics* 9:19. [doi:10.3389/fninf.2015.00019](http://dx.doi.org/10.3389/fninf.2015.00019)
 
 ### Authors
 
 * Julien Vitay (julien.vitay@informatik.tu-chemnitz.de).
 * Helge lo Dinkelbach (helge-uelo.dinkelbach@informatik.tu-chemnitz.de).
 * Fred Hamker (fred.hamker@informatik.tu-chemnitz.de).
 
-
 ## Installation
 
 Using pip, you can install the latest stable release:
 
-```
+```bash
 pip install ANNarchy
 ```
 
+See <https://annarchy.github.io/Installation> for further instructions.
+
 ## Platforms
 
 * GNU/Linux
 * MacOS X
+* Windows (inside WSL2)
 
 ## Dependencies
 
-* g++ >= 6.1 ( >= 7.4 recommended ) or clang++ >= 3.4
-* python >= 3.7 with development files
-* cython >= 0.20
-* setuptools >= 40.0
-* numpy >= 1.13
-* sympy >= 1.6
-* scipy >= 0.19
+* `python` >= 3.10 (with the development files, e.g. `python-dev` or `python-devel`)
+* `g++` >= 7.4 or `clang++` >= 3.4
+* `make` >= 3.0
+* `setuptools` >= 65.0
+* `cython` >= 3.0
+* `numpy` >= 1.21
+* `sympy` >= 1.11
+* `scipy` >= 1.9
+* `matplotlib` >= 3.0
 
 Recommended:
 
-* matplotlib
-* lxml 
-* PyQtGraph 
-* pandoc 
-* tensorboardX
+* `lxml` (to save the networks in `.xml` format).
+* `pandoc` (for `report()`).
+* `tensorflow` (for the `ann_to_snn_conversion` extension)
+* `tensorboardX` (for the `logging` extension).
+* `tqdm` (to display progress bars)
```

### Comparing `ANNarchy-4.7.3/pyproject.toml` & `annarchy-4.8.0.1/pyproject.toml`

 * *Files 20% similar despite different names*

```diff
@@ -1,42 +1,40 @@
 [build-system]
 requires = ["setuptools", "Cython", "numpy"]
 build-backend = "setuptools.build_meta"
 
 [project]
 name = "ANNarchy"
-version = "4.7.3"
+version = "4.8.0.1"
 description = 'Artificial Neural Networks architect'
 readme = "README.md"
-requires-python = ">=3.7"
+requires-python = ">=3.10"
 license = {text = "GPLv2+"}
 keywords = ["neural simulator"]
 authors = [
   { name = "Julien Vitay", email = "julien.vitay@informatik.tu-chemnitz.de" },
   { name = "Helge Dinkelbach", email = "helge-uelo.dinkelbach@informatik.tu-chemnitz.de" },
   { name = "Fred Hamker", email = "fred.hamker@informatik.tu-chemnitz.de" },
 ]
 classifiers = [
   "Development Status :: 5 - Production/Stable",
   "Environment :: Console",
   "Intended Audience :: Science/Research",
   "Programming Language :: Python",
-  "Programming Language :: Python :: 3.7",
-  "Programming Language :: Python :: 3.8",
-  "Programming Language :: Python :: 3.9",
   "Programming Language :: Python :: 3.10",
   "Programming Language :: Python :: 3.11",
+  "Programming Language :: Python :: 3.12",
   "Programming Language :: Python :: Implementation :: CPython",
-  "Programming Language :: Python :: Implementation :: PyPy",
 ]
 dependencies = [
+    'setuptools',
     'cython',
     'numpy',
-    'sympy >= 1.6',
-    'scipy >= 0.19',
+    'sympy',
+    'scipy',
     'matplotlib'
 ]
 
 [project.urls]
 Documentation = "https://annarchy.github.io"
 Issues = "https://github.com/ANNarchy/ANNarchy/issues"
 Source = "https://github.com/ANNarchy/ANNarchy"
```

### Comparing `ANNarchy-4.7.3/setup.py` & `annarchy-4.8.0.1/setup.py`

 * *Files 13% similar despite different names*

```diff
@@ -146,36 +146,36 @@
     extra_compile_args.append("-stdlib=libc++")
     extra_link_args = ["-stdlib=libc++"]
 
 ################################################
 # Perform the installation
 ################################################
 package_data = [
-                'core/cython_ext/*.pxd',
-                'core/cython_ext/*.pyx',
-                'core/cython_ext/CSRMatrix.hpp',
+                'cython_ext/*.pxd',
+                'cython_ext/*.pyx',
+                'cython_ext/CSRMatrix.hpp',
                 'include/*.hpp',
                 'thirdparty/*.hpp'
                 ]
 
 extensions = [
-    Extension("ANNarchy.core.cython_ext.Connector",
-            ["ANNarchy/core/cython_ext/Connector.pyx"],
+    Extension("ANNarchy.cython_ext.Connector",
+            ["ANNarchy/cython_ext/Connector.pyx"],
             include_dirs=[numpy.get_include()],
             extra_compile_args=extra_compile_args,
             extra_link_args=extra_link_args,
             language="c++"),
-    Extension("ANNarchy.core.cython_ext.Coordinates",
-            ["ANNarchy/core/cython_ext/Coordinates.pyx"],
+    Extension("ANNarchy.cython_ext.Coordinates",
+            ["ANNarchy/cython_ext/Coordinates.pyx"],
             include_dirs=[numpy.get_include()],
             extra_compile_args=extra_compile_args,
             extra_link_args=extra_link_args,
             language="c++"),
-    Extension("ANNarchy.core.cython_ext.Transformations",
-            ["ANNarchy/core/cython_ext/Transformations.pyx"],
+    Extension("ANNarchy.cython_ext.Transformations",
+            ["ANNarchy/cython_ext/Transformations.pyx"],
             include_dirs=[numpy.get_include()],
             extra_compile_args=extra_compile_args,
             extra_link_args=extra_link_args,
             language="c++"),
 ]
 
 class CustomizedBuild(build):
@@ -205,8 +205,8 @@
 
 # PyExtension stuff remains here while the rest of metadata is contained in
 # pyproject.toml ...
 setup(
     ext_modules = cythonize(extensions, language_level=int(sys.version_info[0])),
     package_data={'ANNarchy': package_data},
     cmdclass={"build": CustomizedBuild}
-)
+)
```

### Comparing `ANNarchy-4.7.3/tests/test_CUDA.py` & `annarchy-4.8.0.1/tests/test_CUDA.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/tests/test_openmp.py` & `annarchy-4.8.0.1/tests/test_openmp.py`

 * *Files identical despite different names*

### Comparing `ANNarchy-4.7.3/tests/test_single_thread.py` & `annarchy-4.8.0.1/tests/test_single_thread.py`

 * *Files identical despite different names*

