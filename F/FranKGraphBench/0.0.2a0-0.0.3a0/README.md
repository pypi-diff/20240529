# Comparing `tmp/FranKGraphBench-0.0.2a0-py3-none-any.whl.zip` & `tmp/FranKGraphBench-0.0.3a0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,22 +1,22 @@
-Zip file size: 68161 bytes, number of entries: 70
--rw-rw-rw-  2.0 fat     2505 b- defN 24-May-29 14:08 data_integration/__init__.py
+Zip file size: 68266 bytes, number of entries: 70
+-rw-rw-rw-  2.0 fat     2505 b- defN 24-May-29 14:18 data_integration/__init__.py
 -rw-rw-rw-  2.0 fat       84 b- defN 24-May-29 13:11 data_integration/__main__.py
 -rw-rw-rw-  2.0 fat     9954 b- defN 24-May-28 09:42 data_integration/dataset.py
 -rw-rw-rw-  2.0 fat      834 b- defN 24-May-28 09:42 data_integration/dataset2class.py
 -rw-rw-rw-  2.0 fat        0 b- defN 24-May-29 12:27 data_integration/datasets/__init__.py
 -rw-rw-rw-  2.0 fat     5403 b- defN 24-May-28 09:42 data_integration/datasets/amazon.py
 -rw-rw-rw-  2.0 fat     3677 b- defN 24-May-28 09:42 data_integration/datasets/book-crossing.py
 -rw-rw-rw-  2.0 fat     2693 b- defN 24-May-28 09:42 data_integration/datasets/douban-movie.py
 -rw-rw-rw-  2.0 fat     8579 b- defN 24-May-28 09:42 data_integration/datasets/lastfm.py
 -rw-rw-rw-  2.0 fat    13971 b- defN 24-May-28 09:42 data_integration/datasets/movielens.py
 -rw-rw-rw-  2.0 fat     3620 b- defN 24-May-28 09:42 data_integration/datasets/steam.py
 -rw-rw-rw-  2.0 fat     1075 b- defN 24-May-28 09:42 data_integration/datasets/worker.py
 -rw-rw-rw-  2.0 fat     6063 b- defN 24-May-28 09:42 data_integration/datasets/yelp.py
--rw-rw-rw-  2.0 fat      518 b- defN 24-May-29 14:08 framework/__init__.py
+-rw-rw-rw-  2.0 fat      518 b- defN 24-May-29 14:18 framework/__init__.py
 -rw-rw-rw-  2.0 fat       70 b- defN 24-May-29 13:10 framework/__main__.py
 -rw-rw-rw-  2.0 fat     4615 b- defN 24-May-28 09:42 framework/experiment.py
 -rw-rw-rw-  2.0 fat      255 b- defN 24-May-28 09:42 framework/utils.py
 -rw-rw-rw-  2.0 fat        0 b- defN 24-May-28 09:42 framework/dataloader/__init__.py
 -rw-rw-rw-  2.0 fat     2107 b- defN 24-May-28 09:42 framework/dataloader/dataloader.py
 -rw-rw-rw-  2.0 fat        0 b- defN 24-May-28 09:42 framework/dataloader/dataset/__init__.py
 -rw-rw-rw-  2.0 fat     1107 b- defN 24-May-28 09:42 framework/dataloader/dataset/dataset.py
@@ -59,14 +59,14 @@
 -rw-rw-rw-  2.0 fat     7364 b- defN 24-May-28 09:42 framework/recommender/models/transR/model.py
 -rw-rw-rw-  2.0 fat        0 b- defN 24-May-28 09:42 framework/recommender/models/tuckER/__init__.py
 -rw-rw-rw-  2.0 fat     7843 b- defN 24-May-28 09:42 framework/recommender/models/tuckER/model.py
 -rw-rw-rw-  2.0 fat        0 b- defN 24-May-29 12:29 framework/recommender/utils/__init__.py
 -rw-rw-rw-  2.0 fat     5603 b- defN 24-May-28 09:42 framework/recommender/utils/walker.py
 -rw-rw-rw-  2.0 fat        0 b- defN 24-May-28 09:42 framework/reporter/__init__.py
 -rw-rw-rw-  2.0 fat     3831 b- defN 24-May-28 09:42 framework/reporter/report.py
--rw-rw-rw-  2.0 fat    11558 b- defN 24-May-29 14:08 FranKGraphBench-0.0.2a0.dist-info/LICENSE
--rw-rw-rw-  2.0 fat     6407 b- defN 24-May-29 14:08 FranKGraphBench-0.0.2a0.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 24-May-29 14:08 FranKGraphBench-0.0.2a0.dist-info/WHEEL
--rw-rw-rw-  2.0 fat      103 b- defN 24-May-29 14:08 FranKGraphBench-0.0.2a0.dist-info/entry_points.txt
--rw-rw-rw-  2.0 fat       27 b- defN 24-May-29 14:08 FranKGraphBench-0.0.2a0.dist-info/top_level.txt
--rw-rw-r--  2.0 fat     6584 b- defN 24-May-29 14:08 FranKGraphBench-0.0.2a0.dist-info/RECORD
-70 files, 208535 bytes uncompressed, 57365 bytes compressed:  72.5%
+-rw-rw-rw-  2.0 fat    11558 b- defN 24-May-29 14:26 FranKGraphBench-0.0.3a0.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat     9557 b- defN 24-May-29 14:26 FranKGraphBench-0.0.3a0.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 24-May-29 14:26 FranKGraphBench-0.0.3a0.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat      103 b- defN 24-May-29 14:26 FranKGraphBench-0.0.3a0.dist-info/entry_points.txt
+-rw-rw-rw-  2.0 fat       27 b- defN 24-May-29 14:26 FranKGraphBench-0.0.3a0.dist-info/top_level.txt
+-rw-rw-r--  2.0 fat     6584 b- defN 24-May-29 14:26 FranKGraphBench-0.0.3a0.dist-info/RECORD
+70 files, 211685 bytes uncompressed, 57470 bytes compressed:  72.9%
```

## zipnote {}

```diff
@@ -186,26 +186,26 @@
 
 Filename: framework/reporter/__init__.py
 Comment: 
 
 Filename: framework/reporter/report.py
 Comment: 
 
-Filename: FranKGraphBench-0.0.2a0.dist-info/LICENSE
+Filename: FranKGraphBench-0.0.3a0.dist-info/LICENSE
 Comment: 
 
-Filename: FranKGraphBench-0.0.2a0.dist-info/METADATA
+Filename: FranKGraphBench-0.0.3a0.dist-info/METADATA
 Comment: 
 
-Filename: FranKGraphBench-0.0.2a0.dist-info/WHEEL
+Filename: FranKGraphBench-0.0.3a0.dist-info/WHEEL
 Comment: 
 
-Filename: FranKGraphBench-0.0.2a0.dist-info/entry_points.txt
+Filename: FranKGraphBench-0.0.3a0.dist-info/entry_points.txt
 Comment: 
 
-Filename: FranKGraphBench-0.0.2a0.dist-info/top_level.txt
+Filename: FranKGraphBench-0.0.3a0.dist-info/top_level.txt
 Comment: 
 
-Filename: FranKGraphBench-0.0.2a0.dist-info/RECORD
+Filename: FranKGraphBench-0.0.3a0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## data_integration/__init__.py

```diff
@@ -1,13 +1,13 @@
 import argparse
 import importlib
 
 from data_integration.dataset2class import dataset2class
 
-__version__ = "0.0.2-alpha"
+__version__ = "0.0.3-alpha"
 __author__ = "Paulo do Carmo and Alvaro Lopes"
 
 def get_dataset_class(dataset):
     module_name = f'data_integration.{dataset2class[dataset]["submodule"]}'
     class_name = dataset2class[dataset]['class']
     return module_name, class_name
```

## framework/__init__.py

```diff
@@ -1,11 +1,11 @@
 import argparse
 from framework.experiment import run
 
-__version__ = "0.0.2-alpha"
+__version__ = "0.0.3-alpha"
 __author__ = "Paulo do Carmo and Alvaro Lopes"
 
 def framework():
     parser = argparse.ArgumentParser(
         description="Script to run framework for reproducible experiment."
     )
```

## Comparing `FranKGraphBench-0.0.2a0.dist-info/LICENSE` & `FranKGraphBench-0.0.3a0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `FranKGraphBench-0.0.2a0.dist-info/METADATA` & `FranKGraphBench-0.0.3a0.dist-info/METADATA`

 * *Files 21% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: FranKGraphBench
-Version: 0.0.2a0
+Version: 0.0.3a0
 Summary: pip install package for frankgraphbench.
 Home-page: https://github.com/AKSW/frankgraphbench/tree/master/
 Author: Paulo do Carmo and Alvaro Lopes
 Author-email: paulo.carmo@htwk-leipzig.de
 License: Apache-2.0
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Programming Language :: Python :: 3
@@ -27,15 +27,14 @@
 Requires-Dist: tzdata
 Requires-Dist: pykeen
 Requires-Dist: torch ==2.1.2
 Requires-Dist: py-cpuinfo
 Requires-Dist: gputil
 Requires-Dist: psutil
 Requires-Dist: sentence-transformers
-Requires-Dist: pybind11
 Requires-Dist: graph-walker
 Requires-Dist: isodate ==0.6.1
 Requires-Dist: Levenshtein ==0.21.0
 Requires-Dist: pyparsing ==3.0.9
 Requires-Dist: python-Levenshtein ==0.21.0
 Requires-Dist: rapidfuzz ==3.0.0
 Requires-Dist: rdflib ==6.3.2
@@ -50,14 +49,57 @@
 It was first created on Google Summer of Code 2023 for Data Integration between DBpedia and some standard RS datasets in a reproducible framework.
 
 Check the [docs](https://frankgraphbench.readthedocs.io/en/latest/index.html) for more information.
 
 * This repository was first created for Data Integration between DBpedia and some standard Recommender Systems datasets and a framework for reproducible experiments. For more info, check the [project proposal](https://github.com/AlvaroJoseLopes/GSoC-2023) and the project progress with weekly (as possible) [updates](https://github.com/AKSW/frankgraphbench/wiki).
 
 # Data Integration Usage
+
+## pip
+
+We recommend using a python 3.8 virtual environment
+
+```shell
+pip install pybind11
+pip install frankgraphbench
+```
+
+Install the full dataset using bash scripts located at `datasets/`:
+
+```shell
+cd datasets
+bash ml-100k.sh # Downloaded at `datasets/ml-100k` folder
+bash ml-1m.sh   # Downloaded at `datasets/ml-1m` folder
+```
+
+### Usage
+```shell
+data_integration [-h] -d DATASET -i INPUT_PATH -o OUTPUT_PATH [-ci] [-cu] [-cr] [-cs] [-map] [-w]
+```
+Arguments:
+- **-h:** Shows the help message.
+- **-d:** Name of a supported dataset. It will be the same name of the folder created by the bash script provided for the dataset. For now, check `data_integration/dataset2class.py` to see the supported ones.
+- **-i:** Input path where the full dataset is placed.
+- **-o:** Output path where the integrated dataset will be placed.
+- **-ci:** Use this flag if you want to convert item data.
+- **-cu:** Use this flag if you want to convert user data.
+- **-cr:** Use this flag if you want to convert rating data.
+- **-cs:** Use this flag if you want to convert social link data.
+- **-map:** Use this flag if you want to map dataset items with DBpedia. At least the item data should be already converted.
+- **-w:** Choose the number of workers(threads) to be used for parallel queries.
+
+Usage Example:
+
+```shell
+data_integration -d 'ml-100k' -i 'datasets/ml-100k' -o 'datasets/ml-100k/processed' \
+    -ci -cu -cr -map -w 8
+```
+
+## source
+
 Install the required packages using python [virtualenv](https://docs.python.org/3/library/venv.html), using:
 
 ```shell
 python3 -m venv venv_data_integration/
 source venv_data_integration/bin/activate
 pip3 install -r requirements_data_integration.txt 
 ```
@@ -66,15 +108,15 @@
 
 ```shell
 cd datasets
 bash ml-100k.sh # Downloaded at `datasets/ml-100k` folder
 bash ml-1m.sh   # Downloaded at `datasets/ml-1m` folder
 ```
 
-## Usage
+### Usage
 ```shell
 python3 data_integration.py [-h] -d DATASET -i INPUT_PATH -o OUTPUT_PATH [-ci] [-cu] [-cr] [-cs] [-map] [-w]
 ```
 
 Arguments:
 - **-h:** Shows the help message.
 - **-d:** Name of a supported dataset. It will be the same name of the folder created by the bash script provided for the dataset. For now, check `data_integration/dataset2class.py` to see the supported ones.
@@ -104,23 +146,108 @@
 |[MovieLens-1M](https://grouplens.org/datasets/movielens/1m/)|3356|3883|
 |[LastFM-hetrec-2011](https://grouplens.org/datasets/hetrec-2011/)|11815|17632|
 |[Douban-Movie-Short-Comments-Dataset](https://www.kaggle.com/datasets/utmhikari/doubanmovieshortcomments/data)|---|28|douban-movie|
 |[Yelp-Dataset](https://www.yelp.com/dataset/download)|---|150348|yelp|
 |[Amazon-Video-Games-5](https://nijianmo.github.io/amazon/index.html)|---|21106|amazon-video_games-5|
 
 # Framework for reproducible experiments usage
+
+## pip
+
+We recommend using a python 3.8 virtual environment
+
+```shell
+pip install pybind11
+pip install frankgraphbench
+```
+
+### Usage 
+
+```shell
+framework -c 'config_files/test.yml'
+```
+Arguments:
+- **-c:** Experiment configuration file path.
+
+The experiment config file should be a .yaml file like this:
+
+```yaml
+experiment:
+  dataset: 
+    name: ml-100k
+    item:
+      path: datasets/ml-100k/processed/item.csv 
+      extra_features: [movie_year, movie_title] 
+    user:
+      path: datasets/ml-100k/processed/user.csv 
+      extra_features: [gender, occupation] 
+    ratings: 
+      path: datasets/ml-100k/processed/rating.csv 
+      timestamp: True
+    enrich:
+      map_path: datasets/ml-100k/processed/map.csv
+      enrich_path: datasets/ml-100k/processed/enriched.csv
+      remove_unmatched: False
+      properties:
+        - type: subject
+          grouped: True
+          sep: "::"
+        - type: director
+          grouped: True
+          sep: "::"
+
+  preprocess:
+    - method: filter_kcore
+      parameters:
+        k: 20
+        iterations: 1
+        target: user
+
+  split:
+    seed: 42
+    test:
+      method: k_fold
+      k: 2
+      level: 'user'
+
+
+  models:
+    - name: deepwalk_based
+      config:
+        save_weights: True
+      parameters:
+        walk_len: 10
+        p: 1.0
+        q: 1.0
+        n_walks: 50
+        embedding_size: 64
+        epochs: 1
+  
+  evaluation:
+    k: 5
+    relevance_threshold: 3
+    metrics: [MAP, nDCG]
+
+  report:
+    file: 'experiment_results/ml100k_enriched/run1.csv'
+```
+
+See the [config_files/](/config_files/) directory for more examples.
+
+## source
+
 Install the require packages using python [virtualenv](https://docs.python.org/3/library/venv.html), using:
 
 ```shell
 python3 -m venv venv_framework/
 source venv_framework/bin/activate
 pip3 install -r requirements_framework.txt 
 ```
 
-## Usage 
+### Usage 
 
 ```shell
 python3 framework.py -c 'config_files/test.yml'
 ```
 Arguments:
 - **-c:** Experiment configuration file path.
```

## Comparing `FranKGraphBench-0.0.2a0.dist-info/RECORD` & `FranKGraphBench-0.0.3a0.dist-info/RECORD`

 * *Files 3% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-data_integration/__init__.py,sha256=CYWc0Fd3rKkEFq7tnlw5SVZdYqfn7AGG0H4HYmWPfy4,2505
+data_integration/__init__.py,sha256=fW8Vm9BovcbxZ2rb-SBpoYRtvdvLsLbUzimjqW3sCJo,2505
 data_integration/__main__.py,sha256=qkvm2rn7aqJbghtAGGXDsw67sbha2RM9GYBhGBu4g_s,84
 data_integration/dataset.py,sha256=JlAhmIm3E-xDEcvXkQXd0V2P6-19kW5JS82hlfodsO8,9954
 data_integration/dataset2class.py,sha256=m2SdFDpQ2JFONK7GyUj_usA2XZ86dFd95FNZ0ewvt6o,834
 data_integration/datasets/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 data_integration/datasets/amazon.py,sha256=2MQb_ZXGK6Gjw8R8wlfws_hlkpqRI_QZFX1i8zHJtlo,5403
 data_integration/datasets/book-crossing.py,sha256=jEzLYGi7FT4ysgWN_tmufILgQ6riTzfktHg6xz-eEnM,3677
 data_integration/datasets/douban-movie.py,sha256=4A402rwJzM33jF42bxI_wycFYN18eD8UDoWRqFJi7WY,2693
 data_integration/datasets/lastfm.py,sha256=Ro0-6M0R6ZaPx1_d9nwzw54eSGpucZpo-pTbH90xK5U,8579
 data_integration/datasets/movielens.py,sha256=sdGwSCdwXRL4GAcV4Cc428B3O-Dg9OSObWrHP-Ew2-A,13971
 data_integration/datasets/steam.py,sha256=CGO9p4PW2EbFiFKN2bFIi3s8EKN9LpwPzHfF1MebeR0,3620
 data_integration/datasets/worker.py,sha256=IJ4-FmX6Y_Pe0uHp57591rlzHOS_xM0WdR01MhYN0sQ,1075
 data_integration/datasets/yelp.py,sha256=RlOiZvRZxSbvfT05d_wqL3ELGV8zhe26Vlw_OzlNprc,6063
-framework/__init__.py,sha256=pqCvUYyagIZs2Nbmui5umMvjgItkGloU18nepCn7qFQ,518
+framework/__init__.py,sha256=UroJYrEHuQt9ou0Woe-LBsH0oRl42dvTnzbO2GWwyd4,518
 framework/__main__.py,sha256=Ft0oM50z9vFrCFjoIeYyIVMkYgp3SkdOCArx8Ygx1Jw,70
 framework/experiment.py,sha256=pKfvL8VNLmzqOCdyZBi9Vb80dPu2yoMailVTwly9gfQ,4615
 framework/utils.py,sha256=TE9PvcTBUEBdkFqFwpJKE2O9ZH7zFHnbhXZsj3X71r4,255
 framework/dataloader/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 framework/dataloader/dataloader.py,sha256=sRmhWQEt6VMoJzuEKBVfNQcIwIkRFi8mtt1RmWXp3-E,2107
 framework/dataloader/dataset/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 framework/dataloader/dataset/dataset.py,sha256=q-UpdS2LHX5pXPjRiKaR8C-Vb9TfuWL_eReYOT8NAiI,1107
@@ -58,13 +58,13 @@
 framework/recommender/models/transR/model.py,sha256=Hd1nLPYscltTBTPrvBdCUIjmKXM07Iy9D5dQwX2oOCE,7364
 framework/recommender/models/tuckER/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 framework/recommender/models/tuckER/model.py,sha256=ZEk2innTsljJTFKsbQC2UtG5wRVNJNyN5qVaanTacgM,7843
 framework/recommender/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 framework/recommender/utils/walker.py,sha256=hj00ML1ZooVV8qcCon2rhnfKYa_FYHuyuFtOLQ-fCaw,5603
 framework/reporter/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 framework/reporter/report.py,sha256=8YlQpd_gdbldXQZUYR0OgyGQFa3Onko7X044ktXy48k,3831
-FranKGraphBench-0.0.2a0.dist-info/LICENSE,sha256=HrhfyXIkWY2tGFK11kg7vPCqhgh5DcxleloqdhrpyMY,11558
-FranKGraphBench-0.0.2a0.dist-info/METADATA,sha256=ygJls_vgDZgK-DhMPK3rQzBQ0e-BJUolUCD6XNjOD6E,6407
-FranKGraphBench-0.0.2a0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-FranKGraphBench-0.0.2a0.dist-info/entry_points.txt,sha256=cXDIJ8OHjypcsMfYc41oCtAvsSBjsRMWz5d6LSjuCOA,103
-FranKGraphBench-0.0.2a0.dist-info/top_level.txt,sha256=RoD7dhJJkBgu0NKFQ1k_mY6wU05S65SE0gLx3jg9dI8,27
-FranKGraphBench-0.0.2a0.dist-info/RECORD,,
+FranKGraphBench-0.0.3a0.dist-info/LICENSE,sha256=HrhfyXIkWY2tGFK11kg7vPCqhgh5DcxleloqdhrpyMY,11558
+FranKGraphBench-0.0.3a0.dist-info/METADATA,sha256=Er-HMAFtxBNnUx76NSlMCKFiAv2j1jEyUTiWp4Nb1D8,9557
+FranKGraphBench-0.0.3a0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+FranKGraphBench-0.0.3a0.dist-info/entry_points.txt,sha256=cXDIJ8OHjypcsMfYc41oCtAvsSBjsRMWz5d6LSjuCOA,103
+FranKGraphBench-0.0.3a0.dist-info/top_level.txt,sha256=RoD7dhJJkBgu0NKFQ1k_mY6wU05S65SE0gLx3jg9dI8,27
+FranKGraphBench-0.0.3a0.dist-info/RECORD,,
```

