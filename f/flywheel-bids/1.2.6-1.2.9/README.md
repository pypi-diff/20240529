# Comparing `tmp/flywheel_bids-1.2.6-py3-none-any.whl.zip` & `tmp/flywheel_bids-1.2.9-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,26 +1,43 @@
-Zip file size: 106127 bytes, number of entries: 54
--rw-r--r--  2.0 unx        5 b- defN 80-Jan-01 00:00 flywheel_bids/__init__.py
--rw-r--r--  2.0 unx    23826 b- defN 80-Jan-01 00:00 flywheel_bids/curate_bids.py
--rw-r--r--  2.0 unx    23741 b- defN 80-Jan-01 00:00 flywheel_bids/export_bids.py
--rw-r--r--  2.0 unx       76 b- defN 80-Jan-01 00:00 flywheel_bids/results/__init__.py
--rw-r--r--  2.0 unx     2361 b- defN 80-Jan-01 00:00 flywheel_bids/results/zip_htmls.py
--rw-r--r--  2.0 unx     5147 b- defN 80-Jan-01 00:00 flywheel_bids/results/zip_intermediate.py
+Zip file size: 128460 bytes, number of entries: 67
+-rw-r--r--  2.0 unx      122 b- defN 80-Jan-01 00:00 flywheel_bids/__init__.py
+-rw-r--r--  2.0 unx    31649 b- defN 80-Jan-01 00:00 flywheel_bids/curate_bids.py
+-rw-r--r--  2.0 unx    26661 b- defN 80-Jan-01 00:00 flywheel_bids/export_bids.py
+-rw-r--r--  2.0 unx       36 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/__init__.py
+-rw-r--r--  2.0 unx     3335 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/commands.py
+-rw-r--r--  2.0 unx     6427 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/compression.py
+-rw-r--r--  2.0 unx     7827 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/context.py
+-rw-r--r--  2.0 unx     3168 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/prep.py
+-rw-r--r--  2.0 unx     5747 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/report.py
+-rw-r--r--  2.0 unx     2297 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/tests/conftest.py
+-rw-r--r--  2.0 unx     1868 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/tests/test_commands.py
+-rw-r--r--  2.0 unx     5776 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/tests/test_compression.py
+-rw-r--r--  2.0 unx     2291 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/tests/test_context.py
+-rw-r--r--  2.0 unx     6554 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/tests/test_old_run_level.py
+-rw-r--r--  2.0 unx        1 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/tests/test_prep.py
+-rw-r--r--  2.0 unx     1453 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/tests/test_util_helpers.py
+-rw-r--r--  2.0 unx     2693 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/tests/test_utils_query_flywheel.py
+-rw-r--r--  2.0 unx     2103 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/tests/test_utils_tree.py
+-rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/utils/__init__.py
+-rw-r--r--  2.0 unx     2025 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/utils/helpers.py
+-rw-r--r--  2.0 unx     2026 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/utils/performance.py
+-rw-r--r--  2.0 unx    15018 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/utils/query_flywheel.py
+-rw-r--r--  2.0 unx     2520 b- defN 80-Jan-01 00:00 flywheel_bids/flywheel_bids_app_toolkit/utils/tree.py
 -rw-r--r--  2.0 unx        5 b- defN 80-Jan-01 00:00 flywheel_bids/supporting_files/__init__.py
--rw-r--r--  2.0 unx    10537 b- defN 80-Jan-01 00:00 flywheel_bids/supporting_files/bidsify_flywheel.py
+-rw-r--r--  2.0 unx    11070 b- defN 80-Jan-01 00:00 flywheel_bids/supporting_files/bidsify_flywheel.py
 -rw-r--r--  2.0 unx     4353 b- defN 80-Jan-01 00:00 flywheel_bids/supporting_files/classifications.py
 -rw-r--r--  2.0 unx     1234 b- defN 80-Jan-01 00:00 flywheel_bids/supporting_files/errors.py
--rw-r--r--  2.0 unx     6607 b- defN 80-Jan-01 00:00 flywheel_bids/supporting_files/file_funcs.py
--rw-r--r--  2.0 unx     7311 b- defN 80-Jan-01 00:00 flywheel_bids/supporting_files/project_tree.py
--rw-r--r--  2.0 unx     6305 b- defN 80-Jan-01 00:00 flywheel_bids/supporting_files/resolver.py
--rw-r--r--  2.0 unx    23538 b- defN 80-Jan-01 00:00 flywheel_bids/supporting_files/templates.py
--rw-r--r--  2.0 unx    10872 b- defN 80-Jan-01 00:00 flywheel_bids/supporting_files/utils.py
+-rw-r--r--  2.0 unx     6585 b- defN 80-Jan-01 00:00 flywheel_bids/supporting_files/file_funcs.py
+-rw-r--r--  2.0 unx     7310 b- defN 80-Jan-01 00:00 flywheel_bids/supporting_files/project_tree.py
+-rw-r--r--  2.0 unx     4638 b- defN 80-Jan-01 00:00 flywheel_bids/supporting_files/resolver.py
+-rw-r--r--  2.0 unx    23915 b- defN 80-Jan-01 00:00 flywheel_bids/supporting_files/templates.py
+-rw-r--r--  2.0 unx    11836 b- defN 80-Jan-01 00:00 flywheel_bids/supporting_files/utils.py
 -rw-r--r--  2.0 unx      175 b- defN 80-Jan-01 00:00 flywheel_bids/templates/README.md
 -rw-r--r--  2.0 unx    27899 b- defN 80-Jan-01 00:00 flywheel_bids/templates/bids-v1.json
--rw-r--r--  2.0 unx    53901 b- defN 80-Jan-01 00:00 flywheel_bids/templates/default.json
+-rw-r--r--  2.0 unx    54660 b- defN 80-Jan-01 00:00 flywheel_bids/templates/default.json
 -rw-r--r--  2.0 unx     1536 b- defN 80-Jan-01 00:00 flywheel_bids/templates/flywheel_curated/README.md
 -rw-r--r--  2.0 unx      271 b- defN 80-Jan-01 00:00 flywheel_bids/templates/flywheel_curated/bridge-bdlong-project-template-attributes.txt
 -rw-r--r--  2.0 unx    38666 b- defN 80-Jan-01 00:00 flywheel_bids/templates/flywheel_curated/bridge-bdlong-project-template.json
 -rw-r--r--  2.0 unx      280 b- defN 80-Jan-01 00:00 flywheel_bids/templates/flywheel_curated/bridge-global-reproin-project-template-attributes.txt
 -rw-r--r--  2.0 unx    34969 b- defN 80-Jan-01 00:00 flywheel_bids/templates/flywheel_curated/bridge-global-reproin-project-template.json
 -rw-r--r--  2.0 unx      284 b- defN 80-Jan-01 00:00 flywheel_bids/templates/flywheel_curated/bridge-headspace-extension-project-template-attributes.txt
 -rw-r--r--  2.0 unx     3164 b- defN 80-Jan-01 00:00 flywheel_bids/templates/flywheel_curated/bridge-headspace-extension-project-template.json
@@ -38,19 +55,15 @@
 -rw-r--r--  2.0 unx     6031 b- defN 80-Jan-01 00:00 flywheel_bids/templates/flywheel_curated/columbia-tottenham-pacct-project-template.json
 -rw-r--r--  2.0 unx      264 b- defN 80-Jan-01 00:00 flywheel_bids/templates/flywheel_curated/nyu-bair-vfs-project-template-attributes.txt
 -rw-r--r--  2.0 unx     8483 b- defN 80-Jan-01 00:00 flywheel_bids/templates/flywheel_curated/nyu-bair-vfs-project-template.json
 -rw-r--r--  2.0 unx      276 b- defN 80-Jan-01 00:00 flywheel_bids/templates/flywheel_curated/reproin-philips-project-template-attributes.txt
 -rw-r--r--  2.0 unx    30276 b- defN 80-Jan-01 00:00 flywheel_bids/templates/flywheel_curated/reproin-philips-project-template.json
 -rw-r--r--  2.0 unx      269 b- defN 80-Jan-01 00:00 flywheel_bids/templates/flywheel_curated/reproin-reproin-project-template-attributes.txt
 -rw-r--r--  2.0 unx    42094 b- defN 80-Jan-01 00:00 flywheel_bids/templates/flywheel_curated/reproin-reproin-project-template.json
--rw-r--r--  2.0 unx    44997 b- defN 80-Jan-01 00:00 flywheel_bids/templates/reproin.json
--rw-r--r--  2.0 unx    63150 b- defN 80-Jan-01 00:00 flywheel_bids/upload_bids.py
--rw-r--r--  2.0 unx    13998 b- defN 80-Jan-01 00:00 flywheel_bids/utils/download_run_level.py
--rw-r--r--  2.0 unx     2026 b- defN 80-Jan-01 00:00 flywheel_bids/utils/performance.py
--rw-r--r--  2.0 unx     1816 b- defN 80-Jan-01 00:00 flywheel_bids/utils/run_level.py
--rw-r--r--  2.0 unx     2522 b- defN 80-Jan-01 00:00 flywheel_bids/utils/tree.py
+-rw-r--r--  2.0 unx    46867 b- defN 80-Jan-01 00:00 flywheel_bids/templates/reproin.json
+-rw-r--r--  2.0 unx    67471 b- defN 80-Jan-01 00:00 flywheel_bids/upload_bids.py
 -rw-r--r--  2.0 unx     5898 b- defN 80-Jan-01 00:00 flywheel_bids/utils/validate.py
--rw-r--r--  2.0 unx     5627 b- defN 80-Jan-01 00:00 flywheel_bids-1.2.6.dist-info/METADATA
--rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 flywheel_bids-1.2.6.dist-info/WHEEL
--rw-r--r--  2.0 unx     1066 b- defN 80-Jan-01 00:00 flywheel_bids-1.2.6.dist-info/LICENSE
-?rw-r--r--  2.0 unx     6263 b- defN 16-Jan-01 00:00 flywheel_bids-1.2.6.dist-info/RECORD
-54 files, 548830 bytes uncompressed, 95505 bytes compressed:  82.6%
+-rw-r--r--  2.0 unx     1066 b- defN 80-Jan-01 00:00 flywheel_bids-1.2.9.dist-info/LICENSE
+-rw-r--r--  2.0 unx     5887 b- defN 80-Jan-01 00:00 flywheel_bids-1.2.9.dist-info/METADATA
+-rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 flywheel_bids-1.2.9.dist-info/WHEEL
+?rw-r--r--  2.0 unx     7923 b- defN 16-Jan-01 00:00 flywheel_bids-1.2.9.dist-info/RECORD
+67 files, 613963 bytes uncompressed, 115004 bytes compressed:  81.3%
```

## zipnote {}

```diff
@@ -3,21 +3,72 @@
 
 Filename: flywheel_bids/curate_bids.py
 Comment: 
 
 Filename: flywheel_bids/export_bids.py
 Comment: 
 
-Filename: flywheel_bids/results/__init__.py
+Filename: flywheel_bids/flywheel_bids_app_toolkit/__init__.py
 Comment: 
 
-Filename: flywheel_bids/results/zip_htmls.py
+Filename: flywheel_bids/flywheel_bids_app_toolkit/commands.py
 Comment: 
 
-Filename: flywheel_bids/results/zip_intermediate.py
+Filename: flywheel_bids/flywheel_bids_app_toolkit/compression.py
+Comment: 
+
+Filename: flywheel_bids/flywheel_bids_app_toolkit/context.py
+Comment: 
+
+Filename: flywheel_bids/flywheel_bids_app_toolkit/prep.py
+Comment: 
+
+Filename: flywheel_bids/flywheel_bids_app_toolkit/report.py
+Comment: 
+
+Filename: flywheel_bids/flywheel_bids_app_toolkit/tests/conftest.py
+Comment: 
+
+Filename: flywheel_bids/flywheel_bids_app_toolkit/tests/test_commands.py
+Comment: 
+
+Filename: flywheel_bids/flywheel_bids_app_toolkit/tests/test_compression.py
+Comment: 
+
+Filename: flywheel_bids/flywheel_bids_app_toolkit/tests/test_context.py
+Comment: 
+
+Filename: flywheel_bids/flywheel_bids_app_toolkit/tests/test_old_run_level.py
+Comment: 
+
+Filename: flywheel_bids/flywheel_bids_app_toolkit/tests/test_prep.py
+Comment: 
+
+Filename: flywheel_bids/flywheel_bids_app_toolkit/tests/test_util_helpers.py
+Comment: 
+
+Filename: flywheel_bids/flywheel_bids_app_toolkit/tests/test_utils_query_flywheel.py
+Comment: 
+
+Filename: flywheel_bids/flywheel_bids_app_toolkit/tests/test_utils_tree.py
+Comment: 
+
+Filename: flywheel_bids/flywheel_bids_app_toolkit/utils/__init__.py
+Comment: 
+
+Filename: flywheel_bids/flywheel_bids_app_toolkit/utils/helpers.py
+Comment: 
+
+Filename: flywheel_bids/flywheel_bids_app_toolkit/utils/performance.py
+Comment: 
+
+Filename: flywheel_bids/flywheel_bids_app_toolkit/utils/query_flywheel.py
+Comment: 
+
+Filename: flywheel_bids/flywheel_bids_app_toolkit/utils/tree.py
 Comment: 
 
 Filename: flywheel_bids/supporting_files/__init__.py
 Comment: 
 
 Filename: flywheel_bids/supporting_files/bidsify_flywheel.py
 Comment: 
@@ -129,35 +180,23 @@
 
 Filename: flywheel_bids/templates/reproin.json
 Comment: 
 
 Filename: flywheel_bids/upload_bids.py
 Comment: 
 
-Filename: flywheel_bids/utils/download_run_level.py
-Comment: 
-
-Filename: flywheel_bids/utils/performance.py
-Comment: 
-
-Filename: flywheel_bids/utils/run_level.py
-Comment: 
-
-Filename: flywheel_bids/utils/tree.py
-Comment: 
-
 Filename: flywheel_bids/utils/validate.py
 Comment: 
 
-Filename: flywheel_bids-1.2.6.dist-info/METADATA
+Filename: flywheel_bids-1.2.9.dist-info/LICENSE
 Comment: 
 
-Filename: flywheel_bids-1.2.6.dist-info/WHEEL
+Filename: flywheel_bids-1.2.9.dist-info/METADATA
 Comment: 
 
-Filename: flywheel_bids-1.2.6.dist-info/LICENSE
+Filename: flywheel_bids-1.2.9.dist-info/WHEEL
 Comment: 
 
-Filename: flywheel_bids-1.2.6.dist-info/RECORD
+Filename: flywheel_bids-1.2.9.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## flywheel_bids/__init__.py

```diff
@@ -1 +1,4 @@
-# 42
+# """Manage all things BIDS with this package."""
+from importlib.metadata import version
+
+__version__ = version(__name__)
```

## flywheel_bids/curate_bids.py

```diff
@@ -1,22 +1,20 @@
 import argparse
 import json
 import logging
-import os
 import pickle
 import re
 import sys
-import tempfile
 from pathlib import Path
 
 import flywheel
 
 from .supporting_files import bidsify_flywheel, utils
-from .supporting_files.templates import load_template
 from .supporting_files.project_tree import get_project_node, set_tree
+from .supporting_files.templates import load_template
 
 logger = logging.getLogger("curate-bids")
 
 
 def clear_meta_info(context, template):
     if "info" in context:
         if template.namespace in context["info"]:
@@ -139,20 +137,97 @@
                 error_message += "Unknown template: %s. " % templateName
 
         # Assign 'valid' and 'error_message' values
         container["info"][namespace]["valid"] = valid
         container["info"][namespace]["error_message"] = error_message
 
 
-def update_meta_info(fw, context):
+def update_nifti_sidecar_fields(fw, acquisition_id, sidecar_name, sidecar_changes):
+    """Set the values of the given field names to given values for the specified NIfTI file's .json sidecar
+
+    Since this uploads a new file (which becomes a new version of that file), it will lose metadata
+    so info, classification, modality, and tags must be obtained from the original file and attached
+    to the new file.
+
+    Args:
+        fw (Flywheel Client): to be able to access the file
+        acquisition_id (str): The acquisition that the NIfTI and json files are in
+        sidecar_name (str): Name of the NIfTI file's sidecar
+        sidecar_changes (dict): add these key/val pairs to file.info
+    """
+    if isinstance(fw, flywheel.client.Client):
+        acquisition = fw.get_acquisition(acquisition_id).reload()
+        sidecar_file = acquisition.get_file(sidecar_name)
+        sidecar_contents = acquisition.read_file(sidecar_name)
+        if not sidecar_contents:
+            print(f"Unable to load {sidecar_name}")
+        sidecar_json = json.loads(sidecar_contents)
+        need_to_write = False
+        for key, val in sidecar_changes.items():
+            if sidecar_json.get(key) != val:
+                sidecar_json[key] = val
+                need_to_write = True
+        if not need_to_write:
+            print(
+                f"Skipping sidecar {sidecar_name} since it already has {sidecar_changes}"
+            )
+            return
+        json_str = json.dumps(sidecar_json, indent=4)
+        file_spec = flywheel.FileSpec(sidecar_name, json_str, "text/plain")
+        acquisition.upload_file(file_spec)
+
+        # make sure new file gets its old metadata back
+        if len(sidecar_file.info) > 0:
+            fw.set_acquisition_file_info(
+                acquisition_id, sidecar_name, sidecar_file.info
+            )
+        if len(sidecar_file.classification) > 0:
+            if (
+                "Contrast" in sidecar_file.classification
+            ):  # This was added to avoid an exception, delete this someday
+                del sidecar_file.classification[
+                    "Contrast"
+                ]  # Contrast is not in the classification schema (yet?)
+            fw.modify_acquisition_file_classification(
+                acquisition_id,
+                sidecar_name,
+                {
+                    "replace": sidecar_file.classification,
+                    "modality": sidecar_file.modality,
+                },
+            )
+        if len(sidecar_file.tags) > 0:
+            fw.add_file_tags(sidecar_file.file_id, sidecar_file.tags)
+
+    else:  # must be a test
+        print(f"Client is {type(fw)}.  Cannot update sidecar")
+
+
+def update_meta_info(fw, context, save_sidecar_as_metadata):
     """Update file information"""
     # Modify file
     if context["container_type"] == "file":
         # Modify acquisition file
         if context["parent_container_type"] == "acquisition":
+            bids_info = context["file"]["info"]["BIDS"]
+            # Handle things like TaskName is required in BIDS, but it's not in the DICOM, so it has to be set here
+            if "sidecarChanges" in bids_info:
+                if save_sidecar_as_metadata:
+                    for key, val in bids_info["sidecarChanges"].items():
+                        context["file"]["info"][key] = val
+                sidecar_name = context["file"]["name"]
+                if sidecar_name.endswith(
+                    ".json"
+                ):  # only modify sidecar (NIfTI file also has sidecarChanges in BIDS)
+                    update_nifti_sidecar_fields(
+                        fw,
+                        context["acquisition"]["id"],
+                        sidecar_name,
+                        bids_info["sidecarChanges"],
+                    )
             fw.set_acquisition_file_info(
                 context["acquisition"]["id"],
                 context["file"]["name"],
                 context["file"]["info"],
             )
         # Modify project file
         elif context["parent_container_type"] == "project":
@@ -193,53 +268,95 @@
     def __init__(self):
         self.containers = 0  # counts project, sessions and acquisitions
         self.sessions = 0
         self.acquisitions = 0
         self.files = 0
 
 
-def save_project_sidecar(project, project_node, save_sidecar_as_metadata):
-    """Save "dataset_description.json" sidecar file
+def save_project_files(project, template, save_sidecar_as_metadata):
+    """Create required "dataset_description.json" sidecar and README files.
 
-    Remove info that was just put on the project_node and attach it as a json file
-    on the project if it does not yet exist.
+    They are created only if they don't already exist.
 
     Args:
         project (Project container)
-        project_node (TreeNode) a "context" representation of the project
+        template (Template) the project curation template (has contents of dataset_description file)
         save_sidecar_as_metadata (bool): if true, save sidecar data as metadata also
     """
 
     SIDECAR_NAME = "dataset_description.json"
     proj_sidecars = [file for file in project.files if file.name == SIDECAR_NAME]
 
     if len(proj_sidecars) > 1:
         logger.debug("ERROR: multiple '%s' files exist", SIDECAR_NAME)
     elif len(proj_sidecars) == 1:
         logger.info("'%s' file already exists", SIDECAR_NAME)
     else:  # create and attach file to project
         logger.info("'%s' file does not exist, creating it...", SIDECAR_NAME)
-        if "info" in project_node:
-            if "BIDS" in project_node.data["info"]:
-                json_data = project_node.data["info"]["BIDS"]
-                if "template" in json_data:
-                    del json_data["template"]
-                if "rule_id" in json_data:
-                    del json_data["rule_id"]
-                json_str = json.dumps(json_data, indent=4)
-                file_spec = flywheel.FileSpec(SIDECAR_NAME, json_str, "text/plain")
-                project.upload_file(file_spec)
-
-                if not save_sidecar_as_metadata:  # remove BIDS namespace
-                    del project_node.data["info"]["BIDS"]
-                # else: that BIDS info will be updated in project metadata
-            else:
-                logger.debug("ERROR: no BIDS information exists")
+        if "dataset_description_file" in template.definitions:
+            json_data = dict()
+            # get contents of definition to put into json file
+            for key, value in template.definitions["dataset_description_file"][
+                "properties"
+            ].items():
+                json_data[key] = value["default"]
+                if key == "Name":
+                    json_data[key] = project.label
+            json_str = json.dumps(json_data, indent=4)
+            file_spec = flywheel.FileSpec(SIDECAR_NAME, json_str, "text/plain")
+            project.upload_file(file_spec)
+
+        else:
+            logger.debug(
+                "ERROR: dataset_description_file data is missing from project curation template"
+            )
+
+    # Make the dataset_description_file definition a project definition so
+    # that the normal curation processing will add that information to project.info["BIDS"]
+    if save_sidecar_as_metadata:
+        template.definitions["project"] = template.definitions[
+            "dataset_description_file"
+        ]
+    else:
+        if "BIDS" not in project.info:
+            # this shouldn't happen because the reproin.json template adds a "Sidecar" tag to
+            # project.info.BIDS.  That is detected next...
+            logger.info(
+                "Project will be curated with sidecar data in sidecars, not in metadata.  This is good."
+            )
+        elif "Sidecar" in project.info["BIDS"]:
+            logger.info(
+                "Project is being curated with sidecar data in sidecars, not in metadata.  This is good."
+            )
+        elif "Acknowledgements" in project.info["BIDS"]:
+            # then it was curated the old way but save_sidecar_as_metadata is False so say so
+            logger.error(
+                "save_sidecar_as_metadata is False but this project has been "
+                "curated with sidecar data stored in Custom Information (metadata).  "
+                "Something is wrong."
+            )
         else:
-            logger.debug("ERROR: no project.info exists")
+            logger.warning(
+                "Project is being curated with sidecar data in sidecars, not in metadata. "
+                "But 'Sidecar' is not present in project.info['BIDS'].  This is okay, but should"
+                "not have happened."
+            )
+
+    # Create README file on project
+    README_NAME = "README.txt"
+    proj_readmes = [file for file in project.files if file.name == README_NAME]
+    if len(proj_readmes) > 1:
+        logger.debug("ERROR: multiple '%s' files exist", README_NAME)
+    elif len(proj_readmes) == 1:
+        logger.info("'%s' file already exists", README_NAME)
+    else:  # create and attach file to project
+        logger.info("'%s' file does not exist, creating it...", README_NAME)
+        text_str = project.label
+        file_spec = flywheel.FileSpec(README_NAME, text_str, "text/plain")
+        project.upload_file(file_spec)
 
 
 def curate_bids(
     fw,
     project_id,
     subject_id="",
     session_id="",
@@ -265,22 +382,38 @@
         reset (bool): Whether to erase info.BIDS before curation.
         dont_recurate_project (bool): If project container is already curated, make this True
         template_name (str): Which template type to use. Options include:
                 Default, BIDS-v1, ReproIn.
         template_path (str): Provide a specific template file. Supersedes template_name.
         save_sidecar_as_metadata (bool): sidecar data is in file.info (metadata) so for
                 IntendedFors, update metadata instead of updating the actual json sidecar.
-
     """
 
     count = Count()
 
     project = fw.get_project(project_id)
 
-    template = load_template(fw, template_path, template_name, save_sidecar_as_metadata)
+    template = load_template(template_path, template_name, save_sidecar_as_metadata)
+
+    if (
+        "project" in template.definitions
+        and "Acknowledgements" in template.definitions["project"]
+        and not save_sidecar_as_metadata
+    ):
+        # then it is an old project curation template so warn of possible trouble.
+        # if dcm2niix put sidecar data in NIfTI file.info.BIDS, everything will be fine
+        # but if not (the new way where sidecars have that data), there will be an error.
+        logger.warning(
+            "An old style project curation template is being used: "
+            "when exporting data in BIDS format, this will cause any json sidecar "
+            "files TO BE IGNORED and BIDS Custom Information will be used instead to "
+            "create sidecar files."
+        )
+
+    save_project_files(project, template, save_sidecar_as_metadata)
 
     p_name = f"project_node_{project_id}.pickle"
     if pickle_tree and Path(p_name).exists():
         logger.info("Using pickled %s", p_name)
         with open(p_name, "rb") as f:
             project_node = pickle.load(f)
     else:
@@ -295,15 +428,14 @@
         fw,
         template,
         project_node,
         count,
         reset=reset,
         dont_recurate_project=dont_recurate_project,
         dry_run=dry_run,
-        project=project,
         save_sidecar_as_metadata=save_sidecar_as_metadata,
     )
 
     if session_id:
         logger.info("Getting single session ID=%s", session_id)
         session = fw.get_session(session_id)
         subject_id = session.subject.id
@@ -335,14 +467,15 @@
             fw,
             template,
             project_node,
             count,
             reset=reset,
             dont_recurate_project=True,
             dry_run=dry_run,
+            save_sidecar_as_metadata=save_sidecar_as_metadata,
         )
 
         project_node.children.clear()  # no need to keep previous subjects
 
     logger.info("Curated %s session containers", count.sessions)
     logger.info("Curated %s acquisition containers", count.acquisitions)
     logger.info("Curated %s files", count.files)
@@ -359,15 +492,14 @@
     fw,
     template,
     project_node,
     count,
     reset=False,
     dont_recurate_project=False,
     dry_run=False,
-    project=None,
     save_sidecar_as_metadata=False,
 ):
     """Curate BIDS tree.
 
     Given a BIDS project curation template and Flywheel hierarchy context, figure out the proper
     metadata fields to be able to save data in BIDS format.  The context must include the project
     information to be able to curate any subject or session.  The context should include no more
@@ -391,15 +523,14 @@
     """
     # Curation begins: match, resolve, update
 
     # Match: do initial template matching and updating
 
     for context in project_node.context_iter():
         ctype = context["container_type"]
-        parent_ctype = context["parent_container_type"]
 
         if ctype == "project" and dont_recurate_project:
             pass  # don't curate OR reset
         else:
             # Cleanup, if indicated
             if reset:
                 clear_meta_info(context[ctype], template)
@@ -452,35 +583,34 @@
         # Resolve: perform path resolutions, if needed.  Currently only used to handle "IntendedFor" field which
         # needs to happen after a subject has been curated.
         for context in project_node.context_iter():
             bidsify_flywheel.process_resolvers(context, template)
 
         # Update: send updates to Flywheel, if the Flywheel Client is instantiated
         if fw:
-            if project:  # project is only passed in if processing the project
-                save_project_sidecar(project, project_node, save_sidecar_as_metadata)
-
             logger.info("Updating BIDS metadata on Flywheel")
             for context in project_node.context_iter():
                 ctype = context["container_type"]
+                if ctype == "project" and dont_recurate_project:
+                    continue
                 node = context[ctype]
                 if node.is_dirty():
-                    update_meta_info(fw, context)
+                    update_meta_info(fw, context, save_sidecar_as_metadata)
         else:
             logger.info("Missing fw, cannot update BIDS metadata on Flywheel")
     else:
         logger.info("Dry run, NOT updating BIDS metadata on Flywheel")
 
     return count
 
 
 def configure_logging(verbosity):
     my_logs = ["curate-bids"]
 
-    loggers = [
+    loggers = [ # noqa: F841
         logging.getLogger(name)
         for name in logging.root.manager.loggerDict
         if name in my_logs
     ]
 
     # Custom levels of 0 and 1 may be sent from legacy code;
     # 20 == INFO and 10 == DEBUG in modern python logging
@@ -669,22 +799,41 @@
         project_id = utils.get_project_id_from_session_id(fw, args.session_id)
     else:
         logger.error(
             "Either project label (group id optional) or subject/session id is required!"
         )
         sys.exit(1)
 
+    # Originally, BIDS sidecar data was stored in file.info.BIDS and the actual json sidecar was ignored.
+    # This caused a great deal of confusion, especially if the sidecar existed, because that information
+    # was in two places and because anyone doing BIDS outside of Flywheel expects the information to be in
+    # the real sidecar.  The new way is to respect the sidecars and not copy that information into file.info.
+    # The Flywheel UI uses the presences of "BIDS" in project.info to know that it should display in BIDS View,
+    # so the new way adds a key-value pair:
+    #   project.info["BIDS"]["Sidecar"] = "data is in sidecar, not file.info"
+    # This allows the UI to display in BIDS View, even for projects that don't put sidecar data in info.
+    # The old way put the contents of dataset_description.json in project.info["BIDS"].  The new way stores that
+    # as a json file attached to the project (along with a README.txt and other files).
+    # All this means that to test how BIDS was curated for a project has to be like the below conditionals.
+    # "Acknowledgements" is the first required part of dataset_description.json.  It will be present in
+    # project.info["BIDS"] if the project has been curated the old way, and absent if curation is being done
+    # the new way.
     if args.save_sidecar_as_metadata == "yes":
-        save_sidecar_as_metadata = True
+        save_sidecar_as_metadata = True  # ignore sidecar json files
     elif args.save_sidecar_as_metadata == "no":
         save_sidecar_as_metadata = False
-    else:  # check to see if the project has "BIDS" metadata
+    else:  # check to see if the project has old style "BIDS" metadata
         project = fw.get_project(project_id)
         if "BIDS" in project.info:
-            save_sidecar_as_metadata = True
+            if (
+                "Acknowledgements" in project.info["BIDS"]
+            ):  # then it was curated the old way
+                save_sidecar_as_metadata = True  # ignore sidecar json files
+            else:
+                save_sidecar_as_metadata = False
         else:
             save_sidecar_as_metadata = False
 
     # Curate BIDS project
     curate_bids(
         fw,
         project_id,
```

## flywheel_bids/export_bids.py

```diff
@@ -1,22 +1,22 @@
 import argparse
+import copy
 import json
 import logging
 import os
 import re
 import sys
 import zipfile
+from pathlib import Path
 
 import dateutil.parser
 import flywheel
-from datetime import datetime
 
-from pathlib import Path
-from flywheel_bids.supporting_files import errors, utils
-from flywheel_bids.supporting_files.errors import BIDSExportError
+from .supporting_files import errors, utils
+from .supporting_files.errors import BIDSExportError
 
 logging.basicConfig(level=logging.INFO)
 logger = logging.getLogger("bids-exporter")
 
 EPOCH = dateutil.parser.parse("1970-01-01 00:00:0Z")
 
 
@@ -111,15 +111,15 @@
 
 
 def warn_if_bids_invalid(f, namespace):
     """
     Logs a warning iff info.BIDS.valid = false
     """
     metadata = get_metadata(f, namespace)
-    if not metadata or metadata.get("valid") == None:
+    if not metadata or metadata.get("valid") is None:
         return
     elif not parse_bool(metadata.get("valid")):
         logger.warning(
             "File {} is not valid: {}".format(
                 metadata.get("Filename"), metadata.get("error_message")
             )
         )
@@ -152,32 +152,65 @@
     metadata = get_metadata(f, namespace)
     if not metadata:
         return ""
 
     return metadata.get("Folder")
 
 
-def check_sidecar_exist(fw, filepath_downloads, outdir):
-    """Match acquisitions to be downloaded to sidecar.
-    If the sidecar exists, then nothing is changed or created.
+def check_sidecar_exist(fw, filepath_downloads, outdir, ignore_sidecars):
+    """Make sure all NIfTIs in acquisitions to be downloaded have a sidecar.
+
+    If the sidecar exists (the json file is listed in filepath_downloads["sidecar"]),
+    then nothing is changed or created and it will be downloaded with the NIfTI file
+    when this returns to download_bids_files().
     If the sidecar does not exist, then the sidecar is created from the metadata
-    and the newly generated sidecar is added to list of files to download.
+    and the newly generated sidecar is written to outdir.
+
+    Args:
+        fw: (Flywheel Client)
+        filepath_downloads: {container_type: {filepath: {'args': (tuple of args for sdk download function), 'modified': file modified attr}}}
+            args[0] = id
+            args[1] = name from the platform
+            args[2] = name at dest
+            modified = Different, time-based representations of the last changes to the file
+        outdir: (string) path to directory to download files to
+        ignore_sidecars: (bool) true if sidecars should be created using file.info metadata
     """
 
     for acq, acq_details in filepath_downloads["acquisition"].items():
-        if not Path(acq).stem in filepath_downloads["sidecar"]:
-            # Need to get acquisition for the metadata
+        if acq.endswith(".nii.gz"):
+            sidecar_path = acq[:-7] + ".json"
+        elif acq.endswith(".nii"):
+            sidecar_path = acq[:-4] + ".json"
+        else:
+            continue  # only need sidecars from NIfTIs produced from DICOMs
+
+        if ignore_sidecars:
+            if sidecar_path in filepath_downloads["sidecar"]:
+                logger.warning(
+                    "Ignoring real sidecar file %s and using metadata in file.info instead.",
+                    sidecar_path,
+                )
+                del filepath_downloads["sidecar"][sidecar_path]
+
+        # else if not ignore_sidecars and sidecar_path is in filepath_downloads, it will be downloaded later.
+
+        # At this point either ignore_sidecars is true and the path has been deleted from filepath_downloads
+        # or ignore_sidecars is false and the path might be missing from filepath_downloads, so...
+
+        if sidecar_path not in filepath_downloads["sidecar"]:
+            # Need to find the NIfTI file in this acquisition to get its metadata to put in the sidecar
             f = [
                 x
                 for x in fw.get_acquisition(acq_details["args"][0]).get("files", {})
                 if acq_details["args"][1] == x["name"]
             ][0]
             try:
                 create_json_sidecar(f["info"], "BIDS", outdir)
-            except:
+            except: # noqa: E722
                 logger.error(f"{f['name']} does not have info section.")
 
 
 def create_json_sidecar(metadata, namespace, outdir):
     """
     Create a JSON file with the BIDS info.
 
@@ -191,30 +224,24 @@
         namespace (str) : key in the meta_info to save (BIDS)
         outdir: directory where the json will be written
     """
 
     # Remove the 'BIDS' value from info
     try:
         ns_data = metadata.pop(namespace)
-    except:
+    except: # noqa: E722
         ns_data = {}
 
     # If meta info is empty, simply return
     if not metadata:
         logger.info(
             f"No metadata, besides possibly {namespace}, available to create sidecar"
         )
         return
 
-    # If the file is functional,
-    #   move the 'TaskName' from 'BIDS'
-    #   to the top level
-    if "/func" in ns_data["Path"] and "Task" in ns_data:
-        metadata["TaskName"] = ns_data["Task"]
-
     # Perform delete and updates
     for key in ns_data.get("delete_info", []):
         metadata.pop(key, None)
 
     for key, value in ns_data.get("set_info", {}).items():
         metadata[key] = value
 
@@ -229,23 +256,29 @@
 
     # Write out contents to JSON file
     with open(new_path, "w") as outfile:
         json.dump(metadata, outfile, sort_keys=True, indent=4)
     return new_path
 
 
-def download_bids_files(fw, filepath_downloads, dry_run, outdir):
+def download_bids_files(fw, filepath_downloads, dry_run, outdir, ignore_sidecars):
     """
-    filepath_downloads: {container_type: {filepath: {'args': (tuple of args for sdk download function), 'modified': file modified attr}}}
-        args[0] = id
-        args[1] = name from the platform
-        args[2] = name at dest
-        modified = Different, time-based representations of the last changes to the file
+    Args:
+        fw: Flywheel Client
+        filepath_downloads: {container_type: {filepath: {'args': (tuple of args for sdk download function), 'modified': file modified attr}}}
+            args[0] = id
+            args[1] = name from the platform
+            args[2] = name at dest
+            modified = Different, time-based representations of the last changes to the file
+        dry_run: (bool) if true, don't actually do anything
+        outdir: (string) path to directory to download files to
+        ignore_sidecars: (bool) true if sidecars should be created using file.info metadata
     """
-    check_sidecar_exist(fw, filepath_downloads, outdir)
+    check_sidecar_exist(fw, filepath_downloads, outdir, ignore_sidecars)
+
     # Download all project files
     logger.info("Downloading project files")
     for f in filepath_downloads["project"]:
         args = filepath_downloads["project"][f]["args"]
 
         try:
             modified = filepath_downloads["project"][f]["modified"]
@@ -254,15 +287,15 @@
             if dry_run:
                 logger.info(f"  to {args[2]}")
                 continue
             fw.download_file_from_project(*args)
             # Set the mtime of the downloaded file to the 'modified' timestamp in seconds
             modified_time = float(timestamp_to_int(modified))
             os.utime(f, (modified_time, modified_time))
-        except:
+        except: # noqa: E722
             logger.info(f"{f} not found")
 
         # If zipfile is attached to project, unzip...
         path = args[2]
         zip_pattern = re.compile("[a-zA-Z0-9]+(.zip)")
         zip_dirname = path[:-4]
         if zip_pattern.search(path):
@@ -329,27 +362,45 @@
     }
     valid = True
 
     if container_type == "project":
         # Get project
         project = fw.get_project(container_id)
 
-        # Check that project is curated
-        if not project["info"].get(namespace):
+        # Check if and how project is curated
+        how_curated = ""
+        if namespace in project.info and "Acknowledgements" in project.info[namespace]:
+            how_curated = (
+                "BIDS metadata is on the project, file.info.BIDS will be used "
+                "to create sidecars and any json sidecars will be ignored"
+            )
+            ignore_sidecars = True
+        else:
+            for file in project.files:
+                if file.name == "dataset_description.json":
+                    how_curated = (
+                        "The file 'dataset_description.json' is attached to the project "
+                        "and BIDS metadata was not found.  All json sidecars will be "
+                        "exported if they exist.  If not, file.info.BIDS will be used to "
+                        "create sidecars."
+                    )
+                    ignore_sidecars = False
+                    break
+        if how_curated == "":
             raise BIDSExportError(
                 "Project {} has not been curated for {}".format(
                     project.label, namespace
                 )
             )
+        else:
+            logger.info(how_curated)
 
         logger.info("Processing project files")
         # Iterate over any project files
-        for f in project.get(
-            "files", []
-        ):  # Why are jsons excluded from the files list?
+        for f in project.get("files", []):
             # Define path - ensure that the folder exists...
             path = define_path(outdir, f, namespace)
             # If path is not defined (an empty string) move onto next file
             if not path:
                 continue
 
             # Don't exclude any files that specify exclusion
@@ -357,42 +408,50 @@
                 continue
 
             if not os.path.exists(os.path.dirname(path)):
                 os.makedirs(os.path.dirname(path))
 
             warn_if_bids_invalid(f, namespace)
 
-            # For dry run, don't actually download
             if path in filepath_downloads["project"]:
                 logger.error(
                     "Multiple files with path {0}:\n\t{1} and\n\t{2}".format(
                         path, f["name"], filepath_downloads["project"][path]["args"][1]
                     )
                 )
                 valid = False
 
             filepath_downloads["project"][path] = {
                 "args": (project["_id"], f["name"], path),
                 "modified": f.get("modified"),
             }
 
-        ## Create dataset_description.json filepath_download
-        path = os.path.join(outdir, "dataset_description.json")
-        try:
-            filepath_downloads["project"][path] = {
-                "args": (project["info"][namespace], path, namespace),
-                "modified": f.get("modified"),
+        path = os.path.join(outdir, "./dataset_description.json")
+        if ignore_sidecars:
+            if path in filepath_downloads["project"]:
+                logger.warning(
+                    "dataset_description.json will be ignored because sidecar information "
+                    "is stored in project Custom Information (project.info.BIDS)."
+                )
+                del filepath_downloads["project"][path]
+
+            # create the required json file from project info
+            fake_nifti_info = copy.deepcopy(project.info["BIDS"])
+            fake_nifti_info["BIDS"] = {
+                "Filename": "dataset_description.nii.gz",
+                "Path": ".",
             }
-        except:
-            # ApiException 404 "Detail: Not Found"
-            logger.info(f"dataset_description.json not found.")
+            create_json_sidecar(fake_nifti_info, "BIDS", outdir)
+
         # Get project sessions
         project_sessions = fw.get_project_sessions(container_id)
+
     elif container_type == "session":
         project_sessions = [fw.get_session(container_id)]
+
     else:
         project_sessions = []
 
     if project_sessions:
         logger.info("Processing session files")
         all_acqs = []
         for proj_ses in project_sessions:
@@ -458,15 +517,15 @@
         for ses_acq in all_acqs:
             # Skip if BIDS.Ignore is True
             if is_container_excluded(ses_acq, namespace):
                 continue
             # Get true acquisition if files aren't already retrieved, in order to access file info
 
             acq = fw.get_acquisition(ses_acq["_id"])
-            # Iterate over acquistion files
+            # Iterate over acquisition files
             for f in acq.get("files", []):
                 # Skip any folders not in the skip-list (if there is a skip list)
                 if folders:
                     folder = get_folder(f, namespace)
                     if folder not in folders:
                         continue
 
@@ -517,15 +576,15 @@
         # If the BIDS app has its own validation and the user does not want FW to
         # check before downloading the data (validation = False), then don't
         # stop the download and the gear.
         raise BIDSExportError(
             "Error mapping files from Flywheel to BIDS.\n" "Hint: Check curation."
         )
 
-    download_bids_files(fw, filepath_downloads, dry_run, outdir)
+    download_bids_files(fw, filepath_downloads, dry_run, outdir, ignore_sidecars)
 
 
 def determine_container(fw, project_label, container_type, container_id, group_id=None):
     """
     Figures out what container_type and container_id should be if not given
     """
     cid = ctype = None
```

## flywheel_bids/supporting_files/bidsify_flywheel.py

```diff
@@ -53,26 +53,32 @@
         elif proptype == "object":
             obj[key] = properties[key].get("default", {})
         elif "default" in properties[key]:
             obj[key] = properties[key]["default"]
     return obj
 
 
-# update_properties(properties, context, obj)
-# Updates object values for items in properties list containing an 'auto_update' attribute.
-# 'auto_update' may be specified using a string template containing tags to be replaced from value in 'context' object
-# See process_string_template for details on how to use string templates
-# Updated keys are added to the obj object for later update to Flywheel
-
-# 'auto_update' can also be a dictionary with keys '$value' and '$format' that
-# will use util.format_value, the value is a direct dict_lookup, the string
-# is not processed
+def update_properties(properties, context, obj):
+    """Updates object values for items in properties list containing an 'auto_update' attribute.
 
+    This is done ony after the properties have been initialized using the context so values from the
+    BIDS namespace can be used.
+
+    The basic 'auto_update' is specified using a string type containing tags to be replaced from values
+    in the 'context' object.  If 'auto_update' is a dictionary, '$process', '$value' and '$format' can be
+    used to do more complicated things.
+
+    If 'auto_update' is an 'object' type, the properties therein are processed recursively.
+
+    :param properties: (dict) Properties of the template to be updated.
+    :param context: (dict) the current container or file where property values can be found.
+    :param obj: (dict) the result being updated.
+    :return: obj
+    """
 
-def update_properties(properties, context, obj):
     for key in properties:
         proptype = properties[key]["type"]
         if proptype == "string":
             if "auto_update" in properties[key]:
                 auto_update = properties[key]["auto_update"]
                 if isinstance(auto_update, dict):
                     if auto_update.get("$process"):
@@ -82,14 +88,20 @@
                     else:
                         value = utils.dict_lookup(context, auto_update["$value"])
                     obj[key] = utils.format_value(auto_update["$format"], value)
                 else:
                     obj[key] = utils.process_string_template(auto_update, context)
 
                 logger.debug(f"Setting <{key}> to <{obj[key]}>")
+        elif proptype == "array":
+            pass  # so far, no need to auto_update any arrays
+        elif proptype == "object":
+            obj[key] = update_properties(properties[key]["properties"], context, {})
+        else:
+            logger.error("Unsupported property type <{proptype}>")
 
     return obj
 
 
 # process_matching_templates(context, template)
 # Accepts a context object that represents a Flywheel container and related parent containers
 # and looks for matching templates in namespace.
@@ -148,15 +160,15 @@
         )
 
         # Do initial rule matching
         rules = template.rules
         # If matching on upload, test against upload_rules as well
         # The upload_rule may be as simple as {'container_type': 'file', 'parent_container_type': 'acquisition'}
         if upload:
-            logger.debug(f"Matching on upload, testing against upload_rules\n")
+            logger.debug("Matching on upload, testing against upload_rules\n")
             rules = rules + template.upload_rules
 
         # TODO: Prioritize the rules with modality type that matches label
         for rule in rules:
             logger.debug(
                 f"checking rule: <{rule.id}> for container template: <{rule.template}>\n"
             )
```

## flywheel_bids/supporting_files/file_funcs.py

```diff
@@ -22,15 +22,14 @@
     results to only the measurement of interest (i.e., T1)
     """
     # Get rid of localizers
     if not filename.get("classification"):
         return False
 
     arg_dict = {"Intent": [intent], "Measurement": [measurement], "Features": features}
-    check_passes = []
     for k, v in arg_dict.items():
         if filename.get("classification", {}).get(k) and v:
             if isinstance(filename.get("classification", {}).get(k), list):
                 param_set = set(filename.get("classification", {}).get(k))
             elif isinstance(filename.get("classification", {}).get(k), str):
                 param_set = set([filename.get("classification", {}).get(k)])
             if set(v).isdisjoint(param_set):
```

## flywheel_bids/supporting_files/project_tree.py

```diff
@@ -257,12 +257,11 @@
     project_id = utils.validate_project_label(fw, args.project_label)
 
     project = fw.get_project(project_id)
 
     project_node = get_project_node(fw, project_id)
 
     for subject in project.subjects.iter():
-
         set_tree(fw, project_node, subject, session_id=None)
 
     with open(args.output_file, "w") as f:
         json.dump(project_node.to_json(), f, indent=2)
```

## flywheel_bids/supporting_files/resolver.py

```diff
@@ -1,11 +1,11 @@
 import json
 
-
 import flywheel
+
 from . import utils
 
 
 class Filter:
     """
     Simple wrapper for a matching filter that can be applied to a context.
 
@@ -54,26 +54,25 @@
         filter_field: The field that contains the user-defined filter
         container_type: The type of container this resolver should match
         resolve_for: The level that resolution for this resolver should take place (e.g. session)
         format: The format string for resolved values
         value: The path to the value to copy, if not using a format string
     """
 
-    def __init__(self, namespace, resolverDef, fw, save_sidecar_as_metadata=False):
+    def __init__(self, namespace, resolverDef, save_sidecar_as_metadata=False):
         self.namespace = namespace
         self.id = resolverDef.get("id")
         self.templates = resolverDef.get("templates", [])
         self.update_field = resolverDef.get("update")
         self.filter_field = resolverDef.get("filter")
         self.container_type = resolverDef.get("type")
         self.resolve_for = resolverDef.get("resolveFor")
         self.format = resolverDef.get("format")
         self.value = resolverDef.get("value")
         self.save_sidecar_as_metadata = save_sidecar_as_metadata
-        self.client = fw
 
         if self.format and self.value:
             print(
                 'WARNING: Because "format" is specified, "value" will be ignored for resolver: {}'.format(
                     self.id
                 )
             )
@@ -116,48 +115,13 @@
                         if value:
                             if results and results != value:
                                 print(
                                     "WARNING: multiple different matches when resolving results, will take last match!"
                                 )
                             results = value
 
-        # Finally update the field specified
-        if self.save_sidecar_as_metadata:  # then update that metadata
-            utils.dict_set(context, self.update_field, results)
-
-        # always save actual sidecar so update that json file
-        nifti_name = context["file"].data["name"]  # get name of sidecar from NIfTI
-        if not nifti_name.endswith(".nii.gz"):
-            print(f"Unexpected file name '{nifti_name}', should end with '.nii.gz'  ")
-        else:
-            update_nifti_sidecar_field(
-                self.client,
-                context["acquisition"].data["id"],
-                nifti_name,
-                self.update_field.split(".")[-1],
-                results,
-            )
-
-
-def update_nifti_sidecar_field(fw, acquisition_id, nifti_name, field_name, results):
-    """Set the value of the given field_name to results for the specified NIfTI file's .json sidecar
-
-    Args:
-        fw (Flywheel Client): to be able to access the file
-        acquisition_id (str): The acquisition that the NIfTI and json files are in
-        nifti_name (str): Name of the NIfTI file that matches the sidecar file name
-        field_name (str): The key at the top level of the json file where the results should go, e.g. Intendedfor
-        results (object): the value to assign to the key, e.g. a list of strings (BIDS paths)
-    """
-    if isinstance(fw, flywheel.client.Client):
-        sidecar_name = nifti_name[:-7] + ".json"
-        acquisition = fw.get_acquisition(acquisition_id)
-        sidecar_contents = acquisition.read_file(sidecar_name)
-        if not sidecar_contents:
-            print(f"Unable to load {sidecar_name}")
-        sidecar_json = json.loads(sidecar_contents)
-        sidecar_json[field_name] = results
-        json_str = json.dumps(sidecar_json, indent=4)
-        file_spec = flywheel.FileSpec(sidecar_name, json_str, "text/plain")
-        acquisition.upload_file(file_spec)
-    else:  # must be a test
-        print(f"Client is {type(fw)}.  Cannot update sidecar")
+        # put paths resolved above into "sidecarChanges" so they will be written to the sidecar later
+        if "sidecarChanges" not in context["file"].data["info"]["BIDS"]:
+            context["file"].data["info"]["BIDS"]["sidecarChanges"] = {}
+        context["file"].data["info"]["BIDS"]["sidecarChanges"][
+            self.update_field.split(".")[-1]
+        ] = results
```

## flywheel_bids/supporting_files/templates.py

```diff
@@ -6,15 +6,14 @@
 import re
 
 import jsonschema
 import six
 
 from . import resolver, utils
 
-
 logger = logging.getLogger("curate-bids")
 
 DEFAULT_TEMPLATE_NAME = "default"
 BIDS_V1_TEMPLATE_NAME = "bids-v1"
 REPROIN_TEMPLATE_NAME = "reproin"
 
 this_dir = os.path.dirname(os.path.realpath(__file__))
@@ -39,47 +38,46 @@
         description (str): The optional description of the template.
         definitions (dict): The map of template definitions.
         rules (list): The list of if rules for applying templates.
         extends (string): The optional name of the template to extend.
         exclude_rules (list): The optional list of rules to exclude from a parent template.
     """
 
-    def __init__(self, data, fw=None, save_sidecar_as_metadata=False):
+    def __init__(self, data, save_sidecar_as_metadata=False):
         if data:
             self.namespace = data.get("namespace")
             self.description = data.get("description", "")
             self.definitions = data.get("definitions", {})
             self.rules = data.get("rules", [])
             self.upload_rules = data.get("upload_rules", [])
             self.resolvers = data.get("resolvers", [])
             self.custom_initializers = data.get("initializers", [])
             self.extends = data.get("extends")
             self.exclude_rules = data.get("exclude_rules", [])
         else:
             raise Exception("data is required")
 
         if self.extends:
-            self.do_extend(fw, save_sidecar_as_metadata)
+            self.do_extend(save_sidecar_as_metadata)
 
         resolver = jsonschema.RefResolver.from_schema({"definitions": self.definitions})
         self.resolve_refs(resolver, self.definitions)
-        self.compile_resolvers(fw, save_sidecar_as_metadata)
+        self.compile_resolvers(save_sidecar_as_metadata)
         self.compile_rules()
         self.compile_custom_initializers()
 
-    def do_extend(self, fw, save_sidecar_as_metadata):
+    def do_extend(self, save_sidecar_as_metadata):
         """
         The template (json file) just read is an extension template so load the template
         that is to be extended (one of the defined templates).
         """
 
         logger.info("Extending project curation template: '%s'", self.extends)
 
         parent = load_template(
-            fw,
             template_name=self.extends,
             save_sidecar_as_metadata=save_sidecar_as_metadata,
         )
 
         if not self.namespace:
             self.namespace = parent.namespace
 
@@ -112,25 +110,23 @@
                 self.rules[i] = Rule(rule)
 
         for i in range(0, len(self.upload_rules)):
             upload_rule = self.upload_rules[i]
             if not isinstance(upload_rule, Rule):
                 self.upload_rules[i] = Rule(upload_rule)
 
-    def compile_resolvers(self, fw=None, save_sidecar_as_metadata=False):
+    def compile_resolvers(self, save_sidecar_as_metadata=False):
         """
         Walk through the definitions
         """
         self.resolver_map = {}
         for i in range(0, len(self.resolvers)):
             res = self.resolvers[i]
             if not isinstance(res, resolver.Resolver):
-                res = resolver.Resolver(
-                    self.namespace, res, fw, save_sidecar_as_metadata
-                )
+                res = resolver.Resolver(self.namespace, res, save_sidecar_as_metadata)
 
             # Create a mapping of template id to resolver
             for tmpl in res.templates:
                 if tmpl not in self.resolver_map:
                     self.resolver_map[tmpl] = []
                 self.resolver_map[tmpl].append(res)
 
@@ -373,30 +369,42 @@
         logger.debug(f'returning default {caseDef.get("$value")}')
         return caseDef.get("$value")
 
     return None
 
 
 def handle_run_counter_initializer(initializers, info, context):
-    counter = context.get("run_counters")
-    if not counter:
+    counter_map = context.get("run_counters")
+    if not counter_map:
         return
 
     for propName, propDef in initializers.items():
         if isinstance(propDef, dict) and "$run_counter" in propDef:
             current = info.get(propName)
-            if current == "+" or current == "=":
-                key = propDef["$run_counter"]["key"]
-                key = utils.process_string_template(key, context)
 
-                counter = counter[key]
+            key = propDef["$run_counter"]["key"]
+            key = utils.process_string_template(key, context)
+
+            if current == "+" or current == "=":
+                run_counter = counter_map[
+                    key
+                ]  # creates run_counter if it doesn't exist
                 if current == "+":
-                    info[propName] = counter.next()
+                    info[propName] = run_counter.next()
                 else:
-                    info[propName] = counter.current()
+                    info[propName] = run_counter.current()
+
+            elif current.isdigit():
+                run_counter = counter_map[
+                    key
+                ]  # creates run_counter if it doesn't exist
+                info[propName] = run_counter.increment_if_used(current)
+
+            # else: if it is an empty or other string or some crazy thing, just use it as is
+            # and don't create a run_counter
 
 
 def test_where_clause(conditions, context):
     """
     Test if the given context matches this rule.
 
     Args:
@@ -598,15 +606,15 @@
         return any(match_values)
     elif "and" in condition:
         return all(match_values)
     else:
         logger.error("Expected or/and not %s", condition)
 
 
-def load_template(fw, path=None, template_name=None, save_sidecar_as_metadata=False):
+def load_template(path=None, template_name=None, save_sidecar_as_metadata=False):
     """
     Load the template at path or the named template at the default path
 
     Args:
         fw (Flywheel Client)
         path (str): The path to the template to load
         template_name (str): will load default_path + / + template_name + .json
@@ -621,8 +629,8 @@
 
         path = os.path.join(DEFAULT_TEMPLATE_DIR, template_name + ".json")
 
     logger.info("Using project curation template: '%s'", path)
 
     data = load_and_normalize_json(path)
 
-    return Template(data, fw, save_sidecar_as_metadata)
+    return Template(data, save_sidecar_as_metadata)
```

## flywheel_bids/supporting_files/utils.py

```diff
@@ -57,18 +57,26 @@
         )
 
 
 def validate_project_label(fw, project_label, group_id=None):
     """ """
     # Find project id
     if group_id:
-        project = fw.projects.find_one(f"group={group_id},label={project_label}")
+        projects = fw.projects.find(f"group={group_id},label={project_label}")
     else:
-        project = fw.projects.find_one(f"label={project_label}")
+        projects = fw.projects.find(f"label={project_label}")
 
+    num_projects = len(projects)
+    if num_projects > 1:
+        raise ValueError(
+            "Found %d projects with label %s.  Use the --group-id option to specify a group id"
+            % (num_projects, project_label)
+        )
+
+    project = projects[0]
     return project.id
 
 
 def get_project_id_from_subject_id(fw, subject_id):
     """ """
     # Find project id from subject
     subject = fw.get_subject(subject_id)
@@ -299,22 +307,45 @@
             return responses[choice]
         six.print_('Please respond with "yes" or "no".')
 
 
 class RunCounter:
     def __init__(self):
         self.current = 0
+        self.used = set()
 
-    def next(self):
+    def next(self):  # only used for + or =
         self.current = self.current + 1
+        self.used.add(self.current)
         return str(self.current)
 
-    def current(self):
+    def current(self):  # only used for + or =
+        self.used.add(self.current)
         return str(self.current)
 
+    def increment_if_used(
+        self, current_str
+    ):  # only used for digits in handle_run_counter_initializer()
+        new_value = int(current_str)
+
+        while new_value in self.used:
+            new_value += 1
+
+        if new_value != int(current_str):
+            logger.warning(
+                "run_counter %s has already been used, using %s instead",
+                current_str,
+                new_value,
+            )
+
+        self.current = new_value
+        self.used.add(new_value)
+
+        return f"{int(new_value):0>{len(current_str)}}"
+
 
 class RunCounterMap:
     def __init__(self):
         self.entries = {}
 
     def __getitem__(self, key):
         if key not in self.entries:
```

## flywheel_bids/templates/default.json

### Pretty-printed

 * *Similarity: 0.9976703466286799%*

 * *Differences: {"'definitions'": "{'func_file': {'properties': {'sidecarChanges': OrderedDict([('type', "*

 * *                  "'object'), ('title', 'key-value pairs that need to be changed in the sidecar'), "*

 * *                  "('default', OrderedDict()), ('properties', OrderedDict([('TaskName', "*

 * *                  "OrderedDict([('type', 'string'), ('title', 'TaskName'), ('default', ''), "*

 * *                  "('auto_update', '{file.info.BIDS.Task}')]))]))])}}, 'project': {'properties': "*

 * *                  "{replace: OrderedD […]*

```diff
@@ -340,14 +340,81 @@
             },
             "required": [
                 "Filename",
                 "Suffix",
                 "Task"
             ]
         },
+        "dataset_description_file": {
+            "description": "BIDS project level file contents, becomes dataset_description.json or BIDS metadata on project",
+            "properties": {
+                "Acknowledgements": {
+                    "default": "",
+                    "title": "Acknowledgements",
+                    "type": "string"
+                },
+                "Authors": {
+                    "default": [],
+                    "title": "Authors",
+                    "type": "array"
+                },
+                "BIDSVersion": {
+                    "default": "1.4.1",
+                    "title": "BIDS Version",
+                    "type": "string"
+                },
+                "DatasetDOI": {
+                    "default": "",
+                    "title": "Dataset DOI",
+                    "type": "string"
+                },
+                "DatasetType": {
+                    "default": "raw",
+                    "title": "Dataset Type",
+                    "type": "string"
+                },
+                "EthicsApprovals": {
+                    "default": [],
+                    "title": "Ethics Approvals",
+                    "type": "array"
+                },
+                "Funding": {
+                    "default": [],
+                    "title": "Funding",
+                    "type": "array"
+                },
+                "HEDVersion": {
+                    "default": "",
+                    "title": "HED Version",
+                    "type": "string"
+                },
+                "HowToAcknowledge": {
+                    "default": "",
+                    "title": "How To Acknowledge",
+                    "type": "string"
+                },
+                "License": {
+                    "default": "",
+                    "title": "License",
+                    "type": "string"
+                },
+                "Name": {
+                    "auto_update": "{project.label}",
+                    "default": "",
+                    "title": "Name",
+                    "type": "string"
+                },
+                "ReferencesAndLinks": {
+                    "default": [],
+                    "title": "References and Links",
+                    "type": "array"
+                }
+            },
+            "required": []
+        },
         "dicom_file": {
             "description": "BIDS template for DICOM files",
             "properties": {
                 "Filename": {
                     "$ref": "#/definitions/Filename"
                 },
                 "Folder": {
@@ -840,14 +907,27 @@
                         "sbref"
                     ],
                     "title": "Suffix",
                     "type": "string"
                 },
                 "Task": {
                     "$ref": "#/definitions/Task"
+                },
+                "sidecarChanges": {
+                    "default": {},
+                    "properties": {
+                        "TaskName": {
+                            "auto_update": "{file.info.BIDS.Task}",
+                            "default": "",
+                            "title": "TaskName",
+                            "type": "string"
+                        }
+                    },
+                    "title": "key-value pairs that need to be changed in the sidecar",
+                    "type": "object"
                 }
             },
             "required": [
                 "Filename",
                 "Suffix",
                 "Task"
             ]
@@ -1086,74 +1166,18 @@
                     "Modality"
                 ]
             }
         },
         "project": {
             "description": "BIDS project template",
             "properties": {
-                "Acknowledgements": {
-                    "default": "",
-                    "title": "Acknowledgements",
-                    "type": "string"
-                },
-                "Authors": {
-                    "default": [],
-                    "title": "Authors",
-                    "type": "array"
-                },
-                "BIDSVersion": {
-                    "default": "1.4.1",
-                    "title": "BIDS Version",
-                    "type": "string"
-                },
-                "DatasetDOI": {
-                    "default": "",
-                    "title": "Dataset DOI",
-                    "type": "string"
-                },
-                "DatasetType": {
-                    "default": "raw",
-                    "title": "Dataset Type",
+                "Sidecar": {
+                    "default": "data is in json sidecar, not file.info",
+                    "title": "Sidecar",
                     "type": "string"
-                },
-                "EthicsApprovals": {
-                    "default": [],
-                    "title": "Ethics Approvals",
-                    "type": "array"
-                },
-                "Funding": {
-                    "default": [],
-                    "title": "Funding",
-                    "type": "array"
-                },
-                "HEDVersion": {
-                    "default": "",
-                    "title": "HED Version",
-                    "type": "string"
-                },
-                "HowToAcknowledge": {
-                    "default": "",
-                    "title": "How To Acknowledge",
-                    "type": "string"
-                },
-                "License": {
-                    "default": "",
-                    "title": "License",
-                    "type": "string"
-                },
-                "Name": {
-                    "auto_update": "{project.label}",
-                    "default": "",
-                    "title": "Name",
-                    "type": "string"
-                },
-                "ReferencesAndLinks": {
-                    "default": [],
-                    "title": "References and Links",
-                    "type": "array"
                 }
             },
             "required": []
         },
         "project_file": {
             "description": "BIDS template for project files",
             "properties": {
```

## flywheel_bids/templates/reproin.json

### Pretty-printed

 * *Similarity: 0.9722842244385804%*

 * *Differences: {"'definitions'": "{'project': {'properties': {replace: OrderedDict([('Sidecar', "*

 * *                  "OrderedDict([('type', 'string'), ('title', 'Sidecar'), ('default', 'data is in "*

 * *                  "json sidecar, not file.info')]))])}, delete: ['description']}, 'project_file': "*

 * *                  "{'properties': {'Path': {'default': '.'}}}, 'anat_file': {'properties': "*

 * *                  "{'Filename': {'auto_update': "*

 * *                  "'sub-{session.info.BIDS.Subject}[_ses-{session.info.BIDS.Label}][_a […]*

```diff
@@ -111,74 +111,82 @@
                 "Custom": {
                     "$ref": "#/definitions/Custom"
                 },
                 "Echo": {
                     "$ref": "#/definitions/Echo"
                 },
                 "Filename": {
-                    "auto_update": "sub-{session.info.BIDS.Subject}[_ses-{session.info.BIDS.Label}][_acq-{file.info.BIDS.Acq}][_ce-{file.info.BIDS.Ce}][_rec-{file.info.BIDS.Rec}][_run-{file.info.BIDS.Run}][_mod-{file.info.BIDS.Mod}][_echo-{file.info.BIDS.Echo}][_part-{file.info.BIDS.Part}]_{file.info.BIDS.Modality}{ext}",
+                    "auto_update": "sub-{session.info.BIDS.Subject}[_ses-{session.info.BIDS.Label}][_acq-{file.info.BIDS.Acq}][_ce-{file.info.BIDS.Ce}][_rec-{file.info.BIDS.Rec}][_run-{file.info.BIDS.Run}][_mod-{file.info.BIDS.Mod}][_echo-{file.info.BIDS.Echo}][_part-{file.info.BIDS.Part}]_{file.info.BIDS.Suffix}{ext}",
                     "default": "",
                     "minLength": 1,
                     "title": "Filename",
                     "type": "string"
                 },
                 "Folder": {
                     "default": "anat",
                     "title": "Folder",
                     "type": "string"
                 },
                 "Mod": {
                     "$ref": "#/definitions/Mod"
                 },
-                "Modality": {
+                "Part": {
+                    "$ref": "#/definitions/Part"
+                },
+                "Path": {
+                    "auto_update": "sub-{session.info.BIDS.Subject}[/ses-{session.info.BIDS.Label}]/{file.info.BIDS.Folder}",
+                    "default": "",
+                    "title": "Path",
+                    "type": "string"
+                },
+                "Rec": {
+                    "$ref": "#/definitions/Rec"
+                },
+                "Run": {
+                    "$ref": "#/definitions/Run"
+                },
+                "Suffix": {
                     "default": "",
                     "enum": [
-                        "angio",
-                        "defacemask",
                         "FLAIR",
-                        "FLASH",
+                        "PDT2",
+                        "Pdw",
+                        "T1w",
+                        "T2starw",
+                        "T2w",
+                        "UNIT1",
+                        "angio",
                         "inplaneT1",
                         "inplaneT2",
                         "MEGRE",
                         "MESE",
+                        "VFA",
+                        "IRT1",
+                        "MP2RAGE",
+                        "MPM",
+                        "MTS",
+                        "MTR",
+                        "defacemask",
+                        "FLASH",
                         "M0map",
                         "PD",
                         "PDmap",
-                        "PDT2",
                         "R2map",
                         "SWImagandphase",
-                        "T1w",
-                        "T2w",
                         "T1rho",
                         "T1map",
-                        "T2map",
-                        "T2star"
+                        "T2map"
                     ],
-                    "title": "Modality Label",
-                    "type": "string"
-                },
-                "Part": {
-                    "$ref": "#/definitions/Part"
-                },
-                "Path": {
-                    "auto_update": "sub-{session.info.BIDS.Subject}[/ses-{session.info.BIDS.Label}]/{file.info.BIDS.Folder}",
-                    "default": "",
-                    "title": "Path",
+                    "title": "Suffix: after all entities and before the file extension",
                     "type": "string"
-                },
-                "Rec": {
-                    "$ref": "#/definitions/Rec"
-                },
-                "Run": {
-                    "$ref": "#/definitions/Run"
                 }
             },
             "required": [
                 "Filename",
-                "Modality"
+                "Suffix"
             ]
         },
         "beh_events_file": {
             "description": "BIDS behavioral event file template",
             "properties": {
                 "Custom": {
                     "$ref": "#/definitions/Custom"
@@ -206,14 +214,66 @@
                 }
             },
             "required": [
                 "Filename",
                 "Task"
             ]
         },
+        "dataset_description_file": {
+            "description": "BIDS project level file contents, becomes dataset_description.json or BIDS metadata on project",
+            "properties": {
+                "Acknowledgements": {
+                    "default": "",
+                    "title": "Acknowledgements",
+                    "type": "string"
+                },
+                "Authors": {
+                    "default": [],
+                    "title": "Authors",
+                    "type": "array"
+                },
+                "BIDSVersion": {
+                    "default": "1.8.0",
+                    "title": "BIDS Version",
+                    "type": "string"
+                },
+                "DatasetDOI": {
+                    "default": "",
+                    "title": "Dataset DOI",
+                    "type": "string"
+                },
+                "Funding": {
+                    "default": [],
+                    "title": "Funding Sources",
+                    "type": "array"
+                },
+                "HowToAcknowledge": {
+                    "default": "",
+                    "title": "How To Acknowledge",
+                    "type": "string"
+                },
+                "License": {
+                    "default": "",
+                    "title": "License",
+                    "type": "string"
+                },
+                "Name": {
+                    "auto_update": "{project.label}",
+                    "default": "",
+                    "title": "Name",
+                    "type": "string"
+                },
+                "ReferencesAndLinks": {
+                    "default": [],
+                    "title": "Reference and Links",
+                    "type": "array"
+                }
+            },
+            "required": []
+        },
         "dicom_file": {
             "description": "BIDS DICOM file template",
             "properties": {
                 "Filename": {
                     "$ref": "#/definitions/Filename"
                 },
                 "Folder": {
@@ -242,50 +302,50 @@
                 "Acq": {
                     "$ref": "#/definitions/Acq"
                 },
                 "Dir": {
                     "$ref": "#/definitions/Dir"
                 },
                 "Filename": {
-                    "auto_update": "sub-{session.info.BIDS.Subject}[_ses-{session.info.BIDS.Label}][_acq-{file.info.BIDS.Acq}][_dir-{file.info.BIDS.Dir}][_run-{file.info.BIDS.Run}][_part-{file.info.BIDS.Part}]_{file.info.BIDS.Modality}{ext}",
+                    "auto_update": "sub-{session.info.BIDS.Subject}[_ses-{session.info.BIDS.Label}][_acq-{file.info.BIDS.Acq}][_dir-{file.info.BIDS.Dir}][_run-{file.info.BIDS.Run}][_part-{file.info.BIDS.Part}]_{file.info.BIDS.Suffix}{ext}",
                     "default": "",
                     "minLength": 1,
                     "title": "Filename",
                     "type": "string"
                 },
                 "Folder": {
                     "default": "dwi",
                     "title": "Folder",
                     "type": "string"
                 },
-                "Modality": {
-                    "default": "",
-                    "enum": [
-                        "dwi",
-                        "sbref"
-                    ],
-                    "title": "Modality Label",
-                    "type": "string"
-                },
                 "Part": {
                     "$ref": "#/definitions/Part"
                 },
                 "Path": {
                     "auto_update": "sub-{session.info.BIDS.Subject}[/ses-{session.info.BIDS.Label}]/{file.info.BIDS.Folder}",
                     "default": "",
                     "title": "Path",
                     "type": "string"
                 },
                 "Run": {
                     "$ref": "#/definitions/Run"
+                },
+                "Suffix": {
+                    "default": "",
+                    "enum": [
+                        "dwi",
+                        "sbref"
+                    ],
+                    "title": "Suffix: after all entities and before the file extension",
+                    "type": "string"
                 }
             },
             "required": [
                 "Filename",
-                "Modality"
+                "Suffix"
             ]
         },
         "fieldmap_file": {
             "description": "BIDS fieldmap file template",
             "properties": {
                 "Acq": {
                     "$ref": "#/definitions/Acq"
@@ -296,57 +356,57 @@
                 "Custom": {
                     "$ref": "#/definitions/Custom"
                 },
                 "Dir": {
                     "$ref": "#/definitions/Dir"
                 },
                 "Filename": {
-                    "auto_update": "sub-{session.info.BIDS.Subject}[_ses-{session.info.BIDS.Label}][_acq-{file.info.BIDS.Acq}][_ce-{file.info.BIDS.Ce}][_dir-{file.info.BIDS.Dir}][_run-{file.info.BIDS.Run}]_{file.info.BIDS.Modality}{ext}",
+                    "auto_update": "sub-{session.info.BIDS.Subject}[_ses-{session.info.BIDS.Label}][_acq-{file.info.BIDS.Acq}][_ce-{file.info.BIDS.Ce}][_dir-{file.info.BIDS.Dir}][_run-{file.info.BIDS.Run}]_{file.info.BIDS.Suffix}{ext}",
                     "default": "",
                     "minLength": 1,
                     "title": "Filename",
                     "type": "string"
                 },
                 "Folder": {
                     "default": "fmap",
                     "title": "Folder",
                     "type": "string"
                 },
                 "IntendedFor": {
                     "$ref": "#/definitions/IntendedFor"
                 },
-                "Modality": {
+                "Path": {
+                    "auto_update": "sub-{session.info.BIDS.Subject}[/ses-{session.info.BIDS.Label}]/{file.info.BIDS.Folder}",
+                    "default": "",
+                    "title": "Path",
+                    "type": "string"
+                },
+                "Run": {
+                    "$ref": "#/definitions/Run"
+                },
+                "Suffix": {
                     "default": "fieldmap",
                     "enum": [
                         "phasediff",
                         "magnitude1",
                         "magnitude2",
                         "phase1",
                         "phase2",
                         "magnitude",
                         "fieldmap",
                         "epi",
                         "m0scan"
                     ],
-                    "title": "Modality Label",
+                    "title": "Suffix: after all entities and before the file extension",
                     "type": "string"
-                },
-                "Path": {
-                    "auto_update": "sub-{session.info.BIDS.Subject}[/ses-{session.info.BIDS.Label}]/{file.info.BIDS.Folder}",
-                    "default": "",
-                    "title": "Path",
-                    "type": "string"
-                },
-                "Run": {
-                    "$ref": "#/definitions/Run"
                 }
             },
             "required": [
                 "Filename",
-                "Modality"
+                "Suffix"
             ]
         },
         "func_file": {
             "description": "BIDS func file template",
             "properties": {
                 "Acq": {
                     "$ref": "#/definitions/Acq"
@@ -357,36 +417,25 @@
                 "Dir": {
                     "$ref": "#/definitions/Dir"
                 },
                 "Echo": {
                     "$ref": "#/definitions/Echo"
                 },
                 "Filename": {
-                    "auto_update": "sub-{session.info.BIDS.Subject}[_ses-{session.info.BIDS.Label}]_task-{file.info.BIDS.Task}[_acq-{file.info.BIDS.Acq}][_ce-{file.info.BIDS.Ce}][_rec-{file.info.BIDS.Rec}][_dir-{file.info.BIDS.Dir}][_run-{file.info.BIDS.Run}][_echo-{file.info.BIDS.Echo}][_part-{file.info.BIDS.Part}]_{file.info.BIDS.Modality}{ext}",
+                    "auto_update": "sub-{session.info.BIDS.Subject}[_ses-{session.info.BIDS.Label}]_task-{file.info.BIDS.Task}[_acq-{file.info.BIDS.Acq}][_ce-{file.info.BIDS.Ce}][_rec-{file.info.BIDS.Rec}][_dir-{file.info.BIDS.Dir}][_run-{file.info.BIDS.Run}][_echo-{file.info.BIDS.Echo}][_part-{file.info.BIDS.Part}]_{file.info.BIDS.Suffix}{ext}",
                     "default": "",
                     "minLength": 1,
                     "title": "Filename",
                     "type": "string"
                 },
                 "Folder": {
                     "default": "func",
                     "title": "Folder",
                     "type": "string"
                 },
-                "Modality": {
-                    "default": "",
-                    "enum": [
-                        "bold",
-                        "cbv",
-                        "phase",
-                        "sbref"
-                    ],
-                    "title": "Modality Label",
-                    "type": "string"
-                },
                 "Part": {
                     "$ref": "#/definitions/Part"
                 },
                 "Path": {
                     "auto_update": "sub-{session.info.BIDS.Subject}[/ses-{session.info.BIDS.Label}]/{file.info.BIDS.Folder}",
                     "default": "",
                     "title": "Path",
@@ -394,22 +443,46 @@
                 },
                 "Rec": {
                     "$ref": "#/definitions/Rec"
                 },
                 "Run": {
                     "$ref": "#/definitions/Run"
                 },
+                "Suffix": {
+                    "default": "",
+                    "enum": [
+                        "bold",
+                        "cbv",
+                        "phase",
+                        "sbref"
+                    ],
+                    "title": "Suffix: after all entities and before the file extension",
+                    "type": "string"
+                },
                 "Task": {
                     "$ref": "#/definitions/Task"
+                },
+                "sidecarChanges": {
+                    "default": {},
+                    "properties": {
+                        "TaskName": {
+                            "auto_update": "{file.info.BIDS.Task}",
+                            "default": "",
+                            "title": "TaskName",
+                            "type": "string"
+                        }
+                    },
+                    "title": "key-value pairs that need to be changed in the sidecar",
+                    "type": "object"
                 }
             },
             "required": [
                 "Filename",
                 "Task",
-                "Modality"
+                "Suffix"
             ]
         },
         "jpeg_file": {
             "description": "BIDS jpeg file template",
             "properties": {
                 "Filename": {
                     "$ref": "#/definitions/Filename"
@@ -459,97 +532,97 @@
                 "Custom": {
                     "$ref": "#/definitions/Custom"
                 },
                 "Dir": {
                     "$ref": "#/definitions/Dir"
                 },
                 "Filename": {
-                    "auto_update": "sub-{session.info.BIDS.Subject}[_ses-{session.info.BIDS.Label}][_acq-{file.info.BIDS.Acq}][_rec-{file.info.BIDS.Rec}][_dir-{file.info.BIDS.Dir}][_run-{file.info.BIDS.Run}]_{file.info.BIDS.Modality}{ext}",
+                    "auto_update": "sub-{session.info.BIDS.Subject}[_ses-{session.info.BIDS.Label}][_acq-{file.info.BIDS.Acq}][_rec-{file.info.BIDS.Rec}][_dir-{file.info.BIDS.Dir}][_run-{file.info.BIDS.Run}]_{file.info.BIDS.Suffix}{ext}",
                     "default": "",
                     "minLength": 1,
                     "title": "Filename",
                     "type": "string"
                 },
                 "Folder": {
                     "default": "perf",
                     "title": "Folder",
                     "type": "string"
                 },
-                "Modality": {
-                    "default": "aslcontext",
-                    "enum": [
-                        "aslcontext"
-                    ],
-                    "title": "Modality Label",
-                    "type": "string"
-                },
                 "Path": {
                     "auto_update": "sub-{session.info.BIDS.Subject}[/ses-{session.info.BIDS.Label}]/{file.info.BIDS.Folder}",
                     "default": "",
                     "title": "Path",
                     "type": "string"
                 },
                 "Rec": {
                     "$ref": "#/definitions/Rec"
                 },
                 "Run": {
                     "$ref": "#/definitions/Run"
+                },
+                "Suffix": {
+                    "default": "aslcontext",
+                    "enum": [
+                        "aslcontext"
+                    ],
+                    "title": "Suffix: after all entities and before the file extension",
+                    "type": "string"
                 }
             },
             "required": [
                 "Filename",
-                "Modality"
+                "Suffix"
             ]
         },
         "perf_file": {
             "description": "BIDS template for perf files",
             "properties": {
                 "Acq": {
                     "$ref": "#/definitions/Acq"
                 },
                 "Dir": {
                     "$ref": "#/definitions/Dir"
                 },
                 "Filename": {
-                    "auto_update": "sub-{session.info.BIDS.Subject}[_ses-{session.info.BIDS.Label}][_acq-{file.info.BIDS.Acq}][_rec-{file.info.BIDS.Rec}][_dir-{file.info.BIDS.Dir}][_run-{file.info.BIDS.Run}]_{file.info.BIDS.Modality}{ext}",
+                    "auto_update": "sub-{session.info.BIDS.Subject}[_ses-{session.info.BIDS.Label}][_acq-{file.info.BIDS.Acq}][_rec-{file.info.BIDS.Rec}][_dir-{file.info.BIDS.Dir}][_run-{file.info.BIDS.Run}]_{file.info.BIDS.Suffix}{ext}",
                     "default": "",
                     "minLength": 1,
                     "title": "Filename",
                     "type": "string"
                 },
                 "Folder": {
                     "default": "perf",
                     "title": "Folder",
                     "type": "string"
                 },
-                "Modality": {
-                    "default": "asl",
-                    "enum": [
-                        "asl",
-                        "m0scan"
-                    ],
-                    "title": "Modality Label",
-                    "type": "string"
-                },
                 "Path": {
                     "auto_update": "sub-{session.info.BIDS.Subject}[/ses-{session.info.BIDS.Label}]/{file.info.BIDS.Folder}",
                     "default": "",
                     "title": "Path",
                     "type": "string"
                 },
                 "Rec": {
                     "$ref": "#/definitions/Rec"
                 },
                 "Run": {
                     "$ref": "#/definitions/Run"
+                },
+                "Suffix": {
+                    "default": "asl",
+                    "enum": [
+                        "asl",
+                        "m0scan"
+                    ],
+                    "title": "Suffix: after all entities and before the file extension",
+                    "type": "string"
                 }
             },
             "required": [
                 "Filename",
-                "Modality"
+                "Suffix"
             ]
         },
         "perf_tsv_file": {
             "description": "BIDS template for perfusion physio and stim files",
             "properties": {
                 "Acq": {
                     "$ref": "#/definitions/Acq"
@@ -557,34 +630,25 @@
                 "Custom": {
                     "$ref": "#/definitions/Custom"
                 },
                 "Dir": {
                     "$ref": "#/definitions/Dir"
                 },
                 "Filename": {
-                    "auto_update": "sub-{session.info.BIDS.Subject}[_ses-{session.info.BIDS.Label}]_task-{file.info.BIDS.Task}[_acq-{file.info.BIDS.Acq}][_rec-{file.info.BIDS.Rec}][_dir-{file.info.BIDS.Dir}][_run-{file.info.BIDS.Run}][_recording-{file.info.BIDS.Recording}]_{file.info.BIDS.Modality}{ext}",
+                    "auto_update": "sub-{session.info.BIDS.Subject}[_ses-{session.info.BIDS.Label}]_task-{file.info.BIDS.Task}[_acq-{file.info.BIDS.Acq}][_rec-{file.info.BIDS.Rec}][_dir-{file.info.BIDS.Dir}][_run-{file.info.BIDS.Run}][_recording-{file.info.BIDS.Recording}]_{file.info.BIDS.Suffix}{ext}",
                     "default": "",
                     "minLength": 1,
                     "title": "Filename",
                     "type": "string"
                 },
                 "Folder": {
                     "default": "perf",
                     "title": "Folder",
                     "type": "string"
                 },
-                "Modality": {
-                    "default": "NA",
-                    "enum": [
-                        "stim",
-                        "physio"
-                    ],
-                    "title": "Modality Label",
-                    "type": "string"
-                },
                 "Path": {
                     "auto_update": "sub-{session.info.BIDS.Subject}[/ses-{session.info.BIDS.Label}]/{file.info.BIDS.Folder}",
                     "default": "",
                     "title": "Path",
                     "type": "string"
                 },
                 "Rec": {
@@ -592,22 +656,31 @@
                 },
                 "Recording": {
                     "$ref": "#/definitions/Recording"
                 },
                 "Run": {
                     "$ref": "#/definitions/Run"
                 },
+                "Suffix": {
+                    "default": "NA",
+                    "enum": [
+                        "stim",
+                        "physio"
+                    ],
+                    "title": "Suffix: after all entities and before the file extension",
+                    "type": "string"
+                },
                 "Task": {
                     "$ref": "#/definitions/Task"
                 }
             },
             "required": [
                 "Filename",
                 "Task",
-                "Modality"
+                "Suffix"
             ]
         },
         "physio_task_file": {
             "description": "BIDS physio file template",
             "properties": {
                 "Acq": {
                     "$ref": "#/definitions/Acq"
@@ -621,34 +694,25 @@
                 "Dir": {
                     "$ref": "#/definitions/Dir"
                 },
                 "Echo": {
                     "$ref": "#/definitions/Echo"
                 },
                 "Filename": {
-                    "auto_update": "sub-{session.info.BIDS.Subject}[_ses-{session.info.BIDS.Label}]_task-{file.info.BIDS.Task}[_acq-{file.info.BIDS.Acq}][_ce-{file.info.BIDS.Ce}][_rec-{file.info.BIDS.Rec}][_dir-{file.info.BIDS.Dir}][_run-{file.info.BIDS.Run}][_echo-{file.info.BIDS.Echo}][_part-{file.info.BIDS.Part}][_recording-{file.info.BIDS.Recording}]_{file.info.BIDS.Modality}{ext}",
+                    "auto_update": "sub-{session.info.BIDS.Subject}[_ses-{session.info.BIDS.Label}]_task-{file.info.BIDS.Task}[_acq-{file.info.BIDS.Acq}][_ce-{file.info.BIDS.Ce}][_rec-{file.info.BIDS.Rec}][_dir-{file.info.BIDS.Dir}][_run-{file.info.BIDS.Run}][_echo-{file.info.BIDS.Echo}][_part-{file.info.BIDS.Part}][_recording-{file.info.BIDS.Recording}]_{file.info.BIDS.Suffix}{ext}",
                     "default": "",
                     "minLength": 1,
                     "title": "Filename",
                     "type": "string"
                 },
                 "Folder": {
                     "default": "func",
                     "title": "Folder",
                     "type": "string"
                 },
-                "Modality": {
-                    "default": "",
-                    "enum": [
-                        "stim",
-                        "physio"
-                    ],
-                    "title": "Modality Label",
-                    "type": "string"
-                },
                 "Part": {
                     "$ref": "#/definitions/Part"
                 },
                 "Path": {
                     "auto_update": "sub-{session.info.BIDS.Subject}[/ses-{session.info.BIDS.Label}]/{file.info.BIDS.Folder}",
                     "default": "",
                     "title": "Path",
@@ -659,72 +723,39 @@
                 },
                 "Recording": {
                     "$ref": "#/definitions/Recording"
                 },
                 "Run": {
                     "$ref": "#/definitions/Run"
                 },
+                "Suffix": {
+                    "default": "",
+                    "enum": [
+                        "stim",
+                        "physio"
+                    ],
+                    "title": "Suffix: after all entities and before the file extension",
+                    "type": "string"
+                },
                 "Task": {
                     "$ref": "#/definitions/Task"
                 }
             },
             "required": [
                 "Filename",
                 "Task",
-                "Modality"
+                "Suffix"
             ]
         },
         "project": {
-            "description": "BIDS project template, becomes dataset_description.json",
             "properties": {
-                "Acknowledgements": {
-                    "default": "",
-                    "title": "Acknowledgements",
-                    "type": "string"
-                },
-                "Authors": {
-                    "default": [],
-                    "title": "Authors",
-                    "type": "array"
-                },
-                "BIDSVersion": {
-                    "default": "1.6.0",
-                    "title": "BIDS Version",
+                "Sidecar": {
+                    "default": "data is in json sidecar, not file.info",
+                    "title": "Sidecar",
                     "type": "string"
-                },
-                "DatasetDOI": {
-                    "default": "",
-                    "title": "Dataset DOI",
-                    "type": "string"
-                },
-                "Funding": {
-                    "default": [],
-                    "title": "Funding Sources",
-                    "type": "array"
-                },
-                "HowToAcknowledge": {
-                    "default": "",
-                    "title": "How To Acknowledge",
-                    "type": "string"
-                },
-                "License": {
-                    "default": "",
-                    "title": "License",
-                    "type": "string"
-                },
-                "Name": {
-                    "auto_update": "{project.label}",
-                    "default": "",
-                    "title": "Name",
-                    "type": "string"
-                },
-                "ReferencesAndLinks": {
-                    "default": [],
-                    "title": "Reference and Links",
-                    "type": "array"
                 }
             },
             "required": []
         },
         "project_file": {
             "description": "BIDS project file template",
             "properties": {
@@ -733,15 +764,15 @@
                 },
                 "Folder": {
                     "default": "",
                     "title": "Folder",
                     "type": "string"
                 },
                 "Path": {
-                    "default": "",
+                    "default": ".",
                     "title": "Path",
                     "type": "string"
                 }
             },
             "required": [
                 "Filename"
             ]
@@ -847,90 +878,90 @@
             ]
         }
     },
     "description": "Namespace for BIDS info objects in Flywheel",
     "initializers": [
         {
             "initialize": {
-                "Modality": "phasediff"
+                "Suffix": "phasediff"
             },
             "rule": "reproin_fieldmap_file",
             "where": {
                 "acquisition.label": {
                     "$regex": "fmap(-|_)"
                 },
                 "file.name": {
-                    "$regex": "_e\\d+_ph\\.nii(\\.gz|)$"
+                    "$regex": "_e\\d+_ph\\.(nii(\\.gz|)|json)$"
                 }
             }
         },
         {
             "initialize": {
-                "Modality": "magnitude1"
+                "Suffix": "magnitude1"
             },
             "rule": "reproin_fieldmap_file",
             "where": {
                 "acquisition.label": {
                     "$regex": "fmap(-|_)"
                 },
                 "file.name": {
-                    "$regex": "_e1\\.nii(\\.gz|)$"
+                    "$regex": "_e1\\.(nii(\\.gz|)|json)$"
                 }
             }
         },
         {
             "initialize": {
-                "Modality": "magnitude2"
+                "Suffix": "magnitude2"
             },
             "rule": "reproin_fieldmap_file",
             "where": {
                 "acquisition.label": {
                     "$regex": "fmap(-|_)"
                 },
                 "file.name": {
-                    "$regex": "_e2\\.nii(\\.gz|)$"
+                    "$regex": "_e2\\.(nii(\\.gz|)|json)$"
                 }
             }
         },
         {
             "initialize": {
-                "Modality": "epi"
+                "Suffix": "epi"
             },
             "rule": "reproin_fieldmap_file",
             "where": {
                 "acquisition.label": {
                     "$regex": ".*fmap_.*_topup"
                 }
             }
         },
         {
             "initialize": {
-                "Modality": "magnitude"
+                "Suffix": "magnitude"
             },
             "rule": "reproin_fieldmap_file",
             "where": {
                 "acquisition.label": {
                     "$regex": "fmap-fieldmap"
                 },
                 "file.name": {
-                    "$regex": "\\.nii(\\.gz|)$"
+                    "$regex": "\\.(nii(\\.gz|)|json)$"
                 }
             }
         },
         {
             "initialize": {
-                "Modality": "fieldmap"
+                "Suffix": "fieldmap"
             },
             "rule": "reproin_fieldmap_file",
             "where": {
                 "acquisition.label": {
                     "$regex": "fmap-fieldmap"
                 },
                 "file.name": {
-                    "$regex": "fieldmap\\.nii(\\.gz|)$"
+                    "$regex": "fieldmap\\.(nii(\\.gz|)|json)$"
                 }
             }
         }
     ],
     "namespace": "BIDS",
     "resolvers": [
         {
@@ -950,22 +981,14 @@
             "id": "bids_project",
             "template": "project",
             "where": {
                 "container_type": "project"
             }
         },
         {
-            "id": "bids_project_file",
-            "template": "project_file",
-            "where": {
-                "container_type": "file",
-                "parent_container_type": "project"
-            }
-        },
-        {
             "id": "bids_session",
             "initialize": {
                 "ignore": {
                     "$switch": {
                         "$cases": [
                             {
                                 "$regex": "(^|.*_)ignore(-(BIDS|bids)).*$",
@@ -1014,29 +1037,34 @@
             },
             "template": "acquisition",
             "where": {
                 "container_type": "acquisition"
             }
         },
         {
-            "id": "dataset_description_json",
+            "id": "project_files",
             "initialize": {
                 "Filename": {
                     "file.name": {
                         "$take": true
                     }
                 }
             },
             "template": "project_file",
             "where": {
                 "container_type": "file",
+                "file.name": {
+                    "$regex": "^(dataset_description\\.json|README(\\.md|\\.rst|\\.txt|)|CHANGES|LICENSE|participants\\.(tsv|json)|samples\\.(tsv|json))$"
+                },
                 "file.type": {
                     "$in": [
                         "source code",
-                        "JSON"
+                        "tabular data",
+                        "JSON",
+                        "text"
                     ]
                 },
                 "parent_container_type": "project"
             }
         },
         {
             "id": "reproin_anat_file",
@@ -1057,42 +1085,48 @@
                     }
                 },
                 "Mod": {
                     "acquisition.label": {
                         "$regex": "(^|_)mod-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 },
-                "Modality": {
-                    "acquisition.label": {
-                        "$regex": ".*anat-(?P<value>.+?)(_|$)"
-                    }
-                },
                 "Part": {
                     "acquisition.label": {
                         "$regex": "(^|_)part-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 },
                 "Rec": {
                     "acquisition.label": {
                         "$regex": "(^|_)rec-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 },
                 "Run": {
                     "$run_counter": {
-                        "key": "anat"
+                        "key": "anat.{file.info.BIDS.Suffix}"
                     },
                     "acquisition.label": {
-                        "$regex": "(^|_)run-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
+                        "$regex": [
+                            "(^|_)run-(?P<value>\\d+)(_|$)",
+                            "(^|_)run-(?P<value>[=+])(_|$)"
+                        ]
+                    }
+                },
+                "Suffix": {
+                    "acquisition.label": {
+                        "$regex": [
+                            ".*anat-(?P<value>.+?)(_|$)",
+                            ".*anat_.*_(?P<value>.+?)$"
+                        ]
                     }
                 }
             },
             "template": "anat_file",
             "where": {
                 "acquisition.label": {
-                    "$regex": ".*(anat(-.+|$))"
+                    "$regex": ".*anat((-|_).+|$)"
                 },
                 "container_type": "file",
                 "file.classification.Intent": {
                     "$in": [
                         "Structural"
                     ]
                 },
@@ -1131,59 +1165,71 @@
                             {
                                 "$replace": {
                                     "$pattern": "^(\\d{1})$",
                                     "$replacement": "0\\1"
                                 }
                             }
                         ],
-                        "$regex": "^.*_e(?P<value>\\d+)\\.nii.*$"
-                    }
-                },
-                "Modality": {
-                    "$switch": {
-                        "$cases": [
-                            {
-                                "$regex": ".*_SBRef$|.*_sbref$",
-                                "$value": "sbref"
-                            }
-                        ],
-                        "$on": "acquisition.label"
-                    },
-                    "acquisition.label": {
-                        "$regex": ".*func-(?P<value>.+?)(_)"
+                        "$regex": "^.*_e(?P<value>\\d+)(\\.nii.*|\\.json)$"
                     }
                 },
                 "Part": {
                     "acquisition.label": {
                         "$regex": "(^|_)part-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 },
                 "Rec": {
                     "acquisition.label": {
                         "$regex": "(^|_)rec-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 },
                 "Run": {
                     "$run_counter": {
-                        "key": "functional.{file.info.BIDS.Task}"
+                        "key": "func.{file.info.BIDS.Task}.{file.info.BIDS.Suffix}.{file.type}"
                     },
                     "acquisition.label": {
-                        "$regex": "(^|_)run-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
+                        "$regex": [
+                            "(^|_)run-(?P<value>\\d+)(_|$)",
+                            "(^|_)run-(?P<value>[=+])(_|$)"
+                        ]
+                    }
+                },
+                "Suffix": {
+                    "$switch": {
+                        "$cases": [
+                            {
+                                "$regex": ".*_SBRef$|.*_sbref$",
+                                "$value": "sbref"
+                            },
+                            {
+                                "$regex": ".*_cbv$",
+                                "$value": "cbv"
+                            },
+                            {
+                                "$regex": ".*_phase$",
+                                "$value": "phase"
+                            },
+                            {
+                                "$default": true,
+                                "$value": "bold"
+                            }
+                        ],
+                        "$on": "acquisition.label"
                     }
                 },
                 "Task": {
                     "acquisition.label": {
                         "$regex": "(^|_)task-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 }
             },
             "template": "func_file",
             "where": {
                 "acquisition.label": {
-                    "$regex": "(?!.*PhysioLog.*).*(func(-.+|$))"
+                    "$regex": "(?!.*PhysioLog.*).*(func((-|_).+|$))"
                 },
                 "container_type": "file",
                 "file.classification.Intent": {
                     "$in": [
                         "Functional"
                     ]
                 },
@@ -1217,19 +1263,14 @@
                     }
                 },
                 "Echo": {
                     "acquisition.label": {
                         "$regex": "(^|_)echo-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 },
-                "Modality": {
-                    "acquisition.label": {
-                        "$regex": ".*func-(?P<value>.+?)(_)"
-                    }
-                },
                 "Part": {
                     "acquisition.label": {
                         "$regex": "(^|_)part-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 },
                 "Rec": {
                     "acquisition.label": {
@@ -1237,15 +1278,23 @@
                     }
                 },
                 "Run": {
                     "$run_counter": {
                         "key": "task_events.{file.info.BIDS.Task}"
                     },
                     "acquisition.label": {
-                        "$regex": "(^|_)run-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
+                        "$regex": [
+                            "(^|_)run-(?P<value>\\d+)(_|$)",
+                            "(^|_)run-(?P<value>[=+])(_|$)"
+                        ]
+                    }
+                },
+                "Suffix": {
+                    "acquisition.label": {
+                        "$regex": ".*func-(?P<value>.+?)(_)"
                     }
                 },
                 "Task": {
                     "acquisition.label": {
                         "$regex": "(^|_)task-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 }
@@ -1253,20 +1302,22 @@
             "template": "task_events_file",
             "where": {
                 "acquisition.label": {
                     "$regex": ".*(func(-.+|$))"
                 },
                 "container_type": "file",
                 "file.name": {
-                    "$regex": "events/.tsv"
+                    "$regex": "events\\.tsv$"
                 },
                 "file.type": {
                     "$in": [
                         "tabular data",
-                        "Tabular Data"
+                        "Tabular Data",
+                        "source code",
+                        "JSON"
                     ]
                 }
             }
         },
         {
             "id": "reproin_physio_file",
             "initialize": {
@@ -1286,15 +1337,14 @@
                     }
                 },
                 "Echo": {
                     "acquisition.label": {
                         "$regex": "(^|_)echo-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 },
-                "Modality": "physio",
                 "Part": {
                     "acquisition.label": {
                         "$regex": "(^|_)part-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 },
                 "Rec": {
                     "acquisition.label": {
@@ -1307,17 +1357,21 @@
                     }
                 },
                 "Run": {
                     "$run_counter": {
                         "key": "physio.{file.info.BIDS.Task}"
                     },
                     "acquisition.label": {
-                        "$regex": "(^|_)run-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
+                        "$regex": [
+                            "(^|_)run-(?P<value>\\d+)(_|$)",
+                            "(^|_)run-(?P<value>[=+])(_|$)"
+                        ]
                     }
                 },
+                "Suffix": "physio",
                 "Task": {
                     "acquisition.label": {
                         "$regex": "(^|_)task-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 }
             },
             "template": "physio_task_file",
@@ -1341,41 +1395,44 @@
                     }
                 },
                 "Dir": {
                     "acquisition.label": {
                         "$regex": "(^|_)dir-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 },
-                "Modality": {
+                "Part": {
+                    "acquisition.label": {
+                        "$regex": "(^|_)part-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
+                    }
+                },
+                "Run": {
+                    "$run_counter": {
+                        "key": "dwi.{file.info.BIDS.Suffix}"
+                    },
+                    "acquisition.label": {
+                        "$regex": [
+                            "(^|_)run-(?P<value>\\d+)(_|$)",
+                            "(^|_)run-(?P<value>[=+])(_|$)"
+                        ]
+                    }
+                },
+                "Suffix": {
                     "$switch": {
                         "$cases": [
                             {
                                 "$regex": ".*_SBRef$|.*_sbref$",
                                 "$value": "sbref"
                             },
                             {
                                 "$default": true,
                                 "$value": "dwi"
                             }
                         ],
                         "$on": "acquisition.label"
                     }
-                },
-                "Part": {
-                    "acquisition.label": {
-                        "$regex": "(^|_)part-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
-                    }
-                },
-                "Run": {
-                    "$run_counter": {
-                        "key": "diffusion"
-                    },
-                    "acquisition.label": {
-                        "$regex": "(^|_)run-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
-                    }
                 }
             },
             "template": "diffusion_file",
             "where": {
                 "$or": [
                     {
                         "$and": {
@@ -1443,30 +1500,33 @@
                     }
                 },
                 "Dir": {
                     "acquisition.label": {
                         "$regex": "(^|_)dir-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 },
-                "Modality": {
-                    "acquisition.label": {
-                        "$regex": ".*fmap-(?P<value>.*?)(_|$)"
-                    }
-                },
                 "Part": {
                     "acquisition.label": {
                         "$regex": "(^|_)part-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 },
                 "Run": {
                     "$run_counter": {
-                        "key": "field_map{file.info.BIDS.Modality}"
+                        "key": "field_map.{file.info.BIDS.Suffix}"
                     },
                     "acquisition.label": {
-                        "$regex": "(^|_)run-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
+                        "$regex": [
+                            "(^|_)run-(?P<value>\\d+)(_|$)",
+                            "(^|_)run-(?P<value>[=+])(_|$)"
+                        ]
+                    }
+                },
+                "Suffix": {
+                    "acquisition.label": {
+                        "$regex": ".*fmap-(?P<value>.*?)(_|$)"
                     }
                 }
             },
             "template": "fieldmap_file",
             "where": {
                 "acquisition.label": {
                     "$regex": ".*fmap(-|_)"
@@ -1476,15 +1536,17 @@
                     "$in": [
                         "Fieldmap"
                     ]
                 },
                 "file.type": {
                     "$in": [
                         "nifti",
-                        "NIfTI"
+                        "NIfTI",
+                        "source code",
+                        "JSON"
                     ]
                 },
                 "parent_container_type": "acquisition"
             }
         },
         {
             "id": "bids_dicom_file",
@@ -1522,40 +1584,43 @@
                     }
                 },
                 "Dir": {
                     "acquisition.label": {
                         "$regex": "(^|_)dir-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 },
-                "Modality": {
+                "Rec": {
+                    "acquisition.label": {
+                        "$regex": "(^|_)rec-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
+                    }
+                },
+                "Run": {
+                    "$run_counter": {
+                        "key": "perfusion.{file.info.BIDS.Suffix}"
+                    },
+                    "acquisition.label": {
+                        "$regex": [
+                            "(^|_)run-(?P<value>\\d+)(_|$)",
+                            "(^|_)run-(?P<value>[=+])(_|$)"
+                        ]
+                    }
+                },
+                "Suffix": {
                     "$switch": {
                         "$cases": [
                             {
                                 "$regex": ".*_m0scan$",
                                 "$value": "m0scan"
                             }
                         ],
                         "$on": "acquisition.label"
                     },
                     "acquisition.label": {
                         "$regex": ".*perf-(?P<value>.+?)(_)"
                     }
-                },
-                "Rec": {
-                    "acquisition.label": {
-                        "$regex": "(^|_)rec-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
-                    }
-                },
-                "Run": {
-                    "$run_counter": {
-                        "key": "perfusion.{file.info.BIDS.Run}"
-                    },
-                    "acquisition.label": {
-                        "$regex": "(^|_)run-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
-                    }
                 }
             },
             "template": "perf_file",
             "where": {
                 "acquisition.label": {
                     "$regex": "(?!.*PhysioLog.*).*(perf(-.+|$))"
                 },
@@ -1585,30 +1650,33 @@
                     }
                 },
                 "Dir": {
                     "acquisition.label": {
                         "$regex": "(^|_)dir-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 },
-                "Modality": {
-                    "acquisition.label": {
-                        "$regex": "(.*physio|.*stim)(?P<value>.+?)(_|$)"
-                    }
-                },
                 "Rec": {
                     "acquisition.label": {
                         "$regex": "(^|_)rec-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 },
                 "Run": {
                     "$run_counter": {
-                        "key": "perfusion.{file.info.BIDS.Run}"
+                        "key": "perfusion.{file.info.BIDS.Suffix}"
                     },
                     "acquisition.label": {
-                        "$regex": "(^|_)run-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
+                        "$regex": [
+                            "(^|_)run-(?P<value>\\d+)(_|$)",
+                            "(^|_)run-(?P<value>[=+])(_|$)"
+                        ]
+                    }
+                },
+                "Suffix": {
+                    "acquisition.label": {
+                        "$regex": "(.*physio|.*stim)(?P<value>.+?)(_|$)"
                     }
                 },
                 "Task": {
                     "acquisition.label": {
                         "$regex": "(^|_)task-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 }
@@ -1618,15 +1686,17 @@
                 "container_type": "file",
                 "file.name": {
                     "$regex": ".*physio\\.tsv[.gz]|.*physio\\.json|.*stim\\.tsv[.gz]|.*stim\\.json$"
                 },
                 "file.type": {
                     "$in": [
                         "tabular data",
-                        "Tabular Data"
+                        "Tabular Data",
+                        "source code",
+                        "JSON"
                     ]
                 }
             }
         },
         {
             "id": "reproin_perf_context_file",
             "initialize": {
@@ -1636,42 +1706,47 @@
                     }
                 },
                 "Dir": {
                     "acquisition.label": {
                         "$regex": "(^|_)dir-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 },
-                "Modality": {
-                    "acquisition.label": {
-                        "$regex": ".*aslcontext(?P<value>.+?)(_|$)"
-                    }
-                },
                 "Rec": {
                     "acquisition.label": {
                         "$regex": "(^|_)rec-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
                     }
                 },
                 "Run": {
                     "$run_counter": {
-                        "key": "perfusion.{file.info.BIDS.Run}"
+                        "key": "perfusion.{file.info.BIDS.Suffix}"
                     },
                     "acquisition.label": {
-                        "$regex": "(^|_)run-(?P<value>.*?)(_(acq|ce|dir|echo|mod|proc|part|rec|recording|run|task)-|$|_)"
+                        "$regex": [
+                            "(^|_)run-(?P<value>\\d+)(_|$)",
+                            "(^|_)run-(?P<value>[=+])(_|$)"
+                        ]
+                    }
+                },
+                "Suffix": {
+                    "acquisition.label": {
+                        "$regex": ".*aslcontext(?P<value>.+?)(_|$)"
                     }
                 }
             },
             "template": "perf_context_file",
             "where": {
                 "container_type": "file",
                 "file.name": {
                     "$regex": ".*aslcontext\\.tsv|.*aslcontext\\.json$"
                 },
                 "file.type": {
                     "$in": [
                         "tabular data",
-                        "Tabular Data"
+                        "Tabular Data",
+                        "source code",
+                        "JSON"
                     ]
                 }
             }
         }
     ]
 }
```

## flywheel_bids/upload_bids.py

```diff
@@ -6,16 +6,16 @@
 import re
 import shutil
 import sys
 
 import flywheel
 from six.moves import reduce
 
-from flywheel_bids.supporting_files import bidsify_flywheel, classifications, utils
-from flywheel_bids.supporting_files.templates import load_template, Template
+from .supporting_files import bidsify_flywheel, classifications, utils
+from .supporting_files.templates import Template, load_template
 
 SECONDS_PER_YEAR = 86400 * 365.25
 
 logging.basicConfig(level=logging.INFO)
 logger = logging.getLogger("bids-uploader")
 
 
@@ -576,28 +576,22 @@
     """
     # Get all sessions
     existing_acquisitions = fw.get_session_acquisitions(session_id)
     # Determine if acquisition_label within project project_id already exists
     found = False
     for ea in existing_acquisitions:
         if ea["label"] == acquisition_label:
-            logger.info(
-                f"Acquisition %s was found. Adding data to existing acquisition."
-                % acquisition_label
-            )
+            logger.info(f"Acquisition {acquisition_label} was found. Adding data to existing acquisition.")
             # Acquisition exists
             acquisition = ea
             found = True
             break
     # If acquisition does not exist, create new session
     if not found:
-        logger.info(
-            f"Acquisition %s not found. Creating new acquisition for session %s."
-            % (acquisition_label, session_id)
-        )
+        logger.info(f"Acquisition {acquisition_label} not found. Creating new acquisition for session {session_id}.")
         acquisition_id = fw.add_acquisition(
             {"label": acquisition_label, "session": session_id}
         )
         acquisition = fw.get_acquisition(acquisition_id)
 
     # In either case, check if there is BIDS information
     if not hasattr(acquisition["info"], "BIDS"):
@@ -612,62 +606,126 @@
                 }
             }
         )
 
     return acquisition.to_dict()
 
 
-def handle_project(fw, group_id, project_label, assume_upload: bool = False):
+def handle_project(
+    fw,
+    group_id,
+    project_label,
+    template,
+    template_is_old,
+    save_sidecar_as_metadata,
+    assume_upload: bool = False,
+):
     """
     Retrieve or create a project from/on Flywheel.
 
     :param fw: Flywheel client
     :param str group_id: Flywheel identifier
     :param str project_label: Flywheel identifier for the name of the project
+    :param Template template: BIDS Project template
+    :param bool template_is_old: BIDS Project curation template wants to put dataset_description data in project.info.BIDS
+    :param bool save_sidecar_as_metadata: Save dataset_description.json data in project.info.BIDS
     :param bool assume_upload: Should the container be uploaded?
     :return dict project: dictionary detailing a Flywheel project based
                         on group_id and project_label
     """
 
     # Get all projects
     # TODO: Is there a more specific finder method?
     existing_projs = fw.get_all_projects()
     # Determine if project_label with group_id already exists
     found = False
     for ep in existing_projs:
         if (ep["label"] == project_label) and (ep["group"] == group_id):
-            logger.info(
-                f"Project %s was found. Adding data to existing project."
-                % project_label
-            )
+            logger.info(f"Project {project_label} was found. Adding data to existing project.")
             # project exists
             project = ep
             found = True
             if check_enabled_rules(fw, project.to_dict()["id"]):
                 logger.warning(
                     "Project has enabled rules, these may overwrite BIDS data. Either disable rules or run bids curation gear after data is uploaded."
                 )
                 if not assume_upload and not utils.confirmation_prompt(
                     "Continue upload?"
                 ):
                     return
             break
-    # If project does not exist, create project
-    if not found:
-        logger.info(
-            f"Project %s not found. Creating new project for group %s."
-            % (project_label, group_id)
-        )
+
+    if found:  # an existing project should stay the way it is
+        if "BIDS" in project.info and "Acknowledgements" in project.info["BIDS"]:
+            # then project is storing sidecar in metadata on the project and all NIfTI files should
+            # have sidecar data in file.info, and project.info.BIDS should not be modified.
+            if not save_sidecar_as_metadata:
+                save_sidecar_as_metadata = True
+                logger.warning(
+                    "The argument save_sidecar_as_metadata was passed in as False, "
+                    "but dataset_description.json information was detected in project.info.BIDS "
+                    "so save_sidecar_as_metadata has been changed to True because this "
+                    "project already is saving sidecar data in metadata.  All NIfTI files "
+                    "should have sidecar data in file.info and any real json sidecars will be "
+                    "ignored."
+                )
+
+            # Don't replace project.info.BIDS with what is in the template
+            if "properties" in template["project"]["definitions"]:
+                del template["project"]["definitions"]["properties"]
+
+        # Otherwise, dataset_description.json should be a file attached to the project, its data is not
+        # stored in project.info.BIDS, and all NIfTI files should have real json sidecars.
+        else:
+            if save_sidecar_as_metadata:
+                raise ValueError(
+                    "The argument save_sidecar_as_metadata has been passed in as True "
+                    "but there is no dataset_description data in project.info.BIDS.  "
+                    "Either save_sidecar_as_metadata should be False (the default), or "
+                    "the project should be curated for BIDS with save_sidecar_as_metadata set "
+                    "to True."
+                )
+            else:  # save_sidecar_as_metadata is False, which is good, but check the template
+                if template_is_old:
+                    raise ValueError(
+                        "The BIDS Project Curation template is old and expects to "
+                        "put dataset_description.json data in project.info.BIDS but "
+                        "this existing project has not yet been curated with sidecar data in "
+                        "project.info.BIDS and with sidecar data in file.info for NIfTI files.  "
+                        "Either the project should be curated with save_sidecar_as_metadata True "
+                        "or a new template should be used"
+                    )
+
+    else:
+        # for a new project, save_sidecar_as_metadata and the provided template determine if sidecar data
+        # should be in metadata or in real sidecars.
+        if (
+            save_sidecar_as_metadata and not template_is_old
+        ):  # make the new template save sidecar data in metadata
+            template.definitions["project"] = template.definitions[
+                "data_description_file"
+            ]
+
+        if not save_sidecar_as_metadata and template_is_old:
+            raise ValueError(
+                "An old template is being used which will put data_description.json data into "
+                "project.info.BIDS and NIfTI sidecar data in file.info, but save_sidecar_as_metadata"
+                "is False (the default). Either a new template should be used or save_sidecar_as_metadata"
+                "should be passed in as True."
+            )
+
+        logger.info(f"Project {project_label} not found. Creating new project for group {group_id}.")
+
         project_id = fw.add_project(
             {"label": project_label, "group": group_id}, inherit=True
         )
         project = fw.get_project(project_id)
         disable_project_rules(fw, project_id)
 
-    return project.to_dict()
+    return project.to_dict(), save_sidecar_as_metadata
 
 
 def handle_session(fw, project_id, session_name, subject_name):
     """
         Retrieve or create a session from/on Flywheel.
 
     :param fw: Flywheel client
@@ -681,28 +739,23 @@
     """
     # Get all sessions
     existing_sessions = fw.get_project_sessions(project_id)
     # Determine if session_name within project project_id already exists, with same subject_name...
     found = False
     for es in existing_sessions:
         if (es["label"] == session_name) and (es["subject"]["code"] == subject_name):
-            logger.info(
-                f"Session %s for subject %s was found. Adding data to existing session."
-                % (session_name, subject_name)
-            )
+            logger.info(f"Session {session_name} for subject {subject_name} was found. Adding data to existing session.")
             # Session exists
             session = es
             found = True
             break
     # If session does not exist, create new session
     if not found:
-        logger.info(
-            f"Session %s not found. Creating new session for project %s."
-            % (session_name, project_id)
-        )
+        logger.info(f"Session {session_name} not found. Creating new session for project {project_id}.")
+
 
         session_id = fw.add_session(
             {
                 "label": session_name,
                 "project": project_id,
                 "subject": {"code": subject_name},
                 "info": {
@@ -723,27 +776,22 @@
     """Returns a Flywheel subject based on project_id and subject_code"""
     # Get all subjects
     existing_subjects = fw.get_project_subjects(project_id)
     # Determine if subject_name within project project_id already exists, with same subject_name...
     found = False
     for es in existing_subjects:
         if es["code"] == subject_code:
-            logger.info(
-                f"Subject %s was found. Adding data to existing subject." % subject_code
-            )
+            logger.info(f"Subject {subject_code} was found. Adding data to existing subject.")
             # Session exists
             subject = es
             found = True
             break
     # If subject does not exist, create new subject
     if not found:
-        logger.info(
-            f"Subject %s not found. Creating new subject for %s."
-            % (subject_code, project_id)
-        )
+        logger.info(f"Subject {subject_code} not found. Creating new subject for {project_id}.")
 
         subject_id = fw.add_subject(
             {"code": subject_code, "label": subject_code, "project": project_id}
         )
         subject = fw.get_subject(subject_id)
 
     return subject.to_dict()
@@ -940,15 +988,15 @@
                     bc_context["parent_container_type"] = "acquisition"
                     bc_context["ext"] = utils.get_extension(fname)
                     # Identify the templates for the file and return file object
                     bc_context["file"] = bidsify_flywheel.process_matching_templates(
                         bc_context, template, upload=True
                     )
                     # Check that the file matched a template
-                    if bc_context["file"].get("info") and not ".json" in fname:
+                    if bc_context["file"].get("info") and ".json" not in fname:
                         # Update the meta info files w/ BIDS info from the filename and foldername...
                         meta_info = fill_in_properties(
                             bc_context, full_path, local_properties
                         )
                         # Upload the meta info onto the project file
                         fw.set_acquisition_file_info(
                             bc_context["acquisition"]["id"], fname, meta_info
@@ -1252,31 +1300,32 @@
     group_id: str,
     rootdir: os.PathLike,
     hierarchy_type: str,
     template: Template,
     local_properties: bool,
     assume_upload: bool,
     overwrite: bool,
+    save_sidecar_as_metadata: bool,
 ):
     """
 
     :param fw: Flywheel client
     :param dict bids_hierarchy: BIDS hierarchy represented as a nested dict
     :param str rootdir: path to files
     :param hierarchy_type: either 'Flywheel' or 'BIDS'
             if 'Flywheel', the base filename is used as the acquisition label
             if 'BIDS', the BIDS foldername (anat,func,dwi etc...) is used as the acquisition label
     :param bool local_properties: from CLI (--use_template_defaults),
             prioritize template default values for BIDS information
     :param bool assume_upload: from CLI (--yes). Assume yes to prompts, which
             effectively is yes to uploading files
     :param bool overwrite: overwrite existing files
+    :param bool save_sidecar_as_metadata: save sidecar as metadata
     :return list files_for_special_handling: filtered list of files that need to be uploaded,
             but require special handling
-
     """
 
     # Iterate
     # Initialize BIDS-client context (bc_context) object
     bc_context = {
         "container_type": None,
         "parent_container_type": None,
@@ -1287,25 +1336,46 @@
         "file": None,
         "ext": None,
     }
 
     # Collect files to be parsed at the end
     files_for_special_handling = {}
 
+    if (
+        "project" in template.definitions
+        and "Acknowledgements" in template.definitions["project"]
+    ):
+        # dataset_description.json data is in project.info.BIDS, sidecar data should be in
+        # file.info.BIDS for all NIfTI files, and json sidecar files should be ignored
+        template_is_old = True
+    else:
+        # dataset_description.json is a file attached to the project, json sidecars
+        # should exist for all NIfTI files, no sidecar data should be in file.info,
+        # and DICOM headers are in file.info.header.dicom on NIfTI files (the new way)
+        template_is_old = False
+
     # Iterate over BIDS hierarchy (first key will be top level dirname
     # which we will use as the project label)
     for proj_label in bids_hierarchy:
         ## Validate the project
         #   (1) create a project OR
         #   (2) find an existing project by the project_label
         #   -- return project object
         bc_context["container_type"] = "project"
-        bc_context["project"] = handle_project(fw, group_id, proj_label, assume_upload)
+        bc_context["project"], save_sidecar_as_metadata = handle_project(
+            fw,
+            group_id,
+            proj_label,
+            template_is_old,
+            save_sidecar_as_metadata,
+            assume_upload,
+        )
         if bc_context["project"] is None:
             continue
+
         # NOTE: template is the default.json file
         bc_context["project"] = bidsify_flywheel.process_matching_templates(
             bc_context, template, upload=True
         )
         fw.modify_project(
             bc_context["project"]["id"],
             {"info": {"BIDS": bc_context["project"]["info"]["BIDS"]}},
@@ -1533,30 +1603,29 @@
         session_label,
     )
 
     # Determine if hierarchy is valid BIDS
     if validate:
         utils.validate_bids(rootdir)
 
-    template = load_template(
-        fw, template_path, template_name, save_sidecar_as_metadata=False
-    )
+    template = load_template(template_path, template_name, save_sidecar_as_metadata)
 
     ### Upload BIDS directory
     # upload bids dir (and get files of interest and project id)
     files_for_special_handling = upload_bids_dir(
         fw,
         bids_hierarchy,
         group_id,
         rootdir,
         hierarchy_type,
         template,
         local_properties,
         assume_upload,
         overwrite,
+        save_sidecar_as_metadata,
     )
 
     # Parse the BIDS meta files
     #    data_description.json, participants.tsv, *_sessions.tsv, *_scans.tsv
     parse_meta_files(
         fw,
         files_for_special_handling,
```

## Comparing `flywheel_bids/utils/download_run_level.py` & `flywheel_bids/flywheel_bids_app_toolkit/utils/query_flywheel.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,24 +1,26 @@
 #!/usr/bin/env python3
 """A robust template for accessing BIDS formatted data."""
 
 import json
 import logging
 import os.path as op
 import shutil
+import sys
 from glob import glob
 from pathlib import Path
+from typing import Any, List, Tuple, Union
 
 from flywheel import ApiException
+from flywheel_gear_toolkit import GearToolkitContext
 
-from flywheel_bids.export_bids import download_bids_dir
-from flywheel_bids.supporting_files.errors import BIDSExportError
-
-from .tree import tree_bids
-from .validate import validate_bids
+from ...export_bids import download_bids_dir
+from ...supporting_files.errors import BIDSExportError
+from ...utils.validate import validate_bids
+from ...flywheel_bids_app_toolkit.utils.tree import tree_bids
 
 log = logging.getLogger(__name__)
 
 DATASET_DESCRIPTION = {
     "Acknowledgements": "",
     "Authors": [],
     "BIDSVersion": "1.2.0",
@@ -28,14 +30,119 @@
     "License": "",
     "Name": "tome",
     "ReferencesAndLinks": [],
     "template": "project",
 }
 
 
+def copy_bidsignore_file(
+    bids_path: Union[Path, str],
+    bidsignore_file: Union[Path, str] = None,
+    input_dir: Union[Path, str] = "/flywheel/v0/input",
+):
+    """Create the bidsignore file once the bids_path is known.
+
+    bidsignore file will be at the top level of a project, if it exists.
+    The file will be downloaded with `orchestrate_download_bids`; thus, a
+    project-level bidsignore file is most likely in /flywheel/v0/work/bids.
+    A specific .bidsignore entered in the config UI will land in
+    /flywheel/v0/input and needs to be moved.
+
+    Args:
+        bids_path (Path): download path to the BIDS directory
+        input_dir (Path): Most often /flywheel/v0/input
+
+    Returns:
+        None
+    """
+    if bidsignore_file:
+        shutil.copy(str(bidsignore_file), str(bids_path / ".bidsignore"))
+    else:
+        log.info("Searching for bidsignore files")
+        bidsignore_list = list(Path(input_dir).rglob("*bidsignore"))
+        if len(bidsignore_list) > 0:
+            bidsignore_path = str(bidsignore_list[0])
+            if bidsignore_path:
+                shutil.copy(bidsignore_path, str(bids_path / ".bidsignore"))
+
+
+def download_bids_data_for_run_level(
+    gtk_context: GearToolkitContext,
+    run_level: str,
+    hierarchy,
+    folders: List[str],
+    src_data,
+    dry_run: bool,
+    do_validate_bids: bool = False,
+):
+    """
+    Download BIDS data as directed by run_level.
+
+    Args:
+        gtk_context (gear_toolkit.GearToolkitContext): flywheel gear context
+        run_level
+        hierarchy (dict): containing the run_level and labels for the
+            run_label, group, project, subject, session, and
+            acquisition.
+
+
+    """
+    bids_dir = Path(gtk_context.work_dir) / "bids"
+    err_code = None
+
+    if run_level in ["project", "subject", "session"]:
+        log.info(
+            'Downloading BIDS for %s "%s"',
+            hierarchy["run_level"],
+            hierarchy["run_label"],
+        )
+        existing_dirs, reqd_dirs = list_existing_dirs(bids_dir, folders=folders)
+
+        if len(existing_dirs) >= len(reqd_dirs):
+            bids_path = bids_dir
+        else:
+            missing_dirs = list(set(reqd_dirs) - set(existing_dirs))
+            subjects = [
+                v for k, v in hierarchy.items() if "subject" in k and v is not None
+            ]
+            sessions = [
+                v for k, v in hierarchy.items() if "session" in k and v is not None
+            ]
+
+            bids_path = gtk_context.download_project_bids(
+                src_data=src_data,
+                folders=missing_dirs,
+                dry_run=dry_run,
+                subjects=subjects,
+                sessions=sessions,
+            )
+    elif run_level == "acquisition":
+        if hierarchy["acquisition_label"] == "unknown acquisition":
+            bids_path = None
+            err_code = 23
+        else:
+            bids_path = bids_dir
+            if not Path(bids_dir).exists():
+                download_bids_dir(
+                    gtk_context.client,
+                    gtk_context.destination["id"],
+                    "acquisition",
+                    bids_dir,
+                    src_data=src_data,
+                    folders=folders,
+                    dry_run=dry_run,
+                    validation_requested=do_validate_bids,
+                )
+    else:
+        bids_path = None
+        err_code = 20
+
+    return bids_path, err_code
+
+
 def fix_dataset_description(bids_path):
     """Make sure dataset_description.json exists and that "Funding" is a list.
 
     If these are not true, BIDS validation will fail.
 
     The flywheel bids template had (or has, unless it has been fixed), the
     default dataset_description.json file with "Funding" as an empty string.
@@ -51,65 +158,177 @@
 
     Note:
         If dataset_description.json does not exist, it will be created
     """
 
     validator_file = bids_path / "dataset_description.json"
 
-    need_to_write = False
-
     if validator_file.exists():
-
         with open(validator_file) as json_file:
-
             data = json.load(json_file)
 
-            log.info("type of Funding is: %s", str(type(data["Funding"])))
-
-            if not isinstance(data["Funding"], list):
-
+            if isinstance(data.get("Funding"), list):
+                return
+            else:
                 log.warning('data["Funding"] is not a list')
-                data["Funding"] = list(data["Funding"])
+                data["Funding"] = [data.get("Funding", None)]
                 log.info("changed it to: %s", str(type(data["Funding"])))
 
-                need_to_write = True
-
     else:
         log.info("Creating default dataset_description.json file")
         data = DATASET_DESCRIPTION
-        need_to_write = True
 
-    if need_to_write:
-        with open(validator_file, "w") as outfile:
-            json.dump(data, outfile)
+    with open(validator_file, "w") as outfile:
+        json.dump(data, outfile)
 
 
-def download_bids_for_runlevel(
-    gtk_context,
-    hierarchy,
-    tree=False,
-    tree_title=None,
-    src_data=False,
-    folders=[],
-    dry_run=False,
-    do_validate_bids=True,
+def get_analysis_run_level_and_hierarchy(fw, destination_id):
+    """Determine the level at which a job is running, given a destination
+
+    Args:
+        fw (gear_toolkit.GearToolkitContext.client): flywheel client
+        destination_id (id): id of the destination of the gear
+
+    Returns:
+        hierarchy (dict): containing the run_level and labels for the
+            run_label, group, project, subject, session, and
+            acquisition.
+    """
+
+    hierarchy = {
+        "run_level": "no_destination",
+        "run_label": "unknown",
+        "group": None,
+        "project_label": None,
+        "subject_label": None,
+        "session_label": None,
+        "acquisition_label": None,
+    }
+
+    try:
+        destination = fw.get(destination_id)
+
+        if destination.container_type != "analysis":
+            log.error("The destination_id must reference an analysis container.")
+
+        else:
+            hierarchy["run_level"] = destination.parent.type
+            hierarchy["group"] = destination.parents["group"]
+
+            for level in ["project", "subject", "session", "acquisition"]:
+                if destination.parents[level]:
+                    container = fw.get(destination.parents[level])
+                    hierarchy[f"{level}_label"] = container.label
+
+                    if hierarchy["run_level"] == level:
+                        hierarchy["run_label"] = container.label
+
+    except ApiException as err:
+        log.error(
+            f"The destination_id does not reference a valid analysis container.\n{err}"
+        )
+
+    log.info(f"Gear run level and hierarchy labels: {hierarchy}")
+
+    return hierarchy
+
+
+def get_fw_details(gear_context: GearToolkitContext) -> Tuple[Any, Any, str]:
+    """
+    Information about the gear and current run, mostly for reporting.
+    :param gear_context:
+    :return:
+        destination: FW identifier
+        gear_builder_info: Gear builder blob from the manifest
+        container: Basically, the last part of the Docker image
+    """
+    destination = gear_context.client.get(gear_context.destination["id"])
+    if destination.parent.type == "project":
+        log.exception(
+            "This version of the gear does not run at the project level. "
+            "Try running it for each individual subject."
+        )
+        sys.exit(1)
+    gear_builder_info = gear_context.manifest.get("custom").get("gear-builder")
+    # gear_builder_info.get("image") should be something like:
+    # flywheel/bids-qsiprep:0.0.1_0.15.1
+    container = gear_builder_info.get("image").split(":")[0]
+
+    return destination, gear_builder_info, container
+
+
+def list_existing_dirs(bids_dir, folders=["anat", "func", "dwi", "fmap", "perf"]):
+    """
+    Find the existing folders in the BIDS working directory to insure that all
+    associated files are downloaded, but extra re-downloading is avoided.
+    Args:
+        bids_dir (path): The BIDS working directory
+        folders (list): the subset of folders to be included in the download
+
+    Returns:
+        existing_dirs  (list): updated list to pass to download_bids_dir to limit re-download
+        check_dirs (list): Any directories matching the required directory labels.
+    """
+
+    reqd_dirs = list_reqd_folders(folders)
+    existing_dirs = []
+    existing_paths = []
+    for rd in reqd_dirs:
+        if glob(op.join(bids_dir, "**", rd), recursive=True):
+            existing_paths.append(glob(op.join(bids_dir, "**", rd), recursive=True))
+            # Add to the exclusion list, so the data is not re-downloaded
+            existing_dirs.append(rd)
+    existing_dirs = list(set(existing_dirs))
+    return existing_dirs, reqd_dirs
+
+
+def list_reqd_folders(folders=["anat", "func", "dwi", "fmap", "perf"]):
+    """
+    Produce the complete list of folders that are required to be present
+    for a BIDS analysis. This method is implemented specifically to avoid
+    incomplete downloads.
+    Args:
+        folders (list): the subset of folders to be included in the download
+
+    Returns:
+        final_set (list): the set of folders that must be downloaded to produce
+        the analysis.
+    """
+    std_set = ["anat", "func", "dwi", "fmap", "perf"]
+    if not folders:
+        final_set = std_set
+    else:
+        final_set = [x for x in std_set if x in folders]
+
+    return final_set
+
+
+def orchestrate_download_bids(
+    gtk_context: GearToolkitContext,
+    hierarchy: dict,
+    tree: bool = False,
+    tree_title: str = None,
+    src_data: bool = False,
+    folders: list = [],
+    download_data: bool = False,
+    do_validate_bids=False,
 ):
     """Figure out run level, download BIDS, validate BIDS, tree work/bids.
 
     Args:
         gtk_context (gear_toolkit.GearToolkitContext): flywheel gear context
         hierarchy (dict): containing the run_level and labels for the
             run_label, group, project, subject, session, and
             acquisition.
         tree (boolean): create HTML page in output showing 'tree' of bids data
         tree_title (str): Title to put in HTML file that shows the tree
         src_data (boolean): download source data (dicoms) as well
         folders (list): only include the listed folders, if empty include all
-        dry_run (boolean): don't actually download data if True
-        do_validate_bids (boolean): run bids-validator after downloading bids data
+        download_data (boolean): don't actually download data if True
+        do_validate_bids (boolean): [deprecated] run bids-validator after downloading BIDS data
 
     Returns:
         err_code (int): tells a bit about the error:
             0    - no error
             1..9 - error code returned by bids validator
             10   - BIDS validation errors were detected
             11   - the validator could not be run
@@ -123,274 +342,95 @@
             26   - no BIDS data was downloaded
 
     Note: information on BIDS "folders" (used to limit what is downloaded)
     can be found at https://bids-specification.readthedocs.io/en/stable/99-appendices/04-entity-table.html.
     """
 
     extra_tree_text = ""  # Text to be added to the end of the tree HTML file
-
     run_level = hierarchy["run_level"]
 
     # Show the complete destination hierarchy in the tree html output for clarity
     extra_tree_text += f"run_level is {run_level}\n"
     for key, val in hierarchy.items():
         extra_tree_text += f"  {key:<18}: {val}\n"
     extra_tree_text += f'  {"folders":<18}: {folders}\n'
     if src_data:
         extra_tree_text += f'  {"source data?":<18}: downloaded\n'
     else:
         extra_tree_text += f'  {"source data?":<18}: not downloaded\n'
-    if dry_run:
+    if download_data:
         extra_tree_text += f'  {"dry run?":<18}: Yes\n'
     else:
         extra_tree_text += f'  {"dry run?":<18}: No\n'
     extra_tree_text += "\n"
 
     err_code = 0  # assume no error
 
     if run_level == "no_destination":
         msg = "Destination does not exist."
         log.critical(msg)
         extra_tree_text += f"ERROR: {msg}\n"
         bids_path = None
         err_code = 24  # destination does not exist
-
     else:
-
-        # The destination is usually an analysis.  If not, say what's going on
-        if gtk_context.destination["type"] == "analysis":
-            pass
-
-        elif gtk_context.destination["type"] == "acquisition":
-            log.info("Destination is acquisition, changing run_level to " "acquisition")
+        if gtk_context.destination["type"] == "acquisition":
+            log.info("Destination is acquisition, changing run_level to 'acquisition'")
             acquisition = gtk_context.client.get_acquisition(
                 gtk_context.destination["id"]
             )
             hierarchy["acquisition_label"] = acquisition.label
             extra_tree_text += (
                 f'  {"acquisition_label":<18}: changed to ' + f"{acquisition.label}\n\n"
             )
             run_level = "acquisition"
 
-        else:
-            log.info(
-                'The destination "%s" is not an analysis or acquisition.',
-                gtk_context.destination["type"],
+        try:
+            bids_path, err_code = download_bids_data_for_run_level(
+                gtk_context,
+                run_level,
+                hierarchy,
+                folders,
+                src_data,
+                download_data,
+                do_validate_bids,
             )
-
-        try:  # download BIDS data for the proper run level
-
-            if src_data:
-                log.info("Downloading source data.")
-            else:
-                log.info("Not downloading source data.")
-
-            if dry_run:
-                log.info("Dry run is set.  No data will be downloaded.")
-            else:
-                log.info("Dry run is NOT set.  Data WILL be downloaded.")
-
-            if len(folders) > 0:
-                log.info("Downloading BIDS only in folders: %s", folders)
-            else:
-                log.info("Downloading BIDS data in all folders.")
-
-            bids_dir = Path(gtk_context.work_dir) / "bids"
-
-            if run_level in ["project", "subject", "session"]:
-
-                log.info(
-                    'Downloading BIDS for %s "%s"',
-                    hierarchy["run_level"],
-                    hierarchy["run_label"],
-                )
-
-                existing_dirs, reqd_dirs = list_existing_dirs(bids_dir, folders=folders)
-
-                if len(existing_dirs) >= len(reqd_dirs):  # This happens during testing
-                    bids_path = bids_dir
-                    log.info(f"Not actually downloading it because {bids_dir} exists")
-                else:
-                    missing_dirs = list(set(reqd_dirs) - set(existing_dirs))
-                    subjects = [
-                        v
-                        for k, v in hierarchy.items()
-                        if "subject" in k and v is not None
-                    ]
-                    sessions = [
-                        v
-                        for k, v in hierarchy.items()
-                        if "session" in k and v is not None
-                    ]
-
-                    bids_path = gtk_context.download_project_bids(
-                        src_data=src_data,
-                        folders=missing_dirs,
-                        dry_run=dry_run,
-                        subjects=subjects,
-                        sessions=sessions,
-                    )
-
-            elif run_level == "acquisition":
-
-                if hierarchy["acquisition_label"] == "unknown acquisition":
-                    msg = (
-                        'Cannot download BIDS for acquisition "'
-                        + hierarchy["acquisition_label"]
-                        + '"'
-                    )
-                    log.critical(msg)
-                    extra_tree_text += f"ERROR: {msg}\n"
-                    bids_path = None
-                    err_code = 23  # attempt to download unknown acquisition
-
-                else:
-                    log.info(
-                        'Downloading BIDS for acquisition "%s"',
-                        hierarchy["acquisition_label"],
-                    )
-
-                    bids_path = bids_dir
-                    if Path(bids_dir).exists():
-                        log.info(
-                            "Not actually downloading it because " f"{bids_dir} exists"
-                        )
-                    else:
-                        # only download acquisition data
-                        download_bids_dir(
-                            gtk_context.client,
-                            gtk_context.destination["id"],
-                            "acquisition",
-                            bids_dir,
-                            src_data=src_data,
-                            folders=folders,
-                            dry_run=dry_run,
-                        )
-
-            else:
-                msg = (
-                    "This job is not being run at the project, subject, "
-                    + f"session or acquisition level. run_level = {run_level}"
-                )
-                log.critical(msg, exc_info=True)
-                extra_tree_text += f"ERROR: {msg}\n"
-                bids_path = None
-                err_code = 20
-
         except BIDSExportError as bids_err:
             log.critical(bids_err, exc_info=True)
             extra_tree_text += f"{bids_err}\n"
             bids_path = None
             err_code = 21
-
         except ApiException as err:
             log.exception(err, exc_info=True)
             extra_tree_text += f"EXCEPTION: {err}\n"
             bids_path = None
-            err_code = 25  # download_bids_dir() ApiException
-
-    if bids_path:  # then the string was set so check if the directory exists
-
-        if Path(bids_path).exists():
-            log.info("Found BIDS path %s", str(bids_path))
-
-            # Make sure "Funding" is a list or validation will fail
-            fix_dataset_description(bids_path)
-
-            # now that work/bids/ exists, copy in the ignore file
-            bidsignore_list = list(Path("input/bidsignore").glob("*"))
-            if len(bidsignore_list) > 0:
-                bidsignore_path = str(bidsignore_list[0])
-                if bidsignore_path:
-                    shutil.copy(bidsignore_path, "work/bids/.bidsignore")
-                    log.info("Installed .bidsignore in work/bids/")
-
-            try:
-                if do_validate_bids:
-                    # validate (assume returns 1.. something <10 on error)
-                    err_code = validate_bids(bids_path)
-                else:
-                    log.info("Not running BIDS validation")
-                    err_code = 0
-
-            except Exception as exc:
-                log.exception(exc, exc_info=True)
-                extra_tree_text += f"EXCEPTION: {exc}\n"
-                err_code = 22
-
-        else:  # Nothing was downloaded, so what's the point?
-            msg = "No BIDS data was found to download"
-            log.critical(msg)
-            extra_tree_text += f"{msg}\n"
-            err_code = 26  # no BIDS data was downloaded
+            err_code = 25
 
+    if bids_path and Path(bids_path).exists():
+        log.info("Found BIDS path %s", str(bids_path))
+        fix_dataset_description(bids_path)
+        copy_bidsignore_file(bids_path, gtk_context.get_input_path("bidsignore"))
+
+        try:
+            if do_validate_bids:
+                err_code = validate_bids(bids_path)
+            else:
+                log.info("Not running BIDS validation")
+                err_code = 0
+        except Exception as exc:
+            log.exception(exc, exc_info=True)
+            extra_tree_text += f"EXCEPTION: {exc}\n"
+            err_code = 22
     else:
-        # try the usual path in case it was partially created
-        bids_path = Path("work/bids")
-        extra_tree_text += f"Warning: no bids path, checked work/bids anyway.\n"
-
-    if err_code > 0:
-        msg = "Error in BIDS download or validation.  See log for details."
-        log.error(msg)
+        msg = "No BIDS data was found to download"
+        log.critical(msg)
         extra_tree_text += f"{msg}\n"
-        # do not bother processing BIDS data
-
-    else:
-        msg = "Downloading BIDS data was successful!"
-        log.info(msg)
-        extra_tree_text += msg
+        err_code = 26
 
     if tree:
         tree_bids(
             bids_path,
             str(Path(gtk_context.output_dir) / "bids_tree"),
             tree_title,
             extra_tree_text,
         )
 
     return err_code
-
-
-def list_reqd_folders(folders=["anat", "func", "dwi", "fmap"]):
-    """
-    Produce the complete list of folders that are required to be present
-    for a BIDS analysis. This method is implemented specifically to avoid
-    incomplete downloads.
-    Args:
-        folders (list): the subset of folders to be included in the download
-
-    Returns:
-        final_set (list): the set of folders that must be downloaded to produce
-        the analysis.
-    """
-    std_set = ["anat", "func", "dwi", "fmap"]
-    if not folders:
-        final_set = std_set
-    else:
-        final_set = [x for x in std_set if x in folders]
-
-    return final_set
-
-
-def list_existing_dirs(bids_dir, folders=["anat", "func", "dwi", "fmap"]):
-    """
-    Find the existing folders in the BIDS working directory to insure that all
-    associated files are downloaded, but extra re-downloading is avoided.
-    Args:
-        bids_dir (path): The BIDS working directory
-        folders (list): the subset of folders to be included in the download
-
-    Returns:
-        existing_dirs  (list): updated list to pass to download_bids_dir to limit re-download
-        check_dirs (list): Any directories matching the required directory labels.
-    """
-
-    reqd_dirs = list_reqd_folders(folders)
-    existing_dirs = []
-    existing_paths = []
-    for rd in reqd_dirs:
-        if glob(op.join(bids_dir, "**", rd), recursive=True):
-            existing_paths.append(glob(op.join(bids_dir, "**", rd), recursive=True))
-            # Add to the exclusion list, so the data is not re-downloaded
-            existing_dirs.append(rd)
-    existing_dirs = list(set(existing_dirs))
-    return existing_dirs, reqd_dirs
```

## Comparing `flywheel_bids/utils/performance.py` & `flywheel_bids/flywheel_bids_app_toolkit/utils/performance.py`

 * *Files identical despite different names*

## Comparing `flywheel_bids/utils/tree.py` & `flywheel_bids/flywheel_bids_app_toolkit/utils/tree.py`

 * *Files 0% similar despite different names*

```diff
@@ -35,15 +35,14 @@
     if directory is None:
         directory = Path("(unknown)")
 
     if title is None:
         title = ""
 
     with open(base_name + ".html", "w") as html_file:
-
         html1 = (
             '<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 '
             'Transitional//EN">\n'
             + "<html>\n"
             + "  <head>\n"
             + '    <meta http-equiv="content-type" content="text/html; '
             'charset=UTF-8">\n'
@@ -68,15 +67,14 @@
 
         html_file.write(dir_str + "\n")
 
         num_dirs = 0
         num_files = 0
 
         for path in sorted(directory.rglob("*")):
-
             depth = len(path.relative_to(directory).parts)
             spacer = "    " * depth
 
             # print(f'{depth:02d} {spacer}+ {path.name}')
 
             if path.is_file():
                 num_files += 1
```

## Comparing `flywheel_bids-1.2.6.dist-info/METADATA` & `flywheel_bids-1.2.9.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,32 +1,35 @@
 Metadata-Version: 2.1
 Name: flywheel-bids
-Version: 1.2.6
+Version: 1.2.9
 Summary: Flywheel BIDS Client
 Home-page: https://gitlab.com/flywheel-io/public/bids-client
 License: MIT
 Keywords: Flywheel,flywheel,BIDS,SDK
 Author: Flywheel
 Author-email: support@flywheel.io
 Requires-Python: >=3.8,<4.0
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
+Classifier: Programming Language :: Python :: 3.12
 Classifier: Topic :: Scientific/Engineering
-Requires-Dist: flywheel-gear-toolkit (>=0.6.0,<0.7.0)
+Requires-Dist: flywheel-gear-toolkit (>=0.0.0,<1.0.0)
 Requires-Dist: flywheel-sdk (>=15.8.0,<16.0.0) ; python_full_version < "3.8.0"
-Requires-Dist: flywheel-sdk (>=16.8.0,<17.0.0) ; python_full_version >= "3.8.0"
-Requires-Dist: future (>=0.18.2)
-Requires-Dist: importlib-resources (>=5.12.0,<6.0.0)
-Requires-Dist: jsonschema (>=3.2.0)
+Requires-Dist: flywheel-sdk (>=16.8.0,<17.0.0) ; python_full_version >= "3.8.0" and python_full_version < "3.10.0"
+Requires-Dist: flywheel-sdk (>=17.0.0,<18.0.0) ; python_full_version >= "3.10.0" and python_full_version < "4.0.0"
+Requires-Dist: future (>=0.18.0,<0.20.0)
+Requires-Dist: importlib-resources (>=6.0.0,<7.0.0)
+Requires-Dist: jsonschema (>=4.0.0,<5.0.0)
+Requires-Dist: psutil (>=5.0.0,<6.0.0)
 Requires-Dist: rtstatlib (>=1.0.0)
-Requires-Dist: urllib3 (>=1.26.4)
+Requires-Dist: urllib3 (>=2.0.0,<3.0.0)
 Project-URL: Repository, https://gitlab.com/flywheel-io/public/bids-client
 Description-Content-Type: text/markdown
 
 <!-- markdownlint-configure-file { "MD024": { "siblings_only": true } } -->
 # bids-client
 
 ## Overview
```

## Comparing `flywheel_bids-1.2.6.dist-info/LICENSE` & `flywheel_bids-1.2.9.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `flywheel_bids-1.2.6.dist-info/RECORD` & `flywheel_bids-1.2.9.dist-info/RECORD`

 * *Files 24% similar despite different names*

```diff
@@ -1,25 +1,42 @@
-flywheel_bids/__init__.py,sha256=Y4xogqvLXa5sAUBRzU_qrcOE145CqsQhbeTjpwPmX1E,5
-flywheel_bids/curate_bids.py,sha256=nkkFdIfIu6bK8kCtn1ALslHtGVftahCwJU2WxZdHI0M,23826
-flywheel_bids/export_bids.py,sha256=Oa4eQ6Flu61m2DrfaAtnMmUuqpjkjn7W6fnbHHMLPiY,23741
-flywheel_bids/results/__init__.py,sha256=enUMUGNyNRTT1jGvzqiPUAO0b7akF5ybOwmdvELPIbU,76
-flywheel_bids/results/zip_htmls.py,sha256=LcntrHonTlUerhwxZ1SlG--5JMHeIvh1d0dvd2tOUfY,2361
-flywheel_bids/results/zip_intermediate.py,sha256=DZmSBnkj_YdpRKfZC13MimwjGjwclWDXF06uv3uMS9c,5147
+flywheel_bids/__init__.py,sha256=oMR85hVOREOcvwNQyy3883vMMYWgzh_SaCGCAcHeyx0,122
+flywheel_bids/curate_bids.py,sha256=v4uCCi_8BqDBfJBbhobPGuhZLUO0lSdfhDvI9VZN2Wg,31649
+flywheel_bids/export_bids.py,sha256=3FGHdcOORuo_qespffx6WkIIycy5cxMBruzwO5hA7jM,26661
+flywheel_bids/flywheel_bids_app_toolkit/__init__.py,sha256=b0sa6r3HGS-GQorbpUrEavVGdPqsV5xZ2ImzkRSTS-g,36
+flywheel_bids/flywheel_bids_app_toolkit/commands.py,sha256=KUQ-N8DzSsu1HqFR46MjkXM2OraY4_kbdR2yXQqJ-Pg,3335
+flywheel_bids/flywheel_bids_app_toolkit/compression.py,sha256=DXBo-1-as9KDag271JNmtHrc1WZkxy_mGWKwQrOTxrI,6427
+flywheel_bids/flywheel_bids_app_toolkit/context.py,sha256=x_6MkqgpTIXF-6GvXk32OwV5tHKQ-08gUqnYiSOBoM4,7827
+flywheel_bids/flywheel_bids_app_toolkit/prep.py,sha256=ik7T67vjmk2ZLGzAeTw341griNFkpJvn0SITKM26eNc,3168
+flywheel_bids/flywheel_bids_app_toolkit/report.py,sha256=qVU2h2PUNEdgLGlo3H0PO9Q8zwPoR2LTmHxwv-px-Rg,5747
+flywheel_bids/flywheel_bids_app_toolkit/tests/conftest.py,sha256=O9ONKKHF9K_jheX_2vtwnkdDbesBb09bREwp1BfqLGA,2297
+flywheel_bids/flywheel_bids_app_toolkit/tests/test_commands.py,sha256=o786KUa6z_NbeBhH2ZVxvEc8owHBwUoZdjmwZ9nUhpE,1868
+flywheel_bids/flywheel_bids_app_toolkit/tests/test_compression.py,sha256=D44FSZ67c8DQUAP9m42IYliEnBAmc9fTtOCp8M5vTL0,5776
+flywheel_bids/flywheel_bids_app_toolkit/tests/test_context.py,sha256=XQM0lYqHFmV5CLBVPVk8DUzl_Gn_v-U9dPjOfwvo0-w,2291
+flywheel_bids/flywheel_bids_app_toolkit/tests/test_old_run_level.py,sha256=90uUFQHnPZlgW8JIcbuQeDE8A4SIKFQqB8_OSYIO9U0,6554
+flywheel_bids/flywheel_bids_app_toolkit/tests/test_prep.py,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
+flywheel_bids/flywheel_bids_app_toolkit/tests/test_util_helpers.py,sha256=KWChvSGF2OzIOMcVabcFF1feuW8u6up3GKgoStrbBhQ,1453
+flywheel_bids/flywheel_bids_app_toolkit/tests/test_utils_query_flywheel.py,sha256=JKP79u442SJ7Gb0J57LT5n7W8lc3SwBDEteps98iSjw,2693
+flywheel_bids/flywheel_bids_app_toolkit/tests/test_utils_tree.py,sha256=rwKTayx3YnJVwQZ3WdkCQTW5Ynt7cRPD1e17W4bIR-o,2103
+flywheel_bids/flywheel_bids_app_toolkit/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+flywheel_bids/flywheel_bids_app_toolkit/utils/helpers.py,sha256=bhIDUlj2oAxE0U7ixnXxhNSRq7Z1QxrrjVu08viEmdk,2025
+flywheel_bids/flywheel_bids_app_toolkit/utils/performance.py,sha256=rcC3DyvpdJO1k18vyFlK93OhazPctBwABb6qA4kNEMo,2026
+flywheel_bids/flywheel_bids_app_toolkit/utils/query_flywheel.py,sha256=Nk8gqZ5U40Ax6C_iNIm-2fZ8yeFoXshWi6peG26tBbA,15018
+flywheel_bids/flywheel_bids_app_toolkit/utils/tree.py,sha256=js-pud8QbRNBytynVOZg-VAS2tZO585n5EuC11bTrvU,2520
 flywheel_bids/supporting_files/__init__.py,sha256=Y4xogqvLXa5sAUBRzU_qrcOE145CqsQhbeTjpwPmX1E,5
-flywheel_bids/supporting_files/bidsify_flywheel.py,sha256=_JAy7mZOM5BrMl-TMvSs7gnr-lrkfCzI33yo8EvMoH4,10537
+flywheel_bids/supporting_files/bidsify_flywheel.py,sha256=0uKyKzBcdmxxkAGR6E27RyR-f380HUlzVC3ru7AUSho,11070
 flywheel_bids/supporting_files/classifications.py,sha256=uisUcFW-36Zq4uXFnd-sI1Q93E9E6zgeBqipeF0AdtA,4353
 flywheel_bids/supporting_files/errors.py,sha256=6oi6hA2EM7b-7RiOjCUL0lnVLxOuEclzfoyEvtuaR3o,1234
-flywheel_bids/supporting_files/file_funcs.py,sha256=0ZP4w7Ey5uc8MpeEOgOUjZVNOum05C9Ha-V-17XOt1I,6607
-flywheel_bids/supporting_files/project_tree.py,sha256=081OxA5UgL4l1D0rCa1xQWxuu5Bxsepcdha2ir96E7E,7311
-flywheel_bids/supporting_files/resolver.py,sha256=fxPNPj9p4g2U4pQU7ib2wkKZICNhWyvU1U7M4uwpv8k,6305
-flywheel_bids/supporting_files/templates.py,sha256=7MW7Y41Q1fBaATkcK2Sl8bC_9zracyzFjgn4EjzOW-g,23538
-flywheel_bids/supporting_files/utils.py,sha256=apYF0J9yp7vqWmsnMCPZb59m2oPOEld_YbKjYDjRoQM,10872
+flywheel_bids/supporting_files/file_funcs.py,sha256=3X5nIxvq2D60iW9CKB5-MOepJNLTl4JbO0PUoHrbTck,6585
+flywheel_bids/supporting_files/project_tree.py,sha256=ukfQNPEDtvcTDzRL-bKKqK0zqJWEDSwAiP16ILrJ4oQ,7310
+flywheel_bids/supporting_files/resolver.py,sha256=pxyMm3lcgHX1_MYhDAG1VddOjfQqIDBxvKJLROZeG0I,4638
+flywheel_bids/supporting_files/templates.py,sha256=PiBPyQ1_jdXXBufj--yOLSH1nGOlraxb7WTi-vXJDQY,23915
+flywheel_bids/supporting_files/utils.py,sha256=DuiZ8BLf2YWfZLvmhyEj3OmcEYHBbasdcxSx_7z5UH0,11836
 flywheel_bids/templates/README.md,sha256=W2b6jw4TIpoSxEUqdC8AKjFUWLiTX4Q2kDDCOKK1vaw,175
 flywheel_bids/templates/bids-v1.json,sha256=nxiQHfvfN5tEMTn0USoijkFqixnBGhHPpItiUoJ0qt8,27899
-flywheel_bids/templates/default.json,sha256=dLcG0wzXyL33cOnFT3d6m-OVgo8XCQLXDBmpy8KDTTo,53901
+flywheel_bids/templates/default.json,sha256=ZBMorBX2U3Dy4PFAOAXg3awK7lvfEIilEZMtI63Jer8,54660
 flywheel_bids/templates/flywheel_curated/README.md,sha256=k290CuURkHP3w847_qKcVwaqVKTKSZv_r8onr2_peDc,1536
 flywheel_bids/templates/flywheel_curated/bridge-bdlong-project-template-attributes.txt,sha256=PsL48bjRmfcVKQR_rU6b9pshg_qnPNpUL7Ls5zIFH8o,271
 flywheel_bids/templates/flywheel_curated/bridge-bdlong-project-template.json,sha256=6tHxHSwRaaoNKocZh594y4QAYOP-WycYPcaeA05opTo,38666
 flywheel_bids/templates/flywheel_curated/bridge-global-reproin-project-template-attributes.txt,sha256=roKuoSWQJGNRn3f5R012Gu8kLnNx4KfwP9tHSBqaXWY,280
 flywheel_bids/templates/flywheel_curated/bridge-global-reproin-project-template.json,sha256=h3mpmpAFPINerPxPg2RJXuQMkFAAvWI3b6rlk1vq1Bc,34969
 flywheel_bids/templates/flywheel_curated/bridge-headspace-extension-project-template-attributes.txt,sha256=b7IgIkGQi6pl99cuNpgg5WJwT0be3U8QU8oLkUdDjKw,284
 flywheel_bids/templates/flywheel_curated/bridge-headspace-extension-project-template.json,sha256=clbyT-K-vVbpJ7OY8TTUsv_oi3wvxTHmiVW-obrNmoQ,3164
@@ -37,18 +54,14 @@
 flywheel_bids/templates/flywheel_curated/columbia-tottenham-pacct-project-template.json,sha256=wjIDWzItNsns_-06t3jGIiPriibbqAhC-wQfwYw0r0Y,6031
 flywheel_bids/templates/flywheel_curated/nyu-bair-vfs-project-template-attributes.txt,sha256=R5yNRilqy5qdQSGpiywv-WiPI4yVHtPYgkkAuh41hQ8,264
 flywheel_bids/templates/flywheel_curated/nyu-bair-vfs-project-template.json,sha256=6hvJbePJv3h5QW7I54nCXXSC8__4gEZq5aNAxUL_kzo,8483
 flywheel_bids/templates/flywheel_curated/reproin-philips-project-template-attributes.txt,sha256=t7grdbW4tPwepjx45NqTEYj6I_06BpCm0i1X2yilQP0,276
 flywheel_bids/templates/flywheel_curated/reproin-philips-project-template.json,sha256=VKm1m6LODdCrR7zS7TdI-S0yfnAzHvR8mRy1IR8PfC8,30276
 flywheel_bids/templates/flywheel_curated/reproin-reproin-project-template-attributes.txt,sha256=-0swDn_XGInpaYBUeY-ZcWx03WpQUQmhCPuCjEBtfhQ,269
 flywheel_bids/templates/flywheel_curated/reproin-reproin-project-template.json,sha256=v1PhSEOBGDA128GzKzBrWrYLTNZ5Z2tnP7B9vz9ZRrQ,42094
-flywheel_bids/templates/reproin.json,sha256=j9FxrVe3k6wqF4Kgice7FPnMDzdoDnVhkVD3FV0ylgU,44997
-flywheel_bids/upload_bids.py,sha256=Z8NkWpmTtOYGJkXx2gCWvvmkJ51X8DPnMIpIjgnodQ0,63150
-flywheel_bids/utils/download_run_level.py,sha256=NssyGcOzVURfagXgzryQHLA9YZFA3PzwI7EyuQUyVLU,13998
-flywheel_bids/utils/performance.py,sha256=rcC3DyvpdJO1k18vyFlK93OhazPctBwABb6qA4kNEMo,2026
-flywheel_bids/utils/run_level.py,sha256=FL_ChyzCECoUS7HrdRjWCEnE6e78wIA5ePKjQ4PiT2c,1816
-flywheel_bids/utils/tree.py,sha256=6bfQmkp1iqwk9RrIXxrMHMldwe9ALbvL81RA5NIqXn0,2522
+flywheel_bids/templates/reproin.json,sha256=4GFZ8k_d992TqXl9hPt32USNwNYilVEFw0slk1TfNs4,46867
+flywheel_bids/upload_bids.py,sha256=a1Y6z6eOh53eIwQ14FuWLlo4kw2MMgErxbc6BOTm5CU,67471
 flywheel_bids/utils/validate.py,sha256=noMFXBD7_k8wioxhSIiw7JNzExiyPcS3DyBbpWUiaww,5898
-flywheel_bids-1.2.6.dist-info/METADATA,sha256=KckjjMZ-9qUma0-J9J61xz6cSsrezj6jCy4UgZtWNb0,5627
-flywheel_bids-1.2.6.dist-info/WHEEL,sha256=vVCvjcmxuUltf8cYhJ0sJMRDLr1XsPuxEId8YDzbyCY,88
-flywheel_bids-1.2.6.dist-info/LICENSE,sha256=dqr2l_pCmH5B2MnrF0BMMugS_MmWV4bPLqF9aHWn4Tk,1066
-flywheel_bids-1.2.6.dist-info/RECORD,,
+flywheel_bids-1.2.9.dist-info/LICENSE,sha256=dqr2l_pCmH5B2MnrF0BMMugS_MmWV4bPLqF9aHWn4Tk,1066
+flywheel_bids-1.2.9.dist-info/METADATA,sha256=pAEsNW5xEO-ICQNTFwa7cX1x9UqdwE61HansmrMn1Fo,5887
+flywheel_bids-1.2.9.dist-info/WHEEL,sha256=FMvqSimYX_P7y0a7UY-_Mc83r5zkBZsCYPm7Lr0Bsq4,88
+flywheel_bids-1.2.9.dist-info/RECORD,,
```

