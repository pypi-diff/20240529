# Comparing `tmp/cwstorm-0.2.0b2-py2.py3-none-any.whl.zip` & `tmp/cwstorm-0.2.1-py2.py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,38 +1,38 @@
-Zip file size: 25813 bytes, number of entries: 36
--rw-r--r--  2.0 unx       29 b- defN 24-Feb-28 00:09 cwstorm/__init__.py
--rw-r--r--  2.0 unx     4697 b- defN 24-Feb-28 00:09 cwstorm/cli.py
--rw-r--r--  2.0 unx     2657 b- defN 24-Feb-28 00:09 cwstorm/deserializer.py
--rw-r--r--  2.0 unx     4020 b- defN 24-Feb-28 00:09 cwstorm/validator.py
--rw-r--r--  2.0 unx       15 b- defN 24-Feb-28 00:09 cwstorm/version.py
--rw-r--r--  2.0 unx        0 b- defN 24-Feb-28 00:09 cwstorm/dsl/__init__.py
--rw-r--r--  2.0 unx      286 b- defN 24-Feb-28 00:09 cwstorm/dsl/cmd.py
--rw-r--r--  2.0 unx     4472 b- defN 24-Feb-28 00:09 cwstorm/dsl/dag_node.py
--rw-r--r--  2.0 unx     2315 b- defN 24-Feb-28 00:09 cwstorm/dsl/job.py
--rw-r--r--  2.0 unx     4367 b- defN 24-Feb-28 00:09 cwstorm/dsl/node.py
--rw-r--r--  2.0 unx     8824 b- defN 24-Feb-28 00:09 cwstorm/dsl/node_metaclass.py
--rw-r--r--  2.0 unx     1611 b- defN 24-Feb-28 00:09 cwstorm/dsl/task.py
--rw-r--r--  2.0 unx     1123 b- defN 24-Feb-28 00:09 cwstorm/dsl/upload.py
--rw-r--r--  2.0 unx        0 b- defN 24-Feb-28 00:09 cwstorm/examples/__init__.py
--rw-r--r--  2.0 unx      149 b- defN 24-Feb-28 00:09 cwstorm/examples/ass_comp_heavy.py
--rw-r--r--  2.0 unx      147 b- defN 24-Feb-28 00:09 cwstorm/examples/ass_comp_light.py
--rw-r--r--  2.0 unx      148 b- defN 24-Feb-28 00:09 cwstorm/examples/ass_comp_normal.py
--rw-r--r--  2.0 unx      905 b- defN 24-Feb-28 00:09 cwstorm/examples/ass_export.py
--rw-r--r--  2.0 unx      760 b- defN 24-Feb-28 00:09 cwstorm/examples/frames.py
--rw-r--r--  2.0 unx      176 b- defN 24-Feb-28 00:09 cwstorm/examples/one_task.py
--rw-r--r--  2.0 unx      100 b- defN 24-Feb-28 00:09 cwstorm/examples/simple_qt.py
--rw-r--r--  2.0 unx        0 b- defN 24-Feb-28 00:09 cwstorm/serializers/__init__.py
--rw-r--r--  2.0 unx     2552 b- defN 24-Feb-28 00:09 cwstorm/serializers/default.py
--rw-r--r--  2.0 unx        0 b- defN 24-Feb-28 00:09 tests/__init__.py
--rw-r--r--  2.0 unx      438 b- defN 24-Feb-28 00:09 tests/test_cmd.py
--rw-r--r--  2.0 unx     4629 b- defN 24-Feb-28 00:09 tests/test_dag_node.py
--rw-r--r--  2.0 unx     4829 b- defN 24-Feb-28 00:09 tests/test_deserializer.py
--rw-r--r--  2.0 unx      664 b- defN 24-Feb-28 00:09 tests/test_job.py
--rw-r--r--  2.0 unx     8916 b- defN 24-Feb-28 00:09 tests/test_node.py
--rw-r--r--  2.0 unx     1774 b- defN 24-Feb-28 00:09 tests/test_serializers.py
--rw-r--r--  2.0 unx      666 b- defN 24-Feb-28 00:09 tests/test_task.py
--rw-r--r--  2.0 unx     8808 b- defN 24-Feb-28 00:10 cwstorm-0.2.0b2.dist-info/METADATA
--rw-r--r--  2.0 unx      110 b- defN 24-Feb-28 00:10 cwstorm-0.2.0b2.dist-info/WHEEL
--rw-r--r--  2.0 unx       43 b- defN 24-Feb-28 00:10 cwstorm-0.2.0b2.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       14 b- defN 24-Feb-28 00:10 cwstorm-0.2.0b2.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2873 b- defN 24-Feb-28 00:10 cwstorm-0.2.0b2.dist-info/RECORD
-36 files, 73117 bytes uncompressed, 21241 bytes compressed:  70.9%
+Zip file size: 26692 bytes, number of entries: 36
+-rw-r--r--  2.0 unx       29 b- defN 24-May-29 05:55 cwstorm/__init__.py
+-rw-r--r--  2.0 unx    10016 b- defN 24-May-29 05:55 cwstorm/cli.py
+-rw-r--r--  2.0 unx     2374 b- defN 24-May-29 05:55 cwstorm/deserializer.py
+-rw-r--r--  2.0 unx     3858 b- defN 24-May-29 05:55 cwstorm/validator.py
+-rw-r--r--  2.0 unx       15 b- defN 24-May-29 05:55 cwstorm/version.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-29 05:55 cwstorm/dsl/__init__.py
+-rw-r--r--  2.0 unx      526 b- defN 24-May-29 05:55 cwstorm/dsl/cmd.py
+-rw-r--r--  2.0 unx     4167 b- defN 24-May-29 05:55 cwstorm/dsl/dag_node.py
+-rw-r--r--  2.0 unx     2078 b- defN 24-May-29 05:55 cwstorm/dsl/job.py
+-rw-r--r--  2.0 unx     4367 b- defN 24-May-29 05:55 cwstorm/dsl/node.py
+-rw-r--r--  2.0 unx     8824 b- defN 24-May-29 05:55 cwstorm/dsl/node_metaclass.py
+-rw-r--r--  2.0 unx     2311 b- defN 24-May-29 05:55 cwstorm/dsl/task.py
+-rw-r--r--  2.0 unx     1385 b- defN 24-May-29 05:55 cwstorm/dsl/upload.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-29 05:55 cwstorm/examples/__init__.py
+-rw-r--r--  2.0 unx      149 b- defN 24-May-29 05:55 cwstorm/examples/ass_comp_heavy.py
+-rw-r--r--  2.0 unx      147 b- defN 24-May-29 05:55 cwstorm/examples/ass_comp_light.py
+-rw-r--r--  2.0 unx      148 b- defN 24-May-29 05:55 cwstorm/examples/ass_comp_normal.py
+-rw-r--r--  2.0 unx      905 b- defN 24-May-29 05:55 cwstorm/examples/ass_export.py
+-rw-r--r--  2.0 unx      760 b- defN 24-May-29 05:55 cwstorm/examples/frames.py
+-rw-r--r--  2.0 unx      176 b- defN 24-May-29 05:55 cwstorm/examples/one_task.py
+-rw-r--r--  2.0 unx      100 b- defN 24-May-29 05:55 cwstorm/examples/simple_qt.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-29 05:55 cwstorm/serializers/__init__.py
+-rw-r--r--  2.0 unx     2069 b- defN 24-May-29 05:55 cwstorm/serializers/default.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-29 05:55 tests/__init__.py
+-rw-r--r--  2.0 unx      438 b- defN 24-May-29 05:55 tests/test_cmd.py
+-rw-r--r--  2.0 unx     4629 b- defN 24-May-29 05:55 tests/test_dag_node.py
+-rw-r--r--  2.0 unx     4546 b- defN 24-May-29 05:55 tests/test_deserializer.py
+-rw-r--r--  2.0 unx      465 b- defN 24-May-29 05:55 tests/test_job.py
+-rw-r--r--  2.0 unx     8916 b- defN 24-May-29 05:55 tests/test_node.py
+-rw-r--r--  2.0 unx     1774 b- defN 24-May-29 05:55 tests/test_serializers.py
+-rw-r--r--  2.0 unx      666 b- defN 24-May-29 05:55 tests/test_task.py
+-rw-r--r--  2.0 unx     5491 b- defN 24-May-29 05:55 cwstorm-0.2.1.dist-info/METADATA
+-rw-r--r--  2.0 unx      110 b- defN 24-May-29 05:55 cwstorm-0.2.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx       43 b- defN 24-May-29 05:55 cwstorm-0.2.1.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       14 b- defN 24-May-29 05:55 cwstorm-0.2.1.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2864 b- defN 24-May-29 05:55 cwstorm-0.2.1.dist-info/RECORD
+36 files, 74360 bytes uncompressed, 22140 bytes compressed:  70.2%
```

## zipnote {}

```diff
@@ -87,23 +87,23 @@
 
 Filename: tests/test_serializers.py
 Comment: 
 
 Filename: tests/test_task.py
 Comment: 
 
-Filename: cwstorm-0.2.0b2.dist-info/METADATA
+Filename: cwstorm-0.2.1.dist-info/METADATA
 Comment: 
 
-Filename: cwstorm-0.2.0b2.dist-info/WHEEL
+Filename: cwstorm-0.2.1.dist-info/WHEEL
 Comment: 
 
-Filename: cwstorm-0.2.0b2.dist-info/entry_points.txt
+Filename: cwstorm-0.2.1.dist-info/entry_points.txt
 Comment: 
 
-Filename: cwstorm-0.2.0b2.dist-info/top_level.txt
+Filename: cwstorm-0.2.1.dist-info/top_level.txt
 Comment: 
 
-Filename: cwstorm-0.2.0b2.dist-info/RECORD
+Filename: cwstorm-0.2.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## cwstorm/__init__.py

```diff
@@ -1 +1 @@
-__schema_version__ = "0.1.1"
+__schema_version__ = "0.2.1"
```

## cwstorm/cli.py

```diff
@@ -1,17 +1,39 @@
 import os
 import click
 import importlib
 import json
 import yaml
+import sys
 from cwstorm.version import VERSION
 from cwstorm.serializers import default
 from cwstorm import validator
-from tabulate import tabulate
 import textwrap
+import re
+
+from cwstorm.dsl.cmd import Cmd
+from cwstorm.dsl.task import Task
+from cwstorm.dsl.upload import Upload
+from cwstorm.dsl.job import Job
+from cwstorm.dsl.dag_node import DagNode
+
+import markdown
+import io
+import tempfile
+import webbrowser
+
+from cwstorm import __schema_version__
+
+import traceback
+
+
+PURE = """
+<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/purecss@3.0.0/build/pure-min.css" integrity="sha384-X38yfunGUhNzHpBaEBsWLO+A0HDYOQi8ufWDkZ0k9e0eXz/tH3II7uKZ9msv++Ls" crossorigin="anonymous">
+<meta name="viewport" content="width=device-width, initial-scale=1">
+"""
 
 EXAMPLES_FOLDER = os.path.join(os.path.dirname(os.path.realpath(__file__)), "examples")
 EXAMPLE_MODULES_PREFIX = "cwstorm.examples."
 GET_JOB_FUNCTION_NAME = "get_job"
 
 
 EXAMPLE_FILES = os.listdir(EXAMPLES_FOLDER)
@@ -40,115 +62,276 @@
 
 
 SERIALIZE_HELP = """The structure of serialized DAG. 
 
 default: is a list of nodes and a list of edges. The edges contain source and target pointers to node labels. This is the simplest and easiest to understand. It is also understood by the UI.
 """
 
-FORMAT_HELP = """The output format. JSON and YAML are implemented. XML is not yet implemented.
+FORMAT_HELP = """The output format. JSON and YAML are implemented. Pretty is a pretty-printed JSON.
 """
 
 EXAMPLE_HELP = """The example job to serialize. The examples are in the storm/examples folder. The examples are python modules that contain a function called get_job that returns a job object.
 """
 
 
 ########################### SERIALIZE #############################
 @main.command()
 @click.option(
     "-f",
     "--fmt",
     "--format",
     help=FORMAT_HELP,
     default="json",
-    type=click.Choice(choices=["json", "pretty", "yaml", "xml"], case_sensitive=False),
+    type=click.Choice(choices=["json", "pretty", "yaml"], case_sensitive=False),
 )
 @click.option(
     "-x",
     "--example",
     help=EXAMPLE_HELP,
     default="simple",
-    type=click.Choice(choices=MODULE_NAMES, case_sensitive=True),
+    type=click.Choice(choices=MODULE_NAMES + ["all"], case_sensitive=True),
+)
+@click.argument(
+    "output",
+    required=False,
+    type=click.Path(file_okay=False, dir_okay=True, resolve_path=True),
 )
-@click.argument("output", nargs=1, type=click.Path(exists=False, resolve_path=True))
 def serialize(fmt, example, output):
     """
     Serialize a job to json or yaml.
 
     Examples:
 
-    # Output json to a file for visualization.
-
-    storm serialize -f json -x frames ~/Desktop/frames.json
+    # Output json to stdout.
+    storm serialize -f json -x frames
 
-    storm serialize -f json -x ass_comp_light -s fargo ~/Desktop/ass_comp_light.json
+    # Output json to a file for visualization.
+    storm serialize -f json -x frames ~/Desktop
 
     # Output yaml to a file for using the the assex job example.
-
-    storm serialize -f yaml -s storm  -x assex  ~/Desktop/assex.yaml
-
-    # ARGO is not yet implemented
+    storm serialize -f yaml -s storm  -x assex ~/Desktop
 
     """
+    if example == "all":
+        for example in MODULE_NAMES:
+            _serialize(fmt, example, output)
+    else:
+        _serialize(fmt, example, output)
+
 
+def _serialize(fmt, example, output):
     module_name = EXAMPLE_MODULES_PREFIX + example
     module = importlib.import_module(module_name)
     storm_script = getattr(module, GET_JOB_FUNCTION_NAME)
     job = storm_script()
 
     serialized = default.serialize(job)
-
-    if fmt == "json":
-        with open(output, "w", encoding="utf-8") as fh:
+    # Determine the output method (stdout or file)
+    if output:
+        ext = {
+            "json": "json",
+            "pretty": "json",
+            "yaml": "yml",
+        }
+        fh = open(os.path.join(output, f"{example}.{ext[fmt]}"), "w", encoding="utf-8")
+    else:
+        fh = sys.stdout
+    try:
+        if fmt == "json":
             json.dump(serialized, fh)
-    elif fmt == "pretty":
-        with open(output, "w", encoding="utf-8") as fh:
+        elif fmt == "pretty":
             json.dump(serialized, fh, indent=3)
-    elif fmt == "yaml":
-        with open(output, "w", encoding="utf-8") as fh:
+        elif fmt == "yaml":
             yaml.dump(serialized, fh)
-    elif fmt == "xml":
-        raise NotImplementedError("XML serialization not implemented yet.")
-    else:
-        raise ValueError(f"Unknown format: {fmt}")
+        else:
+            raise ValueError(f"Unknown format: {fmt}")
+    finally:
+        # Only close the file if we're not writing to stdout
+        if output:
+            fh.close()
 
 
-# for s in a ss_comp_heavy a ss_comp_light a ss_comp_normal a ss_export frames one_task simple_qt ; do  storm serialize -x $s  /Volumes/xhf/dev/cio/inst_tag_assign/public/graphs/$s.json; done
+# storm serialize -x all  /Volumes/xhf/dev/cio/cioapp/public/graphs/ done
 
 
-########################### DESERIALIZER #############################
-VALIDATOR_INPUT_HELP = """
-    Deserializer input format. The input format is the same as the output format.
-"""
+########################### VALIDATE #############################
 
 
 @main.command()
+@click.option(
+    "-f",
+    "--fmt",
+    "--format",
+    help=FORMAT_HELP,
+    default="html",
+    type=click.Choice(choices=["markdown", "html"], case_sensitive=False),
+)
 @click.argument("infile", nargs=1, type=click.Path(exists=True, resolve_path=True))
-def validate(infile):
+def validate(fmt, infile):
     """
     Validate a JSON file.
 
     storm validate /path/to/file.json
 
 
     """
-    print(f"\nValidating {infile}")
+
+    md = _as_markdown(infile)
+    if fmt == "markdown":
+        print(md)
+    else:  # fmt == "html":
+        html = markdown.markdown(md, extensions=["markdown.extensions.tables"])
+        html = decorate(html)
+
+        with tempfile.NamedTemporaryFile(mode="w", suffix=".html", delete=False) as f:
+            f.write(html)
+            webbrowser.open("file://" + f.name, new=2)
+
+
+def _as_markdown(infile):
+    stream = io.StringIO()
+    stream.write(f"# Storm Validation Report:\n\n{infile}")
+
     with open(infile, "r", encoding="utf-8") as fh:
         data = json.load(fh)
-        result = validator.validate(data)
-    MAX_LINE_LENGTH = 40
-    for line in result["job_info"]:
-        if len(str(line[1])) > MAX_LINE_LENGTH:
-            line[1] = _wrap_text(str(line[1]), MAX_LINE_LENGTH)
+        try:
+            validation = validator.validate(data)
+        except Exception:
+            tb_lines = traceback.format_exc().splitlines()
+            stream.write("\n\n".join(["```python"] + tb_lines + ["```"]))
+            return stream.getvalue()
+
+    stream.write("\n\n## Input Counts\n\n")
+    stream.write("| Type | Count |\n")
+    stream.write("|------|-------|\n")
+    for key, value in validation["input_info"]:
+        stream.write(f"| {key} | {value} |\n")
+
+    stream.write("\n\n## Deserialized Job Info\n\n")
+    stream.write("| Param | Value | Valid |\n")
+    stream.write("|-------|-------|-------|\n")
+    for key, value, valid in validation["job_info"]:
+        stream.write(f"| {key} | {value} | {valid} |\n")
+    result = stream.getvalue()
+    stream.close()
+    return result
 
-    print(f"******** Input counts ********")
 
-    print(tabulate(result["input_info"], headers=["Type", "Count"], tablefmt="grid"))
+########################### DISPLAY #############################
+@main.command()
+@click.option(
+    "-f",
+    "--fmt",
+    "--format",
+    help=FORMAT_HELP,
+    default="html",
+    type=click.Choice(choices=["markdown", "html"], case_sensitive=False),
+)
+def schema(fmt):
+    """
+    Display the schema.
+    
+    Shows the attributes of classes in the DSL in a web page or as markdown.
+    """
+    if fmt == "markdown":
+        display_schema_markdown(DagNode, Job, Task, Cmd, Upload)
+    elif fmt == "html":
+        display_schema_html(DagNode, Job, Task, Cmd, Upload)
 
-    print(f"\n******** Deserialized job info ********")
 
-    print(
-        tabulate(
-            result["job_info"], headers=["Param", "Value", "Valid"], tablefmt="grid"
-        )
+def display_schema_markdown(*klasses):
+    stream = io.StringIO()
+    stream.write(
+        "# Storm DSL Schema - Version {}\n\n".format(__schema_version__)
     )
 
-    # click.echo(result)
+    for klass in klasses:
+        class_schema_to_stream(klass, stream)
+    print(stream.getvalue())
+
+
+def display_schema_html(*klasses):
+    stream = io.StringIO()
+    stream.write(
+        "# Storm DSL Schema - Version {}\n\n".format(__schema_version__)
+    )
+
+    for klass in klasses:
+        class_schema_to_stream(klass, stream)
+    html = markdown.markdown(
+        stream.getvalue(), extensions=["markdown.extensions.tables"]
+    )
+    html = decorate(html)
+    stream.close()
+    with tempfile.NamedTemporaryFile(mode="w", suffix=".html", delete=False) as f:
+        f.write(html)
+        webbrowser.open("file://" + f.name, new=2)
+
+
+def class_schema_to_stream(klass, stream):
+    class_name = klass.__name__
+    base_class = klass.__bases__[0].__name__
+    docstring_paragraphs = re.split(r"\n\s*\n", klass.__doc__) if klass.__doc__ else []
+    docstring_paragraphs = [p.strip() for p in docstring_paragraphs]
+    class_description = (
+        "\n\n".join(docstring_paragraphs[1:])
+        if len(docstring_paragraphs) > 1
+        else "No description available."
+    )
+
+    desc = f"## Class: {class_name} ({base_class})\n\n#### Description:\n{class_description}\n\n"
+    stream.write(desc)
+
+    if len(klass.ATTRS) == 0:
+        stream.write("\n\n")
+        return
+    headers = ["Name", "Type", "Default", "Required", "Validator"]
+    rows = [format_attr(name, attr) for name, attr in klass.ATTRS.items()]
+    column_widths = [max(len(str(item)) for item in col) for col in zip(headers, *rows)]
+    row_format = (
+        "| " + " | ".join("{:<" + str(width) + "}" for width in column_widths) + " |"
+    )
+    stream.write(row_format.format(*headers))
+    stream.write("\n")
+    stream.write("|-" + "-|-".join("-" * width for width in column_widths) + "-|")
+    stream.write("\n")
+    for row in rows:
+        stream.write(row_format.format(*row))
+        stream.write("\n")
+    stream.write("\n\n")
+    stream.write("---\n\n")
+
+
+def format_attr(name, attr):
+    # Format type
+    type_str = (
+        attr["type"]
+        .replace("list:", "List of ")
+        .replace("int", "Integer")
+        .replace("str", "String")
+        .replace("dict", "Dictionary")
+    )
+
+    # Format default value
+    default_str = str(attr.get("default", ""))
+    
+    required_str = "Yes" if attr.get("required", False) else "No"
+
+    # Format validator
+    validator_str = ""
+    if "validator" in attr:
+        if isinstance(attr["validator"], re.Pattern):
+            validator_str = f"Regex: {attr['validator'].pattern}"
+
+        else:
+            validator_str = str(attr["validator"])
+        validator_str = validator_str.replace("|", "\\|")
+        validator_str = f"<code>{validator_str}</code>"
+    return [name, type_str, default_str, required_str, validator_str]
+
+
+def decorate(html):
+    html = html.replace("<table>", '<table class="pure-table pure-table-bordered">')
+    html = '<html><head>{}</head><body style="margin: 2em;width=800px">{}</body></html>'.format(
+        PURE, html
+    )
+    return html
```

## cwstorm/deserializer.py

```diff
@@ -8,47 +8,41 @@
 
 logging.basicConfig(level=logging.DEBUG)
 logger = logging.getLogger(__name__)
 
 def create_job(data):
     j = Job(data.get('id'))
     j.comment(data.get('comment', 'No comment'))
+    j.author(data.get('author', 'No author'))
     j.project(data.get('project', 'No project'))
-    j.status(data.get('status', 'WAITING'))
-    j.location(data.get('location', "52:3D:5C:11:56:AD"))
+    j.location(data.get('location', ""))
     j.schema_version(data.get('schema_version', '1.0.0'))
-    j.author(data.get('author', 'No author'))
-    j.email(data.get('email', 'noemail@nowhere.com'))
     j.metadata(data.get('metadata', {}))
     return j
 
 def create_task(data):
     t = Task(data.get('id'))
     for cmd in data.get('commands', []):  # Use a default empty list if 'commands' is not present
         t.push_commands(Cmd(*cmd.get('argv', [])))  # Use a default empty list if 'argv' is not present
     t.env(data.get('env' , {}))
     t.initial_state(data.get('initial_state', 'HOLD'))
     t.hardware(data.get('hardware', 'No hardware'))
+    t.preemptible(data.get('preemptible', 1))
+    for pkg in data.get('packages', []):  # Use a default empty list if 'packages' is not present
+        t.push_packages(pkg)
     t.lifecycle(data.get('lifecycle', {}))
     t.attempts(data.get('attempts', 1))
-    outputs = data.get('outputs', [])
-    if outputs:  # Need to check if outputs is not None since we're unpacking
-        t.outputs(*outputs)
-    t.status(data.get('status', 'WAITING'))
+    t.output_path(data.get('output_path'))
     return t
 
 def create_upload(data):
     u = Upload(data.get('id'))
     for file_info in data.get('files', []):  # Use a default empty list if 'files' is not present
         u.push_files(file_info)
-    outputs = data.get('outputs', [])
-    if outputs:  # Need to check if outputs is not None since we're unpacking
-        u.outputs(*outputs)
-    u.initial_state(data.get('initial_state', 'HOLD'))
-    u.status(data.get('status', 'WAITING'))
+    u.initial_state(data.get('initial_state'))
     return u
 
 
 # Function to deserialize JSON data
 def deserialize(dikt):
     nodes = {}
     job = None
```

## cwstorm/validator.py

```diff
@@ -112,23 +112,20 @@
     density = 0
     if len(nodes) > 1:
         density = len(edges) / (len(nodes) * (len(nodes) - 1))
 
     has_cycle_ = has_cycle(job)
 
     job_params = [
-        ["Job name", job.name(), True],
-        ["Job schema version", job.schema_version(), True],
-        ["Job comment", job.comment(), True],
-        ["Job project", job.project(), True],
-        ["Job status", job.status(), True],
-        ["Job location", job.location(), True],
-        ["Job author", job.author(), True],
-        ["Job email", job.email(), True],
-        ["Job created at", job.created_at(), True],
+        ["Name", job.name(), True],
+        ["Schema version", job.schema_version(), True],
+        ["Comment", job.comment(), True],
+        ["Project", job.project(), True],
+        ["Location", job.location(), True],
+        ["Author", job.author(), True],
     ]
     job_params.append(["Source nodes", num_source_nodes, num_source_nodes > 0])
     job_params.append(["Connected nodes", num_connected_nodes, num_connected_nodes_okay])
     job_params.append(["Longest path", longest, longest > 0])
     job_params.append(["Density", density, density > 0])
     job_params.append(["Has cycle", has_cycle_, not has_cycle_])
```

## cwstorm/version.py

```diff
@@ -1 +1 @@
-VERSION="0.1.0"
+VERSION="0.2.1"
```

## cwstorm/dsl/cmd.py

```diff
@@ -1,15 +1,21 @@
 from cwstorm.dsl.node import Node
 import re
 
 
 class Cmd(Node):
+    """
+    Cmd.
+    
+    A Cmd represents a single command line to be executed. Tasks hold a list of commands, and Cmd arguments are held in a list. Lists of commands in a task run in serial.
+    """
     ATTRS = {
         "argv": {
             "type": "list:str",
-            "validator": re.compile(r"^[a-zA-Z0-9_@,\-\.\/\s%:]+$", re.IGNORECASE),
+            "validator": re.compile(r"^[a-zA-Z0-9_@,\-\.\/\s%:*?<>$()+%s]+$", re.IGNORECASE),
+            "required": True
         },
 
     }
 
     def __init__(self, *args):
         self.argv(*args)
```

## cwstorm/dsl/dag_node.py

```diff
@@ -3,31 +3,19 @@
 
 
 VALID_NAME_REGEX = re.compile(r"^[a-zA-Z][a-zA-Z0-9_\-]*$")
 NAME_NUMBER_PADDING = 5
 
 
 class DagNode(Node):
+    """
+    A specialized version of Node that represents a node within a directed acyclic graph (DAG).
 
-    """A node in a directed acyclic graph.
-
-    Note: No node removal (ever)
-
-    Subclasses are Job and Task.
-
-    Job can never be a child, but it is a dag_node as
-    its useful to inherit the add() method.
-
-    An Instance is task that is a child of more than one parent
-    It is represented by one node in the DAG. However it must
-    be written many times in the output serialize.
-    During  traversal it is visited repeatedly, from differnt
-    parents. So it is considered the original task with
-    respect to its first parent, and an instance task with
-    respect to all other parents.
+    This class maintains unique naming for each instance and provides functionality to manage
+    DAG-specific properties and relationships such as parents, children, and instance tracking.
     """
 
     instances = {}  # Class dictionary to hold instances
     name_counter = {}  # Dictionary to keep track of class_name and number
 
     @classmethod
     def reset(cls):
```

## cwstorm/dsl/job.py

```diff
@@ -1,70 +1,65 @@
 import re
 import os
 import platform
 from cwstorm.dsl.dag_node import DagNode
 from datetime import datetime
 from cwstorm import __schema_version__
 
-
 class Job(DagNode):
-    """job node."""
+    """Job node.
+    
+    There's exactly one job node for each workflow. The job node summarizes the workflow and its status once tasks start running.
+    """
 
     ATTRS = {
         "comment": {
             "type": "str",
             "validator": re.compile(r'^[_a-z0-9 ,.!?\'"]+$', re.IGNORECASE),
+            "required": False
         },
         "project": {
             "type": "str",
             "validator": re.compile(r"^[a-z0-9_\-\.\s]+$", re.IGNORECASE),
-        },
-        "email": {
-            "type": "str",
-            "validator": re.compile(
-                r"\b[a-z0-9._%+-]+@[a-z0-9.-]+\.[a-z]{2,}\b", re.IGNORECASE
-            ),
+            "required": True
         },
         "author": {
             "type": "str",
             "validator": re.compile(r"^[a-z\s]+$", re.IGNORECASE),
+            "required": False
         },
         "location": {
             "type": "str",
-            "validator": re.compile(r'^(?:[a-z][a-z0-9]+$|([0-9A-Fa-f]{2}[:-]){5}([0-9A-Fa-f]{2})$)', re.IGNORECASE),
+            "validator": re.compile(r'^(?:[a-z][a-z0-9]*$|([0-9A-Fa-f]{2}[:-]){5}([0-9A-Fa-f]{2})$|^$)', re.IGNORECASE),
+            "required": False
+            
         },
-        "created_at": {
-            "type": "str",
-            "validator": re.compile(r"^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2} UTC$"),
+        "metadata": {"type": "dict",
+            "required": False
         },
-        "account_id": {"type": "str", "validator": re.compile(r"^\d{16}$")},
-        "metadata": {"type": "dict"},
         "schema_version": {
             "type": "str",
             "validator": re.compile(r"^\d{1,2}\.\d{1,2}.\d{1,2}$"),
-        },
-        "status": {
-            "type": "str",
-            "validator": re.compile(r"^(WAITING|\d{1,3}|RUNNING|SUCCESS|FAILED)$"),
-            "default": "WAITING",
-        },
+            "default": __schema_version__,
+            "required": True
+            
+        }
     }
-
+    
     def is_original(self, parent=None):
         """Always true."""
         return True
 
     def is_reference(self, parent):
         """Always false."""
         return False
 
     def __init__(self, *args, **kw):
         super().__init__(*args, **kw)
-        self.created_at(datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC"))
-        self.schema_version(__schema_version__)
+        self.schema_version(self.ATTRS["schema_version"]["default"])
         self.author(self.get_username())
 
     @staticmethod
     def get_username():
         """Return the username of the current user."""
         result =  os.environ.get("USERNAME") if platform.system() == "Windows" else os.environ.get("USER")
         if not result:
```

## cwstorm/dsl/task.py

```diff
@@ -1,45 +1,63 @@
 from cwstorm.dsl.dag_node import DagNode
 
 # from cwstorm.dsl.cmd import Cmd
 import re
 
 
 class Task(DagNode):
-    """task node."""
+    """Task node.
+
+    Tasks contain commands. They may be added to other Tasks as children or to the Job. A task may be the child of many parents.
+    """
 
     ATTRS = {
-        "commands": {"type": "list:Cmd"},
+        "commands": {"type": "list:Cmd", "required": True},
         "hardware": {
             "type": "str",
             "validator": re.compile(r"^[a-z0-9_\-\.\s]+$", re.IGNORECASE),
+            "required": True,
+        },
+        "preemptible": {"type": "int", "default": 1, "required": True},
+        "env": {"type": "dict", "required": False},
+        "lifecycle": {
+            "type": "dict",
+            "required": False,
+            "validator": {"keys": ["minsec", "maxsec"]},
+        },
+        "attempts": {
+            "type": "int",
+            "min": 1,
+            "max": 10,
+            "default": 1,
+            "required": True,
         },
-        "env": {"type": "dict"},
-        "lifecycle": {"type": "dict", "validator": {"keys": ["minsec", "maxsec"]}},
-        "attempts": {"type": "int", "min": 1, "max": 10},
         "initial_state": {
             "type": "str",
             "validator": re.compile(r"^(HOLD|START)$"),
             "default": "HOLD",
+            "required": True,
         },
-        "outputs": {"type": "list:str"},
-        "status": {
-            "type": "str",
-            "validator": re.compile(r"^(WAITING|\d{1,3}|RUNNING|SUCCESS|FAILED)$"),
-            "default": "WAITING",
+        "output_path": {"type": "str", "default":"/tmp", "required": True},
+        "packages": {
+            "type": "list:str",
+            "required": False, 
+            "validator": re.compile(r"^[a-fA-F0-9]{32}$"),
         },
     }
 
     def __init__(self, name=None):
         """Init the task."""
-    
+
         super().__init__(name)
-        self.attempts(1)
+        self.preemptible(self.ATTRS["preemptible"]["default"])
+        self.attempts(self.ATTRS["attempts"]["default"])
+        self.initial_state(self.ATTRS["initial_state"]["default"])
+        self.output_path(self.ATTRS["output_path"]["default"])
 
-        
     def is_original(self, parent=None):
         """True if the parent is the first parent or there are no parents."""
         if not parent:
             return True
         if not self.parents:
             return True
         if self.parents[0] == parent:
```

## cwstorm/dsl/upload.py

```diff
@@ -1,33 +1,51 @@
 from cwstorm.dsl.dag_node import DagNode
 
 # from cwstorm.dsl.cmd import Cmd
 import re
 
 
 class Upload(DagNode):
-    """Upload node."""
+    """Upload node.
+
+    Uploads contain lists of filepaths. They are a special kind of task and can be added anywhere a Task can be added.
+    """
 
     ATTRS = {
-        "files": {"type": "list:dict", "validator": {"keys":["path", "size"]}},
-        "initial_state": {"type": "str", "validator": re.compile(r"^(HOLD|START)$"), "default": "HOLD"},
-        "outputs": {"type": "list:str"},
-        "status": {"type": "str", "validator": re.compile(r"^(WAITING|\d{1,3}|RUNNING|SUCCESS|FAILED)$"), "default": "WAITING"},
+        "files": {
+            "type": "list:dict",
+            "required": True,
+            "validator": {"keys": ["path", "size", "md5"]},
+        },
+        "initial_state": {
+            "type": "str",
+            "validator": re.compile(r"^(HOLD|START)$"),
+            "default": "HOLD",
+            "required": True,
+        }
     }
 
+
+    def __init__(self, name=None):
+        """Init the task."""
+
+        super().__init__(name)
+        self.initial_state(self.ATTRS["initial_state"]["default"])
+
+
+
     def is_original(self, parent=None):
         """True if the parent is the first parent or there are no parents."""
         if not parent:
             return True
         if not self.parents:
             return True
         if self.parents[0] == parent:
             return True
         return False
-        
 
     def is_reference(self, parent):
         """True if the parent is a parent and not the first parent."""
         return (
             parent
             and self.parents
             and len(self.parents) > 1
```

## cwstorm/serializers/default.py

```diff
@@ -1,9 +1,8 @@
-import json
-
+ 
 
 def serialize(node):
     elements = _serialize(node)
     result = {"nodes": [], "edges": []}
     for el in elements:
         if el.get("position"):
             result["nodes"].append(el)
@@ -20,20 +19,14 @@
     node_element["type"] = node_type
     if node_type == "job":
         node_element.update(get_job_attrs(node))
     elif node_type == "task":
         node_element.update(get_task_attrs(node))
     elif node_type == "upload":
         node_element.update(get_upload_attrs(node))
-
-    node_element["num_children"] = len(node.children)
-    node_element["num_parents"] = len(node.parents)
-    node_element["num_ancestors"] = node.count_ancestors()
-    node_element["num_descendants"] = node.count_descendents()
-
     elements.append({"data": node_element, "position": {"x": 0, "y": order}})
 
     # edges
     for c in node.children:
         edge_element = {}
         edge_element["source"] = c.name()
         edge_element["target"] = node.name()
@@ -48,39 +41,33 @@
     return elements
 
 
 def get_job_attrs(job):
     attrs = {}
     attrs["comment"] = job.comment()
     attrs["author"] = job.author()
-    attrs["created_at"] = job.created_at()
     attrs["schema_version"] = job.schema_version()
     attrs["metadata"] = job.metadata()
     attrs["location"] = job.location()
     attrs["project"] = job.project()
-    stat = job.status()
-    attrs["status"] = "SUCCESS" if stat == "100" else stat
     return attrs
 
 
 def get_task_attrs(task):
     attrs = {}
     attrs["commands"] = [dict(c) for c in task.commands()]
-    attrs["outputs"] = task.outputs()
+    attrs["output_path"] = task.output_path()
     attrs["hardware"] = task.hardware()
+    attrs["preemptible"] = task.preemptible()
+    attrs["packages"] = task.packages()
     attrs["env"] = task.env()
     attrs["lifecycle"] = task.lifecycle()
     attrs["attempts"] = task.attempts()
     attrs["initial_state"] = task.initial_state()
-    stat = task.status()
-    attrs["status"] = "SUCCESS" if stat == "100" else stat
     return attrs
 
 
 def get_upload_attrs(upload):
     attrs = {}
     attrs["files"] = upload.files()
-    attrs["outputs"] = upload.outputs()
     attrs["initial_state"] = upload.initial_state()
-    stat = upload.status()
-    attrs["status"] = "SUCCESS" if stat == "100" else stat
     return attrs
```

## tests/test_deserializer.py

```diff
@@ -8,52 +8,49 @@
 class TestJobCreation(unittest.TestCase):
     def setUp(self):
         self.job_data = {
             'id': 'job1',
             'comment': 'Test job',
             'project': 'ProjectX',
             'status': 'WAITING',
-            'location': 'LocationY',
+            'location': 'Location',
             'schema_version': '1.0.0',
             'author': 'AuthorZ',
             'email': 'author@example.com',
             'metadata': {'key': 'value'}
         }
     
     def tearDown(self):
         DagNode.reset()
 
     def test_create_job(self):
         job = create_job(self.job_data)
         self.assertEqual(job.name(), self.job_data['id'])
         self.assertEqual(job.comment(), self.job_data['comment'])
         self.assertEqual(job.project(), self.job_data['project'])
-        self.assertEqual(job.status(), self.job_data['status'])
         self.assertEqual(job.location(), self.job_data['location'])
         self.assertEqual(job.schema_version(), self.job_data['schema_version'])
         self.assertEqual(job.author(), self.job_data['author'])
-        self.assertEqual(job.email(), self.job_data['email'])
         self.assertEqual(job.metadata(), self.job_data['metadata'])
         
-        # ... continue for all fields
-
+ 
 class TestTaskCreation(unittest.TestCase):
     def setUp(self):
         self.task_data = {
             'id': 'task1',
             'commands': [
                 {'argv': ['echo', 'Hello World']}, 
                 {'argv': ['echo', 'Goodbye Cruel World']}
             ],
             'env': {'PATH': '/usr/bin'},
             'initial_state': 'HOLD',
             'hardware': 'x86_64',
             'lifecycle':  {'minsec': 30, 'maxsec': 1500},
             'attempts': 3,
-            'outputs': ['output.log'],
+            'output_path': '/tmp/output',
             'status': 'WAITING'
         }
         
     def tearDown(self):
         DagNode.reset()
 
     def test_create_task(self):
@@ -61,51 +58,47 @@
         self.assertEqual(task.name(), self.task_data['id'])
         self.assertEqual(len(task.commands()), 2)
         self.assertEqual(task.env(), self.task_data['env'])
         self.assertEqual(task.initial_state(), self.task_data['initial_state'])
         self.assertEqual(task.hardware(), self.task_data['hardware'])
         self.assertEqual(task.lifecycle(), self.task_data['lifecycle'])
         self.assertEqual(task.attempts(), self.task_data['attempts'])
-        self.assertEqual(len(task.outputs()), 1)
-        self.assertEqual(task.status(), self.task_data['status'])
+        self.assertEqual(task.output_path(), self.task_data['output_path'])
         
         # ... continue for all fields
 
 class TestUploadCreation(unittest.TestCase):
     def setUp(self):
         self.upload_data = {
             'id': 'upload1',
             'files': [
                 {'path': '/tmp/file.txt', 'size': 1024},
                 {'path': '/tmp/other.txt', 'size': 2048}
             ],
-            'outputs': ['file.txt'],
             'initial_state': 'START',
             'status': 'SUCCESS'
         }
         
     def tearDown(self):
         DagNode.reset()
 
     def test_create_upload(self):
         upload = create_upload(self.upload_data)
         self.assertEqual(upload.name(), self.upload_data['id'])
         self.assertEqual(len(upload.files()), 2)
-        self.assertEqual(upload.status(), self.upload_data['status'])
         self.assertEqual(upload.initial_state(), self.upload_data['initial_state'])
-        self.assertEqual(len(upload.outputs()), 1)
         
 
 class TestDeserialization(unittest.TestCase):
     def setUp(self):
         self.deserialized_data = {
             'nodes': [
                 {'data': {'type': 'job', 'id': 'job1'}},
-                {'data': {'type': 'task', 'id': 'task1'}},
-                {'data': {'type': 'upload', 'id': 'upload1'}}
+                {'data': {'type': 'task', 'id': 'task1', "output_path": "/media/","initial_state": "HOLD"}},
+                {'data': {'type': 'upload', 'id': 'upload1',"initial_state": "HOLD"}}
             ],
             'edges': [
                 {'data': {'source': 'task1', 'target': 'job1'}},
                 {'data': {'source': 'upload1', 'target': 'job1'}}
             ]
         }
         
@@ -117,14 +110,15 @@
     @patch('cwstorm.deserializer.create_upload')
     def test_deserialize(self, mock_create_upload, mock_create_task, mock_create_job):
         job = deserialize(self.deserialized_data)
         mock_create_job.assert_called_once()
         mock_create_task.assert_called_once()
         mock_create_upload.assert_called_once()
         
+
     def test_deserialize_connects_nodes(self):
         job = deserialize(self.deserialized_data)
         self.assertEqual(len(job.children), 2)
         self.assertEqual(job.children[0].name(), 'task1')
         self.assertEqual(job.children[1].name(), 'upload1')
 
 if __name__ == '__main__':
```

## tests/test_job.py

```diff
@@ -12,12 +12,7 @@
     def test_env_attribute(self):
         self.node.metadata({"foo": "bar"})
         self.assertEqual(self.node.metadata(), {"foo": "bar"})
 
     def test_comment_attribute(self):
         self.node.comment("foo")
         self.assertEqual(self.node.comment(), "foo")
-
-    def test_account_id_must_be_16_digits(self):
-        self.assertRaises(ValueError, self.node.account_id, "foo")
-        self.assertRaises(ValueError, self.node.account_id, "12345678901234567")
-
```

## Comparing `cwstorm-0.2.0b2.dist-info/RECORD` & `cwstorm-0.2.1.dist-info/RECORD`

 * *Files 11% similar despite different names*

```diff
@@ -1,36 +1,36 @@
-cwstorm/__init__.py,sha256=UHyiWcm9JmXEfGswZoQ3HdsL91HIQK2xrFeMKmPw4pg,29
-cwstorm/cli.py,sha256=HE1FiPvYDMX4teVLCJ-Xy6ikjKweWwwnFWkM70GMU1E,4697
-cwstorm/deserializer.py,sha256=h0aPaQVF8Uol8N9wK9iHbk5GHT7XIuf3E_6cdHg4UmU,2657
-cwstorm/validator.py,sha256=Vvkl8nfvdw-Lh7XdlK1oTseP8PbIoXcgM7MAcDuZ3pE,4020
-cwstorm/version.py,sha256=O58-s1kzqvR10C2rxlryPZBVejADEvOeOngtkvWly9k,15
+cwstorm/__init__.py,sha256=5LlYqxy3FAIopk98vlwNsJJhQ8JRfk8eYpDIhZTH4mg,29
+cwstorm/cli.py,sha256=fSrsdqw2bktaAil4tNHJN10pYN0h6NgzmYYsB_dLu8A,10016
+cwstorm/deserializer.py,sha256=mYR5ClRfyVGruBNTn3GAuFYi0qoWE7UjYD8iQnQZQR8,2374
+cwstorm/validator.py,sha256=LffA0eEq2FCXa9GcuwaMzHgxbI8gUxjsHpMATHqppbg,3858
+cwstorm/version.py,sha256=rPHRjUhylq1WB5bxeL1VpJniIrffpk3FMoA-74MLEN4,15
 cwstorm/dsl/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-cwstorm/dsl/cmd.py,sha256=5k97B8m0OeSvAHnJEabjlpTujNiI_ZhRUqD1N19Sdkk,286
-cwstorm/dsl/dag_node.py,sha256=fyN03mDYlMfznd_PpXBOMVuh4Nbzk3f4AoCvEEazeeA,4472
-cwstorm/dsl/job.py,sha256=C9eBP6feClY0c46VlsN_gA2oZk_vpD3PZlAkU_L-YtI,2315
+cwstorm/dsl/cmd.py,sha256=DtQJor4jqOSKwhlmBZE_y-sgq5nyxZM9dZH0NVa5f90,526
+cwstorm/dsl/dag_node.py,sha256=wFaoIQQVlYBhzIWFHUZNrdLbQ3KPalOXdiT3tDDx2Oo,4167
+cwstorm/dsl/job.py,sha256=xA6lb88BIqLbHHKvKcqVDY3kZRRKeo9Ybv4DgWmWHrg,2078
 cwstorm/dsl/node.py,sha256=eY4gPxt9pDrJDMzSo-nrTh4gFH3ABi08hPnq2HPTt_k,4367
 cwstorm/dsl/node_metaclass.py,sha256=n9wcUklSTL9_RkN9TkwBp677H_zpkI8DrxMA73aV6Xw,8824
-cwstorm/dsl/task.py,sha256=-UUnFIYllya8nyeJ7eq1NrVB4rscDFL2Izut8Hof3xw,1611
-cwstorm/dsl/upload.py,sha256=YNuIMf_4xZg5GNUk7IanRV1xG9M0lxADw8-KGERAF7Q,1123
+cwstorm/dsl/task.py,sha256=g8STDbWod-QbAXC6mkofOVVcR2M-nh_hEiKcoUJUCT0,2311
+cwstorm/dsl/upload.py,sha256=tSoD-4PBlAyvsALPI-B9JIW2_TnpYC_XXq_p-GoNTeY,1385
 cwstorm/examples/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 cwstorm/examples/ass_comp_heavy.py,sha256=tzwyv100QeoaRrkbB7u4UDuNCO5weD6ugjrWLvaWgWY,149
 cwstorm/examples/ass_comp_light.py,sha256=O-uKkaVoBjOtjeRPFJPBjpjrow220tCQFCVAn2YgcoY,147
 cwstorm/examples/ass_comp_normal.py,sha256=79NveUK-nflhyFRJTaKI7hTcn7-h1yTwC52uXXo_8Lo,148
 cwstorm/examples/ass_export.py,sha256=ZXCY7pRPYtFKb84rfbOF9XpBGz3exLnDFiBCR1vqGAQ,905
 cwstorm/examples/frames.py,sha256=o_SshWfNBcngJHHfNwnys-i3IqRysZUvXr-cVGQ4wlE,760
 cwstorm/examples/one_task.py,sha256=LbiN47G21wasDG4B4cwH_tgk2LYDJL4jnAbh2b1KQJM,176
 cwstorm/examples/simple_qt.py,sha256=JUXvvAhXhLKtEbkpETQV9wMfizpUyPytmbTbJ5ZN7lA,100
 cwstorm/serializers/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-cwstorm/serializers/default.py,sha256=GUTrOubRQmmWRT-tAYCJRje2mRJKMY56Ao_x3bi5mg8,2552
+cwstorm/serializers/default.py,sha256=uDdJvArhD17k98sSLGmuJxtQHM2atnXqgkhndTYgh_M,2069
 tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tests/test_cmd.py,sha256=0Ck4zCKxmtxJQVA0kdWrN9e53n-2LtZrk0HaSOudw3g,438
 tests/test_dag_node.py,sha256=WYeK0YRrJ3b0rtgoXdhmTHR4Z0NIMl5jRDRCXbSvhrw,4629
-tests/test_deserializer.py,sha256=x6YvXWDnW0SCWgKS77VET8cy0_nKxjQ2c29qVznZoO4,4829
-tests/test_job.py,sha256=exclkTKudgnAAOHkJ5_MuZf-4SIrFqrH1K-MGKwjoIs,664
+tests/test_deserializer.py,sha256=83sr4lR8kcamWFx0F_QPlBVRHDb2rNWQdaEPbb62ILk,4546
+tests/test_job.py,sha256=x6QQ0flXM3B7Lm955Iis7kuzKFE05aCJLk6Ij24M2JA,465
 tests/test_node.py,sha256=Dp36E9aUChz6XrKcBR4hKvoj7xmwnIP2kiAOCq7OANY,8916
 tests/test_serializers.py,sha256=ibfBNjL0Qpj3LqapBzjIyxeL8Z5gURTzR86N1inAMVY,1774
 tests/test_task.py,sha256=LxcoUsWmoqMTa98s9MIa8piQooi530AaV3Fsi9tF5c0,666
-cwstorm-0.2.0b2.dist-info/METADATA,sha256=xq3tP7uIQGmKI9ziL_FOKC_brkeNPmM5yeq2dd4PyMo,8808
-cwstorm-0.2.0b2.dist-info/WHEEL,sha256=iYlv5fX357PQyRT2o6tw1bN-YcKFFHKqB_LwHO5wP-g,110
-cwstorm-0.2.0b2.dist-info/entry_points.txt,sha256=TMHyKhmQ_Zlzoa19R0QhyB-c1qbDKEP5n0Xhchow1Ts,43
-cwstorm-0.2.0b2.dist-info/top_level.txt,sha256=MnbHmaUJEo7Oos1-P4L7ydVazanb4M0hIVtigvhqHkw,14
-cwstorm-0.2.0b2.dist-info/RECORD,,
+cwstorm-0.2.1.dist-info/METADATA,sha256=SJBRwC-rw5dcp1jWrLv-lA8470YyC3jLfYcGepr2fqI,5491
+cwstorm-0.2.1.dist-info/WHEEL,sha256=DZajD4pwLWue70CAfc7YaxT1wLUciNBvN_TTcvXpltE,110
+cwstorm-0.2.1.dist-info/entry_points.txt,sha256=TMHyKhmQ_Zlzoa19R0QhyB-c1qbDKEP5n0Xhchow1Ts,43
+cwstorm-0.2.1.dist-info/top_level.txt,sha256=MnbHmaUJEo7Oos1-P4L7ydVazanb4M0hIVtigvhqHkw,14
+cwstorm-0.2.1.dist-info/RECORD,,
```

