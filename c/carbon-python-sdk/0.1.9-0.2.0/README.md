# Comparing `tmp/carbon_python_sdk-0.1.9.tar.gz` & `tmp/carbon_python_sdk-0.2.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "carbon_python_sdk-0.1.9.tar", max compression
+gzip compressed data, was "carbon_python_sdk-0.2.0.tar", max compression
```

## Comparing `carbon_python_sdk-0.1.9.tar` & `carbon_python_sdk-0.2.0.tar`

### file list

```diff
@@ -1,831 +1,977 @@
--rw-r--r--   0        0        0     1081 2024-03-14 20:19:21.910625 carbon_python_sdk-0.1.9/LICENSE
--rw-r--r--   0        0        0    94401 2024-03-14 20:21:24.395283 carbon_python_sdk-0.1.9/README.md
--rw-r--r--   0        0        0      675 2024-03-14 20:21:24.395510 carbon_python_sdk-0.1.9/carbon/__init__.py
--rw-r--r--   0        0        0    76911 2024-03-14 20:21:24.395766 carbon_python_sdk-0.1.9/carbon/api_client.py
--rw-r--r--   0        0        0      663 2024-03-14 20:19:21.700070 carbon_python_sdk-0.1.9/carbon/api_response.py
--rw-r--r--   0        0        0      214 2024-03-14 20:19:21.700228 carbon_python_sdk-0.1.9/carbon/apis/__init__.py
--rw-r--r--   0        0        0     9733 2024-03-14 20:21:24.396028 carbon_python_sdk-0.1.9/carbon/apis/path_to_api.py
--rw-r--r--   0        0        0      233 2024-03-14 20:19:21.700846 carbon_python_sdk-0.1.9/carbon/apis/paths/__init__.py
--rw-r--r--   0        0        0      101 2024-03-14 20:19:21.701075 carbon_python_sdk-0.1.9/carbon/apis/paths/add_webhook.py
--rw-r--r--   0        0        0      114 2024-03-14 20:19:21.701225 carbon_python_sdk-0.1.9/carbon/apis/paths/auth_v1_access_token.py
--rw-r--r--   0        0        0      118 2024-03-14 20:19:21.701365 carbon_python_sdk-0.1.9/carbon/apis/paths/auth_v1_white_labeling.py
--rw-r--r--   0        0        0      119 2024-03-14 20:19:21.701681 carbon_python_sdk-0.1.9/carbon/apis/paths/create_user_file_tags.py
--rw-r--r--   0        0        0      103 2024-03-14 20:19:21.701879 carbon_python_sdk-0.1.9/carbon/apis/paths/delete_files.py
--rw-r--r--   0        0        0      119 2024-03-14 20:19:21.702237 carbon_python_sdk-0.1.9/carbon/apis/paths/delete_user_file_tags.py
--rw-r--r--   0        0        0      103 2024-03-14 20:19:21.702554 carbon_python_sdk-0.1.9/carbon/apis/paths/delete_users.py
--rw-r--r--   0        0        0      133 2024-03-14 20:19:21.702713 carbon_python_sdk-0.1.9/carbon/apis/paths/delete_webhook_webhook_id.py
--rw-r--r--   0        0        0      120 2024-03-14 20:19:21.702834 carbon_python_sdk-0.1.9/carbon/apis/paths/deletefile_file_id.py
--rw-r--r--   0        0        0      100 2024-03-14 20:19:21.702948 carbon_python_sdk-0.1.9/carbon/apis/paths/embeddings.py
--rw-r--r--   0        0        0       96 2024-03-14 20:19:21.703105 carbon_python_sdk-0.1.9/carbon/apis/paths/fetch_urls.py
--rw-r--r--   0        0        0      123 2024-03-14 20:19:21.703324 carbon_python_sdk-0.1.9/carbon/apis/paths/fetch_youtube_transcript.py
--rw-r--r--   0        0        0       89 2024-03-14 20:19:21.703766 carbon_python_sdk-0.1.9/carbon/apis/paths/health.py
--rw-r--r--   0        0        0      134 2024-03-14 20:19:21.703980 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_confluence_list.py
--rw-r--r--   0        0        0      134 2024-03-14 20:19:21.704107 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_confluence_sync.py
--rw-r--r--   0        0        0      119 2024-03-14 20:21:24.396111 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_connect.py
--rw-r--r--   0        0        0      124 2024-03-14 20:19:21.704346 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_files_sync.py
--rw-r--r--   0        0        0      123 2024-03-14 20:19:21.704501 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_freshdesk.py
--rw-r--r--   0        0        0      119 2024-03-14 20:19:21.704617 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_gitbook.py
--rw-r--r--   0        0        0      129 2024-03-14 20:19:21.704731 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_gitbook_spaces.py
--rw-r--r--   0        0        0      128 2024-03-14 20:19:21.704855 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_gitbook_sync.py
--rw-r--r--   0        0        0      124 2024-03-14 20:19:21.704975 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_gmail_sync.py
--rw-r--r--   0        0        0      134 2024-03-14 20:19:21.705083 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_gmail_user_labels.py
--rw-r--r--   0        0        0      124 2024-03-14 20:19:21.705308 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_items_list.py
--rw-r--r--   0        0        0      124 2024-03-14 20:19:21.705538 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_items_sync.py
--rw-r--r--   0        0        0      122 2024-03-14 20:19:21.705660 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_oauth_url.py
--rw-r--r--   0        0        0      128 2024-03-14 20:19:21.705775 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_outlook_sync.py
--rw-r--r--   0        0        0      146 2024-03-14 20:19:21.706069 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_outlook_user_categories.py
--rw-r--r--   0        0        0      140 2024-03-14 20:19:21.706238 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_outlook_user_folders.py
--rw-r--r--   0        0        0      120 2024-03-14 20:19:21.706389 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_rss_feed.py
--rw-r--r--   0        0        0      109 2024-03-14 20:19:21.706519 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_s3.py
--rw-r--r--   0        0        0      120 2024-03-14 20:19:21.706641 carbon_python_sdk-0.1.9/carbon/apis/paths/integrations_s3_files.py
--rw-r--r--   0        0        0      128 2024-03-14 20:19:21.706785 carbon_python_sdk-0.1.9/carbon/apis/paths/modify_user_configuration.py
--rw-r--r--   0        0        0      101 2024-03-14 20:19:21.706897 carbon_python_sdk-0.1.9/carbon/apis/paths/organization.py
--rw-r--r--   0        0        0      112 2024-03-14 20:19:21.707007 carbon_python_sdk-0.1.9/carbon/apis/paths/parsed_file_file_id.py
--rw-r--r--   0        0        0      106 2024-03-14 20:19:21.707114 carbon_python_sdk-0.1.9/carbon/apis/paths/process_sitemap.py
--rw-r--r--   0        0        0      106 2024-03-14 20:19:21.707221 carbon_python_sdk-0.1.9/carbon/apis/paths/raw_file_file_id.py
--rw-r--r--   0        0        0      101 2024-03-14 20:19:21.707323 carbon_python_sdk-0.1.9/carbon/apis/paths/resync_file.py
--rw-r--r--   0        0        0      116 2024-03-14 20:19:21.707590 carbon_python_sdk-0.1.9/carbon/apis/paths/revoke_access_token.py
--rw-r--r--   0        0        0      107 2024-03-14 20:19:21.707803 carbon_python_sdk-0.1.9/carbon/apis/paths/scrape_sitemap.py
--rw-r--r--   0        0        0       98 2024-03-14 20:19:21.707948 carbon_python_sdk-0.1.9/carbon/apis/paths/search_urls.py
--rw-r--r--   0        0        0      101 2024-03-14 20:19:21.708067 carbon_python_sdk-0.1.9/carbon/apis/paths/text_chunks.py
--rw-r--r--   0        0        0      133 2024-03-14 20:19:21.708409 carbon_python_sdk-0.1.9/carbon/apis/paths/upload_chunks_and_embeddings.py
--rw-r--r--   0        0        0      117 2024-03-14 20:19:21.708549 carbon_python_sdk-0.1.9/carbon/apis/paths/upload_file_from_url.py
--rw-r--r--   0        0        0      101 2024-03-14 20:19:21.708660 carbon_python_sdk-0.1.9/carbon/apis/paths/upload_text.py
--rw-r--r--   0        0        0      100 2024-03-14 20:19:21.708939 carbon_python_sdk-0.1.9/carbon/apis/paths/uploadfile.py
--rw-r--r--   0        0        0       88 2024-03-14 20:19:21.709322 carbon_python_sdk-0.1.9/carbon/apis/paths/user.py
--rw-r--r--   0        0        0      112 2024-03-14 20:19:21.709500 carbon_python_sdk-0.1.9/carbon/apis/paths/user_data_sources.py
--rw-r--r--   0        0        0       99 2024-03-14 20:19:21.709626 carbon_python_sdk-0.1.9/carbon/apis/paths/user_files.py
--rw-r--r--   0        0        0      104 2024-03-14 20:19:21.709732 carbon_python_sdk-0.1.9/carbon/apis/paths/user_files_v2.py
--rw-r--r--   0        0        0       99 2024-03-14 20:19:21.709858 carbon_python_sdk-0.1.9/carbon/apis/paths/web_scrape.py
--rw-r--r--   0        0        0       96 2024-03-14 20:19:21.710142 carbon_python_sdk-0.1.9/carbon/apis/paths/webhooks.py
--rw-r--r--   0        0        0     2044 2024-03-14 20:19:21.710315 carbon_python_sdk-0.1.9/carbon/apis/tag_to_api.py
--rw-r--r--   0        0        0      655 2024-03-14 20:19:21.710716 carbon_python_sdk-0.1.9/carbon/apis/tags/__init__.py
--rw-r--r--   0        0        0      663 2024-03-14 20:19:21.710996 carbon_python_sdk-0.1.9/carbon/apis/tags/auth_api.py
--rw-r--r--   0        0        0      493 2024-03-14 20:19:21.711189 carbon_python_sdk-0.1.9/carbon/apis/tags/auth_api_raw.py
--rw-r--r--   0        0        0      709 2024-03-14 20:19:21.711322 carbon_python_sdk-0.1.9/carbon/apis/tags/data_sources_api.py
--rw-r--r--   0        0        0      510 2024-03-14 20:19:21.711436 carbon_python_sdk-0.1.9/carbon/apis/tags/data_sources_api_raw.py
--rw-r--r--   0        0        0      798 2024-03-14 20:19:21.711615 carbon_python_sdk-0.1.9/carbon/apis/tags/embeddings_api.py
--rw-r--r--   0        0        0      610 2024-03-14 20:19:21.711932 carbon_python_sdk-0.1.9/carbon/apis/tags/embeddings_api_raw.py
--rw-r--r--   0        0        0     1418 2024-03-14 20:19:21.712130 carbon_python_sdk-0.1.9/carbon/apis/tags/files_api.py
--rw-r--r--   0        0        0     1304 2024-03-14 20:19:21.712455 carbon_python_sdk-0.1.9/carbon/apis/tags/files_api_raw.py
--rw-r--r--   0        0        0      550 2024-03-14 20:19:21.712612 carbon_python_sdk-0.1.9/carbon/apis/tags/health_api.py
--rw-r--r--   0        0        0      366 2024-03-14 20:19:21.712889 carbon_python_sdk-0.1.9/carbon/apis/tags/health_api_raw.py
--rw-r--r--   0        0        0     2242 2024-03-14 20:21:24.396257 carbon_python_sdk-0.1.9/carbon/apis/tags/integrations_api.py
--rw-r--r--   0        0        0     2142 2024-03-14 20:21:24.396385 carbon_python_sdk-0.1.9/carbon/apis/tags/integrations_api_raw.py
--rw-r--r--   0        0        0      587 2024-03-14 20:19:21.714947 carbon_python_sdk-0.1.9/carbon/apis/tags/organizations_api.py
--rw-r--r--   0        0        0      375 2024-03-14 20:19:21.715088 carbon_python_sdk-0.1.9/carbon/apis/tags/organizations_api_raw.py
--rw-r--r--   0        0        0      701 2024-03-14 20:19:21.715198 carbon_python_sdk-0.1.9/carbon/apis/tags/users_api.py
--rw-r--r--   0        0        0      533 2024-03-14 20:19:21.716769 carbon_python_sdk-0.1.9/carbon/apis/tags/users_api_raw.py
--rw-r--r--   0        0        0      976 2024-03-14 20:19:21.717115 carbon_python_sdk-0.1.9/carbon/apis/tags/utilities_api.py
--rw-r--r--   0        0        0      810 2024-03-14 20:19:21.717240 carbon_python_sdk-0.1.9/carbon/apis/tags/utilities_api_raw.py
--rw-r--r--   0        0        0      705 2024-03-14 20:19:21.717350 carbon_python_sdk-0.1.9/carbon/apis/tags/webhooks_api.py
--rw-r--r--   0        0        0      525 2024-03-14 20:19:21.717463 carbon_python_sdk-0.1.9/carbon/apis/tags/webhooks_api_raw.py
--rw-r--r--   0        0        0     1986 2024-03-14 20:19:21.717570 carbon_python_sdk-0.1.9/carbon/client.py
--rw-r--r--   0        0        0     1986 2024-03-14 20:19:21.717714 carbon_python_sdk-0.1.9/carbon/client.pyi
--rw-r--r--   0        0        0      676 2024-03-14 20:19:21.717835 carbon_python_sdk-0.1.9/carbon/client_custom.py
--rw-r--r--   0        0        0    17804 2024-03-14 20:21:24.396573 carbon_python_sdk-0.1.9/carbon/configuration.py
--rw-r--r--   0        0        0     7679 2024-03-14 20:19:21.718162 carbon_python_sdk-0.1.9/carbon/exceptions.py
--rw-r--r--   0        0        0     2274 2024-03-14 20:19:21.718267 carbon_python_sdk-0.1.9/carbon/exceptions_base.py
--rw-r--r--   0        0        0      340 2024-03-14 20:19:21.718515 carbon_python_sdk-0.1.9/carbon/model/__init__.py
--rw-r--r--   0        0        0     2282 2024-03-14 20:19:21.718659 carbon_python_sdk-0.1.9/carbon/model/add_webhook_props.py
--rw-r--r--   0        0        0     2282 2024-03-14 20:19:21.718766 carbon_python_sdk-0.1.9/carbon/model/add_webhook_props.pyi
--rw-r--r--   0        0        0     2371 2024-03-14 20:19:21.718880 carbon_python_sdk-0.1.9/carbon/model/body_create_upload_file_uploadfile_post.py
--rw-r--r--   0        0        0     2371 2024-03-14 20:19:21.719013 carbon_python_sdk-0.1.9/carbon/model/body_create_upload_file_uploadfile_post.pyi
--rw-r--r--   0        0        0     4752 2024-03-14 20:19:21.719221 carbon_python_sdk-0.1.9/carbon/model/chunk_properties.py
--rw-r--r--   0        0        0     4752 2024-03-14 20:19:21.719402 carbon_python_sdk-0.1.9/carbon/model/chunk_properties.pyi
--rw-r--r--   0        0        0     4359 2024-03-14 20:19:21.719629 carbon_python_sdk-0.1.9/carbon/model/chunk_properties_nullable.py
--rw-r--r--   0        0        0     4359 2024-03-14 20:19:21.719901 carbon_python_sdk-0.1.9/carbon/model/chunk_properties_nullable.pyi
--rw-r--r--   0        0        0     4319 2024-03-14 20:19:21.720151 carbon_python_sdk-0.1.9/carbon/model/chunks_and_embeddings.py
--rw-r--r--   0        0        0     4319 2024-03-14 20:19:21.720361 carbon_python_sdk-0.1.9/carbon/model/chunks_and_embeddings.pyi
--rw-r--r--   0        0        0     1100 2024-03-14 20:19:21.720493 carbon_python_sdk-0.1.9/carbon/model/chunks_and_embeddings_embedding.py
--rw-r--r--   0        0        0     1100 2024-03-14 20:19:21.720649 carbon_python_sdk-0.1.9/carbon/model/chunks_and_embeddings_embedding.pyi
--rw-r--r--   0        0        0     6383 2024-03-14 20:19:21.720856 carbon_python_sdk-0.1.9/carbon/model/chunks_and_embeddings_upload_input.py
--rw-r--r--   0        0        0     6383 2024-03-14 20:19:21.721048 carbon_python_sdk-0.1.9/carbon/model/chunks_and_embeddings_upload_input.pyi
--rw-r--r--   0        0        0      548 2024-03-14 20:19:21.721190 carbon_python_sdk-0.1.9/carbon/model/configuration_keys.py
--rw-r--r--   0        0        0      548 2024-03-14 20:19:21.721341 carbon_python_sdk-0.1.9/carbon/model/configuration_keys.pyi
--rw-r--r--   0        0        0     4861 2024-03-14 20:21:24.396788 carbon_python_sdk-0.1.9/carbon/model/confluence_authentication.py
--rw-r--r--   0        0        0     4861 2024-03-14 20:21:24.396935 carbon_python_sdk-0.1.9/carbon/model/confluence_authentication.pyi
--rw-r--r--   0        0        0     6151 2024-03-14 20:21:24.397087 carbon_python_sdk-0.1.9/carbon/model/connect_data_source_input.py
--rw-r--r--   0        0        0     6151 2024-03-14 20:21:24.397235 carbon_python_sdk-0.1.9/carbon/model/connect_data_source_input.pyi
--rw-r--r--   0        0        0     3763 2024-03-14 20:21:24.397326 carbon_python_sdk-0.1.9/carbon/model/connect_data_source_response.py
--rw-r--r--   0        0        0     3763 2024-03-14 20:21:24.397407 carbon_python_sdk-0.1.9/carbon/model/connect_data_source_response.pyi
--rw-r--r--   0        0        0     1183 2024-03-14 20:19:21.722462 carbon_python_sdk-0.1.9/carbon/model/data_source_last_sync_actions.py
--rw-r--r--   0        0        0      998 2024-03-14 20:19:21.722574 carbon_python_sdk-0.1.9/carbon/model/data_source_last_sync_actions.pyi
--rw-r--r--   0        0        0     1256 2024-03-14 20:19:21.722931 carbon_python_sdk-0.1.9/carbon/model/data_source_sync_statuses.py
--rw-r--r--   0        0        0     1033 2024-03-14 20:19:21.723086 carbon_python_sdk-0.1.9/carbon/model/data_source_sync_statuses.pyi
--rw-r--r--   0        0        0     5534 2024-03-14 20:19:21.723280 carbon_python_sdk-0.1.9/carbon/model/data_source_type.py
--rw-r--r--   0        0        0     4143 2024-03-14 20:19:21.723473 carbon_python_sdk-0.1.9/carbon/model/data_source_type.pyi
--rw-r--r--   0        0        0     5909 2024-03-14 20:19:21.723676 carbon_python_sdk-0.1.9/carbon/model/data_source_type_nullable.py
--rw-r--r--   0        0        0     5909 2024-03-14 20:19:21.723887 carbon_python_sdk-0.1.9/carbon/model/data_source_type_nullable.pyi
--rw-r--r--   0        0        0     6047 2024-03-14 20:19:21.724087 carbon_python_sdk-0.1.9/carbon/model/delete_files_query_input.py
--rw-r--r--   0        0        0     6047 2024-03-14 20:19:21.724293 carbon_python_sdk-0.1.9/carbon/model/delete_files_query_input.pyi
--rw-r--r--   0        0        0     1097 2024-03-14 20:19:21.724430 carbon_python_sdk-0.1.9/carbon/model/delete_files_query_input_file_ids.py
--rw-r--r--   0        0        0     1097 2024-03-14 20:19:21.724742 carbon_python_sdk-0.1.9/carbon/model/delete_files_query_input_file_ids.pyi
--rw-r--r--   0        0        0     2600 2024-03-14 20:19:21.724972 carbon_python_sdk-0.1.9/carbon/model/delete_users_input.py
--rw-r--r--   0        0        0     2600 2024-03-14 20:19:21.725105 carbon_python_sdk-0.1.9/carbon/model/delete_users_input.pyi
--rw-r--r--   0        0        0     1199 2024-03-14 20:19:21.725254 carbon_python_sdk-0.1.9/carbon/model/delete_users_input_customer_ids.py
--rw-r--r--   0        0        0     1199 2024-03-14 20:19:21.725398 carbon_python_sdk-0.1.9/carbon/model/delete_users_input_customer_ids.pyi
--rw-r--r--   0        0        0     3902 2024-03-14 20:19:21.725522 carbon_python_sdk-0.1.9/carbon/model/directory_item.py
--rw-r--r--   0        0        0     3902 2024-03-14 20:19:21.725699 carbon_python_sdk-0.1.9/carbon/model/directory_item.pyi
--rw-r--r--   0        0        0    13554 2024-03-14 20:19:21.725847 carbon_python_sdk-0.1.9/carbon/model/document_response.py
--rw-r--r--   0        0        0    13554 2024-03-14 20:19:21.726157 carbon_python_sdk-0.1.9/carbon/model/document_response.pyi
--rw-r--r--   0        0        0     3350 2024-03-14 20:19:21.726671 carbon_python_sdk-0.1.9/carbon/model/document_response_list.py
--rw-r--r--   0        0        0     3350 2024-03-14 20:19:21.726896 carbon_python_sdk-0.1.9/carbon/model/document_response_list.pyi
--rw-r--r--   0        0        0     7489 2024-03-14 20:19:21.727124 carbon_python_sdk-0.1.9/carbon/model/document_response_tags.py
--rw-r--r--   0        0        0     7489 2024-03-14 20:19:21.727347 carbon_python_sdk-0.1.9/carbon/model/document_response_tags.pyi
--rw-r--r--   0        0        0     1088 2024-03-14 20:19:21.727504 carbon_python_sdk-0.1.9/carbon/model/document_response_vector.py
--rw-r--r--   0        0        0     1088 2024-03-14 20:19:21.727618 carbon_python_sdk-0.1.9/carbon/model/document_response_vector.pyi
--rw-r--r--   0        0        0     5044 2024-03-14 20:19:21.727796 carbon_python_sdk-0.1.9/carbon/model/embedding_and_chunk.py
--rw-r--r--   0        0        0     5044 2024-03-14 20:19:21.727979 carbon_python_sdk-0.1.9/carbon/model/embedding_and_chunk.pyi
--rw-r--r--   0        0        0     1096 2024-03-14 20:19:21.728103 carbon_python_sdk-0.1.9/carbon/model/embedding_and_chunk_embedding.py
--rw-r--r--   0        0        0     1096 2024-03-14 20:19:21.728214 carbon_python_sdk-0.1.9/carbon/model/embedding_and_chunk_embedding.pyi
--rw-r--r--   0        0        0     3025 2024-03-14 20:19:21.728317 carbon_python_sdk-0.1.9/carbon/model/embedding_generators.py
--rw-r--r--   0        0        0     2166 2024-03-14 20:19:21.728460 carbon_python_sdk-0.1.9/carbon/model/embedding_generators.pyi
--rw-r--r--   0        0        0     3405 2024-03-14 20:19:21.728781 carbon_python_sdk-0.1.9/carbon/model/embedding_generators_nullable.py
--rw-r--r--   0        0        0     3405 2024-03-14 20:19:21.728978 carbon_python_sdk-0.1.9/carbon/model/embedding_generators_nullable.pyi
--rw-r--r--   0        0        0     4307 2024-03-14 20:19:21.729172 carbon_python_sdk-0.1.9/carbon/model/embedding_properties.py
--rw-r--r--   0        0        0     4307 2024-03-14 20:19:21.729351 carbon_python_sdk-0.1.9/carbon/model/embedding_properties.pyi
--rw-r--r--   0        0        0     3267 2024-03-14 20:19:21.729474 carbon_python_sdk-0.1.9/carbon/model/embeddings_and_chunks_filters.py
--rw-r--r--   0        0        0     3267 2024-03-14 20:19:21.729773 carbon_python_sdk-0.1.9/carbon/model/embeddings_and_chunks_filters.pyi
--rw-r--r--   0        0        0     1141 2024-03-14 20:19:21.730158 carbon_python_sdk-0.1.9/carbon/model/embeddings_and_chunks_order_by_columns.py
--rw-r--r--   0        0        0      956 2024-03-14 20:19:21.730413 carbon_python_sdk-0.1.9/carbon/model/embeddings_and_chunks_order_by_columns.pyi
--rw-r--r--   0        0        0     5194 2024-03-14 20:19:21.730629 carbon_python_sdk-0.1.9/carbon/model/embeddings_and_chunks_query_input.py
--rw-r--r--   0        0        0     5194 2024-03-14 20:19:21.730833 carbon_python_sdk-0.1.9/carbon/model/embeddings_and_chunks_query_input.pyi
--rw-r--r--   0        0        0     3847 2024-03-14 20:19:21.731194 carbon_python_sdk-0.1.9/carbon/model/embeddings_and_chunks_response.py
--rw-r--r--   0        0        0     3847 2024-03-14 20:19:21.731344 carbon_python_sdk-0.1.9/carbon/model/embeddings_and_chunks_response.pyi
--rw-r--r--   0        0        0     1944 2024-03-14 20:19:21.731466 carbon_python_sdk-0.1.9/carbon/model/external_file_sync_statuses.py
--rw-r--r--   0        0        0     1503 2024-03-14 20:19:21.731784 carbon_python_sdk-0.1.9/carbon/model/external_file_sync_statuses.pyi
--rw-r--r--   0        0        0    16741 2024-03-14 20:19:21.731945 carbon_python_sdk-0.1.9/carbon/model/external_source_item.py
--rw-r--r--   0        0        0    16741 2024-03-14 20:19:21.732128 carbon_python_sdk-0.1.9/carbon/model/external_source_item.pyi
--rw-r--r--   0        0        0     3061 2024-03-14 20:19:21.732301 carbon_python_sdk-0.1.9/carbon/model/fetch_urls_response.py
--rw-r--r--   0        0        0     3061 2024-03-14 20:19:21.732438 carbon_python_sdk-0.1.9/carbon/model/fetch_urls_response.pyi
--rw-r--r--   0        0        0     1187 2024-03-14 20:19:21.732549 carbon_python_sdk-0.1.9/carbon/model/fetch_urls_response_urls.py
--rw-r--r--   0        0        0     1187 2024-03-14 20:19:21.732663 carbon_python_sdk-0.1.9/carbon/model/fetch_urls_response_urls.pyi
--rw-r--r--   0        0        0      946 2024-03-14 20:19:21.732782 carbon_python_sdk-0.1.9/carbon/model/file_content_types.py
--rw-r--r--   0        0        0      825 2024-03-14 20:19:21.732888 carbon_python_sdk-0.1.9/carbon/model/file_content_types.pyi
--rw-r--r--   0        0        0     1706 2024-03-14 20:19:21.733162 carbon_python_sdk-0.1.9/carbon/model/file_content_types_nullable.py
--rw-r--r--   0        0        0     1706 2024-03-14 20:19:21.733321 carbon_python_sdk-0.1.9/carbon/model/file_content_types_nullable.pyi
--rw-r--r--   0        0        0     4851 2024-03-14 20:19:21.733582 carbon_python_sdk-0.1.9/carbon/model/file_formats.py
--rw-r--r--   0        0        0     3650 2024-03-14 20:19:21.733878 carbon_python_sdk-0.1.9/carbon/model/file_formats.pyi
--rw-r--r--   0        0        0     5223 2024-03-14 20:19:21.734132 carbon_python_sdk-0.1.9/carbon/model/file_formats_nullable.py
--rw-r--r--   0        0        0     5223 2024-03-14 20:19:21.734330 carbon_python_sdk-0.1.9/carbon/model/file_formats_nullable.pyi
--rw-r--r--   0        0        0     7489 2024-03-14 20:19:21.734537 carbon_python_sdk-0.1.9/carbon/model/file_statistics.py
--rw-r--r--   0        0        0     7489 2024-03-14 20:19:21.734721 carbon_python_sdk-0.1.9/carbon/model/file_statistics.pyi
--rw-r--r--   0        0        0     6952 2024-03-14 20:19:21.734902 carbon_python_sdk-0.1.9/carbon/model/file_statistics_nullable.py
--rw-r--r--   0        0        0     6952 2024-03-14 20:19:21.735087 carbon_python_sdk-0.1.9/carbon/model/file_statistics_nullable.pyi
--rw-r--r--   0        0        0     1283 2024-03-14 20:19:21.735300 carbon_python_sdk-0.1.9/carbon/model/files_query_user_files_deprecated_response.py
--rw-r--r--   0        0        0     1283 2024-03-14 20:19:21.735671 carbon_python_sdk-0.1.9/carbon/model/files_query_user_files_deprecated_response.pyi
--rw-r--r--   0        0        0    12927 2024-03-14 20:19:21.735836 carbon_python_sdk-0.1.9/carbon/model/fresh_desk_connect_request.py
--rw-r--r--   0        0        0    12927 2024-03-14 20:19:21.736216 carbon_python_sdk-0.1.9/carbon/model/fresh_desk_connect_request.pyi
--rw-r--r--   0        0        0     3529 2024-03-14 20:21:24.397501 carbon_python_sdk-0.1.9/carbon/model/freskdesk_authentication.py
--rw-r--r--   0        0        0     3529 2024-03-14 20:21:24.397587 carbon_python_sdk-0.1.9/carbon/model/freskdesk_authentication.pyi
--rw-r--r--   0        0        0     2362 2024-03-14 20:19:21.737422 carbon_python_sdk-0.1.9/carbon/model/generic_success_response.py
--rw-r--r--   0        0        0     2362 2024-03-14 20:19:21.737621 carbon_python_sdk-0.1.9/carbon/model/generic_success_response.pyi
--rw-r--r--   0        0        0    15093 2024-03-14 20:19:21.737746 carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body.py
--rw-r--r--   0        0        0    14942 2024-03-14 20:19:21.738016 carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body.pyi
--rw-r--r--   0        0        0     1159 2024-03-14 20:19:21.738267 carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body_file_ids.py
--rw-r--r--   0        0        0     1159 2024-03-14 20:19:21.738410 carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body_file_ids.pyi
--rw-r--r--   0        0        0     1264 2024-03-14 20:19:21.738527 carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body_parent_file_ids.py
--rw-r--r--   0        0        0     1264 2024-03-14 20:19:21.738646 carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body_parent_file_ids.pyi
--rw-r--r--   0        0        0     1377 2024-03-14 20:19:21.738761 carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body_query_vector.py
--rw-r--r--   0        0        0     1377 2024-03-14 20:19:21.738877 carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body_query_vector.pyi
--rw-r--r--   0        0        0     6490 2024-03-14 20:19:21.739064 carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body_tags.py
--rw-r--r--   0        0        0     6490 2024-03-14 20:19:21.739249 carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body_tags.pyi
--rw-r--r--   0        0        0     3779 2024-03-14 20:21:24.397661 carbon_python_sdk-0.1.9/carbon/model/gitbook_authetication.py
--rw-r--r--   0        0        0     3779 2024-03-14 20:21:24.397734 carbon_python_sdk-0.1.9/carbon/model/gitbook_authetication.pyi
--rw-r--r--   0        0        0    13042 2024-03-14 20:19:21.739622 carbon_python_sdk-0.1.9/carbon/model/gitbook_connect_request.py
--rw-r--r--   0        0        0    13042 2024-03-14 20:19:21.739885 carbon_python_sdk-0.1.9/carbon/model/gitbook_connect_request.pyi
--rw-r--r--   0        0        0    11852 2024-03-14 20:19:21.740125 carbon_python_sdk-0.1.9/carbon/model/gitbook_sync_request.py
--rw-r--r--   0        0        0    11852 2024-03-14 20:19:21.740450 carbon_python_sdk-0.1.9/carbon/model/gitbook_sync_request.pyi
--rw-r--r--   0        0        0     1220 2024-03-14 20:19:21.740666 carbon_python_sdk-0.1.9/carbon/model/gitbook_sync_request_space_ids.py
--rw-r--r--   0        0        0     1197 2024-03-14 20:19:21.740785 carbon_python_sdk-0.1.9/carbon/model/gitbook_sync_request_space_ids.pyi
--rw-r--r--   0        0        0    12263 2024-03-14 20:19:21.740898 carbon_python_sdk-0.1.9/carbon/model/gmail_sync_input.py
--rw-r--r--   0        0        0    12263 2024-03-14 20:19:21.741092 carbon_python_sdk-0.1.9/carbon/model/gmail_sync_input.pyi
--rw-r--r--   0        0        0     3251 2024-03-14 20:19:21.741281 carbon_python_sdk-0.1.9/carbon/model/http_validation_error.py
--rw-r--r--   0        0        0     3251 2024-03-14 20:19:21.741391 carbon_python_sdk-0.1.9/carbon/model/http_validation_error.pyi
--rw-r--r--   0        0        0     2974 2024-03-14 20:19:21.741499 carbon_python_sdk-0.1.9/carbon/model/hybrid_search_tuning_params.py
--rw-r--r--   0        0        0     2974 2024-03-14 20:19:21.741607 carbon_python_sdk-0.1.9/carbon/model/hybrid_search_tuning_params.pyi
--rw-r--r--   0        0        0     2907 2024-03-14 20:19:21.741731 carbon_python_sdk-0.1.9/carbon/model/hybrid_search_tuning_params_nullable.py
--rw-r--r--   0        0        0     2907 2024-03-14 20:19:21.741851 carbon_python_sdk-0.1.9/carbon/model/hybrid_search_tuning_params_nullable.pyi
--rw-r--r--   0        0        0     4274 2024-03-14 20:19:21.742036 carbon_python_sdk-0.1.9/carbon/model/list_data_source_items_request.py
--rw-r--r--   0        0        0     4274 2024-03-14 20:19:21.742216 carbon_python_sdk-0.1.9/carbon/model/list_data_source_items_request.pyi
--rw-r--r--   0        0        0     3820 2024-03-14 20:19:21.742320 carbon_python_sdk-0.1.9/carbon/model/list_data_source_items_response.py
--rw-r--r--   0        0        0     3820 2024-03-14 20:19:21.742429 carbon_python_sdk-0.1.9/carbon/model/list_data_source_items_response.pyi
--rw-r--r--   0        0        0     3613 2024-03-14 20:19:21.742536 carbon_python_sdk-0.1.9/carbon/model/list_request.py
--rw-r--r--   0        0        0     3613 2024-03-14 20:19:21.742640 carbon_python_sdk-0.1.9/carbon/model/list_request.pyi
--rw-r--r--   0        0        0     3228 2024-03-14 20:19:21.742813 carbon_python_sdk-0.1.9/carbon/model/list_response.py
--rw-r--r--   0        0        0     3228 2024-03-14 20:19:21.743097 carbon_python_sdk-0.1.9/carbon/model/list_response.pyi
--rw-r--r--   0        0        0     3129 2024-03-14 20:19:21.743234 carbon_python_sdk-0.1.9/carbon/model/modify_user_configuration_input.py
--rw-r--r--   0        0        0     3129 2024-03-14 20:19:21.743357 carbon_python_sdk-0.1.9/carbon/model/modify_user_configuration_input.pyi
--rw-r--r--   0        0        0     3699 2024-03-14 20:21:24.397809 carbon_python_sdk-0.1.9/carbon/model/notion_authentication.py
--rw-r--r--   0        0        0     3699 2024-03-14 20:21:24.397890 carbon_python_sdk-0.1.9/carbon/model/notion_authentication.pyi
--rw-r--r--   0        0        0     4300 2024-03-14 20:21:24.398043 carbon_python_sdk-0.1.9/carbon/model/o_auth_authentication.py
--rw-r--r--   0        0        0     4300 2024-03-14 20:21:24.398185 carbon_python_sdk-0.1.9/carbon/model/o_auth_authentication.pyi
--rw-r--r--   0        0        0    23818 2024-03-14 20:19:21.744307 carbon_python_sdk-0.1.9/carbon/model/o_auth_url_request.py
--rw-r--r--   0        0        0    23818 2024-03-14 20:19:21.744451 carbon_python_sdk-0.1.9/carbon/model/o_auth_url_request.pyi
--rw-r--r--   0        0        0      930 2024-03-14 20:19:21.744576 carbon_python_sdk-0.1.9/carbon/model/order_dir.py
--rw-r--r--   0        0        0      813 2024-03-14 20:19:21.744712 carbon_python_sdk-0.1.9/carbon/model/order_dir.pyi
--rw-r--r--   0        0        0    14659 2024-03-14 20:19:21.744844 carbon_python_sdk-0.1.9/carbon/model/organization_response.py
--rw-r--r--   0        0        0    14659 2024-03-14 20:19:21.745174 carbon_python_sdk-0.1.9/carbon/model/organization_response.pyi
--rw-r--r--   0        0        0    13610 2024-03-14 20:21:24.398453 carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_api.py
--rw-r--r--   0        0        0    13610 2024-03-14 20:21:24.398875 carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_api.pyi
--rw-r--r--   0        0        0     4467 2024-03-14 20:19:21.746055 carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_filters.py
--rw-r--r--   0        0        0     4467 2024-03-14 20:19:21.746250 carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_filters.pyi
--rw-r--r--   0        0        0     1113 2024-03-14 20:19:21.746376 carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_filters_ids.py
--rw-r--r--   0        0        0     1113 2024-03-14 20:19:21.746497 carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_filters_ids.pyi
--rw-r--r--   0        0        0     1014 2024-03-14 20:19:21.746606 carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_order_by_columns.py
--rw-r--r--   0        0        0      871 2024-03-14 20:19:21.746720 carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_order_by_columns.pyi
--rw-r--r--   0        0        0     4657 2024-03-14 20:19:21.746920 carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_query_input.py
--rw-r--r--   0        0        0     4657 2024-03-14 20:19:21.747123 carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_query_input.pyi
--rw-r--r--   0        0        0     3947 2024-03-14 20:19:21.747245 carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_response.py
--rw-r--r--   0        0        0     3947 2024-03-14 20:19:21.747357 carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_response.pyi
--rw-r--r--   0        0        0     3408 2024-03-14 20:19:21.747481 carbon_python_sdk-0.1.9/carbon/model/organization_user_file_tag_create.py
--rw-r--r--   0        0        0     3408 2024-03-14 20:19:21.747603 carbon_python_sdk-0.1.9/carbon/model/organization_user_file_tag_create.pyi
--rw-r--r--   0        0        0     6330 2024-03-14 20:19:21.747782 carbon_python_sdk-0.1.9/carbon/model/organization_user_file_tag_create_tags.py
--rw-r--r--   0        0        0     6330 2024-03-14 20:19:21.747962 carbon_python_sdk-0.1.9/carbon/model/organization_user_file_tag_create_tags.pyi
--rw-r--r--   0        0        0     3418 2024-03-14 20:19:21.748092 carbon_python_sdk-0.1.9/carbon/model/organization_user_file_tags_remove.py
--rw-r--r--   0        0        0     3418 2024-03-14 20:19:21.748217 carbon_python_sdk-0.1.9/carbon/model/organization_user_file_tags_remove.pyi
--rw-r--r--   0        0        0     1213 2024-03-14 20:19:21.748396 carbon_python_sdk-0.1.9/carbon/model/organization_user_file_tags_remove_tags.py
--rw-r--r--   0        0        0     1213 2024-03-14 20:19:21.748542 carbon_python_sdk-0.1.9/carbon/model/organization_user_file_tags_remove_tags.pyi
--rw-r--r--   0        0        0    16946 2024-03-14 20:19:21.748689 carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters.py
--rw-r--r--   0        0        0    16946 2024-03-14 20:19:21.749023 carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters.pyi
--rw-r--r--   0        0        0     1139 2024-03-14 20:19:21.749303 carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_external_file_ids.py
--rw-r--r--   0        0        0     1139 2024-03-14 20:19:21.749564 carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_external_file_ids.pyi
--rw-r--r--   0        0        0     1115 2024-03-14 20:19:21.749837 carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_ids.py
--rw-r--r--   0        0        0     1115 2024-03-14 20:19:21.750048 carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_ids.pyi
--rw-r--r--   0        0        0     1165 2024-03-14 20:19:21.750206 carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_organization_user_data_source_id.py
--rw-r--r--   0        0        0     1165 2024-03-14 20:19:21.750349 carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_organization_user_data_source_id.pyi
--rw-r--r--   0        0        0     1135 2024-03-14 20:19:21.750477 carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_parent_file_ids.py
--rw-r--r--   0        0        0     1135 2024-03-14 20:19:21.750604 carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_parent_file_ids.pyi
--rw-r--r--   0        0        0     6420 2024-03-14 20:19:21.750801 carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_tags.py
--rw-r--r--   0        0        0     6420 2024-03-14 20:19:21.751036 carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_tags.pyi
--rw-r--r--   0        0        0     1371 2024-03-14 20:19:21.751182 carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_order_by_types.py
--rw-r--r--   0        0        0     1124 2024-03-14 20:19:21.751314 carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_order_by_types.pyi
--rw-r--r--   0        0        0     8629 2024-03-14 20:19:21.751443 carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_query_input.py
--rw-r--r--   0        0        0     8629 2024-03-14 20:19:21.751788 carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_query_input.pyi
--rw-r--r--   0        0        0     2378 2024-03-14 20:19:21.752074 carbon_python_sdk-0.1.9/carbon/model/outh_url_response.py
--rw-r--r--   0        0        0     2378 2024-03-14 20:19:21.752194 carbon_python_sdk-0.1.9/carbon/model/outh_url_response.pyi
--rw-r--r--   0        0        0    13371 2024-03-14 20:19:21.752354 carbon_python_sdk-0.1.9/carbon/model/outlook_sync_input.py
--rw-r--r--   0        0        0    13371 2024-03-14 20:19:21.752621 carbon_python_sdk-0.1.9/carbon/model/outlook_sync_input.pyi
--rw-r--r--   0        0        0     2807 2024-03-14 20:19:21.752867 carbon_python_sdk-0.1.9/carbon/model/pagination.py
--rw-r--r--   0        0        0     2807 2024-03-14 20:19:21.752975 carbon_python_sdk-0.1.9/carbon/model/pagination.pyi
--rw-r--r--   0        0        0     2452 2024-03-14 20:19:21.753085 carbon_python_sdk-0.1.9/carbon/model/presigned_url_response.py
--rw-r--r--   0        0        0     2452 2024-03-14 20:19:21.753189 carbon_python_sdk-0.1.9/carbon/model/presigned_url_response.pyi
--rw-r--r--   0        0        0    10068 2024-03-14 20:19:21.753404 carbon_python_sdk-0.1.9/carbon/model/raw_text_input.py
--rw-r--r--   0        0        0    10068 2024-03-14 20:19:21.753872 carbon_python_sdk-0.1.9/carbon/model/raw_text_input.pyi
--rw-r--r--   0        0        0     5578 2024-03-14 20:19:21.754304 carbon_python_sdk-0.1.9/carbon/model/resync_file_query_input.py
--rw-r--r--   0        0        0     5578 2024-03-14 20:19:21.754547 carbon_python_sdk-0.1.9/carbon/model/resync_file_query_input.pyi
--rw-r--r--   0        0        0     2489 2024-03-14 20:19:21.754678 carbon_python_sdk-0.1.9/carbon/model/revoke_access_token_input.py
--rw-r--r--   0        0        0     2489 2024-03-14 20:19:21.754789 carbon_python_sdk-0.1.9/carbon/model/revoke_access_token_input.pyi
--rw-r--r--   0        0        0    10916 2024-03-14 20:19:21.754904 carbon_python_sdk-0.1.9/carbon/model/rss_feed_input.py
--rw-r--r--   0        0        0    10916 2024-03-14 20:19:21.755110 carbon_python_sdk-0.1.9/carbon/model/rss_feed_input.pyi
--rw-r--r--   0        0        0     3074 2024-03-14 20:19:21.755306 carbon_python_sdk-0.1.9/carbon/model/s3_auth_request.py
--rw-r--r--   0        0        0     3074 2024-03-14 20:19:21.755424 carbon_python_sdk-0.1.9/carbon/model/s3_auth_request.pyi
--rw-r--r--   0        0        0     3739 2024-03-14 20:21:24.399000 carbon_python_sdk-0.1.9/carbon/model/s3_authentication.py
--rw-r--r--   0        0        0     3739 2024-03-14 20:21:24.399089 carbon_python_sdk-0.1.9/carbon/model/s3_authentication.pyi
--rw-r--r--   0        0        0    15132 2024-03-14 20:19:21.755795 carbon_python_sdk-0.1.9/carbon/model/s3_file_sync_input.py
--rw-r--r--   0        0        0    15132 2024-03-14 20:19:21.756092 carbon_python_sdk-0.1.9/carbon/model/s3_file_sync_input.pyi
--rw-r--r--   0        0        0     3936 2024-03-14 20:19:21.756345 carbon_python_sdk-0.1.9/carbon/model/s3_get_file_input.py
--rw-r--r--   0        0        0     3936 2024-03-14 20:19:21.756458 carbon_python_sdk-0.1.9/carbon/model/s3_get_file_input.pyi
--rw-r--r--   0        0        0     4813 2024-03-14 20:21:24.399249 carbon_python_sdk-0.1.9/carbon/model/salesforce_authentication.py
--rw-r--r--   0        0        0     4813 2024-03-14 20:21:24.399398 carbon_python_sdk-0.1.9/carbon/model/salesforce_authentication.pyi
--rw-r--r--   0        0        0     5449 2024-03-14 20:21:24.399559 carbon_python_sdk-0.1.9/carbon/model/sharepoint_authentication.py
--rw-r--r--   0        0        0     5449 2024-03-14 20:21:24.399710 carbon_python_sdk-0.1.9/carbon/model/sharepoint_authentication.pyi
--rw-r--r--   0        0        0     1566 2024-03-14 20:21:24.399796 carbon_python_sdk-0.1.9/carbon/model/simple_o_auth_data_sources.py
--rw-r--r--   0        0        0     1263 2024-03-14 20:21:24.399879 carbon_python_sdk-0.1.9/carbon/model/simple_o_auth_data_sources.pyi
--rw-r--r--   0        0        0     6587 2024-03-14 20:19:21.757590 carbon_python_sdk-0.1.9/carbon/model/single_chunks_and_embeddings_upload_input.py
--rw-r--r--   0        0        0     6587 2024-03-14 20:19:21.757776 carbon_python_sdk-0.1.9/carbon/model/single_chunks_and_embeddings_upload_input.pyi
--rw-r--r--   0        0        0    15650 2024-03-14 20:21:24.400135 carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request.py
--rw-r--r--   0        0        0    15608 2024-03-14 20:21:24.400418 carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request.pyi
--rw-r--r--   0        0        0     1113 2024-03-14 20:19:21.758376 carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request_css_classes_to_skip.py
--rw-r--r--   0        0        0     1113 2024-03-14 20:19:21.758484 carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request_css_classes_to_skip.pyi
--rw-r--r--   0        0        0     1117 2024-03-14 20:19:21.758601 carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request_css_selectors_to_skip.py
--rw-r--r--   0        0        0     1117 2024-03-14 20:19:21.758718 carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request_css_selectors_to_skip.pyi
--rw-r--r--   0        0        0     1109 2024-03-14 20:19:21.758828 carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request_html_tags_to_skip.py
--rw-r--r--   0        0        0     1109 2024-03-14 20:19:21.758938 carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request_html_tags_to_skip.pyi
--rw-r--r--   0        0        0     6392 2024-03-14 20:19:21.759118 carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request_tags.py
--rw-r--r--   0        0        0     6392 2024-03-14 20:19:21.759296 carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request_tags.pyi
--rw-r--r--   0        0        0     2485 2024-03-14 20:19:21.759403 carbon_python_sdk-0.1.9/carbon/model/sync_directory_request.py
--rw-r--r--   0        0        0     2485 2024-03-14 20:19:21.759508 carbon_python_sdk-0.1.9/carbon/model/sync_directory_request.pyi
--rw-r--r--   0        0        0     2784 2024-03-14 20:19:21.759615 carbon_python_sdk-0.1.9/carbon/model/sync_files_ids.py
--rw-r--r--   0        0        0     2784 2024-03-14 20:19:21.759719 carbon_python_sdk-0.1.9/carbon/model/sync_files_ids.pyi
--rw-r--r--   0        0        0    17722 2024-03-14 20:19:21.759869 carbon_python_sdk-0.1.9/carbon/model/sync_files_request.py
--rw-r--r--   0        0        0    17722 2024-03-14 20:19:21.760015 carbon_python_sdk-0.1.9/carbon/model/sync_files_request.pyi
--rw-r--r--   0        0        0    13129 2024-03-14 20:21:24.400650 carbon_python_sdk-0.1.9/carbon/model/sync_options.py
--rw-r--r--   0        0        0    13129 2024-03-14 20:21:24.400872 carbon_python_sdk-0.1.9/carbon/model/sync_options.pyi
--rw-r--r--   0        0        0     2029 2024-03-14 20:19:21.760642 carbon_python_sdk-0.1.9/carbon/model/text_embedding_generators.py
--rw-r--r--   0        0        0     1520 2024-03-14 20:19:21.760756 carbon_python_sdk-0.1.9/carbon/model/text_embedding_generators.pyi
--rw-r--r--   0        0        0     3042 2024-03-14 20:19:21.760863 carbon_python_sdk-0.1.9/carbon/model/token_response.py
--rw-r--r--   0        0        0     3042 2024-03-14 20:19:21.760971 carbon_python_sdk-0.1.9/carbon/model/token_response.pyi
--rw-r--r--   0        0        0    11472 2024-03-14 20:19:21.761087 carbon_python_sdk-0.1.9/carbon/model/upload_file_from_url_input.py
--rw-r--r--   0        0        0    11472 2024-03-14 20:19:21.761296 carbon_python_sdk-0.1.9/carbon/model/upload_file_from_url_input.pyi
--rw-r--r--   0        0        0    31568 2024-03-14 20:19:21.761508 carbon_python_sdk-0.1.9/carbon/model/user_file.py
--rw-r--r--   0        0        0    31568 2024-03-14 20:19:21.761644 carbon_python_sdk-0.1.9/carbon/model/user_file.pyi
--rw-r--r--   0        0        0     1650 2024-03-14 20:19:21.761767 carbon_python_sdk-0.1.9/carbon/model/user_file_embedding_properties.py
--rw-r--r--   0        0        0     1650 2024-03-14 20:19:21.761875 carbon_python_sdk-0.1.9/carbon/model/user_file_embedding_properties.pyi
--rw-r--r--   0        0        0     3751 2024-03-14 20:19:21.761995 carbon_python_sdk-0.1.9/carbon/model/user_files_v2.py
--rw-r--r--   0        0        0     3751 2024-03-14 20:19:21.762100 carbon_python_sdk-0.1.9/carbon/model/user_files_v2.pyi
--rw-r--r--   0        0        0     2416 2024-03-14 20:19:21.762210 carbon_python_sdk-0.1.9/carbon/model/user_request_content.py
--rw-r--r--   0        0        0     2416 2024-03-14 20:19:21.762320 carbon_python_sdk-0.1.9/carbon/model/user_request_content.pyi
--rw-r--r--   0        0        0    10845 2024-03-14 20:19:21.762433 carbon_python_sdk-0.1.9/carbon/model/user_response.py
--rw-r--r--   0        0        0    10845 2024-03-14 20:19:21.762632 carbon_python_sdk-0.1.9/carbon/model/user_response.pyi
--rw-r--r--   0        0        0     1246 2024-03-14 20:19:21.762859 carbon_python_sdk-0.1.9/carbon/model/user_response_unique_file_tags.py
--rw-r--r--   0        0        0     1246 2024-03-14 20:19:21.762981 carbon_python_sdk-0.1.9/carbon/model/user_response_unique_file_tags.pyi
--rw-r--r--   0        0        0     1315 2024-03-14 20:19:21.763091 carbon_python_sdk-0.1.9/carbon/model/utilities_scrape_web_request.py
--rw-r--r--   0        0        0     1315 2024-03-14 20:19:21.763202 carbon_python_sdk-0.1.9/carbon/model/utilities_scrape_web_request.pyi
--rw-r--r--   0        0        0     3352 2024-03-14 20:19:21.763305 carbon_python_sdk-0.1.9/carbon/model/validation_error.py
--rw-r--r--   0        0        0     3352 2024-03-14 20:19:21.763412 carbon_python_sdk-0.1.9/carbon/model/validation_error.pyi
--rw-r--r--   0        0        0     3149 2024-03-14 20:19:21.763519 carbon_python_sdk-0.1.9/carbon/model/validation_error_loc.py
--rw-r--r--   0        0        0     3149 2024-03-14 20:19:21.763630 carbon_python_sdk-0.1.9/carbon/model/validation_error_loc.pyi
--rw-r--r--   0        0        0     5158 2024-03-14 20:19:21.763809 carbon_python_sdk-0.1.9/carbon/model/webhook.py
--rw-r--r--   0        0        0     5158 2024-03-14 20:19:21.763998 carbon_python_sdk-0.1.9/carbon/model/webhook.pyi
--rw-r--r--   0        0        0     2396 2024-03-14 20:19:21.764120 carbon_python_sdk-0.1.9/carbon/model/webhook_filters.py
--rw-r--r--   0        0        0     2396 2024-03-14 20:19:21.764235 carbon_python_sdk-0.1.9/carbon/model/webhook_filters.pyi
--rw-r--r--   0        0        0     1075 2024-03-14 20:19:21.764395 carbon_python_sdk-0.1.9/carbon/model/webhook_filters_ids.py
--rw-r--r--   0        0        0     1075 2024-03-14 20:19:21.764518 carbon_python_sdk-0.1.9/carbon/model/webhook_filters_ids.pyi
--rw-r--r--   0        0        0     4580 2024-03-14 20:19:21.764706 carbon_python_sdk-0.1.9/carbon/model/webhook_no_key.py
--rw-r--r--   0        0        0     4580 2024-03-14 20:19:21.764928 carbon_python_sdk-0.1.9/carbon/model/webhook_no_key.pyi
--rw-r--r--   0        0        0      995 2024-03-14 20:19:21.765075 carbon_python_sdk-0.1.9/carbon/model/webhook_order_by_columns.py
--rw-r--r--   0        0        0      852 2024-03-14 20:19:21.765220 carbon_python_sdk-0.1.9/carbon/model/webhook_order_by_columns.pyi
--rw-r--r--   0        0        0     4347 2024-03-14 20:19:21.765415 carbon_python_sdk-0.1.9/carbon/model/webhook_query_input.py
--rw-r--r--   0        0        0     4347 2024-03-14 20:19:21.765614 carbon_python_sdk-0.1.9/carbon/model/webhook_query_input.pyi
--rw-r--r--   0        0        0     3798 2024-03-14 20:19:21.765778 carbon_python_sdk-0.1.9/carbon/model/webhook_query_response.py
--rw-r--r--   0        0        0     3798 2024-03-14 20:19:21.765900 carbon_python_sdk-0.1.9/carbon/model/webhook_query_response.pyi
--rw-r--r--   0        0        0    16894 2024-03-14 20:21:24.401013 carbon_python_sdk-0.1.9/carbon/model/webscrape_request.py
--rw-r--r--   0        0        0    16810 2024-03-14 20:21:24.401165 carbon_python_sdk-0.1.9/carbon/model/webscrape_request.pyi
--rw-r--r--   0        0        0     1105 2024-03-14 20:19:21.766551 carbon_python_sdk-0.1.9/carbon/model/webscrape_request_css_classes_to_skip.py
--rw-r--r--   0        0        0     1105 2024-03-14 20:19:21.766679 carbon_python_sdk-0.1.9/carbon/model/webscrape_request_css_classes_to_skip.pyi
--rw-r--r--   0        0        0     1109 2024-03-14 20:19:21.766826 carbon_python_sdk-0.1.9/carbon/model/webscrape_request_css_selectors_to_skip.py
--rw-r--r--   0        0        0     1109 2024-03-14 20:19:21.766949 carbon_python_sdk-0.1.9/carbon/model/webscrape_request_css_selectors_to_skip.pyi
--rw-r--r--   0        0        0     1101 2024-03-14 20:19:21.767069 carbon_python_sdk-0.1.9/carbon/model/webscrape_request_html_tags_to_skip.py
--rw-r--r--   0        0        0     1101 2024-03-14 20:19:21.767204 carbon_python_sdk-0.1.9/carbon/model/webscrape_request_html_tags_to_skip.pyi
--rw-r--r--   0        0        0     6384 2024-03-14 20:19:21.767422 carbon_python_sdk-0.1.9/carbon/model/webscrape_request_tags.py
--rw-r--r--   0        0        0     6384 2024-03-14 20:19:21.767648 carbon_python_sdk-0.1.9/carbon/model/webscrape_request_tags.pyi
--rw-r--r--   0        0        0     3117 2024-03-14 20:19:21.767881 carbon_python_sdk-0.1.9/carbon/model/white_labeling_response.py
--rw-r--r--   0        0        0     3117 2024-03-14 20:19:21.768084 carbon_python_sdk-0.1.9/carbon/model/white_labeling_response.pyi
--rw-r--r--   0        0        0     5401 2024-03-14 20:19:21.768365 carbon_python_sdk-0.1.9/carbon/model/youtube_transcript_response.py
--rw-r--r--   0        0        0     5401 2024-03-14 20:19:21.768629 carbon_python_sdk-0.1.9/carbon/model/youtube_transcript_response.pyi
--rw-r--r--   0        0        0     1375 2024-03-14 20:19:21.768813 carbon_python_sdk-0.1.9/carbon/model/youtube_transcript_response_raw_transcript.py
--rw-r--r--   0        0        0     1375 2024-03-14 20:19:21.769014 carbon_python_sdk-0.1.9/carbon/model/youtube_transcript_response_raw_transcript.pyi
--rw-r--r--   0        0        0     3326 2024-03-14 20:19:21.769176 carbon_python_sdk-0.1.9/carbon/model/youtube_transcript_response_raw_transcript_item.py
--rw-r--r--   0        0        0     3326 2024-03-14 20:19:21.769430 carbon_python_sdk-0.1.9/carbon/model/youtube_transcript_response_raw_transcript_item.pyi
--rw-r--r--   0        0        0     3653 2024-03-14 20:21:24.401362 carbon_python_sdk-0.1.9/carbon/model/zendesk_authentication.py
--rw-r--r--   0        0        0     3653 2024-03-14 20:21:24.401483 carbon_python_sdk-0.1.9/carbon/model/zendesk_authentication.pyi
--rw-r--r--   0        0        0     4907 2024-03-14 20:21:24.401650 carbon_python_sdk-0.1.9/carbon/model/zotero_authentication.py
--rw-r--r--   0        0        0     4907 2024-03-14 20:21:24.401808 carbon_python_sdk-0.1.9/carbon/model/zotero_authentication.pyi
--rw-r--r--   0        0        0    11378 2024-03-14 20:21:24.402114 carbon_python_sdk-0.1.9/carbon/models/__init__.py
--rw-r--r--   0        0        0    20672 2024-03-14 20:21:24.402300 carbon_python_sdk-0.1.9/carbon/operation_parameter_map.py
--rw-r--r--   0        0        0     2784 2024-03-14 20:21:24.402483 carbon_python_sdk-0.1.9/carbon/paths/__init__.py
--rw-r--r--   0        0        0      293 2024-03-14 20:19:21.771374 carbon_python_sdk-0.1.9/carbon/paths/add_webhook/__init__.py
--rw-r--r--   0        0        0    13953 2024-03-14 20:19:21.771498 carbon_python_sdk-0.1.9/carbon/paths/add_webhook/post.py
--rw-r--r--   0        0        0    13811 2024-03-14 20:19:21.771847 carbon_python_sdk-0.1.9/carbon/paths/add_webhook/post.pyi
--rw-r--r--   0        0        0      311 2024-03-14 20:19:21.772205 carbon_python_sdk-0.1.9/carbon/paths/auth_v1_access_token/__init__.py
--rw-r--r--   0        0        0    11830 2024-03-14 20:19:21.772319 carbon_python_sdk-0.1.9/carbon/paths/auth_v1_access_token/get.py
--rw-r--r--   0        0        0    11656 2024-03-14 20:19:21.772525 carbon_python_sdk-0.1.9/carbon/paths/auth_v1_access_token/get.pyi
--rw-r--r--   0        0        0      315 2024-03-14 20:19:21.772767 carbon_python_sdk-0.1.9/carbon/paths/auth_v1_white_labeling/__init__.py
--rw-r--r--   0        0        0    11983 2024-03-14 20:19:21.772887 carbon_python_sdk-0.1.9/carbon/paths/auth_v1_white_labeling/get.py
--rw-r--r--   0        0        0    11841 2024-03-14 20:19:21.773104 carbon_python_sdk-0.1.9/carbon/paths/auth_v1_white_labeling/get.pyi
--rw-r--r--   0        0        0      313 2024-03-14 20:19:21.773304 carbon_python_sdk-0.1.9/carbon/paths/create_user_file_tags/__init__.py
--rw-r--r--   0        0        0    15880 2024-03-14 20:19:21.773411 carbon_python_sdk-0.1.9/carbon/paths/create_user_file_tags/post.py
--rw-r--r--   0        0        0    15706 2024-03-14 20:19:21.773671 carbon_python_sdk-0.1.9/carbon/paths/create_user_file_tags/post.pyi
--rw-r--r--   0        0        0      295 2024-03-14 20:19:21.773922 carbon_python_sdk-0.1.9/carbon/paths/delete_files/__init__.py
--rw-r--r--   0        0        0    18977 2024-03-14 20:19:21.774055 carbon_python_sdk-0.1.9/carbon/paths/delete_files/post.py
--rw-r--r--   0        0        0    18803 2024-03-14 20:19:21.774201 carbon_python_sdk-0.1.9/carbon/paths/delete_files/post.pyi
--rw-r--r--   0        0        0      313 2024-03-14 20:19:21.774332 carbon_python_sdk-0.1.9/carbon/paths/delete_user_file_tags/__init__.py
--rw-r--r--   0        0        0    15814 2024-03-14 20:19:21.774478 carbon_python_sdk-0.1.9/carbon/paths/delete_user_file_tags/post.py
--rw-r--r--   0        0        0    15640 2024-03-14 20:19:21.774788 carbon_python_sdk-0.1.9/carbon/paths/delete_user_file_tags/post.pyi
--rw-r--r--   0        0        0      295 2024-03-14 20:19:21.775083 carbon_python_sdk-0.1.9/carbon/paths/delete_users/__init__.py
--rw-r--r--   0        0        0    14904 2024-03-14 20:19:21.775203 carbon_python_sdk-0.1.9/carbon/paths/delete_users/post.py
--rw-r--r--   0        0        0    14762 2024-03-14 20:19:21.775495 carbon_python_sdk-0.1.9/carbon/paths/delete_users/post.pyi
--rw-r--r--   0        0        0      321 2024-03-14 20:19:21.775767 carbon_python_sdk-0.1.9/carbon/paths/delete_webhook_webhook_id/__init__.py
--rw-r--r--   0        0        0    14364 2024-03-14 20:19:21.775886 carbon_python_sdk-0.1.9/carbon/paths/delete_webhook_webhook_id/delete.py
--rw-r--r--   0        0        0    14222 2024-03-14 20:19:21.776144 carbon_python_sdk-0.1.9/carbon/paths/delete_webhook_webhook_id/delete.pyi
--rw-r--r--   0        0        0      307 2024-03-14 20:19:21.776397 carbon_python_sdk-0.1.9/carbon/paths/deletefile_file_id/__init__.py
--rw-r--r--   0        0        0    14552 2024-03-14 20:19:21.776521 carbon_python_sdk-0.1.9/carbon/paths/deletefile_file_id/delete.py
--rw-r--r--   0        0        0    14378 2024-03-14 20:19:21.776772 carbon_python_sdk-0.1.9/carbon/paths/deletefile_file_id/delete.pyi
--rw-r--r--   0        0        0      291 2024-03-14 20:19:21.777027 carbon_python_sdk-0.1.9/carbon/paths/embeddings/__init__.py
--rw-r--r--   0        0        0    28339 2024-03-14 20:19:21.777158 carbon_python_sdk-0.1.9/carbon/paths/embeddings/post.py
--rw-r--r--   0        0        0    28165 2024-03-14 20:19:21.777313 carbon_python_sdk-0.1.9/carbon/paths/embeddings/post.pyi
--rw-r--r--   0        0        0      291 2024-03-14 20:19:21.777440 carbon_python_sdk-0.1.9/carbon/paths/fetch_urls/__init__.py
--rw-r--r--   0        0        0    14466 2024-03-14 20:19:21.777558 carbon_python_sdk-0.1.9/carbon/paths/fetch_urls/get.py
--rw-r--r--   0        0        0    14292 2024-03-14 20:19:21.777835 carbon_python_sdk-0.1.9/carbon/paths/fetch_urls/get.pyi
--rw-r--r--   0        0        0      319 2024-03-14 20:19:21.778084 carbon_python_sdk-0.1.9/carbon/paths/fetch_youtube_transcript/__init__.py
--rw-r--r--   0        0        0    15695 2024-03-14 20:19:21.778198 carbon_python_sdk-0.1.9/carbon/paths/fetch_youtube_transcript/get.py
--rw-r--r--   0        0        0    15521 2024-03-14 20:19:21.778627 carbon_python_sdk-0.1.9/carbon/paths/fetch_youtube_transcript/get.pyi
--rw-r--r--   0        0        0      283 2024-03-14 20:19:21.778895 carbon_python_sdk-0.1.9/carbon/paths/health/__init__.py
--rw-r--r--   0        0        0    10429 2024-03-14 20:19:21.779020 carbon_python_sdk-0.1.9/carbon/paths/health/get.py
--rw-r--r--   0        0        0    10348 2024-03-14 20:19:21.779234 carbon_python_sdk-0.1.9/carbon/paths/health/get.pyi
--rw-r--r--   0        0        0      327 2024-03-14 20:19:21.779444 carbon_python_sdk-0.1.9/carbon/paths/integrations_confluence_list/__init__.py
--rw-r--r--   0        0        0    15289 2024-03-14 20:19:21.779552 carbon_python_sdk-0.1.9/carbon/paths/integrations_confluence_list/post.py
--rw-r--r--   0        0        0    15115 2024-03-14 20:19:21.779797 carbon_python_sdk-0.1.9/carbon/paths/integrations_confluence_list/post.pyi
--rw-r--r--   0        0        0      327 2024-03-14 20:19:21.780051 carbon_python_sdk-0.1.9/carbon/paths/integrations_confluence_sync/__init__.py
--rw-r--r--   0        0        0    24653 2024-03-14 20:19:21.780177 carbon_python_sdk-0.1.9/carbon/paths/integrations_confluence_sync/post.py
--rw-r--r--   0        0        0    24479 2024-03-14 20:19:21.780320 carbon_python_sdk-0.1.9/carbon/paths/integrations_confluence_sync/post.pyi
--rw-r--r--   0        0        0      311 2024-03-14 20:21:24.402578 carbon_python_sdk-0.1.9/carbon/paths/integrations_connect/__init__.py
--rw-r--r--   0        0        0    20264 2024-03-14 20:21:24.402676 carbon_python_sdk-0.1.9/carbon/paths/integrations_connect/post.py
--rw-r--r--   0        0        0    20090 2024-03-14 20:21:24.402793 carbon_python_sdk-0.1.9/carbon/paths/integrations_connect/post.pyi
--rw-r--r--   0        0        0      317 2024-03-14 20:19:21.780878 carbon_python_sdk-0.1.9/carbon/paths/integrations_files_sync/__init__.py
--rw-r--r--   0        0        0    24538 2024-03-14 20:19:21.780999 carbon_python_sdk-0.1.9/carbon/paths/integrations_files_sync/post.py
--rw-r--r--   0        0        0    24364 2024-03-14 20:19:21.781143 carbon_python_sdk-0.1.9/carbon/paths/integrations_files_sync/post.pyi
--rw-r--r--   0        0        0      315 2024-03-14 20:19:21.781273 carbon_python_sdk-0.1.9/carbon/paths/integrations_freshdesk/__init__.py
--rw-r--r--   0        0        0    23357 2024-03-14 20:19:21.781397 carbon_python_sdk-0.1.9/carbon/paths/integrations_freshdesk/post.py
--rw-r--r--   0        0        0    23183 2024-03-14 20:19:21.781533 carbon_python_sdk-0.1.9/carbon/paths/integrations_freshdesk/post.pyi
--rw-r--r--   0        0        0      311 2024-03-14 20:19:21.781655 carbon_python_sdk-0.1.9/carbon/paths/integrations_gitbook/__init__.py
--rw-r--r--   0        0        0    23400 2024-03-14 20:19:21.781782 carbon_python_sdk-0.1.9/carbon/paths/integrations_gitbook/post.py
--rw-r--r--   0        0        0    23226 2024-03-14 20:19:21.781924 carbon_python_sdk-0.1.9/carbon/paths/integrations_gitbook/post.pyi
--rw-r--r--   0        0        0      325 2024-03-14 20:19:21.782051 carbon_python_sdk-0.1.9/carbon/paths/integrations_gitbook_spaces/__init__.py
--rw-r--r--   0        0        0    14816 2024-03-14 20:19:21.782169 carbon_python_sdk-0.1.9/carbon/paths/integrations_gitbook_spaces/get.py
--rw-r--r--   0        0        0    14642 2024-03-14 20:19:21.782421 carbon_python_sdk-0.1.9/carbon/paths/integrations_gitbook_spaces/get.pyi
--rw-r--r--   0        0        0      321 2024-03-14 20:19:21.782671 carbon_python_sdk-0.1.9/carbon/paths/integrations_gitbook_sync/__init__.py
--rw-r--r--   0        0        0    22421 2024-03-14 20:19:21.782796 carbon_python_sdk-0.1.9/carbon/paths/integrations_gitbook_sync/post.py
--rw-r--r--   0        0        0    22247 2024-03-14 20:19:21.782930 carbon_python_sdk-0.1.9/carbon/paths/integrations_gitbook_sync/post.pyi
--rw-r--r--   0        0        0      317 2024-03-14 20:19:21.783056 carbon_python_sdk-0.1.9/carbon/paths/integrations_gmail_sync/__init__.py
--rw-r--r--   0        0        0    22959 2024-03-14 20:19:21.783180 carbon_python_sdk-0.1.9/carbon/paths/integrations_gmail_sync/post.py
--rw-r--r--   0        0        0    22785 2024-03-14 20:19:21.783333 carbon_python_sdk-0.1.9/carbon/paths/integrations_gmail_sync/post.pyi
--rw-r--r--   0        0        0      331 2024-03-14 20:19:21.783456 carbon_python_sdk-0.1.9/carbon/paths/integrations_gmail_user_labels/__init__.py
--rw-r--r--   0        0        0    15340 2024-03-14 20:19:21.783566 carbon_python_sdk-0.1.9/carbon/paths/integrations_gmail_user_labels/get.py
--rw-r--r--   0        0        0    15166 2024-03-14 20:19:21.783817 carbon_python_sdk-0.1.9/carbon/paths/integrations_gmail_user_labels/get.pyi
--rw-r--r--   0        0        0      317 2024-03-14 20:19:21.784060 carbon_python_sdk-0.1.9/carbon/paths/integrations_items_list/__init__.py
--rw-r--r--   0        0        0    16639 2024-03-14 20:19:21.784176 carbon_python_sdk-0.1.9/carbon/paths/integrations_items_list/post.py
--rw-r--r--   0        0        0    16465 2024-03-14 20:19:21.784317 carbon_python_sdk-0.1.9/carbon/paths/integrations_items_list/post.pyi
--rw-r--r--   0        0        0      317 2024-03-14 20:19:21.784451 carbon_python_sdk-0.1.9/carbon/paths/integrations_items_sync/__init__.py
--rw-r--r--   0        0        0    14992 2024-03-14 20:19:21.784566 carbon_python_sdk-0.1.9/carbon/paths/integrations_items_sync/post.py
--rw-r--r--   0        0        0    14818 2024-03-14 20:19:21.784825 carbon_python_sdk-0.1.9/carbon/paths/integrations_items_sync/post.pyi
--rw-r--r--   0        0        0      315 2024-03-14 20:19:21.785081 carbon_python_sdk-0.1.9/carbon/paths/integrations_oauth_url/__init__.py
--rw-r--r--   0        0        0    31689 2024-03-14 20:19:21.785209 carbon_python_sdk-0.1.9/carbon/paths/integrations_oauth_url/post.py
--rw-r--r--   0        0        0    31515 2024-03-14 20:19:21.785363 carbon_python_sdk-0.1.9/carbon/paths/integrations_oauth_url/post.pyi
--rw-r--r--   0        0        0      321 2024-03-14 20:19:21.785509 carbon_python_sdk-0.1.9/carbon/paths/integrations_outlook_sync/__init__.py
--rw-r--r--   0        0        0    23693 2024-03-14 20:19:21.785635 carbon_python_sdk-0.1.9/carbon/paths/integrations_outlook_sync/post.py
--rw-r--r--   0        0        0    23519 2024-03-14 20:19:21.785766 carbon_python_sdk-0.1.9/carbon/paths/integrations_outlook_sync/post.pyi
--rw-r--r--   0        0        0      343 2024-03-14 20:19:21.785984 carbon_python_sdk-0.1.9/carbon/paths/integrations_outlook_user_categories/__init__.py
--rw-r--r--   0        0        0    15590 2024-03-14 20:19:21.786094 carbon_python_sdk-0.1.9/carbon/paths/integrations_outlook_user_categories/get.py
--rw-r--r--   0        0        0    15416 2024-03-14 20:19:21.786351 carbon_python_sdk-0.1.9/carbon/paths/integrations_outlook_user_categories/get.pyi
--rw-r--r--   0        0        0      337 2024-03-14 20:19:21.786631 carbon_python_sdk-0.1.9/carbon/paths/integrations_outlook_user_folders/__init__.py
--rw-r--r--   0        0        0    15371 2024-03-14 20:19:21.786936 carbon_python_sdk-0.1.9/carbon/paths/integrations_outlook_user_folders/get.py
--rw-r--r--   0        0        0    15197 2024-03-14 20:19:21.787214 carbon_python_sdk-0.1.9/carbon/paths/integrations_outlook_user_folders/get.pyi
--rw-r--r--   0        0        0      313 2024-03-14 20:19:21.789328 carbon_python_sdk-0.1.9/carbon/paths/integrations_rss_feed/__init__.py
--rw-r--r--   0        0        0    21466 2024-03-14 20:19:21.789610 carbon_python_sdk-0.1.9/carbon/paths/integrations_rss_feed/post.py
--rw-r--r--   0        0        0    21292 2024-03-14 20:19:21.789829 carbon_python_sdk-0.1.9/carbon/paths/integrations_rss_feed/post.pyi
--rw-r--r--   0        0        0      301 2024-03-14 20:19:21.790045 carbon_python_sdk-0.1.9/carbon/paths/integrations_s3/__init__.py
--rw-r--r--   0        0        0    15336 2024-03-14 20:19:21.790238 carbon_python_sdk-0.1.9/carbon/paths/integrations_s3/post.py
--rw-r--r--   0        0        0    15162 2024-03-14 20:19:21.790720 carbon_python_sdk-0.1.9/carbon/paths/integrations_s3/post.pyi
--rw-r--r--   0        0        0      313 2024-03-14 20:19:21.791079 carbon_python_sdk-0.1.9/carbon/paths/integrations_s3_files/__init__.py
--rw-r--r--   0        0        0    24552 2024-03-14 20:19:21.791338 carbon_python_sdk-0.1.9/carbon/paths/integrations_s3_files/post.py
--rw-r--r--   0        0        0    24378 2024-03-14 20:19:21.791542 carbon_python_sdk-0.1.9/carbon/paths/integrations_s3_files/post.pyi
--rw-r--r--   0        0        0      321 2024-03-14 20:19:21.791783 carbon_python_sdk-0.1.9/carbon/paths/modify_user_configuration/__init__.py
--rw-r--r--   0        0        0    16052 2024-03-14 20:19:21.791964 carbon_python_sdk-0.1.9/carbon/paths/modify_user_configuration/post.py
--rw-r--r--   0        0        0    15878 2024-03-14 20:19:21.792261 carbon_python_sdk-0.1.9/carbon/paths/modify_user_configuration/post.pyi
--rw-r--r--   0        0        0      295 2024-03-14 20:19:21.792642 carbon_python_sdk-0.1.9/carbon/paths/organization/__init__.py
--rw-r--r--   0        0        0    11658 2024-03-14 20:19:21.792888 carbon_python_sdk-0.1.9/carbon/paths/organization/get.py
--rw-r--r--   0        0        0    11516 2024-03-14 20:19:21.793144 carbon_python_sdk-0.1.9/carbon/paths/organization/get.pyi
--rw-r--r--   0        0        0      309 2024-03-14 20:19:21.793397 carbon_python_sdk-0.1.9/carbon/paths/parsed_file_file_id/__init__.py
--rw-r--r--   0        0        0    14654 2024-03-14 20:19:21.793589 carbon_python_sdk-0.1.9/carbon/paths/parsed_file_file_id/get.py
--rw-r--r--   0        0        0    14480 2024-03-14 20:19:21.793911 carbon_python_sdk-0.1.9/carbon/paths/parsed_file_file_id/get.pyi
--rw-r--r--   0        0        0      301 2024-03-14 20:19:21.794322 carbon_python_sdk-0.1.9/carbon/paths/process_sitemap/__init__.py
--rw-r--r--   0        0        0    14363 2024-03-14 20:19:21.794851 carbon_python_sdk-0.1.9/carbon/paths/process_sitemap/get.py
--rw-r--r--   0        0        0    14189 2024-03-14 20:19:21.795238 carbon_python_sdk-0.1.9/carbon/paths/process_sitemap/get.pyi
--rw-r--r--   0        0        0      303 2024-03-14 20:19:21.795661 carbon_python_sdk-0.1.9/carbon/paths/raw_file_file_id/__init__.py
--rw-r--r--   0        0        0    14585 2024-03-14 20:19:21.795951 carbon_python_sdk-0.1.9/carbon/paths/raw_file_file_id/get.py
--rw-r--r--   0        0        0    14411 2024-03-14 20:19:21.796430 carbon_python_sdk-0.1.9/carbon/paths/raw_file_file_id/get.pyi
--rw-r--r--   0        0        0      293 2024-03-14 20:19:21.796791 carbon_python_sdk-0.1.9/carbon/paths/resync_file/__init__.py
--rw-r--r--   0        0        0    16696 2024-03-14 20:19:21.797003 carbon_python_sdk-0.1.9/carbon/paths/resync_file/post.py
--rw-r--r--   0        0        0    16522 2024-03-14 20:19:21.799209 carbon_python_sdk-0.1.9/carbon/paths/resync_file/post.pyi
--rw-r--r--   0        0        0      309 2024-03-14 20:19:21.799489 carbon_python_sdk-0.1.9/carbon/paths/revoke_access_token/__init__.py
--rw-r--r--   0        0        0    14828 2024-03-14 20:19:21.799856 carbon_python_sdk-0.1.9/carbon/paths/revoke_access_token/post.py
--rw-r--r--   0        0        0    14654 2024-03-14 20:19:21.800227 carbon_python_sdk-0.1.9/carbon/paths/revoke_access_token/post.pyi
--rw-r--r--   0        0        0      299 2024-03-14 20:19:21.800634 carbon_python_sdk-0.1.9/carbon/paths/scrape_sitemap/__init__.py
--rw-r--r--   0        0        0    27300 2024-03-14 20:19:21.800889 carbon_python_sdk-0.1.9/carbon/paths/scrape_sitemap/post.py
--rw-r--r--   0        0        0    27126 2024-03-14 20:19:21.801226 carbon_python_sdk-0.1.9/carbon/paths/scrape_sitemap/post.pyi
--rw-r--r--   0        0        0      293 2024-03-14 20:19:21.801484 carbon_python_sdk-0.1.9/carbon/paths/search_urls/__init__.py
--rw-r--r--   0        0        0    14549 2024-03-14 20:19:21.801908 carbon_python_sdk-0.1.9/carbon/paths/search_urls/get.py
--rw-r--r--   0        0        0    14375 2024-03-14 20:19:21.802350 carbon_python_sdk-0.1.9/carbon/paths/search_urls/get.pyi
--rw-r--r--   0        0        0      293 2024-03-14 20:19:21.802765 carbon_python_sdk-0.1.9/carbon/paths/text_chunks/__init__.py
--rw-r--r--   0        0        0    19073 2024-03-14 20:19:21.803018 carbon_python_sdk-0.1.9/carbon/paths/text_chunks/post.py
--rw-r--r--   0        0        0    18899 2024-03-14 20:19:21.803411 carbon_python_sdk-0.1.9/carbon/paths/text_chunks/post.pyi
--rw-r--r--   0        0        0      327 2024-03-14 20:19:21.803607 carbon_python_sdk-0.1.9/carbon/paths/upload_chunks_and_embeddings/__init__.py
--rw-r--r--   0        0        0    19841 2024-03-14 20:19:21.803858 carbon_python_sdk-0.1.9/carbon/paths/upload_chunks_and_embeddings/post.py
--rw-r--r--   0        0        0    19667 2024-03-14 20:19:21.804148 carbon_python_sdk-0.1.9/carbon/paths/upload_chunks_and_embeddings/post.pyi
--rw-r--r--   0        0        0      311 2024-03-14 20:19:21.804395 carbon_python_sdk-0.1.9/carbon/paths/upload_file_from_url/__init__.py
--rw-r--r--   0        0        0    23090 2024-03-14 20:19:21.804659 carbon_python_sdk-0.1.9/carbon/paths/upload_file_from_url/post.py
--rw-r--r--   0        0        0    22916 2024-03-14 20:19:21.804911 carbon_python_sdk-0.1.9/carbon/paths/upload_file_from_url/post.pyi
--rw-r--r--   0        0        0      293 2024-03-14 20:19:21.805101 carbon_python_sdk-0.1.9/carbon/paths/upload_text/__init__.py
--rw-r--r--   0        0        0    20504 2024-03-14 20:19:21.805305 carbon_python_sdk-0.1.9/carbon/paths/upload_text/post.py
--rw-r--r--   0        0        0    20330 2024-03-14 20:19:21.805530 carbon_python_sdk-0.1.9/carbon/paths/upload_text/post.pyi
--rw-r--r--   0        0        0      291 2024-03-14 20:19:21.805673 carbon_python_sdk-0.1.9/carbon/paths/uploadfile/__init__.py
--rw-r--r--   0        0        0    29353 2024-03-14 20:19:21.805807 carbon_python_sdk-0.1.9/carbon/paths/uploadfile/post.py
--rw-r--r--   0        0        0    29179 2024-03-14 20:19:21.805945 carbon_python_sdk-0.1.9/carbon/paths/uploadfile/post.pyi
--rw-r--r--   0        0        0      279 2024-03-14 20:19:21.806066 carbon_python_sdk-0.1.9/carbon/paths/user/__init__.py
--rw-r--r--   0        0        0    14161 2024-03-14 20:19:21.806194 carbon_python_sdk-0.1.9/carbon/paths/user/post.py
--rw-r--r--   0        0        0    14019 2024-03-14 20:19:21.806506 carbon_python_sdk-0.1.9/carbon/paths/user/post.pyi
--rw-r--r--   0        0        0      305 2024-03-14 20:19:21.806807 carbon_python_sdk-0.1.9/carbon/paths/user_data_sources/__init__.py
--rw-r--r--   0        0        0    18865 2024-03-14 20:19:21.806936 carbon_python_sdk-0.1.9/carbon/paths/user_data_sources/post.py
--rw-r--r--   0        0        0    18691 2024-03-14 20:19:21.807083 carbon_python_sdk-0.1.9/carbon/paths/user_data_sources/post.pyi
--rw-r--r--   0        0        0      291 2024-03-14 20:19:21.807211 carbon_python_sdk-0.1.9/carbon/paths/user_files/__init__.py
--rw-r--r--   0        0        0    22374 2024-03-14 20:19:21.807330 carbon_python_sdk-0.1.9/carbon/paths/user_files/post.py
--rw-r--r--   0        0        0    22200 2024-03-14 20:19:21.807477 carbon_python_sdk-0.1.9/carbon/paths/user_files/post.pyi
--rw-r--r--   0        0        0      297 2024-03-14 20:19:21.807608 carbon_python_sdk-0.1.9/carbon/paths/user_files_v2/__init__.py
--rw-r--r--   0        0        0    21370 2024-03-14 20:19:21.807723 carbon_python_sdk-0.1.9/carbon/paths/user_files_v2/post.py
--rw-r--r--   0        0        0    21196 2024-03-14 20:19:21.807848 carbon_python_sdk-0.1.9/carbon/paths/user_files_v2/post.pyi
--rw-r--r--   0        0        0      291 2024-03-14 20:19:21.807965 carbon_python_sdk-0.1.9/carbon/paths/web_scrape/__init__.py
--rw-r--r--   0        0        0    14274 2024-03-14 20:19:21.808080 carbon_python_sdk-0.1.9/carbon/paths/web_scrape/post.py
--rw-r--r--   0        0        0    14100 2024-03-14 20:19:21.808341 carbon_python_sdk-0.1.9/carbon/paths/web_scrape/post.pyi
--rw-r--r--   0        0        0      287 2024-03-14 20:19:21.808598 carbon_python_sdk-0.1.9/carbon/paths/webhooks/__init__.py
--rw-r--r--   0        0        0    17372 2024-03-14 20:19:21.808709 carbon_python_sdk-0.1.9/carbon/paths/webhooks/post.py
--rw-r--r--   0        0        0    17230 2024-03-14 20:19:21.808840 carbon_python_sdk-0.1.9/carbon/paths/webhooks/post.pyi
--rw-r--r--   0        0        0        0 2024-03-14 20:19:21.808998 carbon_python_sdk-0.1.9/carbon/pydantic/__init__.py
--rw-r--r--   0        0        0      496 2024-03-14 20:19:21.809109 carbon_python_sdk-0.1.9/carbon/pydantic/add_webhook_props.py
--rw-r--r--   0        0        0      523 2024-03-14 20:19:21.809214 carbon_python_sdk-0.1.9/carbon/pydantic/body_create_upload_file_uploadfile_post.py
--rw-r--r--   0        0        0      697 2024-03-14 20:19:21.809319 carbon_python_sdk-0.1.9/carbon/pydantic/chunk_properties.py
--rw-r--r--   0        0        0      705 2024-03-14 20:19:21.809424 carbon_python_sdk-0.1.9/carbon/pydantic/chunk_properties_nullable.py
--rw-r--r--   0        0        0      758 2024-03-14 20:19:21.809523 carbon_python_sdk-0.1.9/carbon/pydantic/chunks_and_embeddings.py
--rw-r--r--   0        0        0      457 2024-03-14 20:19:21.809639 carbon_python_sdk-0.1.9/carbon/pydantic/chunks_and_embeddings_embedding.py
--rw-r--r--   0        0        0     1180 2024-03-14 20:19:21.809755 carbon_python_sdk-0.1.9/carbon/pydantic/chunks_and_embeddings_upload_input.py
--rw-r--r--   0        0        0      406 2024-03-14 20:19:21.809863 carbon_python_sdk-0.1.9/carbon/pydantic/configuration_keys.py
--rw-r--r--   0        0        0      772 2024-03-14 20:21:24.402931 carbon_python_sdk-0.1.9/carbon/pydantic/confluence_authentication.py
--rw-r--r--   0        0        0     1635 2024-03-14 20:21:24.403027 carbon_python_sdk-0.1.9/carbon/pydantic/connect_data_source_input.py
--rw-r--r--   0        0        0      702 2024-03-14 20:21:24.403115 carbon_python_sdk-0.1.9/carbon/pydantic/connect_data_source_response.py
--rw-r--r--   0        0        0      444 2024-03-14 20:19:21.810321 carbon_python_sdk-0.1.9/carbon/pydantic/data_source_last_sync_actions.py
--rw-r--r--   0        0        0      460 2024-03-14 20:19:21.810454 carbon_python_sdk-0.1.9/carbon/pydantic/data_source_sync_statuses.py
--rw-r--r--   0        0        0      802 2024-03-14 20:19:21.810592 carbon_python_sdk-0.1.9/carbon/pydantic/data_source_type.py
--rw-r--r--   0        0        0      810 2024-03-14 20:19:21.810707 carbon_python_sdk-0.1.9/carbon/pydantic/data_source_type_nullable.py
--rw-r--r--   0        0        0     1124 2024-03-14 20:19:21.810810 carbon_python_sdk-0.1.9/carbon/pydantic/delete_files_query_input.py
--rw-r--r--   0        0        0      436 2024-03-14 20:19:21.810915 carbon_python_sdk-0.1.9/carbon/pydantic/delete_files_query_input_file_ids.py
--rw-r--r--   0        0        0      627 2024-03-14 20:19:21.811022 carbon_python_sdk-0.1.9/carbon/pydantic/delete_users_input.py
--rw-r--r--   0        0        0      418 2024-03-14 20:19:21.811128 carbon_python_sdk-0.1.9/carbon/pydantic/delete_users_input_customer_ids.py
--rw-r--r--   0        0        0      631 2024-03-14 20:19:21.811228 carbon_python_sdk-0.1.9/carbon/pydantic/directory_item.py
--rw-r--r--   0        0        0     1469 2024-03-14 20:19:21.811329 carbon_python_sdk-0.1.9/carbon/pydantic/document_response.py
--rw-r--r--   0        0        0      602 2024-03-14 20:19:21.811445 carbon_python_sdk-0.1.9/carbon/pydantic/document_response_list.py
--rw-r--r--   0        0        0      399 2024-03-14 20:19:21.811558 carbon_python_sdk-0.1.9/carbon/pydantic/document_response_tags.py
--rw-r--r--   0        0        0      451 2024-03-14 20:19:21.811669 carbon_python_sdk-0.1.9/carbon/pydantic/document_response_vector.py
--rw-r--r--   0        0        0      796 2024-03-14 20:19:21.811799 carbon_python_sdk-0.1.9/carbon/pydantic/embedding_and_chunk.py
--rw-r--r--   0        0        0      455 2024-03-14 20:19:21.811922 carbon_python_sdk-0.1.9/carbon/pydantic/embedding_and_chunk_embedding.py
--rw-r--r--   0        0        0      715 2024-03-14 20:19:21.812031 carbon_python_sdk-0.1.9/carbon/pydantic/embedding_generators.py
--rw-r--r--   0        0        0      723 2024-03-14 20:19:21.812136 carbon_python_sdk-0.1.9/carbon/pydantic/embedding_generators_nullable.py
--rw-r--r--   0        0        0      603 2024-03-14 20:19:21.812236 carbon_python_sdk-0.1.9/carbon/pydantic/embedding_properties.py
--rw-r--r--   0        0        0      717 2024-03-14 20:19:21.812348 carbon_python_sdk-0.1.9/carbon/pydantic/embeddings_and_chunks_filters.py
--rw-r--r--   0        0        0      458 2024-03-14 20:19:21.812459 carbon_python_sdk-0.1.9/carbon/pydantic/embeddings_and_chunks_order_by_columns.py
--rw-r--r--   0        0        0     1159 2024-03-14 20:19:21.812681 carbon_python_sdk-0.1.9/carbon/pydantic/embeddings_and_chunks_query_input.py
--rw-r--r--   0        0        0      648 2024-03-14 20:19:21.812919 carbon_python_sdk-0.1.9/carbon/pydantic/embeddings_and_chunks_response.py
--rw-r--r--   0        0        0      541 2024-03-14 20:19:21.813078 carbon_python_sdk-0.1.9/carbon/pydantic/external_file_sync_statuses.py
--rw-r--r--   0        0        0     1647 2024-03-14 20:19:21.813217 carbon_python_sdk-0.1.9/carbon/pydantic/external_source_item.py
--rw-r--r--   0        0        0      646 2024-03-14 20:19:21.813343 carbon_python_sdk-0.1.9/carbon/pydantic/fetch_urls_response.py
--rw-r--r--   0        0        0      412 2024-03-14 20:19:21.813447 carbon_python_sdk-0.1.9/carbon/pydantic/fetch_urls_response_urls.py
--rw-r--r--   0        0        0      415 2024-03-14 20:19:21.813562 carbon_python_sdk-0.1.9/carbon/pydantic/file_content_types.py
--rw-r--r--   0        0        0      423 2024-03-14 20:19:21.813666 carbon_python_sdk-0.1.9/carbon/pydantic/file_content_types_nullable.py
--rw-r--r--   0        0        0      740 2024-03-14 20:19:21.813779 carbon_python_sdk-0.1.9/carbon/pydantic/file_formats.py
--rw-r--r--   0        0        0      748 2024-03-14 20:19:21.813914 carbon_python_sdk-0.1.9/carbon/pydantic/file_formats_nullable.py
--rw-r--r--   0        0        0      875 2024-03-14 20:19:21.814026 carbon_python_sdk-0.1.9/carbon/pydantic/file_statistics.py
--rw-r--r--   0        0        0      883 2024-03-14 20:19:21.814151 carbon_python_sdk-0.1.9/carbon/pydantic/file_statistics_nullable.py
--rw-r--r--   0        0        0      480 2024-03-14 20:19:21.814292 carbon_python_sdk-0.1.9/carbon/pydantic/files_query_user_files_deprecated_response.py
--rw-r--r--   0        0        0     1566 2024-03-14 20:19:21.814422 carbon_python_sdk-0.1.9/carbon/pydantic/fresh_desk_connect_request.py
--rw-r--r--   0        0        0      660 2024-03-14 20:21:24.403203 carbon_python_sdk-0.1.9/carbon/pydantic/freskdesk_authentication.py
--rw-r--r--   0        0        0      512 2024-03-14 20:19:21.814659 carbon_python_sdk-0.1.9/carbon/pydantic/generic_success_response.py
--rw-r--r--   0        0        0     3076 2024-03-14 20:19:21.814790 carbon_python_sdk-0.1.9/carbon/pydantic/get_embedding_documents_body.py
--rw-r--r--   0        0        0      440 2024-03-14 20:19:21.814923 carbon_python_sdk-0.1.9/carbon/pydantic/get_embedding_documents_body_file_ids.py
--rw-r--r--   0        0        0      446 2024-03-14 20:19:21.815058 carbon_python_sdk-0.1.9/carbon/pydantic/get_embedding_documents_body_parent_file_ids.py
--rw-r--r--   0        0        0      465 2024-03-14 20:19:21.815192 carbon_python_sdk-0.1.9/carbon/pydantic/get_embedding_documents_body_query_vector.py
--rw-r--r--   0        0        0      408 2024-03-14 20:19:21.815356 carbon_python_sdk-0.1.9/carbon/pydantic/get_embedding_documents_body_tags.py
--rw-r--r--   0        0        0      689 2024-03-14 20:21:24.403286 carbon_python_sdk-0.1.9/carbon/pydantic/gitbook_authetication.py
--rw-r--r--   0        0        0     1561 2024-03-14 20:19:21.815614 carbon_python_sdk-0.1.9/carbon/pydantic/gitbook_connect_request.py
--rw-r--r--   0        0        0     1547 2024-03-14 20:19:21.815734 carbon_python_sdk-0.1.9/carbon/pydantic/gitbook_sync_request.py
--rw-r--r--   0        0        0      417 2024-03-14 20:19:21.815860 carbon_python_sdk-0.1.9/carbon/pydantic/gitbook_sync_request_space_ids.py
--rw-r--r--   0        0        0     1554 2024-03-14 20:19:21.815984 carbon_python_sdk-0.1.9/carbon/pydantic/gmail_sync_input.py
--rw-r--r--   0        0        0      615 2024-03-14 20:19:21.816105 carbon_python_sdk-0.1.9/carbon/pydantic/http_validation_error.py
--rw-r--r--   0        0        0      602 2024-03-14 20:19:21.816233 carbon_python_sdk-0.1.9/carbon/pydantic/hybrid_search_tuning_params.py
--rw-r--r--   0        0        0      610 2024-03-14 20:19:21.816370 carbon_python_sdk-0.1.9/carbon/pydantic/hybrid_search_tuning_params_nullable.py
--rw-r--r--   0        0        0      745 2024-03-14 20:19:21.816644 carbon_python_sdk-0.1.9/carbon/pydantic/list_data_source_items_request.py
--rw-r--r--   0        0        0      647 2024-03-14 20:19:21.816832 carbon_python_sdk-0.1.9/carbon/pydantic/list_data_source_items_response.py
--rw-r--r--   0        0        0      601 2024-03-14 20:19:21.816985 carbon_python_sdk-0.1.9/carbon/pydantic/list_request.py
--rw-r--r--   0        0        0      575 2024-03-14 20:19:21.817111 carbon_python_sdk-0.1.9/carbon/pydantic/list_response.py
--rw-r--r--   0        0        0      670 2024-03-14 20:19:21.817245 carbon_python_sdk-0.1.9/carbon/pydantic/modify_user_configuration_input.py
--rw-r--r--   0        0        0      679 2024-03-14 20:21:24.403357 carbon_python_sdk-0.1.9/carbon/pydantic/notion_authentication.py
--rw-r--r--   0        0        0      751 2024-03-14 20:21:24.403440 carbon_python_sdk-0.1.9/carbon/pydantic/o_auth_authentication.py
--rw-r--r--   0        0        0     3224 2024-03-14 20:19:21.817669 carbon_python_sdk-0.1.9/carbon/pydantic/o_auth_url_request.py
--rw-r--r--   0        0        0      405 2024-03-14 20:19:21.817848 carbon_python_sdk-0.1.9/carbon/pydantic/order_dir.py
--rw-r--r--   0        0        0     1874 2024-03-14 20:19:21.817990 carbon_python_sdk-0.1.9/carbon/pydantic/organization_response.py
--rw-r--r--   0        0        0     1724 2024-03-14 20:21:24.403571 carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_data_source_api.py
--rw-r--r--   0        0        0      935 2024-03-14 20:19:21.818255 carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_data_source_filters.py
--rw-r--r--   0        0        0      444 2024-03-14 20:19:21.818383 carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_data_source_filters_ids.py
--rw-r--r--   0        0        0      450 2024-03-14 20:19:21.818516 carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_data_source_order_by_columns.py
--rw-r--r--   0        0        0     1150 2024-03-14 20:19:21.818656 carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_data_source_query_input.py
--rw-r--r--   0        0        0      693 2024-03-14 20:19:21.818789 carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_data_source_response.py
--rw-r--r--   0        0        0      722 2024-03-14 20:19:21.818927 carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_file_tag_create.py
--rw-r--r--   0        0        0      412 2024-03-14 20:19:21.819179 carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_file_tag_create_tags.py
--rw-r--r--   0        0        0      726 2024-03-14 20:19:21.819359 carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_file_tags_remove.py
--rw-r--r--   0        0        0      425 2024-03-14 20:19:21.819494 carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_file_tags_remove_tags.py
--rw-r--r--   0        0        0     2693 2024-03-14 20:19:21.819615 carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_files_to_sync_filters.py
--rw-r--r--   0        0        0      457 2024-03-14 20:19:21.819735 carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_files_to_sync_filters_external_file_ids.py
--rw-r--r--   0        0        0      445 2024-03-14 20:19:21.819872 carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_files_to_sync_filters_ids.py
--rw-r--r--   0        0        0      470 2024-03-14 20:19:21.820070 carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_files_to_sync_filters_organization_user_data_source_id.py
--rw-r--r--   0        0        0      455 2024-03-14 20:19:21.820218 carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_files_to_sync_filters_parent_file_ids.py
--rw-r--r--   0        0        0      417 2024-03-14 20:19:21.820396 carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_files_to_sync_filters_tags.py
--rw-r--r--   0        0        0      483 2024-03-14 20:19:21.820545 carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_files_to_sync_order_by_types.py
--rw-r--r--   0        0        0     1491 2024-03-14 20:19:21.820668 carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_files_to_sync_query_input.py
--rw-r--r--   0        0        0      508 2024-03-14 20:19:21.820773 carbon_python_sdk-0.1.9/carbon/pydantic/outh_url_response.py
--rw-r--r--   0        0        0     1637 2024-03-14 20:19:21.820894 carbon_python_sdk-0.1.9/carbon/pydantic/outlook_sync_input.py
--rw-r--r--   0        0        0      582 2024-03-14 20:19:21.821007 carbon_python_sdk-0.1.9/carbon/pydantic/pagination.py
--rw-r--r--   0        0        0      521 2024-03-14 20:19:21.821121 carbon_python_sdk-0.1.9/carbon/pydantic/presigned_url_response.py
--rw-r--r--   0        0        0     1278 2024-03-14 20:19:21.821242 carbon_python_sdk-0.1.9/carbon/pydantic/raw_text_input.py
--rw-r--r--   0        0        0      798 2024-03-14 20:19:21.821357 carbon_python_sdk-0.1.9/carbon/pydantic/resync_file_query_input.py
--rw-r--r--   0        0        0      525 2024-03-14 20:19:21.821506 carbon_python_sdk-0.1.9/carbon/pydantic/revoke_access_token_input.py
--rw-r--r--   0        0        0     1363 2024-03-14 20:19:21.821714 carbon_python_sdk-0.1.9/carbon/pydantic/rss_feed_input.py
--rw-r--r--   0        0        0      571 2024-03-14 20:19:21.821880 carbon_python_sdk-0.1.9/carbon/pydantic/s3_auth_request.py
--rw-r--r--   0        0        0      681 2024-03-14 20:21:24.403644 carbon_python_sdk-0.1.9/carbon/pydantic/s3_authentication.py
--rw-r--r--   0        0        0     1748 2024-03-14 20:19:21.822276 carbon_python_sdk-0.1.9/carbon/pydantic/s3_file_sync_input.py
--rw-r--r--   0        0        0      614 2024-03-14 20:19:21.822388 carbon_python_sdk-0.1.9/carbon/pydantic/s3_get_file_input.py
--rw-r--r--   0        0        0      766 2024-03-14 20:21:24.403715 carbon_python_sdk-0.1.9/carbon/pydantic/salesforce_authentication.py
--rw-r--r--   0        0        0      823 2024-03-14 20:21:24.403789 carbon_python_sdk-0.1.9/carbon/pydantic/sharepoint_authentication.py
--rw-r--r--   0        0        0      482 2024-03-14 20:21:24.403880 carbon_python_sdk-0.1.9/carbon/pydantic/simple_o_auth_data_sources.py
--rw-r--r--   0        0        0      879 2024-03-14 20:19:21.822916 carbon_python_sdk-0.1.9/carbon/pydantic/single_chunks_and_embeddings_upload_input.py
--rw-r--r--   0        0        0     2274 2024-03-14 20:19:21.823405 carbon_python_sdk-0.1.9/carbon/pydantic/sitemap_scrape_request.py
--rw-r--r--   0        0        0      444 2024-03-14 20:19:21.823629 carbon_python_sdk-0.1.9/carbon/pydantic/sitemap_scrape_request_css_classes_to_skip.py
--rw-r--r--   0        0        0      446 2024-03-14 20:19:21.823786 carbon_python_sdk-0.1.9/carbon/pydantic/sitemap_scrape_request_css_selectors_to_skip.py
--rw-r--r--   0        0        0      442 2024-03-14 20:19:21.823971 carbon_python_sdk-0.1.9/carbon/pydantic/sitemap_scrape_request_html_tags_to_skip.py
--rw-r--r--   0        0        0      403 2024-03-14 20:19:21.824097 carbon_python_sdk-0.1.9/carbon/pydantic/sitemap_scrape_request_tags.py
--rw-r--r--   0        0        0      523 2024-03-14 20:19:21.824256 carbon_python_sdk-0.1.9/carbon/pydantic/sync_directory_request.py
--rw-r--r--   0        0        0      534 2024-03-14 20:19:21.824492 carbon_python_sdk-0.1.9/carbon/pydantic/sync_files_ids.py
--rw-r--r--   0        0        0     1759 2024-03-14 20:19:21.824612 carbon_python_sdk-0.1.9/carbon/pydantic/sync_files_request.py
--rw-r--r--   0        0        0     1940 2024-03-14 20:21:24.403957 carbon_python_sdk-0.1.9/carbon/pydantic/sync_options.py
--rw-r--r--   0        0        0      580 2024-03-14 20:19:21.824831 carbon_python_sdk-0.1.9/carbon/pydantic/text_embedding_generators.py
--rw-r--r--   0        0        0      567 2024-03-14 20:19:21.824936 carbon_python_sdk-0.1.9/carbon/pydantic/token_response.py
--rw-r--r--   0        0        0     1525 2024-03-14 20:19:21.825044 carbon_python_sdk-0.1.9/carbon/pydantic/upload_file_from_url_input.py
--rw-r--r--   0        0        0     3106 2024-03-14 20:19:21.825146 carbon_python_sdk-0.1.9/carbon/pydantic/user_file.py
--rw-r--r--   0        0        0      475 2024-03-14 20:19:21.825255 carbon_python_sdk-0.1.9/carbon/pydantic/user_file_embedding_properties.py
--rw-r--r--   0        0        0      604 2024-03-14 20:19:21.825373 carbon_python_sdk-0.1.9/carbon/pydantic/user_files_v2.py
--rw-r--r--   0        0        0      515 2024-03-14 20:19:21.825483 carbon_python_sdk-0.1.9/carbon/pydantic/user_request_content.py
--rw-r--r--   0        0        0     1343 2024-03-14 20:19:21.825629 carbon_python_sdk-0.1.9/carbon/pydantic/user_response.py
--rw-r--r--   0        0        0      420 2024-03-14 20:19:21.825781 carbon_python_sdk-0.1.9/carbon/pydantic/user_response_unique_file_tags.py
--rw-r--r--   0        0        0      492 2024-03-14 20:19:21.825897 carbon_python_sdk-0.1.9/carbon/pydantic/utilities_scrape_web_request.py
--rw-r--r--   0        0        0      651 2024-03-14 20:19:21.826015 carbon_python_sdk-0.1.9/carbon/pydantic/validation_error.py
--rw-r--r--   0        0        0      454 2024-03-14 20:19:21.826159 carbon_python_sdk-0.1.9/carbon/pydantic/validation_error_loc.py
--rw-r--r--   0        0        0      739 2024-03-14 20:19:21.826267 carbon_python_sdk-0.1.9/carbon/pydantic/webhook.py
--rw-r--r--   0        0        0      598 2024-03-14 20:19:21.826393 carbon_python_sdk-0.1.9/carbon/pydantic/webhook_filters.py
--rw-r--r--   0        0        0      425 2024-03-14 20:19:21.826687 carbon_python_sdk-0.1.9/carbon/pydantic/webhook_filters_ids.py
--rw-r--r--   0        0        0      693 2024-03-14 20:19:21.826929 carbon_python_sdk-0.1.9/carbon/pydantic/webhook_no_key.py
--rw-r--r--   0        0        0      431 2024-03-14 20:19:21.827236 carbon_python_sdk-0.1.9/carbon/pydantic/webhook_order_by_columns.py
--rw-r--r--   0        0        0     1011 2024-03-14 20:19:21.827370 carbon_python_sdk-0.1.9/carbon/pydantic/webhook_query_input.py
--rw-r--r--   0        0        0      626 2024-03-14 20:19:21.827580 carbon_python_sdk-0.1.9/carbon/pydantic/webhook_query_response.py
--rw-r--r--   0        0        0     2317 2024-03-14 20:19:21.827724 carbon_python_sdk-0.1.9/carbon/pydantic/webscrape_request.py
--rw-r--r--   0        0        0      440 2024-03-14 20:19:21.827883 carbon_python_sdk-0.1.9/carbon/pydantic/webscrape_request_css_classes_to_skip.py
--rw-r--r--   0        0        0      442 2024-03-14 20:19:21.828055 carbon_python_sdk-0.1.9/carbon/pydantic/webscrape_request_css_selectors_to_skip.py
--rw-r--r--   0        0        0      438 2024-03-14 20:19:21.828189 carbon_python_sdk-0.1.9/carbon/pydantic/webscrape_request_html_tags_to_skip.py
--rw-r--r--   0        0        0      399 2024-03-14 20:19:21.828313 carbon_python_sdk-0.1.9/carbon/pydantic/webscrape_request_tags.py
--rw-r--r--   0        0        0      664 2024-03-14 20:19:21.828612 carbon_python_sdk-0.1.9/carbon/pydantic/white_labeling_response.py
--rw-r--r--   0        0        0      824 2024-03-14 20:19:21.828778 carbon_python_sdk-0.1.9/carbon/pydantic/youtube_transcript_response.py
--rw-r--r--   0        0        0      604 2024-03-14 20:19:21.828920 carbon_python_sdk-0.1.9/carbon/pydantic/youtube_transcript_response_raw_transcript.py
--rw-r--r--   0        0        0      421 2024-03-14 20:19:21.829046 carbon_python_sdk-0.1.9/carbon/pydantic/youtube_transcript_response_raw_transcript_item.py
--rw-r--r--   0        0        0      674 2024-03-14 20:21:24.404036 carbon_python_sdk-0.1.9/carbon/pydantic/zendesk_authentication.py
--rw-r--r--   0        0        0      785 2024-03-14 20:21:24.404106 carbon_python_sdk-0.1.9/carbon/pydantic/zotero_authentication.py
--rw-r--r--   0        0        0      654 2024-03-14 20:19:21.829722 carbon_python_sdk-0.1.9/carbon/request_after_hook.py
--rw-r--r--   0        0        0      712 2024-03-14 20:19:21.829996 carbon_python_sdk-0.1.9/carbon/request_before_hook.py
--rw-r--r--   0        0        0      677 2024-03-14 20:19:21.830123 carbon_python_sdk-0.1.9/carbon/request_before_url_hook.py
--rw-r--r--   0        0        0    10974 2024-03-14 20:19:21.830264 carbon_python_sdk-0.1.9/carbon/rest.py
--rw-r--r--   0        0        0    96042 2024-03-14 20:19:21.830610 carbon_python_sdk-0.1.9/carbon/schemas.py
--rw-r--r--   0        0        0        0 2024-03-14 20:19:21.830792 carbon_python_sdk-0.1.9/carbon/type/__init__.py
--rw-r--r--   0        0        0      525 2024-03-14 20:19:21.831044 carbon_python_sdk-0.1.9/carbon/type/add_webhook_props.py
--rw-r--r--   0        0        0      627 2024-03-14 20:19:21.831206 carbon_python_sdk-0.1.9/carbon/type/body_create_upload_file_uploadfile_post.py
--rw-r--r--   0        0        0      628 2024-03-14 20:19:21.831489 carbon_python_sdk-0.1.9/carbon/type/chunk_properties.py
--rw-r--r--   0        0        0      668 2024-03-14 20:19:21.831615 carbon_python_sdk-0.1.9/carbon/type/chunk_properties_nullable.py
--rw-r--r--   0        0        0      707 2024-03-14 20:19:21.831897 carbon_python_sdk-0.1.9/carbon/type/chunks_and_embeddings.py
--rw-r--r--   0        0        0      408 2024-03-14 20:19:21.832015 carbon_python_sdk-0.1.9/carbon/type/chunks_and_embeddings_embedding.py
--rw-r--r--   0        0        0     1030 2024-03-14 20:19:21.832128 carbon_python_sdk-0.1.9/carbon/type/chunks_and_embeddings_upload_input.py
--rw-r--r--   0        0        0      322 2024-03-14 20:19:21.832239 carbon_python_sdk-0.1.9/carbon/type/configuration_keys.py
--rw-r--r--   0        0        0      713 2024-03-14 20:21:24.404193 carbon_python_sdk-0.1.9/carbon/type/confluence_authentication.py
--rw-r--r--   0        0        0     1574 2024-03-14 20:21:24.404280 carbon_python_sdk-0.1.9/carbon/type/connect_data_source_input.py
--rw-r--r--   0        0        0      733 2024-03-14 20:21:24.404367 carbon_python_sdk-0.1.9/carbon/type/connect_data_source_response.py
--rw-r--r--   0        0        0      395 2024-03-14 20:19:21.833113 carbon_python_sdk-0.1.9/carbon/type/data_source_last_sync_actions.py
--rw-r--r--   0        0        0      411 2024-03-14 20:19:21.833415 carbon_python_sdk-0.1.9/carbon/type/data_source_sync_statuses.py
--rw-r--r--   0        0        0      753 2024-03-14 20:19:21.833539 carbon_python_sdk-0.1.9/carbon/type/data_source_type.py
--rw-r--r--   0        0        0      761 2024-03-14 20:19:21.833653 carbon_python_sdk-0.1.9/carbon/type/data_source_type_nullable.py
--rw-r--r--   0        0        0      912 2024-03-14 20:19:21.833866 carbon_python_sdk-0.1.9/carbon/type/delete_files_query_input.py
--rw-r--r--   0        0        0      387 2024-03-14 20:19:21.834233 carbon_python_sdk-0.1.9/carbon/type/delete_files_query_input_file_ids.py
--rw-r--r--   0        0        0      647 2024-03-14 20:19:21.834394 carbon_python_sdk-0.1.9/carbon/type/delete_users_input.py
--rw-r--r--   0        0        0      369 2024-03-14 20:19:21.834521 carbon_python_sdk-0.1.9/carbon/type/delete_users_input_customer_ids.py
--rw-r--r--   0        0        0      574 2024-03-14 20:19:21.834638 carbon_python_sdk-0.1.9/carbon/type/directory_item.py
--rw-r--r--   0        0        0     1224 2024-03-14 20:19:21.834817 carbon_python_sdk-0.1.9/carbon/type/document_response.py
--rw-r--r--   0        0        0      641 2024-03-14 20:19:21.834936 carbon_python_sdk-0.1.9/carbon/type/document_response_list.py
--rw-r--r--   0        0        0      350 2024-03-14 20:19:21.835052 carbon_python_sdk-0.1.9/carbon/type/document_response_tags.py
--rw-r--r--   0        0        0      402 2024-03-14 20:19:21.835165 carbon_python_sdk-0.1.9/carbon/type/document_response_vector.py
--rw-r--r--   0        0        0      732 2024-03-14 20:19:21.835280 carbon_python_sdk-0.1.9/carbon/type/embedding_and_chunk.py
--rw-r--r--   0        0        0      406 2024-03-14 20:19:21.835392 carbon_python_sdk-0.1.9/carbon/type/embedding_and_chunk_embedding.py
--rw-r--r--   0        0        0      666 2024-03-14 20:19:21.835501 carbon_python_sdk-0.1.9/carbon/type/embedding_generators.py
--rw-r--r--   0        0        0      674 2024-03-14 20:19:21.835606 carbon_python_sdk-0.1.9/carbon/type/embedding_generators_nullable.py
--rw-r--r--   0        0        0      610 2024-03-14 20:19:21.835712 carbon_python_sdk-0.1.9/carbon/type/embedding_properties.py
--rw-r--r--   0        0        0      711 2024-03-14 20:19:21.835822 carbon_python_sdk-0.1.9/carbon/type/embeddings_and_chunks_filters.py
--rw-r--r--   0        0        0      409 2024-03-14 20:19:21.835935 carbon_python_sdk-0.1.9/carbon/type/embeddings_and_chunks_order_by_columns.py
--rw-r--r--   0        0        0     1008 2024-03-14 20:19:21.836047 carbon_python_sdk-0.1.9/carbon/type/embeddings_and_chunks_query_input.py
--rw-r--r--   0        0        0      694 2024-03-14 20:19:21.836164 carbon_python_sdk-0.1.9/carbon/type/embeddings_and_chunks_response.py
--rw-r--r--   0        0        0      492 2024-03-14 20:19:21.836272 carbon_python_sdk-0.1.9/carbon/type/external_file_sync_statuses.py
--rw-r--r--   0        0        0     1149 2024-03-14 20:19:21.836381 carbon_python_sdk-0.1.9/carbon/type/external_source_item.py
--rw-r--r--   0        0        0      648 2024-03-14 20:19:21.836491 carbon_python_sdk-0.1.9/carbon/type/fetch_urls_response.py
--rw-r--r--   0        0        0      363 2024-03-14 20:19:21.836616 carbon_python_sdk-0.1.9/carbon/type/fetch_urls_response_urls.py
--rw-r--r--   0        0        0      366 2024-03-14 20:19:21.849682 carbon_python_sdk-0.1.9/carbon/type/file_content_types.py
--rw-r--r--   0        0        0      374 2024-03-14 20:19:21.850110 carbon_python_sdk-0.1.9/carbon/type/file_content_types_nullable.py
--rw-r--r--   0        0        0      691 2024-03-14 20:19:21.850253 carbon_python_sdk-0.1.9/carbon/type/file_formats.py
--rw-r--r--   0        0        0      699 2024-03-14 20:19:21.850389 carbon_python_sdk-0.1.9/carbon/type/file_formats_nullable.py
--rw-r--r--   0        0        0      769 2024-03-14 20:19:21.853449 carbon_python_sdk-0.1.9/carbon/type/file_statistics.py
--rw-r--r--   0        0        0      809 2024-03-14 20:19:21.853593 carbon_python_sdk-0.1.9/carbon/type/file_statistics_nullable.py
--rw-r--r--   0        0        0      427 2024-03-14 20:19:21.853741 carbon_python_sdk-0.1.9/carbon/type/files_query_user_files_deprecated_response.py
--rw-r--r--   0        0        0     1117 2024-03-14 20:19:21.853889 carbon_python_sdk-0.1.9/carbon/type/fresh_desk_connect_request.py
--rw-r--r--   0        0        0      669 2024-03-14 20:21:24.404447 carbon_python_sdk-0.1.9/carbon/type/freskdesk_authentication.py
--rw-r--r--   0        0        0      565 2024-03-14 20:19:21.854181 carbon_python_sdk-0.1.9/carbon/type/generic_success_response.py
--rw-r--r--   0        0        0     2436 2024-03-14 20:19:21.854310 carbon_python_sdk-0.1.9/carbon/type/get_embedding_documents_body.py
--rw-r--r--   0        0        0      391 2024-03-14 20:19:21.854455 carbon_python_sdk-0.1.9/carbon/type/get_embedding_documents_body_file_ids.py
--rw-r--r--   0        0        0      397 2024-03-14 20:19:21.854771 carbon_python_sdk-0.1.9/carbon/type/get_embedding_documents_body_parent_file_ids.py
--rw-r--r--   0        0        0      416 2024-03-14 20:19:21.854946 carbon_python_sdk-0.1.9/carbon/type/get_embedding_documents_body_query_vector.py
--rw-r--r--   0        0        0      359 2024-03-14 20:19:21.855084 carbon_python_sdk-0.1.9/carbon/type/get_embedding_documents_body_tags.py
--rw-r--r--   0        0        0      670 2024-03-14 20:21:24.404535 carbon_python_sdk-0.1.9/carbon/type/gitbook_authetication.py
--rw-r--r--   0        0        0     1093 2024-03-14 20:19:21.855332 carbon_python_sdk-0.1.9/carbon/type/gitbook_connect_request.py
--rw-r--r--   0        0        0     1129 2024-03-14 20:19:21.856897 carbon_python_sdk-0.1.9/carbon/type/gitbook_sync_request.py
--rw-r--r--   0        0        0      368 2024-03-14 20:19:21.857016 carbon_python_sdk-0.1.9/carbon/type/gitbook_sync_request_space_ids.py
--rw-r--r--   0        0        0     1103 2024-03-14 20:19:21.857128 carbon_python_sdk-0.1.9/carbon/type/gmail_sync_input.py
--rw-r--r--   0        0        0      630 2024-03-14 20:19:21.857241 carbon_python_sdk-0.1.9/carbon/type/http_validation_error.py
--rw-r--r--   0        0        0      636 2024-03-14 20:19:21.857379 carbon_python_sdk-0.1.9/carbon/type/hybrid_search_tuning_params.py
--rw-r--r--   0        0        0      676 2024-03-14 20:19:21.857540 carbon_python_sdk-0.1.9/carbon/type/hybrid_search_tuning_params_nullable.py
--rw-r--r--   0        0        0      692 2024-03-14 20:19:21.857658 carbon_python_sdk-0.1.9/carbon/type/list_data_source_items_request.py
--rw-r--r--   0        0        0      695 2024-03-14 20:19:21.857787 carbon_python_sdk-0.1.9/carbon/type/list_data_source_items_response.py
--rw-r--r--   0        0        0      543 2024-03-14 20:19:21.857900 carbon_python_sdk-0.1.9/carbon/type/list_request.py
--rw-r--r--   0        0        0      587 2024-03-14 20:19:21.858012 carbon_python_sdk-0.1.9/carbon/type/list_response.py
--rw-r--r--   0        0        0      709 2024-03-14 20:19:21.858126 carbon_python_sdk-0.1.9/carbon/type/modify_user_configuration_input.py
--rw-r--r--   0        0        0      665 2024-03-14 20:21:24.404622 carbon_python_sdk-0.1.9/carbon/type/notion_authentication.py
--rw-r--r--   0        0        0      695 2024-03-14 20:21:24.404699 carbon_python_sdk-0.1.9/carbon/type/o_auth_authentication.py
--rw-r--r--   0        0        0     2183 2024-03-14 20:19:21.858514 carbon_python_sdk-0.1.9/carbon/type/o_auth_url_request.py
--rw-r--r--   0        0        0      356 2024-03-14 20:19:21.858632 carbon_python_sdk-0.1.9/carbon/type/order_dir.py
--rw-r--r--   0        0        0     1494 2024-03-14 20:19:21.858744 carbon_python_sdk-0.1.9/carbon/type/organization_response.py
--rw-r--r--   0        0        0     1359 2024-03-14 20:21:24.404839 carbon_python_sdk-0.1.9/carbon/type/organization_user_data_source_api.py
--rw-r--r--   0        0        0      903 2024-03-14 20:19:21.858988 carbon_python_sdk-0.1.9/carbon/type/organization_user_data_source_filters.py
--rw-r--r--   0        0        0      395 2024-03-14 20:19:21.859100 carbon_python_sdk-0.1.9/carbon/type/organization_user_data_source_filters_ids.py
--rw-r--r--   0        0        0      401 2024-03-14 20:19:21.859231 carbon_python_sdk-0.1.9/carbon/type/organization_user_data_source_order_by_columns.py
--rw-r--r--   0        0        0     1070 2024-03-14 20:19:21.859383 carbon_python_sdk-0.1.9/carbon/type/organization_user_data_source_query_input.py
--rw-r--r--   0        0        0      767 2024-03-14 20:19:21.859531 carbon_python_sdk-0.1.9/carbon/type/organization_user_data_source_response.py
--rw-r--r--   0        0        0      759 2024-03-14 20:19:21.859658 carbon_python_sdk-0.1.9/carbon/type/organization_user_file_tag_create.py
--rw-r--r--   0        0        0      363 2024-03-14 20:19:21.859783 carbon_python_sdk-0.1.9/carbon/type/organization_user_file_tag_create_tags.py
--rw-r--r--   0        0        0      767 2024-03-14 20:19:21.859921 carbon_python_sdk-0.1.9/carbon/type/organization_user_file_tags_remove.py
--rw-r--r--   0        0        0      376 2024-03-14 20:19:21.860138 carbon_python_sdk-0.1.9/carbon/type/organization_user_file_tags_remove_tags.py
--rw-r--r--   0        0        0     2200 2024-03-14 20:19:21.860305 carbon_python_sdk-0.1.9/carbon/type/organization_user_files_to_sync_filters.py
--rw-r--r--   0        0        0      408 2024-03-14 20:19:21.860524 carbon_python_sdk-0.1.9/carbon/type/organization_user_files_to_sync_filters_external_file_ids.py
--rw-r--r--   0        0        0      396 2024-03-14 20:19:21.860689 carbon_python_sdk-0.1.9/carbon/type/organization_user_files_to_sync_filters_ids.py
--rw-r--r--   0        0        0      421 2024-03-14 20:19:21.860821 carbon_python_sdk-0.1.9/carbon/type/organization_user_files_to_sync_filters_organization_user_data_source_id.py
--rw-r--r--   0        0        0      406 2024-03-14 20:19:21.860940 carbon_python_sdk-0.1.9/carbon/type/organization_user_files_to_sync_filters_parent_file_ids.py
--rw-r--r--   0        0        0      368 2024-03-14 20:19:21.861707 carbon_python_sdk-0.1.9/carbon/type/organization_user_files_to_sync_filters_tags.py
--rw-r--r--   0        0        0      434 2024-03-14 20:19:21.863419 carbon_python_sdk-0.1.9/carbon/type/organization_user_files_to_sync_order_by_types.py
--rw-r--r--   0        0        0     1228 2024-03-14 20:19:21.865229 carbon_python_sdk-0.1.9/carbon/type/organization_user_files_to_sync_query_input.py
--rw-r--r--   0        0        0      531 2024-03-14 20:19:21.865400 carbon_python_sdk-0.1.9/carbon/type/outh_url_response.py
--rw-r--r--   0        0        0     1147 2024-03-14 20:19:21.865530 carbon_python_sdk-0.1.9/carbon/type/outlook_sync_input.py
--rw-r--r--   0        0        0      519 2024-03-14 20:19:21.865649 carbon_python_sdk-0.1.9/carbon/type/pagination.py
--rw-r--r--   0        0        0      560 2024-03-14 20:19:21.865781 carbon_python_sdk-0.1.9/carbon/type/presigned_url_response.py
--rw-r--r--   0        0        0      882 2024-03-14 20:19:21.865901 carbon_python_sdk-0.1.9/carbon/type/raw_text_input.py
--rw-r--r--   0        0        0      661 2024-03-14 20:19:21.866026 carbon_python_sdk-0.1.9/carbon/type/resync_file_query_input.py
--rw-r--r--   0        0        0      571 2024-03-14 20:19:21.866147 carbon_python_sdk-0.1.9/carbon/type/revoke_access_token_input.py
--rw-r--r--   0        0        0      963 2024-03-14 20:19:21.866265 carbon_python_sdk-0.1.9/carbon/type/rss_feed_input.py
--rw-r--r--   0        0        0      550 2024-03-14 20:19:21.866403 carbon_python_sdk-0.1.9/carbon/type/s3_auth_request.py
--rw-r--r--   0        0        0      648 2024-03-14 20:21:24.404924 carbon_python_sdk-0.1.9/carbon/type/s3_authentication.py
--rw-r--r--   0        0        0     1180 2024-03-14 20:19:21.866652 carbon_python_sdk-0.1.9/carbon/type/s3_file_sync_input.py
--rw-r--r--   0        0        0      570 2024-03-14 20:19:21.866777 carbon_python_sdk-0.1.9/carbon/type/s3_get_file_input.py
--rw-r--r--   0        0        0      710 2024-03-14 20:21:24.404996 carbon_python_sdk-0.1.9/carbon/type/salesforce_authentication.py
--rw-r--r--   0        0        0      735 2024-03-14 20:21:24.405080 carbon_python_sdk-0.1.9/carbon/type/sharepoint_authentication.py
--rw-r--r--   0        0        0      433 2024-03-14 20:21:24.405169 carbon_python_sdk-0.1.9/carbon/type/simple_o_auth_data_sources.py
--rw-r--r--   0        0        0      830 2024-03-14 20:19:21.867251 carbon_python_sdk-0.1.9/carbon/type/single_chunks_and_embeddings_upload_input.py
--rw-r--r--   0        0        0     1593 2024-03-14 20:19:21.867369 carbon_python_sdk-0.1.9/carbon/type/sitemap_scrape_request.py
--rw-r--r--   0        0        0      395 2024-03-14 20:19:21.867490 carbon_python_sdk-0.1.9/carbon/type/sitemap_scrape_request_css_classes_to_skip.py
--rw-r--r--   0        0        0      397 2024-03-14 20:19:21.867613 carbon_python_sdk-0.1.9/carbon/type/sitemap_scrape_request_css_selectors_to_skip.py
--rw-r--r--   0        0        0      393 2024-03-14 20:19:21.867732 carbon_python_sdk-0.1.9/carbon/type/sitemap_scrape_request_html_tags_to_skip.py
--rw-r--r--   0        0        0      354 2024-03-14 20:19:21.867869 carbon_python_sdk-0.1.9/carbon/type/sitemap_scrape_request_tags.py
--rw-r--r--   0        0        0      561 2024-03-14 20:19:21.867998 carbon_python_sdk-0.1.9/carbon/type/sync_directory_request.py
--rw-r--r--   0        0        0      527 2024-03-14 20:19:21.868130 carbon_python_sdk-0.1.9/carbon/type/sync_files_ids.py
--rw-r--r--   0        0        0     1218 2024-03-14 20:19:21.868250 carbon_python_sdk-0.1.9/carbon/type/sync_files_request.py
--rw-r--r--   0        0        0     1381 2024-03-14 20:21:24.405244 carbon_python_sdk-0.1.9/carbon/type/sync_options.py
--rw-r--r--   0        0        0      531 2024-03-14 20:19:21.868480 carbon_python_sdk-0.1.9/carbon/type/text_embedding_generators.py
--rw-r--r--   0        0        0      548 2024-03-14 20:19:21.868763 carbon_python_sdk-0.1.9/carbon/type/token_response.py
--rw-r--r--   0        0        0      986 2024-03-14 20:19:21.868945 carbon_python_sdk-0.1.9/carbon/type/upload_file_from_url_input.py
--rw-r--r--   0        0        0     2196 2024-03-14 20:19:21.869084 carbon_python_sdk-0.1.9/carbon/type/user_file.py
--rw-r--r--   0        0        0      422 2024-03-14 20:19:21.869222 carbon_python_sdk-0.1.9/carbon/type/user_file_embedding_properties.py
--rw-r--r--   0        0        0      586 2024-03-14 20:19:21.869372 carbon_python_sdk-0.1.9/carbon/type/user_files_v2.py
--rw-r--r--   0        0        0      548 2024-03-14 20:19:21.869506 carbon_python_sdk-0.1.9/carbon/type/user_request_content.py
--rw-r--r--   0        0        0     1017 2024-03-14 20:19:21.869624 carbon_python_sdk-0.1.9/carbon/type/user_response.py
--rw-r--r--   0        0        0      371 2024-03-14 20:19:21.869757 carbon_python_sdk-0.1.9/carbon/type/user_response_unique_file_tags.py
--rw-r--r--   0        0        0      439 2024-03-14 20:19:21.870096 carbon_python_sdk-0.1.9/carbon/type/utilities_scrape_web_request.py
--rw-r--r--   0        0        0      633 2024-03-14 20:19:21.870409 carbon_python_sdk-0.1.9/carbon/type/validation_error.py
--rw-r--r--   0        0        0      405 2024-03-14 20:19:21.870892 carbon_python_sdk-0.1.9/carbon/type/validation_error_loc.py
--rw-r--r--   0        0        0      598 2024-03-14 20:19:21.871039 carbon_python_sdk-0.1.9/carbon/type/webhook.py
--rw-r--r--   0        0        0      596 2024-03-14 20:19:21.871170 carbon_python_sdk-0.1.9/carbon/type/webhook_filters.py
--rw-r--r--   0        0        0      376 2024-03-14 20:19:21.871304 carbon_python_sdk-0.1.9/carbon/type/webhook_filters_ids.py
--rw-r--r--   0        0        0      601 2024-03-14 20:19:21.871423 carbon_python_sdk-0.1.9/carbon/type/webhook_no_key.py
--rw-r--r--   0        0        0      382 2024-03-14 20:19:21.871547 carbon_python_sdk-0.1.9/carbon/type/webhook_order_by_columns.py
--rw-r--r--   0        0        0      855 2024-03-14 20:19:21.871685 carbon_python_sdk-0.1.9/carbon/type/webhook_query_input.py
--rw-r--r--   0        0        0      644 2024-03-14 20:19:21.871838 carbon_python_sdk-0.1.9/carbon/type/webhook_query_response.py
--rw-r--r--   0        0        0     1564 2024-03-14 20:19:21.871980 carbon_python_sdk-0.1.9/carbon/type/webscrape_request.py
--rw-r--r--   0        0        0      391 2024-03-14 20:19:21.872279 carbon_python_sdk-0.1.9/carbon/type/webscrape_request_css_classes_to_skip.py
--rw-r--r--   0        0        0      393 2024-03-14 20:19:21.872422 carbon_python_sdk-0.1.9/carbon/type/webscrape_request_css_selectors_to_skip.py
--rw-r--r--   0        0        0      389 2024-03-14 20:19:21.872562 carbon_python_sdk-0.1.9/carbon/type/webscrape_request_html_tags_to_skip.py
--rw-r--r--   0        0        0      350 2024-03-14 20:19:21.872681 carbon_python_sdk-0.1.9/carbon/type/webscrape_request_tags.py
--rw-r--r--   0        0        0      675 2024-03-14 20:19:21.872805 carbon_python_sdk-0.1.9/carbon/type/white_labeling_response.py
--rw-r--r--   0        0        0      809 2024-03-14 20:19:21.872938 carbon_python_sdk-0.1.9/carbon/type/youtube_transcript_response.py
--rw-r--r--   0        0        0      551 2024-03-14 20:19:21.873072 carbon_python_sdk-0.1.9/carbon/type/youtube_transcript_response_raw_transcript.py
--rw-r--r--   0        0        0      372 2024-03-14 20:19:21.873210 carbon_python_sdk-0.1.9/carbon/type/youtube_transcript_response_raw_transcript_item.py
--rw-r--r--   0        0        0      667 2024-03-14 20:21:24.405345 carbon_python_sdk-0.1.9/carbon/type/zendesk_authentication.py
--rw-r--r--   0        0        0      711 2024-03-14 20:21:24.405453 carbon_python_sdk-0.1.9/carbon/type/zotero_authentication.py
--rw-r--r--   0        0        0      514 2024-03-14 20:19:21.873604 carbon_python_sdk-0.1.9/carbon/type_util.py
--rw-r--r--   0        0        0     3162 2024-03-14 20:19:21.873725 carbon_python_sdk-0.1.9/carbon/validation_metadata.py
--rw-r--r--   0        0        0      736 2024-03-14 20:21:24.405610 carbon_python_sdk-0.1.9/pyproject.toml
--rw-r--r--   0        0        0    95328 1970-01-01 00:00:00.000000 carbon_python_sdk-0.1.9/PKG-INFO
+-rw-r--r--   0        0        0     1081 2024-05-29 00:18:21.457892 carbon_python_sdk-0.2.0/LICENSE
+-rw-r--r--   0        0        0   112746 2024-05-29 00:21:37.940324 carbon_python_sdk-0.2.0/README.md
+-rw-r--r--   0        0        0      675 2024-05-29 00:21:37.940990 carbon_python_sdk-0.2.0/carbon/__init__.py
+-rw-r--r--   0        0        0    76940 2024-05-29 00:21:37.941796 carbon_python_sdk-0.2.0/carbon/api_client.py
+-rw-r--r--   0        0        0      663 2024-05-29 00:18:21.317261 carbon_python_sdk-0.2.0/carbon/api_response.py
+-rw-r--r--   0        0        0      214 2024-05-29 00:18:21.317350 carbon_python_sdk-0.2.0/carbon/apis/__init__.py
+-rw-r--r--   0        0        0    11104 2024-05-29 00:21:37.942975 carbon_python_sdk-0.2.0/carbon/apis/path_to_api.py
+-rw-r--r--   0        0        0      233 2024-05-29 00:18:21.318223 carbon_python_sdk-0.2.0/carbon/apis/paths/__init__.py
+-rw-r--r--   0        0        0      101 2024-05-29 00:18:21.318317 carbon_python_sdk-0.2.0/carbon/apis/paths/add_webhook.py
+-rw-r--r--   0        0        0      114 2024-05-29 00:18:21.318410 carbon_python_sdk-0.2.0/carbon/apis/paths/auth_v1_access_token.py
+-rw-r--r--   0        0        0      118 2024-05-29 00:18:21.318496 carbon_python_sdk-0.2.0/carbon/apis/paths/auth_v1_white_labeling.py
+-rw-r--r--   0        0        0      119 2024-05-29 00:18:21.318577 carbon_python_sdk-0.2.0/carbon/apis/paths/create_user_file_tags.py
+-rw-r--r--   0        0        0      103 2024-05-29 00:18:21.318662 carbon_python_sdk-0.2.0/carbon/apis/paths/delete_files.py
+-rw-r--r--   0        0        0      108 2024-05-29 00:18:21.318743 carbon_python_sdk-0.2.0/carbon/apis/paths/delete_files_v2.py
+-rw-r--r--   0        0        0      119 2024-05-29 00:18:21.318825 carbon_python_sdk-0.2.0/carbon/apis/paths/delete_user_file_tags.py
+-rw-r--r--   0        0        0      103 2024-05-29 00:18:21.318910 carbon_python_sdk-0.2.0/carbon/apis/paths/delete_users.py
+-rw-r--r--   0        0        0      133 2024-05-29 00:18:21.319018 carbon_python_sdk-0.2.0/carbon/apis/paths/delete_webhook_webhook_id.py
+-rw-r--r--   0        0        0      120 2024-05-29 00:18:21.319125 carbon_python_sdk-0.2.0/carbon/apis/paths/deletefile_file_id.py
+-rw-r--r--   0        0        0      100 2024-05-29 00:18:21.319209 carbon_python_sdk-0.2.0/carbon/apis/paths/embeddings.py
+-rw-r--r--   0        0        0       96 2024-05-29 00:18:21.319300 carbon_python_sdk-0.2.0/carbon/apis/paths/fetch_urls.py
+-rw-r--r--   0        0        0      123 2024-05-29 00:18:21.319386 carbon_python_sdk-0.2.0/carbon/apis/paths/fetch_youtube_transcript.py
+-rw-r--r--   0        0        0       89 2024-05-29 00:18:21.319472 carbon_python_sdk-0.2.0/carbon/apis/paths/health.py
+-rw-r--r--   0        0        0      134 2024-05-29 00:18:21.319564 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_confluence_list.py
+-rw-r--r--   0        0        0      134 2024-05-29 00:18:21.319655 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_confluence_sync.py
+-rw-r--r--   0        0        0      119 2024-05-29 00:18:21.319739 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_connect.py
+-rw-r--r--   0        0        0      124 2024-05-29 00:18:21.319825 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_files_sync.py
+-rw-r--r--   0        0        0      123 2024-05-29 00:18:21.319911 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_freshdesk.py
+-rw-r--r--   0        0        0      119 2024-05-29 00:18:21.319998 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_gitbook.py
+-rw-r--r--   0        0        0      129 2024-05-29 00:18:21.320094 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_gitbook_spaces.py
+-rw-r--r--   0        0        0      128 2024-05-29 00:18:21.320187 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_gitbook_sync.py
+-rw-r--r--   0        0        0      117 2024-05-29 00:18:21.320286 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_github.py
+-rw-r--r--   0        0        0      125 2024-05-29 00:18:21.320376 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_github_repos.py
+-rw-r--r--   0        0        0      137 2024-05-29 00:18:21.320463 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_github_sync_repos.py
+-rw-r--r--   0        0        0      124 2024-05-29 00:18:21.320545 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_gmail_sync.py
+-rw-r--r--   0        0        0      134 2024-05-29 00:18:21.320633 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_gmail_user_labels.py
+-rw-r--r--   0        0        0      124 2024-05-29 00:18:21.320720 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_items_list.py
+-rw-r--r--   0        0        0      124 2024-05-29 00:18:21.320808 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_items_sync.py
+-rw-r--r--   0        0        0      122 2024-05-29 00:18:21.320895 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_oauth_url.py
+-rw-r--r--   0        0        0      128 2024-05-29 00:18:21.320981 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_outlook_sync.py
+-rw-r--r--   0        0        0      146 2024-05-29 00:18:21.321071 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_outlook_user_categories.py
+-rw-r--r--   0        0        0      140 2024-05-29 00:18:21.321158 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_outlook_user_folders.py
+-rw-r--r--   0        0        0      120 2024-05-29 00:18:21.321255 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_rss_feed.py
+-rw-r--r--   0        0        0      109 2024-05-29 00:18:21.321341 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_s3.py
+-rw-r--r--   0        0        0      120 2024-05-29 00:18:21.321426 carbon_python_sdk-0.2.0/carbon/apis/paths/integrations_s3_files.py
+-rw-r--r--   0        0        0      128 2024-05-29 00:18:21.321510 carbon_python_sdk-0.2.0/carbon/apis/paths/modify_user_configuration.py
+-rw-r--r--   0        0        0      101 2024-05-29 00:18:21.321592 carbon_python_sdk-0.2.0/carbon/apis/paths/organization.py
+-rw-r--r--   0        0        0      125 2024-05-29 00:21:37.943184 carbon_python_sdk-0.2.0/carbon/apis/paths/organization_statistics.py
+-rw-r--r--   0        0        0      117 2024-05-29 00:18:21.321761 carbon_python_sdk-0.2.0/carbon/apis/paths/organization_update.py
+-rw-r--r--   0        0        0      112 2024-05-29 00:18:21.321851 carbon_python_sdk-0.2.0/carbon/apis/paths/parsed_file_file_id.py
+-rw-r--r--   0        0        0      106 2024-05-29 00:18:21.321935 carbon_python_sdk-0.2.0/carbon/apis/paths/process_sitemap.py
+-rw-r--r--   0        0        0      106 2024-05-29 00:18:21.322014 carbon_python_sdk-0.2.0/carbon/apis/paths/raw_file_file_id.py
+-rw-r--r--   0        0        0      101 2024-05-29 00:18:21.322230 carbon_python_sdk-0.2.0/carbon/apis/paths/resync_file.py
+-rw-r--r--   0        0        0      116 2024-05-29 00:18:21.322325 carbon_python_sdk-0.2.0/carbon/apis/paths/revoke_access_token.py
+-rw-r--r--   0        0        0      107 2024-05-29 00:18:21.322419 carbon_python_sdk-0.2.0/carbon/apis/paths/scrape_sitemap.py
+-rw-r--r--   0        0        0       98 2024-05-29 00:18:21.322502 carbon_python_sdk-0.2.0/carbon/apis/paths/search_urls.py
+-rw-r--r--   0        0        0      101 2024-05-29 00:18:21.322582 carbon_python_sdk-0.2.0/carbon/apis/paths/text_chunks.py
+-rw-r--r--   0        0        0      103 2024-05-29 00:18:21.322659 carbon_python_sdk-0.2.0/carbon/apis/paths/update_users.py
+-rw-r--r--   0        0        0      133 2024-05-29 00:18:21.322746 carbon_python_sdk-0.2.0/carbon/apis/paths/upload_chunks_and_embeddings.py
+-rw-r--r--   0        0        0      117 2024-05-29 00:18:21.322833 carbon_python_sdk-0.2.0/carbon/apis/paths/upload_file_from_url.py
+-rw-r--r--   0        0        0      101 2024-05-29 00:18:21.322921 carbon_python_sdk-0.2.0/carbon/apis/paths/upload_text.py
+-rw-r--r--   0        0        0      100 2024-05-29 00:18:21.323012 carbon_python_sdk-0.2.0/carbon/apis/paths/uploadfile.py
+-rw-r--r--   0        0        0       88 2024-05-29 00:18:21.323096 carbon_python_sdk-0.2.0/carbon/apis/paths/user.py
+-rw-r--r--   0        0        0      112 2024-05-29 00:18:21.323324 carbon_python_sdk-0.2.0/carbon/apis/paths/user_data_sources.py
+-rw-r--r--   0        0        0       99 2024-05-29 00:18:21.323458 carbon_python_sdk-0.2.0/carbon/apis/paths/user_files.py
+-rw-r--r--   0        0        0      104 2024-05-29 00:18:21.323556 carbon_python_sdk-0.2.0/carbon/apis/paths/user_files_v2.py
+-rw-r--r--   0        0        0       99 2024-05-29 00:18:21.323645 carbon_python_sdk-0.2.0/carbon/apis/paths/web_scrape.py
+-rw-r--r--   0        0        0       96 2024-05-29 00:18:21.323738 carbon_python_sdk-0.2.0/carbon/apis/paths/webhooks.py
+-rw-r--r--   0        0        0     2044 2024-05-29 00:21:37.943424 carbon_python_sdk-0.2.0/carbon/apis/tag_to_api.py
+-rw-r--r--   0        0        0      655 2024-05-29 00:21:37.943742 carbon_python_sdk-0.2.0/carbon/apis/tags/__init__.py
+-rw-r--r--   0        0        0      125 2024-05-29 00:18:21.324039 carbon_python_sdk-0.2.0/carbon/apis/tags/auth_api.py
+-rw-r--r--   0        0        0      671 2024-05-29 00:18:21.324125 carbon_python_sdk-0.2.0/carbon/apis/tags/auth_api_generated.py
+-rw-r--r--   0        0        0      493 2024-05-29 00:18:21.324213 carbon_python_sdk-0.2.0/carbon/apis/tags/auth_api_raw.py
+-rw-r--r--   0        0        0      154 2024-05-29 00:18:21.324311 carbon_python_sdk-0.2.0/carbon/apis/tags/data_sources_api.py
+-rw-r--r--   0        0        0      717 2024-05-29 00:18:21.324431 carbon_python_sdk-0.2.0/carbon/apis/tags/data_sources_api_generated.py
+-rw-r--r--   0        0        0      510 2024-05-29 00:18:21.324544 carbon_python_sdk-0.2.0/carbon/apis/tags/data_sources_api_raw.py
+-rw-r--r--   0        0        0      149 2024-05-29 00:18:21.324645 carbon_python_sdk-0.2.0/carbon/apis/tags/embeddings_api.py
+-rw-r--r--   0        0        0      806 2024-05-29 00:18:21.324741 carbon_python_sdk-0.2.0/carbon/apis/tags/embeddings_api_generated.py
+-rw-r--r--   0        0        0      610 2024-05-29 00:18:21.324827 carbon_python_sdk-0.2.0/carbon/apis/tags/embeddings_api_raw.py
+-rw-r--r--   0        0        0      129 2024-05-29 00:18:21.324912 carbon_python_sdk-0.2.0/carbon/apis/tags/files_api.py
+-rw-r--r--   0        0        0     1495 2024-05-29 00:18:21.325001 carbon_python_sdk-0.2.0/carbon/apis/tags/files_api_generated.py
+-rw-r--r--   0        0        0     1379 2024-05-29 00:18:21.325091 carbon_python_sdk-0.2.0/carbon/apis/tags/files_api_raw.py
+-rw-r--r--   0        0        0      133 2024-05-29 00:18:21.325174 carbon_python_sdk-0.2.0/carbon/apis/tags/health_api.py
+-rw-r--r--   0        0        0      558 2024-05-29 00:18:21.325260 carbon_python_sdk-0.2.0/carbon/apis/tags/health_api_generated.py
+-rw-r--r--   0        0        0      366 2024-05-29 00:18:21.325341 carbon_python_sdk-0.2.0/carbon/apis/tags/health_api_raw.py
+-rw-r--r--   0        0        0      157 2024-05-29 00:18:21.325572 carbon_python_sdk-0.2.0/carbon/apis/tags/integrations_api.py
+-rw-r--r--   0        0        0     2493 2024-05-29 00:18:21.325667 carbon_python_sdk-0.2.0/carbon/apis/tags/integrations_api_generated.py
+-rw-r--r--   0        0        0     2403 2024-05-29 00:18:21.325749 carbon_python_sdk-0.2.0/carbon/apis/tags/integrations_api_raw.py
+-rw-r--r--   0        0        0      161 2024-05-29 00:18:21.325832 carbon_python_sdk-0.2.0/carbon/apis/tags/organizations_api.py
+-rw-r--r--   0        0        0      747 2024-05-29 00:21:37.943986 carbon_python_sdk-0.2.0/carbon/apis/tags/organizations_api_generated.py
+-rw-r--r--   0        0        0      539 2024-05-29 00:21:37.944469 carbon_python_sdk-0.2.0/carbon/apis/tags/organizations_api_raw.py
+-rw-r--r--   0        0        0      129 2024-05-29 00:18:21.326637 carbon_python_sdk-0.2.0/carbon/apis/tags/users_api.py
+-rw-r--r--   0        0        0      781 2024-05-29 00:18:21.326717 carbon_python_sdk-0.2.0/carbon/apis/tags/users_api_generated.py
+-rw-r--r--   0        0        0      611 2024-05-29 00:18:21.326799 carbon_python_sdk-0.2.0/carbon/apis/tags/users_api_raw.py
+-rw-r--r--   0        0        0      145 2024-05-29 00:18:21.326883 carbon_python_sdk-0.2.0/carbon/apis/tags/utilities_api.py
+-rw-r--r--   0        0        0      984 2024-05-29 00:18:21.326973 carbon_python_sdk-0.2.0/carbon/apis/tags/utilities_api_generated.py
+-rw-r--r--   0        0        0      810 2024-05-29 00:18:21.327056 carbon_python_sdk-0.2.0/carbon/apis/tags/utilities_api_raw.py
+-rw-r--r--   0        0        0      141 2024-05-29 00:18:21.327139 carbon_python_sdk-0.2.0/carbon/apis/tags/webhooks_api.py
+-rw-r--r--   0        0        0      713 2024-05-29 00:18:21.327230 carbon_python_sdk-0.2.0/carbon/apis/tags/webhooks_api_generated.py
+-rw-r--r--   0        0        0      525 2024-05-29 00:18:21.327321 carbon_python_sdk-0.2.0/carbon/apis/tags/webhooks_api_raw.py
+-rw-r--r--   0        0        0     1986 2024-05-29 00:18:21.327410 carbon_python_sdk-0.2.0/carbon/client.py
+-rw-r--r--   0        0        0     1986 2024-05-29 00:18:21.327496 carbon_python_sdk-0.2.0/carbon/client.pyi
+-rw-r--r--   0        0        0      676 2024-05-29 00:18:21.327576 carbon_python_sdk-0.2.0/carbon/client_custom.py
+-rw-r--r--   0        0        0    17804 2024-05-29 00:21:37.944855 carbon_python_sdk-0.2.0/carbon/configuration.py
+-rw-r--r--   0        0        0     7679 2024-05-29 00:18:21.327814 carbon_python_sdk-0.2.0/carbon/exceptions.py
+-rw-r--r--   0        0        0     2274 2024-05-29 00:18:21.327900 carbon_python_sdk-0.2.0/carbon/exceptions_base.py
+-rw-r--r--   0        0        0      340 2024-05-29 00:18:21.328126 carbon_python_sdk-0.2.0/carbon/model/__init__.py
+-rw-r--r--   0        0        0     2282 2024-05-29 00:18:21.328208 carbon_python_sdk-0.2.0/carbon/model/add_webhook_props.py
+-rw-r--r--   0        0        0     2282 2024-05-29 00:18:21.328294 carbon_python_sdk-0.2.0/carbon/model/add_webhook_props.pyi
+-rw-r--r--   0        0        0     2371 2024-05-29 00:18:21.328389 carbon_python_sdk-0.2.0/carbon/model/body_create_upload_file_uploadfile_post.py
+-rw-r--r--   0        0        0     2371 2024-05-29 00:18:21.328484 carbon_python_sdk-0.2.0/carbon/model/body_create_upload_file_uploadfile_post.pyi
+-rw-r--r--   0        0        0     4752 2024-05-29 00:18:21.328597 carbon_python_sdk-0.2.0/carbon/model/chunk_properties.py
+-rw-r--r--   0        0        0     4752 2024-05-29 00:18:21.328736 carbon_python_sdk-0.2.0/carbon/model/chunk_properties.pyi
+-rw-r--r--   0        0        0     4359 2024-05-29 00:18:21.328830 carbon_python_sdk-0.2.0/carbon/model/chunk_properties_nullable.py
+-rw-r--r--   0        0        0     4359 2024-05-29 00:18:21.328924 carbon_python_sdk-0.2.0/carbon/model/chunk_properties_nullable.pyi
+-rw-r--r--   0        0        0     4319 2024-05-29 00:18:21.329043 carbon_python_sdk-0.2.0/carbon/model/chunks_and_embeddings.py
+-rw-r--r--   0        0        0     4319 2024-05-29 00:18:21.329158 carbon_python_sdk-0.2.0/carbon/model/chunks_and_embeddings.pyi
+-rw-r--r--   0        0        0     1100 2024-05-29 00:18:21.329253 carbon_python_sdk-0.2.0/carbon/model/chunks_and_embeddings_embedding.py
+-rw-r--r--   0        0        0     1100 2024-05-29 00:18:21.329343 carbon_python_sdk-0.2.0/carbon/model/chunks_and_embeddings_embedding.pyi
+-rw-r--r--   0        0        0     6672 2024-05-29 00:18:21.329445 carbon_python_sdk-0.2.0/carbon/model/chunks_and_embeddings_upload_input.py
+-rw-r--r--   0        0        0     6672 2024-05-29 00:18:21.329542 carbon_python_sdk-0.2.0/carbon/model/chunks_and_embeddings_upload_input.pyi
+-rw-r--r--   0        0        0     1521 2024-05-29 00:18:21.329665 carbon_python_sdk-0.2.0/carbon/model/chunks_and_embeddings_upload_input_custom_credentials.py
+-rw-r--r--   0        0        0     1521 2024-05-29 00:18:21.329770 carbon_python_sdk-0.2.0/carbon/model/chunks_and_embeddings_upload_input_custom_credentials.pyi
+-rw-r--r--   0        0        0      548 2024-05-29 00:18:21.329880 carbon_python_sdk-0.2.0/carbon/model/configuration_keys.py
+-rw-r--r--   0        0        0      548 2024-05-29 00:18:21.329982 carbon_python_sdk-0.2.0/carbon/model/configuration_keys.pyi
+-rw-r--r--   0        0        0     4861 2024-05-29 00:18:21.330077 carbon_python_sdk-0.2.0/carbon/model/confluence_authentication.py
+-rw-r--r--   0        0        0     4861 2024-05-29 00:18:21.330294 carbon_python_sdk-0.2.0/carbon/model/confluence_authentication.pyi
+-rw-r--r--   0        0        0     6269 2024-05-29 00:18:21.330424 carbon_python_sdk-0.2.0/carbon/model/connect_data_source_input.py
+-rw-r--r--   0        0        0     6269 2024-05-29 00:18:21.330530 carbon_python_sdk-0.2.0/carbon/model/connect_data_source_input.pyi
+-rw-r--r--   0        0        0     3763 2024-05-29 00:18:21.330633 carbon_python_sdk-0.2.0/carbon/model/connect_data_source_response.py
+-rw-r--r--   0        0        0     3763 2024-05-29 00:18:21.330758 carbon_python_sdk-0.2.0/carbon/model/connect_data_source_response.pyi
+-rw-r--r--   0        0        0     1369 2024-05-29 00:18:21.330868 carbon_python_sdk-0.2.0/carbon/model/custom_credentials_type.py
+-rw-r--r--   0        0        0     1114 2024-05-29 00:18:21.330967 carbon_python_sdk-0.2.0/carbon/model/custom_credentials_type.pyi
+-rw-r--r--   0        0        0      554 2024-05-29 00:18:21.331065 carbon_python_sdk-0.2.0/carbon/model/data_source_extended_input.py
+-rw-r--r--   0        0        0      554 2024-05-29 00:18:21.331157 carbon_python_sdk-0.2.0/carbon/model/data_source_extended_input.pyi
+-rw-r--r--   0        0        0     1183 2024-05-29 00:18:21.331266 carbon_python_sdk-0.2.0/carbon/model/data_source_last_sync_actions.py
+-rw-r--r--   0        0        0      998 2024-05-29 00:18:21.331362 carbon_python_sdk-0.2.0/carbon/model/data_source_last_sync_actions.pyi
+-rw-r--r--   0        0        0     1256 2024-05-29 00:18:21.331454 carbon_python_sdk-0.2.0/carbon/model/data_source_sync_statuses.py
+-rw-r--r--   0        0        0     1033 2024-05-29 00:18:21.331553 carbon_python_sdk-0.2.0/carbon/model/data_source_sync_statuses.pyi
+-rw-r--r--   0        0        0     6578 2024-05-29 00:21:37.945354 carbon_python_sdk-0.2.0/carbon/model/data_source_type.py
+-rw-r--r--   0        0        0     4915 2024-05-29 00:21:37.946477 carbon_python_sdk-0.2.0/carbon/model/data_source_type.pyi
+-rw-r--r--   0        0        0     6953 2024-05-29 00:21:37.946898 carbon_python_sdk-0.2.0/carbon/model/data_source_type_nullable.py
+-rw-r--r--   0        0        0     6953 2024-05-29 00:21:37.947214 carbon_python_sdk-0.2.0/carbon/model/data_source_type_nullable.pyi
+-rw-r--r--   0        0        0     6047 2024-05-29 00:18:21.332134 carbon_python_sdk-0.2.0/carbon/model/delete_files_query_input.py
+-rw-r--r--   0        0        0     6047 2024-05-29 00:18:21.332237 carbon_python_sdk-0.2.0/carbon/model/delete_files_query_input.pyi
+-rw-r--r--   0        0        0     1097 2024-05-29 00:18:21.332547 carbon_python_sdk-0.2.0/carbon/model/delete_files_query_input_file_ids.py
+-rw-r--r--   0        0        0     1097 2024-05-29 00:18:21.332662 carbon_python_sdk-0.2.0/carbon/model/delete_files_query_input_file_ids.pyi
+-rw-r--r--   0        0        0     3161 2024-05-29 00:18:21.332760 carbon_python_sdk-0.2.0/carbon/model/delete_files_v2_query_input.py
+-rw-r--r--   0        0        0     3161 2024-05-29 00:18:21.332857 carbon_python_sdk-0.2.0/carbon/model/delete_files_v2_query_input.pyi
+-rw-r--r--   0        0        0     2600 2024-05-29 00:18:21.332954 carbon_python_sdk-0.2.0/carbon/model/delete_users_input.py
+-rw-r--r--   0        0        0     2600 2024-05-29 00:18:21.333051 carbon_python_sdk-0.2.0/carbon/model/delete_users_input.pyi
+-rw-r--r--   0        0        0     1199 2024-05-29 00:18:21.333149 carbon_python_sdk-0.2.0/carbon/model/delete_users_input_customer_ids.py
+-rw-r--r--   0        0        0     1199 2024-05-29 00:18:21.333241 carbon_python_sdk-0.2.0/carbon/model/delete_users_input_customer_ids.pyi
+-rw-r--r--   0        0        0     3902 2024-05-29 00:18:21.333334 carbon_python_sdk-0.2.0/carbon/model/directory_item.py
+-rw-r--r--   0        0        0     3902 2024-05-29 00:18:21.333428 carbon_python_sdk-0.2.0/carbon/model/directory_item.pyi
+-rw-r--r--   0        0        0    16065 2024-05-29 00:18:21.333528 carbon_python_sdk-0.2.0/carbon/model/document_response.py
+-rw-r--r--   0        0        0    16065 2024-05-29 00:18:21.333704 carbon_python_sdk-0.2.0/carbon/model/document_response.pyi
+-rw-r--r--   0        0        0     3350 2024-05-29 00:18:21.333859 carbon_python_sdk-0.2.0/carbon/model/document_response_list.py
+-rw-r--r--   0        0        0     3350 2024-05-29 00:18:21.333950 carbon_python_sdk-0.2.0/carbon/model/document_response_list.pyi
+-rw-r--r--   0        0        0     7489 2024-05-29 00:18:21.334055 carbon_python_sdk-0.2.0/carbon/model/document_response_tags.py
+-rw-r--r--   0        0        0     7489 2024-05-29 00:18:21.334154 carbon_python_sdk-0.2.0/carbon/model/document_response_tags.pyi
+-rw-r--r--   0        0        0     1088 2024-05-29 00:18:21.334255 carbon_python_sdk-0.2.0/carbon/model/document_response_vector.py
+-rw-r--r--   0        0        0     1088 2024-05-29 00:18:21.334355 carbon_python_sdk-0.2.0/carbon/model/document_response_vector.pyi
+-rw-r--r--   0        0        0     6594 2024-05-29 00:18:21.334458 carbon_python_sdk-0.2.0/carbon/model/embedding_and_chunk.py
+-rw-r--r--   0        0        0     6594 2024-05-29 00:18:21.334558 carbon_python_sdk-0.2.0/carbon/model/embedding_and_chunk.pyi
+-rw-r--r--   0        0        0     1096 2024-05-29 00:18:21.334654 carbon_python_sdk-0.2.0/carbon/model/embedding_and_chunk_embedding.py
+-rw-r--r--   0        0        0     1096 2024-05-29 00:18:21.334747 carbon_python_sdk-0.2.0/carbon/model/embedding_and_chunk_embedding.pyi
+-rw-r--r--   0        0        0     3163 2024-05-29 00:18:21.334845 carbon_python_sdk-0.2.0/carbon/model/embedding_generators.py
+-rw-r--r--   0        0        0     2260 2024-05-29 00:18:21.334941 carbon_python_sdk-0.2.0/carbon/model/embedding_generators.pyi
+-rw-r--r--   0        0        0     3543 2024-05-29 00:18:21.335041 carbon_python_sdk-0.2.0/carbon/model/embedding_generators_nullable.py
+-rw-r--r--   0        0        0     3543 2024-05-29 00:18:21.335135 carbon_python_sdk-0.2.0/carbon/model/embedding_generators_nullable.pyi
+-rw-r--r--   0        0        0     4307 2024-05-29 00:18:21.335240 carbon_python_sdk-0.2.0/carbon/model/embedding_properties.py
+-rw-r--r--   0        0        0     4307 2024-05-29 00:18:21.335341 carbon_python_sdk-0.2.0/carbon/model/embedding_properties.pyi
+-rw-r--r--   0        0        0     3267 2024-05-29 00:18:21.335440 carbon_python_sdk-0.2.0/carbon/model/embeddings_and_chunks_filters.py
+-rw-r--r--   0        0        0     3267 2024-05-29 00:18:21.335541 carbon_python_sdk-0.2.0/carbon/model/embeddings_and_chunks_filters.pyi
+-rw-r--r--   0        0        0     1141 2024-05-29 00:18:21.335637 carbon_python_sdk-0.2.0/carbon/model/embeddings_and_chunks_order_by_columns.py
+-rw-r--r--   0        0        0      956 2024-05-29 00:18:21.335739 carbon_python_sdk-0.2.0/carbon/model/embeddings_and_chunks_order_by_columns.pyi
+-rw-r--r--   0        0        0     5194 2024-05-29 00:18:21.335845 carbon_python_sdk-0.2.0/carbon/model/embeddings_and_chunks_query_input.py
+-rw-r--r--   0        0        0     5194 2024-05-29 00:18:21.335950 carbon_python_sdk-0.2.0/carbon/model/embeddings_and_chunks_query_input.pyi
+-rw-r--r--   0        0        0     3847 2024-05-29 00:18:21.336050 carbon_python_sdk-0.2.0/carbon/model/embeddings_and_chunks_response.py
+-rw-r--r--   0        0        0     3847 2024-05-29 00:18:21.336449 carbon_python_sdk-0.2.0/carbon/model/embeddings_and_chunks_response.pyi
+-rw-r--r--   0        0        0     1944 2024-05-29 00:18:21.336549 carbon_python_sdk-0.2.0/carbon/model/external_file_sync_statuses.py
+-rw-r--r--   0        0        0     1503 2024-05-29 00:18:21.336648 carbon_python_sdk-0.2.0/carbon/model/external_file_sync_statuses.pyi
+-rw-r--r--   0        0        0    17950 2024-05-29 00:18:21.336763 carbon_python_sdk-0.2.0/carbon/model/external_source_item.py
+-rw-r--r--   0        0        0    17950 2024-05-29 00:18:21.336923 carbon_python_sdk-0.2.0/carbon/model/external_source_item.pyi
+-rw-r--r--   0        0        0     1102 2024-05-29 00:18:21.337056 carbon_python_sdk-0.2.0/carbon/model/external_source_items_order_by.py
+-rw-r--r--   0        0        0      933 2024-05-29 00:18:21.337156 carbon_python_sdk-0.2.0/carbon/model/external_source_items_order_by.pyi
+-rw-r--r--   0        0        0     4287 2024-05-29 00:18:21.337259 carbon_python_sdk-0.2.0/carbon/model/fetch_urls_response.py
+-rw-r--r--   0        0        0     4287 2024-05-29 00:18:21.337360 carbon_python_sdk-0.2.0/carbon/model/fetch_urls_response.pyi
+-rw-r--r--   0        0        0     1187 2024-05-29 00:18:21.337457 carbon_python_sdk-0.2.0/carbon/model/fetch_urls_response_urls.py
+-rw-r--r--   0        0        0     1187 2024-05-29 00:18:21.337560 carbon_python_sdk-0.2.0/carbon/model/fetch_urls_response_urls.pyi
+-rw-r--r--   0        0        0     1166 2024-05-29 00:21:37.947432 carbon_python_sdk-0.2.0/carbon/model/file_content_types.py
+-rw-r--r--   0        0        0      985 2024-05-29 00:21:37.947606 carbon_python_sdk-0.2.0/carbon/model/file_content_types.pyi
+-rw-r--r--   0        0        0     1926 2024-05-29 00:21:37.947785 carbon_python_sdk-0.2.0/carbon/model/file_content_types_nullable.py
+-rw-r--r--   0        0        0     1926 2024-05-29 00:21:37.947929 carbon_python_sdk-0.2.0/carbon/model/file_content_types_nullable.pyi
+-rw-r--r--   0        0        0     5789 2024-05-29 00:21:37.948170 carbon_python_sdk-0.2.0/carbon/model/file_formats.py
+-rw-r--r--   0        0        0     4344 2024-05-29 00:21:37.948468 carbon_python_sdk-0.2.0/carbon/model/file_formats.pyi
+-rw-r--r--   0        0        0     6161 2024-05-29 00:21:37.948727 carbon_python_sdk-0.2.0/carbon/model/file_formats_nullable.py
+-rw-r--r--   0        0        0     6161 2024-05-29 00:21:37.948868 carbon_python_sdk-0.2.0/carbon/model/file_formats_nullable.pyi
+-rw-r--r--   0        0        0     8647 2024-05-29 00:18:21.338420 carbon_python_sdk-0.2.0/carbon/model/file_statistics.py
+-rw-r--r--   0        0        0     8647 2024-05-29 00:18:21.338683 carbon_python_sdk-0.2.0/carbon/model/file_statistics.pyi
+-rw-r--r--   0        0        0     8000 2024-05-29 00:18:21.339016 carbon_python_sdk-0.2.0/carbon/model/file_statistics_nullable.py
+-rw-r--r--   0        0        0     8000 2024-05-29 00:18:21.339117 carbon_python_sdk-0.2.0/carbon/model/file_statistics_nullable.pyi
+-rw-r--r--   0        0        0     4847 2024-05-29 00:18:21.339213 carbon_python_sdk-0.2.0/carbon/model/file_sync_config.py
+-rw-r--r--   0        0        0     4847 2024-05-29 00:18:21.339306 carbon_python_sdk-0.2.0/carbon/model/file_sync_config.pyi
+-rw-r--r--   0        0        0     5047 2024-05-29 00:18:21.339408 carbon_python_sdk-0.2.0/carbon/model/file_sync_config_nullable.py
+-rw-r--r--   0        0        0     5047 2024-05-29 00:18:21.339505 carbon_python_sdk-0.2.0/carbon/model/file_sync_config_nullable.pyi
+-rw-r--r--   0        0        0     1283 2024-05-29 00:18:21.339620 carbon_python_sdk-0.2.0/carbon/model/files_query_user_files_deprecated_response.py
+-rw-r--r--   0        0        0     1283 2024-05-29 00:18:21.339724 carbon_python_sdk-0.2.0/carbon/model/files_query_user_files_deprecated_response.pyi
+-rw-r--r--   0        0        0    15514 2024-05-29 00:18:21.339823 carbon_python_sdk-0.2.0/carbon/model/fresh_desk_connect_request.py
+-rw-r--r--   0        0        0    15514 2024-05-29 00:18:21.339975 carbon_python_sdk-0.2.0/carbon/model/fresh_desk_connect_request.pyi
+-rw-r--r--   0        0        0     3529 2024-05-29 00:18:21.340114 carbon_python_sdk-0.2.0/carbon/model/freskdesk_authentication.py
+-rw-r--r--   0        0        0     3529 2024-05-29 00:18:21.340207 carbon_python_sdk-0.2.0/carbon/model/freskdesk_authentication.pyi
+-rw-r--r--   0        0        0     2362 2024-05-29 00:18:21.340302 carbon_python_sdk-0.2.0/carbon/model/generic_success_response.py
+-rw-r--r--   0        0        0     2362 2024-05-29 00:18:21.340405 carbon_python_sdk-0.2.0/carbon/model/generic_success_response.pyi
+-rw-r--r--   0        0        0    15782 2024-05-29 00:18:21.340505 carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body.py
+-rw-r--r--   0        0        0    15631 2024-05-29 00:18:21.340652 carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body.pyi
+-rw-r--r--   0        0        0     1159 2024-05-29 00:18:21.340796 carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body_file_ids.py
+-rw-r--r--   0        0        0     1159 2024-05-29 00:18:21.340889 carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body_file_ids.pyi
+-rw-r--r--   0        0        0     1264 2024-05-29 00:18:21.340976 carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body_parent_file_ids.py
+-rw-r--r--   0        0        0     1264 2024-05-29 00:18:21.341067 carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body_parent_file_ids.pyi
+-rw-r--r--   0        0        0     1377 2024-05-29 00:18:21.341161 carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body_query_vector.py
+-rw-r--r--   0        0        0     1377 2024-05-29 00:18:21.341251 carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body_query_vector.pyi
+-rw-r--r--   0        0        0     6490 2024-05-29 00:18:21.341349 carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body_tags.py
+-rw-r--r--   0        0        0     6490 2024-05-29 00:18:21.341443 carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body_tags.pyi
+-rw-r--r--   0        0        0     3779 2024-05-29 00:18:21.341534 carbon_python_sdk-0.2.0/carbon/model/gitbook_authetication.py
+-rw-r--r--   0        0        0     3779 2024-05-29 00:18:21.341623 carbon_python_sdk-0.2.0/carbon/model/gitbook_authetication.pyi
+-rw-r--r--   0        0        0    14852 2024-05-29 00:18:21.341716 carbon_python_sdk-0.2.0/carbon/model/gitbook_connect_request.py
+-rw-r--r--   0        0        0    14852 2024-05-29 00:18:21.341868 carbon_python_sdk-0.2.0/carbon/model/gitbook_connect_request.pyi
+-rw-r--r--   0        0        0    13012 2024-05-29 00:18:21.342015 carbon_python_sdk-0.2.0/carbon/model/gitbook_sync_request.py
+-rw-r--r--   0        0        0    13012 2024-05-29 00:18:21.342172 carbon_python_sdk-0.2.0/carbon/model/gitbook_sync_request.pyi
+-rw-r--r--   0        0        0     1220 2024-05-29 00:18:21.342324 carbon_python_sdk-0.2.0/carbon/model/gitbook_sync_request_space_ids.py
+-rw-r--r--   0        0        0     1197 2024-05-29 00:18:21.342421 carbon_python_sdk-0.2.0/carbon/model/gitbook_sync_request_space_ids.pyi
+-rw-r--r--   0        0        0     3635 2024-05-29 00:18:21.342510 carbon_python_sdk-0.2.0/carbon/model/github_authentication.py
+-rw-r--r--   0        0        0     3635 2024-05-29 00:18:21.342610 carbon_python_sdk-0.2.0/carbon/model/github_authentication.pyi
+-rw-r--r--   0        0        0     3626 2024-05-29 00:18:21.342709 carbon_python_sdk-0.2.0/carbon/model/github_connect_request.py
+-rw-r--r--   0        0        0     3626 2024-05-29 00:18:21.342808 carbon_python_sdk-0.2.0/carbon/model/github_connect_request.pyi
+-rw-r--r--   0        0        0     3792 2024-05-29 00:18:21.342912 carbon_python_sdk-0.2.0/carbon/model/github_fetch_repos_request.py
+-rw-r--r--   0        0        0     3792 2024-05-29 00:18:21.343021 carbon_python_sdk-0.2.0/carbon/model/github_fetch_repos_request.pyi
+-rw-r--r--   0        0        0     1246 2024-05-29 00:18:21.343127 carbon_python_sdk-0.2.0/carbon/model/github_fetch_repos_request_repos.py
+-rw-r--r--   0        0        0     1201 2024-05-29 00:18:21.343229 carbon_python_sdk-0.2.0/carbon/model/github_fetch_repos_request_repos.pyi
+-rw-r--r--   0        0        0    16085 2024-05-29 00:18:21.343336 carbon_python_sdk-0.2.0/carbon/model/gmail_sync_input.py
+-rw-r--r--   0        0        0    16085 2024-05-29 00:18:21.343494 carbon_python_sdk-0.2.0/carbon/model/gmail_sync_input.pyi
+-rw-r--r--   0        0        0      963 2024-05-29 00:18:21.343655 carbon_python_sdk-0.2.0/carbon/model/helpdesk_file_types.py
+-rw-r--r--   0        0        0      834 2024-05-29 00:18:21.343762 carbon_python_sdk-0.2.0/carbon/model/helpdesk_file_types.pyi
+-rw-r--r--   0        0        0     3251 2024-05-29 00:18:21.343863 carbon_python_sdk-0.2.0/carbon/model/http_validation_error.py
+-rw-r--r--   0        0        0     3251 2024-05-29 00:18:21.344078 carbon_python_sdk-0.2.0/carbon/model/http_validation_error.pyi
+-rw-r--r--   0        0        0     2974 2024-05-29 00:18:21.344186 carbon_python_sdk-0.2.0/carbon/model/hybrid_search_tuning_params.py
+-rw-r--r--   0        0        0     2974 2024-05-29 00:18:21.344283 carbon_python_sdk-0.2.0/carbon/model/hybrid_search_tuning_params.pyi
+-rw-r--r--   0        0        0     2907 2024-05-29 00:18:21.344395 carbon_python_sdk-0.2.0/carbon/model/hybrid_search_tuning_params_nullable.py
+-rw-r--r--   0        0        0     2907 2024-05-29 00:18:21.344500 carbon_python_sdk-0.2.0/carbon/model/hybrid_search_tuning_params_nullable.pyi
+-rw-r--r--   0        0        0     6323 2024-05-29 00:18:21.344610 carbon_python_sdk-0.2.0/carbon/model/list_data_source_items_request.py
+-rw-r--r--   0        0        0     6323 2024-05-29 00:18:21.344715 carbon_python_sdk-0.2.0/carbon/model/list_data_source_items_request.pyi
+-rw-r--r--   0        0        0     3820 2024-05-29 00:18:21.344819 carbon_python_sdk-0.2.0/carbon/model/list_data_source_items_response.py
+-rw-r--r--   0        0        0     3820 2024-05-29 00:18:21.344923 carbon_python_sdk-0.2.0/carbon/model/list_data_source_items_response.pyi
+-rw-r--r--   0        0        0     5498 2024-05-29 00:18:21.345021 carbon_python_sdk-0.2.0/carbon/model/list_items_filters.py
+-rw-r--r--   0        0        0     5498 2024-05-29 00:18:21.345126 carbon_python_sdk-0.2.0/carbon/model/list_items_filters.pyi
+-rw-r--r--   0        0        0     1095 2024-05-29 00:18:21.345228 carbon_python_sdk-0.2.0/carbon/model/list_items_filters_external_ids.py
+-rw-r--r--   0        0        0     1095 2024-05-29 00:18:21.345326 carbon_python_sdk-0.2.0/carbon/model/list_items_filters_external_ids.pyi
+-rw-r--r--   0        0        0     1079 2024-05-29 00:18:21.345422 carbon_python_sdk-0.2.0/carbon/model/list_items_filters_ids.py
+-rw-r--r--   0        0        0     1079 2024-05-29 00:18:21.345518 carbon_python_sdk-0.2.0/carbon/model/list_items_filters_ids.pyi
+-rw-r--r--   0        0        0     5708 2024-05-29 00:18:21.345626 carbon_python_sdk-0.2.0/carbon/model/list_items_filters_nullable.py
+-rw-r--r--   0        0        0     5708 2024-05-29 00:18:21.345739 carbon_python_sdk-0.2.0/carbon/model/list_items_filters_nullable.pyi
+-rw-r--r--   0        0        0     1111 2024-05-29 00:18:21.345834 carbon_python_sdk-0.2.0/carbon/model/list_items_filters_nullable_external_ids.py
+-rw-r--r--   0        0        0     1111 2024-05-29 00:18:21.345941 carbon_python_sdk-0.2.0/carbon/model/list_items_filters_nullable_external_ids.pyi
+-rw-r--r--   0        0        0     1095 2024-05-29 00:18:21.346041 carbon_python_sdk-0.2.0/carbon/model/list_items_filters_nullable_ids.py
+-rw-r--r--   0        0        0     1095 2024-05-29 00:18:21.346142 carbon_python_sdk-0.2.0/carbon/model/list_items_filters_nullable_ids.pyi
+-rw-r--r--   0        0        0     3613 2024-05-29 00:18:21.346355 carbon_python_sdk-0.2.0/carbon/model/list_request.py
+-rw-r--r--   0        0        0     3613 2024-05-29 00:18:21.346448 carbon_python_sdk-0.2.0/carbon/model/list_request.pyi
+-rw-r--r--   0        0        0     3228 2024-05-29 00:18:21.346544 carbon_python_sdk-0.2.0/carbon/model/list_response.py
+-rw-r--r--   0        0        0     3228 2024-05-29 00:18:21.346636 carbon_python_sdk-0.2.0/carbon/model/list_response.pyi
+-rw-r--r--   0        0        0     3129 2024-05-29 00:18:21.346732 carbon_python_sdk-0.2.0/carbon/model/modify_user_configuration_input.py
+-rw-r--r--   0        0        0     3129 2024-05-29 00:18:21.346833 carbon_python_sdk-0.2.0/carbon/model/modify_user_configuration_input.pyi
+-rw-r--r--   0        0        0     3699 2024-05-29 00:18:21.346931 carbon_python_sdk-0.2.0/carbon/model/notion_authentication.py
+-rw-r--r--   0        0        0     3699 2024-05-29 00:18:21.347030 carbon_python_sdk-0.2.0/carbon/model/notion_authentication.pyi
+-rw-r--r--   0        0        0     4300 2024-05-29 00:18:21.347127 carbon_python_sdk-0.2.0/carbon/model/o_auth_authentication.py
+-rw-r--r--   0        0        0     4300 2024-05-29 00:18:21.347222 carbon_python_sdk-0.2.0/carbon/model/o_auth_authentication.pyi
+-rw-r--r--   0        0        0    29598 2024-05-29 00:18:21.347339 carbon_python_sdk-0.2.0/carbon/model/o_auth_url_request.py
+-rw-r--r--   0        0        0    29598 2024-05-29 00:18:21.347501 carbon_python_sdk-0.2.0/carbon/model/o_auth_url_request.pyi
+-rw-r--r--   0        0        0      930 2024-05-29 00:18:21.347626 carbon_python_sdk-0.2.0/carbon/model/order_dir.py
+-rw-r--r--   0        0        0      813 2024-05-29 00:18:21.347720 carbon_python_sdk-0.2.0/carbon/model/order_dir.pyi
+-rw-r--r--   0        0        0      932 2024-05-29 00:18:21.347847 carbon_python_sdk-0.2.0/carbon/model/order_dir_v2.py
+-rw-r--r--   0        0        0      815 2024-05-29 00:18:21.347967 carbon_python_sdk-0.2.0/carbon/model/order_dir_v2.pyi
+-rw-r--r--   0        0        0    18921 2024-05-29 00:21:37.949670 carbon_python_sdk-0.2.0/carbon/model/organization_response.py
+-rw-r--r--   0        0        0    18921 2024-05-29 00:21:37.949975 carbon_python_sdk-0.2.0/carbon/model/organization_response.pyi
+-rw-r--r--   0        0        0    17065 2024-05-29 00:18:21.348378 carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_api.py
+-rw-r--r--   0        0        0    17065 2024-05-29 00:18:21.348523 carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_api.pyi
+-rw-r--r--   0        0        0     4467 2024-05-29 00:18:21.348663 carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_filters.py
+-rw-r--r--   0        0        0     4467 2024-05-29 00:18:21.348770 carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_filters.pyi
+-rw-r--r--   0        0        0     1113 2024-05-29 00:18:21.348875 carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_filters_ids.py
+-rw-r--r--   0        0        0     1113 2024-05-29 00:18:21.348976 carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_filters_ids.pyi
+-rw-r--r--   0        0        0     1014 2024-05-29 00:18:21.349084 carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_order_by_columns.py
+-rw-r--r--   0        0        0      871 2024-05-29 00:18:21.349185 carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_order_by_columns.pyi
+-rw-r--r--   0        0        0     4657 2024-05-29 00:18:21.349293 carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_query_input.py
+-rw-r--r--   0        0        0     4657 2024-05-29 00:18:21.349400 carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_query_input.pyi
+-rw-r--r--   0        0        0     3947 2024-05-29 00:18:21.349506 carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_response.py
+-rw-r--r--   0        0        0     3947 2024-05-29 00:18:21.349613 carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_response.pyi
+-rw-r--r--   0        0        0     3408 2024-05-29 00:18:21.349715 carbon_python_sdk-0.2.0/carbon/model/organization_user_file_tag_create.py
+-rw-r--r--   0        0        0     3408 2024-05-29 00:18:21.349814 carbon_python_sdk-0.2.0/carbon/model/organization_user_file_tag_create.pyi
+-rw-r--r--   0        0        0     6330 2024-05-29 00:18:21.349914 carbon_python_sdk-0.2.0/carbon/model/organization_user_file_tag_create_tags.py
+-rw-r--r--   0        0        0     6330 2024-05-29 00:18:21.350020 carbon_python_sdk-0.2.0/carbon/model/organization_user_file_tag_create_tags.pyi
+-rw-r--r--   0        0        0     3418 2024-05-29 00:18:21.350120 carbon_python_sdk-0.2.0/carbon/model/organization_user_file_tags_remove.py
+-rw-r--r--   0        0        0     3418 2024-05-29 00:18:21.350220 carbon_python_sdk-0.2.0/carbon/model/organization_user_file_tags_remove.pyi
+-rw-r--r--   0        0        0     1213 2024-05-29 00:18:21.350313 carbon_python_sdk-0.2.0/carbon/model/organization_user_file_tags_remove_tags.py
+-rw-r--r--   0        0        0     1213 2024-05-29 00:18:21.350416 carbon_python_sdk-0.2.0/carbon/model/organization_user_file_tags_remove_tags.pyi
+-rw-r--r--   0        0        0    21692 2024-05-29 00:18:21.350526 carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters.py
+-rw-r--r--   0        0        0    21692 2024-05-29 00:18:21.350665 carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters.pyi
+-rw-r--r--   0        0        0     1238 2024-05-29 00:18:21.350948 carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_external_file_ids.py
+-rw-r--r--   0        0        0     1238 2024-05-29 00:18:21.351067 carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_external_file_ids.pyi
+-rw-r--r--   0        0        0     1186 2024-05-29 00:18:21.351189 carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_ids.py
+-rw-r--r--   0        0        0     1186 2024-05-29 00:18:21.351298 carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_ids.pyi
+-rw-r--r--   0        0        0     1296 2024-05-29 00:18:21.351406 carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_organization_user_data_source_id.py
+-rw-r--r--   0        0        0     1296 2024-05-29 00:18:21.351510 carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_organization_user_data_source_id.pyi
+-rw-r--r--   0        0        0     1135 2024-05-29 00:18:21.351739 carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_parent_file_ids.py
+-rw-r--r--   0        0        0     1135 2024-05-29 00:18:21.351829 carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_parent_file_ids.pyi
+-rw-r--r--   0        0        0     1216 2024-05-29 00:18:21.351925 carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_request_ids.py
+-rw-r--r--   0        0        0     1192 2024-05-29 00:18:21.352019 carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_request_ids.pyi
+-rw-r--r--   0        0        0     6420 2024-05-29 00:18:21.352128 carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_tags.py
+-rw-r--r--   0        0        0     6420 2024-05-29 00:18:21.352227 carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_tags.pyi
+-rw-r--r--   0        0        0     1469 2024-05-29 00:18:21.352322 carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_order_by_types.py
+-rw-r--r--   0        0        0     1198 2024-05-29 00:18:21.352544 carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_order_by_types.pyi
+-rw-r--r--   0        0        0     8629 2024-05-29 00:18:21.352675 carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_query_input.py
+-rw-r--r--   0        0        0     8629 2024-05-29 00:18:21.353113 carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_query_input.pyi
+-rw-r--r--   0        0        0     2378 2024-05-29 00:18:21.353805 carbon_python_sdk-0.2.0/carbon/model/outh_url_response.py
+-rw-r--r--   0        0        0     2378 2024-05-29 00:18:21.353895 carbon_python_sdk-0.2.0/carbon/model/outh_url_response.pyi
+-rw-r--r--   0        0        0    17193 2024-05-29 00:18:21.353993 carbon_python_sdk-0.2.0/carbon/model/outlook_sync_input.py
+-rw-r--r--   0        0        0    17193 2024-05-29 00:18:21.354111 carbon_python_sdk-0.2.0/carbon/model/outlook_sync_input.pyi
+-rw-r--r--   0        0        0     2807 2024-05-29 00:18:21.354229 carbon_python_sdk-0.2.0/carbon/model/pagination.py
+-rw-r--r--   0        0        0     2807 2024-05-29 00:18:21.354326 carbon_python_sdk-0.2.0/carbon/model/pagination.pyi
+-rw-r--r--   0        0        0     2452 2024-05-29 00:18:21.354426 carbon_python_sdk-0.2.0/carbon/model/presigned_url_response.py
+-rw-r--r--   0        0        0     2452 2024-05-29 00:18:21.354629 carbon_python_sdk-0.2.0/carbon/model/presigned_url_response.pyi
+-rw-r--r--   0        0        0    10223 2024-05-29 00:18:21.354738 carbon_python_sdk-0.2.0/carbon/model/raw_text_input.py
+-rw-r--r--   0        0        0    10151 2024-05-29 00:18:21.354863 carbon_python_sdk-0.2.0/carbon/model/raw_text_input.pyi
+-rw-r--r--   0        0        0     5578 2024-05-29 00:18:21.354994 carbon_python_sdk-0.2.0/carbon/model/resync_file_query_input.py
+-rw-r--r--   0        0        0     5578 2024-05-29 00:18:21.355093 carbon_python_sdk-0.2.0/carbon/model/resync_file_query_input.pyi
+-rw-r--r--   0        0        0     2489 2024-05-29 00:18:21.355178 carbon_python_sdk-0.2.0/carbon/model/revoke_access_token_input.py
+-rw-r--r--   0        0        0     2489 2024-05-29 00:18:21.355260 carbon_python_sdk-0.2.0/carbon/model/revoke_access_token_input.pyi
+-rw-r--r--   0        0        0    12076 2024-05-29 00:18:21.355341 carbon_python_sdk-0.2.0/carbon/model/rss_feed_input.py
+-rw-r--r--   0        0        0    12076 2024-05-29 00:18:21.355458 carbon_python_sdk-0.2.0/carbon/model/rss_feed_input.pyi
+-rw-r--r--   0        0        0     3724 2024-05-29 00:18:21.355589 carbon_python_sdk-0.2.0/carbon/model/s3_auth_request.py
+-rw-r--r--   0        0        0     3724 2024-05-29 00:18:21.355690 carbon_python_sdk-0.2.0/carbon/model/s3_auth_request.pyi
+-rw-r--r--   0        0        0     3739 2024-05-29 00:18:21.355784 carbon_python_sdk-0.2.0/carbon/model/s3_authentication.py
+-rw-r--r--   0        0        0     3739 2024-05-29 00:18:21.355885 carbon_python_sdk-0.2.0/carbon/model/s3_authentication.pyi
+-rw-r--r--   0        0        0    19565 2024-05-29 00:18:21.355990 carbon_python_sdk-0.2.0/carbon/model/s3_file_sync_input.py
+-rw-r--r--   0        0        0    19565 2024-05-29 00:18:21.356115 carbon_python_sdk-0.2.0/carbon/model/s3_file_sync_input.pyi
+-rw-r--r--   0        0        0     3936 2024-05-29 00:18:21.356346 carbon_python_sdk-0.2.0/carbon/model/s3_get_file_input.py
+-rw-r--r--   0        0        0     3936 2024-05-29 00:18:21.356446 carbon_python_sdk-0.2.0/carbon/model/s3_get_file_input.pyi
+-rw-r--r--   0        0        0     4813 2024-05-29 00:18:21.356546 carbon_python_sdk-0.2.0/carbon/model/salesforce_authentication.py
+-rw-r--r--   0        0        0     4813 2024-05-29 00:18:21.356644 carbon_python_sdk-0.2.0/carbon/model/salesforce_authentication.pyi
+-rw-r--r--   0        0        0     5449 2024-05-29 00:18:21.356745 carbon_python_sdk-0.2.0/carbon/model/sharepoint_authentication.py
+-rw-r--r--   0        0        0     5449 2024-05-29 00:18:21.356845 carbon_python_sdk-0.2.0/carbon/model/sharepoint_authentication.pyi
+-rw-r--r--   0        0        0     1566 2024-05-29 00:18:21.356945 carbon_python_sdk-0.2.0/carbon/model/simple_o_auth_data_sources.py
+-rw-r--r--   0        0        0     1263 2024-05-29 00:18:21.357040 carbon_python_sdk-0.2.0/carbon/model/simple_o_auth_data_sources.pyi
+-rw-r--r--   0        0        0     6587 2024-05-29 00:18:21.357143 carbon_python_sdk-0.2.0/carbon/model/single_chunks_and_embeddings_upload_input.py
+-rw-r--r--   0        0        0     6587 2024-05-29 00:18:21.357245 carbon_python_sdk-0.2.0/carbon/model/single_chunks_and_embeddings_upload_input.pyi
+-rw-r--r--   0        0        0    15650 2024-05-29 00:18:21.357336 carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request.py
+-rw-r--r--   0        0        0    15608 2024-05-29 00:18:21.357490 carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request.pyi
+-rw-r--r--   0        0        0     1113 2024-05-29 00:18:21.357648 carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request_css_classes_to_skip.py
+-rw-r--r--   0        0        0     1113 2024-05-29 00:18:21.357751 carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request_css_classes_to_skip.pyi
+-rw-r--r--   0        0        0     1117 2024-05-29 00:18:21.357848 carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request_css_selectors_to_skip.py
+-rw-r--r--   0        0        0     1117 2024-05-29 00:18:21.357937 carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request_css_selectors_to_skip.pyi
+-rw-r--r--   0        0        0     1109 2024-05-29 00:18:21.358027 carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request_html_tags_to_skip.py
+-rw-r--r--   0        0        0     1109 2024-05-29 00:18:21.358119 carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request_html_tags_to_skip.pyi
+-rw-r--r--   0        0        0     6392 2024-05-29 00:18:21.358212 carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request_tags.py
+-rw-r--r--   0        0        0     6392 2024-05-29 00:18:21.358312 carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request_tags.pyi
+-rw-r--r--   0        0        0     2485 2024-05-29 00:18:21.358401 carbon_python_sdk-0.2.0/carbon/model/sync_directory_request.py
+-rw-r--r--   0        0        0     2485 2024-05-29 00:18:21.358489 carbon_python_sdk-0.2.0/carbon/model/sync_directory_request.pyi
+-rw-r--r--   0        0        0     2784 2024-05-29 00:18:21.358571 carbon_python_sdk-0.2.0/carbon/model/sync_files_ids.py
+-rw-r--r--   0        0        0     2784 2024-05-29 00:18:21.358651 carbon_python_sdk-0.2.0/carbon/model/sync_files_ids.pyi
+-rw-r--r--   0        0        0    22189 2024-05-29 00:18:21.358746 carbon_python_sdk-0.2.0/carbon/model/sync_files_request.py
+-rw-r--r--   0        0        0    22189 2024-05-29 00:18:21.358853 carbon_python_sdk-0.2.0/carbon/model/sync_files_request.pyi
+-rw-r--r--   0        0        0    16413 2024-05-29 00:18:21.358952 carbon_python_sdk-0.2.0/carbon/model/sync_options.py
+-rw-r--r--   0        0        0    16413 2024-05-29 00:18:21.359050 carbon_python_sdk-0.2.0/carbon/model/sync_options.pyi
+-rw-r--r--   0        0        0     3009 2024-05-29 00:18:21.359146 carbon_python_sdk-0.2.0/carbon/model/text_embedding_generators.py
+-rw-r--r--   0        0        0     2160 2024-05-29 00:18:21.359231 carbon_python_sdk-0.2.0/carbon/model/text_embedding_generators.pyi
+-rw-r--r--   0        0        0     3042 2024-05-29 00:18:21.359313 carbon_python_sdk-0.2.0/carbon/model/token_response.py
+-rw-r--r--   0        0        0     3042 2024-05-29 00:18:21.359482 carbon_python_sdk-0.2.0/carbon/model/token_response.pyi
+-rw-r--r--   0        0        0     2620 2024-05-29 00:18:21.359567 carbon_python_sdk-0.2.0/carbon/model/update_organization_input.py
+-rw-r--r--   0        0        0     2620 2024-05-29 00:18:21.359648 carbon_python_sdk-0.2.0/carbon/model/update_organization_input.pyi
+-rw-r--r--   0        0        0     9214 2024-05-29 00:18:21.359735 carbon_python_sdk-0.2.0/carbon/model/update_users_input.py
+-rw-r--r--   0        0        0     9128 2024-05-29 00:18:21.359848 carbon_python_sdk-0.2.0/carbon/model/update_users_input.pyi
+-rw-r--r--   0        0        0     1267 2024-05-29 00:18:21.360281 carbon_python_sdk-0.2.0/carbon/model/update_users_input_customer_ids.py
+-rw-r--r--   0        0        0     1243 2024-05-29 00:18:21.360376 carbon_python_sdk-0.2.0/carbon/model/update_users_input_customer_ids.pyi
+-rw-r--r--   0        0        0    12928 2024-05-29 00:18:21.360470 carbon_python_sdk-0.2.0/carbon/model/upload_file_from_url_input.py
+-rw-r--r--   0        0        0    12928 2024-05-29 00:18:21.360635 carbon_python_sdk-0.2.0/carbon/model/upload_file_from_url_input.pyi
+-rw-r--r--   0        0        0     8405 2024-05-29 00:18:21.360799 carbon_python_sdk-0.2.0/carbon/model/user_configuration.py
+-rw-r--r--   0        0        0     8319 2024-05-29 00:18:21.360941 carbon_python_sdk-0.2.0/carbon/model/user_configuration.pyi
+-rw-r--r--   0        0        0     8665 2024-05-29 00:18:21.361069 carbon_python_sdk-0.2.0/carbon/model/user_configuration_nullable.py
+-rw-r--r--   0        0        0     8579 2024-05-29 00:18:21.361199 carbon_python_sdk-0.2.0/carbon/model/user_configuration_nullable.pyi
+-rw-r--r--   0        0        0    35549 2024-05-29 00:18:21.361342 carbon_python_sdk-0.2.0/carbon/model/user_file.py
+-rw-r--r--   0        0        0    35549 2024-05-29 00:18:21.361474 carbon_python_sdk-0.2.0/carbon/model/user_file.pyi
+-rw-r--r--   0        0        0     1650 2024-05-29 00:18:21.361607 carbon_python_sdk-0.2.0/carbon/model/user_file_embedding_properties.py
+-rw-r--r--   0        0        0     1650 2024-05-29 00:18:21.361813 carbon_python_sdk-0.2.0/carbon/model/user_file_embedding_properties.pyi
+-rw-r--r--   0        0        0     3751 2024-05-29 00:18:21.361905 carbon_python_sdk-0.2.0/carbon/model/user_files_v2.py
+-rw-r--r--   0        0        0     3751 2024-05-29 00:18:21.362000 carbon_python_sdk-0.2.0/carbon/model/user_files_v2.pyi
+-rw-r--r--   0        0        0     2416 2024-05-29 00:18:21.362095 carbon_python_sdk-0.2.0/carbon/model/user_request_content.py
+-rw-r--r--   0        0        0     2416 2024-05-29 00:18:21.362188 carbon_python_sdk-0.2.0/carbon/model/user_request_content.pyi
+-rw-r--r--   0        0        0    17500 2024-05-29 00:21:37.950501 carbon_python_sdk-0.2.0/carbon/model/user_response.py
+-rw-r--r--   0        0        0    17500 2024-05-29 00:21:37.951062 carbon_python_sdk-0.2.0/carbon/model/user_response.pyi
+-rw-r--r--   0        0        0     1511 2024-05-29 00:18:21.362514 carbon_python_sdk-0.2.0/carbon/model/user_response_auto_sync_enabled_sources.py
+-rw-r--r--   0        0        0     1511 2024-05-29 00:18:21.362609 carbon_python_sdk-0.2.0/carbon/model/user_response_auto_sync_enabled_sources.pyi
+-rw-r--r--   0        0        0     1246 2024-05-29 00:18:21.362710 carbon_python_sdk-0.2.0/carbon/model/user_response_unique_file_tags.py
+-rw-r--r--   0        0        0     1246 2024-05-29 00:18:21.362811 carbon_python_sdk-0.2.0/carbon/model/user_response_unique_file_tags.pyi
+-rw-r--r--   0        0        0     1315 2024-05-29 00:18:21.363332 carbon_python_sdk-0.2.0/carbon/model/utilities_scrape_web_request.py
+-rw-r--r--   0        0        0     1315 2024-05-29 00:18:21.363428 carbon_python_sdk-0.2.0/carbon/model/utilities_scrape_web_request.pyi
+-rw-r--r--   0        0        0     3352 2024-05-29 00:18:21.363515 carbon_python_sdk-0.2.0/carbon/model/validation_error.py
+-rw-r--r--   0        0        0     3352 2024-05-29 00:18:21.363603 carbon_python_sdk-0.2.0/carbon/model/validation_error.pyi
+-rw-r--r--   0        0        0     3149 2024-05-29 00:18:21.363721 carbon_python_sdk-0.2.0/carbon/model/validation_error_loc.py
+-rw-r--r--   0        0        0     3149 2024-05-29 00:18:21.363815 carbon_python_sdk-0.2.0/carbon/model/validation_error_loc.pyi
+-rw-r--r--   0        0        0     6973 2024-05-29 00:21:37.952667 carbon_python_sdk-0.2.0/carbon/model/webhook.py
+-rw-r--r--   0        0        0     6973 2024-05-29 00:21:37.952854 carbon_python_sdk-0.2.0/carbon/model/webhook.pyi
+-rw-r--r--   0        0        0     2396 2024-05-29 00:18:21.364110 carbon_python_sdk-0.2.0/carbon/model/webhook_filters.py
+-rw-r--r--   0        0        0     2396 2024-05-29 00:18:21.364202 carbon_python_sdk-0.2.0/carbon/model/webhook_filters.pyi
+-rw-r--r--   0        0        0     1075 2024-05-29 00:18:21.364294 carbon_python_sdk-0.2.0/carbon/model/webhook_filters_ids.py
+-rw-r--r--   0        0        0     1075 2024-05-29 00:18:21.364388 carbon_python_sdk-0.2.0/carbon/model/webhook_filters_ids.pyi
+-rw-r--r--   0        0        0     6395 2024-05-29 00:21:37.953037 carbon_python_sdk-0.2.0/carbon/model/webhook_no_key.py
+-rw-r--r--   0        0        0     6395 2024-05-29 00:21:37.953179 carbon_python_sdk-0.2.0/carbon/model/webhook_no_key.pyi
+-rw-r--r--   0        0        0      995 2024-05-29 00:18:21.364686 carbon_python_sdk-0.2.0/carbon/model/webhook_order_by_columns.py
+-rw-r--r--   0        0        0      852 2024-05-29 00:18:21.364778 carbon_python_sdk-0.2.0/carbon/model/webhook_order_by_columns.pyi
+-rw-r--r--   0        0        0     4347 2024-05-29 00:18:21.364878 carbon_python_sdk-0.2.0/carbon/model/webhook_query_input.py
+-rw-r--r--   0        0        0     4347 2024-05-29 00:18:21.365005 carbon_python_sdk-0.2.0/carbon/model/webhook_query_input.pyi
+-rw-r--r--   0        0        0     3798 2024-05-29 00:18:21.365097 carbon_python_sdk-0.2.0/carbon/model/webhook_query_response.py
+-rw-r--r--   0        0        0     3798 2024-05-29 00:18:21.365192 carbon_python_sdk-0.2.0/carbon/model/webhook_query_response.pyi
+-rw-r--r--   0        0        0      959 2024-05-29 00:21:37.953416 carbon_python_sdk-0.2.0/carbon/model/webhook_status.py
+-rw-r--r--   0        0        0      830 2024-05-29 00:21:37.953690 carbon_python_sdk-0.2.0/carbon/model/webhook_status.pyi
+-rw-r--r--   0        0        0    16894 2024-05-29 00:18:21.365762 carbon_python_sdk-0.2.0/carbon/model/webscrape_request.py
+-rw-r--r--   0        0        0    16810 2024-05-29 00:18:21.365890 carbon_python_sdk-0.2.0/carbon/model/webscrape_request.pyi
+-rw-r--r--   0        0        0     1105 2024-05-29 00:18:21.366006 carbon_python_sdk-0.2.0/carbon/model/webscrape_request_css_classes_to_skip.py
+-rw-r--r--   0        0        0     1105 2024-05-29 00:18:21.366106 carbon_python_sdk-0.2.0/carbon/model/webscrape_request_css_classes_to_skip.pyi
+-rw-r--r--   0        0        0     1109 2024-05-29 00:18:21.366607 carbon_python_sdk-0.2.0/carbon/model/webscrape_request_css_selectors_to_skip.py
+-rw-r--r--   0        0        0     1109 2024-05-29 00:18:21.366858 carbon_python_sdk-0.2.0/carbon/model/webscrape_request_css_selectors_to_skip.pyi
+-rw-r--r--   0        0        0     1101 2024-05-29 00:18:21.366963 carbon_python_sdk-0.2.0/carbon/model/webscrape_request_html_tags_to_skip.py
+-rw-r--r--   0        0        0     1101 2024-05-29 00:18:21.367070 carbon_python_sdk-0.2.0/carbon/model/webscrape_request_html_tags_to_skip.pyi
+-rw-r--r--   0        0        0     6384 2024-05-29 00:18:21.367175 carbon_python_sdk-0.2.0/carbon/model/webscrape_request_tags.py
+-rw-r--r--   0        0        0     6384 2024-05-29 00:18:21.367272 carbon_python_sdk-0.2.0/carbon/model/webscrape_request_tags.pyi
+-rw-r--r--   0        0        0     3117 2024-05-29 00:18:21.367360 carbon_python_sdk-0.2.0/carbon/model/white_labeling_response.py
+-rw-r--r--   0        0        0     3117 2024-05-29 00:18:21.367456 carbon_python_sdk-0.2.0/carbon/model/white_labeling_response.pyi
+-rw-r--r--   0        0        0     5401 2024-05-29 00:18:21.367558 carbon_python_sdk-0.2.0/carbon/model/youtube_transcript_response.py
+-rw-r--r--   0        0        0     5401 2024-05-29 00:18:21.367659 carbon_python_sdk-0.2.0/carbon/model/youtube_transcript_response.pyi
+-rw-r--r--   0        0        0     1375 2024-05-29 00:18:21.367756 carbon_python_sdk-0.2.0/carbon/model/youtube_transcript_response_raw_transcript.py
+-rw-r--r--   0        0        0     1375 2024-05-29 00:18:21.367962 carbon_python_sdk-0.2.0/carbon/model/youtube_transcript_response_raw_transcript.pyi
+-rw-r--r--   0        0        0     3326 2024-05-29 00:18:21.368202 carbon_python_sdk-0.2.0/carbon/model/youtube_transcript_response_raw_transcript_item.py
+-rw-r--r--   0        0        0     3326 2024-05-29 00:18:21.368299 carbon_python_sdk-0.2.0/carbon/model/youtube_transcript_response_raw_transcript_item.pyi
+-rw-r--r--   0        0        0     3653 2024-05-29 00:18:21.368531 carbon_python_sdk-0.2.0/carbon/model/zendesk_authentication.py
+-rw-r--r--   0        0        0     3653 2024-05-29 00:18:21.368625 carbon_python_sdk-0.2.0/carbon/model/zendesk_authentication.pyi
+-rw-r--r--   0        0        0     4907 2024-05-29 00:18:21.368724 carbon_python_sdk-0.2.0/carbon/model/zotero_authentication.py
+-rw-r--r--   0        0        0     4907 2024-05-29 00:18:21.368824 carbon_python_sdk-0.2.0/carbon/model/zotero_authentication.pyi
+-rw-r--r--   0        0        0    13472 2024-05-29 00:21:37.954593 carbon_python_sdk-0.2.0/carbon/models/__init__.py
+-rw-r--r--   0        0        0    25498 2024-05-29 00:21:37.954946 carbon_python_sdk-0.2.0/carbon/operation_parameter_map.py
+-rw-r--r--   0        0        0     3147 2024-05-29 00:21:37.955661 carbon_python_sdk-0.2.0/carbon/paths/__init__.py
+-rw-r--r--   0        0        0      293 2024-05-29 00:18:21.369333 carbon_python_sdk-0.2.0/carbon/paths/add_webhook/__init__.py
+-rw-r--r--   0        0        0    13948 2024-05-29 00:18:21.369424 carbon_python_sdk-0.2.0/carbon/paths/add_webhook/post.py
+-rw-r--r--   0        0        0    13811 2024-05-29 00:18:21.369589 carbon_python_sdk-0.2.0/carbon/paths/add_webhook/post.pyi
+-rw-r--r--   0        0        0      311 2024-05-29 00:18:21.369757 carbon_python_sdk-0.2.0/carbon/paths/auth_v1_access_token/__init__.py
+-rw-r--r--   0        0        0    11830 2024-05-29 00:18:21.369858 carbon_python_sdk-0.2.0/carbon/paths/auth_v1_access_token/get.py
+-rw-r--r--   0        0        0    11656 2024-05-29 00:18:21.369987 carbon_python_sdk-0.2.0/carbon/paths/auth_v1_access_token/get.pyi
+-rw-r--r--   0        0        0      315 2024-05-29 00:18:21.370226 carbon_python_sdk-0.2.0/carbon/paths/auth_v1_white_labeling/__init__.py
+-rw-r--r--   0        0        0    11193 2024-05-29 00:18:21.370323 carbon_python_sdk-0.2.0/carbon/paths/auth_v1_white_labeling/get.py
+-rw-r--r--   0        0        0    11049 2024-05-29 00:18:21.370447 carbon_python_sdk-0.2.0/carbon/paths/auth_v1_white_labeling/get.pyi
+-rw-r--r--   0        0        0      313 2024-05-29 00:18:21.370571 carbon_python_sdk-0.2.0/carbon/paths/create_user_file_tags/__init__.py
+-rw-r--r--   0        0        0    15880 2024-05-29 00:18:21.370664 carbon_python_sdk-0.2.0/carbon/paths/create_user_file_tags/post.py
+-rw-r--r--   0        0        0    15706 2024-05-29 00:18:21.370835 carbon_python_sdk-0.2.0/carbon/paths/create_user_file_tags/post.pyi
+-rw-r--r--   0        0        0      295 2024-05-29 00:18:21.370998 carbon_python_sdk-0.2.0/carbon/paths/delete_files/__init__.py
+-rw-r--r--   0        0        0    19307 2024-05-29 00:18:21.371099 carbon_python_sdk-0.2.0/carbon/paths/delete_files/post.py
+-rw-r--r--   0        0        0    19133 2024-05-29 00:18:21.371205 carbon_python_sdk-0.2.0/carbon/paths/delete_files/post.pyi
+-rw-r--r--   0        0        0      301 2024-05-29 00:18:21.371302 carbon_python_sdk-0.2.0/carbon/paths/delete_files_v2/__init__.py
+-rw-r--r--   0        0        0    15967 2024-05-29 00:18:21.371382 carbon_python_sdk-0.2.0/carbon/paths/delete_files_v2/post.py
+-rw-r--r--   0        0        0    15793 2024-05-29 00:18:21.371539 carbon_python_sdk-0.2.0/carbon/paths/delete_files_v2/post.pyi
+-rw-r--r--   0        0        0      313 2024-05-29 00:18:21.371712 carbon_python_sdk-0.2.0/carbon/paths/delete_user_file_tags/__init__.py
+-rw-r--r--   0        0        0    15814 2024-05-29 00:18:21.371795 carbon_python_sdk-0.2.0/carbon/paths/delete_user_file_tags/post.py
+-rw-r--r--   0        0        0    15640 2024-05-29 00:18:21.371957 carbon_python_sdk-0.2.0/carbon/paths/delete_user_file_tags/post.pyi
+-rw-r--r--   0        0        0      295 2024-05-29 00:18:21.372318 carbon_python_sdk-0.2.0/carbon/paths/delete_users/__init__.py
+-rw-r--r--   0        0        0    14899 2024-05-29 00:18:21.372420 carbon_python_sdk-0.2.0/carbon/paths/delete_users/post.py
+-rw-r--r--   0        0        0    14762 2024-05-29 00:18:21.372606 carbon_python_sdk-0.2.0/carbon/paths/delete_users/post.pyi
+-rw-r--r--   0        0        0      321 2024-05-29 00:18:21.372791 carbon_python_sdk-0.2.0/carbon/paths/delete_webhook_webhook_id/__init__.py
+-rw-r--r--   0        0        0    14359 2024-05-29 00:18:21.372872 carbon_python_sdk-0.2.0/carbon/paths/delete_webhook_webhook_id/delete.py
+-rw-r--r--   0        0        0    14222 2024-05-29 00:18:21.373059 carbon_python_sdk-0.2.0/carbon/paths/delete_webhook_webhook_id/delete.pyi
+-rw-r--r--   0        0        0      307 2024-05-29 00:18:21.373249 carbon_python_sdk-0.2.0/carbon/paths/deletefile_file_id/__init__.py
+-rw-r--r--   0        0        0    14552 2024-05-29 00:18:21.373333 carbon_python_sdk-0.2.0/carbon/paths/deletefile_file_id/delete.py
+-rw-r--r--   0        0        0    14378 2024-05-29 00:18:21.373528 carbon_python_sdk-0.2.0/carbon/paths/deletefile_file_id/delete.pyi
+-rw-r--r--   0        0        0      291 2024-05-29 00:18:21.373867 carbon_python_sdk-0.2.0/carbon/paths/embeddings/__init__.py
+-rw-r--r--   0        0        0    29199 2024-05-29 00:18:21.374023 carbon_python_sdk-0.2.0/carbon/paths/embeddings/post.py
+-rw-r--r--   0        0        0    29025 2024-05-29 00:18:21.374167 carbon_python_sdk-0.2.0/carbon/paths/embeddings/post.pyi
+-rw-r--r--   0        0        0      291 2024-05-29 00:18:21.374295 carbon_python_sdk-0.2.0/carbon/paths/fetch_urls/__init__.py
+-rw-r--r--   0        0        0    14466 2024-05-29 00:18:21.374397 carbon_python_sdk-0.2.0/carbon/paths/fetch_urls/get.py
+-rw-r--r--   0        0        0    14292 2024-05-29 00:18:21.374619 carbon_python_sdk-0.2.0/carbon/paths/fetch_urls/get.pyi
+-rw-r--r--   0        0        0      319 2024-05-29 00:18:21.374843 carbon_python_sdk-0.2.0/carbon/paths/fetch_youtube_transcript/__init__.py
+-rw-r--r--   0        0        0    15695 2024-05-29 00:18:21.374951 carbon_python_sdk-0.2.0/carbon/paths/fetch_youtube_transcript/get.py
+-rw-r--r--   0        0        0    15521 2024-05-29 00:18:21.375307 carbon_python_sdk-0.2.0/carbon/paths/fetch_youtube_transcript/get.pyi
+-rw-r--r--   0        0        0      283 2024-05-29 00:18:21.375518 carbon_python_sdk-0.2.0/carbon/paths/health/__init__.py
+-rw-r--r--   0        0        0    10429 2024-05-29 00:18:21.375609 carbon_python_sdk-0.2.0/carbon/paths/health/get.py
+-rw-r--r--   0        0        0    10348 2024-05-29 00:18:21.376041 carbon_python_sdk-0.2.0/carbon/paths/health/get.pyi
+-rw-r--r--   0        0        0      327 2024-05-29 00:18:21.376163 carbon_python_sdk-0.2.0/carbon/paths/integrations_confluence_list/__init__.py
+-rw-r--r--   0        0        0    15289 2024-05-29 00:18:21.376250 carbon_python_sdk-0.2.0/carbon/paths/integrations_confluence_list/post.py
+-rw-r--r--   0        0        0    15115 2024-05-29 00:18:21.376445 carbon_python_sdk-0.2.0/carbon/paths/integrations_confluence_list/post.pyi
+-rw-r--r--   0        0        0      327 2024-05-29 00:18:21.376645 carbon_python_sdk-0.2.0/carbon/paths/integrations_confluence_sync/__init__.py
+-rw-r--r--   0        0        0    29028 2024-05-29 00:18:21.376740 carbon_python_sdk-0.2.0/carbon/paths/integrations_confluence_sync/post.py
+-rw-r--r--   0        0        0    28854 2024-05-29 00:18:21.376849 carbon_python_sdk-0.2.0/carbon/paths/integrations_confluence_sync/post.pyi
+-rw-r--r--   0        0        0      311 2024-05-29 00:18:21.376949 carbon_python_sdk-0.2.0/carbon/paths/integrations_connect/__init__.py
+-rw-r--r--   0        0        0    20686 2024-05-29 00:18:21.377041 carbon_python_sdk-0.2.0/carbon/paths/integrations_connect/post.py
+-rw-r--r--   0        0        0    20512 2024-05-29 00:18:21.377156 carbon_python_sdk-0.2.0/carbon/paths/integrations_connect/post.pyi
+-rw-r--r--   0        0        0      317 2024-05-29 00:18:21.377254 carbon_python_sdk-0.2.0/carbon/paths/integrations_files_sync/__init__.py
+-rw-r--r--   0        0        0    28913 2024-05-29 00:18:21.377349 carbon_python_sdk-0.2.0/carbon/paths/integrations_files_sync/post.py
+-rw-r--r--   0        0        0    28739 2024-05-29 00:18:21.377462 carbon_python_sdk-0.2.0/carbon/paths/integrations_files_sync/post.pyi
+-rw-r--r--   0        0        0      315 2024-05-29 00:18:21.377560 carbon_python_sdk-0.2.0/carbon/paths/integrations_freshdesk/__init__.py
+-rw-r--r--   0        0        0    26091 2024-05-29 00:18:21.377661 carbon_python_sdk-0.2.0/carbon/paths/integrations_freshdesk/post.py
+-rw-r--r--   0        0        0    25917 2024-05-29 00:18:21.377769 carbon_python_sdk-0.2.0/carbon/paths/integrations_freshdesk/post.pyi
+-rw-r--r--   0        0        0      311 2024-05-29 00:18:21.377867 carbon_python_sdk-0.2.0/carbon/paths/integrations_gitbook/__init__.py
+-rw-r--r--   0        0        0    24946 2024-05-29 00:18:21.377971 carbon_python_sdk-0.2.0/carbon/paths/integrations_gitbook/post.py
+-rw-r--r--   0        0        0    24772 2024-05-29 00:18:21.378078 carbon_python_sdk-0.2.0/carbon/paths/integrations_gitbook/post.pyi
+-rw-r--r--   0        0        0      325 2024-05-29 00:18:21.378180 carbon_python_sdk-0.2.0/carbon/paths/integrations_gitbook_spaces/__init__.py
+-rw-r--r--   0        0        0    14816 2024-05-29 00:18:21.378267 carbon_python_sdk-0.2.0/carbon/paths/integrations_gitbook_spaces/get.py
+-rw-r--r--   0        0        0    14642 2024-05-29 00:18:21.378461 carbon_python_sdk-0.2.0/carbon/paths/integrations_gitbook_spaces/get.pyi
+-rw-r--r--   0        0        0      321 2024-05-29 00:18:21.378653 carbon_python_sdk-0.2.0/carbon/paths/integrations_gitbook_sync/__init__.py
+-rw-r--r--   0        0        0    23173 2024-05-29 00:18:21.378746 carbon_python_sdk-0.2.0/carbon/paths/integrations_gitbook_sync/post.py
+-rw-r--r--   0        0        0    22999 2024-05-29 00:18:21.378873 carbon_python_sdk-0.2.0/carbon/paths/integrations_gitbook_sync/post.pyi
+-rw-r--r--   0        0        0      309 2024-05-29 00:18:21.378988 carbon_python_sdk-0.2.0/carbon/paths/integrations_github/__init__.py
+-rw-r--r--   0        0        0    15826 2024-05-29 00:18:21.379087 carbon_python_sdk-0.2.0/carbon/paths/integrations_github/post.py
+-rw-r--r--   0        0        0    15652 2024-05-29 00:18:21.379292 carbon_python_sdk-0.2.0/carbon/paths/integrations_github/post.pyi
+-rw-r--r--   0        0        0      321 2024-05-29 00:18:21.379497 carbon_python_sdk-0.2.0/carbon/paths/integrations_github_repos/__init__.py
+-rw-r--r--   0        0        0    17078 2024-05-29 00:18:21.379601 carbon_python_sdk-0.2.0/carbon/paths/integrations_github_repos/get.py
+-rw-r--r--   0        0        0    16904 2024-05-29 00:18:21.379721 carbon_python_sdk-0.2.0/carbon/paths/integrations_github_repos/get.pyi
+-rw-r--r--   0        0        0      331 2024-05-29 00:18:21.379856 carbon_python_sdk-0.2.0/carbon/paths/integrations_github_sync_repos/__init__.py
+-rw-r--r--   0        0        0    15560 2024-05-29 00:18:21.379954 carbon_python_sdk-0.2.0/carbon/paths/integrations_github_sync_repos/post.py
+-rw-r--r--   0        0        0    15386 2024-05-29 00:18:21.380169 carbon_python_sdk-0.2.0/carbon/paths/integrations_github_sync_repos/post.pyi
+-rw-r--r--   0        0        0      317 2024-05-29 00:18:21.380378 carbon_python_sdk-0.2.0/carbon/paths/integrations_gmail_sync/__init__.py
+-rw-r--r--   0        0        0    26562 2024-05-29 00:18:21.380495 carbon_python_sdk-0.2.0/carbon/paths/integrations_gmail_sync/post.py
+-rw-r--r--   0        0        0    26388 2024-05-29 00:18:21.380625 carbon_python_sdk-0.2.0/carbon/paths/integrations_gmail_sync/post.pyi
+-rw-r--r--   0        0        0      331 2024-05-29 00:18:21.380734 carbon_python_sdk-0.2.0/carbon/paths/integrations_gmail_user_labels/__init__.py
+-rw-r--r--   0        0        0    15340 2024-05-29 00:18:21.380836 carbon_python_sdk-0.2.0/carbon/paths/integrations_gmail_user_labels/get.py
+-rw-r--r--   0        0        0    15166 2024-05-29 00:18:21.381043 carbon_python_sdk-0.2.0/carbon/paths/integrations_gmail_user_labels/get.pyi
+-rw-r--r--   0        0        0      317 2024-05-29 00:18:21.381247 carbon_python_sdk-0.2.0/carbon/paths/integrations_items_list/__init__.py
+-rw-r--r--   0        0        0    19585 2024-05-29 00:18:21.381357 carbon_python_sdk-0.2.0/carbon/paths/integrations_items_list/post.py
+-rw-r--r--   0        0        0    19411 2024-05-29 00:18:21.381475 carbon_python_sdk-0.2.0/carbon/paths/integrations_items_list/post.pyi
+-rw-r--r--   0        0        0      317 2024-05-29 00:18:21.381597 carbon_python_sdk-0.2.0/carbon/paths/integrations_items_sync/__init__.py
+-rw-r--r--   0        0        0    14992 2024-05-29 00:18:21.381702 carbon_python_sdk-0.2.0/carbon/paths/integrations_items_sync/post.py
+-rw-r--r--   0        0        0    14818 2024-05-29 00:18:21.381908 carbon_python_sdk-0.2.0/carbon/paths/integrations_items_sync/post.pyi
+-rw-r--r--   0        0        0      315 2024-05-29 00:18:21.382118 carbon_python_sdk-0.2.0/carbon/paths/integrations_oauth_url/__init__.py
+-rw-r--r--   0        0        0    37674 2024-05-29 00:18:21.382238 carbon_python_sdk-0.2.0/carbon/paths/integrations_oauth_url/post.py
+-rw-r--r--   0        0        0    37500 2024-05-29 00:18:21.382391 carbon_python_sdk-0.2.0/carbon/paths/integrations_oauth_url/post.pyi
+-rw-r--r--   0        0        0      321 2024-05-29 00:18:21.382505 carbon_python_sdk-0.2.0/carbon/paths/integrations_outlook_sync/__init__.py
+-rw-r--r--   0        0        0    27296 2024-05-29 00:18:21.382618 carbon_python_sdk-0.2.0/carbon/paths/integrations_outlook_sync/post.py
+-rw-r--r--   0        0        0    27122 2024-05-29 00:18:21.382742 carbon_python_sdk-0.2.0/carbon/paths/integrations_outlook_sync/post.pyi
+-rw-r--r--   0        0        0      343 2024-05-29 00:18:21.382867 carbon_python_sdk-0.2.0/carbon/paths/integrations_outlook_user_categories/__init__.py
+-rw-r--r--   0        0        0    15590 2024-05-29 00:18:21.382985 carbon_python_sdk-0.2.0/carbon/paths/integrations_outlook_user_categories/get.py
+-rw-r--r--   0        0        0    15416 2024-05-29 00:18:21.383211 carbon_python_sdk-0.2.0/carbon/paths/integrations_outlook_user_categories/get.pyi
+-rw-r--r--   0        0        0      337 2024-05-29 00:18:21.383418 carbon_python_sdk-0.2.0/carbon/paths/integrations_outlook_user_folders/__init__.py
+-rw-r--r--   0        0        0    15371 2024-05-29 00:18:21.383520 carbon_python_sdk-0.2.0/carbon/paths/integrations_outlook_user_folders/get.py
+-rw-r--r--   0        0        0    15197 2024-05-29 00:18:21.383727 carbon_python_sdk-0.2.0/carbon/paths/integrations_outlook_user_folders/get.pyi
+-rw-r--r--   0        0        0      313 2024-05-29 00:18:21.384146 carbon_python_sdk-0.2.0/carbon/paths/integrations_rss_feed/__init__.py
+-rw-r--r--   0        0        0    22218 2024-05-29 00:18:21.384257 carbon_python_sdk-0.2.0/carbon/paths/integrations_rss_feed/post.py
+-rw-r--r--   0        0        0    22044 2024-05-29 00:18:21.384385 carbon_python_sdk-0.2.0/carbon/paths/integrations_rss_feed/post.pyi
+-rw-r--r--   0        0        0      301 2024-05-29 00:18:21.384507 carbon_python_sdk-0.2.0/carbon/paths/integrations_s3/__init__.py
+-rw-r--r--   0        0        0    16130 2024-05-29 00:18:21.384610 carbon_python_sdk-0.2.0/carbon/paths/integrations_s3/post.py
+-rw-r--r--   0        0        0    15956 2024-05-29 00:18:21.384826 carbon_python_sdk-0.2.0/carbon/paths/integrations_s3/post.pyi
+-rw-r--r--   0        0        0      313 2024-05-29 00:18:21.385034 carbon_python_sdk-0.2.0/carbon/paths/integrations_s3_files/__init__.py
+-rw-r--r--   0        0        0    28274 2024-05-29 00:18:21.385148 carbon_python_sdk-0.2.0/carbon/paths/integrations_s3_files/post.py
+-rw-r--r--   0        0        0    28100 2024-05-29 00:18:21.385286 carbon_python_sdk-0.2.0/carbon/paths/integrations_s3_files/post.pyi
+-rw-r--r--   0        0        0      321 2024-05-29 00:18:21.385399 carbon_python_sdk-0.2.0/carbon/paths/modify_user_configuration/__init__.py
+-rw-r--r--   0        0        0    16382 2024-05-29 00:18:21.385504 carbon_python_sdk-0.2.0/carbon/paths/modify_user_configuration/post.py
+-rw-r--r--   0        0        0    16208 2024-05-29 00:18:21.385712 carbon_python_sdk-0.2.0/carbon/paths/modify_user_configuration/post.pyi
+-rw-r--r--   0        0        0      295 2024-05-29 00:18:21.385920 carbon_python_sdk-0.2.0/carbon/paths/organization/__init__.py
+-rw-r--r--   0        0        0    10831 2024-05-29 00:18:21.386021 carbon_python_sdk-0.2.0/carbon/paths/organization/get.py
+-rw-r--r--   0        0        0    10724 2024-05-29 00:18:21.386150 carbon_python_sdk-0.2.0/carbon/paths/organization/get.pyi
+-rw-r--r--   0        0        0      317 2024-05-29 00:21:37.955933 carbon_python_sdk-0.2.0/carbon/paths/organization_statistics/__init__.py
+-rw-r--r--   0        0        0    11092 2024-05-29 00:21:37.956331 carbon_python_sdk-0.2.0/carbon/paths/organization_statistics/post.py
+-rw-r--r--   0        0        0    10985 2024-05-29 00:21:37.957015 carbon_python_sdk-0.2.0/carbon/paths/organization_statistics/post.pyi
+-rw-r--r--   0        0        0      309 2024-05-29 00:18:21.386615 carbon_python_sdk-0.2.0/carbon/paths/organization_update/__init__.py
+-rw-r--r--   0        0        0    15275 2024-05-29 00:18:21.386712 carbon_python_sdk-0.2.0/carbon/paths/organization_update/post.py
+-rw-r--r--   0        0        0    15138 2024-05-29 00:18:21.386926 carbon_python_sdk-0.2.0/carbon/paths/organization_update/post.pyi
+-rw-r--r--   0        0        0      309 2024-05-29 00:18:21.387141 carbon_python_sdk-0.2.0/carbon/paths/parsed_file_file_id/__init__.py
+-rw-r--r--   0        0        0    14654 2024-05-29 00:18:21.387241 carbon_python_sdk-0.2.0/carbon/paths/parsed_file_file_id/get.py
+-rw-r--r--   0        0        0    14480 2024-05-29 00:18:21.387445 carbon_python_sdk-0.2.0/carbon/paths/parsed_file_file_id/get.pyi
+-rw-r--r--   0        0        0      301 2024-05-29 00:18:21.387654 carbon_python_sdk-0.2.0/carbon/paths/process_sitemap/__init__.py
+-rw-r--r--   0        0        0    14363 2024-05-29 00:18:21.387758 carbon_python_sdk-0.2.0/carbon/paths/process_sitemap/get.py
+-rw-r--r--   0        0        0    14189 2024-05-29 00:18:21.387969 carbon_python_sdk-0.2.0/carbon/paths/process_sitemap/get.pyi
+-rw-r--r--   0        0        0      303 2024-05-29 00:18:21.388167 carbon_python_sdk-0.2.0/carbon/paths/raw_file_file_id/__init__.py
+-rw-r--r--   0        0        0    14585 2024-05-29 00:18:21.388264 carbon_python_sdk-0.2.0/carbon/paths/raw_file_file_id/get.py
+-rw-r--r--   0        0        0    14411 2024-05-29 00:18:21.388462 carbon_python_sdk-0.2.0/carbon/paths/raw_file_file_id/get.pyi
+-rw-r--r--   0        0        0      293 2024-05-29 00:18:21.388926 carbon_python_sdk-0.2.0/carbon/paths/resync_file/__init__.py
+-rw-r--r--   0        0        0    16696 2024-05-29 00:18:21.389033 carbon_python_sdk-0.2.0/carbon/paths/resync_file/post.py
+-rw-r--r--   0        0        0    16522 2024-05-29 00:18:21.389152 carbon_python_sdk-0.2.0/carbon/paths/resync_file/post.pyi
+-rw-r--r--   0        0        0      309 2024-05-29 00:18:21.389265 carbon_python_sdk-0.2.0/carbon/paths/revoke_access_token/__init__.py
+-rw-r--r--   0        0        0    14828 2024-05-29 00:18:21.389362 carbon_python_sdk-0.2.0/carbon/paths/revoke_access_token/post.py
+-rw-r--r--   0        0        0    14654 2024-05-29 00:18:21.389563 carbon_python_sdk-0.2.0/carbon/paths/revoke_access_token/post.pyi
+-rw-r--r--   0        0        0      299 2024-05-29 00:18:21.389890 carbon_python_sdk-0.2.0/carbon/paths/scrape_sitemap/__init__.py
+-rw-r--r--   0        0        0    27300 2024-05-29 00:18:21.389993 carbon_python_sdk-0.2.0/carbon/paths/scrape_sitemap/post.py
+-rw-r--r--   0        0        0    27126 2024-05-29 00:18:21.390109 carbon_python_sdk-0.2.0/carbon/paths/scrape_sitemap/post.pyi
+-rw-r--r--   0        0        0      293 2024-05-29 00:18:21.390214 carbon_python_sdk-0.2.0/carbon/paths/search_urls/__init__.py
+-rw-r--r--   0        0        0    14549 2024-05-29 00:18:21.390307 carbon_python_sdk-0.2.0/carbon/paths/search_urls/get.py
+-rw-r--r--   0        0        0    14375 2024-05-29 00:18:21.390504 carbon_python_sdk-0.2.0/carbon/paths/search_urls/get.pyi
+-rw-r--r--   0        0        0      293 2024-05-29 00:18:21.390707 carbon_python_sdk-0.2.0/carbon/paths/text_chunks/__init__.py
+-rw-r--r--   0        0        0    19073 2024-05-29 00:18:21.390798 carbon_python_sdk-0.2.0/carbon/paths/text_chunks/post.py
+-rw-r--r--   0        0        0    18899 2024-05-29 00:18:21.390904 carbon_python_sdk-0.2.0/carbon/paths/text_chunks/post.pyi
+-rw-r--r--   0        0        0      295 2024-05-29 00:18:21.390998 carbon_python_sdk-0.2.0/carbon/paths/update_users/__init__.py
+-rw-r--r--   0        0        0    18200 2024-05-29 00:18:21.391083 carbon_python_sdk-0.2.0/carbon/paths/update_users/post.py
+-rw-r--r--   0        0        0    18063 2024-05-29 00:18:21.391180 carbon_python_sdk-0.2.0/carbon/paths/update_users/post.pyi
+-rw-r--r--   0        0        0      327 2024-05-29 00:18:21.391290 carbon_python_sdk-0.2.0/carbon/paths/upload_chunks_and_embeddings/__init__.py
+-rw-r--r--   0        0        0    20060 2024-05-29 00:18:21.391379 carbon_python_sdk-0.2.0/carbon/paths/upload_chunks_and_embeddings/post.py
+-rw-r--r--   0        0        0    19886 2024-05-29 00:18:21.391487 carbon_python_sdk-0.2.0/carbon/paths/upload_chunks_and_embeddings/post.pyi
+-rw-r--r--   0        0        0      311 2024-05-29 00:18:21.391608 carbon_python_sdk-0.2.0/carbon/paths/upload_file_from_url/__init__.py
+-rw-r--r--   0        0        0    24942 2024-05-29 00:18:21.391709 carbon_python_sdk-0.2.0/carbon/paths/upload_file_from_url/post.py
+-rw-r--r--   0        0        0    24768 2024-05-29 00:18:21.391820 carbon_python_sdk-0.2.0/carbon/paths/upload_file_from_url/post.pyi
+-rw-r--r--   0        0        0      293 2024-05-29 00:18:21.391917 carbon_python_sdk-0.2.0/carbon/paths/upload_text/__init__.py
+-rw-r--r--   0        0        0    20504 2024-05-29 00:18:21.392031 carbon_python_sdk-0.2.0/carbon/paths/upload_text/post.py
+-rw-r--r--   0        0        0    20330 2024-05-29 00:18:21.392156 carbon_python_sdk-0.2.0/carbon/paths/upload_text/post.pyi
+-rw-r--r--   0        0        0      291 2024-05-29 00:18:21.392303 carbon_python_sdk-0.2.0/carbon/paths/uploadfile/__init__.py
+-rw-r--r--   0        0        0    33555 2024-05-29 00:21:37.957956 carbon_python_sdk-0.2.0/carbon/paths/uploadfile/post.py
+-rw-r--r--   0        0        0    33381 2024-05-29 00:21:37.958951 carbon_python_sdk-0.2.0/carbon/paths/uploadfile/post.pyi
+-rw-r--r--   0        0        0      279 2024-05-29 00:18:21.392768 carbon_python_sdk-0.2.0/carbon/paths/user/__init__.py
+-rw-r--r--   0        0        0    14156 2024-05-29 00:18:21.392881 carbon_python_sdk-0.2.0/carbon/paths/user/post.py
+-rw-r--r--   0        0        0    14019 2024-05-29 00:18:21.393098 carbon_python_sdk-0.2.0/carbon/paths/user/post.pyi
+-rw-r--r--   0        0        0      305 2024-05-29 00:18:21.393323 carbon_python_sdk-0.2.0/carbon/paths/user_data_sources/__init__.py
+-rw-r--r--   0        0        0    18865 2024-05-29 00:18:21.393439 carbon_python_sdk-0.2.0/carbon/paths/user_data_sources/post.py
+-rw-r--r--   0        0        0    18691 2024-05-29 00:18:21.393573 carbon_python_sdk-0.2.0/carbon/paths/user_data_sources/post.pyi
+-rw-r--r--   0        0        0      291 2024-05-29 00:18:21.393721 carbon_python_sdk-0.2.0/carbon/paths/user_files/__init__.py
+-rw-r--r--   0        0        0    22374 2024-05-29 00:18:21.393852 carbon_python_sdk-0.2.0/carbon/paths/user_files/post.py
+-rw-r--r--   0        0        0    22200 2024-05-29 00:18:21.394009 carbon_python_sdk-0.2.0/carbon/paths/user_files/post.pyi
+-rw-r--r--   0        0        0      297 2024-05-29 00:18:21.394150 carbon_python_sdk-0.2.0/carbon/paths/user_files_v2/__init__.py
+-rw-r--r--   0        0        0    21370 2024-05-29 00:18:21.394281 carbon_python_sdk-0.2.0/carbon/paths/user_files_v2/post.py
+-rw-r--r--   0        0        0    21196 2024-05-29 00:18:21.394426 carbon_python_sdk-0.2.0/carbon/paths/user_files_v2/post.pyi
+-rw-r--r--   0        0        0      291 2024-05-29 00:18:21.394565 carbon_python_sdk-0.2.0/carbon/paths/web_scrape/__init__.py
+-rw-r--r--   0        0        0    14274 2024-05-29 00:18:21.394684 carbon_python_sdk-0.2.0/carbon/paths/web_scrape/post.py
+-rw-r--r--   0        0        0    14100 2024-05-29 00:18:21.394923 carbon_python_sdk-0.2.0/carbon/paths/web_scrape/post.pyi
+-rw-r--r--   0        0        0      287 2024-05-29 00:18:21.395156 carbon_python_sdk-0.2.0/carbon/paths/webhooks/__init__.py
+-rw-r--r--   0        0        0    17367 2024-05-29 00:18:21.395298 carbon_python_sdk-0.2.0/carbon/paths/webhooks/post.py
+-rw-r--r--   0        0        0    17230 2024-05-29 00:18:21.395463 carbon_python_sdk-0.2.0/carbon/paths/webhooks/post.pyi
+-rw-r--r--   0        0        0        0 2024-05-29 00:18:21.395636 carbon_python_sdk-0.2.0/carbon/pydantic/__init__.py
+-rw-r--r--   0        0        0      559 2024-05-29 00:18:21.395761 carbon_python_sdk-0.2.0/carbon/pydantic/add_webhook_props.py
+-rw-r--r--   0        0        0      586 2024-05-29 00:18:21.395872 carbon_python_sdk-0.2.0/carbon/pydantic/body_create_upload_file_uploadfile_post.py
+-rw-r--r--   0        0        0      760 2024-05-29 00:18:21.395987 carbon_python_sdk-0.2.0/carbon/pydantic/chunk_properties.py
+-rw-r--r--   0        0        0      768 2024-05-29 00:18:21.396126 carbon_python_sdk-0.2.0/carbon/pydantic/chunk_properties_nullable.py
+-rw-r--r--   0        0        0      821 2024-05-29 00:18:21.396264 carbon_python_sdk-0.2.0/carbon/pydantic/chunks_and_embeddings.py
+-rw-r--r--   0        0        0      469 2024-05-29 00:18:21.396382 carbon_python_sdk-0.2.0/carbon/pydantic/chunks_and_embeddings_embedding.py
+-rw-r--r--   0        0        0     1333 2024-05-29 00:18:21.396489 carbon_python_sdk-0.2.0/carbon/pydantic/chunks_and_embeddings_upload_input.py
+-rw-r--r--   0        0        0      438 2024-05-29 00:18:21.396607 carbon_python_sdk-0.2.0/carbon/pydantic/chunks_and_embeddings_upload_input_custom_credentials.py
+-rw-r--r--   0        0        0      418 2024-05-29 00:18:21.396713 carbon_python_sdk-0.2.0/carbon/pydantic/configuration_keys.py
+-rw-r--r--   0        0        0      835 2024-05-29 00:18:21.396828 carbon_python_sdk-0.2.0/carbon/pydantic/confluence_authentication.py
+-rw-r--r--   0        0        0     1791 2024-05-29 00:18:21.396942 carbon_python_sdk-0.2.0/carbon/pydantic/connect_data_source_input.py
+-rw-r--r--   0        0        0      765 2024-05-29 00:18:21.397054 carbon_python_sdk-0.2.0/carbon/pydantic/connect_data_source_response.py
+-rw-r--r--   0        0        0      481 2024-05-29 00:18:21.397162 carbon_python_sdk-0.2.0/carbon/pydantic/custom_credentials_type.py
+-rw-r--r--   0        0        0      424 2024-05-29 00:18:21.397271 carbon_python_sdk-0.2.0/carbon/pydantic/data_source_extended_input.py
+-rw-r--r--   0        0        0      456 2024-05-29 00:18:21.397383 carbon_python_sdk-0.2.0/carbon/pydantic/data_source_last_sync_actions.py
+-rw-r--r--   0        0        0      472 2024-05-29 00:18:21.397492 carbon_python_sdk-0.2.0/carbon/pydantic/data_source_sync_statuses.py
+-rw-r--r--   0        0        0      890 2024-05-29 00:21:37.960154 carbon_python_sdk-0.2.0/carbon/pydantic/data_source_type.py
+-rw-r--r--   0        0        0      898 2024-05-29 00:21:37.960464 carbon_python_sdk-0.2.0/carbon/pydantic/data_source_type_nullable.py
+-rw-r--r--   0        0        0     1187 2024-05-29 00:18:21.397813 carbon_python_sdk-0.2.0/carbon/pydantic/delete_files_query_input.py
+-rw-r--r--   0        0        0      448 2024-05-29 00:18:21.397924 carbon_python_sdk-0.2.0/carbon/pydantic/delete_files_query_input_file_ids.py
+-rw-r--r--   0        0        0      809 2024-05-29 00:18:21.398036 carbon_python_sdk-0.2.0/carbon/pydantic/delete_files_v2_query_input.py
+-rw-r--r--   0        0        0      690 2024-05-29 00:18:21.398146 carbon_python_sdk-0.2.0/carbon/pydantic/delete_users_input.py
+-rw-r--r--   0        0        0      430 2024-05-29 00:18:21.398275 carbon_python_sdk-0.2.0/carbon/pydantic/delete_users_input_customer_ids.py
+-rw-r--r--   0        0        0      694 2024-05-29 00:18:21.398383 carbon_python_sdk-0.2.0/carbon/pydantic/directory_item.py
+-rw-r--r--   0        0        0     1674 2024-05-29 00:18:21.398497 carbon_python_sdk-0.2.0/carbon/pydantic/document_response.py
+-rw-r--r--   0        0        0      665 2024-05-29 00:18:21.398744 carbon_python_sdk-0.2.0/carbon/pydantic/document_response_list.py
+-rw-r--r--   0        0        0      411 2024-05-29 00:18:21.398844 carbon_python_sdk-0.2.0/carbon/pydantic/document_response_tags.py
+-rw-r--r--   0        0        0      463 2024-05-29 00:18:21.398950 carbon_python_sdk-0.2.0/carbon/pydantic/document_response_vector.py
+-rw-r--r--   0        0        0     1021 2024-05-29 00:18:21.399035 carbon_python_sdk-0.2.0/carbon/pydantic/embedding_and_chunk.py
+-rw-r--r--   0        0        0      467 2024-05-29 00:18:21.399115 carbon_python_sdk-0.2.0/carbon/pydantic/embedding_and_chunk_embedding.py
+-rw-r--r--   0        0        0      743 2024-05-29 00:18:21.399202 carbon_python_sdk-0.2.0/carbon/pydantic/embedding_generators.py
+-rw-r--r--   0        0        0      751 2024-05-29 00:18:21.399299 carbon_python_sdk-0.2.0/carbon/pydantic/embedding_generators_nullable.py
+-rw-r--r--   0        0        0      666 2024-05-29 00:18:21.399392 carbon_python_sdk-0.2.0/carbon/pydantic/embedding_properties.py
+-rw-r--r--   0        0        0      780 2024-05-29 00:18:21.399480 carbon_python_sdk-0.2.0/carbon/pydantic/embeddings_and_chunks_filters.py
+-rw-r--r--   0        0        0      470 2024-05-29 00:18:21.399573 carbon_python_sdk-0.2.0/carbon/pydantic/embeddings_and_chunks_order_by_columns.py
+-rw-r--r--   0        0        0     1222 2024-05-29 00:18:21.399658 carbon_python_sdk-0.2.0/carbon/pydantic/embeddings_and_chunks_query_input.py
+-rw-r--r--   0        0        0      711 2024-05-29 00:18:21.399750 carbon_python_sdk-0.2.0/carbon/pydantic/embeddings_and_chunks_response.py
+-rw-r--r--   0        0        0      553 2024-05-29 00:18:21.399841 carbon_python_sdk-0.2.0/carbon/pydantic/external_file_sync_statuses.py
+-rw-r--r--   0        0        0     1780 2024-05-29 00:18:21.399935 carbon_python_sdk-0.2.0/carbon/pydantic/external_source_item.py
+-rw-r--r--   0        0        0      455 2024-05-29 00:18:21.400029 carbon_python_sdk-0.2.0/carbon/pydantic/external_source_items_order_by.py
+-rw-r--r--   0        0        0      781 2024-05-29 00:18:21.400123 carbon_python_sdk-0.2.0/carbon/pydantic/fetch_urls_response.py
+-rw-r--r--   0        0        0      424 2024-05-29 00:18:21.400213 carbon_python_sdk-0.2.0/carbon/pydantic/fetch_urls_response_urls.py
+-rw-r--r--   0        0        0      445 2024-05-29 00:21:37.960716 carbon_python_sdk-0.2.0/carbon/pydantic/file_content_types.py
+-rw-r--r--   0        0        0      453 2024-05-29 00:21:37.961034 carbon_python_sdk-0.2.0/carbon/pydantic/file_content_types_nullable.py
+-rw-r--r--   0        0        0      820 2024-05-29 00:21:37.961290 carbon_python_sdk-0.2.0/carbon/pydantic/file_formats.py
+-rw-r--r--   0        0        0      828 2024-05-29 00:21:37.961543 carbon_python_sdk-0.2.0/carbon/pydantic/file_formats_nullable.py
+-rw-r--r--   0        0        0     1002 2024-05-29 00:18:21.400670 carbon_python_sdk-0.2.0/carbon/pydantic/file_statistics.py
+-rw-r--r--   0        0        0     1010 2024-05-29 00:18:21.400765 carbon_python_sdk-0.2.0/carbon/pydantic/file_statistics_nullable.py
+-rw-r--r--   0        0        0     1240 2024-05-29 00:18:21.400857 carbon_python_sdk-0.2.0/carbon/pydantic/file_sync_config.py
+-rw-r--r--   0        0        0     1248 2024-05-29 00:18:21.400946 carbon_python_sdk-0.2.0/carbon/pydantic/file_sync_config_nullable.py
+-rw-r--r--   0        0        0      492 2024-05-29 00:18:21.401043 carbon_python_sdk-0.2.0/carbon/pydantic/files_query_user_files_deprecated_response.py
+-rw-r--r--   0        0        0     2096 2024-05-29 00:18:21.401133 carbon_python_sdk-0.2.0/carbon/pydantic/fresh_desk_connect_request.py
+-rw-r--r--   0        0        0      723 2024-05-29 00:18:21.401225 carbon_python_sdk-0.2.0/carbon/pydantic/freskdesk_authentication.py
+-rw-r--r--   0        0        0      575 2024-05-29 00:18:21.401318 carbon_python_sdk-0.2.0/carbon/pydantic/generic_success_response.py
+-rw-r--r--   0        0        0     3379 2024-05-29 00:18:21.401417 carbon_python_sdk-0.2.0/carbon/pydantic/get_embedding_documents_body.py
+-rw-r--r--   0        0        0      452 2024-05-29 00:18:21.401516 carbon_python_sdk-0.2.0/carbon/pydantic/get_embedding_documents_body_file_ids.py
+-rw-r--r--   0        0        0      458 2024-05-29 00:18:21.401613 carbon_python_sdk-0.2.0/carbon/pydantic/get_embedding_documents_body_parent_file_ids.py
+-rw-r--r--   0        0        0      477 2024-05-29 00:18:21.401706 carbon_python_sdk-0.2.0/carbon/pydantic/get_embedding_documents_body_query_vector.py
+-rw-r--r--   0        0        0      420 2024-05-29 00:18:21.401797 carbon_python_sdk-0.2.0/carbon/pydantic/get_embedding_documents_body_tags.py
+-rw-r--r--   0        0        0      752 2024-05-29 00:18:21.401888 carbon_python_sdk-0.2.0/carbon/pydantic/gitbook_authetication.py
+-rw-r--r--   0        0        0     1911 2024-05-29 00:18:21.401977 carbon_python_sdk-0.2.0/carbon/pydantic/gitbook_connect_request.py
+-rw-r--r--   0        0        0     1699 2024-05-29 00:18:21.402067 carbon_python_sdk-0.2.0/carbon/pydantic/gitbook_sync_request.py
+-rw-r--r--   0        0        0      429 2024-05-29 00:18:21.402165 carbon_python_sdk-0.2.0/carbon/pydantic/gitbook_sync_request_space_ids.py
+-rw-r--r--   0        0        0      734 2024-05-29 00:18:21.402255 carbon_python_sdk-0.2.0/carbon/pydantic/github_authentication.py
+-rw-r--r--   0        0        0      825 2024-05-29 00:18:21.402345 carbon_python_sdk-0.2.0/carbon/pydantic/github_connect_request.py
+-rw-r--r--   0        0        0      783 2024-05-29 00:18:21.402439 carbon_python_sdk-0.2.0/carbon/pydantic/github_fetch_repos_request.py
+-rw-r--r--   0        0        0      431 2024-05-29 00:18:21.402664 carbon_python_sdk-0.2.0/carbon/pydantic/github_fetch_repos_request_repos.py
+-rw-r--r--   0        0        0     2073 2024-05-29 00:18:21.402759 carbon_python_sdk-0.2.0/carbon/pydantic/gmail_sync_input.py
+-rw-r--r--   0        0        0      432 2024-05-29 00:18:21.402852 carbon_python_sdk-0.2.0/carbon/pydantic/helpdesk_file_types.py
+-rw-r--r--   0        0        0      678 2024-05-29 00:18:21.402944 carbon_python_sdk-0.2.0/carbon/pydantic/http_validation_error.py
+-rw-r--r--   0        0        0      665 2024-05-29 00:18:21.403039 carbon_python_sdk-0.2.0/carbon/pydantic/hybrid_search_tuning_params.py
+-rw-r--r--   0        0        0      673 2024-05-29 00:18:21.403133 carbon_python_sdk-0.2.0/carbon/pydantic/hybrid_search_tuning_params_nullable.py
+-rw-r--r--   0        0        0     1282 2024-05-29 00:18:21.403222 carbon_python_sdk-0.2.0/carbon/pydantic/list_data_source_items_request.py
+-rw-r--r--   0        0        0      710 2024-05-29 00:18:21.403313 carbon_python_sdk-0.2.0/carbon/pydantic/list_data_source_items_response.py
+-rw-r--r--   0        0        0     1035 2024-05-29 00:18:21.403403 carbon_python_sdk-0.2.0/carbon/pydantic/list_items_filters.py
+-rw-r--r--   0        0        0      447 2024-05-29 00:18:21.403493 carbon_python_sdk-0.2.0/carbon/pydantic/list_items_filters_external_ids.py
+-rw-r--r--   0        0        0      439 2024-05-29 00:18:21.403584 carbon_python_sdk-0.2.0/carbon/pydantic/list_items_filters_ids.py
+-rw-r--r--   0        0        0     1093 2024-05-29 00:18:21.403667 carbon_python_sdk-0.2.0/carbon/pydantic/list_items_filters_nullable.py
+-rw-r--r--   0        0        0      455 2024-05-29 00:18:21.403751 carbon_python_sdk-0.2.0/carbon/pydantic/list_items_filters_nullable_external_ids.py
+-rw-r--r--   0        0        0      447 2024-05-29 00:18:21.403837 carbon_python_sdk-0.2.0/carbon/pydantic/list_items_filters_nullable_ids.py
+-rw-r--r--   0        0        0      664 2024-05-29 00:18:21.403916 carbon_python_sdk-0.2.0/carbon/pydantic/list_request.py
+-rw-r--r--   0        0        0      638 2024-05-29 00:18:21.404004 carbon_python_sdk-0.2.0/carbon/pydantic/list_response.py
+-rw-r--r--   0        0        0      733 2024-05-29 00:18:21.404096 carbon_python_sdk-0.2.0/carbon/pydantic/modify_user_configuration_input.py
+-rw-r--r--   0        0        0      742 2024-05-29 00:18:21.404186 carbon_python_sdk-0.2.0/carbon/pydantic/notion_authentication.py
+-rw-r--r--   0        0        0      814 2024-05-29 00:18:21.404287 carbon_python_sdk-0.2.0/carbon/pydantic/o_auth_authentication.py
+-rw-r--r--   0        0        0     4718 2024-05-29 00:21:37.961870 carbon_python_sdk-0.2.0/carbon/pydantic/o_auth_url_request.py
+-rw-r--r--   0        0        0      417 2024-05-29 00:18:21.404494 carbon_python_sdk-0.2.0/carbon/pydantic/order_dir.py
+-rw-r--r--   0        0        0      419 2024-05-29 00:18:21.404585 carbon_python_sdk-0.2.0/carbon/pydantic/order_dir_v2.py
+-rw-r--r--   0        0        0     2547 2024-05-29 00:21:37.962310 carbon_python_sdk-0.2.0/carbon/pydantic/organization_response.py
+-rw-r--r--   0        0        0     2100 2024-05-29 00:18:21.404778 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_data_source_api.py
+-rw-r--r--   0        0        0      998 2024-05-29 00:18:21.404871 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_data_source_filters.py
+-rw-r--r--   0        0        0      456 2024-05-29 00:18:21.404962 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_data_source_filters_ids.py
+-rw-r--r--   0        0        0      462 2024-05-29 00:18:21.405055 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_data_source_order_by_columns.py
+-rw-r--r--   0        0        0     1213 2024-05-29 00:18:21.405155 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_data_source_query_input.py
+-rw-r--r--   0        0        0      756 2024-05-29 00:18:21.405249 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_data_source_response.py
+-rw-r--r--   0        0        0      785 2024-05-29 00:18:21.405346 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_file_tag_create.py
+-rw-r--r--   0        0        0      424 2024-05-29 00:18:21.405432 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_file_tag_create_tags.py
+-rw-r--r--   0        0        0      789 2024-05-29 00:18:21.405516 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_file_tags_remove.py
+-rw-r--r--   0        0        0      437 2024-05-29 00:18:21.405601 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_file_tags_remove_tags.py
+-rw-r--r--   0        0        0     5786 2024-05-29 00:18:21.405689 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_files_to_sync_filters.py
+-rw-r--r--   0        0        0      469 2024-05-29 00:18:21.405776 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_files_to_sync_filters_external_file_ids.py
+-rw-r--r--   0        0        0      457 2024-05-29 00:18:21.405857 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_files_to_sync_filters_ids.py
+-rw-r--r--   0        0        0      482 2024-05-29 00:18:21.405947 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_files_to_sync_filters_organization_user_data_source_id.py
+-rw-r--r--   0        0        0      467 2024-05-29 00:18:21.406037 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_files_to_sync_filters_parent_file_ids.py
+-rw-r--r--   0        0        0      464 2024-05-29 00:18:21.406121 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_files_to_sync_filters_request_ids.py
+-rw-r--r--   0        0        0      429 2024-05-29 00:18:21.406217 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_files_to_sync_filters_tags.py
+-rw-r--r--   0        0        0      501 2024-05-29 00:18:21.406301 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_files_to_sync_order_by_types.py
+-rw-r--r--   0        0        0     1554 2024-05-29 00:18:21.406384 carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_files_to_sync_query_input.py
+-rw-r--r--   0        0        0      571 2024-05-29 00:18:21.406461 carbon_python_sdk-0.2.0/carbon/pydantic/outh_url_response.py
+-rw-r--r--   0        0        0     2156 2024-05-29 00:18:21.406540 carbon_python_sdk-0.2.0/carbon/pydantic/outlook_sync_input.py
+-rw-r--r--   0        0        0      645 2024-05-29 00:18:21.406620 carbon_python_sdk-0.2.0/carbon/pydantic/pagination.py
+-rw-r--r--   0        0        0      584 2024-05-29 00:18:21.406700 carbon_python_sdk-0.2.0/carbon/pydantic/presigned_url_response.py
+-rw-r--r--   0        0        0     1341 2024-05-29 00:18:21.406781 carbon_python_sdk-0.2.0/carbon/pydantic/raw_text_input.py
+-rw-r--r--   0        0        0      861 2024-05-29 00:18:21.406861 carbon_python_sdk-0.2.0/carbon/pydantic/resync_file_query_input.py
+-rw-r--r--   0        0        0      588 2024-05-29 00:18:21.406947 carbon_python_sdk-0.2.0/carbon/pydantic/revoke_access_token_input.py
+-rw-r--r--   0        0        0     1515 2024-05-29 00:18:21.407028 carbon_python_sdk-0.2.0/carbon/pydantic/rss_feed_input.py
+-rw-r--r--   0        0        0      832 2024-05-29 00:18:21.407112 carbon_python_sdk-0.2.0/carbon/pydantic/s3_auth_request.py
+-rw-r--r--   0        0        0      744 2024-05-29 00:18:21.407188 carbon_python_sdk-0.2.0/carbon/pydantic/s3_authentication.py
+-rw-r--r--   0        0        0     2360 2024-05-29 00:18:21.407266 carbon_python_sdk-0.2.0/carbon/pydantic/s3_file_sync_input.py
+-rw-r--r--   0        0        0      677 2024-05-29 00:18:21.407355 carbon_python_sdk-0.2.0/carbon/pydantic/s3_get_file_input.py
+-rw-r--r--   0        0        0      829 2024-05-29 00:18:21.407442 carbon_python_sdk-0.2.0/carbon/pydantic/salesforce_authentication.py
+-rw-r--r--   0        0        0      886 2024-05-29 00:18:21.407531 carbon_python_sdk-0.2.0/carbon/pydantic/sharepoint_authentication.py
+-rw-r--r--   0        0        0      494 2024-05-29 00:18:21.407620 carbon_python_sdk-0.2.0/carbon/pydantic/simple_o_auth_data_sources.py
+-rw-r--r--   0        0        0      942 2024-05-29 00:18:21.407702 carbon_python_sdk-0.2.0/carbon/pydantic/single_chunks_and_embeddings_upload_input.py
+-rw-r--r--   0        0        0     2337 2024-05-29 00:18:21.407789 carbon_python_sdk-0.2.0/carbon/pydantic/sitemap_scrape_request.py
+-rw-r--r--   0        0        0      456 2024-05-29 00:18:21.407884 carbon_python_sdk-0.2.0/carbon/pydantic/sitemap_scrape_request_css_classes_to_skip.py
+-rw-r--r--   0        0        0      458 2024-05-29 00:18:21.407978 carbon_python_sdk-0.2.0/carbon/pydantic/sitemap_scrape_request_css_selectors_to_skip.py
+-rw-r--r--   0        0        0      454 2024-05-29 00:18:21.408081 carbon_python_sdk-0.2.0/carbon/pydantic/sitemap_scrape_request_html_tags_to_skip.py
+-rw-r--r--   0        0        0      415 2024-05-29 00:18:21.408174 carbon_python_sdk-0.2.0/carbon/pydantic/sitemap_scrape_request_tags.py
+-rw-r--r--   0        0        0      586 2024-05-29 00:18:21.408265 carbon_python_sdk-0.2.0/carbon/pydantic/sync_directory_request.py
+-rw-r--r--   0        0        0      597 2024-05-29 00:18:21.408358 carbon_python_sdk-0.2.0/carbon/pydantic/sync_files_ids.py
+-rw-r--r--   0        0        0     2668 2024-05-29 00:18:21.408445 carbon_python_sdk-0.2.0/carbon/pydantic/sync_files_request.py
+-rw-r--r--   0        0        0     2932 2024-05-29 00:18:21.408526 carbon_python_sdk-0.2.0/carbon/pydantic/sync_options.py
+-rw-r--r--   0        0        0      726 2024-05-29 00:18:21.408608 carbon_python_sdk-0.2.0/carbon/pydantic/text_embedding_generators.py
+-rw-r--r--   0        0        0      630 2024-05-29 00:18:21.408691 carbon_python_sdk-0.2.0/carbon/pydantic/token_response.py
+-rw-r--r--   0        0        0      724 2024-05-29 00:18:21.408779 carbon_python_sdk-0.2.0/carbon/pydantic/update_organization_input.py
+-rw-r--r--   0        0        0     1746 2024-05-29 00:18:21.408861 carbon_python_sdk-0.2.0/carbon/pydantic/update_users_input.py
+-rw-r--r--   0        0        0      430 2024-05-29 00:18:21.408951 carbon_python_sdk-0.2.0/carbon/pydantic/update_users_input_customer_ids.py
+-rw-r--r--   0        0        0     1862 2024-05-29 00:18:21.409070 carbon_python_sdk-0.2.0/carbon/pydantic/upload_file_from_url_input.py
+-rw-r--r--   0        0        0     1582 2024-05-29 00:18:21.409155 carbon_python_sdk-0.2.0/carbon/pydantic/user_configuration.py
+-rw-r--r--   0        0        0     1590 2024-05-29 00:18:21.409237 carbon_python_sdk-0.2.0/carbon/pydantic/user_configuration_nullable.py
+-rw-r--r--   0        0        0     3606 2024-05-29 00:18:21.409328 carbon_python_sdk-0.2.0/carbon/pydantic/user_file.py
+-rw-r--r--   0        0        0      487 2024-05-29 00:18:21.409415 carbon_python_sdk-0.2.0/carbon/pydantic/user_file_embedding_properties.py
+-rw-r--r--   0        0        0      667 2024-05-29 00:18:21.409498 carbon_python_sdk-0.2.0/carbon/pydantic/user_files_v2.py
+-rw-r--r--   0        0        0      578 2024-05-29 00:18:21.409646 carbon_python_sdk-0.2.0/carbon/pydantic/user_request_content.py
+-rw-r--r--   0        0        0     2736 2024-05-29 00:21:37.962762 carbon_python_sdk-0.2.0/carbon/pydantic/user_response.py
+-rw-r--r--   0        0        0      503 2024-05-29 00:18:21.409925 carbon_python_sdk-0.2.0/carbon/pydantic/user_response_auto_sync_enabled_sources.py
+-rw-r--r--   0        0        0      432 2024-05-29 00:18:21.410011 carbon_python_sdk-0.2.0/carbon/pydantic/user_response_unique_file_tags.py
+-rw-r--r--   0        0        0      504 2024-05-29 00:18:21.410115 carbon_python_sdk-0.2.0/carbon/pydantic/utilities_scrape_web_request.py
+-rw-r--r--   0        0        0      714 2024-05-29 00:18:21.410225 carbon_python_sdk-0.2.0/carbon/pydantic/validation_error.py
+-rw-r--r--   0        0        0      440 2024-05-29 00:18:21.410333 carbon_python_sdk-0.2.0/carbon/pydantic/validation_error_loc.py
+-rw-r--r--   0        0        0      982 2024-05-29 00:21:37.963262 carbon_python_sdk-0.2.0/carbon/pydantic/webhook.py
+-rw-r--r--   0        0        0      661 2024-05-29 00:18:21.410546 carbon_python_sdk-0.2.0/carbon/pydantic/webhook_filters.py
+-rw-r--r--   0        0        0      437 2024-05-29 00:18:21.410658 carbon_python_sdk-0.2.0/carbon/pydantic/webhook_filters_ids.py
+-rw-r--r--   0        0        0      936 2024-05-29 00:21:37.963773 carbon_python_sdk-0.2.0/carbon/pydantic/webhook_no_key.py
+-rw-r--r--   0        0        0      443 2024-05-29 00:18:21.410886 carbon_python_sdk-0.2.0/carbon/pydantic/webhook_order_by_columns.py
+-rw-r--r--   0        0        0     1074 2024-05-29 00:18:21.411009 carbon_python_sdk-0.2.0/carbon/pydantic/webhook_query_input.py
+-rw-r--r--   0        0        0      689 2024-05-29 00:18:21.411122 carbon_python_sdk-0.2.0/carbon/pydantic/webhook_query_response.py
+-rw-r--r--   0        0        0      428 2024-05-29 00:21:37.964658 carbon_python_sdk-0.2.0/carbon/pydantic/webhook_status.py
+-rw-r--r--   0        0        0     2380 2024-05-29 00:18:21.411327 carbon_python_sdk-0.2.0/carbon/pydantic/webscrape_request.py
+-rw-r--r--   0        0        0      452 2024-05-29 00:18:21.411590 carbon_python_sdk-0.2.0/carbon/pydantic/webscrape_request_css_classes_to_skip.py
+-rw-r--r--   0        0        0      454 2024-05-29 00:18:21.411702 carbon_python_sdk-0.2.0/carbon/pydantic/webscrape_request_css_selectors_to_skip.py
+-rw-r--r--   0        0        0      450 2024-05-29 00:18:21.411792 carbon_python_sdk-0.2.0/carbon/pydantic/webscrape_request_html_tags_to_skip.py
+-rw-r--r--   0        0        0      411 2024-05-29 00:18:21.411883 carbon_python_sdk-0.2.0/carbon/pydantic/webscrape_request_tags.py
+-rw-r--r--   0        0        0      727 2024-05-29 00:18:21.411975 carbon_python_sdk-0.2.0/carbon/pydantic/white_labeling_response.py
+-rw-r--r--   0        0        0      887 2024-05-29 00:18:21.412073 carbon_python_sdk-0.2.0/carbon/pydantic/youtube_transcript_response.py
+-rw-r--r--   0        0        0      616 2024-05-29 00:18:21.412163 carbon_python_sdk-0.2.0/carbon/pydantic/youtube_transcript_response_raw_transcript.py
+-rw-r--r--   0        0        0      433 2024-05-29 00:18:21.412259 carbon_python_sdk-0.2.0/carbon/pydantic/youtube_transcript_response_raw_transcript_item.py
+-rw-r--r--   0        0        0      737 2024-05-29 00:18:21.412357 carbon_python_sdk-0.2.0/carbon/pydantic/zendesk_authentication.py
+-rw-r--r--   0        0        0      848 2024-05-29 00:18:21.412456 carbon_python_sdk-0.2.0/carbon/pydantic/zotero_authentication.py
+-rw-r--r--   0        0        0      654 2024-05-29 00:18:21.412623 carbon_python_sdk-0.2.0/carbon/request_after_hook.py
+-rw-r--r--   0        0        0      712 2024-05-29 00:18:21.412746 carbon_python_sdk-0.2.0/carbon/request_before_hook.py
+-rw-r--r--   0        0        0      677 2024-05-29 00:18:21.412865 carbon_python_sdk-0.2.0/carbon/request_before_url_hook.py
+-rw-r--r--   0        0        0    10974 2024-05-29 00:18:21.412998 carbon_python_sdk-0.2.0/carbon/rest.py
+-rw-r--r--   0        0        0    96042 2024-05-29 00:18:21.413237 carbon_python_sdk-0.2.0/carbon/schemas.py
+-rw-r--r--   0        0        0        0 2024-05-29 00:18:21.413422 carbon_python_sdk-0.2.0/carbon/type/__init__.py
+-rw-r--r--   0        0        0      525 2024-05-29 00:18:21.413557 carbon_python_sdk-0.2.0/carbon/type/add_webhook_props.py
+-rw-r--r--   0        0        0      627 2024-05-29 00:18:21.413788 carbon_python_sdk-0.2.0/carbon/type/body_create_upload_file_uploadfile_post.py
+-rw-r--r--   0        0        0      628 2024-05-29 00:18:21.413902 carbon_python_sdk-0.2.0/carbon/type/chunk_properties.py
+-rw-r--r--   0        0        0      668 2024-05-29 00:18:21.414026 carbon_python_sdk-0.2.0/carbon/type/chunk_properties_nullable.py
+-rw-r--r--   0        0        0      725 2024-05-29 00:18:21.414147 carbon_python_sdk-0.2.0/carbon/type/chunks_and_embeddings.py
+-rw-r--r--   0        0        0      408 2024-05-29 00:18:21.414286 carbon_python_sdk-0.2.0/carbon/type/chunks_and_embeddings_embedding.py
+-rw-r--r--   0        0        0     1117 2024-05-29 00:18:21.414412 carbon_python_sdk-0.2.0/carbon/type/chunks_and_embeddings_upload_input.py
+-rw-r--r--   0        0        0      377 2024-05-29 00:18:21.414545 carbon_python_sdk-0.2.0/carbon/type/chunks_and_embeddings_upload_input_custom_credentials.py
+-rw-r--r--   0        0        0      346 2024-05-29 00:18:21.414645 carbon_python_sdk-0.2.0/carbon/type/configuration_keys.py
+-rw-r--r--   0        0        0      714 2024-05-29 00:18:21.414754 carbon_python_sdk-0.2.0/carbon/type/confluence_authentication.py
+-rw-r--r--   0        0        0     1664 2024-05-29 00:18:21.414853 carbon_python_sdk-0.2.0/carbon/type/connect_data_source_input.py
+-rw-r--r--   0        0        0      733 2024-05-29 00:18:21.414965 carbon_python_sdk-0.2.0/carbon/type/connect_data_source_response.py
+-rw-r--r--   0        0        0      420 2024-05-29 00:18:21.415094 carbon_python_sdk-0.2.0/carbon/type/custom_credentials_type.py
+-rw-r--r--   0        0        0      352 2024-05-29 00:18:21.415216 carbon_python_sdk-0.2.0/carbon/type/data_source_extended_input.py
+-rw-r--r--   0        0        0      395 2024-05-29 00:18:21.415324 carbon_python_sdk-0.2.0/carbon/type/data_source_last_sync_actions.py
+-rw-r--r--   0        0        0      411 2024-05-29 00:18:21.415425 carbon_python_sdk-0.2.0/carbon/type/data_source_sync_statuses.py
+-rw-r--r--   0        0        0      829 2024-05-29 00:21:37.965633 carbon_python_sdk-0.2.0/carbon/type/data_source_type.py
+-rw-r--r--   0        0        0      837 2024-05-29 00:21:37.966879 carbon_python_sdk-0.2.0/carbon/type/data_source_type_nullable.py
+-rw-r--r--   0        0        0      929 2024-05-29 00:18:21.415732 carbon_python_sdk-0.2.0/carbon/type/delete_files_query_input.py
+-rw-r--r--   0        0        0      387 2024-05-29 00:18:21.415836 carbon_python_sdk-0.2.0/carbon/type/delete_files_query_input_file_ids.py
+-rw-r--r--   0        0        0      723 2024-05-29 00:18:21.415931 carbon_python_sdk-0.2.0/carbon/type/delete_files_v2_query_input.py
+-rw-r--r--   0        0        0      647 2024-05-29 00:18:21.416026 carbon_python_sdk-0.2.0/carbon/type/delete_users_input.py
+-rw-r--r--   0        0        0      369 2024-05-29 00:18:21.416123 carbon_python_sdk-0.2.0/carbon/type/delete_users_input_customer_ids.py
+-rw-r--r--   0        0        0      574 2024-05-29 00:18:21.416235 carbon_python_sdk-0.2.0/carbon/type/directory_item.py
+-rw-r--r--   0        0        0     1356 2024-05-29 00:18:21.416333 carbon_python_sdk-0.2.0/carbon/type/document_response.py
+-rw-r--r--   0        0        0      641 2024-05-29 00:18:21.416426 carbon_python_sdk-0.2.0/carbon/type/document_response_list.py
+-rw-r--r--   0        0        0      350 2024-05-29 00:18:21.416517 carbon_python_sdk-0.2.0/carbon/type/document_response_tags.py
+-rw-r--r--   0        0        0      402 2024-05-29 00:18:21.416615 carbon_python_sdk-0.2.0/carbon/type/document_response_vector.py
+-rw-r--r--   0        0        0      877 2024-05-29 00:18:21.416711 carbon_python_sdk-0.2.0/carbon/type/embedding_and_chunk.py
+-rw-r--r--   0        0        0      406 2024-05-29 00:18:21.416816 carbon_python_sdk-0.2.0/carbon/type/embedding_and_chunk_embedding.py
+-rw-r--r--   0        0        0      682 2024-05-29 00:18:21.416908 carbon_python_sdk-0.2.0/carbon/type/embedding_generators.py
+-rw-r--r--   0        0        0      690 2024-05-29 00:18:21.417005 carbon_python_sdk-0.2.0/carbon/type/embedding_generators_nullable.py
+-rw-r--r--   0        0        0      610 2024-05-29 00:18:21.417103 carbon_python_sdk-0.2.0/carbon/type/embedding_properties.py
+-rw-r--r--   0        0        0      729 2024-05-29 00:18:21.417195 carbon_python_sdk-0.2.0/carbon/type/embeddings_and_chunks_filters.py
+-rw-r--r--   0        0        0      409 2024-05-29 00:18:21.417295 carbon_python_sdk-0.2.0/carbon/type/embeddings_and_chunks_order_by_columns.py
+-rw-r--r--   0        0        0     1009 2024-05-29 00:18:21.417389 carbon_python_sdk-0.2.0/carbon/type/embeddings_and_chunks_query_input.py
+-rw-r--r--   0        0        0      694 2024-05-29 00:18:21.417483 carbon_python_sdk-0.2.0/carbon/type/embeddings_and_chunks_response.py
+-rw-r--r--   0        0        0      492 2024-05-29 00:18:21.417572 carbon_python_sdk-0.2.0/carbon/type/external_file_sync_statuses.py
+-rw-r--r--   0        0        0     1189 2024-05-29 00:18:21.417664 carbon_python_sdk-0.2.0/carbon/type/external_source_item.py
+-rw-r--r--   0        0        0      394 2024-05-29 00:18:21.417751 carbon_python_sdk-0.2.0/carbon/type/external_source_items_order_by.py
+-rw-r--r--   0        0        0      689 2024-05-29 00:18:21.418101 carbon_python_sdk-0.2.0/carbon/type/fetch_urls_response.py
+-rw-r--r--   0        0        0      363 2024-05-29 00:18:21.418216 carbon_python_sdk-0.2.0/carbon/type/fetch_urls_response_urls.py
+-rw-r--r--   0        0        0      384 2024-05-29 00:21:37.967846 carbon_python_sdk-0.2.0/carbon/type/file_content_types.py
+-rw-r--r--   0        0        0      392 2024-05-29 00:21:37.968732 carbon_python_sdk-0.2.0/carbon/type/file_content_types_nullable.py
+-rw-r--r--   0        0        0      759 2024-05-29 00:21:37.969116 carbon_python_sdk-0.2.0/carbon/type/file_formats.py
+-rw-r--r--   0        0        0      767 2024-05-29 00:21:37.969404 carbon_python_sdk-0.2.0/carbon/type/file_formats_nullable.py
+-rw-r--r--   0        0        0      823 2024-05-29 00:18:21.418762 carbon_python_sdk-0.2.0/carbon/type/file_statistics.py
+-rw-r--r--   0        0        0      863 2024-05-29 00:18:21.418858 carbon_python_sdk-0.2.0/carbon/type/file_statistics_nullable.py
+-rw-r--r--   0        0        0     1035 2024-05-29 00:18:21.418943 carbon_python_sdk-0.2.0/carbon/type/file_sync_config.py
+-rw-r--r--   0        0        0     1075 2024-05-29 00:18:21.419030 carbon_python_sdk-0.2.0/carbon/type/file_sync_config_nullable.py
+-rw-r--r--   0        0        0      427 2024-05-29 00:18:21.419128 carbon_python_sdk-0.2.0/carbon/type/files_query_user_files_deprecated_response.py
+-rw-r--r--   0        0        0     1449 2024-05-29 00:18:21.419211 carbon_python_sdk-0.2.0/carbon/type/fresh_desk_connect_request.py
+-rw-r--r--   0        0        0      669 2024-05-29 00:18:21.419293 carbon_python_sdk-0.2.0/carbon/type/freskdesk_authentication.py
+-rw-r--r--   0        0        0      565 2024-05-29 00:18:21.419380 carbon_python_sdk-0.2.0/carbon/type/generic_success_response.py
+-rw-r--r--   0        0        0     2735 2024-05-29 00:18:21.419497 carbon_python_sdk-0.2.0/carbon/type/get_embedding_documents_body.py
+-rw-r--r--   0        0        0      391 2024-05-29 00:18:21.419586 carbon_python_sdk-0.2.0/carbon/type/get_embedding_documents_body_file_ids.py
+-rw-r--r--   0        0        0      397 2024-05-29 00:18:21.419671 carbon_python_sdk-0.2.0/carbon/type/get_embedding_documents_body_parent_file_ids.py
+-rw-r--r--   0        0        0      416 2024-05-29 00:18:21.419759 carbon_python_sdk-0.2.0/carbon/type/get_embedding_documents_body_query_vector.py
+-rw-r--r--   0        0        0      359 2024-05-29 00:18:21.419857 carbon_python_sdk-0.2.0/carbon/type/get_embedding_documents_body_tags.py
+-rw-r--r--   0        0        0      670 2024-05-29 00:18:21.419947 carbon_python_sdk-0.2.0/carbon/type/gitbook_authetication.py
+-rw-r--r--   0        0        0     1272 2024-05-29 00:18:21.420031 carbon_python_sdk-0.2.0/carbon/type/gitbook_connect_request.py
+-rw-r--r--   0        0        0     1168 2024-05-29 00:18:21.420114 carbon_python_sdk-0.2.0/carbon/type/gitbook_sync_request.py
+-rw-r--r--   0        0        0      368 2024-05-29 00:18:21.420199 carbon_python_sdk-0.2.0/carbon/type/gitbook_sync_request_space_ids.py
+-rw-r--r--   0        0        0      661 2024-05-29 00:18:21.420296 carbon_python_sdk-0.2.0/carbon/type/github_authentication.py
+-rw-r--r--   0        0        0      709 2024-05-29 00:18:21.420383 carbon_python_sdk-0.2.0/carbon/type/github_connect_request.py
+-rw-r--r--   0        0        0      711 2024-05-29 00:18:21.420468 carbon_python_sdk-0.2.0/carbon/type/github_fetch_repos_request.py
+-rw-r--r--   0        0        0      370 2024-05-29 00:18:21.420566 carbon_python_sdk-0.2.0/carbon/type/github_fetch_repos_request_repos.py
+-rw-r--r--   0        0        0     1351 2024-05-29 00:18:21.420650 carbon_python_sdk-0.2.0/carbon/type/gmail_sync_input.py
+-rw-r--r--   0        0        0      371 2024-05-29 00:18:21.420735 carbon_python_sdk-0.2.0/carbon/type/helpdesk_file_types.py
+-rw-r--r--   0        0        0      630 2024-05-29 00:18:21.420936 carbon_python_sdk-0.2.0/carbon/type/http_validation_error.py
+-rw-r--r--   0        0        0      636 2024-05-29 00:18:21.421025 carbon_python_sdk-0.2.0/carbon/type/hybrid_search_tuning_params.py
+-rw-r--r--   0        0        0      676 2024-05-29 00:18:21.421119 carbon_python_sdk-0.2.0/carbon/type/hybrid_search_tuning_params_nullable.py
+-rw-r--r--   0        0        0     1025 2024-05-29 00:18:21.421217 carbon_python_sdk-0.2.0/carbon/type/list_data_source_items_request.py
+-rw-r--r--   0        0        0      695 2024-05-29 00:18:21.421312 carbon_python_sdk-0.2.0/carbon/type/list_data_source_items_response.py
+-rw-r--r--   0        0        0      854 2024-05-29 00:18:21.421411 carbon_python_sdk-0.2.0/carbon/type/list_items_filters.py
+-rw-r--r--   0        0        0      386 2024-05-29 00:18:21.421511 carbon_python_sdk-0.2.0/carbon/type/list_items_filters_external_ids.py
+-rw-r--r--   0        0        0      378 2024-05-29 00:18:21.421605 carbon_python_sdk-0.2.0/carbon/type/list_items_filters_ids.py
+-rw-r--r--   0        0        0      944 2024-05-29 00:18:21.421702 carbon_python_sdk-0.2.0/carbon/type/list_items_filters_nullable.py
+-rw-r--r--   0        0        0      394 2024-05-29 00:18:21.421798 carbon_python_sdk-0.2.0/carbon/type/list_items_filters_nullable_external_ids.py
+-rw-r--r--   0        0        0      386 2024-05-29 00:18:21.421893 carbon_python_sdk-0.2.0/carbon/type/list_items_filters_nullable_ids.py
+-rw-r--r--   0        0        0      544 2024-05-29 00:18:21.421977 carbon_python_sdk-0.2.0/carbon/type/list_request.py
+-rw-r--r--   0        0        0      587 2024-05-29 00:18:21.422062 carbon_python_sdk-0.2.0/carbon/type/list_response.py
+-rw-r--r--   0        0        0      709 2024-05-29 00:18:21.422142 carbon_python_sdk-0.2.0/carbon/type/modify_user_configuration_input.py
+-rw-r--r--   0        0        0      665 2024-05-29 00:18:21.422228 carbon_python_sdk-0.2.0/carbon/type/notion_authentication.py
+-rw-r--r--   0        0        0      696 2024-05-29 00:18:21.422311 carbon_python_sdk-0.2.0/carbon/type/o_auth_authentication.py
+-rw-r--r--   0        0        0     3249 2024-05-29 00:21:37.969823 carbon_python_sdk-0.2.0/carbon/type/o_auth_url_request.py
+-rw-r--r--   0        0        0      356 2024-05-29 00:18:21.422482 carbon_python_sdk-0.2.0/carbon/type/order_dir.py
+-rw-r--r--   0        0        0      358 2024-05-29 00:18:21.422567 carbon_python_sdk-0.2.0/carbon/type/order_dir_v2.py
+-rw-r--r--   0        0        0     1922 2024-05-29 00:21:37.970197 carbon_python_sdk-0.2.0/carbon/type/organization_response.py
+-rw-r--r--   0        0        0     1567 2024-05-29 00:18:21.422743 carbon_python_sdk-0.2.0/carbon/type/organization_user_data_source_api.py
+-rw-r--r--   0        0        0      937 2024-05-29 00:18:21.422832 carbon_python_sdk-0.2.0/carbon/type/organization_user_data_source_filters.py
+-rw-r--r--   0        0        0      395 2024-05-29 00:18:21.422918 carbon_python_sdk-0.2.0/carbon/type/organization_user_data_source_filters_ids.py
+-rw-r--r--   0        0        0      401 2024-05-29 00:18:21.422999 carbon_python_sdk-0.2.0/carbon/type/organization_user_data_source_order_by_columns.py
+-rw-r--r--   0        0        0     1070 2024-05-29 00:18:21.423084 carbon_python_sdk-0.2.0/carbon/type/organization_user_data_source_query_input.py
+-rw-r--r--   0        0        0      767 2024-05-29 00:18:21.423169 carbon_python_sdk-0.2.0/carbon/type/organization_user_data_source_response.py
+-rw-r--r--   0        0        0      759 2024-05-29 00:18:21.423252 carbon_python_sdk-0.2.0/carbon/type/organization_user_file_tag_create.py
+-rw-r--r--   0        0        0      363 2024-05-29 00:18:21.423332 carbon_python_sdk-0.2.0/carbon/type/organization_user_file_tag_create_tags.py
+-rw-r--r--   0        0        0      767 2024-05-29 00:18:21.423413 carbon_python_sdk-0.2.0/carbon/type/organization_user_file_tags_remove.py
+-rw-r--r--   0        0        0      376 2024-05-29 00:18:21.423495 carbon_python_sdk-0.2.0/carbon/type/organization_user_file_tags_remove_tags.py
+-rw-r--r--   0        0        0     5041 2024-05-29 00:18:21.423599 carbon_python_sdk-0.2.0/carbon/type/organization_user_files_to_sync_filters.py
+-rw-r--r--   0        0        0      408 2024-05-29 00:18:21.423692 carbon_python_sdk-0.2.0/carbon/type/organization_user_files_to_sync_filters_external_file_ids.py
+-rw-r--r--   0        0        0      396 2024-05-29 00:18:21.423788 carbon_python_sdk-0.2.0/carbon/type/organization_user_files_to_sync_filters_ids.py
+-rw-r--r--   0        0        0      421 2024-05-29 00:18:21.423905 carbon_python_sdk-0.2.0/carbon/type/organization_user_files_to_sync_filters_organization_user_data_source_id.py
+-rw-r--r--   0        0        0      406 2024-05-29 00:18:21.424004 carbon_python_sdk-0.2.0/carbon/type/organization_user_files_to_sync_filters_parent_file_ids.py
+-rw-r--r--   0        0        0      403 2024-05-29 00:18:21.424103 carbon_python_sdk-0.2.0/carbon/type/organization_user_files_to_sync_filters_request_ids.py
+-rw-r--r--   0        0        0      368 2024-05-29 00:18:21.424196 carbon_python_sdk-0.2.0/carbon/type/organization_user_files_to_sync_filters_tags.py
+-rw-r--r--   0        0        0      440 2024-05-29 00:18:21.424295 carbon_python_sdk-0.2.0/carbon/type/organization_user_files_to_sync_order_by_types.py
+-rw-r--r--   0        0        0     1228 2024-05-29 00:18:21.424518 carbon_python_sdk-0.2.0/carbon/type/organization_user_files_to_sync_query_input.py
+-rw-r--r--   0        0        0      531 2024-05-29 00:18:21.424614 carbon_python_sdk-0.2.0/carbon/type/outh_url_response.py
+-rw-r--r--   0        0        0     1395 2024-05-29 00:18:21.424704 carbon_python_sdk-0.2.0/carbon/type/outlook_sync_input.py
+-rw-r--r--   0        0        0      519 2024-05-29 00:18:21.424797 carbon_python_sdk-0.2.0/carbon/type/pagination.py
+-rw-r--r--   0        0        0      560 2024-05-29 00:18:21.424891 carbon_python_sdk-0.2.0/carbon/type/presigned_url_response.py
+-rw-r--r--   0        0        0      900 2024-05-29 00:18:21.424972 carbon_python_sdk-0.2.0/carbon/type/raw_text_input.py
+-rw-r--r--   0        0        0      662 2024-05-29 00:18:21.425055 carbon_python_sdk-0.2.0/carbon/type/resync_file_query_input.py
+-rw-r--r--   0        0        0      571 2024-05-29 00:18:21.425138 carbon_python_sdk-0.2.0/carbon/type/revoke_access_token_input.py
+-rw-r--r--   0        0        0     1002 2024-05-29 00:18:21.425224 carbon_python_sdk-0.2.0/carbon/type/rss_feed_input.py
+-rw-r--r--   0        0        0      681 2024-05-29 00:18:21.425305 carbon_python_sdk-0.2.0/carbon/type/s3_auth_request.py
+-rw-r--r--   0        0        0      648 2024-05-29 00:18:21.425389 carbon_python_sdk-0.2.0/carbon/type/s3_authentication.py
+-rw-r--r--   0        0        0     1521 2024-05-29 00:18:21.425478 carbon_python_sdk-0.2.0/carbon/type/s3_file_sync_input.py
+-rw-r--r--   0        0        0      570 2024-05-29 00:18:21.425561 carbon_python_sdk-0.2.0/carbon/type/s3_get_file_input.py
+-rw-r--r--   0        0        0      711 2024-05-29 00:18:21.425646 carbon_python_sdk-0.2.0/carbon/type/salesforce_authentication.py
+-rw-r--r--   0        0        0      736 2024-05-29 00:18:21.425728 carbon_python_sdk-0.2.0/carbon/type/sharepoint_authentication.py
+-rw-r--r--   0        0        0      433 2024-05-29 00:18:21.425836 carbon_python_sdk-0.2.0/carbon/type/simple_o_auth_data_sources.py
+-rw-r--r--   0        0        0      831 2024-05-29 00:18:21.426051 carbon_python_sdk-0.2.0/carbon/type/single_chunks_and_embeddings_upload_input.py
+-rw-r--r--   0        0        0     1662 2024-05-29 00:18:21.426134 carbon_python_sdk-0.2.0/carbon/type/sitemap_scrape_request.py
+-rw-r--r--   0        0        0      395 2024-05-29 00:18:21.426215 carbon_python_sdk-0.2.0/carbon/type/sitemap_scrape_request_css_classes_to_skip.py
+-rw-r--r--   0        0        0      397 2024-05-29 00:18:21.426297 carbon_python_sdk-0.2.0/carbon/type/sitemap_scrape_request_css_selectors_to_skip.py
+-rw-r--r--   0        0        0      393 2024-05-29 00:18:21.426378 carbon_python_sdk-0.2.0/carbon/type/sitemap_scrape_request_html_tags_to_skip.py
+-rw-r--r--   0        0        0      354 2024-05-29 00:18:21.426462 carbon_python_sdk-0.2.0/carbon/type/sitemap_scrape_request_tags.py
+-rw-r--r--   0        0        0      561 2024-05-29 00:18:21.426550 carbon_python_sdk-0.2.0/carbon/type/sync_directory_request.py
+-rw-r--r--   0        0        0      527 2024-05-29 00:18:21.426633 carbon_python_sdk-0.2.0/carbon/type/sync_files_ids.py
+-rw-r--r--   0        0        0     1816 2024-05-29 00:18:21.426715 carbon_python_sdk-0.2.0/carbon/type/sync_files_request.py
+-rw-r--r--   0        0        0     2058 2024-05-29 00:18:21.426794 carbon_python_sdk-0.2.0/carbon/type/sync_options.py
+-rw-r--r--   0        0        0      665 2024-05-29 00:18:21.426877 carbon_python_sdk-0.2.0/carbon/type/text_embedding_generators.py
+-rw-r--r--   0        0        0      548 2024-05-29 00:18:21.426967 carbon_python_sdk-0.2.0/carbon/type/token_response.py
+-rw-r--r--   0        0        0      697 2024-05-29 00:18:21.427058 carbon_python_sdk-0.2.0/carbon/type/update_organization_input.py
+-rw-r--r--   0        0        0     1513 2024-05-29 00:18:21.427145 carbon_python_sdk-0.2.0/carbon/type/update_users_input.py
+-rw-r--r--   0        0        0      369 2024-05-29 00:18:21.427242 carbon_python_sdk-0.2.0/carbon/type/update_users_input_customer_ids.py
+-rw-r--r--   0        0        0     1133 2024-05-29 00:18:21.427341 carbon_python_sdk-0.2.0/carbon/type/upload_file_from_url_input.py
+-rw-r--r--   0        0        0     1396 2024-05-29 00:18:21.427438 carbon_python_sdk-0.2.0/carbon/type/user_configuration.py
+-rw-r--r--   0        0        0     1436 2024-05-29 00:18:21.427534 carbon_python_sdk-0.2.0/carbon/type/user_configuration_nullable.py
+-rw-r--r--   0        0        0     2555 2024-05-29 00:18:21.427618 carbon_python_sdk-0.2.0/carbon/type/user_file.py
+-rw-r--r--   0        0        0      422 2024-05-29 00:18:21.427706 carbon_python_sdk-0.2.0/carbon/type/user_file_embedding_properties.py
+-rw-r--r--   0        0        0      586 2024-05-29 00:18:21.427799 carbon_python_sdk-0.2.0/carbon/type/user_files_v2.py
+-rw-r--r--   0        0        0      548 2024-05-29 00:18:21.428026 carbon_python_sdk-0.2.0/carbon/type/user_request_content.py
+-rw-r--r--   0        0        0     2011 2024-05-29 00:21:37.970937 carbon_python_sdk-0.2.0/carbon/type/user_response.py
+-rw-r--r--   0        0        0      442 2024-05-29 00:18:21.428196 carbon_python_sdk-0.2.0/carbon/type/user_response_auto_sync_enabled_sources.py
+-rw-r--r--   0        0        0      371 2024-05-29 00:18:21.428281 carbon_python_sdk-0.2.0/carbon/type/user_response_unique_file_tags.py
+-rw-r--r--   0        0        0      439 2024-05-29 00:18:21.428375 carbon_python_sdk-0.2.0/carbon/type/utilities_scrape_web_request.py
+-rw-r--r--   0        0        0      633 2024-05-29 00:18:21.428454 carbon_python_sdk-0.2.0/carbon/type/validation_error.py
+-rw-r--r--   0        0        0      379 2024-05-29 00:18:21.428532 carbon_python_sdk-0.2.0/carbon/type/validation_error_loc.py
+-rw-r--r--   0        0        0      719 2024-05-29 00:21:37.972176 carbon_python_sdk-0.2.0/carbon/type/webhook.py
+-rw-r--r--   0        0        0      613 2024-05-29 00:18:21.428687 carbon_python_sdk-0.2.0/carbon/type/webhook_filters.py
+-rw-r--r--   0        0        0      376 2024-05-29 00:18:21.428764 carbon_python_sdk-0.2.0/carbon/type/webhook_filters_ids.py
+-rw-r--r--   0        0        0      722 2024-05-29 00:21:37.973095 carbon_python_sdk-0.2.0/carbon/type/webhook_no_key.py
+-rw-r--r--   0        0        0      382 2024-05-29 00:18:21.428923 carbon_python_sdk-0.2.0/carbon/type/webhook_order_by_columns.py
+-rw-r--r--   0        0        0      855 2024-05-29 00:18:21.429003 carbon_python_sdk-0.2.0/carbon/type/webhook_query_input.py
+-rw-r--r--   0        0        0      644 2024-05-29 00:18:21.429085 carbon_python_sdk-0.2.0/carbon/type/webhook_query_response.py
+-rw-r--r--   0        0        0      367 2024-05-29 00:21:37.973298 carbon_python_sdk-0.2.0/carbon/type/webhook_status.py
+-rw-r--r--   0        0        0     1633 2024-05-29 00:18:21.429243 carbon_python_sdk-0.2.0/carbon/type/webscrape_request.py
+-rw-r--r--   0        0        0      391 2024-05-29 00:18:21.429327 carbon_python_sdk-0.2.0/carbon/type/webscrape_request_css_classes_to_skip.py
+-rw-r--r--   0        0        0      393 2024-05-29 00:18:21.429413 carbon_python_sdk-0.2.0/carbon/type/webscrape_request_css_selectors_to_skip.py
+-rw-r--r--   0        0        0      389 2024-05-29 00:18:21.429496 carbon_python_sdk-0.2.0/carbon/type/webscrape_request_html_tags_to_skip.py
+-rw-r--r--   0        0        0      350 2024-05-29 00:18:21.429578 carbon_python_sdk-0.2.0/carbon/type/webscrape_request_tags.py
+-rw-r--r--   0        0        0      675 2024-05-29 00:18:21.429658 carbon_python_sdk-0.2.0/carbon/type/white_labeling_response.py
+-rw-r--r--   0        0        0      826 2024-05-29 00:18:21.429742 carbon_python_sdk-0.2.0/carbon/type/youtube_transcript_response.py
+-rw-r--r--   0        0        0      551 2024-05-29 00:18:21.429833 carbon_python_sdk-0.2.0/carbon/type/youtube_transcript_response_raw_transcript.py
+-rw-r--r--   0        0        0      372 2024-05-29 00:18:21.429926 carbon_python_sdk-0.2.0/carbon/type/youtube_transcript_response_raw_transcript_item.py
+-rw-r--r--   0        0        0      667 2024-05-29 00:18:21.430014 carbon_python_sdk-0.2.0/carbon/type/zendesk_authentication.py
+-rw-r--r--   0        0        0      711 2024-05-29 00:18:21.430106 carbon_python_sdk-0.2.0/carbon/type/zotero_authentication.py
+-rw-r--r--   0        0        0      514 2024-05-29 00:18:21.430201 carbon_python_sdk-0.2.0/carbon/type_util.py
+-rw-r--r--   0        0        0     3162 2024-05-29 00:18:21.430296 carbon_python_sdk-0.2.0/carbon/validation_metadata.py
+-rw-r--r--   0        0        0      746 2024-05-29 00:21:37.974084 carbon_python_sdk-0.2.0/pyproject.toml
+-rw-r--r--   0        0        0   113673 1970-01-01 00:00:00.000000 carbon_python_sdk-0.2.0/PKG-INFO
```

### Comparing `carbon_python_sdk-0.1.9/LICENSE` & `carbon_python_sdk-0.2.0/LICENSE`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/README.md` & `carbon_python_sdk-0.2.0/PKG-INFO`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,42 @@
+Metadata-Version: 2.1
+Name: carbon-python-sdk
+Version: 0.2.0
+Summary: Client for Carbon
+License: MIT
+Author: Konfig
+Author-email: engineering@konfigthis.com
+Requires-Python: >=3.8,<4.0
+Classifier: License :: OSI Approved :: MIT License
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
+Classifier: Programming Language :: Python :: 3.12
+Requires-Dist: aiohttp (>=3.9.2,<4.0.0)
+Requires-Dist: certifi (>=2023.7.22)
+Requires-Dist: cryptography (>=42.0.5,<43.0.0)
+Requires-Dist: frozendict (>=2.3.4,<3.0.0)
+Requires-Dist: pydantic (>=2.4.2,<3.0.0)
+Requires-Dist: python-dateutil (>=2.8.2,<3.0.0)
+Requires-Dist: typing_extensions (>=4.3.0,<5.0.0)
+Requires-Dist: urllib3 (>=1.26.18,<3.0.0)
+Description-Content-Type: text/markdown
+
 <div align="center">
 
 [![Visit Carbon](https://raw.githubusercontent.com/Carbon-for-Developers/carbon-sdks/HEAD/python/header.png)](https://carbon.ai)
 
 # Carbon<a id="carbon"></a>
 
 Connect external data to LLMs, no matter the source.
 
 
-[![PyPI](https://img.shields.io/badge/PyPI-v0.1.9-blue)](https://pypi.org/project/carbon-python-sdk/0.1.9)
+[![PyPI](https://img.shields.io/badge/PyPI-v0.2.0-blue)](https://pypi.org/project/carbon-python-sdk/0.2.0)
 [![README.md](https://img.shields.io/badge/README-Click%20Here-green)](https://github.com/Carbon-for-Developers/carbon-sdks/tree/main/python#readme)
 
 </div>
 
 ## Table of Contents<a id="table-of-contents"></a>
 
 <!-- toc -->
@@ -29,14 +54,15 @@
   * [`carbon.embeddings.get_documents`](#carbonembeddingsget_documents)
   * [`carbon.embeddings.get_embeddings_and_chunks`](#carbonembeddingsget_embeddings_and_chunks)
   * [`carbon.embeddings.upload_chunks_and_embeddings`](#carbonembeddingsupload_chunks_and_embeddings)
   * [`carbon.files.create_user_file_tags`](#carbonfilescreate_user_file_tags)
   * [`carbon.files.delete`](#carbonfilesdelete)
   * [`carbon.files.delete_file_tags`](#carbonfilesdelete_file_tags)
   * [`carbon.files.delete_many`](#carbonfilesdelete_many)
+  * [`carbon.files.delete_v2`](#carbonfilesdelete_v2)
   * [`carbon.files.get_parsed_file`](#carbonfilesget_parsed_file)
   * [`carbon.files.get_raw_file`](#carbonfilesget_raw_file)
   * [`carbon.files.query_user_files`](#carbonfilesquery_user_files)
   * [`carbon.files.query_user_files_deprecated`](#carbonfilesquery_user_files_deprecated)
   * [`carbon.files.resync`](#carbonfilesresync)
   * [`carbon.files.upload`](#carbonfilesupload)
   * [`carbon.files.upload_from_url`](#carbonfilesupload_from_url)
@@ -49,26 +75,32 @@
   * [`carbon.integrations.get_oauth_url`](#carbonintegrationsget_oauth_url)
   * [`carbon.integrations.list_confluence_pages`](#carbonintegrationslist_confluence_pages)
   * [`carbon.integrations.list_data_source_items`](#carbonintegrationslist_data_source_items)
   * [`carbon.integrations.list_folders`](#carbonintegrationslist_folders)
   * [`carbon.integrations.list_gitbook_spaces`](#carbonintegrationslist_gitbook_spaces)
   * [`carbon.integrations.list_labels`](#carbonintegrationslist_labels)
   * [`carbon.integrations.list_outlook_categories`](#carbonintegrationslist_outlook_categories)
+  * [`carbon.integrations.list_repos`](#carbonintegrationslist_repos)
   * [`carbon.integrations.sync_confluence`](#carbonintegrationssync_confluence)
   * [`carbon.integrations.sync_data_source_items`](#carbonintegrationssync_data_source_items)
   * [`carbon.integrations.sync_files`](#carbonintegrationssync_files)
+  * [`carbon.integrations.sync_git_hub`](#carbonintegrationssync_git_hub)
   * [`carbon.integrations.sync_gitbook`](#carbonintegrationssync_gitbook)
   * [`carbon.integrations.sync_gmail`](#carbonintegrationssync_gmail)
   * [`carbon.integrations.sync_outlook`](#carbonintegrationssync_outlook)
+  * [`carbon.integrations.sync_repos`](#carbonintegrationssync_repos)
   * [`carbon.integrations.sync_rss_feed`](#carbonintegrationssync_rss_feed)
   * [`carbon.integrations.sync_s3_files`](#carbonintegrationssync_s3_files)
   * [`carbon.organizations.get`](#carbonorganizationsget)
+  * [`carbon.organizations.update`](#carbonorganizationsupdate)
+  * [`carbon.organizations.update_stats`](#carbonorganizationsupdate_stats)
   * [`carbon.users.delete`](#carbonusersdelete)
   * [`carbon.users.get`](#carbonusersget)
   * [`carbon.users.toggle_user_features`](#carbonuserstoggle_user_features)
+  * [`carbon.users.update_users`](#carbonusersupdate_users)
   * [`carbon.utilities.fetch_urls`](#carbonutilitiesfetch_urls)
   * [`carbon.utilities.fetch_youtube_transcripts`](#carbonutilitiesfetch_youtube_transcripts)
   * [`carbon.utilities.process_sitemap`](#carbonutilitiesprocess_sitemap)
   * [`carbon.utilities.scrape_sitemap`](#carbonutilitiesscrape_sitemap)
   * [`carbon.utilities.scrape_web`](#carbonutilitiesscrape_web)
   * [`carbon.utilities.search_urls`](#carbonutilitiessearch_urls)
   * [`carbon.webhooks.add_url`](#carbonwebhooksadd_url)
@@ -80,15 +112,15 @@
 ## Requirements<a id="requirements"></a>
 
 Python >=3.7
 
 ## Installation<a id="installation"></a>
 
 ```sh
-pip install carbon-python-sdk==0.1.9
+pip install carbon-python-sdk==0.2.0
 ```
 
 ## Getting Started<a id="getting-started"></a>
 
 ```python
 from carbon import Carbon
 
@@ -410,14 +442,15 @@
     k=1,
     tags={
         "key": "string_example",
     },
     query_vector=[3.14],
     file_ids=[1],
     parent_file_ids=[1],
+    include_all_children=False,
     tags_v2={},
     include_tags=True,
     include_vectors=True,
     include_raw_file=True,
     hybrid_search=True,
     hybrid_search_tuning_parameters={
         "weight_a": 0.5,
@@ -442,14 +475,18 @@
 
 ##### query_vector: [`GetEmbeddingDocumentsBodyQueryVector`](./carbon/type/get_embedding_documents_body_query_vector.py)<a id="query_vector-getembeddingdocumentsbodyqueryvectorcarbontypeget_embedding_documents_body_query_vectorpy"></a>
 
 ##### file_ids: [`GetEmbeddingDocumentsBodyFileIds`](./carbon/type/get_embedding_documents_body_file_ids.py)<a id="file_ids-getembeddingdocumentsbodyfileidscarbontypeget_embedding_documents_body_file_idspy"></a>
 
 ##### parent_file_ids: [`GetEmbeddingDocumentsBodyParentFileIds`](./carbon/type/get_embedding_documents_body_parent_file_ids.py)<a id="parent_file_ids-getembeddingdocumentsbodyparentfileidscarbontypeget_embedding_documents_body_parent_file_idspy"></a>
 
+##### include_all_children: `bool`<a id="include_all_children-bool"></a>
+
+Flag to control whether or not to include all children of filtered files in the embedding search.
+
 ##### tags_v2: `Optional[Dict[str, Union[bool, date, datetime, dict, float, int, list, str, None]]]`<a id="tags_v2-optionaldictstr-unionbool-date-datetime-dict-float-int-list-str-none"></a>
 
 A set of tags to limit the search to. Use this instead of `tags`, which is deprecated.
 
 ##### include_tags: `Optional[bool]`<a id="include_tags-optionalbool"></a>
 
 Flag to control whether or not to include tags for each chunk in the response.
@@ -557,29 +594,31 @@
                     "chunk": "chunk_example",
                 }
             ],
         }
     ],
     overwrite_existing=False,
     chunks_only=False,
-    custom_credentials={},
+    custom_credentials={
+        "key": {},
+    },
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### embedding_model: [`EmbeddingGenerators`](./carbon/type/embedding_generators.py)<a id="embedding_model-embeddinggeneratorscarbontypeembedding_generatorspy"></a>
 
 ##### chunks_and_embeddings: List[`SingleChunksAndEmbeddingsUploadInput`]<a id="chunks_and_embeddings-listsinglechunksandembeddingsuploadinput"></a>
 
 ##### overwrite_existing: `bool`<a id="overwrite_existing-bool"></a>
 
 ##### chunks_only: `bool`<a id="chunks_only-bool"></a>
 
-##### custom_credentials: `Dict[str, Union[bool, date, datetime, dict, float, int, list, str, None]]`<a id="custom_credentials-dictstr-unionbool-date-datetime-dict-float-int-list-str-none"></a>
+##### custom_credentials: [`ChunksAndEmbeddingsUploadInputCustomCredentials`](./carbon/type/chunks_and_embeddings_upload_input_custom_credentials.py)<a id="custom_credentials-chunksandembeddingsuploadinputcustomcredentialscarbontypechunks_and_embeddings_upload_input_custom_credentialspy"></a>
 
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`ChunksAndEmbeddingsUploadInput`](./carbon/type/chunks_and_embeddings_upload_input.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
@@ -635,14 +674,15 @@
 `/create_user_file_tags` `post`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
 ### `carbon.files.delete`<a id="carbonfilesdelete"></a>
+![Deprecated](https://img.shields.io/badge/deprecated-yellow)
 
 Delete File Endpoint
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
 delete_response = carbon.files.delete(
@@ -697,14 +737,15 @@
 `/delete_user_file_tags` `post`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
 ### `carbon.files.delete_many`<a id="carbonfilesdelete_many"></a>
+![Deprecated](https://img.shields.io/badge/deprecated-yellow)
 
 Delete Files Endpoint
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
 delete_many_response = carbon.files.delete_many(
@@ -739,15 +780,54 @@
 
 `/delete_files` `post`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
+### `carbon.files.delete_v2`<a id="carbonfilesdelete_v2"></a>
+
+Delete Files V2 Endpoint
+
+#### 🛠️ Usage<a id="🛠️-usage"></a>
+
+```python
+delete_v2_response = carbon.files.delete_v2(
+    filters={
+        "include_all_children": False,
+        "non_synced_only": False,
+    },
+    send_webhook=False,
+)
+```
+
+#### ⚙️ Parameters<a id="⚙️-parameters"></a>
+
+##### filters: [`OrganizationUserFilesToSyncFilters`](./carbon/type/organization_user_files_to_sync_filters.py)<a id="filters-organizationuserfilestosyncfilterscarbontypeorganization_user_files_to_sync_filterspy"></a>
+
+
+##### send_webhook: `bool`<a id="send_webhook-bool"></a>
+
+#### ⚙️ Request Body<a id="⚙️-request-body"></a>
+
+[`DeleteFilesV2QueryInput`](./carbon/type/delete_files_v2_query_input.py)
+#### 🔄 Return<a id="🔄-return"></a>
+
+[`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
+
+#### 🌐 Endpoint<a id="🌐-endpoint"></a>
+
+`/delete_files_v2` `post`
+
+[🔙 **Back to Table of Contents**](#table-of-contents)
+
+---
+
 ### `carbon.files.get_parsed_file`<a id="carbonfilesget_parsed_file"></a>
+![Deprecated](https://img.shields.io/badge/deprecated-yellow)
 
 This route is deprecated. Use `/user_files_v2` instead.
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
 get_parsed_file_response = carbon.files.get_parsed_file(
@@ -768,14 +848,15 @@
 `/parsed_file/{file_id}` `get`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
 ### `carbon.files.get_raw_file`<a id="carbonfilesget_raw_file"></a>
+![Deprecated](https://img.shields.io/badge/deprecated-yellow)
 
 This route is deprecated. Use `/user_files_v2` instead.
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
 get_raw_file_response = carbon.files.get_raw_file(
@@ -858,15 +939,18 @@
 query_user_files_response = carbon.files.query_user_files(
     pagination={
         "limit": 10,
         "offset": 0,
     },
     order_by="created_at",
     order_dir="desc",
-    filters={},
+    filters={
+        "include_all_children": False,
+        "non_synced_only": False,
+    },
     include_raw_file=True,
     include_parsed_text_file=True,
     include_additional_files=True,
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
@@ -899,28 +983,32 @@
 `/user_files_v2` `post`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
 ### `carbon.files.query_user_files_deprecated`<a id="carbonfilesquery_user_files_deprecated"></a>
+![Deprecated](https://img.shields.io/badge/deprecated-yellow)
 
 This route is deprecated. Use `/user_files_v2` instead.
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
 query_user_files_deprecated_response = carbon.files.query_user_files_deprecated(
     pagination={
         "limit": 10,
         "offset": 0,
     },
     order_by="created_at",
     order_dir="desc",
-    filters={},
+    filters={
+        "include_all_children": False,
+        "non_synced_only": False,
+    },
     include_raw_file=True,
     include_parsed_text_file=True,
     include_additional_files=True,
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
@@ -1034,14 +1122,17 @@
     skip_embedding_generation=False,
     set_page_as_boundary=False,
     embedding_model="OPENAI",
     use_ocr=False,
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
     max_items_per_chunk=1,
+    parse_pdf_tables_with_ocr=False,
+    detect_audio_language=False,
+    media_type="TEXT",
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### file: `IO`<a id="file-io"></a>
 
@@ -1075,15 +1166,27 @@
 
 ##### prepend_filename_to_chunks: `bool`<a id="prepend_filename_to_chunks-bool"></a>
 
 Whether or not to prepend the file's name to chunks.
 
 ##### max_items_per_chunk: `Optional[int]`<a id="max_items_per_chunk-optionalint"></a>
 
-Number of objects per chunk. For json files only.
+Number of objects per chunk. For csv, tsv, xlsx, and json files only.
+
+##### parse_pdf_tables_with_ocr: `bool`<a id="parse_pdf_tables_with_ocr-bool"></a>
+
+Whether to use rich table parsing when `use_ocr` is enabled.
+
+##### detect_audio_language: `bool`<a id="detect_audio_language-bool"></a>
+
+Whether to automatically detect the language of the uploaded audio file.
+
+##### media_type: [`FileContentTypesNullable`](./carbon/type/.py)<a id="media_type-filecontenttypesnullablecarbontypepy"></a>
+
+The media type of the file. If not provided, it will be inferred from the file extension.
 
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`BodyCreateUploadFileUploadfilePost`](./carbon/type/body_create_upload_file_uploadfile_post.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`UserFile`](./carbon/pydantic/user_file.py)
@@ -1111,14 +1214,16 @@
     skip_embedding_generation=False,
     set_page_as_boundary=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     use_textract=False,
     prepend_filename_to_chunks=False,
     max_items_per_chunk=1,
+    parse_pdf_tables_with_ocr=False,
+    detect_audio_language=False,
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### url: `str`<a id="url-str"></a>
 
@@ -1138,14 +1243,20 @@
 
 ##### use_textract: `bool`<a id="use_textract-bool"></a>
 
 ##### prepend_filename_to_chunks: `bool`<a id="prepend_filename_to_chunks-bool"></a>
 
 ##### max_items_per_chunk: `Optional[int]`<a id="max_items_per_chunk-optionalint"></a>
 
+Number of objects per chunk. For csv, tsv, xlsx, and json files only.
+
+##### parse_pdf_tables_with_ocr: `bool`<a id="parse_pdf_tables_with_ocr-bool"></a>
+
+##### detect_audio_language: `bool`<a id="detect_audio_language-bool"></a>
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`UploadFileFromUrlInput`](./carbon/type/upload_file_from_url_input.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`UserFile`](./carbon/pydantic/user_file.py)
 
@@ -1170,15 +1281,15 @@
 the set of all files you want considered for a query have embeddings generated via the same model. For now, **do not**
 set `VERTEX_MULTIMODAL` as an `embedding_model`. This model is used automatically by Carbon when it detects an image file.
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
 upload_text_response = carbon.files.upload_text(
-    contents="string_example",
+    contents="aaaaa",
     name="string_example",
     chunk_size=1,
     chunk_overlap=1,
     skip_embedding_generation=False,
     overwrite_file_id=1,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
@@ -1253,21 +1364,25 @@
         "chunk_overlap": 20,
         "skip_embedding_generation": False,
         "embedding_model": "OPENAI",
         "generate_sparse_vectors": False,
         "prepend_filename_to_chunks": False,
         "sync_files_on_connection": True,
         "set_page_as_boundary": False,
+        "request_id": "f5552316-5da3-46e6-ad9f-2f94e30d02cd",
+        "enable_file_picker": True,
+        "sync_source_items": True,
+        "incremental_sync": False,
     },
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
-##### authentication: Union[`OAuthAuthentication`, `NotionAuthentication`, `SharepointAuthentication`, `ConfluenceAuthentication`, `ZendeskAuthentication`, `ZoteroAuthentication`, `GitbookAuthetication`, `SalesforceAuthentication`, `FreskdeskAuthentication`, `S3Authentication`]<a id="authentication-unionoauthauthentication-notionauthentication-sharepointauthentication-confluenceauthentication-zendeskauthentication-zoteroauthentication-gitbookauthetication-salesforceauthentication-freskdeskauthentication-s3authentication"></a>
+##### authentication: Union[`OAuthAuthentication`, `NotionAuthentication`, `SharepointAuthentication`, `ConfluenceAuthentication`, `ZendeskAuthentication`, `ZoteroAuthentication`, `GitbookAuthetication`, `SalesforceAuthentication`, `FreskdeskAuthentication`, `S3Authentication`, `GithubAuthentication`]<a id="authentication-unionoauthauthentication-notionauthentication-sharepointauthentication-confluenceauthentication-zendeskauthentication-zoteroauthentication-gitbookauthetication-salesforceauthentication-freskdeskauthentication-s3authentication-githubauthentication"></a>
 
 
 ##### sync_options: [`SyncOptions`](./carbon/type/sync_options.py)<a id="sync_options-syncoptionscarbontypesync_optionspy"></a>
 
 
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
@@ -1302,14 +1417,21 @@
     chunk_size=1500,
     chunk_overlap=20,
     skip_embedding_generation=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
     sync_files_on_connection=True,
+    request_id="string_example",
+    sync_source_items=True,
+    file_sync_config={
+        "auto_synced_source_types": ["ARTICLE"],
+        "sync_attachments": False,
+        "detect_audio_language": False,
+    },
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### domain: `str`<a id="domain-str"></a>
 
@@ -1327,14 +1449,23 @@
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
 ##### sync_files_on_connection: `Optional[bool]`<a id="sync_files_on_connection-optionalbool"></a>
 
+##### request_id: `Optional[str]`<a id="request_id-optionalstr"></a>
+
+##### sync_source_items: `bool`<a id="sync_source_items-bool"></a>
+
+Enabling this flag will fetch all available content from the source to be listed via list items endpoint
+
+##### file_sync_config: [`FileSyncConfigNullable`](./carbon/type/file_sync_config_nullable.py)<a id="file_sync_config-filesyncconfignullablecarbontypefile_sync_config_nullablepy"></a>
+
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`FreshDeskConnectRequest`](./carbon/type/fresh_desk_connect_request.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
 
@@ -1363,14 +1494,16 @@
     chunk_size=1500,
     chunk_overlap=20,
     skip_embedding_generation=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
     sync_files_on_connection=True,
+    request_id="string_example",
+    sync_source_items=True,
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### organization: `str`<a id="organization-str"></a>
 
@@ -1388,14 +1521,20 @@
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
 ##### sync_files_on_connection: `Optional[bool]`<a id="sync_files_on_connection-optionalbool"></a>
 
+##### request_id: `Optional[str]`<a id="request_id-optionalstr"></a>
+
+##### sync_source_items: `bool`<a id="sync_source_items-bool"></a>
+
+Enabling this flag will fetch all available content from the source to be listed via list items endpoint
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`GitbookConnectRequest`](./carbon/type/gitbook_connect_request.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
 
@@ -1419,23 +1558,28 @@
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
 create_aws_iam_user_response = carbon.integrations.create_aws_iam_user(
     access_key="string_example",
     access_key_secret="string_example",
+    sync_source_items=True,
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### access_key: `str`<a id="access_key-str"></a>
 
 ##### access_key_secret: `str`<a id="access_key_secret-str"></a>
 
+##### sync_source_items: `bool`<a id="sync_source_items-bool"></a>
+
+Enabling this flag will fetch all available content from the source to be listed via list items endpoint
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`S3AuthRequest`](./carbon/type/s3_auth_request.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`OrganizationUserDataSourceAPI`](./carbon/pydantic/organization_user_data_source_api.py)
 
@@ -1473,14 +1617,25 @@
     prepend_filename_to_chunks=False,
     max_items_per_chunk=1,
     salesforce_domain="string_example",
     sync_files_on_connection=True,
     set_page_as_boundary=False,
     data_source_id=1,
     connecting_new_account=False,
+    request_id="273420dd-e05c-463f-a3cf-0ff28029639e",
+    use_ocr=False,
+    parse_pdf_tables_with_ocr=False,
+    enable_file_picker=True,
+    sync_source_items=True,
+    incremental_sync=False,
+    file_sync_config={
+        "auto_synced_source_types": ["ARTICLE"],
+        "sync_attachments": False,
+        "detect_audio_language": False,
+    },
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### service: [`DataSourceType`](./carbon/type/data_source_type.py)<a id="service-datasourcetypecarbontypedata_source_typepy"></a>
 
@@ -1506,14 +1661,16 @@
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
 ##### max_items_per_chunk: `Optional[int]`<a id="max_items_per_chunk-optionalint"></a>
 
+Number of objects per chunk. For csv, tsv, xlsx, and json files only.
+
 ##### salesforce_domain: `Optional[str]`<a id="salesforce_domain-optionalstr"></a>
 
 ##### sync_files_on_connection: `Optional[bool]`<a id="sync_files_on_connection-optionalbool"></a>
 
 Used to specify whether Carbon should attempt to sync all your files automatically when authorization         is complete. This is only supported for a subset of connectors and will be ignored for the rest. Supported         connectors: Intercom, Zendesk, Gitbook, Confluence, Salesforce, Freshdesk
 
 ##### set_page_as_boundary: `bool`<a id="set_page_as_boundary-bool"></a>
@@ -1522,14 +1679,39 @@
 
 Used to specify a data source to sync from if you have multiple connected. It can be skipped if          you only have one data source of that type connected or are connecting a new account.
 
 ##### connecting_new_account: `Optional[bool]`<a id="connecting_new_account-optionalbool"></a>
 
 Used to connect a new data source. If not specified, we will attempt to create a sync URL         for an existing data source based on type and ID.
 
+##### request_id: `str`<a id="request_id-str"></a>
+
+This request id will be added to all files that get synced using the generated OAuth URL
+
+##### use_ocr: `Optional[bool]`<a id="use_ocr-optionalbool"></a>
+
+Enable OCR for files that support it. Supported formats: pdf
+
+##### parse_pdf_tables_with_ocr: `Optional[bool]`<a id="parse_pdf_tables_with_ocr-optionalbool"></a>
+
+##### enable_file_picker: `bool`<a id="enable_file_picker-bool"></a>
+
+Enable integration's file picker for sources that support it. Supported sources: SHAREPOINT, DROPBOX, GOOGLE_DRIVE, BOX, ONEDRIVE
+
+##### sync_source_items: `bool`<a id="sync_source_items-bool"></a>
+
+Enabling this flag will fetch all available content from the source to be listed via list items endpoint
+
+##### incremental_sync: `bool`<a id="incremental_sync-bool"></a>
+
+Only sync files if they have not already been synced or if the embedding properties have changed.         This flag is currently supported by ONEDRIVE, GOOGLE_DRIVE, BOX, DROPBOX. It will be ignored for other data sources.
+
+##### file_sync_config: [`FileSyncConfigNullable`](./carbon/type/file_sync_config_nullable.py)<a id="file_sync_config-filesyncconfignullablecarbontypefile_sync_config_nullablepy"></a>
+
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`OAuthURLRequest`](./carbon/type/o_auth_url_request.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`OuthURLResponse`](./carbon/pydantic/outh_url_response.py)
 
@@ -1587,30 +1769,40 @@
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
 list_data_source_items_response = carbon.integrations.list_data_source_items(
     data_source_id=1,
     parent_id="string_example",
+    filters={},
     pagination={
         "limit": 10,
         "offset": 0,
     },
+    order_by="name",
+    order_dir="asc",
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### data_source_id: `int`<a id="data_source_id-int"></a>
 
 ##### parent_id: `Optional[str]`<a id="parent_id-optionalstr"></a>
 
+##### filters: [`ListItemsFiltersNullable`](./carbon/type/list_items_filters_nullable.py)<a id="filters-listitemsfiltersnullablecarbontypelist_items_filters_nullablepy"></a>
+
+
 ##### pagination: [`Pagination`](./carbon/type/pagination.py)<a id="pagination-paginationcarbontypepaginationpy"></a>
 
 
+##### order_by: [`ExternalSourceItemsOrderBy`](./carbon/type/external_source_items_order_by.py)<a id="order_by-externalsourceitemsorderbycarbontypeexternal_source_items_order_bypy"></a>
+
+##### order_dir: [`OrderDirV2`](./carbon/type/order_dir_v2.py)<a id="order_dir-orderdirv2carbontypeorder_dir_v2py"></a>
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`ListDataSourceItemsRequest`](./carbon/type/list_data_source_items_request.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`ListDataSourceItemsResponse`](./carbon/pydantic/list_data_source_items_response.py)
 
@@ -1717,14 +1909,45 @@
 
 `/integrations/outlook/user_categories` `get`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
+### `carbon.integrations.list_repos`<a id="carbonintegrationslist_repos"></a>
+
+Once you have connected your GitHub account, you can use this endpoint to list the 
+    repositories your account has access to. You can use a data source ID or username to fetch from a specific account.
+
+#### 🛠️ Usage<a id="🛠️-usage"></a>
+
+```python
+list_repos_response = carbon.integrations.list_repos(
+    per_page=30,
+    page=1,
+    data_source_id=1,
+)
+```
+
+#### ⚙️ Parameters<a id="⚙️-parameters"></a>
+
+##### per_page: `int`<a id="per_page-int"></a>
+
+##### page: `int`<a id="page-int"></a>
+
+##### data_source_id: `Optional[int]`<a id="data_source_id-optionalint"></a>
+
+#### 🌐 Endpoint<a id="🌐-endpoint"></a>
+
+`/integrations/github/repos` `get`
+
+[🔙 **Back to Table of Contents**](#table-of-contents)
+
+---
+
 ### `carbon.integrations.sync_confluence`<a id="carbonintegrationssync_confluence"></a>
 
 After listing pages in a user's Confluence account, the set of selected page `ids` and the
 connected account's `data_source_id` can be passed into this endpoint to sync them into
 Carbon. Additional parameters listed below can be used to associate data to the selected
 pages or alter the behavior of the sync.
 
@@ -1739,14 +1962,23 @@
     chunk_overlap=20,
     skip_embedding_generation=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
     max_items_per_chunk=1,
     set_page_as_boundary=False,
+    request_id="2782cb96-1bf6-452c-a8d9-60c2378fd079",
+    use_ocr=False,
+    parse_pdf_tables_with_ocr=False,
+    incremental_sync=False,
+    file_sync_config={
+        "auto_synced_source_types": ["ARTICLE"],
+        "sync_attachments": False,
+        "detect_audio_language": False,
+    },
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### data_source_id: `int`<a id="data_source_id-int"></a>
 
@@ -1765,16 +1997,31 @@
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
 ##### max_items_per_chunk: `Optional[int]`<a id="max_items_per_chunk-optionalint"></a>
 
+Number of objects per chunk. For csv, tsv, xlsx, and json files only.
+
 ##### set_page_as_boundary: `bool`<a id="set_page_as_boundary-bool"></a>
 
+##### request_id: `str`<a id="request_id-str"></a>
+
+##### use_ocr: `Optional[bool]`<a id="use_ocr-optionalbool"></a>
+
+##### parse_pdf_tables_with_ocr: `Optional[bool]`<a id="parse_pdf_tables_with_ocr-optionalbool"></a>
+
+##### incremental_sync: `bool`<a id="incremental_sync-bool"></a>
+
+Only sync files if they have not already been synced or if the embedding properties have changed.         This flag is currently supported by ONEDRIVE, GOOGLE_DRIVE, BOX, DROPBOX. It will be ignored for other data sources.
+
+##### file_sync_config: [`FileSyncConfigNullable`](./carbon/type/file_sync_config_nullable.py)<a id="file_sync_config-filesyncconfignullablecarbontypefile_sync_config_nullablepy"></a>
+
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`SyncFilesRequest`](./carbon/type/sync_files_request.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
 
@@ -1835,14 +2082,23 @@
     chunk_overlap=20,
     skip_embedding_generation=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
     max_items_per_chunk=1,
     set_page_as_boundary=False,
+    request_id="2782cb96-1bf6-452c-a8d9-60c2378fd079",
+    use_ocr=False,
+    parse_pdf_tables_with_ocr=False,
+    incremental_sync=False,
+    file_sync_config={
+        "auto_synced_source_types": ["ARTICLE"],
+        "sync_attachments": False,
+        "detect_audio_language": False,
+    },
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### data_source_id: `int`<a id="data_source_id-int"></a>
 
@@ -1861,16 +2117,31 @@
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
 ##### max_items_per_chunk: `Optional[int]`<a id="max_items_per_chunk-optionalint"></a>
 
+Number of objects per chunk. For csv, tsv, xlsx, and json files only.
+
 ##### set_page_as_boundary: `bool`<a id="set_page_as_boundary-bool"></a>
 
+##### request_id: `str`<a id="request_id-str"></a>
+
+##### use_ocr: `Optional[bool]`<a id="use_ocr-optionalbool"></a>
+
+##### parse_pdf_tables_with_ocr: `Optional[bool]`<a id="parse_pdf_tables_with_ocr-optionalbool"></a>
+
+##### incremental_sync: `bool`<a id="incremental_sync-bool"></a>
+
+Only sync files if they have not already been synced or if the embedding properties have changed.         This flag is currently supported by ONEDRIVE, GOOGLE_DRIVE, BOX, DROPBOX. It will be ignored for other data sources.
+
+##### file_sync_config: [`FileSyncConfigNullable`](./carbon/type/file_sync_config_nullable.py)<a id="file_sync_config-filesyncconfignullablecarbontypefile_sync_config_nullablepy"></a>
+
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`SyncFilesRequest`](./carbon/type/sync_files_request.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
 
@@ -1878,14 +2149,55 @@
 
 `/integrations/files/sync` `post`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
+### `carbon.integrations.sync_git_hub`<a id="carbonintegrationssync_git_hub"></a>
+
+Refer this article to obtain an access token https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens.
+Make sure that your access token has the permission to read content from your desired repos. Note that if your access token
+expires you will need to manually update it through this endpoint.
+
+#### 🛠️ Usage<a id="🛠️-usage"></a>
+
+```python
+sync_git_hub_response = carbon.integrations.sync_git_hub(
+    username="string_example",
+    access_token="string_example",
+    sync_source_items=False,
+)
+```
+
+#### ⚙️ Parameters<a id="⚙️-parameters"></a>
+
+##### username: `str`<a id="username-str"></a>
+
+##### access_token: `str`<a id="access_token-str"></a>
+
+##### sync_source_items: `bool`<a id="sync_source_items-bool"></a>
+
+Enabling this flag will fetch all available content from the source to be listed via list items endpoint
+
+#### ⚙️ Request Body<a id="⚙️-request-body"></a>
+
+[`GithubConnectRequest`](./carbon/type/github_connect_request.py)
+#### 🔄 Return<a id="🔄-return"></a>
+
+[`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
+
+#### 🌐 Endpoint<a id="🌐-endpoint"></a>
+
+`/integrations/github` `post`
+
+[🔙 **Back to Table of Contents**](#table-of-contents)
+
+---
+
 ### `carbon.integrations.sync_gitbook`<a id="carbonintegrationssync_gitbook"></a>
 
 You can sync upto 20 Gitbook spaces at a time using this endpoint. Additional parameters below can be used to associate 
 data with the synced pages or modify the sync behavior.
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
@@ -1896,14 +2208,15 @@
     tags={},
     chunk_size=1500,
     chunk_overlap=20,
     skip_embedding_generation=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
+    request_id="string_example",
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### space_ids: [`GitbookSyncRequestSpaceIds`](./carbon/type/gitbook_sync_request_space_ids.py)<a id="space_ids-gitbooksyncrequestspaceidscarbontypegitbook_sync_request_space_idspy"></a>
 
@@ -1919,14 +2232,16 @@
 
 ##### embedding_model: [`EmbeddingGenerators`](./carbon/type/embedding_generators.py)<a id="embedding_model-embeddinggeneratorscarbontypeembedding_generatorspy"></a>
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
+##### request_id: `Optional[str]`<a id="request_id-optionalstr"></a>
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`GitbookSyncRequest`](./carbon/type/gitbook_sync_request.py)
 #### 🌐 Endpoint<a id="🌐-endpoint"></a>
 
 `/integrations/gitbook/sync` `post`
 
@@ -1996,14 +2311,22 @@
     chunk_size=1500,
     chunk_overlap=20,
     skip_embedding_generation=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
     data_source_id=1,
+    request_id="string_example",
+    sync_attachments=False,
+    file_sync_config={
+        "auto_synced_source_types": ["ARTICLE"],
+        "sync_attachments": False,
+        "detect_audio_language": False,
+    },
+    incremental_sync=False,
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### filters: `Dict[str, Union[bool, date, datetime, dict, float, int, list, str, None]]`<a id="filters-dictstr-unionbool-date-datetime-dict-float-int-list-str-none"></a>
 
@@ -2019,14 +2342,23 @@
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
 ##### data_source_id: `Optional[int]`<a id="data_source_id-optionalint"></a>
 
+##### request_id: `Optional[str]`<a id="request_id-optionalstr"></a>
+
+##### sync_attachments: `Optional[bool]`<a id="sync_attachments-optionalbool"></a>
+
+##### file_sync_config: [`FileSyncConfigNullable`](./carbon/type/file_sync_config_nullable.py)<a id="file_sync_config-filesyncconfignullablecarbontypefile_sync_config_nullablepy"></a>
+
+
+##### incremental_sync: `bool`<a id="incremental_sync-bool"></a>
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`GmailSyncInput`](./carbon/type/gmail_sync_input.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
 
@@ -2111,14 +2443,22 @@
     chunk_size=1500,
     chunk_overlap=20,
     skip_embedding_generation=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
     data_source_id=1,
+    request_id="string_example",
+    sync_attachments=False,
+    file_sync_config={
+        "auto_synced_source_types": ["ARTICLE"],
+        "sync_attachments": False,
+        "detect_audio_language": False,
+    },
+    incremental_sync=False,
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### filters: `Dict[str, Union[bool, date, datetime, dict, float, int, list, str, None]]`<a id="filters-dictstr-unionbool-date-datetime-dict-float-int-list-str-none"></a>
 
@@ -2136,14 +2476,23 @@
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
 ##### data_source_id: `Optional[int]`<a id="data_source_id-optionalint"></a>
 
+##### request_id: `Optional[str]`<a id="request_id-optionalstr"></a>
+
+##### sync_attachments: `Optional[bool]`<a id="sync_attachments-optionalbool"></a>
+
+##### file_sync_config: [`FileSyncConfigNullable`](./carbon/type/file_sync_config_nullable.py)<a id="file_sync_config-filesyncconfignullablecarbontypefile_sync_config_nullablepy"></a>
+
+
+##### incremental_sync: `bool`<a id="incremental_sync-bool"></a>
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`OutlookSyncInput`](./carbon/type/outlook_sync_input.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
 
@@ -2151,14 +2500,46 @@
 
 `/integrations/outlook/sync` `post`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
+### `carbon.integrations.sync_repos`<a id="carbonintegrationssync_repos"></a>
+
+You can retreive repos your token has access to using /integrations/github/repos and sync their content. 
+You can also pass full name of any public repository (username/repo-name). This will store the repo content with 
+carbon which can be accessed through /integrations/items/list endpoint. Maximum of 25 repositories are accepted per request.
+
+#### 🛠️ Usage<a id="🛠️-usage"></a>
+
+```python
+sync_repos_response = carbon.integrations.sync_repos(
+    repos=["string_example"],
+    data_source_id=1,
+)
+```
+
+#### ⚙️ Parameters<a id="⚙️-parameters"></a>
+
+##### repos: [`GithubFetchReposRequestRepos`](./carbon/type/github_fetch_repos_request_repos.py)<a id="repos-githubfetchreposrequestreposcarbontypegithub_fetch_repos_request_repospy"></a>
+
+##### data_source_id: `Optional[int]`<a id="data_source_id-optionalint"></a>
+
+#### ⚙️ Request Body<a id="⚙️-request-body"></a>
+
+[`GithubFetchReposRequest`](./carbon/type/github_fetch_repos_request.py)
+#### 🌐 Endpoint<a id="🌐-endpoint"></a>
+
+`/integrations/github/sync_repos` `post`
+
+[🔙 **Back to Table of Contents**](#table-of-contents)
+
+---
+
 ### `carbon.integrations.sync_rss_feed`<a id="carbonintegrationssync_rss_feed"></a>
 
 Rss Feed
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
@@ -2167,14 +2548,15 @@
     tags={},
     chunk_size=1500,
     chunk_overlap=20,
     skip_embedding_generation=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
+    request_id="string_example",
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### url: `str`<a id="url-str"></a>
 
@@ -2188,14 +2570,16 @@
 
 ##### embedding_model: [`EmbeddingGenerators`](./carbon/type/embedding_generators.py)<a id="embedding_model-embeddinggeneratorscarbontypeembedding_generatorspy"></a>
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
+##### request_id: `Optional[str]`<a id="request_id-optionalstr"></a>
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`RSSFeedInput`](./carbon/type/rss_feed_input.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
 
@@ -2224,14 +2608,22 @@
     skip_embedding_generation=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
     max_items_per_chunk=1,
     set_page_as_boundary=False,
     data_source_id=1,
+    request_id="string_example",
+    use_ocr=False,
+    parse_pdf_tables_with_ocr=False,
+    file_sync_config={
+        "auto_synced_source_types": ["ARTICLE"],
+        "sync_attachments": False,
+        "detect_audio_language": False,
+    },
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### ids: List[`S3GetFileInput`]<a id="ids-lists3getfileinput"></a>
 
@@ -2247,18 +2639,29 @@
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
 ##### max_items_per_chunk: `Optional[int]`<a id="max_items_per_chunk-optionalint"></a>
 
+Number of objects per chunk. For csv, tsv, xlsx, and json files only.
+
 ##### set_page_as_boundary: `bool`<a id="set_page_as_boundary-bool"></a>
 
 ##### data_source_id: `Optional[int]`<a id="data_source_id-optionalint"></a>
 
+##### request_id: `Optional[str]`<a id="request_id-optionalstr"></a>
+
+##### use_ocr: `Optional[bool]`<a id="use_ocr-optionalbool"></a>
+
+##### parse_pdf_tables_with_ocr: `Optional[bool]`<a id="parse_pdf_tables_with_ocr-optionalbool"></a>
+
+##### file_sync_config: [`FileSyncConfigNullable`](./carbon/type/file_sync_config_nullable.py)<a id="file_sync_config-filesyncconfignullablecarbontypefile_sync_config_nullablepy"></a>
+
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`S3FileSyncInput`](./carbon/type/s3_file_sync_input.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
 
@@ -2288,14 +2691,71 @@
 
 `/organization` `get`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
+### `carbon.organizations.update`<a id="carbonorganizationsupdate"></a>
+
+Update Organization
+
+#### 🛠️ Usage<a id="🛠️-usage"></a>
+
+```python
+update_response = carbon.organizations.update(
+    global_user_config={},
+)
+```
+
+#### ⚙️ Parameters<a id="⚙️-parameters"></a>
+
+##### global_user_config: [`UserConfigurationNullable`](./carbon/type/user_configuration_nullable.py)<a id="global_user_config-userconfigurationnullablecarbontypeuser_configuration_nullablepy"></a>
+
+
+#### ⚙️ Request Body<a id="⚙️-request-body"></a>
+
+[`UpdateOrganizationInput`](./carbon/type/update_organization_input.py)
+#### 🔄 Return<a id="🔄-return"></a>
+
+[`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
+
+#### 🌐 Endpoint<a id="🌐-endpoint"></a>
+
+`/organization/update` `post`
+
+[🔙 **Back to Table of Contents**](#table-of-contents)
+
+---
+
+### `carbon.organizations.update_stats`<a id="carbonorganizationsupdate_stats"></a>
+
+Use this endpoint to reaggregate the statistics for an organization, for example aggregate_file_size. The reaggregation
+process is asyncronous so a webhook will be sent with the event type being FILE_STATISTICS_AGGREGATED to notify when the
+process is complee. After this aggregation is complete, the updated statistics can be retrieved using the /organization
+endpoint. The response of /organization willalso contain a timestamp of the last time the statistics were reaggregated.
+
+#### 🛠️ Usage<a id="🛠️-usage"></a>
+
+```python
+update_stats_response = carbon.organizations.update_stats()
+```
+
+#### 🔄 Return<a id="🔄-return"></a>
+
+[`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
+
+#### 🌐 Endpoint<a id="🌐-endpoint"></a>
+
+`/organization/statistics` `post`
+
+[🔙 **Back to Table of Contents**](#table-of-contents)
+
+---
+
 ### `carbon.users.delete`<a id="carbonusersdelete"></a>
 
 Delete Users
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
@@ -2351,14 +2811,15 @@
 `/user` `post`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
 ### `carbon.users.toggle_user_features`<a id="carbonuserstoggle_user_features"></a>
+![Deprecated](https://img.shields.io/badge/deprecated-yellow)
 
 Toggle User Features
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
 toggle_user_features_response = carbon.users.toggle_user_features(
@@ -2384,14 +2845,61 @@
 
 `/modify_user_configuration` `post`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
+### `carbon.users.update_users`<a id="carbonusersupdate_users"></a>
+
+Update Users
+
+#### 🛠️ Usage<a id="🛠️-usage"></a>
+
+```python
+update_users_response = carbon.users.update_users(
+    customer_ids=["string_example"],
+    auto_sync_enabled_sources=["string_example"],
+    max_files=-1,
+    max_files_per_upload=-1,
+)
+```
+
+#### ⚙️ Parameters<a id="⚙️-parameters"></a>
+
+##### customer_ids: [`UpdateUsersInputCustomerIds`](./carbon/type/update_users_input_customer_ids.py)<a id="customer_ids-updateusersinputcustomeridscarbontypeupdate_users_input_customer_idspy"></a>
+
+##### auto_sync_enabled_sources: Union[List[[`DataSourceType`](./carbon/type/data_source_type.py)], `str`]<a id="auto_sync_enabled_sources-unionlistdatasourcetypecarbontypedata_source_typepy-str"></a>
+
+
+List of data source types to enable auto sync for. Empty array will remove all sources          and the string \\\"ALL\\\" will enable it for all data sources
+
+##### max_files: `Optional[int]`<a id="max_files-optionalint"></a>
+
+Custom file upload limit for the user over *all* user's files across all uploads.          If set, then the user will not be allowed to upload more files than this limit. If not set, or if set to -1,         then the user will have no limit.
+
+##### max_files_per_upload: `Optional[int]`<a id="max_files_per_upload-optionalint"></a>
+
+Custom file upload limit for the user across a single upload.         If set, then the user will not be allowed to upload more files than this limit in a single upload. If not set,         or if set to -1, then the user will have no limit.
+
+#### ⚙️ Request Body<a id="⚙️-request-body"></a>
+
+[`UpdateUsersInput`](./carbon/type/update_users_input.py)
+#### 🔄 Return<a id="🔄-return"></a>
+
+[`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
+
+#### 🌐 Endpoint<a id="🌐-endpoint"></a>
+
+`/update_users` `post`
+
+[🔙 **Back to Table of Contents**](#table-of-contents)
+
+---
+
 ### `carbon.utilities.fetch_urls`<a id="carbonutilitiesfetch_urls"></a>
 
 Extracts all URLs from a webpage. 
 
 Args:
     url (str): URL of the webpage
 
@@ -2758,7 +3266,8 @@
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
 
 ## Author<a id="author"></a>
 This Python package is automatically generated by [Konfig](https://konfigthis.com)
+
```

### Comparing `carbon_python_sdk-0.1.9/carbon/__init__.py` & `carbon_python_sdk-0.2.0/carbon/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 
     Connect external data to LLMs, no matter the source.
 
     The version of the OpenAPI document: 1.0.0
     Generated by: https://konfigthis.com
 """
 
-__version__ = "0.1.9"
+__version__ = "0.2.0"
 
 # import ApiClient
 from carbon.api_client import ApiClient
 
 # import Configuration
 from carbon.configuration import Configuration
```

### Comparing `carbon_python_sdk-0.1.9/carbon/api_client.py` & `carbon_python_sdk-0.2.0/carbon/api_client.py`

 * *Files 1% similar despite different names*

```diff
@@ -26,4782 +26,4784 @@
 00000190: 706f 7274 2074 7970 696e 670a 696d 706f  port typing.impo
 000001a0: 7274 2074 7970 696e 675f 6578 7465 6e73  rt typing_extens
 000001b0: 696f 6e73 0a69 6d70 6f72 7420 6169 6f68  ions.import aioh
 000001c0: 7474 700a 696d 706f 7274 2075 726c 6c69  ttp.import urlli
 000001d0: 6233 0a66 726f 6d20 7079 6461 6e74 6963  b3.from pydantic
 000001e0: 2069 6d70 6f72 7420 4261 7365 4d6f 6465   import BaseMode
 000001f0: 6c2c 2052 6f6f 744d 6f64 656c 2c20 5661  l, RootModel, Va
-00000200: 6c69 6461 7469 6f6e 4572 726f 720a 6672  lidationError.fr
-00000210: 6f6d 2075 726c 6c69 6233 2e5f 636f 6c6c  om urllib3._coll
-00000220: 6563 7469 6f6e 7320 696d 706f 7274 2048  ections import H
-00000230: 5454 5048 6561 6465 7244 6963 740a 6672  TTPHeaderDict.fr
-00000240: 6f6d 2075 726c 6c69 622e 7061 7273 6520  om urllib.parse 
-00000250: 696d 706f 7274 2075 726c 7061 7273 652c  import urlparse,
-00000260: 2071 756f 7465 0a66 726f 6d20 7572 6c6c   quote.from urll
-00000270: 6962 332e 6669 656c 6473 2069 6d70 6f72  ib3.fields impor
-00000280: 7420 5265 7175 6573 7446 6965 6c64 2061  t RequestField a
-00000290: 7320 5265 7175 6573 7446 6965 6c64 4261  s RequestFieldBa
-000002a0: 7365 0a66 726f 6d20 7572 6c6c 6962 332e  se.from urllib3.
-000002b0: 6669 656c 6473 2069 6d70 6f72 7420 6775  fields import gu
-000002c0: 6573 735f 636f 6e74 656e 745f 7479 7065  ess_content_type
-000002d0: 0a0a 696d 706f 7274 2066 726f 7a65 6e64  ..import frozend
-000002e0: 6963 740a 0a66 726f 6d20 6361 7262 6f6e  ict..from carbon
-000002f0: 2069 6d70 6f72 7420 7265 7374 0a66 726f   import rest.fro
-00000300: 6d20 6361 7262 6f6e 2e61 7069 5f72 6573  m carbon.api_res
-00000310: 706f 6e73 6520 696d 706f 7274 2041 7069  ponse import Api
-00000320: 5265 7370 6f6e 7365 2c20 4173 796e 6341  Response, AsyncA
-00000330: 7069 5265 7370 6f6e 7365 0a66 726f 6d20  piResponse.from 
-00000340: 6361 7262 6f6e 2e72 6573 7420 696d 706f  carbon.rest impo
-00000350: 7274 2041 7379 6e63 5265 7370 6f6e 7365  rt AsyncResponse
-00000360: 5772 6170 7065 722c 2052 6573 706f 6e73  Wrapper, Respons
-00000370: 6557 7261 7070 6572 0a66 726f 6d20 6361  eWrapper.from ca
-00000380: 7262 6f6e 2e63 6f6e 6669 6775 7261 7469  rbon.configurati
-00000390: 6f6e 2069 6d70 6f72 7420 436f 6e66 6967  on import Config
-000003a0: 7572 6174 696f 6e0a 6672 6f6d 2063 6172  uration.from car
-000003b0: 626f 6e2e 6578 6365 7074 696f 6e73 2069  bon.exceptions i
-000003c0: 6d70 6f72 7420 4170 6954 7970 6545 7272  mport ApiTypeErr
-000003d0: 6f72 2c20 4170 6956 616c 7565 4572 726f  or, ApiValueErro
-000003e0: 722c 204d 6973 7369 6e67 5265 7175 6972  r, MissingRequir
-000003f0: 6564 5061 7261 6d65 7465 7273 4572 726f  edParametersErro
-00000400: 720a 6672 6f6d 2063 6172 626f 6e2e 7265  r.from carbon.re
-00000410: 7175 6573 745f 6166 7465 725f 686f 6f6b  quest_after_hook
-00000420: 2069 6d70 6f72 7420 7265 7175 6573 745f   import request_
-00000430: 6166 7465 725f 686f 6f6b 0a66 726f 6d20  after_hook.from 
-00000440: 6361 7262 6f6e 2e72 6571 7565 7374 5f62  carbon.request_b
-00000450: 6566 6f72 655f 7572 6c5f 686f 6f6b 2069  efore_url_hook i
-00000460: 6d70 6f72 7420 7265 7175 6573 745f 6265  mport request_be
-00000470: 666f 7265 5f75 726c 5f68 6f6f 6b0a 6672  fore_url_hook.fr
-00000480: 6f6d 2063 6172 626f 6e2e 7363 6865 6d61  om carbon.schema
-00000490: 7320 696d 706f 7274 2028 0a20 2020 204e  s import (.    N
-000004a0: 6f6e 6543 6c61 7373 2c0a 2020 2020 426f  oneClass,.    Bo
-000004b0: 6f6c 436c 6173 732c 0a20 2020 2053 6368  olClass,.    Sch
-000004c0: 656d 612c 0a20 2020 2046 696c 6549 4f2c  ema,.    FileIO,
-000004d0: 0a20 2020 2042 696e 6172 7953 6368 656d  .    BinarySchem
-000004e0: 612c 0a20 2020 2064 6174 652c 0a20 2020  a,.    date,.   
-000004f0: 2064 6174 6574 696d 652c 0a20 2020 206e   datetime,.    n
-00000500: 6f6e 655f 7479 7065 2c0a 2020 2020 556e  one_type,.    Un
-00000510: 7365 742c 0a20 2020 2075 6e73 6574 2c0a  set,.    unset,.
-00000520: 290a 0a40 6461 7461 636c 6173 730a 636c  )..@dataclass.cl
-00000530: 6173 7320 4d61 7070 6564 4172 6773 3a0a  ass MappedArgs:.
-00000540: 2020 2020 626f 6479 3a20 7479 7069 6e67      body: typing
-00000550: 2e41 6e79 203d 204e 6f6e 650a 2020 2020  .Any = None.    
-00000560: 7175 6572 793a 2074 7970 696e 672e 4f70  query: typing.Op
-00000570: 7469 6f6e 616c 5b64 6963 745d 203d 204e  tional[dict] = N
-00000580: 6f6e 650a 2020 2020 7061 7468 3a20 7479  one.    path: ty
-00000590: 7069 6e67 2e4f 7074 696f 6e61 6c5b 6469  ping.Optional[di
-000005a0: 6374 5d20 3d20 4e6f 6e65 0a20 2020 2068  ct] = None.    h
-000005b0: 6561 6465 723a 2074 7970 696e 672e 4f70  eader: typing.Op
-000005c0: 7469 6f6e 616c 5b64 6963 745d 203d 204e  tional[dict] = N
-000005d0: 6f6e 650a 2020 2020 636f 6f6b 6965 3a20  one.    cookie: 
-000005e0: 7479 7069 6e67 2e4f 7074 696f 6e61 6c5b  typing.Optional[
-000005f0: 6469 6374 5d20 3d20 4e6f 6e65 0a0a 636c  dict] = None..cl
-00000600: 6173 7320 5265 7175 6573 7446 6965 6c64  ass RequestField
-00000610: 2852 6571 7565 7374 4669 656c 6442 6173  (RequestFieldBas
-00000620: 6529 3a0a 2020 2020 6465 6620 5f5f 6571  e):.    def __eq
-00000630: 5f5f 2873 656c 662c 206f 7468 6572 293a  __(self, other):
-00000640: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
-00000650: 6973 696e 7374 616e 6365 286f 7468 6572  isinstance(other
-00000660: 2c20 5265 7175 6573 7446 6965 6c64 293a  , RequestField):
-00000670: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-00000680: 7572 6e20 4661 6c73 650a 2020 2020 2020  urn False.      
-00000690: 2020 7265 7475 726e 2073 656c 662e 5f5f    return self.__
-000006a0: 6469 6374 5f5f 203d 3d20 6f74 6865 722e  dict__ == other.
-000006b0: 5f5f 6469 6374 5f5f 0a0a 0a54 203d 2074  __dict__...T = t
-000006c0: 7970 696e 672e 5479 7065 5661 7228 2754  yping.TypeVar('T
-000006d0: 2729 0a0a 0a64 6566 2063 6c6f 7365 7374  ')...def closest
-000006e0: 5f74 7970 655f 6d61 7463 6828 7661 6c75  _type_match(valu
-000006f0: 653a 2074 7970 696e 672e 416e 792c 2074  e: typing.Any, t
-00000700: 7970 6573 3a20 7479 7069 6e67 2e4c 6973  ypes: typing.Lis
-00000710: 745b 7479 7069 6e67 2e54 7970 655d 2920  t[typing.Type]) 
-00000720: 2d3e 2074 7970 696e 672e 5479 7065 3a0a  -> typing.Type:.
-00000730: 2020 2020 6265 7374 5f6d 6174 6368 203d      best_match =
-00000740: 204e 6f6e 650a 0a20 2020 2066 6f72 2074   None..    for t
-00000750: 2069 6e20 7479 7065 733a 0a20 2020 2020   in types:.     
-00000760: 2020 2023 2043 6865 636b 2066 6f72 2067     # Check for g
-00000770: 656e 6572 6963 2074 7970 6573 0a20 2020  eneric types.   
-00000780: 2020 2020 206f 7269 6769 6e20 3d20 7479       origin = ty
-00000790: 7069 6e67 5f65 7874 656e 7369 6f6e 732e  ping_extensions.
-000007a0: 6765 745f 6f72 6967 696e 2874 290a 2020  get_origin(t).  
-000007b0: 2020 2020 2020 6172 6773 203d 2074 7970        args = typ
-000007c0: 696e 675f 6578 7465 6e73 696f 6e73 2e67  ing_extensions.g
-000007d0: 6574 5f61 7267 7328 7429 0a0a 2020 2020  et_args(t)..    
-000007e0: 2020 2020 2320 4368 6563 6b20 666f 7220      # Check for 
-000007f0: 4c69 7465 7261 6c20 7479 7065 730a 2020  Literal types.  
-00000800: 2020 2020 2020 6966 206f 7269 6769 6e20        if origin 
-00000810: 3d3d 2074 7970 696e 675f 6578 7465 6e73  == typing_extens
-00000820: 696f 6e73 2e4c 6974 6572 616c 3a0a 2020  ions.Literal:.  
-00000830: 2020 2020 2020 2020 2020 6966 2076 616c            if val
-00000840: 7565 2069 6e20 6172 6773 3a0a 2020 2020  ue in args:.    
-00000850: 2020 2020 2020 2020 2020 2020 6265 7374              best
-00000860: 5f6d 6174 6368 203d 2074 0a20 2020 2020  _match = t.     
-00000870: 2020 2020 2020 2020 2020 2063 6f6e 7469             conti
-00000880: 6e75 650a 0a20 2020 2020 2020 2023 2043  nue..        # C
-00000890: 6865 636b 2066 6f72 2050 7964 616e 7469  heck for Pydanti
-000008a0: 6320 6d6f 6465 6c73 2061 6e64 206e 6f6e  c models and non
-000008b0: 2d67 656e 6572 6963 2074 7970 6573 0a20  -generic types. 
-000008c0: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
-000008d0: 616e 6365 2874 2c20 7479 7065 293a 2020  ance(t, type):  
-000008e0: 2320 456e 7375 7265 2074 2069 7320 6120  # Ensure t is a 
-000008f0: 636c 6173 730a 2020 2020 2020 2020 2020  class.          
-00000900: 2020 6966 2069 7373 7562 636c 6173 7328    if issubclass(
-00000910: 742c 2042 6173 654d 6f64 656c 293a 0a20  t, BaseModel):. 
-00000920: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-00000930: 6620 6973 696e 7374 616e 6365 2876 616c  f isinstance(val
-00000940: 7565 2c20 6469 6374 293a 0a20 2020 2020  ue, dict):.     
-00000950: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-00000960: 7279 3a0a 2020 2020 2020 2020 2020 2020  ry:.            
-00000970: 2020 2020 2020 2020 2020 2020 7428 2a2a              t(**
-00000980: 7661 6c75 6529 0a20 2020 2020 2020 2020  value).         
-00000990: 2020 2020 2020 2020 2020 2020 2020 2062                 b
-000009a0: 6573 745f 6d61 7463 6820 3d20 740a 2020  est_match = t.  
-000009b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000009c0: 2020 6578 6365 7074 2056 616c 6964 6174    except Validat
-000009d0: 696f 6e45 7272 6f72 3a0a 2020 2020 2020  ionError:.      
-000009e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000009f0: 2020 636f 6e74 696e 7565 0a20 2020 2020    continue.     
-00000a00: 2020 2020 2020 2065 6c73 653a 2020 2320         else:  # 
-00000a10: 5468 6973 2069 7320 6120 6e6f 6e2d 6765  This is a non-ge
-00000a20: 6e65 7269 6320 7479 7065 0a20 2020 2020  neric type.     
-00000a30: 2020 2020 2020 2020 2020 2069 6620 6973             if is
-00000a40: 696e 7374 616e 6365 2876 616c 7565 2c20  instance(value, 
-00000a50: 7429 3a0a 2020 2020 2020 2020 2020 2020  t):.            
-00000a60: 2020 2020 2020 2020 6966 2062 6573 745f          if best_
-00000a70: 6d61 7463 6820 6973 204e 6f6e 6520 6f72  match is None or
-00000a80: 2028 6973 696e 7374 616e 6365 2876 616c   (isinstance(val
-00000a90: 7565 2c20 7479 7065 2920 616e 6420 6973  ue, type) and is
-00000aa0: 7375 6263 6c61 7373 2862 6573 745f 6d61  subclass(best_ma
-00000ab0: 7463 682c 2074 2929 3a0a 2020 2020 2020  tch, t)):.      
-00000ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000ad0: 2020 6265 7374 5f6d 6174 6368 203d 2074    best_match = t
-00000ae0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00000af0: 2063 6f6e 7469 6e75 650a 0a20 2020 2020   continue..     
-00000b00: 2020 2023 2043 6865 636b 2066 6f72 2067     # Check for g
-00000b10: 656e 6572 6963 206c 6973 7420 7479 7065  eneric list type
-00000b20: 0a20 2020 2020 2020 2069 6620 6f72 6967  .        if orig
-00000b30: 696e 203d 3d20 6c69 7374 2061 6e64 2069  in == list and i
-00000b40: 7369 6e73 7461 6e63 6528 7661 6c75 652c  sinstance(value,
-00000b50: 206c 6973 7429 3a0a 2020 2020 2020 2020   list):.        
-00000b60: 2020 2020 6265 7374 5f6d 6174 6368 203d      best_match =
-00000b70: 2074 0a0a 2020 2020 7265 7475 726e 2062   t..    return b
-00000b80: 6573 745f 6d61 7463 680a 0a0a 6465 6620  est_match...def 
-00000b90: 636f 6e73 7472 7563 745f 6d6f 6465 6c5f  construct_model_
-00000ba0: 696e 7374 616e 6365 286d 6f64 656c 3a20  instance(model: 
-00000bb0: 7479 7069 6e67 2e54 7970 655b 545d 2c20  typing.Type[T], 
-00000bc0: 6461 7461 3a20 7479 7069 6e67 2e41 6e79  data: typing.Any
-00000bd0: 2920 2d3e 2054 3a0a 2020 2020 2222 220a  ) -> T:.    """.
-00000be0: 2020 2020 5265 6375 7273 6976 656c 7920      Recursively 
-00000bf0: 636f 6e73 7472 7563 7420 616e 2069 6e73  construct an ins
-00000c00: 7461 6e63 6520 6f66 2061 2050 7964 616e  tance of a Pydan
-00000c10: 7469 6320 6d6f 6465 6c20 616c 6f6e 6720  tic model along 
-00000c20: 7769 7468 2069 7473 206e 6573 7465 6420  with its nested 
-00000c30: 6d6f 6465 6c73 2e0a 2020 2020 2222 220a  models..    """.
-00000c40: 0a20 2020 2023 2069 6620 6d6f 6465 6c20  .    # if model 
-00000c50: 6973 2055 6e69 6f6e 2c0a 2020 2020 6966  is Union,.    if
-00000c60: 2074 7970 696e 675f 6578 7465 6e73 696f   typing_extensio
-00000c70: 6e73 2e67 6574 5f6f 7269 6769 6e28 6d6f  ns.get_origin(mo
-00000c80: 6465 6c29 2069 7320 7479 7069 6e67 2e55  del) is typing.U
-00000c90: 6e69 6f6e 3a0a 2020 2020 2020 2020 6265  nion:.        be
-00000ca0: 7374 5f74 7970 6520 3d20 636c 6f73 6573  st_type = closes
-00000cb0: 745f 7479 7065 5f6d 6174 6368 2864 6174  t_type_match(dat
-00000cc0: 612c 206d 6f64 656c 2e5f 5f61 7267 735f  a, model.__args_
-00000cd0: 5f29 0a20 2020 2020 2020 2072 6574 7572  _).        retur
-00000ce0: 6e20 636f 6e73 7472 7563 745f 6d6f 6465  n construct_mode
-00000cf0: 6c5f 696e 7374 616e 6365 2862 6573 745f  l_instance(best_
-00000d00: 7479 7065 2c20 6461 7461 290a 2020 2020  type, data).    
-00000d10: 656c 6966 206d 6f64 656c 2069 7320 4e6f  elif model is No
-00000d20: 6e65 206f 7220 6d6f 6465 6c20 6973 2074  ne or model is t
-00000d30: 7970 6528 4e6f 6e65 293a 0a20 2020 2020  ype(None):.     
-00000d40: 2020 2072 6574 7572 6e20 6461 7461 0a20     return data. 
-00000d50: 2020 2023 2069 6620 6d6f 6465 6c20 6973     # if model is
-00000d60: 2073 6361 6c61 7220 7661 6c75 6520 6c69   scalar value li
-00000d70: 6b65 2073 7472 2c20 6e75 6d62 6572 2c20  ke str, number, 
-00000d80: 6574 632e 206a 7573 7420 7265 7475 726e  etc. just return
-00000d90: 2074 6865 2076 616c 7565 0a20 2020 2065   the value.    e
-00000da0: 6c69 6620 6973 696e 7374 616e 6365 2864  lif isinstance(d
-00000db0: 6174 612c 2028 7374 722c 2066 6c6f 6174  ata, (str, float
-00000dc0: 2c20 696e 742c 2062 7974 6573 2c20 626f  , int, bytes, bo
-00000dd0: 6f6c 2929 3a0a 2020 2020 2020 2020 7265  ol)):.        re
-00000de0: 7475 726e 2064 6174 610a 2020 2020 656c  turn data.    el
-00000df0: 6966 2064 6174 6120 6973 204e 6f6e 653a  if data is None:
-00000e00: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00000e10: 6461 7461 0a20 2020 2023 2069 6620 6d6f  data.    # if mo
-00000e20: 6465 6c20 6973 206c 6973 742c 2069 7465  del is list, ite
-00000e30: 7261 7465 206f 7665 7220 6c69 7374 2061  rate over list a
-00000e40: 6e64 2072 6563 7572 7369 7665 6c79 2063  nd recursively c
-00000e50: 616c 6c0a 2020 2020 656c 6966 2074 7970  all.    elif typ
-00000e60: 696e 675f 6578 7465 6e73 696f 6e73 2e67  ing_extensions.g
-00000e70: 6574 5f6f 7269 6769 6e28 6d6f 6465 6c29  et_origin(model)
-00000e80: 2069 7320 6c69 7374 3a0a 2020 2020 2020   is list:.      
-00000e90: 2020 6974 656d 5f6d 6f64 656c 203d 2074    item_model = t
-00000ea0: 7970 696e 675f 6578 7465 6e73 696f 6e73  yping_extensions
-00000eb0: 2e67 6574 5f61 7267 7328 6d6f 6465 6c29  .get_args(model)
-00000ec0: 5b30 5d0a 2020 2020 2020 2020 7265 7475  [0].        retu
-00000ed0: 726e 205b 636f 6e73 7472 7563 745f 6d6f  rn [construct_mo
-00000ee0: 6465 6c5f 696e 7374 616e 6365 2869 7465  del_instance(ite
-00000ef0: 6d5f 6d6f 6465 6c2c 2069 7465 6d29 2066  m_model, item) f
-00000f00: 6f72 2069 7465 6d20 696e 2064 6174 615d  or item in data]
-00000f10: 0a20 2020 2023 2069 6620 6d6f 6465 6c20  .    # if model 
-00000f20: 6973 2066 7265 6520 666f 726d 206f 626a  is free form obj
-00000f30: 6563 742c 206a 7573 7420 7265 7475 726e  ect, just return
-00000f40: 2074 6865 2076 616c 7565 0a20 2020 2065   the value.    e
-00000f50: 6c69 6620 7479 7069 6e67 5f65 7874 656e  lif typing_exten
-00000f60: 7369 6f6e 732e 6765 745f 6f72 6967 696e  sions.get_origin
-00000f70: 286d 6f64 656c 2920 6973 2064 6963 743a  (model) is dict:
-00000f80: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00000f90: 6461 7461 0a20 2020 2065 6c69 6620 6d6f  data.    elif mo
-00000fa0: 6465 6c20 6973 2064 6963 743a 0a20 2020  del is dict:.   
-00000fb0: 2020 2020 2072 6574 7572 6e20 6461 7461       return data
-00000fc0: 0a20 2020 2065 6c69 6620 6d6f 6465 6c20  .    elif model 
-00000fd0: 6973 206f 626a 6563 743a 0a20 2020 2020  is object:.     
-00000fe0: 2020 2072 6574 7572 6e20 6461 7461 0a20     return data. 
-00000ff0: 2020 2023 2069 6620 6d6f 6465 6c20 6973     # if model is
-00001000: 2042 6173 654d 6f64 656c 2c20 6974 6572   BaseModel, iter
-00001010: 6174 6520 6f76 6572 2066 6965 6c64 7320  ate over fields 
-00001020: 616e 6420 7265 6375 7273 6976 656c 7920  and recursively 
-00001030: 6361 6c6c 0a20 2020 2065 6c69 6620 6973  call.    elif is
-00001040: 7375 6263 6c61 7373 286d 6f64 656c 2c20  subclass(model, 
-00001050: 4261 7365 4d6f 6465 6c29 3a0a 2020 2020  BaseModel):.    
-00001060: 2020 2020 6e65 775f 6461 7461 203d 207b      new_data = {
-00001070: 7d0a 2020 2020 2020 2020 666f 7220 6669  }.        for fi
-00001080: 656c 645f 6e61 6d65 2c20 6669 656c 645f  eld_name, field_
-00001090: 7479 7065 2069 6e20 6d6f 6465 6c2e 5f5f  type in model.__
-000010a0: 616e 6e6f 7461 7469 6f6e 735f 5f2e 6974  annotations__.it
-000010b0: 656d 7328 293a 0a20 2020 2020 2020 2020  ems():.         
-000010c0: 2020 2023 2067 6574 2061 6c69 6173 0a20     # get alias. 
-000010d0: 2020 2020 2020 2020 2020 2061 6c69 6173             alias
-000010e0: 203d 206d 6f64 656c 2e6d 6f64 656c 5f66   = model.model_f
-000010f0: 6965 6c64 735b 6669 656c 645f 6e61 6d65  ields[field_name
-00001100: 5d2e 616c 6961 730a 2020 2020 2020 2020  ].alias.        
-00001110: 2020 2020 6966 2061 6c69 6173 2069 6e20      if alias in 
-00001120: 6461 7461 3a0a 2020 2020 2020 2020 2020  data:.          
-00001130: 2020 2020 2020 6e65 775f 6461 7461 5b61        new_data[a
-00001140: 6c69 6173 5d20 3d20 636f 6e73 7472 7563  lias] = construc
-00001150: 745f 6d6f 6465 6c5f 696e 7374 616e 6365  t_model_instance
-00001160: 2866 6965 6c64 5f74 7970 652c 2064 6174  (field_type, dat
-00001170: 615b 616c 6961 735d 290a 2020 2020 2020  a[alias]).      
-00001180: 2020 7265 7475 726e 206d 6f64 656c 2e6d    return model.m
-00001190: 6f64 656c 5f63 6f6e 7374 7275 6374 282a  odel_construct(*
-000011a0: 2a6e 6577 5f64 6174 6129 0a20 2020 2072  *new_data).    r
-000011b0: 6169 7365 2041 7069 5479 7065 4572 726f  aise ApiTypeErro
-000011c0: 7228 6622 556e 6162 6c65 2074 6f20 636f  r(f"Unable to co
-000011d0: 6e73 7472 7563 7420 6d6f 6465 6c20 696e  nstruct model in
-000011e0: 7374 616e 6365 206f 6620 7479 7065 207b  stance of type {
-000011f0: 6d6f 6465 6c7d 2229 0a0a 0a63 6c61 7373  model}")...class
-00001200: 2044 6963 7469 6f6e 6172 7928 4261 7365   Dictionary(Base
-00001210: 4d6f 6465 6c29 3a0a 2020 2020 2222 220a  Model):.    """.
-00001220: 2020 2020 466f 7220 6672 6565 2d66 6f72      For free-for
-00001230: 6d20 6f62 6a65 6374 7320 7468 6174 2063  m objects that c
-00001240: 616e 2068 6176 6520 616e 7920 6b65 7973  an have any keys
-00001250: 2061 6e64 2076 616c 7565 730a 2020 2020   and values.    
-00001260: 2869 2e65 2e20 2274 7970 653a 206f 626a  (i.e. "type: obj
-00001270: 6563 7422 2077 6974 6820 6e6f 2070 726f  ect" with no pro
-00001280: 7065 7274 6965 7329 0a20 2020 2022 2222  perties).    """
-00001290: 0a20 2020 2063 6c61 7373 2043 6f6e 6669  .    class Confi
-000012a0: 673a 0a20 2020 2020 2020 2065 7874 7261  g:.        extra
-000012b0: 203d 2027 616c 6c6f 7727 0a0a 0a64 6566   = 'allow'...def
-000012c0: 2044 6570 7265 6361 7469 6f6e 5761 726e   DeprecationWarn
-000012d0: 696e 674f 6e63 6528 6675 6e63 3d4e 6f6e  ingOnce(func=Non
-000012e0: 652c 202a 2c20 7072 6566 6978 3d4e 6f6e  e, *, prefix=Non
-000012f0: 6529 3a0a 2020 2020 6465 6620 6465 636f  e):.    def deco
-00001300: 7261 746f 7228 6675 6e63 293a 0a20 2020  rator(func):.   
-00001310: 2020 2020 2077 6172 6e65 6420 3d20 4661       warned = Fa
-00001320: 6c73 650a 2020 2020 2020 2020 6465 6620  lse.        def 
-00001330: 7772 6170 7065 7228 696e 7374 616e 6365  wrapper(instance
-00001340: 2c20 2a61 7267 732c 202a 2a6b 7761 7267  , *args, **kwarg
-00001350: 7329 3a0a 2020 2020 2020 2020 2020 2020  s):.            
-00001360: 6e6f 6e6c 6f63 616c 2077 6172 6e65 640a  nonlocal warned.
-00001370: 2020 2020 2020 2020 2020 2020 6966 206e              if n
-00001380: 6f74 2077 6172 6e65 643a 0a20 2020 2020  ot warned:.     
-00001390: 2020 2020 2020 2020 2020 206d 7367 203d             msg =
-000013a0: 2066 227b 6675 6e63 2e5f 5f6e 616d 655f   f"{func.__name_
-000013b0: 5f7d 2069 7320 6465 7072 6563 6174 6564  _} is deprecated
-000013c0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-000013d0: 2020 6966 2070 7265 6669 783a 0a20 2020    if prefix:.   
-000013e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000013f0: 206d 7367 203d 2066 227b 7072 6566 6978   msg = f"{prefix
-00001400: 7d2e 7b6d 7367 7d22 0a20 2020 2020 2020  }.{msg}".       
-00001410: 2020 2020 2020 2020 2069 6e73 7461 6e63           instanc
-00001420: 652e 6170 695f 636c 6965 6e74 2e63 6f6e  e.api_client.con
-00001430: 6669 6775 7261 7469 6f6e 2e6c 6f67 6765  figuration.logge
-00001440: 722e 7761 726e 696e 6728 6d73 6729 0a20  r.warning(msg). 
-00001450: 2020 2020 2020 2020 2020 2020 2020 2077                 w
-00001460: 6172 6e65 6420 3d20 5472 7565 0a20 2020  arned = True.   
-00001470: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-00001480: 6675 6e63 2869 6e73 7461 6e63 652c 202a  func(instance, *
-00001490: 6172 6773 2c20 2a2a 6b77 6172 6773 290a  args, **kwargs).
-000014a0: 2020 2020 2020 2020 7265 7475 726e 2077          return w
-000014b0: 7261 7070 6572 0a20 2020 2069 6620 6675  rapper.    if fu
-000014c0: 6e63 2069 7320 4e6f 6e65 3a0a 2020 2020  nc is None:.    
-000014d0: 2020 2020 7265 7475 726e 2064 6563 6f72      return decor
-000014e0: 6174 6f72 0a20 2020 2065 6c73 653a 0a20  ator.    else:. 
-000014f0: 2020 2020 2020 2072 6574 7572 6e20 6465         return de
-00001500: 636f 7261 746f 7228 6675 6e63 290a 0a63  corator(func)..c
-00001510: 6c61 7373 204a 534f 4e45 6e63 6f64 6572  lass JSONEncoder
-00001520: 286a 736f 6e2e 4a53 4f4e 456e 636f 6465  (json.JSONEncode
-00001530: 7229 3a0a 2020 2020 636f 6d70 6163 745f  r):.    compact_
-00001540: 7365 7061 7261 746f 7273 203d 2028 272c  separators = (',
-00001550: 272c 2027 3a27 290a 0a20 2020 2064 6566  ', ':')..    def
-00001560: 2064 6566 6175 6c74 2873 656c 662c 206f   default(self, o
-00001570: 626a 293a 0a20 2020 2020 2020 2069 6620  bj):.        if 
-00001580: 6973 696e 7374 616e 6365 286f 626a 2c20  isinstance(obj, 
-00001590: 7374 7229 3a0a 2020 2020 2020 2020 2020  str):.          
-000015a0: 2020 7265 7475 726e 2073 7472 286f 626a    return str(obj
-000015b0: 290a 2020 2020 2020 2020 656c 6966 2069  ).        elif i
-000015c0: 7369 6e73 7461 6e63 6528 6f62 6a2c 2066  sinstance(obj, f
-000015d0: 6c6f 6174 293a 0a20 2020 2020 2020 2020  loat):.         
-000015e0: 2020 2072 6574 7572 6e20 666c 6f61 7428     return float(
-000015f0: 6f62 6a29 0a20 2020 2020 2020 2065 6c69  obj).        eli
-00001600: 6620 6973 696e 7374 616e 6365 286f 626a  f isinstance(obj
-00001610: 2c20 696e 7429 3a0a 2020 2020 2020 2020  , int):.        
-00001620: 2020 2020 7265 7475 726e 2069 6e74 286f      return int(o
-00001630: 626a 290a 2020 2020 2020 2020 656c 6966  bj).        elif
-00001640: 2069 7369 6e73 7461 6e63 6528 6f62 6a2c   isinstance(obj,
-00001650: 2044 6563 696d 616c 293a 0a20 2020 2020   Decimal):.     
-00001660: 2020 2020 2020 2069 6620 6f62 6a2e 6173         if obj.as
-00001670: 5f74 7570 6c65 2829 2e65 7870 6f6e 656e  _tuple().exponen
-00001680: 7420 3e3d 2030 3a0a 2020 2020 2020 2020  t >= 0:.        
-00001690: 2020 2020 2020 2020 7265 7475 726e 2069          return i
-000016a0: 6e74 286f 626a 290a 2020 2020 2020 2020  nt(obj).        
-000016b0: 2020 2020 7265 7475 726e 2066 6c6f 6174      return float
-000016c0: 286f 626a 290a 2020 2020 2020 2020 656c  (obj).        el
-000016d0: 6966 2069 7369 6e73 7461 6e63 6528 6f62  if isinstance(ob
-000016e0: 6a2c 204e 6f6e 6543 6c61 7373 293a 0a20  j, NoneClass):. 
-000016f0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00001700: 6e20 4e6f 6e65 0a20 2020 2020 2020 2065  n None.        e
-00001710: 6c69 6620 6973 696e 7374 616e 6365 286f  lif isinstance(o
-00001720: 626a 2c20 426f 6f6c 436c 6173 7329 3a0a  bj, BoolClass):.
-00001730: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00001740: 726e 2062 6f6f 6c28 6f62 6a29 0a20 2020  rn bool(obj).   
-00001750: 2020 2020 2065 6c69 6620 6973 696e 7374       elif isinst
-00001760: 616e 6365 286f 626a 2c20 2864 6963 742c  ance(obj, (dict,
-00001770: 2066 726f 7a65 6e64 6963 742e 6672 6f7a   frozendict.froz
-00001780: 656e 6469 6374 2929 3a0a 2020 2020 2020  endict)):.      
-00001790: 2020 2020 2020 7265 7475 726e 207b 6b65        return {ke
-000017a0: 793a 2073 656c 662e 6465 6661 756c 7428  y: self.default(
-000017b0: 7661 6c29 2066 6f72 206b 6579 2c20 7661  val) for key, va
-000017c0: 6c20 696e 206f 626a 2e69 7465 6d73 2829  l in obj.items()
-000017d0: 7d0a 2020 2020 2020 2020 656c 6966 2069  }.        elif i
-000017e0: 7369 6e73 7461 6e63 6528 6f62 6a2c 2028  sinstance(obj, (
-000017f0: 6c69 7374 2c20 7475 706c 6529 293a 0a20  list, tuple)):. 
-00001800: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00001810: 6e20 5b73 656c 662e 6465 6661 756c 7428  n [self.default(
-00001820: 6974 656d 2920 666f 7220 6974 656d 2069  item) for item i
-00001830: 6e20 6f62 6a5d 0a20 2020 2020 2020 2072  n obj].        r
-00001840: 6169 7365 2041 7069 5661 6c75 6545 7272  aise ApiValueErr
-00001850: 6f72 2827 556e 6162 6c65 2074 6f20 7072  or('Unable to pr
-00001860: 6570 6172 6520 7479 7065 207b 7d20 666f  epare type {} fo
-00001870: 7220 7365 7269 616c 697a 6174 696f 6e27  r serialization'
-00001880: 2e66 6f72 6d61 7428 6f62 6a2e 5f5f 636c  .format(obj.__cl
-00001890: 6173 735f 5f2e 5f5f 6e61 6d65 5f5f 2929  ass__.__name__))
-000018a0: 0a0a 0a63 6c61 7373 2050 6172 616d 6574  ...class Paramet
-000018b0: 6572 496e 5479 7065 2865 6e75 6d2e 456e  erInType(enum.En
-000018c0: 756d 293a 0a20 2020 2051 5545 5259 203d  um):.    QUERY =
-000018d0: 2027 7175 6572 7927 0a20 2020 2048 4541   'query'.    HEA
-000018e0: 4445 5220 3d20 2768 6561 6465 7227 0a20  DER = 'header'. 
-000018f0: 2020 2050 4154 4820 3d20 2770 6174 6827     PATH = 'path'
-00001900: 0a20 2020 2043 4f4f 4b49 4520 3d20 2763  .    COOKIE = 'c
-00001910: 6f6f 6b69 6527 0a0a 0a63 6c61 7373 2050  ookie'...class P
-00001920: 6172 616d 6574 6572 5374 796c 6528 656e  arameterStyle(en
-00001930: 756d 2e45 6e75 6d29 3a0a 2020 2020 4d41  um.Enum):.    MA
-00001940: 5452 4958 203d 2027 6d61 7472 6978 270a  TRIX = 'matrix'.
-00001950: 2020 2020 4c41 4245 4c20 3d20 276c 6162      LABEL = 'lab
-00001960: 656c 270a 2020 2020 464f 524d 203d 2027  el'.    FORM = '
-00001970: 666f 726d 270a 2020 2020 5349 4d50 4c45  form'.    SIMPLE
-00001980: 203d 2027 7369 6d70 6c65 270a 2020 2020   = 'simple'.    
-00001990: 5350 4143 455f 4445 4c49 4d49 5445 4420  SPACE_DELIMITED 
-000019a0: 3d20 2773 7061 6365 4465 6c69 6d69 7465  = 'spaceDelimite
-000019b0: 6427 0a20 2020 2050 4950 455f 4445 4c49  d'.    PIPE_DELI
-000019c0: 4d49 5445 4420 3d20 2770 6970 6544 656c  MITED = 'pipeDel
-000019d0: 696d 6974 6564 270a 2020 2020 4445 4550  imited'.    DEEP
-000019e0: 5f4f 424a 4543 5420 3d20 2764 6565 704f  _OBJECT = 'deepO
-000019f0: 626a 6563 7427 0a0a 0a63 6c61 7373 2050  bject'...class P
-00001a00: 7265 6669 7853 6570 6172 6174 6f72 4974  refixSeparatorIt
-00001a10: 6572 6174 6f72 3a0a 2020 2020 2320 4120  erator:.    # A 
-00001a20: 636c 6173 7320 746f 2073 746f 7265 2070  class to store p
-00001a30: 7265 6669 7865 7320 616e 6420 7365 7061  refixes and sepa
-00001a40: 7261 746f 7273 2066 6f72 2072 6663 3635  rators for rfc65
-00001a50: 3730 2065 7870 616e 7369 6f6e 730a 0a20  70 expansions.. 
-00001a60: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
-00001a70: 7365 6c66 2c20 7072 6566 6978 3a20 7374  self, prefix: st
-00001a80: 722c 2073 6570 6172 6174 6f72 3a20 7374  r, separator: st
-00001a90: 7229 3a0a 2020 2020 2020 2020 7365 6c66  r):.        self
-00001aa0: 2e70 7265 6669 7820 3d20 7072 6566 6978  .prefix = prefix
-00001ab0: 0a20 2020 2020 2020 2073 656c 662e 7365  .        self.se
-00001ac0: 7061 7261 746f 7220 3d20 7365 7061 7261  parator = separa
-00001ad0: 746f 720a 2020 2020 2020 2020 7365 6c66  tor.        self
-00001ae0: 2e66 6972 7374 203d 2054 7275 650a 2020  .first = True.  
-00001af0: 2020 2020 2020 6966 2073 6570 6172 6174        if separat
-00001b00: 6f72 2069 6e20 7b27 2e27 2c20 277c 272c  or in {'.', '|',
-00001b10: 2027 2532 3027 7d3a 0a20 2020 2020 2020   '%20'}:.       
-00001b20: 2020 2020 2069 7465 6d5f 7365 7061 7261       item_separa
-00001b30: 746f 7220 3d20 7365 7061 7261 746f 720a  tor = separator.
-00001b40: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-00001b50: 2020 2020 2020 2020 2020 6974 656d 5f73            item_s
-00001b60: 6570 6172 6174 6f72 203d 2027 2c27 0a20  eparator = ','. 
-00001b70: 2020 2020 2020 2073 656c 662e 6974 656d         self.item
-00001b80: 5f73 6570 6172 6174 6f72 203d 2069 7465  _separator = ite
-00001b90: 6d5f 7365 7061 7261 746f 720a 0a20 2020  m_separator..   
-00001ba0: 2064 6566 205f 5f69 7465 725f 5f28 7365   def __iter__(se
-00001bb0: 6c66 293a 0a20 2020 2020 2020 2072 6574  lf):.        ret
-00001bc0: 7572 6e20 7365 6c66 0a0a 2020 2020 6465  urn self..    de
-00001bd0: 6620 5f5f 6e65 7874 5f5f 2873 656c 6629  f __next__(self)
-00001be0: 3a0a 2020 2020 2020 2020 6966 2073 656c  :.        if sel
-00001bf0: 662e 6669 7273 743a 0a20 2020 2020 2020  f.first:.       
-00001c00: 2020 2020 2073 656c 662e 6669 7273 7420       self.first 
-00001c10: 3d20 4661 6c73 650a 2020 2020 2020 2020  = False.        
-00001c20: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
-00001c30: 7072 6566 6978 0a20 2020 2020 2020 2072  prefix.        r
-00001c40: 6574 7572 6e20 7365 6c66 2e73 6570 6172  eturn self.separ
-00001c50: 6174 6f72 0a0a 0a63 6c61 7373 2050 6172  ator...class Par
-00001c60: 616d 6574 6572 5365 7269 616c 697a 6572  ameterSerializer
-00001c70: 4261 7365 3a0a 2020 2020 4063 6c61 7373  Base:.    @class
-00001c80: 6d65 7468 6f64 0a20 2020 2064 6566 205f  method.    def _
-00001c90: 6765 745f 6465 6661 756c 745f 6578 706c  get_default_expl
-00001ca0: 6f64 6528 636c 732c 2073 7479 6c65 3a20  ode(cls, style: 
-00001cb0: 5061 7261 6d65 7465 7253 7479 6c65 2920  ParameterStyle) 
-00001cc0: 2d3e 2062 6f6f 6c3a 0a20 2020 2020 2020  -> bool:.       
-00001cd0: 2072 6574 7572 6e20 4661 6c73 650a 0a20   return False.. 
-00001ce0: 2020 2040 7374 6174 6963 6d65 7468 6f64     @staticmethod
-00001cf0: 0a20 2020 2064 6566 205f 5f72 6566 3635  .    def __ref65
-00001d00: 3730 5f69 7465 6d5f 7661 6c75 6528 696e  70_item_value(in
-00001d10: 5f64 6174 613a 2074 7970 696e 672e 416e  _data: typing.An
-00001d20: 792c 2070 6572 6365 6e74 5f65 6e63 6f64  y, percent_encod
-00001d30: 653a 2062 6f6f 6c29 3a0a 2020 2020 2020  e: bool):.      
-00001d40: 2020 2222 220a 2020 2020 2020 2020 4765    """.        Ge
-00001d50: 7420 7265 7072 6573 656e 7461 7469 6f6e  t representation
-00001d60: 2069 6620 7374 722f 666c 6f61 742f 696e   if str/float/in
-00001d70: 742f 4e6f 6e65 2f69 7465 6d73 2069 6e20  t/None/items in 
-00001d80: 6c69 7374 2f20 7661 6c75 6573 2069 6e20  list/ values in 
-00001d90: 6469 6374 0a20 2020 2020 2020 204e 6f6e  dict.        Non
-00001da0: 6520 6973 2072 6574 7572 6e65 6420 6966  e is returned if
-00001db0: 2061 6e20 6974 656d 2069 7320 756e 6465   an item is unde
-00001dc0: 6669 6e65 642c 2075 7365 2063 6173 6573  fined, use cases
-00001dd0: 2061 7265 2076 616c 7565 3d0a 2020 2020   are value=.    
-00001de0: 2020 2020 2d20 4e6f 6e65 0a20 2020 2020      - None.     
-00001df0: 2020 202d 205b 5d0a 2020 2020 2020 2020     - [].        
-00001e00: 2d20 7b7d 0a20 2020 2020 2020 202d 205b  - {}.        - [
-00001e10: 4e6f 6e65 2c20 4e6f 6e65 204e 6f6e 655d  None, None None]
-00001e20: 0a20 2020 2020 2020 202d 207b 2761 273a  .        - {'a':
-00001e30: 204e 6f6e 652c 2027 6227 3a20 4e6f 6e65   None, 'b': None
-00001e40: 7d0a 2020 2020 2020 2020 2222 220a 2020  }.        """.  
-00001e50: 2020 2020 2020 6966 2074 7970 6528 696e        if type(in
-00001e60: 5f64 6174 6129 2069 6e20 7b73 7472 2c20  _data) in {str, 
-00001e70: 666c 6f61 742c 2069 6e74 7d3a 0a20 2020  float, int}:.   
-00001e80: 2020 2020 2020 2020 2069 6620 7065 7263           if perc
-00001e90: 656e 745f 656e 636f 6465 3a0a 2020 2020  ent_encode:.    
-00001ea0: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00001eb0: 726e 2071 756f 7465 2873 7472 2869 6e5f  rn quote(str(in_
-00001ec0: 6461 7461 2929 0a20 2020 2020 2020 2020  data)).         
-00001ed0: 2020 2072 6574 7572 6e20 7374 7228 696e     return str(in
-00001ee0: 5f64 6174 6129 0a20 2020 2020 2020 2065  _data).        e
-00001ef0: 6c69 6620 6973 696e 7374 616e 6365 2869  lif isinstance(i
-00001f00: 6e5f 6461 7461 2c20 6e6f 6e65 5f74 7970  n_data, none_typ
-00001f10: 6529 3a0a 2020 2020 2020 2020 2020 2020  e):.            
-00001f20: 2320 6967 6e6f 7265 6420 6279 2074 6865  # ignored by the
-00001f30: 2065 7870 616e 7369 6f6e 2070 726f 6365   expansion proce
-00001f40: 7373 2068 7474 7073 3a2f 2f64 6174 6174  ss https://datat
-00001f50: 7261 636b 6572 2e69 6574 662e 6f72 672f  racker.ietf.org/
-00001f60: 646f 632f 6874 6d6c 2f72 6663 3635 3730  doc/html/rfc6570
-00001f70: 2373 6563 7469 6f6e 2d33 2e32 2e31 0a20  #section-3.2.1. 
-00001f80: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00001f90: 6e20 4e6f 6e65 0a20 2020 2020 2020 2065  n None.        e
-00001fa0: 6c69 6620 6973 696e 7374 616e 6365 2869  lif isinstance(i
-00001fb0: 6e5f 6461 7461 2c20 6c69 7374 2920 616e  n_data, list) an
-00001fc0: 6420 6e6f 7420 696e 5f64 6174 613a 0a20  d not in_data:. 
-00001fd0: 2020 2020 2020 2020 2020 2023 2069 676e             # ign
-00001fe0: 6f72 6564 2062 7920 7468 6520 6578 7061  ored by the expa
-00001ff0: 6e73 696f 6e20 7072 6f63 6573 7320 6874  nsion process ht
-00002000: 7470 733a 2f2f 6461 7461 7472 6163 6b65  tps://datatracke
-00002010: 722e 6965 7466 2e6f 7267 2f64 6f63 2f68  r.ietf.org/doc/h
-00002020: 746d 6c2f 7266 6336 3537 3023 7365 6374  tml/rfc6570#sect
-00002030: 696f 6e2d 332e 322e 310a 2020 2020 2020  ion-3.2.1.      
-00002040: 2020 2020 2020 7265 7475 726e 204e 6f6e        return Non
-00002050: 650a 2020 2020 2020 2020 656c 6966 2069  e.        elif i
-00002060: 7369 6e73 7461 6e63 6528 696e 5f64 6174  sinstance(in_dat
-00002070: 612c 2064 6963 7429 2061 6e64 206e 6f74  a, dict) and not
-00002080: 2069 6e5f 6461 7461 3a0a 2020 2020 2020   in_data:.      
-00002090: 2020 2020 2020 2320 6967 6e6f 7265 6420        # ignored 
-000020a0: 6279 2074 6865 2065 7870 616e 7369 6f6e  by the expansion
-000020b0: 2070 726f 6365 7373 2068 7474 7073 3a2f   process https:/
-000020c0: 2f64 6174 6174 7261 636b 6572 2e69 6574  /datatracker.iet
-000020d0: 662e 6f72 672f 646f 632f 6874 6d6c 2f72  f.org/doc/html/r
-000020e0: 6663 3635 3730 2373 6563 7469 6f6e 2d33  fc6570#section-3
-000020f0: 2e32 2e31 0a20 2020 2020 2020 2020 2020  .2.1.           
-00002100: 2072 6574 7572 6e20 4e6f 6e65 0a20 2020   return None.   
-00002110: 2020 2020 2072 6169 7365 2041 7069 5661       raise ApiVa
-00002120: 6c75 6545 7272 6f72 2827 556e 6162 6c65  lueError('Unable
-00002130: 2074 6f20 6765 6e65 7261 7465 2061 2072   to generate a r
-00002140: 6566 3635 3730 2069 7465 6d20 7265 7072  ef6570 item repr
-00002150: 6573 656e 7461 7469 6f6e 206f 6620 7b7d  esentation of {}
-00002160: 272e 666f 726d 6174 2869 6e5f 6461 7461  '.format(in_data
-00002170: 2929 0a0a 2020 2020 4073 7461 7469 636d  ))..    @staticm
-00002180: 6574 686f 640a 2020 2020 6465 6620 5f74  ethod.    def _t
-00002190: 6f5f 6469 6374 286e 616d 653a 2073 7472  o_dict(name: str
-000021a0: 2c20 7661 6c75 653a 2073 7472 293a 0a20  , value: str):. 
-000021b0: 2020 2020 2020 2072 6574 7572 6e20 7b6e         return {n
-000021c0: 616d 653a 2076 616c 7565 7d0a 0a20 2020  ame: value}..   
-000021d0: 2022 2222 0a20 2020 2072 6663 3635 3730   """.    rfc6570
-000021e0: 2064 6f65 7320 6e6f 7420 7370 6563 6966   does not specif
-000021f0: 7920 686f 7720 626f 6f6c 6561 6e20 7661  y how boolean va
-00002200: 6c75 6573 2061 7265 2073 6572 6961 6c69  lues are seriali
-00002210: 7a65 6420 736f 2077 6520 7573 6520 6c6f  zed so we use lo
-00002220: 7765 7263 6173 6520 2274 7275 6522 2061  wercase "true" a
-00002230: 6e64 2022 6661 6c73 650a 2020 2020 2222  nd "false.    ""
-00002240: 220a 2020 2020 4063 6c61 7373 6d65 7468  ".    @classmeth
-00002250: 6f64 0a20 2020 2064 6566 205f 5f6b 6f6e  od.    def __kon
-00002260: 6669 675f 626f 6f6c 5f65 7870 616e 7369  fig_bool_expansi
-00002270: 6f6e 280a 2020 2020 2020 2020 636c 732c  on(.        cls,
-00002280: 0a20 2020 2020 2020 2069 6e5f 6461 7461  .        in_data
-00002290: 3a20 7479 7069 6e67 2e41 6e79 2c0a 2020  : typing.Any,.  
-000022a0: 2020 2020 2020 7072 6566 6978 5f73 6570        prefix_sep
-000022b0: 6172 6174 6f72 5f69 7465 7261 746f 723a  arator_iterator:
-000022c0: 2050 7265 6669 7853 6570 6172 6174 6f72   PrefixSeparator
-000022d0: 4974 6572 6174 6f72 2c0a 2020 2020 2020  Iterator,.      
-000022e0: 2020 7661 725f 6e61 6d65 5f70 6965 6365    var_name_piece
-000022f0: 3a20 7374 722c 0a20 2020 2020 2020 206e  : str,.        n
-00002300: 616d 6564 5f70 6172 616d 6574 6572 5f65  amed_parameter_e
-00002310: 7870 616e 7369 6f6e 3a20 626f 6f6c 0a20  xpansion: bool. 
-00002320: 2020 2029 202d 3e20 7374 723a 0a20 2020     ) -> str:.   
-00002330: 2020 2020 2069 7465 6d5f 7661 6c75 6520       item_value 
-00002340: 3d20 2274 7275 6522 2069 6620 696e 5f64  = "true" if in_d
-00002350: 6174 6120 6973 2054 7275 6520 656c 7365  ata is True else
-00002360: 2022 6661 6c73 6522 0a20 2020 2020 2020   "false".       
-00002370: 2069 6620 6974 656d 5f76 616c 7565 2069   if item_value i
-00002380: 7320 4e6f 6e65 206f 7220 2869 7465 6d5f  s None or (item_
-00002390: 7661 6c75 6520 3d3d 2027 2720 616e 6420  value == '' and 
-000023a0: 7072 6566 6978 5f73 6570 6172 6174 6f72  prefix_separator
-000023b0: 5f69 7465 7261 746f 722e 7365 7061 7261  _iterator.separa
-000023c0: 746f 7220 3d3d 2027 3b27 293a 0a20 2020  tor == ';'):.   
-000023d0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-000023e0: 6e65 7874 2870 7265 6669 785f 7365 7061  next(prefix_sepa
-000023f0: 7261 746f 725f 6974 6572 6174 6f72 2920  rator_iterator) 
-00002400: 2b20 7661 725f 6e61 6d65 5f70 6965 6365  + var_name_piece
-00002410: 0a20 2020 2020 2020 2076 616c 7565 5f70  .        value_p
-00002420: 6169 725f 6571 7561 6c73 203d 2027 3d27  air_equals = '='
-00002430: 2069 6620 6e61 6d65 645f 7061 7261 6d65   if named_parame
-00002440: 7465 725f 6578 7061 6e73 696f 6e20 656c  ter_expansion el
-00002450: 7365 2027 270a 2020 2020 2020 2020 7265  se ''.        re
-00002460: 7475 726e 206e 6578 7428 7072 6566 6978  turn next(prefix
-00002470: 5f73 6570 6172 6174 6f72 5f69 7465 7261  _separator_itera
-00002480: 746f 7229 202b 2076 6172 5f6e 616d 655f  tor) + var_name_
-00002490: 7069 6563 6520 2b20 7661 6c75 655f 7061  piece + value_pa
-000024a0: 6972 5f65 7175 616c 7320 2b20 6974 656d  ir_equals + item
-000024b0: 5f76 616c 7565 0a0a 2020 2020 4063 6c61  _value..    @cla
-000024c0: 7373 6d65 7468 6f64 0a20 2020 2064 6566  ssmethod.    def
-000024d0: 205f 5f72 6566 3635 3730 5f73 7472 5f66   __ref6570_str_f
-000024e0: 6c6f 6174 5f69 6e74 5f65 7870 616e 7369  loat_int_expansi
-000024f0: 6f6e 280a 2020 2020 2020 2020 636c 732c  on(.        cls,
-00002500: 0a20 2020 2020 2020 2076 6172 6961 626c  .        variabl
-00002510: 655f 6e61 6d65 3a20 7374 722c 0a20 2020  e_name: str,.   
-00002520: 2020 2020 2069 6e5f 6461 7461 3a20 7479       in_data: ty
-00002530: 7069 6e67 2e41 6e79 2c0a 2020 2020 2020  ping.Any,.      
-00002540: 2020 6578 706c 6f64 653a 2062 6f6f 6c2c    explode: bool,
-00002550: 0a20 2020 2020 2020 2070 6572 6365 6e74  .        percent
-00002560: 5f65 6e63 6f64 653a 2062 6f6f 6c2c 0a20  _encode: bool,. 
-00002570: 2020 2020 2020 2070 7265 6669 785f 7365         prefix_se
-00002580: 7061 7261 746f 725f 6974 6572 6174 6f72  parator_iterator
-00002590: 3a20 5072 6566 6978 5365 7061 7261 746f  : PrefixSeparato
-000025a0: 7249 7465 7261 746f 722c 0a20 2020 2020  rIterator,.     
-000025b0: 2020 2076 6172 5f6e 616d 655f 7069 6563     var_name_piec
-000025c0: 653a 2073 7472 2c0a 2020 2020 2020 2020  e: str,.        
-000025d0: 6e61 6d65 645f 7061 7261 6d65 7465 725f  named_parameter_
-000025e0: 6578 7061 6e73 696f 6e3a 2062 6f6f 6c0a  expansion: bool.
-000025f0: 2020 2020 2920 2d3e 2073 7472 3a0a 2020      ) -> str:.  
-00002600: 2020 2020 2020 6974 656d 5f76 616c 7565        item_value
-00002610: 203d 2063 6c73 2e5f 5f72 6566 3635 3730   = cls.__ref6570
-00002620: 5f69 7465 6d5f 7661 6c75 6528 696e 5f64  _item_value(in_d
-00002630: 6174 612c 2070 6572 6365 6e74 5f65 6e63  ata, percent_enc
-00002640: 6f64 6529 0a20 2020 2020 2020 2069 6620  ode).        if 
-00002650: 6974 656d 5f76 616c 7565 2069 7320 4e6f  item_value is No
-00002660: 6e65 206f 7220 2869 7465 6d5f 7661 6c75  ne or (item_valu
-00002670: 6520 3d3d 2027 2720 616e 6420 7072 6566  e == '' and pref
-00002680: 6978 5f73 6570 6172 6174 6f72 5f69 7465  ix_separator_ite
-00002690: 7261 746f 722e 7365 7061 7261 746f 7220  rator.separator 
-000026a0: 3d3d 2027 3b27 293a 0a20 2020 2020 2020  == ';'):.       
-000026b0: 2020 2020 2072 6574 7572 6e20 6e65 7874       return next
-000026c0: 2870 7265 6669 785f 7365 7061 7261 746f  (prefix_separato
-000026d0: 725f 6974 6572 6174 6f72 2920 2b20 7661  r_iterator) + va
-000026e0: 725f 6e61 6d65 5f70 6965 6365 0a20 2020  r_name_piece.   
-000026f0: 2020 2020 2076 616c 7565 5f70 6169 725f       value_pair_
-00002700: 6571 7561 6c73 203d 2027 3d27 2069 6620  equals = '=' if 
-00002710: 6e61 6d65 645f 7061 7261 6d65 7465 725f  named_parameter_
-00002720: 6578 7061 6e73 696f 6e20 656c 7365 2027  expansion else '
-00002730: 270a 2020 2020 2020 2020 7265 7475 726e  '.        return
-00002740: 206e 6578 7428 7072 6566 6978 5f73 6570   next(prefix_sep
-00002750: 6172 6174 6f72 5f69 7465 7261 746f 7229  arator_iterator)
-00002760: 202b 2076 6172 5f6e 616d 655f 7069 6563   + var_name_piec
-00002770: 6520 2b20 7661 6c75 655f 7061 6972 5f65  e + value_pair_e
-00002780: 7175 616c 7320 2b20 6974 656d 5f76 616c  quals + item_val
-00002790: 7565 0a0a 2020 2020 4063 6c61 7373 6d65  ue..    @classme
-000027a0: 7468 6f64 0a20 2020 2064 6566 205f 5f72  thod.    def __r
-000027b0: 6566 3635 3730 5f6c 6973 745f 6578 7061  ef6570_list_expa
-000027c0: 6e73 696f 6e28 0a20 2020 2020 2020 2063  nsion(.        c
-000027d0: 6c73 2c0a 2020 2020 2020 2020 7661 7269  ls,.        vari
-000027e0: 6162 6c65 5f6e 616d 653a 2073 7472 2c0a  able_name: str,.
-000027f0: 2020 2020 2020 2020 696e 5f64 6174 613a          in_data:
-00002800: 2074 7970 696e 672e 416e 792c 0a20 2020   typing.Any,.   
-00002810: 2020 2020 2065 7870 6c6f 6465 3a20 626f       explode: bo
-00002820: 6f6c 2c0a 2020 2020 2020 2020 7065 7263  ol,.        perc
-00002830: 656e 745f 656e 636f 6465 3a20 626f 6f6c  ent_encode: bool
-00002840: 2c0a 2020 2020 2020 2020 7072 6566 6978  ,.        prefix
-00002850: 5f73 6570 6172 6174 6f72 5f69 7465 7261  _separator_itera
-00002860: 746f 723a 2050 7265 6669 7853 6570 6172  tor: PrefixSepar
-00002870: 6174 6f72 4974 6572 6174 6f72 2c0a 2020  atorIterator,.  
-00002880: 2020 2020 2020 7661 725f 6e61 6d65 5f70        var_name_p
-00002890: 6965 6365 3a20 7374 722c 0a20 2020 2020  iece: str,.     
-000028a0: 2020 206e 616d 6564 5f70 6172 616d 6574     named_paramet
-000028b0: 6572 5f65 7870 616e 7369 6f6e 3a20 626f  er_expansion: bo
-000028c0: 6f6c 0a20 2020 2029 202d 3e20 7374 723a  ol.    ) -> str:
-000028d0: 0a20 2020 2020 2020 2069 7465 6d5f 7661  .        item_va
-000028e0: 6c75 6573 203d 205b 636c 732e 5f5f 7265  lues = [cls.__re
-000028f0: 6636 3537 305f 6974 656d 5f76 616c 7565  f6570_item_value
-00002900: 2876 2c20 7065 7263 656e 745f 656e 636f  (v, percent_enco
-00002910: 6465 2920 666f 7220 7620 696e 2069 6e5f  de) for v in in_
-00002920: 6461 7461 5d0a 2020 2020 2020 2020 6974  data].        it
-00002930: 656d 5f76 616c 7565 7320 3d20 5b76 2066  em_values = [v f
-00002940: 6f72 2076 2069 6e20 6974 656d 5f76 616c  or v in item_val
-00002950: 7565 7320 6966 2076 2069 7320 6e6f 7420  ues if v is not 
-00002960: 4e6f 6e65 5d0a 2020 2020 2020 2020 6966  None].        if
-00002970: 206e 6f74 2069 7465 6d5f 7661 6c75 6573   not item_values
-00002980: 3a0a 2020 2020 2020 2020 2020 2020 2320  :.            # 
-00002990: 6967 6e6f 7265 6420 6279 2074 6865 2065  ignored by the e
-000029a0: 7870 616e 7369 6f6e 2070 726f 6365 7373  xpansion process
-000029b0: 2068 7474 7073 3a2f 2f64 6174 6174 7261   https://datatra
-000029c0: 636b 6572 2e69 6574 662e 6f72 672f 646f  cker.ietf.org/do
-000029d0: 632f 6874 6d6c 2f72 6663 3635 3730 2373  c/html/rfc6570#s
-000029e0: 6563 7469 6f6e 2d33 2e32 2e31 0a20 2020  ection-3.2.1.   
-000029f0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-00002a00: 2222 0a20 2020 2020 2020 2076 616c 7565  "".        value
-00002a10: 5f70 6169 725f 6571 7561 6c73 203d 2027  _pair_equals = '
-00002a20: 3d27 2069 6620 6e61 6d65 645f 7061 7261  =' if named_para
-00002a30: 6d65 7465 725f 6578 7061 6e73 696f 6e20  meter_expansion 
-00002a40: 656c 7365 2027 270a 2020 2020 2020 2020  else ''.        
-00002a50: 6966 206e 6f74 2065 7870 6c6f 6465 3a0a  if not explode:.
-00002a60: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00002a70: 726e 2028 0a20 2020 2020 2020 2020 2020  rn (.           
-00002a80: 2020 2020 206e 6578 7428 7072 6566 6978       next(prefix
-00002a90: 5f73 6570 6172 6174 6f72 5f69 7465 7261  _separator_itera
-00002aa0: 746f 7229 202b 0a20 2020 2020 2020 2020  tor) +.         
-00002ab0: 2020 2020 2020 2076 6172 5f6e 616d 655f         var_name_
-00002ac0: 7069 6563 6520 2b0a 2020 2020 2020 2020  piece +.        
-00002ad0: 2020 2020 2020 2020 7661 6c75 655f 7061          value_pa
-00002ae0: 6972 5f65 7175 616c 7320 2b0a 2020 2020  ir_equals +.    
-00002af0: 2020 2020 2020 2020 2020 2020 7072 6566              pref
-00002b00: 6978 5f73 6570 6172 6174 6f72 5f69 7465  ix_separator_ite
-00002b10: 7261 746f 722e 6974 656d 5f73 6570 6172  rator.item_separ
-00002b20: 6174 6f72 2e6a 6f69 6e28 6974 656d 5f76  ator.join(item_v
-00002b30: 616c 7565 7329 0a20 2020 2020 2020 2020  alues).         
-00002b40: 2020 2029 0a20 2020 2020 2020 2023 2065     ).        # e
-00002b50: 7870 6c6f 6465 640a 2020 2020 2020 2020  xploded.        
-00002b60: 7265 7475 726e 206e 6578 7428 7072 6566  return next(pref
-00002b70: 6978 5f73 6570 6172 6174 6f72 5f69 7465  ix_separator_ite
-00002b80: 7261 746f 7229 202b 206e 6578 7428 7072  rator) + next(pr
-00002b90: 6566 6978 5f73 6570 6172 6174 6f72 5f69  efix_separator_i
-00002ba0: 7465 7261 746f 7229 2e6a 6f69 6e28 0a20  terator).join(. 
-00002bb0: 2020 2020 2020 2020 2020 205b 7661 725f             [var_
-00002bc0: 6e61 6d65 5f70 6965 6365 202b 2076 616c  name_piece + val
-00002bd0: 7565 5f70 6169 725f 6571 7561 6c73 202b  ue_pair_equals +
-00002be0: 2076 616c 2066 6f72 2076 616c 2069 6e20   val for val in 
-00002bf0: 6974 656d 5f76 616c 7565 735d 0a20 2020  item_values].   
-00002c00: 2020 2020 2029 0a0a 2020 2020 4063 6c61       )..    @cla
-00002c10: 7373 6d65 7468 6f64 0a20 2020 2064 6566  ssmethod.    def
-00002c20: 205f 5f72 6566 3635 3730 5f64 6963 745f   __ref6570_dict_
-00002c30: 6578 7061 6e73 696f 6e28 0a20 2020 2020  expansion(.     
-00002c40: 2020 2063 6c73 2c0a 2020 2020 2020 2020     cls,.        
-00002c50: 7661 7269 6162 6c65 5f6e 616d 653a 2073  variable_name: s
-00002c60: 7472 2c0a 2020 2020 2020 2020 696e 5f64  tr,.        in_d
-00002c70: 6174 613a 2074 7970 696e 672e 416e 792c  ata: typing.Any,
-00002c80: 0a20 2020 2020 2020 2065 7870 6c6f 6465  .        explode
-00002c90: 3a20 626f 6f6c 2c0a 2020 2020 2020 2020  : bool,.        
-00002ca0: 7065 7263 656e 745f 656e 636f 6465 3a20  percent_encode: 
-00002cb0: 626f 6f6c 2c0a 2020 2020 2020 2020 7072  bool,.        pr
-00002cc0: 6566 6978 5f73 6570 6172 6174 6f72 5f69  efix_separator_i
-00002cd0: 7465 7261 746f 723a 2050 7265 6669 7853  terator: PrefixS
-00002ce0: 6570 6172 6174 6f72 4974 6572 6174 6f72  eparatorIterator
-00002cf0: 2c0a 2020 2020 2020 2020 7661 725f 6e61  ,.        var_na
-00002d00: 6d65 5f70 6965 6365 3a20 7374 722c 0a20  me_piece: str,. 
-00002d10: 2020 2020 2020 206e 616d 6564 5f70 6172         named_par
-00002d20: 616d 6574 6572 5f65 7870 616e 7369 6f6e  ameter_expansion
-00002d30: 3a20 626f 6f6c 0a20 2020 2029 202d 3e20  : bool.    ) -> 
-00002d40: 7374 723a 0a20 2020 2020 2020 2069 6e5f  str:.        in_
-00002d50: 6461 7461 5f74 7261 6e73 666f 726d 6564  data_transformed
-00002d60: 203d 207b 6b65 793a 2063 6c73 2e5f 5f72   = {key: cls.__r
-00002d70: 6566 3635 3730 5f69 7465 6d5f 7661 6c75  ef6570_item_valu
-00002d80: 6528 7661 6c2c 2070 6572 6365 6e74 5f65  e(val, percent_e
-00002d90: 6e63 6f64 6529 2066 6f72 206b 6579 2c20  ncode) for key, 
-00002da0: 7661 6c20 696e 2069 6e5f 6461 7461 2e69  val in in_data.i
-00002db0: 7465 6d73 2829 7d0a 2020 2020 2020 2020  tems()}.        
-00002dc0: 696e 5f64 6174 615f 7472 616e 7366 6f72  in_data_transfor
-00002dd0: 6d65 6420 3d20 7b6b 6579 3a20 7661 6c20  med = {key: val 
-00002de0: 666f 7220 6b65 792c 2076 616c 2069 6e20  for key, val in 
-00002df0: 696e 5f64 6174 615f 7472 616e 7366 6f72  in_data_transfor
-00002e00: 6d65 642e 6974 656d 7328 2920 6966 2076  med.items() if v
-00002e10: 616c 2069 7320 6e6f 7420 4e6f 6e65 7d0a  al is not None}.
-00002e20: 2020 2020 2020 2020 6966 206e 6f74 2069          if not i
-00002e30: 6e5f 6461 7461 5f74 7261 6e73 666f 726d  n_data_transform
-00002e40: 6564 3a0a 2020 2020 2020 2020 2020 2020  ed:.            
-00002e50: 2320 6967 6e6f 7265 6420 6279 2074 6865  # ignored by the
-00002e60: 2065 7870 616e 7369 6f6e 2070 726f 6365   expansion proce
-00002e70: 7373 2068 7474 7073 3a2f 2f64 6174 6174  ss https://datat
-00002e80: 7261 636b 6572 2e69 6574 662e 6f72 672f  racker.ietf.org/
-00002e90: 646f 632f 6874 6d6c 2f72 6663 3635 3730  doc/html/rfc6570
-00002ea0: 2373 6563 7469 6f6e 2d33 2e32 2e31 0a20  #section-3.2.1. 
-00002eb0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00002ec0: 6e20 2222 0a20 2020 2020 2020 2076 616c  n "".        val
-00002ed0: 7565 5f70 6169 725f 6571 7561 6c73 203d  ue_pair_equals =
-00002ee0: 2027 3d27 2069 6620 6e61 6d65 645f 7061   '=' if named_pa
-00002ef0: 7261 6d65 7465 725f 6578 7061 6e73 696f  rameter_expansio
-00002f00: 6e20 656c 7365 2027 270a 2020 2020 2020  n else ''.      
-00002f10: 2020 6966 206e 6f74 2065 7870 6c6f 6465    if not explode
-00002f20: 3a0a 2020 2020 2020 2020 2020 2020 7265  :.            re
-00002f30: 7475 726e 2028 0a20 2020 2020 2020 2020  turn (.         
-00002f40: 2020 2020 2020 206e 6578 7428 7072 6566         next(pref
-00002f50: 6978 5f73 6570 6172 6174 6f72 5f69 7465  ix_separator_ite
-00002f60: 7261 746f 7229 202b 0a20 2020 2020 2020  rator) +.       
-00002f70: 2020 2020 2020 2020 2076 6172 5f6e 616d           var_nam
-00002f80: 655f 7069 6563 6520 2b20 7661 6c75 655f  e_piece + value_
-00002f90: 7061 6972 5f65 7175 616c 7320 2b0a 2020  pair_equals +.  
-00002fa0: 2020 2020 2020 2020 2020 2020 2020 7072                pr
-00002fb0: 6566 6978 5f73 6570 6172 6174 6f72 5f69  efix_separator_i
-00002fc0: 7465 7261 746f 722e 6974 656d 5f73 6570  terator.item_sep
-00002fd0: 6172 6174 6f72 2e6a 6f69 6e28 0a20 2020  arator.join(.   
-00002fe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002ff0: 2070 7265 6669 785f 7365 7061 7261 746f   prefix_separato
-00003000: 725f 6974 6572 6174 6f72 2e69 7465 6d5f  r_iterator.item_
-00003010: 7365 7061 7261 746f 722e 6a6f 696e 280a  separator.join(.
-00003020: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003030: 2020 2020 2020 2020 6974 656d 5f70 6169          item_pai
-00003040: 720a 2020 2020 2020 2020 2020 2020 2020  r.              
-00003050: 2020 2020 2020 2920 666f 7220 6974 656d        ) for item
-00003060: 5f70 6169 7220 696e 2069 6e5f 6461 7461  _pair in in_data
-00003070: 5f74 7261 6e73 666f 726d 6564 2e69 7465  _transformed.ite
-00003080: 6d73 2829 0a20 2020 2020 2020 2020 2020  ms().           
-00003090: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
-000030a0: 2020 2029 0a20 2020 2020 2020 2023 2065     ).        # e
-000030b0: 7870 6c6f 6465 640a 2020 2020 2020 2020  xploded.        
-000030c0: 7265 7475 726e 206e 6578 7428 7072 6566  return next(pref
-000030d0: 6978 5f73 6570 6172 6174 6f72 5f69 7465  ix_separator_ite
-000030e0: 7261 746f 7229 202b 206e 6578 7428 7072  rator) + next(pr
-000030f0: 6566 6978 5f73 6570 6172 6174 6f72 5f69  efix_separator_i
-00003100: 7465 7261 746f 7229 2e6a 6f69 6e28 0a20  terator).join(. 
-00003110: 2020 2020 2020 2020 2020 205b 6b65 7920             [key 
-00003120: 2b20 273d 2720 2b20 7661 6c20 666f 7220  + '=' + val for 
-00003130: 6b65 792c 2076 616c 2069 6e20 696e 5f64  key, val in in_d
-00003140: 6174 615f 7472 616e 7366 6f72 6d65 642e  ata_transformed.
-00003150: 6974 656d 7328 295d 0a20 2020 2020 2020  items()].       
-00003160: 2029 0a0a 2020 2020 4063 6c61 7373 6d65   )..    @classme
-00003170: 7468 6f64 0a20 2020 2064 6566 205f 7265  thod.    def _re
-00003180: 6636 3537 305f 6578 7061 6e73 696f 6e28  f6570_expansion(
-00003190: 0a20 2020 2020 2020 2063 6c73 2c0a 2020  .        cls,.  
-000031a0: 2020 2020 2020 7661 7269 6162 6c65 5f6e        variable_n
-000031b0: 616d 653a 2073 7472 2c0a 2020 2020 2020  ame: str,.      
-000031c0: 2020 696e 5f64 6174 613a 2074 7970 696e    in_data: typin
-000031d0: 672e 416e 792c 0a20 2020 2020 2020 2065  g.Any,.        e
-000031e0: 7870 6c6f 6465 3a20 626f 6f6c 2c0a 2020  xplode: bool,.  
-000031f0: 2020 2020 2020 7065 7263 656e 745f 656e        percent_en
-00003200: 636f 6465 3a20 626f 6f6c 2c0a 2020 2020  code: bool,.    
-00003210: 2020 2020 7072 6566 6978 5f73 6570 6172      prefix_separ
-00003220: 6174 6f72 5f69 7465 7261 746f 723a 2050  ator_iterator: P
-00003230: 7265 6669 7853 6570 6172 6174 6f72 4974  refixSeparatorIt
-00003240: 6572 6174 6f72 0a20 2020 2029 202d 3e20  erator.    ) -> 
-00003250: 7374 723a 0a20 2020 2020 2020 2022 2222  str:.        """
-00003260: 0a20 2020 2020 2020 2053 6570 6172 6174  .        Separat
-00003270: 6f72 2069 7320 666f 7220 7365 7061 7261  or is for separa
-00003280: 7465 2076 6172 6961 626c 6573 206c 696b  te variables lik
-00003290: 6520 6469 6374 2077 6974 6820 6578 706c  e dict with expl
-000032a0: 6f64 6520 7472 7565 2c20 6e6f 7420 666f  ode true, not fo
-000032b0: 7220 6172 7261 7920 6974 656d 2073 6570  r array item sep
-000032c0: 6172 6174 696f 6e0a 2020 2020 2020 2020  aration.        
-000032d0: 2222 220a 2020 2020 2020 2020 6e61 6d65  """.        name
-000032e0: 645f 7061 7261 6d65 7465 725f 6578 7061  d_parameter_expa
-000032f0: 6e73 696f 6e20 3d20 7072 6566 6978 5f73  nsion = prefix_s
-00003300: 6570 6172 6174 6f72 5f69 7465 7261 746f  eparator_iterato
-00003310: 722e 7365 7061 7261 746f 7220 696e 207b  r.separator in {
-00003320: 2726 272c 2027 3b27 7d0a 2020 2020 2020  '&', ';'}.      
-00003330: 2020 7661 725f 6e61 6d65 5f70 6965 6365    var_name_piece
-00003340: 203d 2076 6172 6961 626c 655f 6e61 6d65   = variable_name
-00003350: 2069 6620 6e61 6d65 645f 7061 7261 6d65   if named_parame
-00003360: 7465 725f 6578 7061 6e73 696f 6e20 656c  ter_expansion el
-00003370: 7365 2027 270a 2020 2020 2020 2020 6966  se ''.        if
-00003380: 2074 7970 6528 696e 5f64 6174 6129 2069   type(in_data) i
-00003390: 6e20 7b73 7472 2c20 666c 6f61 742c 2069  n {str, float, i
-000033a0: 6e74 7d3a 0a20 2020 2020 2020 2020 2020  nt}:.           
-000033b0: 2072 6574 7572 6e20 636c 732e 5f5f 7265   return cls.__re
-000033c0: 6636 3537 305f 7374 725f 666c 6f61 745f  f6570_str_float_
-000033d0: 696e 745f 6578 7061 6e73 696f 6e28 0a20  int_expansion(. 
-000033e0: 2020 2020 2020 2020 2020 2020 2020 2076                 v
-000033f0: 6172 6961 626c 655f 6e61 6d65 2c0a 2020  ariable_name,.  
-00003400: 2020 2020 2020 2020 2020 2020 2020 696e                in
-00003410: 5f64 6174 612c 0a20 2020 2020 2020 2020  _data,.         
-00003420: 2020 2020 2020 2065 7870 6c6f 6465 2c0a         explode,.
-00003430: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003440: 7065 7263 656e 745f 656e 636f 6465 2c0a  percent_encode,.
-00003450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003460: 7072 6566 6978 5f73 6570 6172 6174 6f72  prefix_separator
-00003470: 5f69 7465 7261 746f 722c 0a20 2020 2020  _iterator,.     
-00003480: 2020 2020 2020 2020 2020 2076 6172 5f6e             var_n
-00003490: 616d 655f 7069 6563 652c 0a20 2020 2020  ame_piece,.     
-000034a0: 2020 2020 2020 2020 2020 206e 616d 6564             named
-000034b0: 5f70 6172 616d 6574 6572 5f65 7870 616e  _parameter_expan
-000034c0: 7369 6f6e 0a20 2020 2020 2020 2020 2020  sion.           
-000034d0: 2029 0a20 2020 2020 2020 2065 6c69 6620   ).        elif 
-000034e0: 6973 696e 7374 616e 6365 2869 6e5f 6461  isinstance(in_da
-000034f0: 7461 2c20 6e6f 6e65 5f74 7970 6529 3a0a  ta, none_type):.
-00003500: 2020 2020 2020 2020 2020 2020 2320 6967              # ig
-00003510: 6e6f 7265 6420 6279 2074 6865 2065 7870  nored by the exp
-00003520: 616e 7369 6f6e 2070 726f 6365 7373 2068  ansion process h
-00003530: 7474 7073 3a2f 2f64 6174 6174 7261 636b  ttps://datatrack
-00003540: 6572 2e69 6574 662e 6f72 672f 646f 632f  er.ietf.org/doc/
-00003550: 6874 6d6c 2f72 6663 3635 3730 2373 6563  html/rfc6570#sec
-00003560: 7469 6f6e 2d33 2e32 2e31 0a20 2020 2020  tion-3.2.1.     
-00003570: 2020 2020 2020 2072 6574 7572 6e20 2222         return ""
-00003580: 0a20 2020 2020 2020 2065 6c69 6620 6973  .        elif is
-00003590: 696e 7374 616e 6365 2869 6e5f 6461 7461  instance(in_data
-000035a0: 2c20 6c69 7374 293a 0a20 2020 2020 2020  , list):.       
-000035b0: 2020 2020 2072 6574 7572 6e20 636c 732e       return cls.
-000035c0: 5f5f 7265 6636 3537 305f 6c69 7374 5f65  __ref6570_list_e
-000035d0: 7870 616e 7369 6f6e 280a 2020 2020 2020  xpansion(.      
-000035e0: 2020 2020 2020 2020 2020 7661 7269 6162            variab
-000035f0: 6c65 5f6e 616d 652c 0a20 2020 2020 2020  le_name,.       
-00003600: 2020 2020 2020 2020 2069 6e5f 6461 7461           in_data
-00003610: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00003620: 2020 6578 706c 6f64 652c 0a20 2020 2020    explode,.     
-00003630: 2020 2020 2020 2020 2020 2070 6572 6365             perce
-00003640: 6e74 5f65 6e63 6f64 652c 0a20 2020 2020  nt_encode,.     
-00003650: 2020 2020 2020 2020 2020 2070 7265 6669             prefi
-00003660: 785f 7365 7061 7261 746f 725f 6974 6572  x_separator_iter
-00003670: 6174 6f72 2c0a 2020 2020 2020 2020 2020  ator,.          
-00003680: 2020 2020 2020 7661 725f 6e61 6d65 5f70        var_name_p
-00003690: 6965 6365 2c0a 2020 2020 2020 2020 2020  iece,.          
-000036a0: 2020 2020 2020 6e61 6d65 645f 7061 7261        named_para
-000036b0: 6d65 7465 725f 6578 7061 6e73 696f 6e0a  meter_expansion.
-000036c0: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
-000036d0: 2020 2020 2020 656c 6966 2069 7369 6e73        elif isins
-000036e0: 7461 6e63 6528 696e 5f64 6174 612c 2064  tance(in_data, d
-000036f0: 6963 7429 3a0a 2020 2020 2020 2020 2020  ict):.          
-00003700: 2020 7265 7475 726e 2063 6c73 2e5f 5f72    return cls.__r
-00003710: 6566 3635 3730 5f64 6963 745f 6578 7061  ef6570_dict_expa
-00003720: 6e73 696f 6e28 0a20 2020 2020 2020 2020  nsion(.         
-00003730: 2020 2020 2020 2076 6172 6961 626c 655f         variable_
-00003740: 6e61 6d65 2c0a 2020 2020 2020 2020 2020  name,.          
-00003750: 2020 2020 2020 696e 5f64 6174 612c 0a20        in_data,. 
-00003760: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-00003770: 7870 6c6f 6465 2c0a 2020 2020 2020 2020  xplode,.        
-00003780: 2020 2020 2020 2020 7065 7263 656e 745f          percent_
-00003790: 656e 636f 6465 2c0a 2020 2020 2020 2020  encode,.        
-000037a0: 2020 2020 2020 2020 7072 6566 6978 5f73          prefix_s
-000037b0: 6570 6172 6174 6f72 5f69 7465 7261 746f  eparator_iterato
-000037c0: 722c 0a20 2020 2020 2020 2020 2020 2020  r,.             
-000037d0: 2020 2076 6172 5f6e 616d 655f 7069 6563     var_name_piec
-000037e0: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
-000037f0: 2020 206e 616d 6564 5f70 6172 616d 6574     named_paramet
-00003800: 6572 5f65 7870 616e 7369 6f6e 0a20 2020  er_expansion.   
-00003810: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
-00003820: 2020 2065 6c69 6620 6973 696e 7374 616e     elif isinstan
-00003830: 6365 2869 6e5f 6461 7461 2c20 626f 6f6c  ce(in_data, bool
-00003840: 293a 0a20 2020 2020 2020 2020 2020 2072  ):.            r
-00003850: 6574 7572 6e20 636c 732e 5f5f 6b6f 6e66  eturn cls.__konf
-00003860: 6967 5f62 6f6f 6c5f 6578 7061 6e73 696f  ig_bool_expansio
-00003870: 6e28 0a20 2020 2020 2020 2020 2020 2020  n(.             
-00003880: 2020 2069 6e5f 6461 7461 2c0a 2020 2020     in_data,.    
-00003890: 2020 2020 2020 2020 2020 2020 7072 6566              pref
-000038a0: 6978 5f73 6570 6172 6174 6f72 5f69 7465  ix_separator_ite
-000038b0: 7261 746f 722c 0a20 2020 2020 2020 2020  rator,.         
-000038c0: 2020 2020 2020 2076 6172 5f6e 616d 655f         var_name_
-000038d0: 7069 6563 652c 0a20 2020 2020 2020 2020  piece,.         
-000038e0: 2020 2020 2020 206e 616d 6564 5f70 6172         named_par
-000038f0: 616d 6574 6572 5f65 7870 616e 7369 6f6e  ameter_expansion
-00003900: 0a20 2020 2020 2020 2020 2020 2029 0a20  .            ). 
-00003910: 2020 2020 2020 2023 2062 7974 6573 2c20         # bytes, 
-00003920: 6574 630a 2020 2020 2020 2020 7261 6973  etc.        rais
-00003930: 6520 4170 6956 616c 7565 4572 726f 7228  e ApiValueError(
-00003940: 2755 6e61 626c 6520 746f 2067 656e 6572  'Unable to gener
-00003950: 6174 6520 6120 7265 6636 3537 3020 7265  ate a ref6570 re
-00003960: 7072 6573 656e 7461 7469 6f6e 206f 6620  presentation of 
-00003970: 7b7d 272e 666f 726d 6174 2869 6e5f 6461  {}'.format(in_da
-00003980: 7461 2929 0a0a 0a63 6c61 7373 2053 7479  ta))...class Sty
-00003990: 6c65 466f 726d 5365 7269 616c 697a 6572  leFormSerializer
-000039a0: 2850 6172 616d 6574 6572 5365 7269 616c  (ParameterSerial
-000039b0: 697a 6572 4261 7365 293a 0a20 2020 2040  izerBase):.    @
-000039c0: 636c 6173 736d 6574 686f 640a 2020 2020  classmethod.    
-000039d0: 6465 6620 5f67 6574 5f64 6566 6175 6c74  def _get_default
-000039e0: 5f65 7870 6c6f 6465 2863 6c73 2c20 7374  _explode(cls, st
-000039f0: 796c 653a 2050 6172 616d 6574 6572 5374  yle: ParameterSt
-00003a00: 796c 6529 202d 3e20 626f 6f6c 3a0a 2020  yle) -> bool:.  
-00003a10: 2020 2020 2020 6966 2073 7479 6c65 2069        if style i
-00003a20: 7320 5061 7261 6d65 7465 7253 7479 6c65  s ParameterStyle
-00003a30: 2e46 4f52 4d3a 0a20 2020 2020 2020 2020  .FORM:.         
-00003a40: 2020 2072 6574 7572 6e20 5472 7565 0a20     return True. 
-00003a50: 2020 2020 2020 2072 6574 7572 6e20 7375         return su
-00003a60: 7065 7228 292e 5f67 6574 5f64 6566 6175  per()._get_defau
-00003a70: 6c74 5f65 7870 6c6f 6465 2873 7479 6c65  lt_explode(style
-00003a80: 290a 0a20 2020 2064 6566 205f 7365 7269  )..    def _seri
-00003a90: 616c 697a 655f 666f 726d 280a 2020 2020  alize_form(.    
-00003aa0: 2020 2020 7365 6c66 2c0a 2020 2020 2020      self,.      
-00003ab0: 2020 696e 5f64 6174 613a 2074 7970 696e    in_data: typin
-00003ac0: 672e 556e 696f 6e5b 4e6f 6e65 2c20 696e  g.Union[None, in
-00003ad0: 742c 2066 6c6f 6174 2c20 7374 722c 2062  t, float, str, b
-00003ae0: 6f6f 6c2c 2064 6963 742c 206c 6973 745d  ool, dict, list]
-00003af0: 2c0a 2020 2020 2020 2020 6e61 6d65 3a20  ,.        name: 
-00003b00: 7374 722c 0a20 2020 2020 2020 2065 7870  str,.        exp
-00003b10: 6c6f 6465 3a20 626f 6f6c 2c0a 2020 2020  lode: bool,.    
-00003b20: 2020 2020 7065 7263 656e 745f 656e 636f      percent_enco
-00003b30: 6465 3a20 626f 6f6c 2c0a 2020 2020 2020  de: bool,.      
-00003b40: 2020 7072 6566 6978 5f73 6570 6172 6174    prefix_separat
-00003b50: 6f72 5f69 7465 7261 746f 723a 2074 7970  or_iterator: typ
-00003b60: 696e 672e 4f70 7469 6f6e 616c 5b50 7265  ing.Optional[Pre
-00003b70: 6669 7853 6570 6172 6174 6f72 4974 6572  fixSeparatorIter
-00003b80: 6174 6f72 5d20 3d20 4e6f 6e65 0a20 2020  ator] = None.   
-00003b90: 2029 202d 3e20 7374 723a 0a20 2020 2020   ) -> str:.     
-00003ba0: 2020 2069 6620 7072 6566 6978 5f73 6570     if prefix_sep
-00003bb0: 6172 6174 6f72 5f69 7465 7261 746f 7220  arator_iterator 
-00003bc0: 6973 204e 6f6e 653a 0a20 2020 2020 2020  is None:.       
-00003bd0: 2020 2020 2070 7265 6669 785f 7365 7061       prefix_sepa
-00003be0: 7261 746f 725f 6974 6572 6174 6f72 203d  rator_iterator =
-00003bf0: 2050 7265 6669 7853 6570 6172 6174 6f72   PrefixSeparator
-00003c00: 4974 6572 6174 6f72 2827 272c 2027 2627  Iterator('', '&'
-00003c10: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00003c20: 2073 656c 662e 5f72 6566 3635 3730 5f65   self._ref6570_e
-00003c30: 7870 616e 7369 6f6e 280a 2020 2020 2020  xpansion(.      
-00003c40: 2020 2020 2020 7661 7269 6162 6c65 5f6e        variable_n
-00003c50: 616d 653d 6e61 6d65 2c0a 2020 2020 2020  ame=name,.      
-00003c60: 2020 2020 2020 696e 5f64 6174 613d 696e        in_data=in
-00003c70: 5f64 6174 612c 0a20 2020 2020 2020 2020  _data,.         
-00003c80: 2020 2065 7870 6c6f 6465 3d65 7870 6c6f     explode=explo
-00003c90: 6465 2c0a 2020 2020 2020 2020 2020 2020  de,.            
-00003ca0: 7065 7263 656e 745f 656e 636f 6465 3d70  percent_encode=p
-00003cb0: 6572 6365 6e74 5f65 6e63 6f64 652c 0a20  ercent_encode,. 
-00003cc0: 2020 2020 2020 2020 2020 2070 7265 6669             prefi
-00003cd0: 785f 7365 7061 7261 746f 725f 6974 6572  x_separator_iter
-00003ce0: 6174 6f72 3d70 7265 6669 785f 7365 7061  ator=prefix_sepa
-00003cf0: 7261 746f 725f 6974 6572 6174 6f72 0a20  rator_iterator. 
-00003d00: 2020 2020 2020 2029 0a0a 0a63 6c61 7373         )...class
-00003d10: 2053 7479 6c65 5369 6d70 6c65 5365 7269   StyleSimpleSeri
-00003d20: 616c 697a 6572 2850 6172 616d 6574 6572  alizer(Parameter
-00003d30: 5365 7269 616c 697a 6572 4261 7365 293a  SerializerBase):
-00003d40: 0a0a 2020 2020 6465 6620 5f73 6572 6961  ..    def _seria
-00003d50: 6c69 7a65 5f73 696d 706c 6528 0a20 2020  lize_simple(.   
-00003d60: 2020 2020 2073 656c 662c 0a20 2020 2020       self,.     
-00003d70: 2020 2069 6e5f 6461 7461 3a20 7479 7069     in_data: typi
-00003d80: 6e67 2e55 6e69 6f6e 5b4e 6f6e 652c 2069  ng.Union[None, i
-00003d90: 6e74 2c20 666c 6f61 742c 2073 7472 2c20  nt, float, str, 
-00003da0: 626f 6f6c 2c20 6469 6374 2c20 6c69 7374  bool, dict, list
-00003db0: 5d2c 0a20 2020 2020 2020 206e 616d 653a  ],.        name:
-00003dc0: 2073 7472 2c0a 2020 2020 2020 2020 6578   str,.        ex
-00003dd0: 706c 6f64 653a 2062 6f6f 6c2c 0a20 2020  plode: bool,.   
-00003de0: 2020 2020 2070 6572 6365 6e74 5f65 6e63       percent_enc
-00003df0: 6f64 653a 2062 6f6f 6c0a 2020 2020 2920  ode: bool.    ) 
-00003e00: 2d3e 2073 7472 3a0a 2020 2020 2020 2020  -> str:.        
-00003e10: 7072 6566 6978 5f73 6570 6172 6174 6f72  prefix_separator
-00003e20: 5f69 7465 7261 746f 7220 3d20 5072 6566  _iterator = Pref
-00003e30: 6978 5365 7061 7261 746f 7249 7465 7261  ixSeparatorItera
-00003e40: 746f 7228 2727 2c20 272c 2729 0a20 2020  tor('', ',').   
-00003e50: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
-00003e60: 2e5f 7265 6636 3537 305f 6578 7061 6e73  ._ref6570_expans
-00003e70: 696f 6e28 0a20 2020 2020 2020 2020 2020  ion(.           
-00003e80: 2076 6172 6961 626c 655f 6e61 6d65 3d6e   variable_name=n
-00003e90: 616d 652c 0a20 2020 2020 2020 2020 2020  ame,.           
-00003ea0: 2069 6e5f 6461 7461 3d69 6e5f 6461 7461   in_data=in_data
-00003eb0: 2c0a 2020 2020 2020 2020 2020 2020 6578  ,.            ex
-00003ec0: 706c 6f64 653d 6578 706c 6f64 652c 0a20  plode=explode,. 
-00003ed0: 2020 2020 2020 2020 2020 2070 6572 6365             perce
-00003ee0: 6e74 5f65 6e63 6f64 653d 7065 7263 656e  nt_encode=percen
-00003ef0: 745f 656e 636f 6465 2c0a 2020 2020 2020  t_encode,.      
-00003f00: 2020 2020 2020 7072 6566 6978 5f73 6570        prefix_sep
-00003f10: 6172 6174 6f72 5f69 7465 7261 746f 723d  arator_iterator=
-00003f20: 7072 6566 6978 5f73 6570 6172 6174 6f72  prefix_separator
-00003f30: 5f69 7465 7261 746f 720a 2020 2020 2020  _iterator.      
-00003f40: 2020 290a 0a0a 636c 6173 7320 4a53 4f4e    )...class JSON
-00003f50: 4465 7465 6374 6f72 3a0a 2020 2020 2222  Detector:.    ""
-00003f60: 220a 2020 2020 576f 726b 7320 666f 723a  ".    Works for:
-00003f70: 0a20 2020 2061 7070 6c69 6361 7469 6f6e  .    application
-00003f80: 2f6a 736f 6e0a 2020 2020 6170 706c 6963  /json.    applic
-00003f90: 6174 696f 6e2f 6a73 6f6e 3b20 6368 6172  ation/json; char
-00003fa0: 7365 743d 5554 462d 380a 2020 2020 6170  set=UTF-8.    ap
-00003fb0: 706c 6963 6174 696f 6e2f 6a73 6f6e 2d70  plication/json-p
-00003fc0: 6174 6368 2b6a 736f 6e0a 2020 2020 6170  atch+json.    ap
-00003fd0: 706c 6963 6174 696f 6e2f 6765 6f2b 6a73  plication/geo+js
-00003fe0: 6f6e 0a20 2020 2022 2222 0a20 2020 205f  on.    """.    _
-00003ff0: 5f6a 736f 6e5f 636f 6e74 656e 745f 7479  _json_content_ty
-00004000: 7065 5f70 6174 7465 726e 203d 2072 652e  pe_pattern = re.
-00004010: 636f 6d70 696c 6528 2261 7070 6c69 6361  compile("applica
-00004020: 7469 6f6e 2f5b 5e2b 5d2a 5b2b 5d3f 286a  tion/[^+]*[+]?(j
-00004030: 736f 6e29 3b3f 2e2a 2229 0a0a 2020 2020  son);?.*")..    
-00004040: 4063 6c61 7373 6d65 7468 6f64 0a20 2020  @classmethod.   
-00004050: 2064 6566 205f 636f 6e74 656e 745f 7479   def _content_ty
-00004060: 7065 5f69 735f 6a73 6f6e 2863 6c73 2c20  pe_is_json(cls, 
-00004070: 636f 6e74 656e 745f 7479 7065 3a20 7374  content_type: st
-00004080: 7229 202d 3e20 626f 6f6c 3a0a 2020 2020  r) -> bool:.    
-00004090: 2020 2020 6966 2063 6c73 2e5f 5f6a 736f      if cls.__jso
-000040a0: 6e5f 636f 6e74 656e 745f 7479 7065 5f70  n_content_type_p
-000040b0: 6174 7465 726e 2e6d 6174 6368 2863 6f6e  attern.match(con
-000040c0: 7465 6e74 5f74 7970 6529 3a0a 2020 2020  tent_type):.    
-000040d0: 2020 2020 2020 2020 7265 7475 726e 2054          return T
-000040e0: 7275 650a 2020 2020 2020 2020 7265 7475  rue.        retu
-000040f0: 726e 2046 616c 7365 0a0a 0a40 6461 7461  rn False...@data
-00004100: 636c 6173 730a 636c 6173 7320 5061 7261  class.class Para
-00004110: 6d65 7465 7242 6173 6528 4a53 4f4e 4465  meterBase(JSONDe
-00004120: 7465 6374 6f72 293a 0a20 2020 206e 616d  tector):.    nam
-00004130: 653a 2073 7472 0a20 2020 2069 6e5f 7479  e: str.    in_ty
-00004140: 7065 3a20 5061 7261 6d65 7465 7249 6e54  pe: ParameterInT
-00004150: 7970 650a 2020 2020 7265 7175 6972 6564  ype.    required
-00004160: 3a20 626f 6f6c 0a20 2020 2073 7479 6c65  : bool.    style
-00004170: 3a20 7479 7069 6e67 2e4f 7074 696f 6e61  : typing.Optiona
-00004180: 6c5b 5061 7261 6d65 7465 7253 7479 6c65  l[ParameterStyle
-00004190: 5d0a 2020 2020 6578 706c 6f64 653a 2074  ].    explode: t
-000041a0: 7970 696e 672e 4f70 7469 6f6e 616c 5b62  yping.Optional[b
-000041b0: 6f6f 6c5d 0a20 2020 2061 6c6c 6f77 5f72  ool].    allow_r
-000041c0: 6573 6572 7665 643a 2074 7970 696e 672e  eserved: typing.
-000041d0: 4f70 7469 6f6e 616c 5b62 6f6f 6c5d 0a20  Optional[bool]. 
-000041e0: 2020 2073 6368 656d 613a 2074 7970 696e     schema: typin
-000041f0: 672e 4f70 7469 6f6e 616c 5b74 7970 696e  g.Optional[typin
-00004200: 672e 5479 7065 5b53 6368 656d 615d 5d0a  g.Type[Schema]].
-00004210: 2020 2020 636f 6e74 656e 743a 2074 7970      content: typ
-00004220: 696e 672e 4f70 7469 6f6e 616c 5b74 7970  ing.Optional[typ
-00004230: 696e 672e 4469 6374 5b73 7472 2c20 7479  ing.Dict[str, ty
-00004240: 7069 6e67 2e54 7970 655b 5363 6865 6d61  ping.Type[Schema
-00004250: 5d5d 5d0a 0a20 2020 205f 5f73 7479 6c65  ]]]..    __style
-00004260: 5f74 6f5f 696e 5f74 7970 6520 3d20 7b0a  _to_in_type = {.
-00004270: 2020 2020 2020 2020 5061 7261 6d65 7465          Paramete
-00004280: 7253 7479 6c65 2e4d 4154 5249 583a 207b  rStyle.MATRIX: {
-00004290: 5061 7261 6d65 7465 7249 6e54 7970 652e  ParameterInType.
-000042a0: 5041 5448 7d2c 0a20 2020 2020 2020 2050  PATH},.        P
-000042b0: 6172 616d 6574 6572 5374 796c 652e 4c41  arameterStyle.LA
-000042c0: 4245 4c3a 207b 5061 7261 6d65 7465 7249  BEL: {ParameterI
-000042d0: 6e54 7970 652e 5041 5448 7d2c 0a20 2020  nType.PATH},.   
-000042e0: 2020 2020 2050 6172 616d 6574 6572 5374       ParameterSt
-000042f0: 796c 652e 464f 524d 3a20 7b50 6172 616d  yle.FORM: {Param
-00004300: 6574 6572 496e 5479 7065 2e51 5545 5259  eterInType.QUERY
-00004310: 2c20 5061 7261 6d65 7465 7249 6e54 7970  , ParameterInTyp
-00004320: 652e 434f 4f4b 4945 7d2c 0a20 2020 2020  e.COOKIE},.     
-00004330: 2020 2050 6172 616d 6574 6572 5374 796c     ParameterStyl
-00004340: 652e 5349 4d50 4c45 3a20 7b50 6172 616d  e.SIMPLE: {Param
-00004350: 6574 6572 496e 5479 7065 2e50 4154 482c  eterInType.PATH,
-00004360: 2050 6172 616d 6574 6572 496e 5479 7065   ParameterInType
-00004370: 2e48 4541 4445 527d 2c0a 2020 2020 2020  .HEADER},.      
-00004380: 2020 5061 7261 6d65 7465 7253 7479 6c65    ParameterStyle
-00004390: 2e53 5041 4345 5f44 454c 494d 4954 4544  .SPACE_DELIMITED
-000043a0: 3a20 7b50 6172 616d 6574 6572 496e 5479  : {ParameterInTy
-000043b0: 7065 2e51 5545 5259 7d2c 0a20 2020 2020  pe.QUERY},.     
-000043c0: 2020 2050 6172 616d 6574 6572 5374 796c     ParameterStyl
-000043d0: 652e 5049 5045 5f44 454c 494d 4954 4544  e.PIPE_DELIMITED
-000043e0: 3a20 7b50 6172 616d 6574 6572 496e 5479  : {ParameterInTy
-000043f0: 7065 2e51 5545 5259 7d2c 0a20 2020 2020  pe.QUERY},.     
-00004400: 2020 2050 6172 616d 6574 6572 5374 796c     ParameterStyl
-00004410: 652e 4445 4550 5f4f 424a 4543 543a 207b  e.DEEP_OBJECT: {
-00004420: 5061 7261 6d65 7465 7249 6e54 7970 652e  ParameterInType.
-00004430: 5155 4552 597d 2c0a 2020 2020 7d0a 2020  QUERY},.    }.  
-00004440: 2020 5f5f 696e 5f74 7970 655f 746f 5f64    __in_type_to_d
-00004450: 6566 6175 6c74 5f73 7479 6c65 203d 207b  efault_style = {
-00004460: 0a20 2020 2020 2020 2050 6172 616d 6574  .        Paramet
-00004470: 6572 496e 5479 7065 2e51 5545 5259 3a20  erInType.QUERY: 
-00004480: 5061 7261 6d65 7465 7253 7479 6c65 2e46  ParameterStyle.F
-00004490: 4f52 4d2c 0a20 2020 2020 2020 2050 6172  ORM,.        Par
-000044a0: 616d 6574 6572 496e 5479 7065 2e50 4154  ameterInType.PAT
-000044b0: 483a 2050 6172 616d 6574 6572 5374 796c  H: ParameterStyl
-000044c0: 652e 5349 4d50 4c45 2c0a 2020 2020 2020  e.SIMPLE,.      
-000044d0: 2020 5061 7261 6d65 7465 7249 6e54 7970    ParameterInTyp
-000044e0: 652e 4845 4144 4552 3a20 5061 7261 6d65  e.HEADER: Parame
-000044f0: 7465 7253 7479 6c65 2e53 494d 504c 452c  terStyle.SIMPLE,
-00004500: 0a20 2020 2020 2020 2050 6172 616d 6574  .        Paramet
-00004510: 6572 496e 5479 7065 2e43 4f4f 4b49 453a  erInType.COOKIE:
-00004520: 2050 6172 616d 6574 6572 5374 796c 652e   ParameterStyle.
-00004530: 464f 524d 2c0a 2020 2020 7d0a 2020 2020  FORM,.    }.    
-00004540: 5f5f 6469 7361 6c6c 6f77 6564 5f68 6561  __disallowed_hea
-00004550: 6465 725f 6e61 6d65 7320 3d20 7b27 4163  der_names = {'Ac
-00004560: 6365 7074 272c 2027 436f 6e74 656e 742d  cept', 'Content-
-00004570: 5479 7065 272c 2027 4175 7468 6f72 697a  Type', 'Authoriz
-00004580: 6174 696f 6e27 7d0a 2020 2020 5f6a 736f  ation'}.    _jso
-00004590: 6e5f 656e 636f 6465 7220 3d20 4a53 4f4e  n_encoder = JSON
-000045a0: 456e 636f 6465 7228 290a 0a20 2020 2040  Encoder()..    @
-000045b0: 636c 6173 736d 6574 686f 640a 2020 2020  classmethod.    
-000045c0: 6465 6620 5f5f 7665 7269 6679 5f73 7479  def __verify_sty
-000045d0: 6c65 5f74 6f5f 696e 5f74 7970 6528 636c  le_to_in_type(cl
-000045e0: 732c 2073 7479 6c65 3a20 7479 7069 6e67  s, style: typing
-000045f0: 2e4f 7074 696f 6e61 6c5b 5061 7261 6d65  .Optional[Parame
-00004600: 7465 7253 7479 6c65 5d2c 2069 6e5f 7479  terStyle], in_ty
-00004610: 7065 3a20 5061 7261 6d65 7465 7249 6e54  pe: ParameterInT
-00004620: 7970 6529 3a0a 2020 2020 2020 2020 6966  ype):.        if
-00004630: 2073 7479 6c65 2069 7320 4e6f 6e65 3a0a   style is None:.
-00004640: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00004650: 726e 0a20 2020 2020 2020 2069 6e5f 7479  rn.        in_ty
-00004660: 7065 5f73 6574 203d 2063 6c73 2e5f 5f73  pe_set = cls.__s
-00004670: 7479 6c65 5f74 6f5f 696e 5f74 7970 655b  tyle_to_in_type[
-00004680: 7374 796c 655d 0a20 2020 2020 2020 2069  style].        i
-00004690: 6620 696e 5f74 7970 6520 6e6f 7420 696e  f in_type not in
-000046a0: 2069 6e5f 7479 7065 5f73 6574 3a0a 2020   in_type_set:.  
-000046b0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-000046c0: 5661 6c75 6545 7272 6f72 280a 2020 2020  ValueError(.    
-000046d0: 2020 2020 2020 2020 2020 2020 2749 6e76              'Inv
-000046e0: 616c 6964 2073 7479 6c65 2061 6e64 2069  alid style and i
-000046f0: 6e5f 7479 7065 2063 6f6d 6269 6e61 7469  n_type combinati
-00004700: 6f6e 2e20 466f 7220 7374 796c 653d 7b7d  on. For style={}
-00004710: 206f 6e6c 7920 696e 5f74 7970 653d 7b7d   only in_type={}
-00004720: 2061 7265 2061 6c6c 6f77 6564 272e 666f   are allowed'.fo
-00004730: 726d 6174 280a 2020 2020 2020 2020 2020  rmat(.          
-00004740: 2020 2020 2020 2020 2020 7374 796c 652c            style,
-00004750: 2069 6e5f 7479 7065 5f73 6574 0a20 2020   in_type_set.   
-00004760: 2020 2020 2020 2020 2020 2020 2029 0a20               ). 
-00004770: 2020 2020 2020 2020 2020 2029 0a0a 2020             )..  
-00004780: 2020 6465 6620 5f5f 696e 6974 5f5f 280a    def __init__(.
-00004790: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
-000047a0: 2020 2020 2020 6e61 6d65 3a20 7374 722c        name: str,
-000047b0: 0a20 2020 2020 2020 2069 6e5f 7479 7065  .        in_type
-000047c0: 3a20 5061 7261 6d65 7465 7249 6e54 7970  : ParameterInTyp
-000047d0: 652c 0a20 2020 2020 2020 2072 6571 7569  e,.        requi
-000047e0: 7265 643a 2062 6f6f 6c20 3d20 4661 6c73  red: bool = Fals
-000047f0: 652c 0a20 2020 2020 2020 2073 7479 6c65  e,.        style
-00004800: 3a20 7479 7069 6e67 2e4f 7074 696f 6e61  : typing.Optiona
-00004810: 6c5b 5061 7261 6d65 7465 7253 7479 6c65  l[ParameterStyle
-00004820: 5d20 3d20 4e6f 6e65 2c0a 2020 2020 2020  ] = None,.      
-00004830: 2020 6578 706c 6f64 653a 2062 6f6f 6c20    explode: bool 
-00004840: 3d20 4661 6c73 652c 0a20 2020 2020 2020  = False,.       
-00004850: 2061 6c6c 6f77 5f72 6573 6572 7665 643a   allow_reserved:
-00004860: 2074 7970 696e 672e 4f70 7469 6f6e 616c   typing.Optional
-00004870: 5b62 6f6f 6c5d 203d 204e 6f6e 652c 0a20  [bool] = None,. 
-00004880: 2020 2020 2020 2073 6368 656d 613a 2074         schema: t
-00004890: 7970 696e 672e 4f70 7469 6f6e 616c 5b74  yping.Optional[t
-000048a0: 7970 696e 672e 5479 7065 5b53 6368 656d  yping.Type[Schem
-000048b0: 615d 5d20 3d20 4e6f 6e65 2c0a 2020 2020  a]] = None,.    
-000048c0: 2020 2020 636f 6e74 656e 743a 2074 7970      content: typ
-000048d0: 696e 672e 4f70 7469 6f6e 616c 5b74 7970  ing.Optional[typ
-000048e0: 696e 672e 4469 6374 5b73 7472 2c20 7479  ing.Dict[str, ty
-000048f0: 7069 6e67 2e54 7970 655b 5363 6865 6d61  ping.Type[Schema
-00004900: 5d5d 5d20 3d20 4e6f 6e65 0a20 2020 2029  ]]] = None.    )
-00004910: 3a0a 2020 2020 2020 2020 6966 2073 6368  :.        if sch
-00004920: 656d 6120 6973 204e 6f6e 6520 616e 6420  ema is None and 
-00004930: 636f 6e74 656e 7420 6973 204e 6f6e 653a  content is None:
-00004940: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
-00004950: 7365 2056 616c 7565 4572 726f 7228 2756  se ValueError('V
-00004960: 616c 7565 206d 6973 7369 6e67 3b20 5061  alue missing; Pa
-00004970: 7373 2069 6e20 6569 7468 6572 2073 6368  ss in either sch
-00004980: 656d 6120 6f72 2063 6f6e 7465 6e74 2729  ema or content')
-00004990: 0a20 2020 2020 2020 2069 6620 7363 6865  .        if sche
-000049a0: 6d61 2061 6e64 2063 6f6e 7465 6e74 3a0a  ma and content:.
-000049b0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-000049c0: 6520 5661 6c75 6545 7272 6f72 2827 546f  e ValueError('To
-000049d0: 6f20 6d61 6e79 2076 616c 7565 7320 7072  o many values pr
-000049e0: 6f76 6964 6564 2e20 426f 7468 2073 6368  ovided. Both sch
-000049f0: 656d 6120 616e 6420 636f 6e74 656e 7420  ema and content 
-00004a00: 7765 7265 2070 726f 7669 6465 642e 204f  were provided. O
-00004a10: 6e6c 7920 6f6e 6520 6d61 7920 6265 2069  nly one may be i
-00004a20: 6e70 7574 2729 0a20 2020 2020 2020 2069  nput').        i
-00004a30: 6620 6e61 6d65 2069 6e20 7365 6c66 2e5f  f name in self._
-00004a40: 5f64 6973 616c 6c6f 7765 645f 6865 6164  _disallowed_head
-00004a50: 6572 5f6e 616d 6573 2061 6e64 2069 6e5f  er_names and in_
-00004a60: 7479 7065 2069 7320 5061 7261 6d65 7465  type is Paramete
-00004a70: 7249 6e54 7970 652e 4845 4144 4552 3a0a  rInType.HEADER:.
-00004a80: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-00004a90: 6520 5661 6c75 6545 7272 6f72 2827 496e  e ValueError('In
-00004aa0: 7661 6c69 6420 6e61 6d65 2c20 6e61 6d65  valid name, name
-00004ab0: 206d 6179 206e 6f74 2062 6520 6f6e 6520   may not be one 
-00004ac0: 6f66 207b 7d27 2e66 6f72 6d61 7428 7365  of {}'.format(se
-00004ad0: 6c66 2e5f 5f64 6973 616c 6c6f 7765 645f  lf.__disallowed_
-00004ae0: 6865 6164 6572 5f6e 616d 6573 2929 0a20  header_names)). 
-00004af0: 2020 2020 2020 2073 656c 662e 5f5f 7665         self.__ve
-00004b00: 7269 6679 5f73 7479 6c65 5f74 6f5f 696e  rify_style_to_in
-00004b10: 5f74 7970 6528 7374 796c 652c 2069 6e5f  _type(style, in_
-00004b20: 7479 7065 290a 2020 2020 2020 2020 6966  type).        if
-00004b30: 2063 6f6e 7465 6e74 2069 7320 4e6f 6e65   content is None
-00004b40: 2061 6e64 2073 7479 6c65 2069 7320 4e6f   and style is No
-00004b50: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-00004b60: 7374 796c 6520 3d20 7365 6c66 2e5f 5f69  style = self.__i
-00004b70: 6e5f 7479 7065 5f74 6f5f 6465 6661 756c  n_type_to_defaul
-00004b80: 745f 7374 796c 655b 696e 5f74 7970 655d  t_style[in_type]
-00004b90: 0a20 2020 2020 2020 2069 6620 636f 6e74  .        if cont
-00004ba0: 656e 7420 6973 206e 6f74 204e 6f6e 6520  ent is not None 
-00004bb0: 616e 6420 696e 5f74 7970 6520 696e 2073  and in_type in s
-00004bc0: 656c 662e 5f5f 696e 5f74 7970 655f 746f  elf.__in_type_to
-00004bd0: 5f64 6566 6175 6c74 5f73 7479 6c65 2061  _default_style a
-00004be0: 6e64 206c 656e 2863 6f6e 7465 6e74 2920  nd len(content) 
-00004bf0: 213d 2031 3a0a 2020 2020 2020 2020 2020  != 1:.          
-00004c00: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
-00004c10: 6f72 2827 496e 7661 6c69 6420 636f 6e74  or('Invalid cont
-00004c20: 656e 7420 6c65 6e67 7468 2c20 636f 6e74  ent length, cont
-00004c30: 656e 7420 6c65 6e67 7468 206d 7573 7420  ent length must 
-00004c40: 6571 7561 6c20 3127 290a 2020 2020 2020  equal 1').      
-00004c50: 2020 7365 6c66 2e69 6e5f 7479 7065 203d    self.in_type =
-00004c60: 2069 6e5f 7479 7065 0a20 2020 2020 2020   in_type.       
-00004c70: 2073 656c 662e 6e61 6d65 203d 206e 616d   self.name = nam
-00004c80: 650a 2020 2020 2020 2020 7365 6c66 2e72  e.        self.r
-00004c90: 6571 7569 7265 6420 3d20 7265 7175 6972  equired = requir
-00004ca0: 6564 0a20 2020 2020 2020 2073 656c 662e  ed.        self.
-00004cb0: 7374 796c 6520 3d20 7374 796c 650a 2020  style = style.  
-00004cc0: 2020 2020 2020 7365 6c66 2e65 7870 6c6f        self.explo
-00004cd0: 6465 203d 2065 7870 6c6f 6465 0a20 2020  de = explode.   
-00004ce0: 2020 2020 2073 656c 662e 616c 6c6f 775f       self.allow_
-00004cf0: 7265 7365 7276 6564 203d 2061 6c6c 6f77  reserved = allow
-00004d00: 5f72 6573 6572 7665 640a 2020 2020 2020  _reserved.      
-00004d10: 2020 7365 6c66 2e73 6368 656d 6120 3d20    self.schema = 
-00004d20: 7363 6865 6d61 0a20 2020 2020 2020 2073  schema.        s
-00004d30: 656c 662e 636f 6e74 656e 7420 3d20 636f  elf.content = co
-00004d40: 6e74 656e 740a 0a20 2020 2064 6566 205f  ntent..    def _
-00004d50: 7365 7269 616c 697a 655f 6a73 6f6e 280a  serialize_json(.
-00004d60: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
-00004d70: 2020 2020 2020 696e 5f64 6174 613a 2074        in_data: t
-00004d80: 7970 696e 672e 556e 696f 6e5b 4e6f 6e65  yping.Union[None
-00004d90: 2c20 696e 742c 2066 6c6f 6174 2c20 7374  , int, float, st
-00004da0: 722c 2062 6f6f 6c2c 2064 6963 742c 206c  r, bool, dict, l
-00004db0: 6973 745d 2c0a 2020 2020 2020 2020 656c  ist],.        el
-00004dc0: 696d 696e 6174 655f 7768 6974 6573 7061  iminate_whitespa
-00004dd0: 6365 3a20 626f 6f6c 203d 2046 616c 7365  ce: bool = False
-00004de0: 0a20 2020 2029 202d 3e20 7374 723a 0a20  .    ) -> str:. 
-00004df0: 2020 2020 2020 2069 6620 656c 696d 696e         if elimin
-00004e00: 6174 655f 7768 6974 6573 7061 6365 3a0a  ate_whitespace:.
-00004e10: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00004e20: 726e 206a 736f 6e2e 6475 6d70 7328 696e  rn json.dumps(in
-00004e30: 5f64 6174 612c 2073 6570 6172 6174 6f72  _data, separator
-00004e40: 733d 7365 6c66 2e5f 6a73 6f6e 5f65 6e63  s=self._json_enc
-00004e50: 6f64 6572 2e63 6f6d 7061 6374 5f73 6570  oder.compact_sep
-00004e60: 6172 6174 6f72 7329 0a20 2020 2020 2020  arators).       
-00004e70: 2072 6574 7572 6e20 6a73 6f6e 2e64 756d   return json.dum
-00004e80: 7073 2869 6e5f 6461 7461 290a 0a0a 636c  ps(in_data)...cl
-00004e90: 6173 7320 5061 7468 5061 7261 6d65 7465  ass PathParamete
-00004ea0: 7228 5061 7261 6d65 7465 7242 6173 652c  r(ParameterBase,
-00004eb0: 2053 7479 6c65 5369 6d70 6c65 5365 7269   StyleSimpleSeri
-00004ec0: 616c 697a 6572 293a 0a0a 2020 2020 6465  alizer):..    de
-00004ed0: 6620 5f5f 696e 6974 5f5f 280a 2020 2020  f __init__(.    
-00004ee0: 2020 2020 7365 6c66 2c0a 2020 2020 2020      self,.      
-00004ef0: 2020 6e61 6d65 3a20 7374 722c 0a20 2020    name: str,.   
-00004f00: 2020 2020 2072 6571 7569 7265 643a 2062       required: b
-00004f10: 6f6f 6c20 3d20 4661 6c73 652c 0a20 2020  ool = False,.   
-00004f20: 2020 2020 2073 7479 6c65 3a20 7479 7069       style: typi
-00004f30: 6e67 2e4f 7074 696f 6e61 6c5b 5061 7261  ng.Optional[Para
-00004f40: 6d65 7465 7253 7479 6c65 5d20 3d20 4e6f  meterStyle] = No
-00004f50: 6e65 2c0a 2020 2020 2020 2020 6578 706c  ne,.        expl
-00004f60: 6f64 653a 2062 6f6f 6c20 3d20 4661 6c73  ode: bool = Fals
-00004f70: 652c 0a20 2020 2020 2020 2061 6c6c 6f77  e,.        allow
-00004f80: 5f72 6573 6572 7665 643a 2074 7970 696e  _reserved: typin
-00004f90: 672e 4f70 7469 6f6e 616c 5b62 6f6f 6c5d  g.Optional[bool]
-00004fa0: 203d 204e 6f6e 652c 0a20 2020 2020 2020   = None,.       
-00004fb0: 2073 6368 656d 613a 2074 7970 696e 672e   schema: typing.
-00004fc0: 4f70 7469 6f6e 616c 5b74 7970 696e 672e  Optional[typing.
-00004fd0: 5479 7065 5b53 6368 656d 615d 5d20 3d20  Type[Schema]] = 
-00004fe0: 4e6f 6e65 2c0a 2020 2020 2020 2020 636f  None,.        co
-00004ff0: 6e74 656e 743a 2074 7970 696e 672e 4f70  ntent: typing.Op
-00005000: 7469 6f6e 616c 5b74 7970 696e 672e 4469  tional[typing.Di
-00005010: 6374 5b73 7472 2c20 7479 7069 6e67 2e54  ct[str, typing.T
-00005020: 7970 655b 5363 6865 6d61 5d5d 5d20 3d20  ype[Schema]]] = 
-00005030: 4e6f 6e65 0a20 2020 2029 3a0a 2020 2020  None.    ):.    
-00005040: 2020 2020 7375 7065 7228 292e 5f5f 696e      super().__in
-00005050: 6974 5f5f 280a 2020 2020 2020 2020 2020  it__(.          
-00005060: 2020 6e61 6d65 2c0a 2020 2020 2020 2020    name,.        
-00005070: 2020 2020 696e 5f74 7970 653d 5061 7261      in_type=Para
-00005080: 6d65 7465 7249 6e54 7970 652e 5041 5448  meterInType.PATH
-00005090: 2c0a 2020 2020 2020 2020 2020 2020 7265  ,.            re
-000050a0: 7175 6972 6564 3d72 6571 7569 7265 642c  quired=required,
-000050b0: 0a20 2020 2020 2020 2020 2020 2073 7479  .            sty
-000050c0: 6c65 3d73 7479 6c65 2c0a 2020 2020 2020  le=style,.      
-000050d0: 2020 2020 2020 6578 706c 6f64 653d 6578        explode=ex
-000050e0: 706c 6f64 652c 0a20 2020 2020 2020 2020  plode,.         
-000050f0: 2020 2061 6c6c 6f77 5f72 6573 6572 7665     allow_reserve
-00005100: 643d 616c 6c6f 775f 7265 7365 7276 6564  d=allow_reserved
-00005110: 2c0a 2020 2020 2020 2020 2020 2020 7363  ,.            sc
-00005120: 6865 6d61 3d73 6368 656d 612c 0a20 2020  hema=schema,.   
-00005130: 2020 2020 2020 2020 2063 6f6e 7465 6e74           content
-00005140: 3d63 6f6e 7465 6e74 0a20 2020 2020 2020  =content.       
-00005150: 2029 0a0a 2020 2020 6465 6620 5f5f 7365   )..    def __se
-00005160: 7269 616c 697a 655f 6c61 6265 6c28 0a20  rialize_label(. 
-00005170: 2020 2020 2020 2073 656c 662c 0a20 2020         self,.   
-00005180: 2020 2020 2069 6e5f 6461 7461 3a20 7479       in_data: ty
-00005190: 7069 6e67 2e55 6e69 6f6e 5b4e 6f6e 652c  ping.Union[None,
-000051a0: 2069 6e74 2c20 666c 6f61 742c 2073 7472   int, float, str
-000051b0: 2c20 626f 6f6c 2c20 6469 6374 2c20 6c69  , bool, dict, li
-000051c0: 7374 5d0a 2020 2020 2920 2d3e 2074 7970  st].    ) -> typ
-000051d0: 696e 672e 4469 6374 5b73 7472 2c20 7374  ing.Dict[str, st
-000051e0: 725d 3a0a 2020 2020 2020 2020 7072 6566  r]:.        pref
-000051f0: 6978 5f73 6570 6172 6174 6f72 5f69 7465  ix_separator_ite
-00005200: 7261 746f 7220 3d20 5072 6566 6978 5365  rator = PrefixSe
-00005210: 7061 7261 746f 7249 7465 7261 746f 7228  paratorIterator(
-00005220: 272e 272c 2027 2e27 290a 2020 2020 2020  '.', '.').      
-00005230: 2020 7661 6c75 6520 3d20 7365 6c66 2e5f    value = self._
-00005240: 7265 6636 3537 305f 6578 7061 6e73 696f  ref6570_expansio
-00005250: 6e28 0a20 2020 2020 2020 2020 2020 2076  n(.            v
-00005260: 6172 6961 626c 655f 6e61 6d65 3d73 656c  ariable_name=sel
-00005270: 662e 6e61 6d65 2c0a 2020 2020 2020 2020  f.name,.        
-00005280: 2020 2020 696e 5f64 6174 613d 696e 5f64      in_data=in_d
-00005290: 6174 612c 0a20 2020 2020 2020 2020 2020  ata,.           
-000052a0: 2065 7870 6c6f 6465 3d73 656c 662e 6578   explode=self.ex
-000052b0: 706c 6f64 652c 0a20 2020 2020 2020 2020  plode,.         
-000052c0: 2020 2070 6572 6365 6e74 5f65 6e63 6f64     percent_encod
-000052d0: 653d 5472 7565 2c0a 2020 2020 2020 2020  e=True,.        
-000052e0: 2020 2020 7072 6566 6978 5f73 6570 6172      prefix_separ
-000052f0: 6174 6f72 5f69 7465 7261 746f 723d 7072  ator_iterator=pr
-00005300: 6566 6978 5f73 6570 6172 6174 6f72 5f69  efix_separator_i
-00005310: 7465 7261 746f 720a 2020 2020 2020 2020  terator.        
-00005320: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00005330: 2073 656c 662e 5f74 6f5f 6469 6374 2873   self._to_dict(s
-00005340: 656c 662e 6e61 6d65 2c20 7661 6c75 6529  elf.name, value)
-00005350: 0a0a 2020 2020 6465 6620 5f5f 7365 7269  ..    def __seri
-00005360: 616c 697a 655f 6d61 7472 6978 280a 2020  alize_matrix(.  
-00005370: 2020 2020 2020 7365 6c66 2c0a 2020 2020        self,.    
-00005380: 2020 2020 696e 5f64 6174 613a 2074 7970      in_data: typ
-00005390: 696e 672e 556e 696f 6e5b 4e6f 6e65 2c20  ing.Union[None, 
-000053a0: 696e 742c 2066 6c6f 6174 2c20 7374 722c  int, float, str,
-000053b0: 2062 6f6f 6c2c 2064 6963 742c 206c 6973   bool, dict, lis
-000053c0: 745d 0a20 2020 2029 202d 3e20 7479 7069  t].    ) -> typi
-000053d0: 6e67 2e44 6963 745b 7374 722c 2073 7472  ng.Dict[str, str
-000053e0: 5d3a 0a20 2020 2020 2020 2070 7265 6669  ]:.        prefi
-000053f0: 785f 7365 7061 7261 746f 725f 6974 6572  x_separator_iter
-00005400: 6174 6f72 203d 2050 7265 6669 7853 6570  ator = PrefixSep
-00005410: 6172 6174 6f72 4974 6572 6174 6f72 2827  aratorIterator('
-00005420: 3b27 2c20 273b 2729 0a20 2020 2020 2020  ;', ';').       
-00005430: 2076 616c 7565 203d 2073 656c 662e 5f72   value = self._r
-00005440: 6566 3635 3730 5f65 7870 616e 7369 6f6e  ef6570_expansion
-00005450: 280a 2020 2020 2020 2020 2020 2020 7661  (.            va
-00005460: 7269 6162 6c65 5f6e 616d 653d 7365 6c66  riable_name=self
-00005470: 2e6e 616d 652c 0a20 2020 2020 2020 2020  .name,.         
-00005480: 2020 2069 6e5f 6461 7461 3d69 6e5f 6461     in_data=in_da
-00005490: 7461 2c0a 2020 2020 2020 2020 2020 2020  ta,.            
-000054a0: 6578 706c 6f64 653d 7365 6c66 2e65 7870  explode=self.exp
-000054b0: 6c6f 6465 2c0a 2020 2020 2020 2020 2020  lode,.          
-000054c0: 2020 7065 7263 656e 745f 656e 636f 6465    percent_encode
-000054d0: 3d54 7275 652c 0a20 2020 2020 2020 2020  =True,.         
-000054e0: 2020 2070 7265 6669 785f 7365 7061 7261     prefix_separa
-000054f0: 746f 725f 6974 6572 6174 6f72 3d70 7265  tor_iterator=pre
-00005500: 6669 785f 7365 7061 7261 746f 725f 6974  fix_separator_it
-00005510: 6572 6174 6f72 0a20 2020 2020 2020 2029  erator.        )
-00005520: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00005530: 7365 6c66 2e5f 746f 5f64 6963 7428 7365  self._to_dict(se
-00005540: 6c66 2e6e 616d 652c 2076 616c 7565 290a  lf.name, value).
-00005550: 0a20 2020 2064 6566 205f 5f73 6572 6961  .    def __seria
-00005560: 6c69 7a65 5f73 696d 706c 6528 0a20 2020  lize_simple(.   
-00005570: 2020 2020 2073 656c 662c 0a20 2020 2020       self,.     
-00005580: 2020 2069 6e5f 6461 7461 3a20 7479 7069     in_data: typi
-00005590: 6e67 2e55 6e69 6f6e 5b4e 6f6e 652c 2069  ng.Union[None, i
-000055a0: 6e74 2c20 666c 6f61 742c 2073 7472 2c20  nt, float, str, 
-000055b0: 626f 6f6c 2c20 6469 6374 2c20 6c69 7374  bool, dict, list
-000055c0: 5d2c 0a20 2020 2029 202d 3e20 7479 7069  ],.    ) -> typi
-000055d0: 6e67 2e44 6963 745b 7374 722c 2073 7472  ng.Dict[str, str
-000055e0: 5d3a 0a20 2020 2020 2020 2076 616c 7565  ]:.        value
-000055f0: 203d 2073 656c 662e 5f73 6572 6961 6c69   = self._seriali
-00005600: 7a65 5f73 696d 706c 6528 0a20 2020 2020  ze_simple(.     
-00005610: 2020 2020 2020 2069 6e5f 6461 7461 3d69         in_data=i
-00005620: 6e5f 6461 7461 2c0a 2020 2020 2020 2020  n_data,.        
-00005630: 2020 2020 6e61 6d65 3d73 656c 662e 6e61      name=self.na
-00005640: 6d65 2c0a 2020 2020 2020 2020 2020 2020  me,.            
-00005650: 6578 706c 6f64 653d 7365 6c66 2e65 7870  explode=self.exp
-00005660: 6c6f 6465 2c0a 2020 2020 2020 2020 2020  lode,.          
-00005670: 2020 7065 7263 656e 745f 656e 636f 6465    percent_encode
-00005680: 3d54 7275 650a 2020 2020 2020 2020 290a  =True.        ).
-00005690: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-000056a0: 656c 662e 5f74 6f5f 6469 6374 2873 656c  elf._to_dict(sel
-000056b0: 662e 6e61 6d65 2c20 7661 6c75 6529 0a0a  f.name, value)..
-000056c0: 2020 2020 6465 6620 7365 7269 616c 697a      def serializ
-000056d0: 6528 0a20 2020 2020 2020 2073 656c 662c  e(.        self,
-000056e0: 0a20 2020 2020 2020 2069 6e5f 6461 7461  .        in_data
-000056f0: 3a20 7479 7069 6e67 2e55 6e69 6f6e 5b0a  : typing.Union[.
-00005700: 2020 2020 2020 2020 2020 2020 5363 6865              Sche
-00005710: 6d61 2c20 4465 6369 6d61 6c2c 2069 6e74  ma, Decimal, int
-00005720: 2c20 666c 6f61 742c 2073 7472 2c20 6461  , float, str, da
-00005730: 7465 2c20 6461 7465 7469 6d65 2c20 4e6f  te, datetime, No
-00005740: 6e65 2c20 626f 6f6c 2c20 6c69 7374 2c20  ne, bool, list, 
-00005750: 7475 706c 652c 2064 6963 742c 2066 726f  tuple, dict, fro
-00005760: 7a65 6e64 6963 742e 6672 6f7a 656e 6469  zendict.frozendi
-00005770: 6374 5d0a 2020 2020 2920 2d3e 2074 7970  ct].    ) -> typ
-00005780: 696e 672e 4469 6374 5b73 7472 2c20 7374  ing.Dict[str, st
-00005790: 725d 3a0a 2020 2020 2020 2020 6966 2073  r]:.        if s
-000057a0: 656c 662e 7363 6865 6d61 3a0a 2020 2020  elf.schema:.    
-000057b0: 2020 2020 2020 2020 6361 7374 5f69 6e5f          cast_in_
-000057c0: 6461 7461 203d 2073 656c 662e 7363 6865  data = self.sche
-000057d0: 6d61 2869 6e5f 6461 7461 290a 2020 2020  ma(in_data).    
-000057e0: 2020 2020 2020 2020 6361 7374 5f69 6e5f          cast_in_
-000057f0: 6461 7461 203d 2073 656c 662e 5f6a 736f  data = self._jso
-00005800: 6e5f 656e 636f 6465 722e 6465 6661 756c  n_encoder.defaul
-00005810: 7428 6361 7374 5f69 6e5f 6461 7461 290a  t(cast_in_data).
-00005820: 2020 2020 2020 2020 2020 2020 2222 220a              """.
-00005830: 2020 2020 2020 2020 2020 2020 7369 6d70              simp
-00005840: 6c65 202d 3e20 7061 7468 0a20 2020 2020  le -> path.     
-00005850: 2020 2020 2020 2020 2020 2070 6174 683a             path:
-00005860: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00005870: 2020 2020 2072 6574 7572 6e73 2070 6174       returns pat
-00005880: 685f 7061 7261 6d73 3a20 6469 6374 0a20  h_params: dict. 
-00005890: 2020 2020 2020 2020 2020 206c 6162 656c             label
-000058a0: 202d 3e20 7061 7468 0a20 2020 2020 2020   -> path.       
-000058b0: 2020 2020 2020 2020 2072 6574 7572 6e73           returns
-000058c0: 2070 6174 685f 7061 7261 6d73 0a20 2020   path_params.   
-000058d0: 2020 2020 2020 2020 206d 6174 7269 7820           matrix 
-000058e0: 2d3e 2070 6174 680a 2020 2020 2020 2020  -> path.        
-000058f0: 2020 2020 2020 2020 7265 7475 726e 7320          returns 
-00005900: 7061 7468 5f70 6172 616d 730a 2020 2020  path_params.    
-00005910: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-00005920: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-00005930: 7374 796c 653a 0a20 2020 2020 2020 2020  style:.         
-00005940: 2020 2020 2020 2069 6620 7365 6c66 2e73         if self.s
-00005950: 7479 6c65 2069 7320 5061 7261 6d65 7465  tyle is Paramete
-00005960: 7253 7479 6c65 2e53 494d 504c 453a 0a20  rStyle.SIMPLE:. 
-00005970: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005980: 2020 2072 6574 7572 6e20 7365 6c66 2e5f     return self._
-00005990: 5f73 6572 6961 6c69 7a65 5f73 696d 706c  _serialize_simpl
-000059a0: 6528 6361 7374 5f69 6e5f 6461 7461 290a  e(cast_in_data).
-000059b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000059c0: 656c 6966 2073 656c 662e 7374 796c 6520  elif self.style 
-000059d0: 6973 2050 6172 616d 6574 6572 5374 796c  is ParameterStyl
-000059e0: 652e 4c41 4245 4c3a 0a20 2020 2020 2020  e.LABEL:.       
-000059f0: 2020 2020 2020 2020 2020 2020 2072 6574               ret
-00005a00: 7572 6e20 7365 6c66 2e5f 5f73 6572 6961  urn self.__seria
-00005a10: 6c69 7a65 5f6c 6162 656c 2863 6173 745f  lize_label(cast_
-00005a20: 696e 5f64 6174 6129 0a20 2020 2020 2020  in_data).       
-00005a30: 2020 2020 2020 2020 2065 6c69 6620 7365           elif se
-00005a40: 6c66 2e73 7479 6c65 2069 7320 5061 7261  lf.style is Para
-00005a50: 6d65 7465 7253 7479 6c65 2e4d 4154 5249  meterStyle.MATRI
-00005a60: 583a 0a20 2020 2020 2020 2020 2020 2020  X:.             
-00005a70: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
-00005a80: 6c66 2e5f 5f73 6572 6961 6c69 7a65 5f6d  lf.__serialize_m
-00005a90: 6174 7269 7828 6361 7374 5f69 6e5f 6461  atrix(cast_in_da
-00005aa0: 7461 290a 2020 2020 2020 2020 2320 7365  ta).        # se
-00005ab0: 6c66 2e63 6f6e 7465 6e74 2077 696c 6c20  lf.content will 
-00005ac0: 6265 206c 656e 6774 6820 6f6e 650a 2020  be length one.  
-00005ad0: 2020 2020 2020 666f 7220 636f 6e74 656e        for conten
-00005ae0: 745f 7479 7065 2c20 7363 6865 6d61 2069  t_type, schema i
-00005af0: 6e20 7365 6c66 2e63 6f6e 7465 6e74 2e69  n self.content.i
-00005b00: 7465 6d73 2829 3a0a 2020 2020 2020 2020  tems():.        
-00005b10: 2020 2020 6361 7374 5f69 6e5f 6461 7461      cast_in_data
-00005b20: 203d 2073 6368 656d 6128 696e 5f64 6174   = schema(in_dat
-00005b30: 6129 0a20 2020 2020 2020 2020 2020 2063  a).            c
-00005b40: 6173 745f 696e 5f64 6174 6120 3d20 7365  ast_in_data = se
-00005b50: 6c66 2e5f 6a73 6f6e 5f65 6e63 6f64 6572  lf._json_encoder
-00005b60: 2e64 6566 6175 6c74 2863 6173 745f 696e  .default(cast_in
-00005b70: 5f64 6174 6129 0a20 2020 2020 2020 2020  _data).         
-00005b80: 2020 2069 6620 7365 6c66 2e5f 636f 6e74     if self._cont
-00005b90: 656e 745f 7479 7065 5f69 735f 6a73 6f6e  ent_type_is_json
-00005ba0: 2863 6f6e 7465 6e74 5f74 7970 6529 3a0a  (content_type):.
-00005bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005bc0: 7661 6c75 6520 3d20 7365 6c66 2e5f 7365  value = self._se
-00005bd0: 7269 616c 697a 655f 6a73 6f6e 2863 6173  rialize_json(cas
-00005be0: 745f 696e 5f64 6174 6129 0a20 2020 2020  t_in_data).     
-00005bf0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00005c00: 6e20 7365 6c66 2e5f 746f 5f64 6963 7428  n self._to_dict(
-00005c10: 7365 6c66 2e6e 616d 652c 2076 616c 7565  self.name, value
-00005c20: 290a 2020 2020 2020 2020 2020 2020 7261  ).            ra
-00005c30: 6973 6520 4e6f 7449 6d70 6c65 6d65 6e74  ise NotImplement
-00005c40: 6564 4572 726f 7228 2753 6572 6961 6c69  edError('Seriali
-00005c50: 7a61 7469 6f6e 206f 6620 7b7d 2068 6173  zation of {} has
-00005c60: 206e 6f74 2079 6574 2062 6565 6e20 696d   not yet been im
-00005c70: 706c 656d 656e 7465 6427 2e66 6f72 6d61  plemented'.forma
-00005c80: 7428 636f 6e74 656e 745f 7479 7065 2929  t(content_type))
-00005c90: 0a0a 0a63 6c61 7373 2051 7565 7279 5061  ...class QueryPa
-00005ca0: 7261 6d65 7465 7228 5061 7261 6d65 7465  rameter(Paramete
-00005cb0: 7242 6173 652c 2053 7479 6c65 466f 726d  rBase, StyleForm
-00005cc0: 5365 7269 616c 697a 6572 293a 0a0a 2020  Serializer):..  
-00005cd0: 2020 6465 6620 5f5f 696e 6974 5f5f 280a    def __init__(.
-00005ce0: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
-00005cf0: 2020 2020 2020 6e61 6d65 3a20 7374 722c        name: str,
-00005d00: 0a20 2020 2020 2020 2072 6571 7569 7265  .        require
-00005d10: 643a 2062 6f6f 6c20 3d20 4661 6c73 652c  d: bool = False,
-00005d20: 0a20 2020 2020 2020 2073 7479 6c65 3a20  .        style: 
-00005d30: 7479 7069 6e67 2e4f 7074 696f 6e61 6c5b  typing.Optional[
-00005d40: 5061 7261 6d65 7465 7253 7479 6c65 5d20  ParameterStyle] 
-00005d50: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
-00005d60: 6578 706c 6f64 653a 2074 7970 696e 672e  explode: typing.
-00005d70: 4f70 7469 6f6e 616c 5b62 6f6f 6c5d 203d  Optional[bool] =
-00005d80: 204e 6f6e 652c 0a20 2020 2020 2020 2061   None,.        a
-00005d90: 6c6c 6f77 5f72 6573 6572 7665 643a 2074  llow_reserved: t
-00005da0: 7970 696e 672e 4f70 7469 6f6e 616c 5b62  yping.Optional[b
-00005db0: 6f6f 6c5d 203d 204e 6f6e 652c 0a20 2020  ool] = None,.   
-00005dc0: 2020 2020 2073 6368 656d 613a 2074 7970       schema: typ
-00005dd0: 696e 672e 4f70 7469 6f6e 616c 5b74 7970  ing.Optional[typ
-00005de0: 696e 672e 5479 7065 5b53 6368 656d 615d  ing.Type[Schema]
-00005df0: 5d20 3d20 4e6f 6e65 2c0a 2020 2020 2020  ] = None,.      
-00005e00: 2020 636f 6e74 656e 743a 2074 7970 696e    content: typin
-00005e10: 672e 4f70 7469 6f6e 616c 5b74 7970 696e  g.Optional[typin
-00005e20: 672e 4469 6374 5b73 7472 2c20 7479 7069  g.Dict[str, typi
-00005e30: 6e67 2e54 7970 655b 5363 6865 6d61 5d5d  ng.Type[Schema]]
-00005e40: 5d20 3d20 4e6f 6e65 0a20 2020 2029 3a0a  ] = None.    ):.
-00005e50: 2020 2020 2020 2020 7573 6564 5f73 7479          used_sty
-00005e60: 6c65 203d 2050 6172 616d 6574 6572 5374  le = ParameterSt
-00005e70: 796c 652e 464f 524d 2069 6620 7374 796c  yle.FORM if styl
-00005e80: 6520 6973 204e 6f6e 6520 656c 7365 2073  e is None else s
-00005e90: 7479 6c65 0a20 2020 2020 2020 2075 7365  tyle.        use
-00005ea0: 645f 6578 706c 6f64 6520 3d20 7365 6c66  d_explode = self
-00005eb0: 2e5f 6765 745f 6465 6661 756c 745f 6578  ._get_default_ex
-00005ec0: 706c 6f64 6528 7573 6564 5f73 7479 6c65  plode(used_style
-00005ed0: 2920 6966 2065 7870 6c6f 6465 2069 7320  ) if explode is 
-00005ee0: 4e6f 6e65 2065 6c73 6520 6578 706c 6f64  None else explod
-00005ef0: 650a 0a20 2020 2020 2020 2073 7570 6572  e..        super
-00005f00: 2829 2e5f 5f69 6e69 745f 5f28 0a20 2020  ().__init__(.   
-00005f10: 2020 2020 2020 2020 206e 616d 652c 0a20           name,. 
-00005f20: 2020 2020 2020 2020 2020 2069 6e5f 7479             in_ty
-00005f30: 7065 3d50 6172 616d 6574 6572 496e 5479  pe=ParameterInTy
-00005f40: 7065 2e51 5545 5259 2c0a 2020 2020 2020  pe.QUERY,.      
-00005f50: 2020 2020 2020 7265 7175 6972 6564 3d72        required=r
-00005f60: 6571 7569 7265 642c 0a20 2020 2020 2020  equired,.       
-00005f70: 2020 2020 2073 7479 6c65 3d75 7365 645f       style=used_
-00005f80: 7374 796c 652c 0a20 2020 2020 2020 2020  style,.         
-00005f90: 2020 2065 7870 6c6f 6465 3d75 7365 645f     explode=used_
-00005fa0: 6578 706c 6f64 652c 0a20 2020 2020 2020  explode,.       
-00005fb0: 2020 2020 2061 6c6c 6f77 5f72 6573 6572       allow_reser
-00005fc0: 7665 643d 616c 6c6f 775f 7265 7365 7276  ved=allow_reserv
-00005fd0: 6564 2c0a 2020 2020 2020 2020 2020 2020  ed,.            
-00005fe0: 7363 6865 6d61 3d73 6368 656d 612c 0a20  schema=schema,. 
-00005ff0: 2020 2020 2020 2020 2020 2063 6f6e 7465             conte
-00006000: 6e74 3d63 6f6e 7465 6e74 0a20 2020 2020  nt=content.     
-00006010: 2020 2029 0a0a 2020 2020 6465 6620 5f5f     )..    def __
-00006020: 7365 7269 616c 697a 655f 7370 6163 655f  serialize_space_
-00006030: 6465 6c69 6d69 7465 6428 0a20 2020 2020  delimited(.     
-00006040: 2020 2073 656c 662c 0a20 2020 2020 2020     self,.       
-00006050: 2069 6e5f 6461 7461 3a20 7479 7069 6e67   in_data: typing
-00006060: 2e55 6e69 6f6e 5b4e 6f6e 652c 2069 6e74  .Union[None, int
-00006070: 2c20 666c 6f61 742c 2073 7472 2c20 626f  , float, str, bo
-00006080: 6f6c 2c20 6469 6374 2c20 6c69 7374 5d2c  ol, dict, list],
-00006090: 0a20 2020 2020 2020 2070 7265 6669 785f  .        prefix_
-000060a0: 7365 7061 7261 746f 725f 6974 6572 6174  separator_iterat
-000060b0: 6f72 3a20 7479 7069 6e67 2e4f 7074 696f  or: typing.Optio
-000060c0: 6e61 6c5b 5072 6566 6978 5365 7061 7261  nal[PrefixSepara
-000060d0: 746f 7249 7465 7261 746f 725d 0a20 2020  torIterator].   
-000060e0: 2029 202d 3e20 7479 7069 6e67 2e44 6963   ) -> typing.Dic
-000060f0: 745b 7374 722c 2073 7472 5d3a 0a20 2020  t[str, str]:.   
-00006100: 2020 2020 2069 6620 7072 6566 6978 5f73       if prefix_s
-00006110: 6570 6172 6174 6f72 5f69 7465 7261 746f  eparator_iterato
-00006120: 7220 6973 204e 6f6e 653a 0a20 2020 2020  r is None:.     
-00006130: 2020 2020 2020 2070 7265 6669 785f 7365         prefix_se
-00006140: 7061 7261 746f 725f 6974 6572 6174 6f72  parator_iterator
-00006150: 203d 2073 656c 662e 6765 745f 7072 6566   = self.get_pref
-00006160: 6978 5f73 6570 6172 6174 6f72 5f69 7465  ix_separator_ite
-00006170: 7261 746f 7228 290a 2020 2020 2020 2020  rator().        
-00006180: 7661 6c75 6520 3d20 7365 6c66 2e5f 7265  value = self._re
-00006190: 6636 3537 305f 6578 7061 6e73 696f 6e28  f6570_expansion(
-000061a0: 0a20 2020 2020 2020 2020 2020 2076 6172  .            var
-000061b0: 6961 626c 655f 6e61 6d65 3d73 656c 662e  iable_name=self.
-000061c0: 6e61 6d65 2c0a 2020 2020 2020 2020 2020  name,.          
-000061d0: 2020 696e 5f64 6174 613d 696e 5f64 6174    in_data=in_dat
-000061e0: 612c 0a20 2020 2020 2020 2020 2020 2065  a,.            e
-000061f0: 7870 6c6f 6465 3d73 656c 662e 6578 706c  xplode=self.expl
-00006200: 6f64 652c 0a20 2020 2020 2020 2020 2020  ode,.           
-00006210: 2070 6572 6365 6e74 5f65 6e63 6f64 653d   percent_encode=
-00006220: 5472 7565 2c0a 2020 2020 2020 2020 2020  True,.          
-00006230: 2020 7072 6566 6978 5f73 6570 6172 6174    prefix_separat
-00006240: 6f72 5f69 7465 7261 746f 723d 7072 6566  or_iterator=pref
-00006250: 6978 5f73 6570 6172 6174 6f72 5f69 7465  ix_separator_ite
-00006260: 7261 746f 720a 2020 2020 2020 2020 290a  rator.        ).
-00006270: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-00006280: 656c 662e 5f74 6f5f 6469 6374 2873 656c  elf._to_dict(sel
-00006290: 662e 6e61 6d65 2c20 7661 6c75 6529 0a0a  f.name, value)..
-000062a0: 2020 2020 6465 6620 5f5f 7365 7269 616c      def __serial
-000062b0: 697a 655f 7069 7065 5f64 656c 696d 6974  ize_pipe_delimit
-000062c0: 6564 280a 2020 2020 2020 2020 7365 6c66  ed(.        self
-000062d0: 2c0a 2020 2020 2020 2020 696e 5f64 6174  ,.        in_dat
-000062e0: 613a 2074 7970 696e 672e 556e 696f 6e5b  a: typing.Union[
-000062f0: 4e6f 6e65 2c20 696e 742c 2066 6c6f 6174  None, int, float
-00006300: 2c20 7374 722c 2062 6f6f 6c2c 2064 6963  , str, bool, dic
-00006310: 742c 206c 6973 745d 2c0a 2020 2020 2020  t, list],.      
-00006320: 2020 7072 6566 6978 5f73 6570 6172 6174    prefix_separat
-00006330: 6f72 5f69 7465 7261 746f 723a 2074 7970  or_iterator: typ
-00006340: 696e 672e 4f70 7469 6f6e 616c 5b50 7265  ing.Optional[Pre
-00006350: 6669 7853 6570 6172 6174 6f72 4974 6572  fixSeparatorIter
-00006360: 6174 6f72 5d0a 2020 2020 2920 2d3e 2074  ator].    ) -> t
-00006370: 7970 696e 672e 4469 6374 5b73 7472 2c20  yping.Dict[str, 
-00006380: 7374 725d 3a0a 2020 2020 2020 2020 6966  str]:.        if
-00006390: 2070 7265 6669 785f 7365 7061 7261 746f   prefix_separato
-000063a0: 725f 6974 6572 6174 6f72 2069 7320 4e6f  r_iterator is No
-000063b0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-000063c0: 7072 6566 6978 5f73 6570 6172 6174 6f72  prefix_separator
-000063d0: 5f69 7465 7261 746f 7220 3d20 7365 6c66  _iterator = self
-000063e0: 2e67 6574 5f70 7265 6669 785f 7365 7061  .get_prefix_sepa
-000063f0: 7261 746f 725f 6974 6572 6174 6f72 2829  rator_iterator()
-00006400: 0a20 2020 2020 2020 2076 616c 7565 203d  .        value =
-00006410: 2073 656c 662e 5f72 6566 3635 3730 5f65   self._ref6570_e
-00006420: 7870 616e 7369 6f6e 280a 2020 2020 2020  xpansion(.      
-00006430: 2020 2020 2020 7661 7269 6162 6c65 5f6e        variable_n
-00006440: 616d 653d 7365 6c66 2e6e 616d 652c 0a20  ame=self.name,. 
-00006450: 2020 2020 2020 2020 2020 2069 6e5f 6461             in_da
-00006460: 7461 3d69 6e5f 6461 7461 2c0a 2020 2020  ta=in_data,.    
-00006470: 2020 2020 2020 2020 6578 706c 6f64 653d          explode=
-00006480: 7365 6c66 2e65 7870 6c6f 6465 2c0a 2020  self.explode,.  
-00006490: 2020 2020 2020 2020 2020 7065 7263 656e            percen
-000064a0: 745f 656e 636f 6465 3d54 7275 652c 0a20  t_encode=True,. 
-000064b0: 2020 2020 2020 2020 2020 2070 7265 6669             prefi
-000064c0: 785f 7365 7061 7261 746f 725f 6974 6572  x_separator_iter
-000064d0: 6174 6f72 3d70 7265 6669 785f 7365 7061  ator=prefix_sepa
-000064e0: 7261 746f 725f 6974 6572 6174 6f72 0a20  rator_iterator. 
-000064f0: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
-00006500: 2072 6574 7572 6e20 7365 6c66 2e5f 746f   return self._to
-00006510: 5f64 6963 7428 7365 6c66 2e6e 616d 652c  _dict(self.name,
-00006520: 2076 616c 7565 290a 0a20 2020 2064 6566   value)..    def
-00006530: 205f 5f73 6572 6961 6c69 7a65 5f66 6f72   __serialize_for
-00006540: 6d28 0a20 2020 2020 2020 2073 656c 662c  m(.        self,
-00006550: 0a20 2020 2020 2020 2069 6e5f 6461 7461  .        in_data
-00006560: 3a20 7479 7069 6e67 2e55 6e69 6f6e 5b4e  : typing.Union[N
-00006570: 6f6e 652c 2069 6e74 2c20 666c 6f61 742c  one, int, float,
-00006580: 2073 7472 2c20 626f 6f6c 2c20 6469 6374   str, bool, dict
-00006590: 2c20 6c69 7374 5d2c 0a20 2020 2020 2020  , list],.       
-000065a0: 2070 7265 6669 785f 7365 7061 7261 746f   prefix_separato
-000065b0: 725f 6974 6572 6174 6f72 3a20 7479 7069  r_iterator: typi
-000065c0: 6e67 2e4f 7074 696f 6e61 6c5b 5072 6566  ng.Optional[Pref
-000065d0: 6978 5365 7061 7261 746f 7249 7465 7261  ixSeparatorItera
-000065e0: 746f 725d 0a20 2020 2029 202d 3e20 7479  tor].    ) -> ty
-000065f0: 7069 6e67 2e44 6963 745b 7374 722c 2073  ping.Dict[str, s
-00006600: 7472 5d3a 0a20 2020 2020 2020 2069 6620  tr]:.        if 
-00006610: 7072 6566 6978 5f73 6570 6172 6174 6f72  prefix_separator
-00006620: 5f69 7465 7261 746f 7220 6973 204e 6f6e  _iterator is Non
-00006630: 653a 0a20 2020 2020 2020 2020 2020 2070  e:.            p
-00006640: 7265 6669 785f 7365 7061 7261 746f 725f  refix_separator_
-00006650: 6974 6572 6174 6f72 203d 2073 656c 662e  iterator = self.
-00006660: 6765 745f 7072 6566 6978 5f73 6570 6172  get_prefix_separ
-00006670: 6174 6f72 5f69 7465 7261 746f 7228 290a  ator_iterator().
-00006680: 2020 2020 2020 2020 7661 6c75 6520 3d20          value = 
-00006690: 7365 6c66 2e5f 7365 7269 616c 697a 655f  self._serialize_
-000066a0: 666f 726d 280a 2020 2020 2020 2020 2020  form(.          
-000066b0: 2020 696e 5f64 6174 612c 0a20 2020 2020    in_data,.     
-000066c0: 2020 2020 2020 206e 616d 653d 7365 6c66         name=self
-000066d0: 2e6e 616d 652c 0a20 2020 2020 2020 2020  .name,.         
-000066e0: 2020 2065 7870 6c6f 6465 3d73 656c 662e     explode=self.
-000066f0: 6578 706c 6f64 652c 0a20 2020 2020 2020  explode,.       
-00006700: 2020 2020 2070 6572 6365 6e74 5f65 6e63       percent_enc
-00006710: 6f64 653d 5472 7565 2c0a 2020 2020 2020  ode=True,.      
-00006720: 2020 2020 2020 7072 6566 6978 5f73 6570        prefix_sep
-00006730: 6172 6174 6f72 5f69 7465 7261 746f 723d  arator_iterator=
-00006740: 7072 6566 6978 5f73 6570 6172 6174 6f72  prefix_separator
-00006750: 5f69 7465 7261 746f 720a 2020 2020 2020  _iterator.      
-00006760: 2020 290a 2020 2020 2020 2020 7265 7475    ).        retu
-00006770: 726e 2073 656c 662e 5f74 6f5f 6469 6374  rn self._to_dict
-00006780: 2873 656c 662e 6e61 6d65 2c20 7661 6c75  (self.name, valu
-00006790: 6529 0a0a 2020 2020 6465 6620 6765 745f  e)..    def get_
-000067a0: 7072 6566 6978 5f73 6570 6172 6174 6f72  prefix_separator
-000067b0: 5f69 7465 7261 746f 7228 7365 6c66 2920  _iterator(self) 
-000067c0: 2d3e 2074 7970 696e 672e 4f70 7469 6f6e  -> typing.Option
-000067d0: 616c 5b50 7265 6669 7853 6570 6172 6174  al[PrefixSeparat
-000067e0: 6f72 4974 6572 6174 6f72 5d3a 0a20 2020  orIterator]:.   
-000067f0: 2020 2020 2069 6620 7365 6c66 2e73 7479       if self.sty
-00006800: 6c65 2069 7320 5061 7261 6d65 7465 7253  le is ParameterS
-00006810: 7479 6c65 2e46 4f52 4d3a 0a20 2020 2020  tyle.FORM:.     
-00006820: 2020 2020 2020 2072 6574 7572 6e20 5072         return Pr
-00006830: 6566 6978 5365 7061 7261 746f 7249 7465  efixSeparatorIte
-00006840: 7261 746f 7228 273f 272c 2027 2627 290a  rator('?', '&').
-00006850: 2020 2020 2020 2020 656c 6966 2073 656c          elif sel
-00006860: 662e 7374 796c 6520 6973 2050 6172 616d  f.style is Param
-00006870: 6574 6572 5374 796c 652e 5350 4143 455f  eterStyle.SPACE_
-00006880: 4445 4c49 4d49 5445 443a 0a20 2020 2020  DELIMITED:.     
-00006890: 2020 2020 2020 2072 6574 7572 6e20 5072         return Pr
-000068a0: 6566 6978 5365 7061 7261 746f 7249 7465  efixSeparatorIte
-000068b0: 7261 746f 7228 2727 2c20 2725 3230 2729  rator('', '%20')
-000068c0: 0a20 2020 2020 2020 2065 6c69 6620 7365  .        elif se
-000068d0: 6c66 2e73 7479 6c65 2069 7320 5061 7261  lf.style is Para
-000068e0: 6d65 7465 7253 7479 6c65 2e50 4950 455f  meterStyle.PIPE_
-000068f0: 4445 4c49 4d49 5445 443a 0a20 2020 2020  DELIMITED:.     
-00006900: 2020 2020 2020 2072 6574 7572 6e20 5072         return Pr
-00006910: 6566 6978 5365 7061 7261 746f 7249 7465  efixSeparatorIte
-00006920: 7261 746f 7228 2727 2c20 277c 2729 0a0a  rator('', '|')..
-00006930: 2020 2020 6465 6620 7365 7269 616c 697a      def serializ
-00006940: 6528 0a20 2020 2020 2020 2073 656c 662c  e(.        self,
-00006950: 0a20 2020 2020 2020 2069 6e5f 6461 7461  .        in_data
-00006960: 3a20 7479 7069 6e67 2e55 6e69 6f6e 5b0a  : typing.Union[.
-00006970: 2020 2020 2020 2020 2020 2020 5363 6865              Sche
-00006980: 6d61 2c20 4465 6369 6d61 6c2c 2069 6e74  ma, Decimal, int
-00006990: 2c20 666c 6f61 742c 2073 7472 2c20 6461  , float, str, da
-000069a0: 7465 2c20 6461 7465 7469 6d65 2c20 4e6f  te, datetime, No
-000069b0: 6e65 2c20 626f 6f6c 2c20 6c69 7374 2c20  ne, bool, list, 
-000069c0: 7475 706c 652c 2064 6963 742c 2066 726f  tuple, dict, fro
-000069d0: 7a65 6e64 6963 742e 6672 6f7a 656e 6469  zendict.frozendi
-000069e0: 6374 5d2c 0a20 2020 2020 2020 2070 7265  ct],.        pre
-000069f0: 6669 785f 7365 7061 7261 746f 725f 6974  fix_separator_it
-00006a00: 6572 6174 6f72 3a20 7479 7069 6e67 2e4f  erator: typing.O
-00006a10: 7074 696f 6e61 6c5b 5072 6566 6978 5365  ptional[PrefixSe
-00006a20: 7061 7261 746f 7249 7465 7261 746f 725d  paratorIterator]
-00006a30: 203d 204e 6f6e 650a 2020 2020 2920 2d3e   = None.    ) ->
-00006a40: 2074 7970 696e 672e 4469 6374 5b73 7472   typing.Dict[str
-00006a50: 2c20 7374 725d 3a0a 2020 2020 2020 2020  , str]:.        
-00006a60: 6966 2073 656c 662e 7363 6865 6d61 3a0a  if self.schema:.
-00006a70: 2020 2020 2020 2020 2020 2020 6361 7374              cast
-00006a80: 5f69 6e5f 6461 7461 203d 2073 656c 662e  _in_data = self.
-00006a90: 7363 6865 6d61 2869 6e5f 6461 7461 290a  schema(in_data).
-00006aa0: 2020 2020 2020 2020 2020 2020 6361 7374              cast
-00006ab0: 5f69 6e5f 6461 7461 203d 2073 656c 662e  _in_data = self.
-00006ac0: 5f6a 736f 6e5f 656e 636f 6465 722e 6465  _json_encoder.de
-00006ad0: 6661 756c 7428 6361 7374 5f69 6e5f 6461  fault(cast_in_da
-00006ae0: 7461 290a 2020 2020 2020 2020 2020 2020  ta).            
-00006af0: 2222 220a 2020 2020 2020 2020 2020 2020  """.            
-00006b00: 666f 726d 202d 3e20 7175 6572 790a 2020  form -> query.  
-00006b10: 2020 2020 2020 2020 2020 2020 2020 7175                qu
-00006b20: 6572 793a 0a20 2020 2020 2020 2020 2020  ery:.           
-00006b30: 2020 2020 2020 2020 202d 2047 4554 2f48           - GET/H
-00006b40: 4541 442f 4445 4c45 5445 3a20 636f 756c  EAD/DELETE: coul
-00006b50: 6420 7573 6520 6669 656c 6473 0a20 2020  d use fields.   
-00006b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006b70: 202d 2050 5554 2f50 4f53 543a 206d 7573   - PUT/POST: mus
-00006b80: 7420 7573 6520 7572 6c65 6e63 6f64 6520  t use urlencode 
-00006b90: 746f 2073 656e 6420 7061 7261 6d65 7465  to send paramete
-00006ba0: 7273 0a20 2020 2020 2020 2020 2020 2020  rs.             
-00006bb0: 2020 2020 2020 2072 6574 7572 6e73 2066         returns f
-00006bc0: 6965 6c64 733a 2074 7570 6c65 0a20 2020  ields: tuple.   
-00006bd0: 2020 2020 2020 2020 2073 7061 6365 4465           spaceDe
-00006be0: 6c69 6d69 7465 6420 2d3e 2071 7565 7279  limited -> query
-00006bf0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00006c00: 2072 6574 7572 6e73 2066 6965 6c64 730a   returns fields.
-00006c10: 2020 2020 2020 2020 2020 2020 7069 7065              pipe
-00006c20: 4465 6c69 6d69 7465 6420 2d3e 2071 7565  Delimited -> que
-00006c30: 7279 0a20 2020 2020 2020 2020 2020 2020  ry.             
-00006c40: 2020 2072 6574 7572 6e73 2066 6965 6c64     returns field
-00006c50: 730a 2020 2020 2020 2020 2020 2020 6465  s.            de
-00006c60: 6570 4f62 6a65 6374 202d 3e20 7175 6572  epObject -> quer
-00006c70: 792c 2068 7474 7073 3a2f 2f67 6974 6875  y, https://githu
-00006c80: 622e 636f 6d2f 4f41 492f 4f70 656e 4150  b.com/OAI/OpenAP
-00006c90: 492d 5370 6563 6966 6963 6174 696f 6e2f  I-Specification/
-00006ca0: 6973 7375 6573 2f31 3730 360a 2020 2020  issues/1706.    
-00006cb0: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00006cc0: 726e 7320 6669 656c 6473 0a20 2020 2020  rns fields.     
-00006cd0: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
-00006ce0: 2020 2020 2020 2069 6620 7365 6c66 2e73         if self.s
-00006cf0: 7479 6c65 3a0a 2020 2020 2020 2020 2020  tyle:.          
-00006d00: 2020 2020 2020 2320 544f 444f 2075 7064        # TODO upd
-00006d10: 6174 6520 7175 6572 7920 6f6e 6573 2074  ate query ones t
-00006d20: 6f20 6f6d 6974 2073 6574 7469 6e67 2076  o omit setting v
-00006d30: 616c 7565 7320 7768 656e 205b 5d20 7b7d  alues when [] {}
-00006d40: 206f 7220 4e6f 6e65 2069 7320 696e 7075   or None is inpu
-00006d50: 740a 2020 2020 2020 2020 2020 2020 2020  t.              
-00006d60: 2020 6966 2073 656c 662e 7374 796c 6520    if self.style 
-00006d70: 6973 2050 6172 616d 6574 6572 5374 796c  is ParameterStyl
-00006d80: 652e 464f 524d 3a0a 2020 2020 2020 2020  e.FORM:.        
-00006d90: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00006da0: 726e 2073 656c 662e 5f5f 7365 7269 616c  rn self.__serial
-00006db0: 697a 655f 666f 726d 2863 6173 745f 696e  ize_form(cast_in
-00006dc0: 5f64 6174 612c 2070 7265 6669 785f 7365  _data, prefix_se
-00006dd0: 7061 7261 746f 725f 6974 6572 6174 6f72  parator_iterator
-00006de0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00006df0: 2020 656c 6966 2073 656c 662e 7374 796c    elif self.styl
-00006e00: 6520 6973 2050 6172 616d 6574 6572 5374  e is ParameterSt
-00006e10: 796c 652e 5350 4143 455f 4445 4c49 4d49  yle.SPACE_DELIMI
-00006e20: 5445 443a 0a20 2020 2020 2020 2020 2020  TED:.           
-00006e30: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-00006e40: 7365 6c66 2e5f 5f73 6572 6961 6c69 7a65  self.__serialize
-00006e50: 5f73 7061 6365 5f64 656c 696d 6974 6564  _space_delimited
-00006e60: 2863 6173 745f 696e 5f64 6174 612c 2070  (cast_in_data, p
-00006e70: 7265 6669 785f 7365 7061 7261 746f 725f  refix_separator_
-00006e80: 6974 6572 6174 6f72 290a 2020 2020 2020  iterator).      
-00006e90: 2020 2020 2020 2020 2020 656c 6966 2073            elif s
-00006ea0: 656c 662e 7374 796c 6520 6973 2050 6172  elf.style is Par
-00006eb0: 616d 6574 6572 5374 796c 652e 5049 5045  ameterStyle.PIPE
-00006ec0: 5f44 454c 494d 4954 4544 3a0a 2020 2020  _DELIMITED:.    
-00006ed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006ee0: 7265 7475 726e 2073 656c 662e 5f5f 7365  return self.__se
-00006ef0: 7269 616c 697a 655f 7069 7065 5f64 656c  rialize_pipe_del
-00006f00: 696d 6974 6564 2863 6173 745f 696e 5f64  imited(cast_in_d
-00006f10: 6174 612c 2070 7265 6669 785f 7365 7061  ata, prefix_sepa
-00006f20: 7261 746f 725f 6974 6572 6174 6f72 290a  rator_iterator).
-00006f30: 2020 2020 2020 2020 2320 7365 6c66 2e63          # self.c
-00006f40: 6f6e 7465 6e74 2077 696c 6c20 6265 206c  ontent will be l
-00006f50: 656e 6774 6820 6f6e 650a 2020 2020 2020  ength one.      
-00006f60: 2020 6966 2070 7265 6669 785f 7365 7061    if prefix_sepa
-00006f70: 7261 746f 725f 6974 6572 6174 6f72 2069  rator_iterator i
-00006f80: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
-00006f90: 2020 2020 7072 6566 6978 5f73 6570 6172      prefix_separ
-00006fa0: 6174 6f72 5f69 7465 7261 746f 7220 3d20  ator_iterator = 
-00006fb0: 7365 6c66 2e67 6574 5f70 7265 6669 785f  self.get_prefix_
-00006fc0: 7365 7061 7261 746f 725f 6974 6572 6174  separator_iterat
-00006fd0: 6f72 2829 0a20 2020 2020 2020 2066 6f72  or().        for
-00006fe0: 2063 6f6e 7465 6e74 5f74 7970 652c 2073   content_type, s
-00006ff0: 6368 656d 6120 696e 2073 656c 662e 636f  chema in self.co
-00007000: 6e74 656e 742e 6974 656d 7328 293a 0a20  ntent.items():. 
-00007010: 2020 2020 2020 2020 2020 2063 6173 745f             cast_
-00007020: 696e 5f64 6174 6120 3d20 7363 6865 6d61  in_data = schema
-00007030: 2869 6e5f 6461 7461 290a 2020 2020 2020  (in_data).      
-00007040: 2020 2020 2020 6361 7374 5f69 6e5f 6461        cast_in_da
-00007050: 7461 203d 2073 656c 662e 5f6a 736f 6e5f  ta = self._json_
-00007060: 656e 636f 6465 722e 6465 6661 756c 7428  encoder.default(
-00007070: 6361 7374 5f69 6e5f 6461 7461 290a 2020  cast_in_data).  
-00007080: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
-00007090: 662e 5f63 6f6e 7465 6e74 5f74 7970 655f  f._content_type_
-000070a0: 6973 5f6a 736f 6e28 636f 6e74 656e 745f  is_json(content_
-000070b0: 7479 7065 293a 0a20 2020 2020 2020 2020  type):.         
-000070c0: 2020 2020 2020 2076 616c 7565 203d 2073         value = s
-000070d0: 656c 662e 5f73 6572 6961 6c69 7a65 5f6a  elf._serialize_j
-000070e0: 736f 6e28 6361 7374 5f69 6e5f 6461 7461  son(cast_in_data
-000070f0: 2c20 656c 696d 696e 6174 655f 7768 6974  , eliminate_whit
-00007100: 6573 7061 6365 3d54 7275 6529 0a20 2020  espace=True).   
-00007110: 2020 2020 2020 2020 2020 2020 2072 6574               ret
-00007120: 7572 6e20 7365 6c66 2e5f 746f 5f64 6963  urn self._to_dic
-00007130: 7428 0a20 2020 2020 2020 2020 2020 2020  t(.             
-00007140: 2020 2020 2020 2073 656c 662e 6e61 6d65         self.name
-00007150: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00007160: 2020 2020 2020 6e65 7874 2870 7265 6669        next(prefi
-00007170: 785f 7365 7061 7261 746f 725f 6974 6572  x_separator_iter
-00007180: 6174 6f72 2920 2b20 7365 6c66 2e6e 616d  ator) + self.nam
-00007190: 6520 2b20 273d 2720 2b20 7175 6f74 6528  e + '=' + quote(
-000071a0: 7661 6c75 6529 0a20 2020 2020 2020 2020  value).         
-000071b0: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
-000071c0: 2020 2020 2072 6169 7365 204e 6f74 496d       raise NotIm
-000071d0: 706c 656d 656e 7465 6445 7272 6f72 2827  plementedError('
-000071e0: 5365 7269 616c 697a 6174 696f 6e20 6f66  Serialization of
-000071f0: 207b 7d20 6861 7320 6e6f 7420 7965 7420   {} has not yet 
-00007200: 6265 656e 2069 6d70 6c65 6d65 6e74 6564  been implemented
-00007210: 272e 666f 726d 6174 2863 6f6e 7465 6e74  '.format(content
-00007220: 5f74 7970 6529 290a 0a0a 636c 6173 7320  _type))...class 
-00007230: 436f 6f6b 6965 5061 7261 6d65 7465 7228  CookieParameter(
-00007240: 5061 7261 6d65 7465 7242 6173 652c 2053  ParameterBase, S
-00007250: 7479 6c65 466f 726d 5365 7269 616c 697a  tyleFormSerializ
-00007260: 6572 293a 0a0a 2020 2020 6465 6620 5f5f  er):..    def __
-00007270: 696e 6974 5f5f 280a 2020 2020 2020 2020  init__(.        
-00007280: 7365 6c66 2c0a 2020 2020 2020 2020 6e61  self,.        na
-00007290: 6d65 3a20 7374 722c 0a20 2020 2020 2020  me: str,.       
-000072a0: 2072 6571 7569 7265 643a 2062 6f6f 6c20   required: bool 
-000072b0: 3d20 4661 6c73 652c 0a20 2020 2020 2020  = False,.       
-000072c0: 2073 7479 6c65 3a20 7479 7069 6e67 2e4f   style: typing.O
-000072d0: 7074 696f 6e61 6c5b 5061 7261 6d65 7465  ptional[Paramete
-000072e0: 7253 7479 6c65 5d20 3d20 4e6f 6e65 2c0a  rStyle] = None,.
-000072f0: 2020 2020 2020 2020 6578 706c 6f64 653a          explode:
-00007300: 2074 7970 696e 672e 4f70 7469 6f6e 616c   typing.Optional
-00007310: 5b62 6f6f 6c5d 203d 204e 6f6e 652c 0a20  [bool] = None,. 
-00007320: 2020 2020 2020 2061 6c6c 6f77 5f72 6573         allow_res
-00007330: 6572 7665 643a 2074 7970 696e 672e 4f70  erved: typing.Op
-00007340: 7469 6f6e 616c 5b62 6f6f 6c5d 203d 204e  tional[bool] = N
-00007350: 6f6e 652c 0a20 2020 2020 2020 2073 6368  one,.        sch
-00007360: 656d 613a 2074 7970 696e 672e 4f70 7469  ema: typing.Opti
-00007370: 6f6e 616c 5b74 7970 696e 672e 5479 7065  onal[typing.Type
-00007380: 5b53 6368 656d 615d 5d20 3d20 4e6f 6e65  [Schema]] = None
-00007390: 2c0a 2020 2020 2020 2020 636f 6e74 656e  ,.        conten
-000073a0: 743a 2074 7970 696e 672e 4f70 7469 6f6e  t: typing.Option
-000073b0: 616c 5b74 7970 696e 672e 4469 6374 5b73  al[typing.Dict[s
-000073c0: 7472 2c20 7479 7069 6e67 2e54 7970 655b  tr, typing.Type[
-000073d0: 5363 6865 6d61 5d5d 5d20 3d20 4e6f 6e65  Schema]]] = None
-000073e0: 0a20 2020 2029 3a0a 2020 2020 2020 2020  .    ):.        
-000073f0: 7573 6564 5f73 7479 6c65 203d 2050 6172  used_style = Par
-00007400: 616d 6574 6572 5374 796c 652e 464f 524d  ameterStyle.FORM
-00007410: 2069 6620 7374 796c 6520 6973 204e 6f6e   if style is Non
-00007420: 6520 616e 6420 636f 6e74 656e 7420 6973  e and content is
-00007430: 204e 6f6e 6520 616e 6420 7363 6865 6d61   None and schema
-00007440: 2065 6c73 6520 7374 796c 650a 2020 2020   else style.    
-00007450: 2020 2020 7573 6564 5f65 7870 6c6f 6465      used_explode
-00007460: 203d 2073 656c 662e 5f67 6574 5f64 6566   = self._get_def
-00007470: 6175 6c74 5f65 7870 6c6f 6465 2875 7365  ault_explode(use
-00007480: 645f 7374 796c 6529 2069 6620 6578 706c  d_style) if expl
-00007490: 6f64 6520 6973 204e 6f6e 6520 656c 7365  ode is None else
-000074a0: 2065 7870 6c6f 6465 0a0a 2020 2020 2020   explode..      
-000074b0: 2020 7375 7065 7228 292e 5f5f 696e 6974    super().__init
-000074c0: 5f5f 280a 2020 2020 2020 2020 2020 2020  __(.            
-000074d0: 6e61 6d65 2c0a 2020 2020 2020 2020 2020  name,.          
-000074e0: 2020 696e 5f74 7970 653d 5061 7261 6d65    in_type=Parame
-000074f0: 7465 7249 6e54 7970 652e 434f 4f4b 4945  terInType.COOKIE
-00007500: 2c0a 2020 2020 2020 2020 2020 2020 7265  ,.            re
-00007510: 7175 6972 6564 3d72 6571 7569 7265 642c  quired=required,
-00007520: 0a20 2020 2020 2020 2020 2020 2073 7479  .            sty
-00007530: 6c65 3d75 7365 645f 7374 796c 652c 0a20  le=used_style,. 
-00007540: 2020 2020 2020 2020 2020 2065 7870 6c6f             explo
-00007550: 6465 3d75 7365 645f 6578 706c 6f64 652c  de=used_explode,
-00007560: 0a20 2020 2020 2020 2020 2020 2061 6c6c  .            all
-00007570: 6f77 5f72 6573 6572 7665 643d 616c 6c6f  ow_reserved=allo
-00007580: 775f 7265 7365 7276 6564 2c0a 2020 2020  w_reserved,.    
-00007590: 2020 2020 2020 2020 7363 6865 6d61 3d73          schema=s
-000075a0: 6368 656d 612c 0a20 2020 2020 2020 2020  chema,.         
-000075b0: 2020 2063 6f6e 7465 6e74 3d63 6f6e 7465     content=conte
-000075c0: 6e74 0a20 2020 2020 2020 2029 0a0a 2020  nt.        )..  
-000075d0: 2020 6465 6620 7365 7269 616c 697a 6528    def serialize(
-000075e0: 0a20 2020 2020 2020 2073 656c 662c 0a20  .        self,. 
-000075f0: 2020 2020 2020 2069 6e5f 6461 7461 3a20         in_data: 
-00007600: 7479 7069 6e67 2e55 6e69 6f6e 5b0a 2020  typing.Union[.  
-00007610: 2020 2020 2020 2020 2020 5363 6865 6d61            Schema
-00007620: 2c20 4465 6369 6d61 6c2c 2069 6e74 2c20  , Decimal, int, 
-00007630: 666c 6f61 742c 2073 7472 2c20 6461 7465  float, str, date
-00007640: 2c20 6461 7465 7469 6d65 2c20 4e6f 6e65  , datetime, None
-00007650: 2c20 626f 6f6c 2c20 6c69 7374 2c20 7475  , bool, list, tu
-00007660: 706c 652c 2064 6963 742c 2066 726f 7a65  ple, dict, froze
-00007670: 6e64 6963 742e 6672 6f7a 656e 6469 6374  ndict.frozendict
-00007680: 5d0a 2020 2020 2920 2d3e 2074 7970 696e  ].    ) -> typin
-00007690: 672e 4469 6374 5b73 7472 2c20 7374 725d  g.Dict[str, str]
-000076a0: 3a0a 2020 2020 2020 2020 6966 2073 656c  :.        if sel
-000076b0: 662e 7363 6865 6d61 3a0a 2020 2020 2020  f.schema:.      
-000076c0: 2020 2020 2020 6361 7374 5f69 6e5f 6461        cast_in_da
-000076d0: 7461 203d 2073 656c 662e 7363 6865 6d61  ta = self.schema
-000076e0: 2869 6e5f 6461 7461 290a 2020 2020 2020  (in_data).      
-000076f0: 2020 2020 2020 6361 7374 5f69 6e5f 6461        cast_in_da
-00007700: 7461 203d 2073 656c 662e 5f6a 736f 6e5f  ta = self._json_
-00007710: 656e 636f 6465 722e 6465 6661 756c 7428  encoder.default(
-00007720: 6361 7374 5f69 6e5f 6461 7461 290a 2020  cast_in_data).  
-00007730: 2020 2020 2020 2020 2020 2222 220a 2020            """.  
-00007740: 2020 2020 2020 2020 2020 666f 726d 202d            form -
-00007750: 3e20 636f 6f6b 6965 0a20 2020 2020 2020  > cookie.       
-00007760: 2020 2020 2020 2020 2072 6574 7572 6e73           returns
-00007770: 2066 6965 6c64 733a 2074 7570 6c65 0a20   fields: tuple. 
-00007780: 2020 2020 2020 2020 2020 2022 2222 0a20             """. 
-00007790: 2020 2020 2020 2020 2020 2069 6620 7365             if se
-000077a0: 6c66 2e73 7479 6c65 3a0a 2020 2020 2020  lf.style:.      
-000077b0: 2020 2020 2020 2020 2020 2222 220a 2020            """.  
-000077c0: 2020 2020 2020 2020 2020 2020 2020 544f                TO
-000077d0: 444f 2061 6464 2065 7363 6170 696e 6720  DO add escaping 
-000077e0: 6f66 2063 6f6d 6d61 2c20 7370 6163 652c  of comma, space,
-000077f0: 2065 7175 616c 730a 2020 2020 2020 2020   equals.        
-00007800: 2020 2020 2020 2020 6f72 2074 7572 6e20          or turn 
-00007810: 656e 636f 6469 6e67 206f 6e0a 2020 2020  encoding on.    
-00007820: 2020 2020 2020 2020 2020 2020 2222 220a              """.
-00007830: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007840: 7661 6c75 6520 3d20 7365 6c66 2e5f 7365  value = self._se
-00007850: 7269 616c 697a 655f 666f 726d 280a 2020  rialize_form(.  
-00007860: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007870: 2020 6361 7374 5f69 6e5f 6461 7461 2c0a    cast_in_data,.
-00007880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007890: 2020 2020 6578 706c 6f64 653d 7365 6c66      explode=self
-000078a0: 2e65 7870 6c6f 6465 2c0a 2020 2020 2020  .explode,.      
-000078b0: 2020 2020 2020 2020 2020 2020 2020 6e61                na
-000078c0: 6d65 3d73 656c 662e 6e61 6d65 2c0a 2020  me=self.name,.  
-000078d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000078e0: 2020 7065 7263 656e 745f 656e 636f 6465    percent_encode
-000078f0: 3d46 616c 7365 2c0a 2020 2020 2020 2020  =False,.        
-00007900: 2020 2020 2020 2020 2020 2020 7072 6566              pref
-00007910: 6978 5f73 6570 6172 6174 6f72 5f69 7465  ix_separator_ite
-00007920: 7261 746f 723d 5072 6566 6978 5365 7061  rator=PrefixSepa
-00007930: 7261 746f 7249 7465 7261 746f 7228 2727  ratorIterator(''
-00007940: 2c20 2726 2729 0a20 2020 2020 2020 2020  , '&').         
-00007950: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
-00007960: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-00007970: 7365 6c66 2e5f 746f 5f64 6963 7428 7365  self._to_dict(se
-00007980: 6c66 2e6e 616d 652c 2076 616c 7565 290a  lf.name, value).
-00007990: 2020 2020 2020 2020 2320 7365 6c66 2e63          # self.c
-000079a0: 6f6e 7465 6e74 2077 696c 6c20 6265 206c  ontent will be l
-000079b0: 656e 6774 6820 6f6e 650a 2020 2020 2020  ength one.      
-000079c0: 2020 666f 7220 636f 6e74 656e 745f 7479    for content_ty
-000079d0: 7065 2c20 7363 6865 6d61 2069 6e20 7365  pe, schema in se
-000079e0: 6c66 2e63 6f6e 7465 6e74 2e69 7465 6d73  lf.content.items
-000079f0: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
-00007a00: 6361 7374 5f69 6e5f 6461 7461 203d 2073  cast_in_data = s
-00007a10: 6368 656d 6128 696e 5f64 6174 6129 0a20  chema(in_data). 
-00007a20: 2020 2020 2020 2020 2020 2063 6173 745f             cast_
-00007a30: 696e 5f64 6174 6120 3d20 7365 6c66 2e5f  in_data = self._
-00007a40: 6a73 6f6e 5f65 6e63 6f64 6572 2e64 6566  json_encoder.def
-00007a50: 6175 6c74 2863 6173 745f 696e 5f64 6174  ault(cast_in_dat
-00007a60: 6129 0a20 2020 2020 2020 2020 2020 2069  a).            i
-00007a70: 6620 7365 6c66 2e5f 636f 6e74 656e 745f  f self._content_
-00007a80: 7479 7065 5f69 735f 6a73 6f6e 2863 6f6e  type_is_json(con
-00007a90: 7465 6e74 5f74 7970 6529 3a0a 2020 2020  tent_type):.    
-00007aa0: 2020 2020 2020 2020 2020 2020 7661 6c75              valu
-00007ab0: 6520 3d20 7365 6c66 2e5f 7365 7269 616c  e = self._serial
-00007ac0: 697a 655f 6a73 6f6e 2863 6173 745f 696e  ize_json(cast_in
-00007ad0: 5f64 6174 6129 0a20 2020 2020 2020 2020  _data).         
-00007ae0: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
-00007af0: 6c66 2e5f 746f 5f64 6963 7428 7365 6c66  lf._to_dict(self
-00007b00: 2e6e 616d 652c 2076 616c 7565 290a 2020  .name, value).  
-00007b10: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00007b20: 4e6f 7449 6d70 6c65 6d65 6e74 6564 4572  NotImplementedEr
-00007b30: 726f 7228 2753 6572 6961 6c69 7a61 7469  ror('Serializati
-00007b40: 6f6e 206f 6620 7b7d 2068 6173 206e 6f74  on of {} has not
-00007b50: 2079 6574 2062 6565 6e20 696d 706c 656d   yet been implem
-00007b60: 656e 7465 6427 2e66 6f72 6d61 7428 636f  ented'.format(co
-00007b70: 6e74 656e 745f 7479 7065 2929 0a0a 0a63  ntent_type))...c
-00007b80: 6c61 7373 2048 6561 6465 7250 6172 616d  lass HeaderParam
-00007b90: 6574 6572 2850 6172 616d 6574 6572 4261  eter(ParameterBa
-00007ba0: 7365 2c20 5374 796c 6553 696d 706c 6553  se, StyleSimpleS
-00007bb0: 6572 6961 6c69 7a65 7229 3a0a 2020 2020  erializer):.    
-00007bc0: 6465 6620 5f5f 696e 6974 5f5f 280a 2020  def __init__(.  
-00007bd0: 2020 2020 2020 7365 6c66 2c0a 2020 2020        self,.    
-00007be0: 2020 2020 6e61 6d65 3a20 7374 722c 0a20      name: str,. 
-00007bf0: 2020 2020 2020 2072 6571 7569 7265 643a         required:
-00007c00: 2062 6f6f 6c20 3d20 4661 6c73 652c 0a20   bool = False,. 
-00007c10: 2020 2020 2020 2073 7479 6c65 3a20 7479         style: ty
-00007c20: 7069 6e67 2e4f 7074 696f 6e61 6c5b 5061  ping.Optional[Pa
-00007c30: 7261 6d65 7465 7253 7479 6c65 5d20 3d20  rameterStyle] = 
-00007c40: 4e6f 6e65 2c0a 2020 2020 2020 2020 6578  None,.        ex
-00007c50: 706c 6f64 653a 2062 6f6f 6c20 3d20 4661  plode: bool = Fa
-00007c60: 6c73 652c 0a20 2020 2020 2020 2061 6c6c  lse,.        all
-00007c70: 6f77 5f72 6573 6572 7665 643a 2074 7970  ow_reserved: typ
-00007c80: 696e 672e 4f70 7469 6f6e 616c 5b62 6f6f  ing.Optional[boo
-00007c90: 6c5d 203d 204e 6f6e 652c 0a20 2020 2020  l] = None,.     
-00007ca0: 2020 2073 6368 656d 613a 2074 7970 696e     schema: typin
-00007cb0: 672e 4f70 7469 6f6e 616c 5b74 7970 696e  g.Optional[typin
-00007cc0: 672e 5479 7065 5b53 6368 656d 615d 5d20  g.Type[Schema]] 
-00007cd0: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
-00007ce0: 636f 6e74 656e 743a 2074 7970 696e 672e  content: typing.
-00007cf0: 4f70 7469 6f6e 616c 5b74 7970 696e 672e  Optional[typing.
-00007d00: 4469 6374 5b73 7472 2c20 7479 7069 6e67  Dict[str, typing
-00007d10: 2e54 7970 655b 5363 6865 6d61 5d5d 5d20  .Type[Schema]]] 
-00007d20: 3d20 4e6f 6e65 0a20 2020 2029 3a0a 2020  = None.    ):.  
-00007d30: 2020 2020 2020 7375 7065 7228 292e 5f5f        super().__
-00007d40: 696e 6974 5f5f 280a 2020 2020 2020 2020  init__(.        
-00007d50: 2020 2020 6e61 6d65 2c0a 2020 2020 2020      name,.      
-00007d60: 2020 2020 2020 696e 5f74 7970 653d 5061        in_type=Pa
-00007d70: 7261 6d65 7465 7249 6e54 7970 652e 4845  rameterInType.HE
-00007d80: 4144 4552 2c0a 2020 2020 2020 2020 2020  ADER,.          
-00007d90: 2020 7265 7175 6972 6564 3d72 6571 7569    required=requi
-00007da0: 7265 642c 0a20 2020 2020 2020 2020 2020  red,.           
-00007db0: 2073 7479 6c65 3d73 7479 6c65 2c0a 2020   style=style,.  
-00007dc0: 2020 2020 2020 2020 2020 6578 706c 6f64            explod
-00007dd0: 653d 6578 706c 6f64 652c 0a20 2020 2020  e=explode,.     
-00007de0: 2020 2020 2020 2061 6c6c 6f77 5f72 6573         allow_res
-00007df0: 6572 7665 643d 616c 6c6f 775f 7265 7365  erved=allow_rese
-00007e00: 7276 6564 2c0a 2020 2020 2020 2020 2020  rved,.          
-00007e10: 2020 7363 6865 6d61 3d73 6368 656d 612c    schema=schema,
-00007e20: 0a20 2020 2020 2020 2020 2020 2063 6f6e  .            con
-00007e30: 7465 6e74 3d63 6f6e 7465 6e74 0a20 2020  tent=content.   
-00007e40: 2020 2020 2029 0a0a 2020 2020 4073 7461       )..    @sta
-00007e50: 7469 636d 6574 686f 640a 2020 2020 6465  ticmethod.    de
-00007e60: 6620 5f5f 746f 5f68 6561 6465 7273 2869  f __to_headers(i
-00007e70: 6e5f 6461 7461 3a20 7479 7069 6e67 2e54  n_data: typing.T
-00007e80: 7570 6c65 5b74 7970 696e 672e 5475 706c  uple[typing.Tupl
-00007e90: 655b 7374 722c 2073 7472 5d2c 202e 2e2e  e[str, str], ...
-00007ea0: 5d29 202d 3e20 4854 5450 4865 6164 6572  ]) -> HTTPHeader
-00007eb0: 4469 6374 3a0a 2020 2020 2020 2020 6461  Dict:.        da
-00007ec0: 7461 203d 2074 7570 6c65 2874 2066 6f72  ta = tuple(t for
-00007ed0: 2074 2069 6e20 696e 5f64 6174 6120 6966   t in in_data if
-00007ee0: 2074 290a 2020 2020 2020 2020 6865 6164   t).        head
-00007ef0: 6572 7320 3d20 4854 5450 4865 6164 6572  ers = HTTPHeader
-00007f00: 4469 6374 2829 0a20 2020 2020 2020 2069  Dict().        i
-00007f10: 6620 6e6f 7420 6461 7461 3a0a 2020 2020  f not data:.    
-00007f20: 2020 2020 2020 2020 7265 7475 726e 2068          return h
-00007f30: 6561 6465 7273 0a20 2020 2020 2020 2068  eaders.        h
-00007f40: 6561 6465 7273 2e65 7874 656e 6428 6461  eaders.extend(da
-00007f50: 7461 290a 2020 2020 2020 2020 7265 7475  ta).        retu
-00007f60: 726e 2068 6561 6465 7273 0a0a 2020 2020  rn headers..    
-00007f70: 6465 6620 7365 7269 616c 697a 6528 0a20  def serialize(. 
-00007f80: 2020 2020 2020 2073 656c 662c 0a20 2020         self,.   
-00007f90: 2020 2020 2069 6e5f 6461 7461 3a20 7479       in_data: ty
-00007fa0: 7069 6e67 2e55 6e69 6f6e 5b0a 2020 2020  ping.Union[.    
-00007fb0: 2020 2020 2020 2020 5363 6865 6d61 2c20          Schema, 
-00007fc0: 4465 6369 6d61 6c2c 2069 6e74 2c20 666c  Decimal, int, fl
-00007fd0: 6f61 742c 2073 7472 2c20 6461 7465 2c20  oat, str, date, 
-00007fe0: 6461 7465 7469 6d65 2c20 4e6f 6e65 2c20  datetime, None, 
-00007ff0: 626f 6f6c 2c20 6c69 7374 2c20 7475 706c  bool, list, tupl
-00008000: 652c 2064 6963 742c 2066 726f 7a65 6e64  e, dict, frozend
-00008010: 6963 742e 6672 6f7a 656e 6469 6374 5d0a  ict.frozendict].
-00008020: 2020 2020 2920 2d3e 2048 5454 5048 6561      ) -> HTTPHea
-00008030: 6465 7244 6963 743a 0a20 2020 2020 2020  derDict:.       
-00008040: 2069 6620 7365 6c66 2e73 6368 656d 613a   if self.schema:
-00008050: 0a20 2020 2020 2020 2020 2020 2063 6173  .            cas
-00008060: 745f 696e 5f64 6174 6120 3d20 7365 6c66  t_in_data = self
-00008070: 2e73 6368 656d 6128 696e 5f64 6174 6129  .schema(in_data)
-00008080: 0a20 2020 2020 2020 2020 2020 2063 6173  .            cas
-00008090: 745f 696e 5f64 6174 6120 3d20 7365 6c66  t_in_data = self
-000080a0: 2e5f 6a73 6f6e 5f65 6e63 6f64 6572 2e64  ._json_encoder.d
-000080b0: 6566 6175 6c74 2863 6173 745f 696e 5f64  efault(cast_in_d
-000080c0: 6174 6129 0a20 2020 2020 2020 2020 2020  ata).           
-000080d0: 2022 2222 0a20 2020 2020 2020 2020 2020   """.           
-000080e0: 2073 696d 706c 6520 2d3e 2068 6561 6465   simple -> heade
-000080f0: 720a 2020 2020 2020 2020 2020 2020 2020  r.              
-00008100: 2020 6865 6164 6572 733a 2050 6f6f 6c4d    headers: PoolM
-00008110: 616e 6167 6572 206e 6565 6473 2061 206d  anager needs a m
-00008120: 6170 7069 6e67 2c20 7475 706c 6520 6973  apping, tuple is
-00008130: 2063 6c6f 7365 0a20 2020 2020 2020 2020   close.         
-00008140: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00008150: 6e73 2068 6561 6465 7273 3a20 6469 6374  ns headers: dict
-00008160: 0a20 2020 2020 2020 2020 2020 2022 2222  .            """
-00008170: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00008180: 7365 6c66 2e73 7479 6c65 3a0a 2020 2020  self.style:.    
-00008190: 2020 2020 2020 2020 2020 2020 7661 6c75              valu
-000081a0: 6520 3d20 7365 6c66 2e5f 7365 7269 616c  e = self._serial
-000081b0: 697a 655f 7369 6d70 6c65 2863 6173 745f  ize_simple(cast_
-000081c0: 696e 5f64 6174 612c 2073 656c 662e 6e61  in_data, self.na
-000081d0: 6d65 2c20 7365 6c66 2e65 7870 6c6f 6465  me, self.explode
-000081e0: 2c20 4661 6c73 6529 0a20 2020 2020 2020  , False).       
-000081f0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-00008200: 7365 6c66 2e5f 5f74 6f5f 6865 6164 6572  self.__to_header
-00008210: 7328 2828 7365 6c66 2e6e 616d 652c 2076  s(((self.name, v
-00008220: 616c 7565 292c 2929 0a20 2020 2020 2020  alue),)).       
-00008230: 2023 2073 656c 662e 636f 6e74 656e 7420   # self.content 
-00008240: 7769 6c6c 2062 6520 6c65 6e67 7468 206f  will be length o
-00008250: 6e65 0a20 2020 2020 2020 2066 6f72 2063  ne.        for c
-00008260: 6f6e 7465 6e74 5f74 7970 652c 2073 6368  ontent_type, sch
-00008270: 656d 6120 696e 2073 656c 662e 636f 6e74  ema in self.cont
-00008280: 656e 742e 6974 656d 7328 293a 0a20 2020  ent.items():.   
-00008290: 2020 2020 2020 2020 2063 6173 745f 696e           cast_in
-000082a0: 5f64 6174 6120 3d20 7363 6865 6d61 2869  _data = schema(i
-000082b0: 6e5f 6461 7461 290a 2020 2020 2020 2020  n_data).        
-000082c0: 2020 2020 6361 7374 5f69 6e5f 6461 7461      cast_in_data
-000082d0: 203d 2073 656c 662e 5f6a 736f 6e5f 656e   = self._json_en
-000082e0: 636f 6465 722e 6465 6661 756c 7428 6361  coder.default(ca
-000082f0: 7374 5f69 6e5f 6461 7461 290a 2020 2020  st_in_data).    
-00008300: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-00008310: 5f63 6f6e 7465 6e74 5f74 7970 655f 6973  _content_type_is
-00008320: 5f6a 736f 6e28 636f 6e74 656e 745f 7479  _json(content_ty
-00008330: 7065 293a 0a20 2020 2020 2020 2020 2020  pe):.           
-00008340: 2020 2020 2076 616c 7565 203d 2073 656c       value = sel
-00008350: 662e 5f73 6572 6961 6c69 7a65 5f6a 736f  f._serialize_jso
-00008360: 6e28 6361 7374 5f69 6e5f 6461 7461 290a  n(cast_in_data).
-00008370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008380: 7265 7475 726e 2073 656c 662e 5f5f 746f  return self.__to
-00008390: 5f68 6561 6465 7273 2828 2873 656c 662e  _headers(((self.
-000083a0: 6e61 6d65 2c20 7661 6c75 6529 2c29 290a  name, value),)).
-000083b0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-000083c0: 6520 4e6f 7449 6d70 6c65 6d65 6e74 6564  e NotImplemented
-000083d0: 4572 726f 7228 2753 6572 6961 6c69 7a61  Error('Serializa
-000083e0: 7469 6f6e 206f 6620 7b7d 2068 6173 206e  tion of {} has n
-000083f0: 6f74 2079 6574 2062 6565 6e20 696d 706c  ot yet been impl
-00008400: 656d 656e 7465 6427 2e66 6f72 6d61 7428  emented'.format(
-00008410: 636f 6e74 656e 745f 7479 7065 2929 0a0a  content_type))..
-00008420: 0a63 6c61 7373 2045 6e63 6f64 696e 673a  .class Encoding:
-00008430: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
-00008440: 5f28 0a20 2020 2020 2020 2073 656c 662c  _(.        self,
-00008450: 0a20 2020 2020 2020 2063 6f6e 7465 6e74  .        content
-00008460: 5f74 7970 653a 2073 7472 2c0a 2020 2020  _type: str,.    
-00008470: 2020 2020 6865 6164 6572 733a 2074 7970      headers: typ
-00008480: 696e 672e 4f70 7469 6f6e 616c 5b74 7970  ing.Optional[typ
-00008490: 696e 672e 4469 6374 5b73 7472 2c20 4865  ing.Dict[str, He
-000084a0: 6164 6572 5061 7261 6d65 7465 725d 5d20  aderParameter]] 
-000084b0: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
-000084c0: 7374 796c 653a 2074 7970 696e 672e 4f70  style: typing.Op
-000084d0: 7469 6f6e 616c 5b50 6172 616d 6574 6572  tional[Parameter
-000084e0: 5374 796c 655d 203d 204e 6f6e 652c 0a20  Style] = None,. 
-000084f0: 2020 2020 2020 2065 7870 6c6f 6465 3a20         explode: 
-00008500: 626f 6f6c 203d 2046 616c 7365 2c0a 2020  bool = False,.  
-00008510: 2020 2020 2020 616c 6c6f 775f 7265 7365        allow_rese
-00008520: 7276 6564 3a20 626f 6f6c 203d 2046 616c  rved: bool = Fal
-00008530: 7365 2c0a 2020 2020 293a 0a20 2020 2020  se,.    ):.     
-00008540: 2020 2073 656c 662e 636f 6e74 656e 745f     self.content_
-00008550: 7479 7065 203d 2063 6f6e 7465 6e74 5f74  type = content_t
-00008560: 7970 650a 2020 2020 2020 2020 7365 6c66  ype.        self
-00008570: 2e68 6561 6465 7273 203d 2068 6561 6465  .headers = heade
-00008580: 7273 0a20 2020 2020 2020 2073 656c 662e  rs.        self.
-00008590: 7374 796c 6520 3d20 7374 796c 650a 2020  style = style.  
-000085a0: 2020 2020 2020 7365 6c66 2e65 7870 6c6f        self.explo
-000085b0: 6465 203d 2065 7870 6c6f 6465 0a20 2020  de = explode.   
-000085c0: 2020 2020 2073 656c 662e 616c 6c6f 775f       self.allow_
-000085d0: 7265 7365 7276 6564 203d 2061 6c6c 6f77  reserved = allow
-000085e0: 5f72 6573 6572 7665 640a 0a0a 4064 6174  _reserved...@dat
-000085f0: 6163 6c61 7373 0a63 6c61 7373 204d 6564  aclass.class Med
-00008600: 6961 5479 7065 3a0a 2020 2020 2222 220a  iaType:.    """.
-00008610: 2020 2020 5573 6564 2074 6f20 7374 6f72      Used to stor
-00008620: 6520 7265 7175 6573 7420 616e 6420 7265  e request and re
-00008630: 7370 6f6e 7365 2062 6f64 7920 7363 6865  sponse body sche
-00008640: 6d61 2069 6e66 6f72 6d61 7469 6f6e 0a20  ma information. 
-00008650: 2020 2065 6e63 6f64 696e 673a 0a20 2020     encoding:.   
-00008660: 2020 2020 2041 206d 6170 2062 6574 7765       A map betwe
-00008670: 656e 2061 2070 726f 7065 7274 7920 6e61  en a property na
-00008680: 6d65 2061 6e64 2069 7473 2065 6e63 6f64  me and its encod
-00008690: 696e 6720 696e 666f 726d 6174 696f 6e2e  ing information.
-000086a0: 0a20 2020 2020 2020 2054 6865 206b 6579  .        The key
-000086b0: 2c20 6265 696e 6720 7468 6520 7072 6f70  , being the prop
-000086c0: 6572 7479 206e 616d 652c 204d 5553 5420  erty name, MUST 
-000086d0: 6578 6973 7420 696e 2074 6865 2073 6368  exist in the sch
-000086e0: 656d 6120 6173 2061 2070 726f 7065 7274  ema as a propert
-000086f0: 792e 0a20 2020 2020 2020 2054 6865 2065  y..        The e
-00008700: 6e63 6f64 696e 6720 6f62 6a65 6374 2053  ncoding object S
-00008710: 4841 4c4c 206f 6e6c 7920 6170 706c 7920  HALL only apply 
-00008720: 746f 2072 6571 7565 7374 426f 6479 206f  to requestBody o
-00008730: 626a 6563 7473 2077 6865 6e20 7468 6520  bjects when the 
-00008740: 6d65 6469 6120 7479 7065 2069 730a 2020  media type is.  
-00008750: 2020 2020 2020 6d75 6c74 6970 6172 7420        multipart 
-00008760: 6f72 2061 7070 6c69 6361 7469 6f6e 2f78  or application/x
-00008770: 2d77 7777 2d66 6f72 6d2d 7572 6c65 6e63  -www-form-urlenc
-00008780: 6f64 6564 2e0a 2020 2020 2222 220a 2020  oded..    """.  
-00008790: 2020 7363 6865 6d61 3a20 7479 7069 6e67    schema: typing
-000087a0: 2e4f 7074 696f 6e61 6c5b 7479 7069 6e67  .Optional[typing
-000087b0: 2e54 7970 655b 5363 6865 6d61 5d5d 203d  .Type[Schema]] =
-000087c0: 204e 6f6e 650a 2020 2020 656e 636f 6469   None.    encodi
-000087d0: 6e67 3a20 7479 7069 6e67 2e4f 7074 696f  ng: typing.Optio
-000087e0: 6e61 6c5b 7479 7069 6e67 2e44 6963 745b  nal[typing.Dict[
-000087f0: 7374 722c 2045 6e63 6f64 696e 675d 5d20  str, Encoding]] 
-00008800: 3d20 4e6f 6e65 0a0a 0a40 6461 7461 636c  = None...@datacl
-00008810: 6173 730a 636c 6173 7320 4170 6952 6573  ass.class ApiRes
-00008820: 706f 6e73 6557 6974 686f 7574 4465 7365  ponseWithoutDese
-00008830: 7269 616c 697a 6174 696f 6e28 4170 6952  rialization(ApiR
-00008840: 6573 706f 6e73 6529 3a0a 2020 2020 7061  esponse):.    pa
-00008850: 7373 0a0a 4064 6174 6163 6c61 7373 0a63  ss..@dataclass.c
-00008860: 6c61 7373 2041 7069 5265 7370 6f6e 7365  lass ApiResponse
-00008870: 5769 7468 6f75 7444 6573 6572 6961 6c69  WithoutDeseriali
-00008880: 7a61 7469 6f6e 4173 796e 6328 4173 796e  zationAsync(Asyn
-00008890: 6341 7069 5265 7370 6f6e 7365 293a 0a20  cApiResponse):. 
-000088a0: 2020 2070 6173 730a 0a0a 636c 6173 7320     pass...class 
-000088b0: 4f70 656e 4170 6952 6573 706f 6e73 6528  OpenApiResponse(
-000088c0: 4a53 4f4e 4465 7465 6374 6f72 293a 0a20  JSONDetector):. 
-000088d0: 2020 205f 5f66 696c 656e 616d 655f 636f     __filename_co
-000088e0: 6e74 656e 745f 6469 7370 6f73 6974 696f  ntent_dispositio
-000088f0: 6e5f 7061 7474 6572 6e20 3d20 7265 2e63  n_pattern = re.c
-00008900: 6f6d 7069 6c65 2827 6669 6c65 6e61 6d65  ompile('filename
-00008910: 3d22 282e 2b3f 2922 2729 0a0a 2020 2020  ="(.+?)"')..    
-00008920: 6465 6620 5f5f 696e 6974 5f5f 280a 2020  def __init__(.  
-00008930: 2020 2020 2020 7365 6c66 2c0a 2020 2020        self,.    
-00008940: 2020 2020 7265 7370 6f6e 7365 5f63 6c73      response_cls
-00008950: 3a20 7479 7069 6e67 2e54 7970 655b 4170  : typing.Type[Ap
-00008960: 6952 6573 706f 6e73 655d 203d 2041 7069  iResponse] = Api
-00008970: 5265 7370 6f6e 7365 2c0a 2020 2020 2020  Response,.      
-00008980: 2020 7265 7370 6f6e 7365 5f63 6c73 5f61    response_cls_a
-00008990: 7379 6e63 3a20 7479 7069 6e67 2e54 7970  sync: typing.Typ
-000089a0: 655b 4173 796e 6341 7069 5265 7370 6f6e  e[AsyncApiRespon
-000089b0: 7365 5d20 3d20 4173 796e 6341 7069 5265  se] = AsyncApiRe
-000089c0: 7370 6f6e 7365 2c0a 2020 2020 2020 2020  sponse,.        
-000089d0: 636f 6e74 656e 743a 2074 7970 696e 672e  content: typing.
-000089e0: 4f70 7469 6f6e 616c 5b74 7970 696e 672e  Optional[typing.
-000089f0: 4469 6374 5b73 7472 2c20 4d65 6469 6154  Dict[str, MediaT
-00008a00: 7970 655d 5d20 3d20 4e6f 6e65 2c0a 2020  ype]] = None,.  
-00008a10: 2020 2020 2020 6865 6164 6572 733a 2074        headers: t
-00008a20: 7970 696e 672e 4f70 7469 6f6e 616c 5b74  yping.Optional[t
-00008a30: 7970 696e 672e 4c69 7374 5b48 6561 6465  yping.List[Heade
-00008a40: 7250 6172 616d 6574 6572 5d5d 203d 204e  rParameter]] = N
-00008a50: 6f6e 652c 0a20 2020 2029 3a0a 2020 2020  one,.    ):.    
-00008a60: 2020 2020 7365 6c66 2e68 6561 6465 7273      self.headers
-00008a70: 203d 2068 6561 6465 7273 0a20 2020 2020   = headers.     
-00008a80: 2020 2069 6620 636f 6e74 656e 7420 6973     if content is
-00008a90: 206e 6f74 204e 6f6e 6520 616e 6420 6c65   not None and le
-00008aa0: 6e28 636f 6e74 656e 7429 203d 3d20 303a  n(content) == 0:
-00008ab0: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
-00008ac0: 7365 2056 616c 7565 4572 726f 7228 2749  se ValueError('I
-00008ad0: 6e76 616c 6964 2076 616c 7565 2066 6f72  nvalid value for
-00008ae0: 2063 6f6e 7465 6e74 2c20 7468 6520 636f   content, the co
-00008af0: 6e74 656e 7420 6469 6374 206d 7573 7420  ntent dict must 
-00008b00: 6861 7665 203e 3d20 3120 656e 7472 7927  have >= 1 entry'
-00008b10: 290a 2020 2020 2020 2020 7365 6c66 2e63  ).        self.c
-00008b20: 6f6e 7465 6e74 203d 2063 6f6e 7465 6e74  ontent = content
-00008b30: 0a20 2020 2020 2020 2073 656c 662e 7265  .        self.re
-00008b40: 7370 6f6e 7365 5f63 6c73 203d 2072 6573  sponse_cls = res
-00008b50: 706f 6e73 655f 636c 730a 2020 2020 2020  ponse_cls.      
-00008b60: 2020 7365 6c66 2e72 6573 706f 6e73 655f    self.response_
-00008b70: 636c 735f 6173 796e 6320 3d20 7265 7370  cls_async = resp
-00008b80: 6f6e 7365 5f63 6c73 5f61 7379 6e63 0a0a  onse_cls_async..
-00008b90: 2020 2020 4073 7461 7469 636d 6574 686f      @staticmetho
-00008ba0: 640a 2020 2020 6465 6620 5f5f 6465 7365  d.    def __dese
-00008bb0: 7269 616c 697a 655f 6a73 6f6e 2872 6573  rialize_json(res
-00008bc0: 706f 6e73 653a 2062 7974 6573 2920 2d3e  ponse: bytes) ->
-00008bd0: 2074 7970 696e 672e 416e 793a 0a20 2020   typing.Any:.   
-00008be0: 2020 2020 2023 2070 7974 686f 6e20 6d75       # python mu
-00008bf0: 7374 2062 6520 3e3d 2033 2e39 2073 6f20  st be >= 3.9 so 
-00008c00: 7765 2063 616e 2070 6173 7320 696e 2062  we can pass in b
-00008c10: 7974 6573 2069 6e74 6f20 6a73 6f6e 2e6c  ytes into json.l
-00008c20: 6f61 6473 0a20 2020 2020 2020 2072 6574  oads.        ret
-00008c30: 7572 6e20 6a73 6f6e 2e6c 6f61 6473 2872  urn json.loads(r
-00008c40: 6573 706f 6e73 6529 0a0a 2020 2020 4073  esponse)..    @s
-00008c50: 7461 7469 636d 6574 686f 640a 2020 2020  taticmethod.    
-00008c60: 6465 6620 5f5f 6669 6c65 5f6e 616d 655f  def __file_name_
-00008c70: 6672 6f6d 5f72 6573 706f 6e73 655f 7572  from_response_ur
-00008c80: 6c28 7265 7370 6f6e 7365 5f75 726c 3a20  l(response_url: 
-00008c90: 7479 7069 6e67 2e4f 7074 696f 6e61 6c5b  typing.Optional[
-00008ca0: 7374 725d 2920 2d3e 2074 7970 696e 672e  str]) -> typing.
-00008cb0: 4f70 7469 6f6e 616c 5b73 7472 5d3a 0a20  Optional[str]:. 
-00008cc0: 2020 2020 2020 2069 6620 7265 7370 6f6e         if respon
-00008cd0: 7365 5f75 726c 2069 7320 4e6f 6e65 3a0a  se_url is None:.
-00008ce0: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00008cf0: 726e 204e 6f6e 650a 2020 2020 2020 2020  rn None.        
-00008d00: 7572 6c5f 7061 7468 203d 2075 726c 7061  url_path = urlpa
-00008d10: 7273 6528 7265 7370 6f6e 7365 5f75 726c  rse(response_url
-00008d20: 292e 7061 7468 0a20 2020 2020 2020 2069  ).path.        i
-00008d30: 6620 7572 6c5f 7061 7468 3a0a 2020 2020  f url_path:.    
-00008d40: 2020 2020 2020 2020 7061 7468 5f62 6173          path_bas
-00008d50: 656e 616d 6520 3d20 6f73 2e70 6174 682e  ename = os.path.
-00008d60: 6261 7365 6e61 6d65 2875 726c 5f70 6174  basename(url_pat
-00008d70: 6829 0a20 2020 2020 2020 2020 2020 2069  h).            i
-00008d80: 6620 7061 7468 5f62 6173 656e 616d 653a  f path_basename:
-00008d90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00008da0: 205f 6669 6c65 6e61 6d65 2c20 6578 7420   _filename, ext 
-00008db0: 3d20 6f73 2e70 6174 682e 7370 6c69 7465  = os.path.splite
-00008dc0: 7874 2870 6174 685f 6261 7365 6e61 6d65  xt(path_basename
-00008dd0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00008de0: 2020 6966 2065 7874 3a0a 2020 2020 2020    if ext:.      
-00008df0: 2020 2020 2020 2020 2020 2020 2020 7265                re
-00008e00: 7475 726e 2070 6174 685f 6261 7365 6e61  turn path_basena
-00008e10: 6d65 0a20 2020 2020 2020 2072 6574 7572  me.        retur
-00008e20: 6e20 4e6f 6e65 0a0a 2020 2020 4063 6c61  n None..    @cla
-00008e30: 7373 6d65 7468 6f64 0a20 2020 2064 6566  ssmethod.    def
-00008e40: 205f 5f66 696c 655f 6e61 6d65 5f66 726f   __file_name_fro
-00008e50: 6d5f 636f 6e74 656e 745f 6469 7370 6f73  m_content_dispos
-00008e60: 6974 696f 6e28 636c 732c 2063 6f6e 7465  ition(cls, conte
-00008e70: 6e74 5f64 6973 706f 7369 7469 6f6e 3a20  nt_disposition: 
-00008e80: 7479 7069 6e67 2e4f 7074 696f 6e61 6c5b  typing.Optional[
-00008e90: 7374 725d 2920 2d3e 2074 7970 696e 672e  str]) -> typing.
-00008ea0: 4f70 7469 6f6e 616c 5b73 7472 5d3a 0a20  Optional[str]:. 
-00008eb0: 2020 2020 2020 2069 6620 636f 6e74 656e         if conten
-00008ec0: 745f 6469 7370 6f73 6974 696f 6e20 6973  t_disposition is
-00008ed0: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
-00008ee0: 2020 2072 6574 7572 6e20 4e6f 6e65 0a20     return None. 
-00008ef0: 2020 2020 2020 206d 6174 6368 203d 2063         match = c
-00008f00: 6c73 2e5f 5f66 696c 656e 616d 655f 636f  ls.__filename_co
-00008f10: 6e74 656e 745f 6469 7370 6f73 6974 696f  ntent_dispositio
-00008f20: 6e5f 7061 7474 6572 6e2e 7365 6172 6368  n_pattern.search
-00008f30: 2863 6f6e 7465 6e74 5f64 6973 706f 7369  (content_disposi
-00008f40: 7469 6f6e 290a 2020 2020 2020 2020 6966  tion).        if
-00008f50: 206e 6f74 206d 6174 6368 3a0a 2020 2020   not match:.    
-00008f60: 2020 2020 2020 2020 7265 7475 726e 204e          return N
-00008f70: 6f6e 650a 2020 2020 2020 2020 7265 7475  one.        retu
-00008f80: 726e 206d 6174 6368 2e67 726f 7570 2831  rn match.group(1
-00008f90: 290a 0a20 2020 2064 6566 205f 5f64 6573  )..    def __des
-00008fa0: 6572 6961 6c69 7a65 5f61 7070 6c69 6361  erialize_applica
-00008fb0: 7469 6f6e 5f6f 6374 6574 5f73 7472 6561  tion_octet_strea
-00008fc0: 6d28 0a20 2020 2020 2020 2073 656c 662c  m(.        self,
-00008fd0: 2072 6573 706f 6e73 653a 2075 726c 6c69   response: urlli
-00008fe0: 6233 2e48 5454 5052 6573 706f 6e73 650a  b3.HTTPResponse.
-00008ff0: 2020 2020 2920 2d3e 2074 7970 696e 672e      ) -> typing.
-00009000: 556e 696f 6e5b 6279 7465 732c 2069 6f2e  Union[bytes, io.
-00009010: 4275 6666 6572 6564 5265 6164 6572 5d3a  BufferedReader]:
-00009020: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
-00009030: 2020 2020 2075 726c 6c69 6233 2075 7365       urllib3 use
-00009040: 2063 6173 6573 3a0a 2020 2020 2020 2020   cases:.        
-00009050: 312e 2077 6865 6e20 7072 656c 6f61 645f  1. when preload_
-00009060: 636f 6e74 656e 743d 5472 7565 2028 7374  content=True (st
-00009070: 7265 616d 3d46 616c 7365 2920 7468 656e  ream=False) then
-00009080: 2073 7570 706f 7274 735f 6368 756e 6b65   supports_chunke
-00009090: 645f 7265 6164 7320 6973 2046 616c 7365  d_reads is False
-000090a0: 2061 6e64 2062 7974 6573 2061 7265 2072   and bytes are r
-000090b0: 6574 7572 6e65 640a 2020 2020 2020 2020  eturned.        
-000090c0: 322e 2077 6865 6e20 7072 656c 6f61 645f  2. when preload_
-000090d0: 636f 6e74 656e 743d 4661 6c73 6520 2873  content=False (s
-000090e0: 7472 6561 6d3d 5472 7565 2920 7468 656e  tream=True) then
-000090f0: 2073 7570 706f 7274 735f 6368 756e 6b65   supports_chunke
-00009100: 645f 7265 6164 7320 6973 2054 7275 6520  d_reads is True 
-00009110: 616e 640a 2020 2020 2020 2020 2020 2020  and.            
-00009120: 6120 6669 6c65 2077 696c 6c20 6265 2077  a file will be w
-00009130: 7269 7474 656e 2061 6e64 2072 6574 7572  ritten and retur
-00009140: 6e65 640a 2020 2020 2020 2020 2222 220a  ned.        """.
-00009150: 2020 2020 2020 2020 6966 2072 6573 706f          if respo
-00009160: 6e73 652e 7375 7070 6f72 7473 5f63 6875  nse.supports_chu
-00009170: 6e6b 6564 5f72 6561 6473 2829 3a0a 2020  nked_reads():.  
-00009180: 2020 2020 2020 2020 2020 6669 6c65 5f6e            file_n
-00009190: 616d 6520 3d20 280a 2020 2020 2020 2020  ame = (.        
-000091a0: 2020 2020 2020 2020 7365 6c66 2e5f 5f66          self.__f
-000091b0: 696c 655f 6e61 6d65 5f66 726f 6d5f 636f  ile_name_from_co
-000091c0: 6e74 656e 745f 6469 7370 6f73 6974 696f  ntent_dispositio
-000091d0: 6e28 7265 7370 6f6e 7365 2e68 6561 6465  n(response.heade
-000091e0: 7273 2e67 6574 2827 636f 6e74 656e 742d  rs.get('content-
-000091f0: 6469 7370 6f73 6974 696f 6e27 2929 0a20  disposition')). 
-00009200: 2020 2020 2020 2020 2020 2020 2020 206f                 o
-00009210: 7220 7365 6c66 2e5f 5f66 696c 655f 6e61  r self.__file_na
-00009220: 6d65 5f66 726f 6d5f 7265 7370 6f6e 7365  me_from_response
-00009230: 5f75 726c 2872 6573 706f 6e73 652e 6765  _url(response.ge
-00009240: 7475 726c 2829 290a 2020 2020 2020 2020  turl()).        
-00009250: 2020 2020 290a 0a20 2020 2020 2020 2020      )..         
-00009260: 2020 2069 6620 6669 6c65 5f6e 616d 6520     if file_name 
-00009270: 6973 204e 6f6e 653a 0a20 2020 2020 2020  is None:.       
-00009280: 2020 2020 2020 2020 205f 6664 2c20 7061           _fd, pa
-00009290: 7468 203d 2074 656d 7066 696c 652e 6d6b  th = tempfile.mk
-000092a0: 7374 656d 7028 290a 2020 2020 2020 2020  stemp().        
-000092b0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-000092c0: 2020 2020 2020 2020 2020 7061 7468 203d            path =
-000092d0: 206f 732e 7061 7468 2e6a 6f69 6e28 7465   os.path.join(te
-000092e0: 6d70 6669 6c65 2e67 6574 7465 6d70 6469  mpfile.gettempdi
-000092f0: 7228 292c 2066 696c 655f 6e61 6d65 290a  r(), file_name).
-00009300: 0a20 2020 2020 2020 2020 2020 2077 6974  .            wit
-00009310: 6820 6f70 656e 2870 6174 682c 2027 7762  h open(path, 'wb
-00009320: 2729 2061 7320 6e65 775f 6669 6c65 3a0a  ') as new_file:.
-00009330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009340: 6368 756e 6b5f 7369 7a65 203d 2031 3032  chunk_size = 102
-00009350: 340a 2020 2020 2020 2020 2020 2020 2020  4.              
-00009360: 2020 7768 696c 6520 5472 7565 3a0a 2020    while True:.  
-00009370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009380: 2020 6461 7461 203d 2072 6573 706f 6e73    data = respons
-00009390: 652e 7265 6164 2863 6875 6e6b 5f73 697a  e.read(chunk_siz
-000093a0: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
-000093b0: 2020 2020 2020 2069 6620 6e6f 7420 6461         if not da
-000093c0: 7461 3a0a 2020 2020 2020 2020 2020 2020  ta:.            
-000093d0: 2020 2020 2020 2020 2020 2020 6272 6561              brea
-000093e0: 6b0a 2020 2020 2020 2020 2020 2020 2020  k.              
-000093f0: 2020 2020 2020 6e65 775f 6669 6c65 2e77        new_file.w
-00009400: 7269 7465 2864 6174 6129 0a20 2020 2020  rite(data).     
-00009410: 2020 2020 2020 2023 2072 656c 6561 7365         # release
-00009420: 5f63 6f6e 6e20 6973 206e 6565 6465 6420  _conn is needed 
-00009430: 666f 7220 7374 7265 616d 696e 6720 636f  for streaming co
-00009440: 6e6e 6563 7469 6f6e 7320 6f6e 6c79 0a20  nnections only. 
-00009450: 2020 2020 2020 2020 2020 2072 6573 706f             respo
-00009460: 6e73 652e 7265 6c65 6173 655f 636f 6e6e  nse.release_conn
-00009470: 2829 0a20 2020 2020 2020 2020 2020 206e  ().            n
-00009480: 6577 5f66 696c 6520 3d20 6f70 656e 2870  ew_file = open(p
-00009490: 6174 682c 2027 7262 2729 0a20 2020 2020  ath, 'rb').     
-000094a0: 2020 2020 2020 2072 6574 7572 6e20 6e65         return ne
-000094b0: 775f 6669 6c65 0a20 2020 2020 2020 2065  w_file.        e
-000094c0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-000094d0: 2072 6574 7572 6e20 7265 7370 6f6e 7365   return response
-000094e0: 2e64 6174 610a 0a20 2020 2040 7374 6174  .data..    @stat
-000094f0: 6963 6d65 7468 6f64 0a20 2020 2064 6566  icmethod.    def
-00009500: 205f 5f64 6573 6572 6961 6c69 7a65 5f6d   __deserialize_m
-00009510: 756c 7469 7061 7274 5f66 6f72 6d5f 6461  ultipart_form_da
-00009520: 7461 280a 2020 2020 2020 2020 7265 7370  ta(.        resp
-00009530: 6f6e 7365 3a20 6279 7465 730a 2020 2020  onse: bytes.    
-00009540: 2920 2d3e 2074 7970 696e 672e 4469 6374  ) -> typing.Dict
-00009550: 5b73 7472 2c20 7479 7069 6e67 2e41 6e79  [str, typing.Any
-00009560: 5d3a 0a20 2020 2020 2020 206d 7367 203d  ]:.        msg =
-00009570: 2065 6d61 696c 2e6d 6573 7361 6765 5f66   email.message_f
-00009580: 726f 6d5f 6279 7465 7328 7265 7370 6f6e  rom_bytes(respon
-00009590: 7365 290a 2020 2020 2020 2020 7265 7475  se).        retu
-000095a0: 726e 207b 0a20 2020 2020 2020 2020 2020  rn {.           
-000095b0: 2070 6172 742e 6765 745f 7061 7261 6d28   part.get_param(
-000095c0: 226e 616d 6522 2c20 6865 6164 6572 3d22  "name", header="
-000095d0: 436f 6e74 656e 742d 4469 7370 6f73 6974  Content-Disposit
-000095e0: 696f 6e22 293a 2070 6172 742e 6765 745f  ion"): part.get_
-000095f0: 7061 796c 6f61 6428 0a20 2020 2020 2020  payload(.       
-00009600: 2020 2020 2020 2020 2064 6563 6f64 653d           decode=
-00009610: 5472 7565 0a20 2020 2020 2020 2020 2020  True.           
-00009620: 2029 2e64 6563 6f64 6528 7061 7274 2e67   ).decode(part.g
-00009630: 6574 5f63 6f6e 7465 6e74 5f63 6861 7273  et_content_chars
-00009640: 6574 2829 290a 2020 2020 2020 2020 2020  et()).          
-00009650: 2020 6966 2070 6172 742e 6765 745f 636f    if part.get_co
-00009660: 6e74 656e 745f 6368 6172 7365 7428 290a  ntent_charset().
-00009670: 2020 2020 2020 2020 2020 2020 656c 7365              else
-00009680: 2070 6172 742e 6765 745f 7061 796c 6f61   part.get_payloa
-00009690: 6428 290a 2020 2020 2020 2020 2020 2020  d().            
-000096a0: 666f 7220 7061 7274 2069 6e20 6d73 672e  for part in msg.
-000096b0: 6765 745f 7061 796c 6f61 6428 290a 2020  get_payload().  
-000096c0: 2020 2020 2020 7d0a 0a20 2020 2064 6566        }..    def
-000096d0: 205f 5f67 6574 5f73 6368 656d 615f 666f   __get_schema_fo
-000096e0: 725f 636f 6e74 656e 745f 7479 7065 280a  r_content_type(.
-000096f0: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
-00009700: 2020 2020 2020 636f 6e74 656e 745f 7479        content_ty
-00009710: 7065 0a20 2020 2029 202d 3e20 7479 7069  pe.    ) -> typi
-00009720: 6e67 2e4f 7074 696f 6e61 6c5b 7479 7069  ng.Optional[typi
-00009730: 6e67 2e54 7970 655b 5363 6865 6d61 5d5d  ng.Type[Schema]]
-00009740: 3a0a 2020 2020 2020 2020 2222 220a 2020  :.        """.  
-00009750: 2020 2020 2020 4669 6e64 7320 7468 6520        Finds the 
-00009760: 636f 7272 6563 7420 5363 6865 6d61 4f62  correct SchemaOb
-00009770: 6a65 6374 2066 6f72 2061 2070 6172 7469  ject for a parti
-00009780: 6375 6c61 7220 636f 6e74 656e 7420 7479  cular content ty
-00009790: 7065 2e20 4861 6e64 6c65 730a 2020 2020  pe. Handles.    
-000097a0: 2020 2020 7468 6520 6173 7465 7269 736b      the asterisk
-000097b0: 2022 2a22 2063 6861 7261 6374 6572 2074   "*" character t
-000097c0: 6861 7420 6973 2075 7365 6420 746f 2067  hat is used to g
-000097d0: 726f 7570 206d 6564 6961 2074 7970 6573  roup media types
-000097e0: 2069 6e74 6f20 7261 6e67 6573 0a20 2020   into ranges.   
-000097f0: 2020 2020 2028 6874 7470 733a 2f2f 7777       (https://ww
-00009800: 772e 7266 632d 6564 6974 6f72 2e6f 7267  w.rfc-editor.org
-00009810: 2f72 6663 2f72 6663 3732 3331 2373 6563  /rfc/rfc7231#sec
-00009820: 7469 6f6e 2d35 2e33 2e32 292e 2041 6c73  tion-5.3.2). Als
-00009830: 6f20 6861 6e64 6c65 730a 2020 2020 2020  o handles.      
-00009840: 2020 7061 7261 6d65 7465 7273 2069 6e20    parameters in 
-00009850: 7468 6520 666f 726d 206f 6620 6e61 6d65  the form of name
-00009860: 3d76 616c 7565 2070 6169 7273 2e0a 2020  =value pairs..  
-00009870: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
-00009880: 2020 6d65 6469 615f 7479 7065 7320 3d20    media_types = 
-00009890: 7365 6c66 2e63 6f6e 7465 6e74 2e6b 6579  self.content.key
-000098a0: 7328 290a 2020 2020 2020 2020 6d61 7463  s().        matc
-000098b0: 6865 645f 6d65 6469 615f 7479 7065 203d  hed_media_type =
-000098c0: 204f 7065 6e41 7069 5265 7370 6f6e 7365   OpenApiResponse
-000098d0: 2e6d 6174 6368 5f63 6f6e 7465 6e74 5f74  .match_content_t
-000098e0: 7970 6528 0a20 2020 2020 2020 2020 2020  ype(.           
-000098f0: 2063 6f6e 7465 6e74 5f74 7970 653d 636f   content_type=co
-00009900: 6e74 656e 745f 7479 7065 2c0a 2020 2020  ntent_type,.    
-00009910: 2020 2020 2020 2020 6d65 6469 615f 7479          media_ty
-00009920: 7065 733d 6d65 6469 615f 7479 7065 730a  pes=media_types.
-00009930: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
-00009940: 2020 6966 206d 6174 6368 6564 5f6d 6564    if matched_med
-00009950: 6961 5f74 7970 6520 6973 204e 6f6e 653a  ia_type is None:
-00009960: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-00009970: 7572 6e20 4e6f 6e65 0a20 2020 2020 2020  urn None.       
-00009980: 2072 6574 7572 6e20 7365 6c66 2e63 6f6e   return self.con
-00009990: 7465 6e74 5b6d 6174 6368 6564 5f6d 6564  tent[matched_med
-000099a0: 6961 5f74 7970 655d 2e73 6368 656d 610a  ia_type].schema.
-000099b0: 0a20 2020 2040 7374 6174 6963 6d65 7468  .    @staticmeth
-000099c0: 6f64 0a20 2020 2064 6566 206d 6174 6368  od.    def match
-000099d0: 5f63 6f6e 7465 6e74 5f74 7970 6528 636f  _content_type(co
-000099e0: 6e74 656e 745f 7479 7065 3a20 7374 722c  ntent_type: str,
-000099f0: 206d 6564 6961 5f74 7970 6573 3a20 7479   media_types: ty
-00009a00: 7069 6e67 2e4c 6973 745b 7374 725d 2920  ping.List[str]) 
-00009a10: 2d3e 2074 7970 696e 672e 4f70 7469 6f6e  -> typing.Option
-00009a20: 616c 5b73 7472 5d3a 0a20 2020 2020 2020  al[str]:.       
-00009a30: 2022 2222 0a20 2020 2020 2020 204d 6174   """.        Mat
-00009a40: 6368 6573 2061 2063 6f6e 7465 6e74 2074  ches a content t
-00009a50: 7970 6520 746f 2061 206d 6564 6961 2074  ype to a media t
-00009a60: 7970 6520 696e 2061 206c 6973 7420 6f66  ype in a list of
-00009a70: 206d 6564 6961 2074 7970 6573 2c20 6861   media types, ha
-00009a80: 6e64 6c69 6e67 206d 6564 6961 2074 7970  ndling media typ
-00009a90: 6520 7261 6e67 6573 2061 7320 6465 6669  e ranges as defi
-00009aa0: 6e65 6420 696e 2052 4643 3732 3331 2e0a  ned in RFC7231..
-00009ab0: 0a20 2020 2020 2020 2050 6172 616d 6574  .        Paramet
-00009ac0: 6572 733a 0a20 2020 2020 2020 2063 6f6e  ers:.        con
-00009ad0: 7465 6e74 5f74 7970 6520 2873 7472 293a  tent_type (str):
-00009ae0: 2054 6865 2063 6f6e 7465 6e74 2074 7970   The content typ
-00009af0: 6520 746f 206d 6174 6368 2e0a 2020 2020  e to match..    
-00009b00: 2020 2020 6d65 6469 615f 7479 7065 7320      media_types 
-00009b10: 286c 6973 7429 3a20 5468 6520 6c69 7374  (list): The list
-00009b20: 206f 6620 6d65 6469 6120 7479 7065 7320   of media types 
-00009b30: 746f 2073 6561 7263 682e 0a0a 2020 2020  to search...    
-00009b40: 2020 2020 5265 7475 726e 733a 0a20 2020      Returns:.   
-00009b50: 2020 2020 2073 7472 3a20 5468 6520 6669       str: The fi
-00009b60: 7273 7420 6d65 6469 6120 7479 7065 2074  rst media type t
-00009b70: 6861 7420 6d61 7463 6865 7320 7468 6520  hat matches the 
-00009b80: 636f 6e74 656e 7420 7479 7065 2c20 6f72  content type, or
-00009b90: 204e 6f6e 6520 6966 206e 6f20 6d61 7463   None if no matc
-00009ba0: 6820 6973 2066 6f75 6e64 2e0a 2020 2020  h is found..    
-00009bb0: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
-00009bc0: 666f 7220 6d65 6469 615f 7479 7065 2069  for media_type i
-00009bd0: 6e20 6d65 6469 615f 7479 7065 733a 0a20  n media_types:. 
-00009be0: 2020 2020 2020 2020 2020 2069 6620 6d65             if me
-00009bf0: 6469 615f 7479 7065 203d 3d20 272a 2f2a  dia_type == '*/*
-00009c00: 2720 6f72 206d 6564 6961 5f74 7970 6520  ' or media_type 
-00009c10: 3d3d 2063 6f6e 7465 6e74 5f74 7970 653a  == content_type:
-00009c20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00009c30: 2072 6574 7572 6e20 6d65 6469 615f 7479   return media_ty
-00009c40: 7065 0a20 2020 2020 2020 2020 2020 2065  pe.            e
-00009c50: 6c69 6620 272f 2720 696e 206d 6564 6961  lif '/' in media
-00009c60: 5f74 7970 653a 0a20 2020 2020 2020 2020  _type:.         
-00009c70: 2020 2020 2020 2074 7970 655f 2c20 7375         type_, su
-00009c80: 6274 7970 6520 3d20 6d65 6469 615f 7479  btype = media_ty
-00009c90: 7065 2e73 706c 6974 2827 2f27 290a 2020  pe.split('/').  
-00009ca0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00009cb0: 2028 7479 7065 5f20 3d3d 2027 2a27 206f   (type_ == '*' o
-00009cc0: 7220 7479 7065 5f20 3d3d 2063 6f6e 7465  r type_ == conte
-00009cd0: 6e74 5f74 7970 652e 7370 6c69 7428 272f  nt_type.split('/
-00009ce0: 2729 5b30 5d29 2061 6e64 205c 0a20 2020  ')[0]) and \.   
-00009cf0: 2020 2020 2020 2020 2020 2020 2028 7375               (su
-00009d00: 6274 7970 6520 3d3d 2027 2a27 206f 7220  btype == '*' or 
-00009d10: 7375 6274 7970 6520 3d3d 2063 6f6e 7465  subtype == conte
-00009d20: 6e74 5f74 7970 652e 7370 6c69 7428 272f  nt_type.split('/
-00009d30: 2729 5b31 5d2e 7370 6c69 7428 273b 2729  ')[1].split(';')
-00009d40: 5b30 5d29 3a0a 2020 2020 2020 2020 2020  [0]):.          
-00009d50: 2020 2020 2020 2020 2020 7265 7475 726e            return
-00009d60: 206d 6564 6961 5f74 7970 650a 0a20 2020   media_type..   
-00009d70: 2020 2020 2072 6574 7572 6e20 4e6f 6e65       return None
-00009d80: 0a0a 2020 2020 6173 796e 6320 6465 6620  ..    async def 
-00009d90: 6465 7365 7269 616c 697a 655f 6173 796e  deserialize_asyn
-00009da0: 6328 7365 6c66 2c20 7265 7370 6f6e 7365  c(self, response
-00009db0: 3a20 4173 796e 6352 6573 706f 6e73 6557  : AsyncResponseW
-00009dc0: 7261 7070 6572 2c20 636f 6e66 6967 7572  rapper, configur
-00009dd0: 6174 696f 6e3a 2043 6f6e 6669 6775 7261  ation: Configura
-00009de0: 7469 6f6e 2c20 736b 6970 5f64 6573 6572  tion, skip_deser
-00009df0: 6961 6c69 7a61 7469 6f6e 203d 2046 616c  ialization = Fal
-00009e00: 7365 2920 2d3e 2041 7379 6e63 4170 6952  se) -> AsyncApiR
-00009e10: 6573 706f 6e73 653a 0a20 2020 2020 2020  esponse:.       
-00009e20: 2022 2222 0a20 2020 2020 2020 2044 6573   """.        Des
-00009e30: 6572 6961 6c69 7a65 7320 616e 2048 5454  erializes an HTT
-00009e40: 5020 7265 7370 6f6e 7365 2062 6f64 7920  P response body 
-00009e50: 696e 746f 2061 6e20 6f62 6a65 6374 2e0a  into an object..
-00009e60: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-00009e70: 2020 2020 636f 6e74 656e 745f 7479 7065      content_type
-00009e80: 203d 2072 6573 706f 6e73 652e 6874 7470   = response.http
-00009e90: 5f72 6573 706f 6e73 652e 636f 6e74 656e  _response.conten
-00009ea0: 745f 7479 7065 0a20 2020 2020 2020 2064  t_type.        d
-00009eb0: 6573 6572 6961 6c69 7a65 645f 626f 6479  eserialized_body
-00009ec0: 203d 2075 6e73 6574 0a20 2020 2020 2020   = unset.       
-00009ed0: 2069 6620 7365 6c66 2e63 6f6e 7465 6e74   if self.content
-00009ee0: 2069 7320 6e6f 7420 4e6f 6e65 3a0a 2020   is not None:.  
-00009ef0: 2020 2020 2020 2020 2020 6966 206c 656e            if len
-00009f00: 2873 656c 662e 636f 6e74 656e 7429 203d  (self.content) =
-00009f10: 3d20 303a 0a20 2020 2020 2020 2020 2020  = 0:.           
-00009f20: 2020 2020 2023 2073 6f6d 6520 7370 6563       # some spec
-00009f30: 7320 646f 206e 6f74 2064 6566 696e 6520  s do not define 
-00009f40: 7265 7370 6f6e 7365 2063 6f6e 7465 6e74  response content
-00009f50: 206d 6564 6961 2074 7970 6520 7363 6865   media type sche
-00009f60: 6d61 730a 2020 2020 2020 2020 2020 2020  mas.            
-00009f70: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
-00009f80: 7265 7370 6f6e 7365 5f63 6c73 5f61 7379  response_cls_asy
-00009f90: 6e63 280a 2020 2020 2020 2020 2020 2020  nc(.            
-00009fa0: 2020 2020 2020 2020 726f 756e 645f 7472          round_tr
-00009fb0: 6970 5f74 696d 653d 7265 7370 6f6e 7365  ip_time=response
-00009fc0: 2e72 6f75 6e64 5f74 7269 705f 7469 6d65  .round_trip_time
-00009fd0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00009fe0: 2020 2020 2020 7265 7370 6f6e 7365 3d72        response=r
-00009ff0: 6573 706f 6e73 652e 6874 7470 5f72 6573  esponse.http_res
-0000a000: 706f 6e73 652c 0a20 2020 2020 2020 2020  ponse,.         
-0000a010: 2020 2020 2020 2020 2020 2062 6f64 793d             body=
-0000a020: 756e 7365 742c 0a20 2020 2020 2020 2020  unset,.         
-0000a030: 2020 2020 2020 2020 2020 2068 6561 6465             heade
-0000a040: 7273 3d72 6573 706f 6e73 652e 6874 7470  rs=response.http
-0000a050: 5f72 6573 706f 6e73 652e 6865 6164 6572  _response.header
-0000a060: 732c 0a20 2020 2020 2020 2020 2020 2020  s,.             
-0000a070: 2020 2020 2020 2073 7461 7475 733d 7265         status=re
-0000a080: 7370 6f6e 7365 2e68 7474 705f 7265 7370  sponse.http_resp
-0000a090: 6f6e 7365 2e73 7461 7475 730a 2020 2020  onse.status.    
-0000a0a0: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
-0000a0b0: 2020 2020 2020 2020 2020 626f 6479 5f73            body_s
-0000a0c0: 6368 656d 6120 3d20 7365 6c66 2e5f 5f67  chema = self.__g
-0000a0d0: 6574 5f73 6368 656d 615f 666f 725f 636f  et_schema_for_co
-0000a0e0: 6e74 656e 745f 7479 7065 2863 6f6e 7465  ntent_type(conte
-0000a0f0: 6e74 5f74 7970 6529 0a20 2020 2020 2020  nt_type).       
-0000a100: 2020 2020 2069 6620 626f 6479 5f73 6368       if body_sch
-0000a110: 656d 6120 6973 204e 6f6e 653a 0a20 2020  ema is None:.   
-0000a120: 2020 2020 2020 2020 2020 2020 2072 6169               rai
-0000a130: 7365 2041 7069 5661 6c75 6545 7272 6f72  se ApiValueError
-0000a140: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-0000a150: 2020 2020 2020 6622 496e 7661 6c69 6420        f"Invalid 
-0000a160: 636f 6e74 656e 745f 7479 7065 2072 6574  content_type ret
-0000a170: 7572 6e65 642e 2043 6f6e 7465 6e74 5f74  urned. Content_t
-0000a180: 7970 653d 277b 636f 6e74 656e 745f 7479  ype='{content_ty
-0000a190: 7065 7d27 2077 6173 2072 6574 7572 6e65  pe}' was returne
-0000a1a0: 6420 220a 2020 2020 2020 2020 2020 2020  d ".            
-0000a1b0: 2020 2020 2020 2020 6622 7768 656e 206f          f"when o
-0000a1c0: 6e6c 7920 7b73 7472 2873 6574 2873 656c  nly {str(set(sel
-0000a1d0: 662e 636f 6e74 656e 7429 297d 2061 7265  f.content))} are
-0000a1e0: 2064 6566 696e 6564 2066 6f72 2073 7461   defined for sta
-0000a1f0: 7475 735f 636f 6465 3d7b 7374 7228 7265  tus_code={str(re
-0000a200: 7370 6f6e 7365 2e68 7474 705f 7265 7370  sponse.http_resp
-0000a210: 6f6e 7365 2e73 7461 7475 7329 7d22 0a20  onse.status)}". 
-0000a220: 2020 2020 2020 2020 2020 2020 2020 2029                 )
-0000a230: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-0000a240: 7365 6c66 2e5f 636f 6e74 656e 745f 7479  self._content_ty
-0000a250: 7065 5f69 735f 6a73 6f6e 2863 6f6e 7465  pe_is_json(conte
-0000a260: 6e74 5f74 7970 6529 3a0a 2020 2020 2020  nt_type):.      
-0000a270: 2020 2020 2020 2020 2020 626f 6479 5f64            body_d
-0000a280: 6174 6120 3d20 7365 6c66 2e5f 5f64 6573  ata = self.__des
-0000a290: 6572 6961 6c69 7a65 5f6a 736f 6e28 6177  erialize_json(aw
-0000a2a0: 6169 7420 7265 7370 6f6e 7365 2e68 7474  ait response.htt
-0000a2b0: 705f 7265 7370 6f6e 7365 2e72 6561 6428  p_response.read(
-0000a2c0: 2929 0a20 2020 2020 2020 2020 2020 2065  )).            e
-0000a2d0: 6c69 6620 636f 6e74 656e 745f 7479 7065  lif content_type
-0000a2e0: 2e73 7461 7274 7377 6974 6828 276d 756c  .startswith('mul
-0000a2f0: 7469 7061 7274 2f66 6f72 6d2d 6461 7461  tipart/form-data
-0000a300: 2729 3a0a 2020 2020 2020 2020 2020 2020  '):.            
-0000a310: 2020 2020 626f 6479 5f64 6174 6120 3d20      body_data = 
-0000a320: 7365 6c66 2e5f 5f64 6573 6572 6961 6c69  self.__deseriali
-0000a330: 7a65 5f6d 756c 7469 7061 7274 5f66 6f72  ze_multipart_for
-0000a340: 6d5f 6461 7461 2861 7761 6974 2072 6573  m_data(await res
-0000a350: 706f 6e73 652e 6874 7470 5f72 6573 706f  ponse.http_respo
-0000a360: 6e73 652e 7265 6164 2829 290a 2020 2020  nse.read()).    
-0000a370: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-0000a380: 2020 2020 2020 2020 2020 2020 2020 7261                ra
-0000a390: 6973 6520 4e6f 7449 6d70 6c65 6d65 6e74  ise NotImplement
-0000a3a0: 6564 4572 726f 7228 2744 6573 6572 6961  edError('Deseria
-0000a3b0: 6c69 7a61 7469 6f6e 206f 6620 7b7d 2068  lization of {} h
-0000a3c0: 6173 206e 6f74 2079 6574 2062 6565 6e20  as not yet been 
-0000a3d0: 696d 706c 656d 656e 7465 6427 2e66 6f72  implemented'.for
-0000a3e0: 6d61 7428 636f 6e74 656e 745f 7479 7065  mat(content_type
-0000a3f0: 2929 0a20 2020 2020 2020 2020 2020 2069  )).            i
-0000a400: 6620 736b 6970 5f64 6573 6572 6961 6c69  f skip_deseriali
-0000a410: 7a61 7469 6f6e 3a0a 2020 2020 2020 2020  zation:.        
-0000a420: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-0000a430: 656c 662e 7265 7370 6f6e 7365 5f63 6c73  elf.response_cls
-0000a440: 5f61 7379 6e63 280a 2020 2020 2020 2020  _async(.        
-0000a450: 2020 2020 2020 2020 2020 2020 726f 756e              roun
-0000a460: 645f 7472 6970 5f74 696d 653d 7265 7370  d_trip_time=resp
-0000a470: 6f6e 7365 2e72 6f75 6e64 5f74 7269 705f  onse.round_trip_
-0000a480: 7469 6d65 2c0a 2020 2020 2020 2020 2020  time,.          
-0000a490: 2020 2020 2020 2020 2020 7265 7370 6f6e            respon
-0000a4a0: 7365 3d72 6573 706f 6e73 652e 6874 7470  se=response.http
-0000a4b0: 5f72 6573 706f 6e73 652c 0a20 2020 2020  _response,.     
-0000a4c0: 2020 2020 2020 2020 2020 2020 2020 2062                 b
-0000a4d0: 6f64 793d 626f 6479 5f64 6174 612c 0a20  ody=body_data,. 
-0000a4e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a4f0: 2020 2068 6561 6465 7273 3d72 6573 706f     headers=respo
-0000a500: 6e73 652e 6874 7470 5f72 6573 706f 6e73  nse.http_respons
-0000a510: 652e 6865 6164 6572 732c 0a20 2020 2020  e.headers,.     
-0000a520: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-0000a530: 7461 7475 733d 7265 7370 6f6e 7365 2e68  tatus=response.h
-0000a540: 7474 705f 7265 7370 6f6e 7365 2e73 7461  ttp_response.sta
-0000a550: 7475 730a 2020 2020 2020 2020 2020 2020  tus.            
-0000a560: 2020 2020 290a 2020 2020 2020 2020 2020      ).          
-0000a570: 2020 2320 4578 6563 7574 6520 7661 6c69    # Execute vali
-0000a580: 6461 7469 6f6e 2061 6e64 2074 6872 6f77  dation and throw
-0000a590: 2061 7320 6120 7369 6465 2065 6666 6563   as a side effec
-0000a5a0: 7420 6966 2076 616c 6964 6174 696f 6e20  t if validation 
-0000a5b0: 6661 696c 730a 2020 2020 2020 2020 2020  fails.          
-0000a5c0: 2020 626f 6479 5f73 6368 656d 612e 6672    body_schema.fr
-0000a5d0: 6f6d 5f6f 7065 6e61 7069 5f64 6174 615f  om_openapi_data_
-0000a5e0: 6f61 7067 280a 2020 2020 2020 2020 2020  oapg(.          
-0000a5f0: 2020 2020 2020 626f 6479 5f64 6174 612c        body_data,
-0000a600: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000a610: 205f 636f 6e66 6967 7572 6174 696f 6e3d   _configuration=
-0000a620: 636f 6e66 6967 7572 6174 696f 6e0a 2020  configuration.  
-0000a630: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
-0000a640: 2020 2020 2020 2020 2320 5661 6c69 6461          # Valida
-0000a650: 7469 6f6e 2070 6173 7365 642c 2073 6574  tion passed, set
-0000a660: 2064 6573 6572 6961 6c69 7a65 645f 626f   deserialized_bo
-0000a670: 6479 2074 6f20 706c 6169 6e20 6f6c 6420  dy to plain old 
-0000a680: 6465 7365 7269 616c 697a 6564 2064 6174  deserialized dat
-0000a690: 610a 2020 2020 2020 2020 2020 2020 6465  a.            de
-0000a6a0: 7365 7269 616c 697a 6564 5f62 6f64 7920  serialized_body 
-0000a6b0: 3d20 626f 6479 5f64 6174 610a 0a20 2020  = body_data..   
-0000a6c0: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
-0000a6d0: 2e72 6573 706f 6e73 655f 636c 735f 6173  .response_cls_as
-0000a6e0: 796e 6328 0a20 2020 2020 2020 2020 2020  ync(.           
-0000a6f0: 2072 6f75 6e64 5f74 7269 705f 7469 6d65   round_trip_time
-0000a700: 3d72 6573 706f 6e73 652e 726f 756e 645f  =response.round_
-0000a710: 7472 6970 5f74 696d 652c 0a20 2020 2020  trip_time,.     
-0000a720: 2020 2020 2020 2072 6573 706f 6e73 653d         response=
-0000a730: 7265 7370 6f6e 7365 2e68 7474 705f 7265  response.http_re
-0000a740: 7370 6f6e 7365 2c0a 2020 2020 2020 2020  sponse,.        
-0000a750: 2020 2020 626f 6479 3d64 6573 6572 6961      body=deseria
-0000a760: 6c69 7a65 645f 626f 6479 2c0a 2020 2020  lized_body,.    
-0000a770: 2020 2020 2020 2020 6865 6164 6572 733d          headers=
-0000a780: 7265 7370 6f6e 7365 2e68 7474 705f 7265  response.http_re
-0000a790: 7370 6f6e 7365 2e68 6561 6465 7273 2c0a  sponse.headers,.
-0000a7a0: 2020 2020 2020 2020 2020 2020 7374 6174              stat
-0000a7b0: 7573 3d72 6573 706f 6e73 652e 6874 7470  us=response.http
-0000a7c0: 5f72 6573 706f 6e73 652e 7374 6174 7573  _response.status
-0000a7d0: 0a20 2020 2020 2020 2029 0a0a 2020 2020  .        )..    
-0000a7e0: 6465 6620 6465 7365 7269 616c 697a 655f  def deserialize_
-0000a7f0: 626f 6479 2873 656c 662c 2072 6573 706f  body(self, respo
-0000a800: 6e73 653a 2052 6573 706f 6e73 6557 7261  nse: ResponseWra
-0000a810: 7070 6572 2c20 636f 6e74 656e 745f 7479  pper, content_ty
-0000a820: 7065 3a20 7374 7229 202d 3e20 2861 6e79  pe: str) -> (any
-0000a830: 2c20 7374 7229 3a0a 2020 2020 2020 2020  , str):.        
-0000a840: 6966 2073 656c 662e 5f63 6f6e 7465 6e74  if self._content
-0000a850: 5f74 7970 655f 6973 5f6a 736f 6e28 636f  _type_is_json(co
-0000a860: 6e74 656e 745f 7479 7065 293a 0a20 2020  ntent_type):.   
-0000a870: 2020 2020 2020 2020 2064 6573 6572 6961           deseria
-0000a880: 6c69 7a65 645f 626f 6479 203d 2073 656c  lized_body = sel
-0000a890: 662e 5f5f 6465 7365 7269 616c 697a 655f  f.__deserialize_
-0000a8a0: 6a73 6f6e 2872 6573 706f 6e73 652e 6874  json(response.ht
-0000a8b0: 7470 5f72 6573 706f 6e73 652e 6461 7461  tp_response.data
-0000a8c0: 290a 2020 2020 2020 2020 656c 6966 2063  ).        elif c
-0000a8d0: 6f6e 7465 6e74 5f74 7970 6520 3d3d 2027  ontent_type == '
-0000a8e0: 6170 706c 6963 6174 696f 6e2f 6f63 7465  application/octe
-0000a8f0: 742d 7374 7265 616d 273a 0a20 2020 2020  t-stream':.     
-0000a900: 2020 2020 2020 2064 6573 6572 6961 6c69         deseriali
-0000a910: 7a65 645f 626f 6479 203d 2073 656c 662e  zed_body = self.
-0000a920: 5f5f 6465 7365 7269 616c 697a 655f 6170  __deserialize_ap
-0000a930: 706c 6963 6174 696f 6e5f 6f63 7465 745f  plication_octet_
-0000a940: 7374 7265 616d 2872 6573 706f 6e73 652e  stream(response.
-0000a950: 6874 7470 5f72 6573 706f 6e73 6529 0a20  http_response). 
-0000a960: 2020 2020 2020 2065 6c69 6620 636f 6e74         elif cont
-0000a970: 656e 745f 7479 7065 2e73 7461 7274 7377  ent_type.startsw
-0000a980: 6974 6828 276d 756c 7469 7061 7274 2f66  ith('multipart/f
-0000a990: 6f72 6d2d 6461 7461 2729 3a0a 2020 2020  orm-data'):.    
-0000a9a0: 2020 2020 2020 2020 6465 7365 7269 616c          deserial
-0000a9b0: 697a 6564 5f62 6f64 7920 3d20 7365 6c66  ized_body = self
-0000a9c0: 2e5f 5f64 6573 6572 6961 6c69 7a65 5f6d  .__deserialize_m
-0000a9d0: 756c 7469 7061 7274 5f66 6f72 6d5f 6461  ultipart_form_da
-0000a9e0: 7461 2872 6573 706f 6e73 652e 6874 7470  ta(response.http
-0000a9f0: 5f72 6573 706f 6e73 652e 6461 7461 290a  _response.data).
-0000aa00: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
-0000aa10: 656e 745f 7479 7065 203d 2027 6d75 6c74  ent_type = 'mult
-0000aa20: 6970 6172 742f 666f 726d 2d64 6174 6127  ipart/form-data'
-0000aa30: 0a20 2020 2020 2020 2065 6c73 653a 2023  .        else: #
-0000aa40: 2049 6620 7765 2064 6f6e 2774 206b 6e6f   If we don't kno
-0000aa50: 7720 686f 7720 746f 2064 6573 6572 6961  w how to deseria
-0000aa60: 6c69 7a65 2c20 7573 6520 7261 7720 626f  lize, use raw bo
-0000aa70: 6479 2073 7472 696e 670a 2020 2020 2020  dy string.      
-0000aa80: 2020 2020 2020 6465 7365 7269 616c 697a        deserializ
-0000aa90: 6564 5f62 6f64 7920 3d20 7265 7370 6f6e  ed_body = respon
-0000aaa0: 7365 2e68 7474 705f 7265 7370 6f6e 7365  se.http_response
-0000aab0: 2e64 6174 612e 6465 636f 6465 2829 0a20  .data.decode(). 
-0000aac0: 2020 2020 2020 2072 6574 7572 6e20 6465         return de
-0000aad0: 7365 7269 616c 697a 6564 5f62 6f64 792c  serialized_body,
-0000aae0: 2063 6f6e 7465 6e74 5f74 7970 650a 0a20   content_type.. 
-0000aaf0: 2020 2064 6566 2064 6573 6572 6961 6c69     def deseriali
-0000ab00: 7a65 2873 656c 662c 2072 6573 706f 6e73  ze(self, respons
-0000ab10: 653a 2052 6573 706f 6e73 6557 7261 7070  e: ResponseWrapp
-0000ab20: 6572 2c20 636f 6e66 6967 7572 6174 696f  er, configuratio
-0000ab30: 6e3a 2043 6f6e 6669 6775 7261 7469 6f6e  n: Configuration
-0000ab40: 2c20 736b 6970 5f64 6573 6572 6961 6c69  , skip_deseriali
-0000ab50: 7a61 7469 6f6e 203d 2046 616c 7365 2920  zation = False) 
-0000ab60: 2d3e 2041 7069 5265 7370 6f6e 7365 3a0a  -> ApiResponse:.
-0000ab70: 2020 2020 2020 2020 636f 6e74 656e 745f          content_
-0000ab80: 7479 7065 203d 2072 6573 706f 6e73 652e  type = response.
-0000ab90: 6874 7470 5f72 6573 706f 6e73 652e 6865  http_response.he
-0000aba0: 6164 6572 732e 6765 7428 2763 6f6e 7465  aders.get('conte
-0000abb0: 6e74 2d74 7970 6527 290a 2020 2020 2020  nt-type').      
-0000abc0: 2020 7374 7265 616d 6564 203d 2072 6573    streamed = res
-0000abd0: 706f 6e73 652e 6874 7470 5f72 6573 706f  ponse.http_respo
-0000abe0: 6e73 652e 7375 7070 6f72 7473 5f63 6875  nse.supports_chu
-0000abf0: 6e6b 6564 5f72 6561 6473 2829 0a0a 2020  nked_reads()..  
-0000ac00: 2020 2020 2020 6465 7365 7269 616c 697a        deserializ
-0000ac10: 6564 5f68 6561 6465 7273 203d 2075 6e73  ed_headers = uns
-0000ac20: 6574 0a20 2020 2020 2020 2069 6620 7365  et.        if se
-0000ac30: 6c66 2e68 6561 6465 7273 2069 7320 6e6f  lf.headers is no
-0000ac40: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
-0000ac50: 2020 2020 2320 544f 444f 2061 6464 2068      # TODO add h
-0000ac60: 6561 6465 7220 6465 7365 7269 616c 697a  eader deserializ
-0000ac70: 6174 696f 6e20 6865 7265 0a20 2020 2020  ation here.     
-0000ac80: 2020 2020 2020 2070 6173 730a 0a20 2020         pass..   
-0000ac90: 2020 2020 2069 6620 7365 6c66 2e63 6f6e       if self.con
-0000aca0: 7465 6e74 2069 7320 6e6f 7420 4e6f 6e65  tent is not None
-0000acb0: 2061 6e64 206c 656e 2873 656c 662e 636f   and len(self.co
-0000acc0: 6e74 656e 7429 203d 3d20 303a 0a20 2020  ntent) == 0:.   
-0000acd0: 2020 2020 2020 2020 2023 2073 6f6d 6520           # some 
-0000ace0: 7370 6563 7320 646f 206e 6f74 2064 6566  specs do not def
-0000acf0: 696e 6520 7265 7370 6f6e 7365 2063 6f6e  ine response con
-0000ad00: 7465 6e74 206d 6564 6961 2074 7970 6520  tent media type 
-0000ad10: 7363 6865 6d61 730a 2020 2020 2020 2020  schemas.        
-0000ad20: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
-0000ad30: 7265 7370 6f6e 7365 5f63 6c73 280a 2020  response_cls(.  
-0000ad40: 2020 2020 2020 2020 2020 2020 2020 726f                ro
-0000ad50: 756e 645f 7472 6970 5f74 696d 653d 7265  und_trip_time=re
-0000ad60: 7370 6f6e 7365 2e72 6f75 6e64 5f74 7269  sponse.round_tri
-0000ad70: 705f 7469 6d65 2c0a 2020 2020 2020 2020  p_time,.        
-0000ad80: 2020 2020 2020 2020 7265 7370 6f6e 7365          response
-0000ad90: 3d72 6573 706f 6e73 652e 6874 7470 5f72  =response.http_r
-0000ada0: 6573 706f 6e73 652c 0a20 2020 2020 2020  esponse,.       
-0000adb0: 2020 2020 2020 2020 2062 6f64 793d 756e           body=un
-0000adc0: 7365 742c 0a20 2020 2020 2020 2020 2020  set,.           
-0000add0: 2020 2020 2068 6561 6465 7273 3d72 6573       headers=res
-0000ade0: 706f 6e73 652e 6874 7470 5f72 6573 706f  ponse.http_respo
-0000adf0: 6e73 652e 6865 6164 6572 732c 0a20 2020  nse.headers,.   
-0000ae00: 2020 2020 2020 2020 2020 2020 2073 7461               sta
-0000ae10: 7475 733d 7265 7370 6f6e 7365 2e68 7474  tus=response.htt
-0000ae20: 705f 7265 7370 6f6e 7365 2e73 7461 7475  p_response.statu
-0000ae30: 730a 2020 2020 2020 2020 2020 2020 290a  s.            ).
-0000ae40: 0a20 2020 2020 2020 2074 7279 3a0a 2020  .        try:.  
-0000ae50: 2020 2020 2020 2020 2020 6465 7365 7269            deseri
-0000ae60: 616c 697a 6564 5f62 6f64 792c 2063 6f6e  alized_body, con
-0000ae70: 7465 6e74 5f74 7970 6520 3d20 7365 6c66  tent_type = self
-0000ae80: 2e64 6573 6572 6961 6c69 7a65 5f62 6f64  .deserialize_bod
-0000ae90: 7928 7265 7370 6f6e 7365 2c20 636f 6e74  y(response, cont
-0000aea0: 656e 745f 7479 7065 290a 2020 2020 2020  ent_type).      
-0000aeb0: 2020 6578 6365 7074 2045 7863 6570 7469    except Excepti
-0000aec0: 6f6e 3a0a 2020 2020 2020 2020 2020 2020  on:.            
-0000aed0: 2320 4d6f 7374 206c 696b 656c 7920 636f  # Most likely co
-0000aee0: 6e74 656e 742d 7479 7065 2064 6964 206e  ntent-type did n
-0000aef0: 6f74 206d 6174 6368 2061 6374 7561 6c20  ot match actual 
-0000af00: 626f 6479 0a20 2020 2020 2020 2020 2020  body.           
-0000af10: 2064 6573 6572 6961 6c69 7a65 645f 626f   deserialized_bo
-0000af20: 6479 203d 2075 6e73 6574 0a0a 2020 2020  dy = unset..    
-0000af30: 2020 2020 6966 206e 6f74 2073 6b69 705f      if not skip_
-0000af40: 6465 7365 7269 616c 697a 6174 696f 6e3a  deserialization:
-0000af50: 0a20 2020 2020 2020 2020 2020 2062 6f64  .            bod
-0000af60: 795f 7363 6865 6d61 203d 2073 656c 662e  y_schema = self.
-0000af70: 5f5f 6765 745f 7363 6865 6d61 5f66 6f72  __get_schema_for
-0000af80: 5f63 6f6e 7465 6e74 5f74 7970 6528 636f  _content_type(co
-0000af90: 6e74 656e 745f 7479 7065 290a 2020 2020  ntent_type).    
-0000afa0: 2020 2020 2020 2020 6966 2062 6f64 795f          if body_
-0000afb0: 7363 6865 6d61 2069 7320 4e6f 6e65 3a0a  schema is None:.
-0000afc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000afd0: 7261 6973 6520 4170 6956 616c 7565 4572  raise ApiValueEr
-0000afe0: 726f 7228 0a20 2020 2020 2020 2020 2020  ror(.           
-0000aff0: 2020 2020 2020 2020 2066 2249 6e76 616c           f"Inval
-0000b000: 6964 2063 6f6e 7465 6e74 5f74 7970 6520  id content_type 
-0000b010: 7265 7475 726e 6564 2e20 436f 6e74 656e  returned. Conten
-0000b020: 745f 7479 7065 3d27 7b63 6f6e 7465 6e74  t_type='{content
-0000b030: 5f74 7970 657d 2720 7761 7320 7265 7475  _type}' was retu
-0000b040: 726e 6564 2022 0a20 2020 2020 2020 2020  rned ".         
-0000b050: 2020 2020 2020 2020 2020 2066 2277 6865             f"whe
-0000b060: 6e20 6f6e 6c79 207b 7374 7228 7365 7428  n only {str(set(
-0000b070: 7365 6c66 2e63 6f6e 7465 6e74 2929 7d20  self.content))} 
-0000b080: 6172 6520 6465 6669 6e65 6420 666f 7220  are defined for 
-0000b090: 7374 6174 7573 5f63 6f64 653d 7b73 7472  status_code={str
-0000b0a0: 2872 6573 706f 6e73 652e 6874 7470 5f72  (response.http_r
-0000b0b0: 6573 706f 6e73 652e 7374 6174 7573 297d  esponse.status)}
-0000b0c0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-0000b0d0: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
-0000b0e0: 2320 4578 6563 7574 6520 7661 6c69 6461  # Execute valida
-0000b0f0: 7469 6f6e 2061 6e64 2074 6872 6f77 2061  tion and throw a
-0000b100: 7320 6120 7369 6465 2065 6666 6563 7420  s a side effect 
-0000b110: 6966 2076 616c 6964 6174 696f 6e20 6661  if validation fa
-0000b120: 696c 730a 2020 2020 2020 2020 2020 2020  ils.            
-0000b130: 626f 6479 5f73 6368 656d 612e 6672 6f6d  body_schema.from
-0000b140: 5f6f 7065 6e61 7069 5f64 6174 615f 6f61  _openapi_data_oa
-0000b150: 7067 280a 2020 2020 2020 2020 2020 2020  pg(.            
-0000b160: 2020 2020 626f 6479 5f64 6174 612c 0a20      body_data,. 
-0000b170: 2020 2020 2020 2020 2020 2020 2020 205f                 _
-0000b180: 636f 6e66 6967 7572 6174 696f 6e3d 636f  configuration=co
-0000b190: 6e66 6967 7572 6174 696f 6e0a 2020 2020  nfiguration.    
-0000b1a0: 2020 2020 2020 2020 290a 0a20 2020 2020          )..     
-0000b1b0: 2020 2069 6620 7374 7265 616d 6564 3a0a     if streamed:.
-0000b1c0: 2020 2020 2020 2020 2020 2020 7265 7370              resp
-0000b1d0: 6f6e 7365 2e68 7474 705f 7265 7370 6f6e  onse.http_respon
-0000b1e0: 7365 2e72 656c 6561 7365 5f63 6f6e 6e28  se.release_conn(
-0000b1f0: 290a 0a20 2020 2020 2020 2072 6574 7572  )..        retur
-0000b200: 6e20 7365 6c66 2e72 6573 706f 6e73 655f  n self.response_
-0000b210: 636c 7328 0a20 2020 2020 2020 2020 2020  cls(.           
-0000b220: 2072 6f75 6e64 5f74 7269 705f 7469 6d65   round_trip_time
-0000b230: 3d72 6573 706f 6e73 652e 726f 756e 645f  =response.round_
-0000b240: 7472 6970 5f74 696d 652c 0a20 2020 2020  trip_time,.     
-0000b250: 2020 2020 2020 2072 6573 706f 6e73 653d         response=
-0000b260: 7265 7370 6f6e 7365 2e68 7474 705f 7265  response.http_re
-0000b270: 7370 6f6e 7365 2c0a 2020 2020 2020 2020  sponse,.        
-0000b280: 2020 2020 626f 6479 3d64 6573 6572 6961      body=deseria
-0000b290: 6c69 7a65 645f 626f 6479 2c0a 2020 2020  lized_body,.    
-0000b2a0: 2020 2020 2020 2020 6865 6164 6572 733d          headers=
-0000b2b0: 7265 7370 6f6e 7365 2e68 7474 705f 7265  response.http_re
-0000b2c0: 7370 6f6e 7365 2e68 6561 6465 7273 2c0a  sponse.headers,.
-0000b2d0: 2020 2020 2020 2020 2020 2020 7374 6174              stat
-0000b2e0: 7573 3d72 6573 706f 6e73 652e 6874 7470  us=response.http
-0000b2f0: 5f72 6573 706f 6e73 652e 7374 6174 7573  _response.status
-0000b300: 0a20 2020 2020 2020 2029 0a0a 0a63 6c61  .        )...cla
-0000b310: 7373 2041 7069 436c 6965 6e74 3a0a 2020  ss ApiClient:.  
-0000b320: 2020 2222 2247 656e 6572 6963 2041 5049    """Generic API
-0000b330: 2063 6c69 656e 7420 666f 7220 4f70 656e   client for Open
-0000b340: 4150 4920 636c 6965 6e74 206c 6962 7261  API client libra
-0000b350: 7279 2062 7569 6c64 732e 0a0a 2020 2020  ry builds...    
-0000b360: 4f70 656e 4150 4920 6765 6e65 7269 6320  OpenAPI generic 
-0000b370: 4150 4920 636c 6965 6e74 2e20 5468 6973  API client. This
-0000b380: 2063 6c69 656e 7420 6861 6e64 6c65 7320   client handles 
-0000b390: 7468 6520 636c 6965 6e74 2d0a 2020 2020  the client-.    
-0000b3a0: 7365 7276 6572 2063 6f6d 6d75 6e69 6361  server communica
-0000b3b0: 7469 6f6e 2c20 616e 6420 6973 2069 6e76  tion, and is inv
-0000b3c0: 6172 6961 6e74 2061 6372 6f73 7320 696d  ariant across im
-0000b3d0: 706c 656d 656e 7461 7469 6f6e 732e 2053  plementations. S
-0000b3e0: 7065 6369 6669 6373 206f 660a 2020 2020  pecifics of.    
-0000b3f0: 7468 6520 6d65 7468 6f64 7320 616e 6420  the methods and 
-0000b400: 6d6f 6465 6c73 2066 6f72 2065 6163 6820  models for each 
-0000b410: 6170 706c 6963 6174 696f 6e20 6172 6520  application are 
-0000b420: 6765 6e65 7261 7465 6420 6672 6f6d 2074  generated from t
-0000b430: 6865 204f 7065 6e41 5049 0a20 2020 2074  he OpenAPI.    t
-0000b440: 656d 706c 6174 6573 2e0a 0a20 2020 2054  emplates...    T
-0000b450: 6869 7320 636c 6173 7320 6973 2061 7574  his class is aut
-0000b460: 6f20 6765 6e65 7261 7465 6420 6279 204b  o generated by K
-0000b470: 6f6e 6669 6720 2868 7474 7073 3a2f 2f6b  onfig (https://k
-0000b480: 6f6e 6669 6774 6869 732e 636f 6d29 0a0a  onfigthis.com)..
-0000b490: 2020 2020 3a70 6172 616d 2063 6f6e 6669      :param confi
-0000b4a0: 6775 7261 7469 6f6e 3a20 2e43 6f6e 6669  guration: .Confi
-0000b4b0: 6775 7261 7469 6f6e 206f 626a 6563 7420  guration object 
-0000b4c0: 666f 7220 7468 6973 2063 6c69 656e 740a  for this client.
-0000b4d0: 2020 2020 3a70 6172 616d 2068 6561 6465      :param heade
-0000b4e0: 725f 6e61 6d65 3a20 6120 6865 6164 6572  r_name: a header
-0000b4f0: 2074 6f20 7061 7373 2077 6865 6e20 6d61   to pass when ma
-0000b500: 6b69 6e67 2063 616c 6c73 2074 6f20 7468  king calls to th
-0000b510: 6520 4150 492e 0a20 2020 203a 7061 7261  e API..    :para
-0000b520: 6d20 6865 6164 6572 5f76 616c 7565 3a20  m header_value: 
-0000b530: 6120 6865 6164 6572 2076 616c 7565 2074  a header value t
-0000b540: 6f20 7061 7373 2077 6865 6e20 6d61 6b69  o pass when maki
-0000b550: 6e67 2063 616c 6c73 2074 6f0a 2020 2020  ng calls to.    
-0000b560: 2020 2020 7468 6520 4150 492e 0a20 2020      the API..   
-0000b570: 203a 7061 7261 6d20 636f 6f6b 6965 3a20   :param cookie: 
-0000b580: 6120 636f 6f6b 6965 2074 6f20 696e 636c  a cookie to incl
-0000b590: 7564 6520 696e 2074 6865 2068 6561 6465  ude in the heade
-0000b5a0: 7220 7768 656e 206d 616b 696e 6720 6361  r when making ca
-0000b5b0: 6c6c 730a 2020 2020 2020 2020 746f 2074  lls.        to t
-0000b5c0: 6865 2041 5049 0a20 2020 203a 7061 7261  he API.    :para
-0000b5d0: 6d20 706f 6f6c 5f74 6872 6561 6473 3a20  m pool_threads: 
-0000b5e0: 5468 6520 6e75 6d62 6572 206f 6620 7468  The number of th
-0000b5f0: 7265 6164 7320 746f 2075 7365 2066 6f72  reads to use for
-0000b600: 2061 7379 6e63 2072 6571 7565 7374 730a   async requests.
-0000b610: 2020 2020 2020 2020 746f 2074 6865 2041          to the A
-0000b620: 5049 2e20 4d6f 7265 2074 6872 6561 6473  PI. More threads
-0000b630: 206d 6561 6e73 206d 6f72 6520 636f 6e63   means more conc
-0000b640: 7572 7265 6e74 2041 5049 2072 6571 7565  urrent API reque
-0000b650: 7374 732e 0a20 2020 2022 2222 0a0a 2020  sts..    """..  
-0000b660: 2020 5f70 6f6f 6c20 3d20 4e6f 6e65 0a0a    _pool = None..
-0000b670: 2020 2020 6465 6620 5f5f 696e 6974 5f5f      def __init__
-0000b680: 280a 2020 2020 2020 2020 7365 6c66 2c0a  (.        self,.
-0000b690: 2020 2020 2020 2020 636f 6e66 6967 7572          configur
-0000b6a0: 6174 696f 6e3a 2074 7970 696e 672e 4f70  ation: typing.Op
-0000b6b0: 7469 6f6e 616c 5b43 6f6e 6669 6775 7261  tional[Configura
-0000b6c0: 7469 6f6e 5d20 3d20 4e6f 6e65 2c0a 2020  tion] = None,.  
-0000b6d0: 2020 2020 2020 6865 6164 6572 5f6e 616d        header_nam
-0000b6e0: 653a 2074 7970 696e 672e 4f70 7469 6f6e  e: typing.Option
-0000b6f0: 616c 5b73 7472 5d20 3d20 4e6f 6e65 2c0a  al[str] = None,.
-0000b700: 2020 2020 2020 2020 6865 6164 6572 5f76          header_v
-0000b710: 616c 7565 3a20 7479 7069 6e67 2e4f 7074  alue: typing.Opt
-0000b720: 696f 6e61 6c5b 7374 725d 203d 204e 6f6e  ional[str] = Non
-0000b730: 652c 0a20 2020 2020 2020 2063 6f6f 6b69  e,.        cooki
-0000b740: 653a 2074 7970 696e 672e 4f70 7469 6f6e  e: typing.Option
-0000b750: 616c 5b73 7472 5d20 3d20 4e6f 6e65 2c0a  al[str] = None,.
-0000b760: 2020 2020 2020 2020 706f 6f6c 5f74 6872          pool_thr
-0000b770: 6561 6473 3a20 696e 7420 3d20 310a 2020  eads: int = 1.  
-0000b780: 2020 293a 0a20 2020 2020 2020 2069 6620    ):.        if 
-0000b790: 636f 6e66 6967 7572 6174 696f 6e20 6973  configuration is
-0000b7a0: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
-0000b7b0: 2020 2063 6f6e 6669 6775 7261 7469 6f6e     configuration
-0000b7c0: 203d 2043 6f6e 6669 6775 7261 7469 6f6e   = Configuration
-0000b7d0: 2829 0a20 2020 2020 2020 2073 656c 662e  ().        self.
-0000b7e0: 636f 6e66 6967 7572 6174 696f 6e20 3d20  configuration = 
-0000b7f0: 636f 6e66 6967 7572 6174 696f 6e0a 2020  configuration.  
-0000b800: 2020 2020 2020 7365 6c66 2e70 6f6f 6c5f        self.pool_
-0000b810: 7468 7265 6164 7320 3d20 706f 6f6c 5f74  threads = pool_t
-0000b820: 6872 6561 6473 0a0a 2020 2020 2020 2020  hreads..        
-0000b830: 7365 6c66 2e72 6573 745f 636c 6965 6e74  self.rest_client
-0000b840: 203d 2072 6573 742e 5245 5354 436c 6965   = rest.RESTClie
-0000b850: 6e74 4f62 6a65 6374 2863 6f6e 6669 6775  ntObject(configu
-0000b860: 7261 7469 6f6e 290a 2020 2020 2020 2020  ration).        
-0000b870: 7365 6c66 2e64 6566 6175 6c74 5f68 6561  self.default_hea
-0000b880: 6465 7273 203d 2048 5454 5048 6561 6465  ders = HTTPHeade
-0000b890: 7244 6963 7428 290a 2020 2020 2020 2020  rDict().        
-0000b8a0: 6966 2068 6561 6465 725f 6e61 6d65 2069  if header_name i
-0000b8b0: 7320 6e6f 7420 4e6f 6e65 3a0a 2020 2020  s not None:.    
-0000b8c0: 2020 2020 2020 2020 7365 6c66 2e64 6566          self.def
-0000b8d0: 6175 6c74 5f68 6561 6465 7273 5b68 6561  ault_headers[hea
-0000b8e0: 6465 725f 6e61 6d65 5d20 3d20 6865 6164  der_name] = head
-0000b8f0: 6572 5f76 616c 7565 0a20 2020 2020 2020  er_value.       
-0000b900: 2073 656c 662e 636f 6f6b 6965 203d 2063   self.cookie = c
-0000b910: 6f6f 6b69 650a 2020 2020 2020 2020 2320  ookie.        # 
-0000b920: 5365 7420 6465 6661 756c 7420 5573 6572  Set default User
-0000b930: 2d41 6765 6e74 2e0a 2020 2020 2020 2020  -Agent..        
-0000b940: 7365 6c66 2e75 7365 725f 6167 656e 7420  self.user_agent 
-0000b950: 3d20 274b 6f6e 6669 672f 302e 312e 392f  = 'Konfig/0.1.9/
-0000b960: 7079 7468 6f6e 270a 0a20 2020 2064 6566  python'..    def
-0000b970: 205f 5f65 6e74 6572 5f5f 2873 656c 6629   __enter__(self)
-0000b980: 3a0a 2020 2020 2020 2020 7265 7475 726e  :.        return
-0000b990: 2073 656c 660a 0a20 2020 2064 6566 205f   self..    def _
-0000b9a0: 5f65 7869 745f 5f28 7365 6c66 2c20 6578  _exit__(self, ex
-0000b9b0: 635f 7479 7065 2c20 6578 635f 7661 6c75  c_type, exc_valu
-0000b9c0: 652c 2074 7261 6365 6261 636b 293a 0a20  e, traceback):. 
-0000b9d0: 2020 2020 2020 2073 656c 662e 636c 6f73         self.clos
-0000b9e0: 6528 290a 0a20 2020 2064 6566 2063 6c6f  e()..    def clo
-0000b9f0: 7365 2873 656c 6629 3a0a 2020 2020 2020  se(self):.      
-0000ba00: 2020 6966 2073 656c 662e 5f70 6f6f 6c3a    if self._pool:
-0000ba10: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
-0000ba20: 662e 5f70 6f6f 6c2e 636c 6f73 6528 290a  f._pool.close().
-0000ba30: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-0000ba40: 2e5f 706f 6f6c 2e6a 6f69 6e28 290a 2020  ._pool.join().  
-0000ba50: 2020 2020 2020 2020 2020 7365 6c66 2e5f            self._
-0000ba60: 706f 6f6c 203d 204e 6f6e 650a 2020 2020  pool = None.    
-0000ba70: 2020 2020 2020 2020 6966 2068 6173 6174          if hasat
-0000ba80: 7472 2861 7465 7869 742c 2027 756e 7265  tr(atexit, 'unre
-0000ba90: 6769 7374 6572 2729 3a0a 2020 2020 2020  gister'):.      
-0000baa0: 2020 2020 2020 2020 2020 6174 6578 6974            atexit
-0000bab0: 2e75 6e72 6567 6973 7465 7228 7365 6c66  .unregister(self
-0000bac0: 2e63 6c6f 7365 290a 0a20 2020 2040 7072  .close)..    @pr
-0000bad0: 6f70 6572 7479 0a20 2020 2064 6566 2070  operty.    def p
-0000bae0: 6f6f 6c28 7365 6c66 293a 0a20 2020 2020  ool(self):.     
-0000baf0: 2020 2022 2222 4372 6561 7465 2074 6872     """Create thr
-0000bb00: 6561 6420 706f 6f6c 206f 6e20 6669 7273  ead pool on firs
-0000bb10: 7420 7265 7175 6573 740a 2020 2020 2020  t request.      
-0000bb20: 2020 2061 766f 6964 7320 696e 7374 616e     avoids instan
-0000bb30: 7469 6174 696e 6720 756e 7573 6564 2074  tiating unused t
-0000bb40: 6872 6561 6470 6f6f 6c20 666f 7220 626c  hreadpool for bl
-0000bb50: 6f63 6b69 6e67 2063 6c69 656e 7473 2e0a  ocking clients..
-0000bb60: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-0000bb70: 2020 2020 6966 2073 656c 662e 5f70 6f6f      if self._poo
-0000bb80: 6c20 6973 204e 6f6e 653a 0a20 2020 2020  l is None:.     
-0000bb90: 2020 2020 2020 2061 7465 7869 742e 7265         atexit.re
-0000bba0: 6769 7374 6572 2873 656c 662e 636c 6f73  gister(self.clos
-0000bbb0: 6529 0a20 2020 2020 2020 2020 2020 2073  e).            s
-0000bbc0: 656c 662e 5f70 6f6f 6c20 3d20 5468 7265  elf._pool = Thre
-0000bbd0: 6164 506f 6f6c 2873 656c 662e 706f 6f6c  adPool(self.pool
-0000bbe0: 5f74 6872 6561 6473 290a 2020 2020 2020  _threads).      
-0000bbf0: 2020 7265 7475 726e 2073 656c 662e 5f70    return self._p
-0000bc00: 6f6f 6c0a 0a20 2020 2040 7072 6f70 6572  ool..    @proper
-0000bc10: 7479 0a20 2020 2064 6566 2075 7365 725f  ty.    def user_
-0000bc20: 6167 656e 7428 7365 6c66 293a 0a20 2020  agent(self):.   
-0000bc30: 2020 2020 2022 2222 5573 6572 2061 6765       """User age
-0000bc40: 6e74 2066 6f72 2074 6869 7320 4150 4920  nt for this API 
-0000bc50: 636c 6965 6e74 2222 220a 2020 2020 2020  client""".      
-0000bc60: 2020 7265 7475 726e 2073 656c 662e 6465    return self.de
-0000bc70: 6661 756c 745f 6865 6164 6572 735b 2755  fault_headers['U
-0000bc80: 7365 722d 4167 656e 7427 5d0a 0a20 2020  ser-Agent']..   
-0000bc90: 2040 7573 6572 5f61 6765 6e74 2e73 6574   @user_agent.set
-0000bca0: 7465 720a 2020 2020 6465 6620 7573 6572  ter.    def user
-0000bcb0: 5f61 6765 6e74 2873 656c 662c 2076 616c  _agent(self, val
-0000bcc0: 7565 293a 0a20 2020 2020 2020 2073 656c  ue):.        sel
-0000bcd0: 662e 6465 6661 756c 745f 6865 6164 6572  f.default_header
-0000bce0: 735b 2755 7365 722d 4167 656e 7427 5d20  s['User-Agent'] 
-0000bcf0: 3d20 7661 6c75 650a 0a20 2020 2064 6566  = value..    def
-0000bd00: 2073 6574 5f64 6566 6175 6c74 5f68 6561   set_default_hea
-0000bd10: 6465 7228 7365 6c66 2c20 6865 6164 6572  der(self, header
-0000bd20: 5f6e 616d 652c 2068 6561 6465 725f 7661  _name, header_va
-0000bd30: 6c75 6529 3a0a 2020 2020 2020 2020 7365  lue):.        se
-0000bd40: 6c66 2e64 6566 6175 6c74 5f68 6561 6465  lf.default_heade
-0000bd50: 7273 5b68 6561 6465 725f 6e61 6d65 5d20  rs[header_name] 
-0000bd60: 3d20 6865 6164 6572 5f76 616c 7565 0a0a  = header_value..
-0000bd70: 2020 2020 6173 796e 6320 6465 6620 5f5f      async def __
-0000bd80: 6173 796e 635f 6361 6c6c 5f61 7069 280a  async_call_api(.
-0000bd90: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
-0000bda0: 2020 2020 2020 7265 736f 7572 6365 5f70        resource_p
-0000bdb0: 6174 683a 2073 7472 2c0a 2020 2020 2020  ath: str,.      
-0000bdc0: 2020 6d65 7468 6f64 3a20 7374 722c 0a20    method: str,. 
-0000bdd0: 2020 2020 2020 2068 6561 6465 7273 3a20         headers: 
-0000bde0: 7479 7069 6e67 2e4f 7074 696f 6e61 6c5b  typing.Optional[
-0000bdf0: 4854 5450 4865 6164 6572 4469 6374 5d20  HTTPHeaderDict] 
-0000be00: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
-0000be10: 7365 7269 616c 697a 6564 5f62 6f64 793a  serialized_body:
-0000be20: 2074 7970 696e 672e 4f70 7469 6f6e 616c   typing.Optional
-0000be30: 5b74 7970 696e 672e 556e 696f 6e5b 7374  [typing.Union[st
-0000be40: 722c 2062 7974 6573 5d5d 203d 204e 6f6e  r, bytes]] = Non
-0000be50: 652c 0a20 2020 2020 2020 2062 6f64 793a  e,.        body:
-0000be60: 2074 7970 696e 672e 416e 7920 3d20 4e6f   typing.Any = No
-0000be70: 6e65 2c0a 2020 2020 2020 2020 6669 656c  ne,.        fiel
-0000be80: 6473 3a20 7479 7069 6e67 2e4f 7074 696f  ds: typing.Optio
-0000be90: 6e61 6c5b 7479 7069 6e67 2e54 7570 6c65  nal[typing.Tuple
-0000bea0: 5b74 7970 696e 672e 5475 706c 655b 7374  [typing.Tuple[st
-0000beb0: 722c 2073 7472 5d2c 202e 2e2e 5d5d 203d  r, str], ...]] =
-0000bec0: 204e 6f6e 652c 0a20 2020 2020 2020 2061   None,.        a
-0000bed0: 7574 685f 7365 7474 696e 6773 3a20 7479  uth_settings: ty
-0000bee0: 7069 6e67 2e4f 7074 696f 6e61 6c5b 7479  ping.Optional[ty
-0000bef0: 7069 6e67 2e4c 6973 745b 7374 725d 5d20  ping.List[str]] 
-0000bf00: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
-0000bf10: 7374 7265 616d 3a20 626f 6f6c 203d 2046  stream: bool = F
-0000bf20: 616c 7365 2c0a 2020 2020 2020 2020 7469  alse,.        ti
-0000bf30: 6d65 6f75 743a 2074 7970 696e 672e 4f70  meout: typing.Op
-0000bf40: 7469 6f6e 616c 5b74 7970 696e 672e 556e  tional[typing.Un
-0000bf50: 696f 6e5b 666c 6f61 742c 2074 7970 696e  ion[float, typin
-0000bf60: 672e 5475 706c 655d 5d20 3d20 4e6f 6e65  g.Tuple]] = None
-0000bf70: 2c0a 2020 2020 2020 2020 686f 7374 3a20  ,.        host: 
-0000bf80: 7479 7069 6e67 2e4f 7074 696f 6e61 6c5b  typing.Optional[
-0000bf90: 7374 725d 203d 204e 6f6e 652c 0a20 2020  str] = None,.   
-0000bfa0: 2020 2020 2070 7265 6669 785f 7365 7061       prefix_sepa
-0000bfb0: 7261 746f 725f 6974 6572 6174 6f72 3a20  rator_iterator: 
-0000bfc0: 5072 6566 6978 5365 7061 7261 746f 7249  PrefixSeparatorI
-0000bfd0: 7465 7261 746f 7220 3d20 4e6f 6e65 2c0a  terator = None,.
-0000bfe0: 2020 2020 2020 2020 2a2a 6b77 6172 6773          **kwargs
-0000bff0: 0a20 2020 2029 202d 3e20 4173 796e 6352  .    ) -> AsyncR
-0000c000: 6573 706f 6e73 6557 7261 7070 6572 3a0a  esponseWrapper:.
-0000c010: 0a20 2020 2020 2020 2023 2068 6561 6465  .        # heade
-0000c020: 7220 7061 7261 6d65 7465 7273 0a20 2020  r parameters.   
-0000c030: 2020 2020 2075 7365 645f 6865 6164 6572       used_header
-0000c040: 7320 3d20 4854 5450 4865 6164 6572 4469  s = HTTPHeaderDi
-0000c050: 6374 2873 656c 662e 6465 6661 756c 745f  ct(self.default_
-0000c060: 6865 6164 6572 7329 0a20 2020 2020 2020  headers).       
-0000c070: 2069 6620 7365 6c66 2e63 6f6f 6b69 653a   if self.cookie:
-0000c080: 0a20 2020 2020 2020 2020 2020 2068 6561  .            hea
-0000c090: 6465 7273 5b27 436f 6f6b 6965 275d 203d  ders['Cookie'] =
-0000c0a0: 2073 656c 662e 636f 6f6b 6965 0a0a 2020   self.cookie..  
-0000c0b0: 2020 2020 2020 2320 6175 7468 2073 6574        # auth set
-0000c0c0: 7469 6e67 0a20 2020 2020 2020 2072 6573  ting.        res
-0000c0d0: 6f75 7263 655f 7061 7468 5f72 6566 203d  ource_path_ref =
-0000c0e0: 205b 7365 6c66 2e75 7064 6174 655f 7061   [self.update_pa
-0000c0f0: 7261 6d73 5f66 6f72 5f61 7574 6828 0a20  rams_for_auth(. 
-0000c100: 2020 2020 2020 2020 2020 2075 7365 645f             used_
-0000c110: 6865 6164 6572 732c 0a20 2020 2020 2020  headers,.       
-0000c120: 2020 2020 2061 7574 685f 7365 7474 696e       auth_settin
-0000c130: 6773 2c0a 2020 2020 2020 2020 2020 2020  gs,.            
-0000c140: 7265 736f 7572 6365 5f70 6174 682c 0a20  resource_path,. 
-0000c150: 2020 2020 2020 2020 2020 206d 6574 686f             metho
-0000c160: 642c 0a20 2020 2020 2020 2020 2020 2062  d,.            b
-0000c170: 6f64 792c 0a20 2020 2020 2020 2020 2020  ody,.           
-0000c180: 2070 7265 6669 785f 7365 7061 7261 746f   prefix_separato
-0000c190: 725f 6974 6572 6174 6f72 0a20 2020 2020  r_iterator.     
-0000c1a0: 2020 2029 5d0a 0a20 2020 2020 2020 2023     )]..        #
-0000c1b0: 206d 7573 7420 6861 7070 656e 2061 6674   must happen aft
-0000c1c0: 6572 2063 6f6f 6b69 6520 7365 7474 696e  er cookie settin
-0000c1d0: 6720 616e 6420 6175 7468 2073 6574 7469  g and auth setti
-0000c1e0: 6e67 2069 6e20 6361 7365 2075 7365 7220  ng in case user 
-0000c1f0: 6973 206f 7665 7272 6964 696e 6720 7468  is overriding th
-0000c200: 6f73 650a 2020 2020 2020 2020 6966 2068  ose.        if h
-0000c210: 6561 6465 7273 3a0a 2020 2020 2020 2020  eaders:.        
-0000c220: 2020 2020 7573 6564 5f68 6561 6465 7273      used_headers
-0000c230: 2e75 7064 6174 6528 6865 6164 6572 7329  .update(headers)
-0000c240: 0a0a 2020 2020 2020 2020 7265 7175 6573  ..        reques
-0000c250: 745f 6265 666f 7265 5f75 726c 5f68 6f6f  t_before_url_hoo
-0000c260: 6b28 0a20 2020 2020 2020 2020 2020 2072  k(.            r
-0000c270: 6573 6f75 7263 655f 7061 7468 5f72 6566  esource_path_ref
-0000c280: 3d72 6573 6f75 7263 655f 7061 7468 5f72  =resource_path_r
-0000c290: 6566 2c0a 2020 2020 2020 2020 2020 2020  ef,.            
-0000c2a0: 6d65 7468 6f64 3d6d 6574 686f 642c 0a20  method=method,. 
-0000c2b0: 2020 2020 2020 2020 2020 2063 6f6e 6669             confi
-0000c2c0: 6775 7261 7469 6f6e 3d73 656c 662e 636f  guration=self.co
-0000c2d0: 6e66 6967 7572 6174 696f 6e2c 0a20 2020  nfiguration,.   
-0000c2e0: 2020 2020 2020 2020 2062 6f64 793d 626f           body=bo
-0000c2f0: 6479 2c0a 2020 2020 2020 2020 2020 2020  dy,.            
-0000c300: 6669 656c 6473 3d66 6965 6c64 732c 0a20  fields=fields,. 
-0000c310: 2020 2020 2020 2020 2020 2061 7574 685f             auth_
-0000c320: 7365 7474 696e 6773 3d61 7574 685f 7365  settings=auth_se
-0000c330: 7474 696e 6773 2c0a 2020 2020 2020 2020  ttings,.        
-0000c340: 2020 2020 6865 6164 6572 733d 7573 6564      headers=used
-0000c350: 5f68 6561 6465 7273 2c0a 2020 2020 2020  _headers,.      
-0000c360: 2020 290a 0a20 2020 2020 2020 2023 2072    )..        # r
-0000c370: 6571 7565 7374 2075 726c 0a20 2020 2020  equest url.     
-0000c380: 2020 2069 6620 686f 7374 2069 7320 4e6f     if host is No
-0000c390: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-0000c3a0: 7572 6c20 3d20 7365 6c66 2e63 6f6e 6669  url = self.confi
-0000c3b0: 6775 7261 7469 6f6e 2e68 6f73 7420 2b20  guration.host + 
-0000c3c0: 7265 736f 7572 6365 5f70 6174 685f 7265  resource_path_re
-0000c3d0: 665b 305d 0a20 2020 2020 2020 2065 6c73  f[0].        els
-0000c3e0: 653a 0a20 2020 2020 2020 2020 2020 2023  e:.            #
-0000c3f0: 2075 7365 2073 6572 7665 722f 686f 7374   use server/host
-0000c400: 2064 6566 696e 6564 2069 6e20 7061 7468   defined in path
-0000c410: 206f 7220 6f70 6572 6174 696f 6e20 696e   or operation in
-0000c420: 7374 6561 640a 2020 2020 2020 2020 2020  stead.          
-0000c430: 2020 7572 6c20 3d20 686f 7374 202b 2072    url = host + r
-0000c440: 6573 6f75 7263 655f 7061 7468 5f72 6566  esource_path_ref
-0000c450: 5b30 5d0a 0a20 2020 2020 2020 2072 6571  [0]..        req
-0000c460: 7565 7374 5f61 6674 6572 5f68 6f6f 6b28  uest_after_hook(
-0000c470: 0a20 2020 2020 2020 2020 2020 2072 6573  .            res
-0000c480: 6f75 7263 655f 7061 7468 3d72 6573 6f75  ource_path=resou
-0000c490: 7263 655f 7061 7468 5f72 6566 5b30 5d2c  rce_path_ref[0],
-0000c4a0: 0a20 2020 2020 2020 2020 2020 206d 6574  .            met
-0000c4b0: 686f 643d 6d65 7468 6f64 2c0a 2020 2020  hod=method,.    
-0000c4c0: 2020 2020 2020 2020 636f 6e66 6967 7572          configur
-0000c4d0: 6174 696f 6e3d 7365 6c66 2e63 6f6e 6669  ation=self.confi
-0000c4e0: 6775 7261 7469 6f6e 2c0a 2020 2020 2020  guration,.      
-0000c4f0: 2020 2020 2020 626f 6479 3d62 6f64 792c        body=body,
-0000c500: 0a20 2020 2020 2020 2020 2020 2066 6965  .            fie
-0000c510: 6c64 733d 6669 656c 6473 2c0a 2020 2020  lds=fields,.    
-0000c520: 2020 2020 2020 2020 6175 7468 5f73 6574          auth_set
-0000c530: 7469 6e67 733d 6175 7468 5f73 6574 7469  tings=auth_setti
-0000c540: 6e67 732c 0a20 2020 2020 2020 2020 2020  ngs,.           
-0000c550: 2068 6561 6465 7273 3d75 7365 645f 6865   headers=used_he
-0000c560: 6164 6572 732c 0a20 2020 2020 2020 2029  aders,.        )
-0000c570: 0a0a 2020 2020 2020 2020 2320 7065 7266  ..        # perf
-0000c580: 6f72 6d20 7265 7175 6573 7420 616e 6420  orm request and 
-0000c590: 7265 7475 726e 2072 6573 706f 6e73 650a  return response.
-0000c5a0: 2020 2020 2020 2020 7265 7370 6f6e 7365          response
-0000c5b0: 203d 2061 7761 6974 2073 656c 662e 6173   = await self.as
-0000c5c0: 796e 635f 7265 7175 6573 7428 0a20 2020  ync_request(.   
-0000c5d0: 2020 2020 2020 2020 206d 6574 686f 642c           method,
-0000c5e0: 0a20 2020 2020 2020 2020 2020 2075 726c  .            url
-0000c5f0: 2c0a 2020 2020 2020 2020 2020 2020 6865  ,.            he
-0000c600: 6164 6572 733d 7573 6564 5f68 6561 6465  aders=used_heade
-0000c610: 7273 2c0a 2020 2020 2020 2020 2020 2020  rs,.            
-0000c620: 6669 656c 6473 3d66 6965 6c64 732c 0a20  fields=fields,. 
-0000c630: 2020 2020 2020 2020 2020 2062 6f64 793d             body=
-0000c640: 7365 7269 616c 697a 6564 5f62 6f64 792c  serialized_body,
-0000c650: 0a20 2020 2020 2020 2020 2020 2073 7472  .            str
-0000c660: 6561 6d3d 7374 7265 616d 2c0a 2020 2020  eam=stream,.    
-0000c670: 2020 2020 2020 2020 7469 6d65 6f75 743d          timeout=
-0000c680: 7469 6d65 6f75 742c 0a20 2020 2020 2020  timeout,.       
-0000c690: 2020 2020 202a 2a6b 7761 7267 730a 2020       **kwargs.  
-0000c6a0: 2020 2020 2020 290a 0a0a 2020 2020 2020        )...      
-0000c6b0: 2020 7265 7475 726e 2072 6573 706f 6e73    return respons
-0000c6c0: 650a 0a20 2020 2064 6566 205f 5f63 616c  e..    def __cal
-0000c6d0: 6c5f 6170 6928 0a20 2020 2020 2020 2073  l_api(.        s
-0000c6e0: 656c 662c 0a20 2020 2020 2020 2072 6573  elf,.        res
-0000c6f0: 6f75 7263 655f 7061 7468 3a20 7374 722c  ource_path: str,
-0000c700: 0a20 2020 2020 2020 206d 6574 686f 643a  .        method:
-0000c710: 2073 7472 2c0a 2020 2020 2020 2020 6865   str,.        he
-0000c720: 6164 6572 733a 2074 7970 696e 672e 4f70  aders: typing.Op
-0000c730: 7469 6f6e 616c 5b48 5454 5048 6561 6465  tional[HTTPHeade
-0000c740: 7244 6963 745d 203d 204e 6f6e 652c 0a20  rDict] = None,. 
-0000c750: 2020 2020 2020 2073 6572 6961 6c69 7a65         serialize
-0000c760: 645f 626f 6479 3a20 7479 7069 6e67 2e4f  d_body: typing.O
-0000c770: 7074 696f 6e61 6c5b 7479 7069 6e67 2e55  ptional[typing.U
-0000c780: 6e69 6f6e 5b73 7472 2c20 6279 7465 735d  nion[str, bytes]
-0000c790: 5d20 3d20 4e6f 6e65 2c0a 2020 2020 2020  ] = None,.      
-0000c7a0: 2020 626f 6479 3a20 7479 7069 6e67 2e41    body: typing.A
-0000c7b0: 6e79 203d 204e 6f6e 652c 0a20 2020 2020  ny = None,.     
-0000c7c0: 2020 2066 6965 6c64 733a 2074 7970 696e     fields: typin
-0000c7d0: 672e 4f70 7469 6f6e 616c 5b74 7970 696e  g.Optional[typin
-0000c7e0: 672e 5475 706c 655b 7479 7069 6e67 2e54  g.Tuple[typing.T
-0000c7f0: 7570 6c65 5b73 7472 2c20 7374 725d 2c20  uple[str, str], 
-0000c800: 2e2e 2e5d 5d20 3d20 4e6f 6e65 2c0a 2020  ...]] = None,.  
-0000c810: 2020 2020 2020 6175 7468 5f73 6574 7469        auth_setti
-0000c820: 6e67 733a 2074 7970 696e 672e 4f70 7469  ngs: typing.Opti
-0000c830: 6f6e 616c 5b74 7970 696e 672e 4c69 7374  onal[typing.List
-0000c840: 5b73 7472 5d5d 203d 204e 6f6e 652c 0a20  [str]] = None,. 
-0000c850: 2020 2020 2020 2073 7472 6561 6d3a 2062         stream: b
-0000c860: 6f6f 6c20 3d20 4661 6c73 652c 0a20 2020  ool = False,.   
-0000c870: 2020 2020 2074 696d 656f 7574 3a20 7479       timeout: ty
-0000c880: 7069 6e67 2e4f 7074 696f 6e61 6c5b 7479  ping.Optional[ty
-0000c890: 7069 6e67 2e55 6e69 6f6e 5b66 6c6f 6174  ping.Union[float
-0000c8a0: 2c20 7479 7069 6e67 2e54 7570 6c65 5d5d  , typing.Tuple]]
-0000c8b0: 203d 204e 6f6e 652c 0a20 2020 2020 2020   = None,.       
-0000c8c0: 2068 6f73 743a 2074 7970 696e 672e 4f70   host: typing.Op
-0000c8d0: 7469 6f6e 616c 5b73 7472 5d20 3d20 4e6f  tional[str] = No
-0000c8e0: 6e65 2c0a 2020 2020 2020 2020 7072 6566  ne,.        pref
-0000c8f0: 6978 5f73 6570 6172 6174 6f72 5f69 7465  ix_separator_ite
-0000c900: 7261 746f 723a 2050 7265 6669 7853 6570  rator: PrefixSep
-0000c910: 6172 6174 6f72 4974 6572 6174 6f72 203d  aratorIterator =
-0000c920: 204e 6f6e 652c 0a20 2020 2029 202d 3e20   None,.    ) -> 
-0000c930: 5265 7370 6f6e 7365 5772 6170 7065 723a  ResponseWrapper:
-0000c940: 0a0a 2020 2020 2020 2020 2320 6865 6164  ..        # head
-0000c950: 6572 2070 6172 616d 6574 6572 730a 2020  er parameters.  
-0000c960: 2020 2020 2020 7573 6564 5f68 6561 6465        used_heade
-0000c970: 7273 203d 2048 5454 5048 6561 6465 7244  rs = HTTPHeaderD
-0000c980: 6963 7428 7365 6c66 2e64 6566 6175 6c74  ict(self.default
-0000c990: 5f68 6561 6465 7273 290a 2020 2020 2020  _headers).      
-0000c9a0: 2020 6966 2073 656c 662e 636f 6f6b 6965    if self.cookie
-0000c9b0: 3a0a 2020 2020 2020 2020 2020 2020 6865  :.            he
-0000c9c0: 6164 6572 735b 2743 6f6f 6b69 6527 5d20  aders['Cookie'] 
-0000c9d0: 3d20 7365 6c66 2e63 6f6f 6b69 650a 0a20  = self.cookie.. 
-0000c9e0: 2020 2020 2020 2023 2061 7574 6820 7365         # auth se
-0000c9f0: 7474 696e 670a 2020 2020 2020 2020 7265  tting.        re
-0000ca00: 736f 7572 6365 5f70 6174 685f 7265 6620  source_path_ref 
-0000ca10: 3d20 5b73 656c 662e 7570 6461 7465 5f70  = [self.update_p
-0000ca20: 6172 616d 735f 666f 725f 6175 7468 280a  arams_for_auth(.
-0000ca30: 2020 2020 2020 2020 2020 2020 7573 6564              used
-0000ca40: 5f68 6561 6465 7273 2c0a 2020 2020 2020  _headers,.      
-0000ca50: 2020 2020 2020 6175 7468 5f73 6574 7469        auth_setti
-0000ca60: 6e67 732c 0a20 2020 2020 2020 2020 2020  ngs,.           
-0000ca70: 2072 6573 6f75 7263 655f 7061 7468 2c0a   resource_path,.
-0000ca80: 2020 2020 2020 2020 2020 2020 6d65 7468              meth
-0000ca90: 6f64 2c0a 2020 2020 2020 2020 2020 2020  od,.            
-0000caa0: 626f 6479 2c0a 2020 2020 2020 2020 2020  body,.          
-0000cab0: 2020 7072 6566 6978 5f73 6570 6172 6174    prefix_separat
-0000cac0: 6f72 5f69 7465 7261 746f 720a 2020 2020  or_iterator.    
-0000cad0: 2020 2020 295d 0a0a 2020 2020 2020 2020      )]..        
-0000cae0: 2320 6d75 7374 2068 6170 7065 6e20 6166  # must happen af
-0000caf0: 7465 7220 636f 6f6b 6965 2073 6574 7469  ter cookie setti
-0000cb00: 6e67 2061 6e64 2061 7574 6820 7365 7474  ng and auth sett
-0000cb10: 696e 6720 696e 2063 6173 6520 7573 6572  ing in case user
-0000cb20: 2069 7320 6f76 6572 7269 6469 6e67 2074   is overriding t
-0000cb30: 686f 7365 0a20 2020 2020 2020 2069 6620  hose.        if 
-0000cb40: 6865 6164 6572 733a 0a20 2020 2020 2020  headers:.       
-0000cb50: 2020 2020 2075 7365 645f 6865 6164 6572       used_header
-0000cb60: 732e 7570 6461 7465 2868 6561 6465 7273  s.update(headers
-0000cb70: 290a 0a20 2020 2020 2020 2072 6571 7565  )..        reque
-0000cb80: 7374 5f62 6566 6f72 655f 7572 6c5f 686f  st_before_url_ho
-0000cb90: 6f6b 280a 2020 2020 2020 2020 2020 2020  ok(.            
-0000cba0: 7265 736f 7572 6365 5f70 6174 685f 7265  resource_path_re
-0000cbb0: 663d 7265 736f 7572 6365 5f70 6174 685f  f=resource_path_
-0000cbc0: 7265 662c 0a20 2020 2020 2020 2020 2020  ref,.           
-0000cbd0: 206d 6574 686f 643d 6d65 7468 6f64 2c0a   method=method,.
-0000cbe0: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
-0000cbf0: 6967 7572 6174 696f 6e3d 7365 6c66 2e63  iguration=self.c
-0000cc00: 6f6e 6669 6775 7261 7469 6f6e 2c0a 2020  onfiguration,.  
-0000cc10: 2020 2020 2020 2020 2020 626f 6479 3d62            body=b
-0000cc20: 6f64 792c 0a20 2020 2020 2020 2020 2020  ody,.           
-0000cc30: 2066 6965 6c64 733d 6669 656c 6473 2c0a   fields=fields,.
-0000cc40: 2020 2020 2020 2020 2020 2020 6175 7468              auth
-0000cc50: 5f73 6574 7469 6e67 733d 6175 7468 5f73  _settings=auth_s
-0000cc60: 6574 7469 6e67 732c 0a20 2020 2020 2020  ettings,.       
-0000cc70: 2020 2020 2068 6561 6465 7273 3d75 7365       headers=use
-0000cc80: 645f 6865 6164 6572 732c 0a20 2020 2020  d_headers,.     
-0000cc90: 2020 2029 0a0a 2020 2020 2020 2020 2320     )..        # 
-0000cca0: 7265 7175 6573 7420 7572 6c0a 2020 2020  request url.    
-0000ccb0: 2020 2020 6966 2068 6f73 7420 6973 204e      if host is N
-0000ccc0: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
-0000ccd0: 2075 726c 203d 2073 656c 662e 636f 6e66   url = self.conf
-0000cce0: 6967 7572 6174 696f 6e2e 686f 7374 202b  iguration.host +
-0000ccf0: 2072 6573 6f75 7263 655f 7061 7468 5f72   resource_path_r
-0000cd00: 6566 5b30 5d0a 2020 2020 2020 2020 656c  ef[0].        el
-0000cd10: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-0000cd20: 2320 7573 6520 7365 7276 6572 2f68 6f73  # use server/hos
-0000cd30: 7420 6465 6669 6e65 6420 696e 2070 6174  t defined in pat
-0000cd40: 6820 6f72 206f 7065 7261 7469 6f6e 2069  h or operation i
-0000cd50: 6e73 7465 6164 0a20 2020 2020 2020 2020  nstead.         
-0000cd60: 2020 2075 726c 203d 2068 6f73 7420 2b20     url = host + 
-0000cd70: 7265 736f 7572 6365 5f70 6174 685f 7265  resource_path_re
-0000cd80: 665b 305d 0a0a 2020 2020 2020 2020 7265  f[0]..        re
-0000cd90: 7175 6573 745f 6166 7465 725f 686f 6f6b  quest_after_hook
-0000cda0: 280a 2020 2020 2020 2020 2020 2020 7265  (.            re
-0000cdb0: 736f 7572 6365 5f70 6174 683d 7265 736f  source_path=reso
-0000cdc0: 7572 6365 5f70 6174 685f 7265 665b 305d  urce_path_ref[0]
-0000cdd0: 2c0a 2020 2020 2020 2020 2020 2020 6d65  ,.            me
-0000cde0: 7468 6f64 3d6d 6574 686f 642c 0a20 2020  thod=method,.   
-0000cdf0: 2020 2020 2020 2020 2063 6f6e 6669 6775           configu
-0000ce00: 7261 7469 6f6e 3d73 656c 662e 636f 6e66  ration=self.conf
-0000ce10: 6967 7572 6174 696f 6e2c 0a20 2020 2020  iguration,.     
-0000ce20: 2020 2020 2020 2062 6f64 793d 626f 6479         body=body
-0000ce30: 2c0a 2020 2020 2020 2020 2020 2020 6669  ,.            fi
-0000ce40: 656c 6473 3d66 6965 6c64 732c 0a20 2020  elds=fields,.   
-0000ce50: 2020 2020 2020 2020 2061 7574 685f 7365           auth_se
-0000ce60: 7474 696e 6773 3d61 7574 685f 7365 7474  ttings=auth_sett
-0000ce70: 696e 6773 2c0a 2020 2020 2020 2020 2020  ings,.          
-0000ce80: 2020 6865 6164 6572 733d 7573 6564 5f68    headers=used_h
-0000ce90: 6561 6465 7273 2c0a 2020 2020 2020 2020  eaders,.        
-0000cea0: 290a 0a20 2020 2020 2020 2023 2070 6572  )..        # per
-0000ceb0: 666f 726d 2072 6571 7565 7374 2061 6e64  form request and
-0000cec0: 2072 6574 7572 6e20 7265 7370 6f6e 7365   return response
-0000ced0: 0a20 2020 2020 2020 2072 6573 706f 6e73  .        respons
-0000cee0: 6520 3d20 7365 6c66 2e72 6571 7565 7374  e = self.request
-0000cef0: 280a 2020 2020 2020 2020 2020 2020 6d65  (.            me
-0000cf00: 7468 6f64 2c0a 2020 2020 2020 2020 2020  thod,.          
-0000cf10: 2020 7572 6c2c 0a20 2020 2020 2020 2020    url,.         
-0000cf20: 2020 2068 6561 6465 7273 3d75 7365 645f     headers=used_
-0000cf30: 6865 6164 6572 732c 0a20 2020 2020 2020  headers,.       
-0000cf40: 2020 2020 2066 6965 6c64 733d 6669 656c       fields=fiel
-0000cf50: 6473 2c0a 2020 2020 2020 2020 2020 2020  ds,.            
-0000cf60: 626f 6479 3d73 6572 6961 6c69 7a65 645f  body=serialized_
-0000cf70: 626f 6479 2c0a 2020 2020 2020 2020 2020  body,.          
-0000cf80: 2020 7374 7265 616d 3d73 7472 6561 6d2c    stream=stream,
-0000cf90: 0a20 2020 2020 2020 2020 2020 2074 696d  .            tim
-0000cfa0: 656f 7574 3d74 696d 656f 7574 2c0a 2020  eout=timeout,.  
-0000cfb0: 2020 2020 2020 290a 0a0a 2020 2020 2020        )...      
-0000cfc0: 2020 7265 7475 726e 2072 6573 706f 6e73    return respons
-0000cfd0: 650a 0a20 2020 2061 7379 6e63 2064 6566  e..    async def
-0000cfe0: 2061 7379 6e63 5f63 616c 6c5f 6170 6928   async_call_api(
-0000cff0: 0a20 2020 2020 2020 2073 656c 662c 0a20  .        self,. 
-0000d000: 2020 2020 2020 2072 6573 6f75 7263 655f         resource_
-0000d010: 7061 7468 3a20 7374 722c 0a20 2020 2020  path: str,.     
-0000d020: 2020 206d 6574 686f 643a 2073 7472 2c0a     method: str,.
-0000d030: 2020 2020 2020 2020 6865 6164 6572 733a          headers:
-0000d040: 2074 7970 696e 672e 4f70 7469 6f6e 616c   typing.Optional
-0000d050: 5b48 5454 5048 6561 6465 7244 6963 745d  [HTTPHeaderDict]
-0000d060: 203d 204e 6f6e 652c 0a20 2020 2020 2020   = None,.       
-0000d070: 2073 6572 6961 6c69 7a65 645f 626f 6479   serialized_body
-0000d080: 3a20 7479 7069 6e67 2e4f 7074 696f 6e61  : typing.Optiona
-0000d090: 6c5b 7479 7069 6e67 2e55 6e69 6f6e 5b73  l[typing.Union[s
-0000d0a0: 7472 2c20 6279 7465 735d 5d20 3d20 4e6f  tr, bytes]] = No
-0000d0b0: 6e65 2c0a 2020 2020 2020 2020 626f 6479  ne,.        body
-0000d0c0: 3a20 7479 7069 6e67 2e41 6e79 203d 204e  : typing.Any = N
-0000d0d0: 6f6e 652c 0a20 2020 2020 2020 2066 6965  one,.        fie
-0000d0e0: 6c64 733a 2074 7970 696e 672e 4f70 7469  lds: typing.Opti
-0000d0f0: 6f6e 616c 5b74 7970 696e 672e 5475 706c  onal[typing.Tupl
-0000d100: 655b 7479 7069 6e67 2e54 7570 6c65 5b73  e[typing.Tuple[s
-0000d110: 7472 2c20 7374 725d 2c20 2e2e 2e5d 5d20  tr, str], ...]] 
-0000d120: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
-0000d130: 6175 7468 5f73 6574 7469 6e67 733a 2074  auth_settings: t
-0000d140: 7970 696e 672e 4f70 7469 6f6e 616c 5b74  yping.Optional[t
-0000d150: 7970 696e 672e 4c69 7374 5b73 7472 5d5d  yping.List[str]]
-0000d160: 203d 204e 6f6e 652c 0a20 2020 2020 2020   = None,.       
-0000d170: 2073 7472 6561 6d3a 2062 6f6f 6c20 3d20   stream: bool = 
-0000d180: 4661 6c73 652c 0a20 2020 2020 2020 2074  False,.        t
-0000d190: 696d 656f 7574 3a20 7479 7069 6e67 2e4f  imeout: typing.O
-0000d1a0: 7074 696f 6e61 6c5b 7479 7069 6e67 2e55  ptional[typing.U
-0000d1b0: 6e69 6f6e 5b66 6c6f 6174 2c20 7479 7069  nion[float, typi
-0000d1c0: 6e67 2e54 7570 6c65 5d5d 203d 204e 6f6e  ng.Tuple]] = Non
-0000d1d0: 652c 0a20 2020 2020 2020 2068 6f73 743a  e,.        host:
-0000d1e0: 2074 7970 696e 672e 4f70 7469 6f6e 616c   typing.Optional
-0000d1f0: 5b73 7472 5d20 3d20 4e6f 6e65 2c0a 2020  [str] = None,.  
-0000d200: 2020 2020 2020 7072 6566 6978 5f73 6570        prefix_sep
-0000d210: 6172 6174 6f72 5f69 7465 7261 746f 723a  arator_iterator:
-0000d220: 2050 7265 6669 7853 6570 6172 6174 6f72   PrefixSeparator
-0000d230: 4974 6572 6174 6f72 203d 204e 6f6e 652c  Iterator = None,
-0000d240: 0a20 2020 2020 2020 202a 2a6b 7761 7267  .        **kwarg
-0000d250: 730a 2020 2020 2920 2d3e 2041 7379 6e63  s.    ) -> Async
-0000d260: 5265 7370 6f6e 7365 5772 6170 7065 723a  ResponseWrapper:
-0000d270: 0a20 2020 2020 2020 2022 2222 4d61 6b65  .        """Make
-0000d280: 7320 7468 6520 4854 5450 2072 6571 7565  s the HTTP reque
-0000d290: 7374 2028 7379 6e63 6872 6f6e 6f75 7329  st (synchronous)
-0000d2a0: 2061 6e64 2072 6574 7572 6e73 2064 6573   and returns des
-0000d2b0: 6572 6961 6c69 7a65 6420 6461 7461 2e0a  erialized data..
-0000d2c0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-0000d2d0: 7265 736f 7572 6365 5f70 6174 683a 2050  resource_path: P
-0000d2e0: 6174 6820 746f 206d 6574 686f 6420 656e  ath to method en
-0000d2f0: 6470 6f69 6e74 2e0a 2020 2020 2020 2020  dpoint..        
-0000d300: 3a70 6172 616d 206d 6574 686f 643a 204d  :param method: M
-0000d310: 6574 686f 6420 746f 2063 616c 6c2e 0a20  ethod to call.. 
-0000d320: 2020 2020 2020 203a 7061 7261 6d20 6865         :param he
-0000d330: 6164 6572 733a 2048 6561 6465 7220 7061  aders: Header pa
-0000d340: 7261 6d65 7465 7273 2074 6f20 6265 0a20  rameters to be. 
-0000d350: 2020 2020 2020 2020 2020 2070 6c61 6365             place
-0000d360: 6420 696e 2074 6865 2072 6571 7565 7374  d in the request
-0000d370: 2068 6561 6465 722e 0a20 2020 2020 2020   header..       
-0000d380: 203a 7061 7261 6d20 626f 6479 3a20 5265   :param body: Re
-0000d390: 7175 6573 7420 626f 6479 2e0a 2020 2020  quest body..    
-0000d3a0: 2020 2020 3a70 6172 616d 2066 6965 6c64      :param field
-0000d3b0: 733a 2052 6571 7565 7374 2070 6f73 7420  s: Request post 
-0000d3c0: 666f 726d 2070 6172 616d 6574 6572 732c  form parameters,
-0000d3d0: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
-0000d3e0: 2060 6170 706c 6963 6174 696f 6e2f 782d   `application/x-
-0000d3f0: 7777 772d 666f 726d 2d75 726c 656e 636f  www-form-urlenco
-0000d400: 6465 6460 2c20 606d 756c 7469 7061 7274  ded`, `multipart
-0000d410: 2f66 6f72 6d2d 6461 7461 602e 0a20 2020  /form-data`..   
-0000d420: 2020 2020 203a 7061 7261 6d20 6175 7468       :param auth
-0000d430: 5f73 6574 7469 6e67 733a 2041 7574 6820  _settings: Auth 
-0000d440: 5365 7474 696e 6773 206e 616d 6573 2066  Settings names f
-0000d450: 6f72 2074 6865 2072 6571 7565 7374 2e0a  or the request..
-0000d460: 2020 2020 2020 2020 3a70 6172 616d 2073          :param s
-0000d470: 7472 6561 6d3a 2069 6620 5472 7565 2c20  tream: if True, 
-0000d480: 7468 6520 7572 6c6c 6962 332e 4854 5450  the urllib3.HTTP
-0000d490: 5265 7370 6f6e 7365 206f 626a 6563 7420  Response object 
-0000d4a0: 7769 6c6c 0a20 2020 2020 2020 2020 2020  will.           
-0000d4b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d4c0: 2020 2020 2020 6265 2072 6574 7572 6e65        be returne
-0000d4d0: 6420 7769 7468 6f75 7420 7265 6164 696e  d without readin
-0000d4e0: 672f 6465 636f 6469 6e67 2072 6573 706f  g/decoding respo
-0000d4f0: 6e73 650a 2020 2020 2020 2020 2020 2020  nse.            
-0000d500: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d510: 2020 2020 2064 6174 612e 2041 6c73 6f20       data. Also 
-0000d520: 7768 656e 2054 7275 652c 2069 6620 7468  when True, if th
-0000d530: 6520 6f70 656e 6170 6920 7370 6563 2064  e openapi spec d
-0000d540: 6573 6372 6962 6573 2061 2066 696c 6520  escribes a file 
-0000d550: 646f 776e 6c6f 6164 2c0a 2020 2020 2020  download,.      
-0000d560: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d570: 2020 2020 2020 2020 2020 2074 6865 2064             the d
-0000d580: 6174 6120 7769 6c6c 2062 6520 7772 6974  ata will be writ
-0000d590: 7465 6e20 746f 2061 206c 6f63 616c 2066  ten to a local f
-0000d5a0: 696c 6573 7973 746d 6520 6669 6c65 2061  ilesystme file a
-0000d5b0: 6e64 2074 6865 2042 696e 6172 7953 6368  nd the BinarySch
-0000d5c0: 656d 610a 2020 2020 2020 2020 2020 2020  ema.            
-0000d5d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d5e0: 2020 2020 2069 6e73 7461 6e63 6520 7769       instance wi
-0000d5f0: 6c6c 2061 6c73 6f20 696e 6865 7269 7420  ll also inherit 
-0000d600: 6672 6f6d 2046 696c 6553 6368 656d 6120  from FileSchema 
-0000d610: 616e 6420 4669 6c65 494f 0a20 2020 2020  and FileIO.     
-0000d620: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d630: 2020 2020 2020 2020 2020 2020 4465 6661              Defa
-0000d640: 756c 7420 6973 2046 616c 7365 2e0a 2020  ult is False..  
-0000d650: 2020 2020 2020 3a74 7970 6520 7374 7265        :type stre
-0000d660: 616d 3a20 626f 6f6c 2c20 6f70 7469 6f6e  am: bool, option
-0000d670: 616c 0a20 2020 2020 2020 203a 7061 7261  al.        :para
-0000d680: 6d20 7469 6d65 6f75 743a 2074 696d 656f  m timeout: timeo
-0000d690: 7574 2073 6574 7469 6e67 2066 6f72 2074  ut setting for t
-0000d6a0: 6869 7320 7265 7175 6573 742e 2049 6620  his request. If 
-0000d6b0: 6f6e 650a 2020 2020 2020 2020 2020 2020  one.            
-0000d6c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d6d0: 2020 2020 206e 756d 6265 7220 7072 6f76       number prov
-0000d6e0: 6964 6564 2c20 6974 2077 696c 6c20 6265  ided, it will be
-0000d6f0: 2074 6f74 616c 2072 6571 7565 7374 0a20   total request. 
-0000d700: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d720: 7469 6d65 6f75 742e 2049 7420 6361 6e20  timeout. It can 
-0000d730: 616c 736f 2062 6520 6120 7061 6972 2028  also be a pair (
-0000d740: 7475 706c 6529 206f 660a 2020 2020 2020  tuple) of.      
-0000d750: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d760: 2020 2020 2020 2020 2020 2028 636f 6e6e             (conn
-0000d770: 6563 7469 6f6e 2c20 7265 6164 2920 7469  ection, read) ti
-0000d780: 6d65 6f75 7473 2e0a 2020 2020 2020 2020  meouts..        
-0000d790: 3a70 6172 616d 2068 6f73 743a 2061 7069  :param host: api
-0000d7a0: 2065 6e64 706f 696e 7420 686f 7374 0a20   endpoint host. 
-0000d7b0: 2020 2020 2020 203a 7265 7475 726e 3a20         :return: 
-0000d7c0: 7265 7370 6f6e 7365 0a20 2020 2020 2020  response.       
-0000d7d0: 2022 2222 0a20 2020 2020 2020 2072 6574   """.        ret
-0000d7e0: 7572 6e20 6177 6169 7420 7365 6c66 2e5f  urn await self._
-0000d7f0: 5f61 7379 6e63 5f63 616c 6c5f 6170 6928  _async_call_api(
-0000d800: 0a20 2020 2020 2020 2020 2020 2072 6573  .            res
-0000d810: 6f75 7263 655f 7061 7468 2c0a 2020 2020  ource_path,.    
-0000d820: 2020 2020 2020 2020 6d65 7468 6f64 2c0a          method,.
-0000d830: 2020 2020 2020 2020 2020 2020 6865 6164              head
-0000d840: 6572 732c 0a20 2020 2020 2020 2020 2020  ers,.           
-0000d850: 2073 6572 6961 6c69 7a65 645f 626f 6479   serialized_body
-0000d860: 2c0a 2020 2020 2020 2020 2020 2020 626f  ,.            bo
-0000d870: 6479 2c0a 2020 2020 2020 2020 2020 2020  dy,.            
-0000d880: 6669 656c 6473 2c0a 2020 2020 2020 2020  fields,.        
-0000d890: 2020 2020 6175 7468 5f73 6574 7469 6e67      auth_setting
-0000d8a0: 732c 0a20 2020 2020 2020 2020 2020 2073  s,.            s
-0000d8b0: 7472 6561 6d2c 0a20 2020 2020 2020 2020  tream,.         
-0000d8c0: 2020 2074 696d 656f 7574 2c0a 2020 2020     timeout,.    
-0000d8d0: 2020 2020 2020 2020 686f 7374 2c0a 2020          host,.  
-0000d8e0: 2020 2020 2020 2020 2020 7072 6566 6978            prefix
-0000d8f0: 5f73 6570 6172 6174 6f72 5f69 7465 7261  _separator_itera
-0000d900: 746f 722c 0a20 2020 2020 2020 2020 2020  tor,.           
-0000d910: 202a 2a6b 7761 7267 730a 2020 2020 2020   **kwargs.      
-0000d920: 2020 290a 0a20 2020 2064 6566 2063 616c    )..    def cal
-0000d930: 6c5f 6170 6928 0a20 2020 2020 2020 2073  l_api(.        s
-0000d940: 656c 662c 0a20 2020 2020 2020 2072 6573  elf,.        res
-0000d950: 6f75 7263 655f 7061 7468 3a20 7374 722c  ource_path: str,
-0000d960: 0a20 2020 2020 2020 206d 6574 686f 643a  .        method:
-0000d970: 2073 7472 2c0a 2020 2020 2020 2020 6865   str,.        he
-0000d980: 6164 6572 733a 2074 7970 696e 672e 4f70  aders: typing.Op
-0000d990: 7469 6f6e 616c 5b48 5454 5048 6561 6465  tional[HTTPHeade
-0000d9a0: 7244 6963 745d 203d 204e 6f6e 652c 0a20  rDict] = None,. 
-0000d9b0: 2020 2020 2020 2073 6572 6961 6c69 7a65         serialize
-0000d9c0: 645f 626f 6479 3a20 7479 7069 6e67 2e4f  d_body: typing.O
-0000d9d0: 7074 696f 6e61 6c5b 7479 7069 6e67 2e55  ptional[typing.U
-0000d9e0: 6e69 6f6e 5b73 7472 2c20 6279 7465 735d  nion[str, bytes]
-0000d9f0: 5d20 3d20 4e6f 6e65 2c0a 2020 2020 2020  ] = None,.      
-0000da00: 2020 626f 6479 3a20 7479 7069 6e67 2e41    body: typing.A
-0000da10: 6e79 203d 204e 6f6e 652c 0a20 2020 2020  ny = None,.     
-0000da20: 2020 2066 6965 6c64 733a 2074 7970 696e     fields: typin
-0000da30: 672e 4f70 7469 6f6e 616c 5b74 7970 696e  g.Optional[typin
-0000da40: 672e 5475 706c 655b 7479 7069 6e67 2e54  g.Tuple[typing.T
-0000da50: 7570 6c65 5b73 7472 2c20 7374 725d 2c20  uple[str, str], 
-0000da60: 2e2e 2e5d 5d20 3d20 4e6f 6e65 2c0a 2020  ...]] = None,.  
-0000da70: 2020 2020 2020 6175 7468 5f73 6574 7469        auth_setti
-0000da80: 6e67 733a 2074 7970 696e 672e 4f70 7469  ngs: typing.Opti
-0000da90: 6f6e 616c 5b74 7970 696e 672e 4c69 7374  onal[typing.List
-0000daa0: 5b73 7472 5d5d 203d 204e 6f6e 652c 0a20  [str]] = None,. 
-0000dab0: 2020 2020 2020 2073 7472 6561 6d3a 2062         stream: b
-0000dac0: 6f6f 6c20 3d20 4661 6c73 652c 0a20 2020  ool = False,.   
-0000dad0: 2020 2020 2074 696d 656f 7574 3a20 7479       timeout: ty
-0000dae0: 7069 6e67 2e4f 7074 696f 6e61 6c5b 7479  ping.Optional[ty
-0000daf0: 7069 6e67 2e55 6e69 6f6e 5b66 6c6f 6174  ping.Union[float
-0000db00: 2c20 7479 7069 6e67 2e54 7570 6c65 5d5d  , typing.Tuple]]
-0000db10: 203d 204e 6f6e 652c 0a20 2020 2020 2020   = None,.       
-0000db20: 2068 6f73 743a 2074 7970 696e 672e 4f70   host: typing.Op
-0000db30: 7469 6f6e 616c 5b73 7472 5d20 3d20 4e6f  tional[str] = No
-0000db40: 6e65 2c0a 2020 2020 2020 2020 7072 6566  ne,.        pref
-0000db50: 6978 5f73 6570 6172 6174 6f72 5f69 7465  ix_separator_ite
-0000db60: 7261 746f 723a 2050 7265 6669 7853 6570  rator: PrefixSep
-0000db70: 6172 6174 6f72 4974 6572 6174 6f72 203d  aratorIterator =
-0000db80: 204e 6f6e 652c 0a20 2020 2029 202d 3e20   None,.    ) -> 
-0000db90: 5265 7370 6f6e 7365 5772 6170 7065 723a  ResponseWrapper:
-0000dba0: 0a20 2020 2020 2020 2022 2222 4d61 6b65  .        """Make
-0000dbb0: 7320 7468 6520 4854 5450 2072 6571 7565  s the HTTP reque
-0000dbc0: 7374 2028 7379 6e63 6872 6f6e 6f75 7329  st (synchronous)
-0000dbd0: 2061 6e64 2072 6574 7572 6e73 2064 6573   and returns des
-0000dbe0: 6572 6961 6c69 7a65 6420 6461 7461 2e0a  erialized data..
-0000dbf0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-0000dc00: 7265 736f 7572 6365 5f70 6174 683a 2050  resource_path: P
-0000dc10: 6174 6820 746f 206d 6574 686f 6420 656e  ath to method en
-0000dc20: 6470 6f69 6e74 2e0a 2020 2020 2020 2020  dpoint..        
-0000dc30: 3a70 6172 616d 206d 6574 686f 643a 204d  :param method: M
-0000dc40: 6574 686f 6420 746f 2063 616c 6c2e 0a20  ethod to call.. 
-0000dc50: 2020 2020 2020 203a 7061 7261 6d20 6865         :param he
-0000dc60: 6164 6572 733a 2048 6561 6465 7220 7061  aders: Header pa
-0000dc70: 7261 6d65 7465 7273 2074 6f20 6265 0a20  rameters to be. 
-0000dc80: 2020 2020 2020 2020 2020 2070 6c61 6365             place
-0000dc90: 6420 696e 2074 6865 2072 6571 7565 7374  d in the request
-0000dca0: 2068 6561 6465 722e 0a20 2020 2020 2020   header..       
-0000dcb0: 203a 7061 7261 6d20 626f 6479 3a20 5265   :param body: Re
-0000dcc0: 7175 6573 7420 626f 6479 2e0a 2020 2020  quest body..    
-0000dcd0: 2020 2020 3a70 6172 616d 2066 6965 6c64      :param field
-0000dce0: 733a 2052 6571 7565 7374 2070 6f73 7420  s: Request post 
-0000dcf0: 666f 726d 2070 6172 616d 6574 6572 732c  form parameters,
-0000dd00: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
-0000dd10: 2060 6170 706c 6963 6174 696f 6e2f 782d   `application/x-
-0000dd20: 7777 772d 666f 726d 2d75 726c 656e 636f  www-form-urlenco
-0000dd30: 6465 6460 2c20 606d 756c 7469 7061 7274  ded`, `multipart
-0000dd40: 2f66 6f72 6d2d 6461 7461 602e 0a20 2020  /form-data`..   
-0000dd50: 2020 2020 203a 7061 7261 6d20 6175 7468       :param auth
-0000dd60: 5f73 6574 7469 6e67 733a 2041 7574 6820  _settings: Auth 
-0000dd70: 5365 7474 696e 6773 206e 616d 6573 2066  Settings names f
-0000dd80: 6f72 2074 6865 2072 6571 7565 7374 2e0a  or the request..
-0000dd90: 2020 2020 2020 2020 3a70 6172 616d 2073          :param s
-0000dda0: 7472 6561 6d3a 2069 6620 5472 7565 2c20  tream: if True, 
-0000ddb0: 7468 6520 7572 6c6c 6962 332e 4854 5450  the urllib3.HTTP
-0000ddc0: 5265 7370 6f6e 7365 206f 626a 6563 7420  Response object 
-0000ddd0: 7769 6c6c 0a20 2020 2020 2020 2020 2020  will.           
-0000dde0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ddf0: 2020 2020 2020 6265 2072 6574 7572 6e65        be returne
-0000de00: 6420 7769 7468 6f75 7420 7265 6164 696e  d without readin
-0000de10: 672f 6465 636f 6469 6e67 2072 6573 706f  g/decoding respo
-0000de20: 6e73 650a 2020 2020 2020 2020 2020 2020  nse.            
-0000de30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000de40: 2020 2020 2064 6174 612e 2041 6c73 6f20       data. Also 
-0000de50: 7768 656e 2054 7275 652c 2069 6620 7468  when True, if th
-0000de60: 6520 6f70 656e 6170 6920 7370 6563 2064  e openapi spec d
-0000de70: 6573 6372 6962 6573 2061 2066 696c 6520  escribes a file 
-0000de80: 646f 776e 6c6f 6164 2c0a 2020 2020 2020  download,.      
-0000de90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dea0: 2020 2020 2020 2020 2020 2074 6865 2064             the d
-0000deb0: 6174 6120 7769 6c6c 2062 6520 7772 6974  ata will be writ
-0000dec0: 7465 6e20 746f 2061 206c 6f63 616c 2066  ten to a local f
-0000ded0: 696c 6573 7973 746d 6520 6669 6c65 2061  ilesystme file a
-0000dee0: 6e64 2074 6865 2042 696e 6172 7953 6368  nd the BinarySch
-0000def0: 656d 610a 2020 2020 2020 2020 2020 2020  ema.            
-0000df00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000df10: 2020 2020 2069 6e73 7461 6e63 6520 7769       instance wi
-0000df20: 6c6c 2061 6c73 6f20 696e 6865 7269 7420  ll also inherit 
-0000df30: 6672 6f6d 2046 696c 6553 6368 656d 6120  from FileSchema 
-0000df40: 616e 6420 4669 6c65 494f 0a20 2020 2020  and FileIO.     
-0000df50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000df60: 2020 2020 2020 2020 2020 2020 4465 6661              Defa
-0000df70: 756c 7420 6973 2046 616c 7365 2e0a 2020  ult is False..  
-0000df80: 2020 2020 2020 3a74 7970 6520 7374 7265        :type stre
-0000df90: 616d 3a20 626f 6f6c 2c20 6f70 7469 6f6e  am: bool, option
-0000dfa0: 616c 0a20 2020 2020 2020 203a 7061 7261  al.        :para
-0000dfb0: 6d20 7469 6d65 6f75 743a 2074 696d 656f  m timeout: timeo
-0000dfc0: 7574 2073 6574 7469 6e67 2066 6f72 2074  ut setting for t
-0000dfd0: 6869 7320 7265 7175 6573 742e 2049 6620  his request. If 
-0000dfe0: 6f6e 650a 2020 2020 2020 2020 2020 2020  one.            
-0000dff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e000: 2020 2020 206e 756d 6265 7220 7072 6f76       number prov
-0000e010: 6964 6564 2c20 6974 2077 696c 6c20 6265  ided, it will be
-0000e020: 2074 6f74 616c 2072 6571 7565 7374 0a20   total request. 
-0000e030: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e040: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e050: 7469 6d65 6f75 742e 2049 7420 6361 6e20  timeout. It can 
-0000e060: 616c 736f 2062 6520 6120 7061 6972 2028  also be a pair (
-0000e070: 7475 706c 6529 206f 660a 2020 2020 2020  tuple) of.      
-0000e080: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e090: 2020 2020 2020 2020 2020 2028 636f 6e6e             (conn
-0000e0a0: 6563 7469 6f6e 2c20 7265 6164 2920 7469  ection, read) ti
-0000e0b0: 6d65 6f75 7473 2e0a 2020 2020 2020 2020  meouts..        
-0000e0c0: 3a70 6172 616d 2068 6f73 743a 2061 7069  :param host: api
-0000e0d0: 2065 6e64 706f 696e 7420 686f 7374 0a20   endpoint host. 
-0000e0e0: 2020 2020 2020 203a 7265 7475 726e 3a20         :return: 
-0000e0f0: 7265 7370 6f6e 7365 0a20 2020 2020 2020  response.       
-0000e100: 2022 2222 0a20 2020 2020 2020 2072 6574   """.        ret
-0000e110: 7572 6e20 7365 6c66 2e5f 5f63 616c 6c5f  urn self.__call_
-0000e120: 6170 6928 0a20 2020 2020 2020 2020 2020  api(.           
-0000e130: 2072 6573 6f75 7263 655f 7061 7468 2c0a   resource_path,.
-0000e140: 2020 2020 2020 2020 2020 2020 6d65 7468              meth
-0000e150: 6f64 2c0a 2020 2020 2020 2020 2020 2020  od,.            
-0000e160: 6865 6164 6572 732c 0a20 2020 2020 2020  headers,.       
-0000e170: 2020 2020 2073 6572 6961 6c69 7a65 645f       serialized_
-0000e180: 626f 6479 2c0a 2020 2020 2020 2020 2020  body,.          
-0000e190: 2020 626f 6479 2c0a 2020 2020 2020 2020    body,.        
-0000e1a0: 2020 2020 6669 656c 6473 2c0a 2020 2020      fields,.    
-0000e1b0: 2020 2020 2020 2020 6175 7468 5f73 6574          auth_set
-0000e1c0: 7469 6e67 732c 0a20 2020 2020 2020 2020  tings,.         
-0000e1d0: 2020 2073 7472 6561 6d2c 0a20 2020 2020     stream,.     
-0000e1e0: 2020 2020 2020 2074 696d 656f 7574 2c0a         timeout,.
-0000e1f0: 2020 2020 2020 2020 2020 2020 686f 7374              host
-0000e200: 2c0a 2020 2020 2020 2020 2020 2020 7072  ,.            pr
-0000e210: 6566 6978 5f73 6570 6172 6174 6f72 5f69  efix_separator_i
-0000e220: 7465 7261 746f 722c 0a20 2020 2020 2020  terator,.       
-0000e230: 2029 0a0a 2020 2020 6465 6620 6669 656c   )..    def fiel
-0000e240: 6473 5f74 6f5f 6469 6374 2873 656c 662c  ds_to_dict(self,
-0000e250: 2066 6965 6c64 733a 2074 7970 696e 672e   fields: typing.
-0000e260: 4f70 7469 6f6e 616c 5b74 7970 696e 672e  Optional[typing.
-0000e270: 5475 706c 655b 7479 7069 6e67 2e54 7570  Tuple[typing.Tup
-0000e280: 6c65 5b73 7472 2c20 7374 725d 2c20 2e2e  le[str, str], ..
-0000e290: 2e5d 5d29 3a0a 2020 2020 2020 2020 2222  .]]):.        ""
-0000e2a0: 2243 6f6e 7665 7274 7320 6669 656c 6473  "Converts fields
-0000e2b0: 2074 6f20 6469 6374 2e0a 0a20 2020 2020   to dict...     
-0000e2c0: 2020 203a 7061 7261 6d20 6669 656c 6473     :param fields
-0000e2d0: 3a20 6669 656c 6473 0a20 2020 2020 2020  : fields.       
-0000e2e0: 203a 7265 7475 726e 3a20 6469 6374 0a20   :return: dict. 
-0000e2f0: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
-0000e300: 2020 2069 6620 6669 656c 6473 2069 7320     if fields is 
-0000e310: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
-0000e320: 2020 7265 7475 726e 204e 6f6e 650a 2020    return None.  
-0000e330: 2020 2020 2020 7265 7475 726e 207b 6b3a        return {k:
-0000e340: 2076 2066 6f72 206b 2c20 7620 696e 2066   v for k, v in f
-0000e350: 6965 6c64 737d 0a0a 2020 2020 6173 796e  ields}..    asyn
-0000e360: 6320 6465 6620 6173 796e 635f 7265 7175  c def async_requ
-0000e370: 6573 7428 0a20 2020 2020 2020 2073 656c  est(.        sel
-0000e380: 662c 0a20 2020 2020 2020 206d 6574 686f  f,.        metho
-0000e390: 643a 2073 7472 2c0a 2020 2020 2020 2020  d: str,.        
-0000e3a0: 7572 6c3a 2073 7472 2c0a 2020 2020 2020  url: str,.      
-0000e3b0: 2020 6865 6164 6572 733a 2074 7970 696e    headers: typin
-0000e3c0: 672e 4f70 7469 6f6e 616c 5b48 5454 5048  g.Optional[HTTPH
-0000e3d0: 6561 6465 7244 6963 745d 203d 204e 6f6e  eaderDict] = Non
-0000e3e0: 652c 0a20 2020 2020 2020 2066 6965 6c64  e,.        field
-0000e3f0: 733a 2074 7970 696e 672e 4f70 7469 6f6e  s: typing.Option
-0000e400: 616c 5b74 7970 696e 672e 5475 706c 655b  al[typing.Tuple[
-0000e410: 7479 7069 6e67 2e54 7570 6c65 5b73 7472  typing.Tuple[str
-0000e420: 2c20 7374 725d 2c20 2e2e 2e5d 5d20 3d20  , str], ...]] = 
-0000e430: 4e6f 6e65 2c0a 2020 2020 2020 2020 626f  None,.        bo
-0000e440: 6479 3a20 7479 7069 6e67 2e4f 7074 696f  dy: typing.Optio
-0000e450: 6e61 6c5b 7479 7069 6e67 2e55 6e69 6f6e  nal[typing.Union
-0000e460: 5b73 7472 2c20 6279 7465 735d 5d20 3d20  [str, bytes]] = 
-0000e470: 4e6f 6e65 2c0a 2020 2020 2020 2020 7374  None,.        st
-0000e480: 7265 616d 3a20 626f 6f6c 203d 2046 616c  ream: bool = Fal
-0000e490: 7365 2c0a 2020 2020 2020 2020 7469 6d65  se,.        time
-0000e4a0: 6f75 743a 2074 7970 696e 672e 4f70 7469  out: typing.Opti
-0000e4b0: 6f6e 616c 5b74 7970 696e 672e 556e 696f  onal[typing.Unio
-0000e4c0: 6e5b 666c 6f61 742c 2074 7970 696e 672e  n[float, typing.
-0000e4d0: 5475 706c 655d 5d20 3d20 4e6f 6e65 2c0a  Tuple]] = None,.
-0000e4e0: 2020 2020 2020 2020 2a2a 6b77 6172 6773          **kwargs
-0000e4f0: 0a20 2020 2029 202d 3e20 4173 796e 6352  .    ) -> AsyncR
-0000e500: 6573 706f 6e73 6557 7261 7070 6572 3a0a  esponseWrapper:.
-0000e510: 2020 2020 2020 2020 6966 2062 6f64 7920          if body 
-0000e520: 616e 6420 6669 656c 6473 3a0a 2020 2020  and fields:.    
-0000e530: 2020 2020 2020 2020 7261 6973 6520 4170          raise Ap
-0000e540: 6956 616c 7565 4572 726f 7228 2262 6f64  iValueError("bod
-0000e550: 7920 7061 7261 6d65 7465 7220 6361 6e6e  y parameter cann
-0000e560: 6f74 2062 6520 7573 6564 2077 6974 6820  ot be used with 
-0000e570: 6669 656c 6473 2070 6172 616d 6574 6572  fields parameter
-0000e580: 2229 0a20 2020 2020 2020 2064 6174 6120  ").        data 
-0000e590: 3d20 4e6f 6e65 0a20 2020 2020 2020 2069  = None.        i
-0000e5a0: 6620 626f 6479 3a0a 2020 2020 2020 2020  f body:.        
-0000e5b0: 2020 2020 6461 7461 3d62 6f64 790a 2020      data=body.  
-0000e5c0: 2020 2020 2020 6966 2066 6965 6c64 733a        if fields:
-0000e5d0: 0a20 2020 2020 2020 2020 2020 2064 6174  .            dat
-0000e5e0: 613d 7365 6c66 2e66 6965 6c64 735f 746f  a=self.fields_to
-0000e5f0: 5f64 6963 7428 6669 656c 6473 290a 2020  _dict(fields).  
-0000e600: 2020 2020 2020 7365 7373 696f 6e20 3d20        session = 
-0000e610: 6169 6f68 7474 702e 436c 6965 6e74 5365  aiohttp.ClientSe
-0000e620: 7373 696f 6e28 290a 2020 2020 2020 2020  ssion().        
-0000e630: 7431 203d 2074 696d 652e 7469 6d65 2829  t1 = time.time()
-0000e640: 0a20 2020 2020 2020 2069 6620 6d65 7468  .        if meth
-0000e650: 6f64 203d 3d20 2247 4554 223a 0a20 2020  od == "GET":.   
-0000e660: 2020 2020 2020 2020 2072 6573 706f 6e73           respons
-0000e670: 6520 3d20 6177 6169 7420 7365 7373 696f  e = await sessio
-0000e680: 6e2e 6765 7428 7572 6c2c 2068 6561 6465  n.get(url, heade
-0000e690: 7273 3d68 6561 6465 7273 2c20 7469 6d65  rs=headers, time
-0000e6a0: 6f75 743d 7469 6d65 6f75 742c 202a 2a6b  out=timeout, **k
-0000e6b0: 7761 7267 7329 0a20 2020 2020 2020 2020  wargs).         
-0000e6c0: 2020 2072 6574 7572 6e20 4173 796e 6352     return AsyncR
-0000e6d0: 6573 706f 6e73 6557 7261 7070 6572 2872  esponseWrapper(r
-0000e6e0: 6573 706f 6e73 652c 2074 696d 652e 7469  esponse, time.ti
-0000e6f0: 6d65 2829 202d 2074 312c 2073 6573 7369  me() - t1, sessi
-0000e700: 6f6e 290a 2020 2020 2020 2020 656c 6966  on).        elif
-0000e710: 206d 6574 686f 6420 3d3d 2022 4845 4144   method == "HEAD
-0000e720: 223a 0a20 2020 2020 2020 2020 2020 2072  ":.            r
-0000e730: 6573 706f 6e73 6520 3d20 6177 6169 7420  esponse = await 
-0000e740: 7365 7373 696f 6e2e 6865 6164 2875 726c  session.head(url
-0000e750: 2c20 6865 6164 6572 733d 6865 6164 6572  , headers=header
-0000e760: 732c 2074 696d 656f 7574 3d74 696d 656f  s, timeout=timeo
-0000e770: 7574 2c20 2a2a 6b77 6172 6773 290a 2020  ut, **kwargs).  
-0000e780: 2020 2020 2020 2020 2020 7265 7475 726e            return
-0000e790: 2041 7379 6e63 5265 7370 6f6e 7365 5772   AsyncResponseWr
-0000e7a0: 6170 7065 7228 7265 7370 6f6e 7365 2c20  apper(response, 
-0000e7b0: 7469 6d65 2e74 696d 6528 2920 2d20 7431  time.time() - t1
-0000e7c0: 2c20 7365 7373 696f 6e29 0a20 2020 2020  , session).     
-0000e7d0: 2020 2065 6c69 6620 6d65 7468 6f64 203d     elif method =
-0000e7e0: 3d20 224f 5054 494f 4e53 223a 0a20 2020  = "OPTIONS":.   
-0000e7f0: 2020 2020 2020 2020 2072 6573 706f 6e73           respons
-0000e800: 6520 3d20 6177 6169 7420 7365 7373 696f  e = await sessio
-0000e810: 6e2e 6f70 7469 6f6e 7328 7572 6c2c 2064  n.options(url, d
-0000e820: 6174 613d 6461 7461 2c20 6865 6164 6572  ata=data, header
-0000e830: 733d 6865 6164 6572 732c 2074 696d 656f  s=headers, timeo
-0000e840: 7574 3d74 696d 656f 7574 2c20 2a2a 6b77  ut=timeout, **kw
-0000e850: 6172 6773 290a 2020 2020 2020 2020 2020  args).          
-0000e860: 2020 7265 7475 726e 2041 7379 6e63 5265    return AsyncRe
-0000e870: 7370 6f6e 7365 5772 6170 7065 7228 7265  sponseWrapper(re
-0000e880: 7370 6f6e 7365 2c20 7469 6d65 2e74 696d  sponse, time.tim
-0000e890: 6528 2920 2d20 7431 2c20 7365 7373 696f  e() - t1, sessio
-0000e8a0: 6e29 0a20 2020 2020 2020 2065 6c69 6620  n).        elif 
-0000e8b0: 6d65 7468 6f64 203d 3d20 2250 4f53 5422  method == "POST"
-0000e8c0: 3a0a 2020 2020 2020 2020 2020 2020 7265  :.            re
-0000e8d0: 7370 6f6e 7365 203d 2061 7761 6974 2073  sponse = await s
-0000e8e0: 6573 7369 6f6e 2e70 6f73 7428 7572 6c2c  ession.post(url,
-0000e8f0: 2064 6174 613d 6461 7461 2c20 6865 6164   data=data, head
-0000e900: 6572 733d 6865 6164 6572 732c 2074 696d  ers=headers, tim
-0000e910: 656f 7574 3d74 696d 656f 7574 2c20 2a2a  eout=timeout, **
-0000e920: 6b77 6172 6773 290a 2020 2020 2020 2020  kwargs).        
-0000e930: 2020 2020 7265 7475 726e 2041 7379 6e63      return Async
-0000e940: 5265 7370 6f6e 7365 5772 6170 7065 7228  ResponseWrapper(
-0000e950: 7265 7370 6f6e 7365 2c20 7469 6d65 2e74  response, time.t
-0000e960: 696d 6528 2920 2d20 7431 2c20 7365 7373  ime() - t1, sess
-0000e970: 696f 6e29 0a20 2020 2020 2020 2065 6c69  ion).        eli
-0000e980: 6620 6d65 7468 6f64 203d 3d20 2250 5554  f method == "PUT
-0000e990: 223a 0a20 2020 2020 2020 2020 2020 2072  ":.            r
-0000e9a0: 6573 706f 6e73 6520 3d20 6177 6169 7420  esponse = await 
-0000e9b0: 7365 7373 696f 6e2e 7075 7428 7572 6c2c  session.put(url,
-0000e9c0: 2064 6174 613d 6461 7461 2c20 6865 6164   data=data, head
-0000e9d0: 6572 733d 6865 6164 6572 732c 2074 696d  ers=headers, tim
-0000e9e0: 656f 7574 3d74 696d 656f 7574 2c20 2a2a  eout=timeout, **
-0000e9f0: 6b77 6172 6773 290a 2020 2020 2020 2020  kwargs).        
-0000ea00: 2020 2020 7265 7475 726e 2041 7379 6e63      return Async
-0000ea10: 5265 7370 6f6e 7365 5772 6170 7065 7228  ResponseWrapper(
-0000ea20: 7265 7370 6f6e 7365 2c20 7469 6d65 2e74  response, time.t
-0000ea30: 696d 6528 2920 2d20 7431 2c20 7365 7373  ime() - t1, sess
-0000ea40: 696f 6e29 0a20 2020 2020 2020 2065 6c69  ion).        eli
-0000ea50: 6620 6d65 7468 6f64 203d 3d20 2250 4154  f method == "PAT
-0000ea60: 4348 223a 0a20 2020 2020 2020 2020 2020  CH":.           
-0000ea70: 2072 6573 706f 6e73 6520 3d20 6177 6169   response = awai
-0000ea80: 7420 7365 7373 696f 6e2e 7061 7463 6828  t session.patch(
-0000ea90: 7572 6c2c 2064 6174 613d 6461 7461 2c20  url, data=data, 
-0000eaa0: 6865 6164 6572 733d 6865 6164 6572 732c  headers=headers,
-0000eab0: 2074 696d 656f 7574 3d74 696d 656f 7574   timeout=timeout
-0000eac0: 2c20 2a2a 6b77 6172 6773 290a 2020 2020  , **kwargs).    
-0000ead0: 2020 2020 2020 2020 7265 7475 726e 2041          return A
-0000eae0: 7379 6e63 5265 7370 6f6e 7365 5772 6170  syncResponseWrap
-0000eaf0: 7065 7228 7265 7370 6f6e 7365 2c20 7469  per(response, ti
-0000eb00: 6d65 2e74 696d 6528 2920 2d20 7431 2c20  me.time() - t1, 
-0000eb10: 7365 7373 696f 6e29 0a20 2020 2020 2020  session).       
-0000eb20: 2065 6c69 6620 6d65 7468 6f64 203d 3d20   elif method == 
-0000eb30: 2244 454c 4554 4522 3a0a 2020 2020 2020  "DELETE":.      
-0000eb40: 2020 2020 2020 7265 7370 6f6e 7365 203d        response =
-0000eb50: 2061 7761 6974 2073 6573 7369 6f6e 2e64   await session.d
-0000eb60: 656c 6574 6528 7572 6c2c 2064 6174 613d  elete(url, data=
-0000eb70: 6461 7461 2c20 6865 6164 6572 733d 6865  data, headers=he
-0000eb80: 6164 6572 732c 2074 696d 656f 7574 3d74  aders, timeout=t
-0000eb90: 696d 656f 7574 2c20 2a2a 6b77 6172 6773  imeout, **kwargs
-0000eba0: 290a 2020 2020 2020 2020 2020 2020 7265  ).            re
-0000ebb0: 7475 726e 2041 7379 6e63 5265 7370 6f6e  turn AsyncRespon
-0000ebc0: 7365 5772 6170 7065 7228 7265 7370 6f6e  seWrapper(respon
-0000ebd0: 7365 2c20 7469 6d65 2e74 696d 6528 2920  se, time.time() 
-0000ebe0: 2d20 7431 2c20 7365 7373 696f 6e29 0a20  - t1, session). 
-0000ebf0: 2020 2020 2020 2072 6169 7365 2041 7069         raise Api
-0000ec00: 5661 6c75 6545 7272 6f72 280a 2020 2020  ValueError(.    
-0000ec10: 2020 2020 2020 2020 2268 7474 7020 6d65          "http me
-0000ec20: 7468 6f64 206d 7573 7420 6265 2060 4745  thod must be `GE
-0000ec30: 5460 2c20 6048 4541 4460 2c20 604f 5054  T`, `HEAD`, `OPT
-0000ec40: 494f 4e53 602c 220a 2020 2020 2020 2020  IONS`,".        
-0000ec50: 2020 2020 2220 6050 4f53 5460 2c20 6050      " `POST`, `P
-0000ec60: 4154 4348 602c 2060 5055 5460 206f 7220  ATCH`, `PUT` or 
-0000ec70: 6044 454c 4554 4560 2e22 0a20 2020 2020  `DELETE`.".     
-0000ec80: 2020 2029 0a0a 2020 2020 6465 6620 7265     )..    def re
-0000ec90: 7175 6573 7428 0a20 2020 2020 2020 2073  quest(.        s
-0000eca0: 656c 662c 0a20 2020 2020 2020 206d 6574  elf,.        met
-0000ecb0: 686f 643a 2073 7472 2c0a 2020 2020 2020  hod: str,.      
-0000ecc0: 2020 7572 6c3a 2073 7472 2c0a 2020 2020    url: str,.    
-0000ecd0: 2020 2020 6865 6164 6572 733a 2074 7970      headers: typ
-0000ece0: 696e 672e 4f70 7469 6f6e 616c 5b48 5454  ing.Optional[HTT
-0000ecf0: 5048 6561 6465 7244 6963 745d 203d 204e  PHeaderDict] = N
-0000ed00: 6f6e 652c 0a20 2020 2020 2020 2066 6965  one,.        fie
-0000ed10: 6c64 733a 2074 7970 696e 672e 4f70 7469  lds: typing.Opti
-0000ed20: 6f6e 616c 5b74 7970 696e 672e 5475 706c  onal[typing.Tupl
-0000ed30: 655b 7479 7069 6e67 2e54 7570 6c65 5b73  e[typing.Tuple[s
-0000ed40: 7472 2c20 7374 725d 2c20 2e2e 2e5d 5d20  tr, str], ...]] 
-0000ed50: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
-0000ed60: 626f 6479 3a20 7479 7069 6e67 2e4f 7074  body: typing.Opt
-0000ed70: 696f 6e61 6c5b 7479 7069 6e67 2e55 6e69  ional[typing.Uni
-0000ed80: 6f6e 5b73 7472 2c20 6279 7465 735d 5d20  on[str, bytes]] 
-0000ed90: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
-0000eda0: 7374 7265 616d 3a20 626f 6f6c 203d 2046  stream: bool = F
-0000edb0: 616c 7365 2c0a 2020 2020 2020 2020 7469  alse,.        ti
-0000edc0: 6d65 6f75 743a 2074 7970 696e 672e 4f70  meout: typing.Op
-0000edd0: 7469 6f6e 616c 5b74 7970 696e 672e 556e  tional[typing.Un
-0000ede0: 696f 6e5b 666c 6f61 742c 2074 7970 696e  ion[float, typin
-0000edf0: 672e 5475 706c 655d 5d20 3d20 4e6f 6e65  g.Tuple]] = None
-0000ee00: 2c0a 2020 2020 2920 2d3e 2052 6573 706f  ,.    ) -> Respo
-0000ee10: 6e73 6557 7261 7070 6572 3a0a 2020 2020  nseWrapper:.    
-0000ee20: 2020 2020 2222 224d 616b 6573 2074 6865      """Makes the
-0000ee30: 2048 5454 5020 7265 7175 6573 7420 7573   HTTP request us
-0000ee40: 696e 6720 5245 5354 436c 6965 6e74 2e22  ing RESTClient."
-0000ee50: 2222 0a20 2020 2020 2020 2069 6620 6d65  "".        if me
-0000ee60: 7468 6f64 203d 3d20 2247 4554 223a 0a20  thod == "GET":. 
-0000ee70: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-0000ee80: 6e20 7365 6c66 2e72 6573 745f 636c 6965  n self.rest_clie
-0000ee90: 6e74 2e47 4554 2875 726c 2c0a 2020 2020  nt.GET(url,.    
-0000eea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000eeb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000eec0: 2020 2020 7374 7265 616d 3d73 7472 6561      stream=strea
-0000eed0: 6d2c 0a20 2020 2020 2020 2020 2020 2020  m,.             
-0000eee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000eef0: 2020 2020 2020 2020 2020 2074 696d 656f             timeo
-0000ef00: 7574 3d74 696d 656f 7574 2c0a 2020 2020  ut=timeout,.    
-0000ef10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ef20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ef30: 2020 2020 6865 6164 6572 733d 6865 6164      headers=head
-0000ef40: 6572 7329 0a20 2020 2020 2020 2065 6c69  ers).        eli
-0000ef50: 6620 6d65 7468 6f64 203d 3d20 2248 4541  f method == "HEA
-0000ef60: 4422 3a0a 2020 2020 2020 2020 2020 2020  D":.            
-0000ef70: 7265 7475 726e 2073 656c 662e 7265 7374  return self.rest
-0000ef80: 5f63 6c69 656e 742e 4845 4144 2875 726c  _client.HEAD(url
-0000ef90: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-0000efa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000efb0: 2020 2020 2020 2020 2020 2073 7472 6561             strea
-0000efc0: 6d3d 7374 7265 616d 2c0a 2020 2020 2020  m=stream,.      
-0000efd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000efe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000eff0: 2020 2074 696d 656f 7574 3d74 696d 656f     timeout=timeo
-0000f000: 7574 2c0a 2020 2020 2020 2020 2020 2020  ut,.            
-0000f010: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f020: 2020 2020 2020 2020 2020 2020 2068 6561               hea
-0000f030: 6465 7273 3d68 6561 6465 7273 290a 2020  ders=headers).  
-0000f040: 2020 2020 2020 656c 6966 206d 6574 686f        elif metho
-0000f050: 6420 3d3d 2022 4f50 5449 4f4e 5322 3a0a  d == "OPTIONS":.
-0000f060: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-0000f070: 726e 2073 656c 662e 7265 7374 5f63 6c69  rn self.rest_cli
-0000f080: 656e 742e 4f50 5449 4f4e 5328 7572 6c2c  ent.OPTIONS(url,
-0000f090: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000f0a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f0b0: 2020 2020 2020 2020 2020 2020 2068 6561               hea
-0000f0c0: 6465 7273 3d68 6561 6465 7273 2c0a 2020  ders=headers,.  
-0000f0d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f0e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f0f0: 2020 2020 2020 2020 2020 6669 656c 6473            fields
-0000f100: 3d66 6965 6c64 732c 0a20 2020 2020 2020  =fields,.       
-0000f110: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f120: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f130: 2020 2020 2073 7472 6561 6d3d 7374 7265       stream=stre
-0000f140: 616d 2c0a 2020 2020 2020 2020 2020 2020  am,.            
-0000f150: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f170: 7469 6d65 6f75 743d 7469 6d65 6f75 742c  timeout=timeout,
-0000f180: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000f190: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f1a0: 2020 2020 2020 2020 2020 2020 2062 6f64               bod
-0000f1b0: 793d 626f 6479 290a 2020 2020 2020 2020  y=body).        
-0000f1c0: 656c 6966 206d 6574 686f 6420 3d3d 2022  elif method == "
-0000f1d0: 504f 5354 223a 0a20 2020 2020 2020 2020  POST":.         
-0000f1e0: 2020 2072 6574 7572 6e20 7365 6c66 2e72     return self.r
-0000f1f0: 6573 745f 636c 6965 6e74 2e50 4f53 5428  est_client.POST(
-0000f200: 7572 6c2c 0a20 2020 2020 2020 2020 2020  url,.           
-0000f210: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f220: 2020 2020 2020 2020 2020 2020 2020 6865                he
-0000f230: 6164 6572 733d 6865 6164 6572 732c 0a20  aders=headers,. 
-0000f240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f250: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f260: 2020 2020 2020 2020 6669 656c 6473 3d66          fields=f
-0000f270: 6965 6c64 732c 0a20 2020 2020 2020 2020  ields,.         
-0000f280: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f290: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f2a0: 7374 7265 616d 3d73 7472 6561 6d2c 0a20  stream=stream,. 
-0000f2b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f2c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f2d0: 2020 2020 2020 2020 7469 6d65 6f75 743d          timeout=
-0000f2e0: 7469 6d65 6f75 742c 0a20 2020 2020 2020  timeout,.       
-0000f2f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f300: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f310: 2020 626f 6479 3d62 6f64 7929 0a20 2020    body=body).   
-0000f320: 2020 2020 2065 6c69 6620 6d65 7468 6f64       elif method
-0000f330: 203d 3d20 2250 5554 223a 0a20 2020 2020   == "PUT":.     
-0000f340: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
-0000f350: 6c66 2e72 6573 745f 636c 6965 6e74 2e50  lf.rest_client.P
-0000f360: 5554 2875 726c 2c0a 2020 2020 2020 2020  UT(url,.        
-0000f370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f380: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f390: 6865 6164 6572 733d 6865 6164 6572 732c  headers=headers,
-0000f3a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000f3b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f3c0: 2020 2020 2020 2020 2066 6965 6c64 733d           fields=
-0000f3d0: 6669 656c 6473 2c0a 2020 2020 2020 2020  fields,.        
-0000f3e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f3f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f400: 7374 7265 616d 3d73 7472 6561 6d2c 0a20  stream=stream,. 
-0000f410: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f420: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f430: 2020 2020 2020 2074 696d 656f 7574 3d74         timeout=t
-0000f440: 696d 656f 7574 2c0a 2020 2020 2020 2020  imeout,.        
-0000f450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f460: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f470: 626f 6479 3d62 6f64 7929 0a20 2020 2020  body=body).     
-0000f480: 2020 2065 6c69 6620 6d65 7468 6f64 203d     elif method =
-0000f490: 3d20 2250 4154 4348 223a 0a20 2020 2020  = "PATCH":.     
-0000f4a0: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
-0000f4b0: 6c66 2e72 6573 745f 636c 6965 6e74 2e50  lf.rest_client.P
-0000f4c0: 4154 4348 2875 726c 2c0a 2020 2020 2020  ATCH(url,.      
-0000f4d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f4e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f4f0: 2020 2020 6865 6164 6572 733d 6865 6164      headers=head
-0000f500: 6572 732c 0a20 2020 2020 2020 2020 2020  ers,.           
-0000f510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f520: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-0000f530: 6965 6c64 733d 6669 656c 6473 2c0a 2020  ields=fields,.  
-0000f540: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f550: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f560: 2020 2020 2020 2020 7374 7265 616d 3d73          stream=s
-0000f570: 7472 6561 6d2c 0a20 2020 2020 2020 2020  tream,.         
-0000f580: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f5a0: 2074 696d 656f 7574 3d74 696d 656f 7574   timeout=timeout
-0000f5b0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-0000f5c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f5d0: 2020 2020 2020 2020 2020 2020 626f 6479              body
-0000f5e0: 3d62 6f64 7929 0a20 2020 2020 2020 2065  =body).        e
-0000f5f0: 6c69 6620 6d65 7468 6f64 203d 3d20 2244  lif method == "D
-0000f600: 454c 4554 4522 3a0a 2020 2020 2020 2020  ELETE":.        
-0000f610: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
-0000f620: 7265 7374 5f63 6c69 656e 742e 4445 4c45  rest_client.DELE
-0000f630: 5445 2875 726c 2c0a 2020 2020 2020 2020  TE(url,.        
-0000f640: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f650: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f660: 2020 2068 6561 6465 7273 3d68 6561 6465     headers=heade
-0000f670: 7273 2c0a 2020 2020 2020 2020 2020 2020  rs,.            
-0000f680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f690: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-0000f6a0: 7472 6561 6d3d 7374 7265 616d 2c0a 2020  tream=stream,.  
-0000f6b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f6c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f6d0: 2020 2020 2020 2020 2074 696d 656f 7574           timeout
-0000f6e0: 3d74 696d 656f 7574 2c0a 2020 2020 2020  =timeout,.      
-0000f6f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f700: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f710: 2020 2020 2062 6f64 793d 626f 6479 290a       body=body).
-0000f720: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-0000f730: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-0000f740: 4170 6956 616c 7565 4572 726f 7228 0a20  ApiValueError(. 
-0000f750: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-0000f760: 6874 7470 206d 6574 686f 6420 6d75 7374  http method must
-0000f770: 2062 6520 6047 4554 602c 2060 4845 4144   be `GET`, `HEAD
-0000f780: 602c 2060 4f50 5449 4f4e 5360 2c22 0a20  `, `OPTIONS`,". 
-0000f790: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-0000f7a0: 2060 504f 5354 602c 2060 5041 5443 4860   `POST`, `PATCH`
-0000f7b0: 2c20 6050 5554 6020 6f72 2060 4445 4c45  , `PUT` or `DELE
-0000f7c0: 5445 602e 220a 2020 2020 2020 2020 2020  TE`.".          
-0000f7d0: 2020 290a 0a20 2020 2064 6566 2075 7064    )..    def upd
-0000f7e0: 6174 655f 7061 7261 6d73 5f66 6f72 5f61  ate_params_for_a
-0000f7f0: 7574 6828 0a20 2020 2020 2020 2020 2020  uth(.           
-0000f800: 2073 656c 662c 0a20 2020 2020 2020 2020   self,.         
-0000f810: 2020 2068 6561 6465 7273 2c0a 2020 2020     headers,.    
-0000f820: 2020 2020 2020 2020 6175 7468 5f73 6574          auth_set
-0000f830: 7469 6e67 732c 0a20 2020 2020 2020 2020  tings,.         
-0000f840: 2020 2072 6573 6f75 7263 655f 7061 7468     resource_path
-0000f850: 2c0a 2020 2020 2020 2020 2020 2020 6d65  ,.            me
-0000f860: 7468 6f64 2c0a 2020 2020 2020 2020 2020  thod,.          
-0000f870: 2020 626f 6479 2c0a 2020 2020 2020 2020    body,.        
-0000f880: 2020 2020 7072 6566 6978 5f73 6570 6172      prefix_separ
-0000f890: 6174 6f72 5f69 7465 7261 746f 723a 2050  ator_iterator: P
-0000f8a0: 7265 6669 7853 6570 6172 6174 6f72 4974  refixSeparatorIt
-0000f8b0: 6572 6174 6f72 203d 204e 6f6e 650a 2020  erator = None.  
-0000f8c0: 2020 2020 2020 2920 2d3e 2073 7472 3a0a        ) -> str:.
-0000f8d0: 2020 2020 2020 2020 2222 2255 7064 6174          """Updat
-0000f8e0: 6573 2068 6561 6465 7220 616e 6420 7175  es header and qu
-0000f8f0: 6572 7920 7061 7261 6d73 2062 6173 6564  ery params based
-0000f900: 206f 6e20 6175 7468 656e 7469 6361 7469   on authenticati
-0000f910: 6f6e 2073 6574 7469 6e67 2e0a 0a20 2020  on setting...   
-0000f920: 2020 2020 203a 7061 7261 6d20 6865 6164       :param head
-0000f930: 6572 733a 2048 6561 6465 7220 7061 7261  ers: Header para
-0000f940: 6d65 7465 7273 2064 6963 7420 746f 2062  meters dict to b
-0000f950: 6520 7570 6461 7465 642e 0a20 2020 2020  e updated..     
-0000f960: 2020 203a 7061 7261 6d20 6175 7468 5f73     :param auth_s
-0000f970: 6574 7469 6e67 733a 2041 7574 6865 6e74  ettings: Authent
-0000f980: 6963 6174 696f 6e20 7365 7474 696e 6720  ication setting 
-0000f990: 6964 656e 7469 6669 6572 7320 6c69 7374  identifiers list
-0000f9a0: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
-0000f9b0: 2072 6573 6f75 7263 655f 7061 7468 3a20   resource_path: 
-0000f9c0: 4120 7374 7269 6e67 2072 6570 7265 7365  A string represe
-0000f9d0: 6e74 6174 696f 6e20 6f66 2074 6865 2048  ntation of the H
-0000f9e0: 5454 5020 7265 7175 6573 7420 7265 736f  TTP request reso
-0000f9f0: 7572 6365 2070 6174 682e 0a20 2020 2020  urce path..     
-0000fa00: 2020 203a 7061 7261 6d20 6d65 7468 6f64     :param method
-0000fa10: 3a20 4120 7374 7269 6e67 2072 6570 7265  : A string repre
-0000fa20: 7365 6e74 6174 696f 6e20 6f66 2074 6865  sentation of the
-0000fa30: 2048 5454 5020 7265 7175 6573 7420 6d65   HTTP request me
-0000fa40: 7468 6f64 2e0a 2020 2020 2020 2020 3a70  thod..        :p
-0000fa50: 6172 616d 2062 6f64 793a 2041 206f 626a  aram body: A obj
-0000fa60: 6563 7420 7265 7072 6573 656e 7469 6e67  ect representing
-0000fa70: 2074 6865 2062 6f64 7920 6f66 2074 6865   the body of the
-0000fa80: 2048 5454 5020 7265 7175 6573 742e 0a20   HTTP request.. 
-0000fa90: 2020 2020 2020 2020 2020 2054 6865 206f             The o
-0000faa0: 626a 6563 7420 7479 7065 2069 7320 7468  bject type is th
-0000fab0: 6520 7265 7475 726e 2076 616c 7565 206f  e return value o
-0000fac0: 6620 5f65 6e63 6f64 6572 2e64 6566 6175  f _encoder.defau
-0000fad0: 6c74 2829 2e0a 2020 2020 2020 2020 2222  lt()..        ""
-0000fae0: 220a 2020 2020 2020 2020 6966 206e 6f74  ".        if not
-0000faf0: 2061 7574 685f 7365 7474 696e 6773 3a0a   auth_settings:.
-0000fb00: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-0000fb10: 726e 2072 6573 6f75 7263 655f 7061 7468  rn resource_path
-0000fb20: 0a20 2020 2020 2020 2069 6620 7072 6566  .        if pref
-0000fb30: 6978 5f73 6570 6172 6174 6f72 5f69 7465  ix_separator_ite
-0000fb40: 7261 746f 7220 6973 204e 6f6e 653a 0a20  rator is None:. 
-0000fb50: 2020 2020 2020 2020 2020 2070 7265 6669             prefi
-0000fb60: 785f 7365 7061 7261 746f 725f 6974 6572  x_separator_iter
-0000fb70: 6174 6f72 203d 2050 7265 6669 7853 6570  ator = PrefixSep
-0000fb80: 6172 6174 6f72 4974 6572 6174 6f72 2822  aratorIterator("
-0000fb90: 3f22 2c20 2226 2229 0a0a 2020 2020 2020  ?", "&")..      
-0000fba0: 2020 666f 7220 6175 7468 2069 6e20 6175    for auth in au
-0000fbb0: 7468 5f73 6574 7469 6e67 733a 0a20 2020  th_settings:.   
-0000fbc0: 2020 2020 2020 2020 2061 7574 685f 7365           auth_se
-0000fbd0: 7474 696e 6720 3d20 7365 6c66 2e63 6f6e  tting = self.con
-0000fbe0: 6669 6775 7261 7469 6f6e 2e61 7574 685f  figuration.auth_
-0000fbf0: 7365 7474 696e 6773 2829 2e67 6574 2861  settings().get(a
-0000fc00: 7574 6829 0a20 2020 2020 2020 2020 2020  uth).           
-0000fc10: 2069 6620 6e6f 7420 6175 7468 5f73 6574   if not auth_set
-0000fc20: 7469 6e67 3a0a 2020 2020 2020 2020 2020  ting:.          
-0000fc30: 2020 2020 2020 636f 6e74 696e 7565 0a20        continue. 
-0000fc40: 2020 2020 2020 2020 2020 2069 6620 6175             if au
-0000fc50: 7468 5f73 6574 7469 6e67 5b27 696e 275d  th_setting['in']
-0000fc60: 203d 3d20 2763 6f6f 6b69 6527 3a0a 2020   == 'cookie':.  
-0000fc70: 2020 2020 2020 2020 2020 2020 2020 6865                he
-0000fc80: 6164 6572 732e 6164 6428 2743 6f6f 6b69  aders.add('Cooki
-0000fc90: 6527 2c20 6175 7468 5f73 6574 7469 6e67  e', auth_setting
-0000fca0: 5b27 7661 6c75 6527 5d29 0a20 2020 2020  ['value']).     
-0000fcb0: 2020 2020 2020 2065 6c69 6620 6175 7468         elif auth
-0000fcc0: 5f73 6574 7469 6e67 5b27 696e 275d 203d  _setting['in'] =
-0000fcd0: 3d20 2768 6561 6465 7227 3a0a 2020 2020  = 'header':.    
-0000fce0: 2020 2020 2020 2020 2020 2020 6966 2061              if a
-0000fcf0: 7574 685f 7365 7474 696e 675b 2774 7970  uth_setting['typ
-0000fd00: 6527 5d20 213d 2027 6874 7470 2d73 6967  e'] != 'http-sig
-0000fd10: 6e61 7475 7265 273a 0a20 2020 2020 2020  nature':.       
-0000fd20: 2020 2020 2020 2020 2020 2020 2068 6561               hea
-0000fd30: 6465 7273 2e61 6464 2861 7574 685f 7365  ders.add(auth_se
-0000fd40: 7474 696e 675b 276b 6579 275d 2c20 6175  tting['key'], au
-0000fd50: 7468 5f73 6574 7469 6e67 5b27 7661 6c75  th_setting['valu
-0000fd60: 6527 5d29 0a20 2020 2020 2020 2020 2020  e']).           
-0000fd70: 2065 6c69 6620 6175 7468 5f73 6574 7469   elif auth_setti
-0000fd80: 6e67 5b27 696e 275d 203d 3d20 2771 7565  ng['in'] == 'que
-0000fd90: 7279 273a 0a20 2020 2020 2020 2020 2020  ry':.           
-0000fda0: 2020 2020 2022 2222 2054 4f44 4f20 696d       """ TODO im
-0000fdb0: 706c 656d 656e 7420 6175 7468 2069 6e20  plement auth in 
-0000fdc0: 7175 6572 790a 2020 2020 2020 2020 2020  query.          
-0000fdd0: 2020 2020 2020 6e65 6564 2074 6f20 7061        need to pa
-0000fde0: 7373 2069 6e20 7072 6566 6978 5f73 6570  ss in prefix_sep
-0000fdf0: 6172 6174 6f72 5f69 7465 7261 746f 720a  arator_iterator.
-0000fe00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fe10: 616e 6420 6e65 6564 2074 6f20 6f75 7470  and need to outp
-0000fe20: 7574 2072 6573 6f75 7263 655f 7061 7468  ut resource_path
-0000fe30: 2077 6974 6820 7175 6572 7920 7061 7261   with query para
-0000fe40: 6d73 2061 6464 6564 0a20 2020 2020 2020  ms added.       
-0000fe50: 2020 2020 2020 2020 2022 2222 0a20 2020           """.   
-0000fe60: 2020 2020 2020 2020 2020 2020 2072 6573               res
-0000fe70: 6f75 7263 655f 7061 7468 202b 3d20 5061  ource_path += Pa
-0000fe80: 7261 6d65 7465 7253 6572 6961 6c69 7a65  rameterSerialize
-0000fe90: 7242 6173 652e 5f72 6566 3635 3730 5f65  rBase._ref6570_e
-0000fea0: 7870 616e 7369 6f6e 280a 2020 2020 2020  xpansion(.      
-0000feb0: 2020 2020 2020 2020 2020 2020 2020 7661                va
-0000fec0: 7269 6162 6c65 5f6e 616d 653d 6175 7468  riable_name=auth
-0000fed0: 5f73 6574 7469 6e67 5b27 6b65 7927 5d2c  _setting['key'],
-0000fee0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000fef0: 2020 2020 2069 6e5f 6461 7461 3d61 7574       in_data=aut
-0000ff00: 685f 7365 7474 696e 675b 2776 616c 7565  h_setting['value
-0000ff10: 275d 2c0a 2020 2020 2020 2020 2020 2020  '],.            
-0000ff20: 2020 2020 2020 2020 6578 706c 6f64 653d          explode=
-0000ff30: 4661 6c73 652c 0a20 2020 2020 2020 2020  False,.         
-0000ff40: 2020 2020 2020 2020 2020 2070 6572 6365             perce
-0000ff50: 6e74 5f65 6e63 6f64 653d 4661 6c73 652c  nt_encode=False,
-0000ff60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000ff70: 2020 2020 2070 7265 6669 785f 7365 7061       prefix_sepa
-0000ff80: 7261 746f 725f 6974 6572 6174 6f72 3d70  rator_iterator=p
-0000ff90: 7265 6669 785f 7365 7061 7261 746f 725f  refix_separator_
-0000ffa0: 6974 6572 6174 6f72 0a20 2020 2020 2020  iterator.       
-0000ffb0: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
-0000ffc0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-0000ffd0: 2020 2020 2020 2020 2020 2020 2072 6169               rai
-0000ffe0: 7365 2041 7069 5661 6c75 6545 7272 6f72  se ApiValueError
-0000fff0: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-00010000: 2020 2020 2020 2741 7574 6865 6e74 6963        'Authentic
-00010010: 6174 696f 6e20 746f 6b65 6e20 6d75 7374  ation token must
-00010020: 2062 6520 696e 2060 7175 6572 7960 206f   be in `query` o
-00010030: 7220 6068 6561 6465 7260 270a 2020 2020  r `header`'.    
-00010040: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
-00010050: 2020 2020 2020 7265 7475 726e 2072 6573        return res
-00010060: 6f75 7263 655f 7061 7468 0a0a 0a63 6c61  ource_path...cla
-00010070: 7373 2041 7069 3a0a 2020 2020 2222 224e  ss Api:.    """N
-00010080: 4f54 453a 0a20 2020 2054 6869 7320 636c  OTE:.    This cl
-00010090: 6173 7320 6973 2061 7574 6f20 6765 6e65  ass is auto gene
-000100a0: 7261 7465 6420 6279 204b 6f6e 6669 6720  rated by Konfig 
-000100b0: 2868 7474 7073 3a2f 2f6b 6f6e 6669 6774  (https://konfigt
-000100c0: 6869 732e 636f 6d29 0a20 2020 2022 2222  his.com).    """
-000100d0: 0a0a 2020 2020 6465 6620 5f5f 696e 6974  ..    def __init
-000100e0: 5f5f 2873 656c 662c 2061 7069 5f63 6c69  __(self, api_cli
-000100f0: 656e 743a 2074 7970 696e 672e 4f70 7469  ent: typing.Opti
-00010100: 6f6e 616c 5b41 7069 436c 6965 6e74 5d20  onal[ApiClient] 
-00010110: 3d20 4e6f 6e65 293a 0a20 2020 2020 2020  = None):.       
-00010120: 2069 6620 6170 695f 636c 6965 6e74 2069   if api_client i
-00010130: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
-00010140: 2020 2020 6170 695f 636c 6965 6e74 203d      api_client =
-00010150: 2041 7069 436c 6965 6e74 2829 0a20 2020   ApiClient().   
-00010160: 2020 2020 2073 656c 662e 6170 695f 636c       self.api_cl
-00010170: 6965 6e74 203d 2061 7069 5f63 6c69 656e  ient = api_clien
-00010180: 740a 0a20 2020 2040 7374 6174 6963 6d65  t..    @staticme
-00010190: 7468 6f64 0a20 2020 2064 6566 205f 7665  thod.    def _ve
-000101a0: 7269 6679 5f74 7970 6564 5f64 6963 745f  rify_typed_dict_
-000101b0: 696e 7075 7473 5f6f 6170 6728 636c 733a  inputs_oapg(cls:
-000101c0: 2074 7970 696e 672e 5479 7065 5b74 7970   typing.Type[typ
-000101d0: 696e 675f 6578 7465 6e73 696f 6e73 2e54  ing_extensions.T
-000101e0: 7970 6564 4469 6374 5d2c 2064 6174 613a  ypedDict], data:
-000101f0: 2074 7970 696e 672e 4469 6374 5b73 7472   typing.Dict[str
-00010200: 2c20 7479 7069 6e67 2e41 6e79 5d29 3a0a  , typing.Any]):.
-00010210: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-00010220: 2020 2020 456e 7375 7265 7320 7468 6174      Ensures that
-00010230: 3a0a 2020 2020 2020 2020 2d20 7265 7175  :.        - requ
-00010240: 6972 6564 206b 6579 7320 6172 6520 7072  ired keys are pr
-00010250: 6573 656e 740a 2020 2020 2020 2020 2d20  esent.        - 
-00010260: 6164 6469 7469 6f6e 616c 2070 726f 7065  additional prope
-00010270: 7274 6965 7320 6172 6520 6e6f 7420 696e  rties are not in
-00010280: 7075 740a 2020 2020 2020 2020 2d20 7661  put.        - va
-00010290: 6c75 6520 7374 6f72 6564 2075 6e64 6572  lue stored under
-000102a0: 2072 6571 7569 7265 6420 6b65 7973 2064   required keys d
-000102b0: 6f20 6e6f 7420 6861 7665 2074 6865 2076  o not have the v
-000102c0: 616c 7565 2075 6e73 6574 0a20 2020 2020  alue unset.     
-000102d0: 2020 204e 6f74 653a 2064 6574 6169 6c65     Note: detaile
-000102e0: 6420 7661 6c75 6520 6368 6563 6b69 6e67  d value checking
-000102f0: 2069 7320 646f 6e65 2069 6e20 7363 6865   is done in sche
-00010300: 6d61 2063 6c61 7373 6573 0a20 2020 2020  ma classes.     
-00010310: 2020 2022 2222 0a20 2020 2020 2020 206d     """.        m
-00010320: 6973 7369 6e67 5f72 6571 7569 7265 645f  issing_required_
-00010330: 6b65 7973 203d 205b 5d0a 2020 2020 2020  keys = [].      
-00010340: 2020 7265 7175 6972 6564 5f6b 6579 735f    required_keys_
-00010350: 7769 7468 5f75 6e73 6574 5f76 616c 7565  with_unset_value
-00010360: 7320 3d20 5b5d 0a20 2020 2020 2020 2066  s = [].        f
-00010370: 6f72 2072 6571 7569 7265 645f 6b65 7920  or required_key 
-00010380: 696e 2063 6c73 2e5f 5f72 6571 7569 7265  in cls.__require
-00010390: 645f 6b65 7973 5f5f 3a0a 2020 2020 2020  d_keys__:.      
-000103a0: 2020 2020 2020 6966 2072 6571 7569 7265        if require
-000103b0: 645f 6b65 7920 6e6f 7420 696e 2064 6174  d_key not in dat
-000103c0: 613a 0a20 2020 2020 2020 2020 2020 2020  a:.             
-000103d0: 2020 206d 6973 7369 6e67 5f72 6571 7569     missing_requi
-000103e0: 7265 645f 6b65 7973 2e61 7070 656e 6428  red_keys.append(
-000103f0: 7265 7175 6972 6564 5f6b 6579 290a 2020  required_key).  
-00010400: 2020 2020 2020 2020 2020 2020 2020 636f                co
-00010410: 6e74 696e 7565 0a20 2020 2020 2020 2020  ntinue.         
-00010420: 2020 2076 616c 7565 203d 2064 6174 615b     value = data[
-00010430: 7265 7175 6972 6564 5f6b 6579 5d0a 2020  required_key].  
-00010440: 2020 2020 2020 2020 2020 6966 2076 616c            if val
-00010450: 7565 2069 7320 756e 7365 743a 0a20 2020  ue is unset:.   
-00010460: 2020 2020 2020 2020 2020 2020 2072 6571               req
-00010470: 7569 7265 645f 6b65 7973 5f77 6974 685f  uired_keys_with_
-00010480: 756e 7365 745f 7661 6c75 6573 2e61 7070  unset_values.app
-00010490: 656e 6428 7265 7175 6972 6564 5f6b 6579  end(required_key
-000104a0: 290a 2020 2020 2020 2020 6966 206d 6973  ).        if mis
-000104b0: 7369 6e67 5f72 6571 7569 7265 645f 6b65  sing_required_ke
-000104c0: 7973 3a0a 2020 2020 2020 2020 2020 2020  ys:.            
-000104d0: 7261 6973 6520 4170 6954 7970 6545 7272  raise ApiTypeErr
-000104e0: 6f72 280a 2020 2020 2020 2020 2020 2020  or(.            
-000104f0: 2020 2020 277b 7d20 6d69 7373 696e 6720      '{} missing 
-00010500: 7b7d 2072 6571 7569 7265 6420 6172 6775  {} required argu
-00010510: 6d65 6e74 733a 207b 7d27 2e66 6f72 6d61  ments: {}'.forma
-00010520: 7428 0a20 2020 2020 2020 2020 2020 2020  t(.             
-00010530: 2020 2020 2020 2063 6c73 2e5f 5f6e 616d         cls.__nam
-00010540: 655f 5f2c 206c 656e 286d 6973 7369 6e67  e__, len(missing
-00010550: 5f72 6571 7569 7265 645f 6b65 7973 292c  _required_keys),
-00010560: 206d 6973 7369 6e67 5f72 6571 7569 7265   missing_require
-00010570: 645f 6b65 7973 0a20 2020 2020 2020 2020  d_keys.         
-00010580: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
-00010590: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
-000105a0: 2069 6620 7265 7175 6972 6564 5f6b 6579   if required_key
-000105b0: 735f 7769 7468 5f75 6e73 6574 5f76 616c  s_with_unset_val
-000105c0: 7565 733a 0a20 2020 2020 2020 2020 2020  ues:.           
-000105d0: 2072 6169 7365 2041 7069 5661 6c75 6545   raise ApiValueE
-000105e0: 7272 6f72 280a 2020 2020 2020 2020 2020  rror(.          
-000105f0: 2020 2020 2020 277b 7d20 636f 6e74 6169        '{} contai
-00010600: 6e73 2069 6e76 616c 6964 2075 6e73 6574  ns invalid unset
-00010610: 2076 616c 7565 7320 666f 7220 7b7d 2072   values for {} r
-00010620: 6571 7569 7265 6420 6b65 7973 3a20 7b7d  equired keys: {}
-00010630: 272e 666f 726d 6174 280a 2020 2020 2020  '.format(.      
-00010640: 2020 2020 2020 2020 2020 2020 2020 636c                cl
-00010650: 732e 5f5f 6e61 6d65 5f5f 2c20 6c65 6e28  s.__name__, len(
-00010660: 7265 7175 6972 6564 5f6b 6579 735f 7769  required_keys_wi
-00010670: 7468 5f75 6e73 6574 5f76 616c 7565 7329  th_unset_values)
-00010680: 2c20 7265 7175 6972 6564 5f6b 6579 735f  , required_keys_
-00010690: 7769 7468 5f75 6e73 6574 5f76 616c 7565  with_unset_value
-000106a0: 730a 2020 2020 2020 2020 2020 2020 2020  s.              
-000106b0: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
-000106c0: 290a 0a20 2020 2020 2020 2064 6973 616c  )..        disal
-000106d0: 6c6f 7765 645f 6164 6469 7469 6f6e 616c  lowed_additional
-000106e0: 5f6b 6579 7320 3d20 5b5d 0a20 2020 2020  _keys = [].     
-000106f0: 2020 2066 6f72 206b 6579 2069 6e20 6461     for key in da
-00010700: 7461 3a0a 2020 2020 2020 2020 2020 2020  ta:.            
-00010710: 6966 206b 6579 2069 6e20 636c 732e 5f5f  if key in cls.__
-00010720: 7265 7175 6972 6564 5f6b 6579 735f 5f20  required_keys__ 
-00010730: 6f72 206b 6579 2069 6e20 636c 732e 5f5f  or key in cls.__
-00010740: 6f70 7469 6f6e 616c 5f6b 6579 735f 5f3a  optional_keys__:
-00010750: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00010760: 2063 6f6e 7469 6e75 650a 2020 2020 2020   continue.      
-00010770: 2020 2020 2020 6469 7361 6c6c 6f77 6564        disallowed
-00010780: 5f61 6464 6974 696f 6e61 6c5f 6b65 7973  _additional_keys
-00010790: 2e61 7070 656e 6428 6b65 7929 0a20 2020  .append(key).   
-000107a0: 2020 2020 2069 6620 6469 7361 6c6c 6f77       if disallow
-000107b0: 6564 5f61 6464 6974 696f 6e61 6c5f 6b65  ed_additional_ke
-000107c0: 7973 3a0a 2020 2020 2020 2020 2020 2020  ys:.            
-000107d0: 7261 6973 6520 4170 6954 7970 6545 7272  raise ApiTypeErr
-000107e0: 6f72 280a 2020 2020 2020 2020 2020 2020  or(.            
-000107f0: 2020 2020 277b 7d20 676f 7420 7b7d 2075      '{} got {} u
-00010800: 6e65 7870 6563 7465 6420 6b65 7977 6f72  nexpected keywor
-00010810: 6420 6172 6775 6d65 6e74 733a 207b 7d27  d arguments: {}'
-00010820: 2e66 6f72 6d61 7428 0a20 2020 2020 2020  .format(.       
-00010830: 2020 2020 2020 2020 2020 2020 2063 6c73               cls
-00010840: 2e5f 5f6e 616d 655f 5f2c 206c 656e 2864  .__name__, len(d
-00010850: 6973 616c 6c6f 7765 645f 6164 6469 7469  isallowed_additi
-00010860: 6f6e 616c 5f6b 6579 7329 2c20 6469 7361  onal_keys), disa
+00000200: 6c69 6461 7469 6f6e 4572 726f 722c 2043  lidationError, C
+00000210: 6f6e 6669 6744 6963 740a 6672 6f6d 2075  onfigDict.from u
+00000220: 726c 6c69 6233 2e5f 636f 6c6c 6563 7469  rllib3._collecti
+00000230: 6f6e 7320 696d 706f 7274 2048 5454 5048  ons import HTTPH
+00000240: 6561 6465 7244 6963 740a 6672 6f6d 2075  eaderDict.from u
+00000250: 726c 6c69 622e 7061 7273 6520 696d 706f  rllib.parse impo
+00000260: 7274 2075 726c 7061 7273 652c 2071 756f  rt urlparse, quo
+00000270: 7465 0a66 726f 6d20 7572 6c6c 6962 332e  te.from urllib3.
+00000280: 6669 656c 6473 2069 6d70 6f72 7420 5265  fields import Re
+00000290: 7175 6573 7446 6965 6c64 2061 7320 5265  questField as Re
+000002a0: 7175 6573 7446 6965 6c64 4261 7365 0a66  questFieldBase.f
+000002b0: 726f 6d20 7572 6c6c 6962 332e 6669 656c  rom urllib3.fiel
+000002c0: 6473 2069 6d70 6f72 7420 6775 6573 735f  ds import guess_
+000002d0: 636f 6e74 656e 745f 7479 7065 0a0a 696d  content_type..im
+000002e0: 706f 7274 2066 726f 7a65 6e64 6963 740a  port frozendict.
+000002f0: 0a66 726f 6d20 6361 7262 6f6e 2069 6d70  .from carbon imp
+00000300: 6f72 7420 7265 7374 0a66 726f 6d20 6361  ort rest.from ca
+00000310: 7262 6f6e 2e61 7069 5f72 6573 706f 6e73  rbon.api_respons
+00000320: 6520 696d 706f 7274 2041 7069 5265 7370  e import ApiResp
+00000330: 6f6e 7365 2c20 4173 796e 6341 7069 5265  onse, AsyncApiRe
+00000340: 7370 6f6e 7365 0a66 726f 6d20 6361 7262  sponse.from carb
+00000350: 6f6e 2e72 6573 7420 696d 706f 7274 2041  on.rest import A
+00000360: 7379 6e63 5265 7370 6f6e 7365 5772 6170  syncResponseWrap
+00000370: 7065 722c 2052 6573 706f 6e73 6557 7261  per, ResponseWra
+00000380: 7070 6572 0a66 726f 6d20 6361 7262 6f6e  pper.from carbon
+00000390: 2e63 6f6e 6669 6775 7261 7469 6f6e 2069  .configuration i
+000003a0: 6d70 6f72 7420 436f 6e66 6967 7572 6174  mport Configurat
+000003b0: 696f 6e0a 6672 6f6d 2063 6172 626f 6e2e  ion.from carbon.
+000003c0: 6578 6365 7074 696f 6e73 2069 6d70 6f72  exceptions impor
+000003d0: 7420 4170 6954 7970 6545 7272 6f72 2c20  t ApiTypeError, 
+000003e0: 4170 6956 616c 7565 4572 726f 722c 204d  ApiValueError, M
+000003f0: 6973 7369 6e67 5265 7175 6972 6564 5061  issingRequiredPa
+00000400: 7261 6d65 7465 7273 4572 726f 720a 6672  rametersError.fr
+00000410: 6f6d 2063 6172 626f 6e2e 7265 7175 6573  om carbon.reques
+00000420: 745f 6166 7465 725f 686f 6f6b 2069 6d70  t_after_hook imp
+00000430: 6f72 7420 7265 7175 6573 745f 6166 7465  ort request_afte
+00000440: 725f 686f 6f6b 0a66 726f 6d20 6361 7262  r_hook.from carb
+00000450: 6f6e 2e72 6571 7565 7374 5f62 6566 6f72  on.request_befor
+00000460: 655f 7572 6c5f 686f 6f6b 2069 6d70 6f72  e_url_hook impor
+00000470: 7420 7265 7175 6573 745f 6265 666f 7265  t request_before
+00000480: 5f75 726c 5f68 6f6f 6b0a 6672 6f6d 2063  _url_hook.from c
+00000490: 6172 626f 6e2e 7363 6865 6d61 7320 696d  arbon.schemas im
+000004a0: 706f 7274 2028 0a20 2020 204e 6f6e 6543  port (.    NoneC
+000004b0: 6c61 7373 2c0a 2020 2020 426f 6f6c 436c  lass,.    BoolCl
+000004c0: 6173 732c 0a20 2020 2053 6368 656d 612c  ass,.    Schema,
+000004d0: 0a20 2020 2046 696c 6549 4f2c 0a20 2020  .    FileIO,.   
+000004e0: 2042 696e 6172 7953 6368 656d 612c 0a20   BinarySchema,. 
+000004f0: 2020 2064 6174 652c 0a20 2020 2064 6174     date,.    dat
+00000500: 6574 696d 652c 0a20 2020 206e 6f6e 655f  etime,.    none_
+00000510: 7479 7065 2c0a 2020 2020 556e 7365 742c  type,.    Unset,
+00000520: 0a20 2020 2075 6e73 6574 2c0a 290a 0a40  .    unset,.)..@
+00000530: 6461 7461 636c 6173 730a 636c 6173 7320  dataclass.class 
+00000540: 4d61 7070 6564 4172 6773 3a0a 2020 2020  MappedArgs:.    
+00000550: 626f 6479 3a20 7479 7069 6e67 2e41 6e79  body: typing.Any
+00000560: 203d 204e 6f6e 650a 2020 2020 7175 6572   = None.    quer
+00000570: 793a 2074 7970 696e 672e 4f70 7469 6f6e  y: typing.Option
+00000580: 616c 5b64 6963 745d 203d 204e 6f6e 650a  al[dict] = None.
+00000590: 2020 2020 7061 7468 3a20 7479 7069 6e67      path: typing
+000005a0: 2e4f 7074 696f 6e61 6c5b 6469 6374 5d20  .Optional[dict] 
+000005b0: 3d20 4e6f 6e65 0a20 2020 2068 6561 6465  = None.    heade
+000005c0: 723a 2074 7970 696e 672e 4f70 7469 6f6e  r: typing.Option
+000005d0: 616c 5b64 6963 745d 203d 204e 6f6e 650a  al[dict] = None.
+000005e0: 2020 2020 636f 6f6b 6965 3a20 7479 7069      cookie: typi
+000005f0: 6e67 2e4f 7074 696f 6e61 6c5b 6469 6374  ng.Optional[dict
+00000600: 5d20 3d20 4e6f 6e65 0a0a 636c 6173 7320  ] = None..class 
+00000610: 5265 7175 6573 7446 6965 6c64 2852 6571  RequestField(Req
+00000620: 7565 7374 4669 656c 6442 6173 6529 3a0a  uestFieldBase):.
+00000630: 2020 2020 6465 6620 5f5f 6571 5f5f 2873      def __eq__(s
+00000640: 656c 662c 206f 7468 6572 293a 0a20 2020  elf, other):.   
+00000650: 2020 2020 2069 6620 6e6f 7420 6973 696e       if not isin
+00000660: 7374 616e 6365 286f 7468 6572 2c20 5265  stance(other, Re
+00000670: 7175 6573 7446 6965 6c64 293a 0a20 2020  questField):.   
+00000680: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00000690: 4661 6c73 650a 2020 2020 2020 2020 7265  False.        re
+000006a0: 7475 726e 2073 656c 662e 5f5f 6469 6374  turn self.__dict
+000006b0: 5f5f 203d 3d20 6f74 6865 722e 5f5f 6469  __ == other.__di
+000006c0: 6374 5f5f 0a0a 0a54 203d 2074 7970 696e  ct__...T = typin
+000006d0: 672e 5479 7065 5661 7228 2754 2729 0a0a  g.TypeVar('T')..
+000006e0: 0a64 6566 2063 6c6f 7365 7374 5f74 7970  .def closest_typ
+000006f0: 655f 6d61 7463 6828 7661 6c75 653a 2074  e_match(value: t
+00000700: 7970 696e 672e 416e 792c 2074 7970 6573  yping.Any, types
+00000710: 3a20 7479 7069 6e67 2e4c 6973 745b 7479  : typing.List[ty
+00000720: 7069 6e67 2e54 7970 655d 2920 2d3e 2074  ping.Type]) -> t
+00000730: 7970 696e 672e 5479 7065 3a0a 2020 2020  yping.Type:.    
+00000740: 6265 7374 5f6d 6174 6368 203d 204e 6f6e  best_match = Non
+00000750: 650a 0a20 2020 2066 6f72 2074 2069 6e20  e..    for t in 
+00000760: 7479 7065 733a 0a20 2020 2020 2020 2023  types:.        #
+00000770: 2043 6865 636b 2066 6f72 2067 656e 6572   Check for gener
+00000780: 6963 2074 7970 6573 0a20 2020 2020 2020  ic types.       
+00000790: 206f 7269 6769 6e20 3d20 7479 7069 6e67   origin = typing
+000007a0: 5f65 7874 656e 7369 6f6e 732e 6765 745f  _extensions.get_
+000007b0: 6f72 6967 696e 2874 290a 2020 2020 2020  origin(t).      
+000007c0: 2020 6172 6773 203d 2074 7970 696e 675f    args = typing_
+000007d0: 6578 7465 6e73 696f 6e73 2e67 6574 5f61  extensions.get_a
+000007e0: 7267 7328 7429 0a0a 2020 2020 2020 2020  rgs(t)..        
+000007f0: 2320 4368 6563 6b20 666f 7220 4c69 7465  # Check for Lite
+00000800: 7261 6c20 7479 7065 730a 2020 2020 2020  ral types.      
+00000810: 2020 6966 206f 7269 6769 6e20 3d3d 2074    if origin == t
+00000820: 7970 696e 675f 6578 7465 6e73 696f 6e73  yping_extensions
+00000830: 2e4c 6974 6572 616c 3a0a 2020 2020 2020  .Literal:.      
+00000840: 2020 2020 2020 6966 2076 616c 7565 2069        if value i
+00000850: 6e20 6172 6773 3a0a 2020 2020 2020 2020  n args:.        
+00000860: 2020 2020 2020 2020 6265 7374 5f6d 6174          best_mat
+00000870: 6368 203d 2074 0a20 2020 2020 2020 2020  ch = t.         
+00000880: 2020 2020 2020 2063 6f6e 7469 6e75 650a         continue.
+00000890: 0a20 2020 2020 2020 2023 2043 6865 636b  .        # Check
+000008a0: 2066 6f72 2050 7964 616e 7469 6320 6d6f   for Pydantic mo
+000008b0: 6465 6c73 2061 6e64 206e 6f6e 2d67 656e  dels and non-gen
+000008c0: 6572 6963 2074 7970 6573 0a20 2020 2020  eric types.     
+000008d0: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
+000008e0: 2874 2c20 7479 7065 293a 2020 2320 456e  (t, type):  # En
+000008f0: 7375 7265 2074 2069 7320 6120 636c 6173  sure t is a clas
+00000900: 730a 2020 2020 2020 2020 2020 2020 6966  s.            if
+00000910: 2069 7373 7562 636c 6173 7328 742c 2042   issubclass(t, B
+00000920: 6173 654d 6f64 656c 293a 0a20 2020 2020  aseModel):.     
+00000930: 2020 2020 2020 2020 2020 2069 6620 6973             if is
+00000940: 696e 7374 616e 6365 2876 616c 7565 2c20  instance(value, 
+00000950: 6469 6374 293a 0a20 2020 2020 2020 2020  dict):.         
+00000960: 2020 2020 2020 2020 2020 2074 7279 3a0a             try:.
+00000970: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000980: 2020 2020 2020 2020 7428 2a2a 7661 6c75          t(**valu
+00000990: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
+000009a0: 2020 2020 2020 2020 2020 2062 6573 745f             best_
+000009b0: 6d61 7463 6820 3d20 740a 2020 2020 2020  match = t.      
+000009c0: 2020 2020 2020 2020 2020 2020 2020 6578                ex
+000009d0: 6365 7074 2056 616c 6964 6174 696f 6e45  cept ValidationE
+000009e0: 7272 6f72 3a0a 2020 2020 2020 2020 2020  rror:.          
+000009f0: 2020 2020 2020 2020 2020 2020 2020 636f                co
+00000a00: 6e74 696e 7565 0a20 2020 2020 2020 2020  ntinue.         
+00000a10: 2020 2065 6c73 653a 2020 2320 5468 6973     else:  # This
+00000a20: 2069 7320 6120 6e6f 6e2d 6765 6e65 7269   is a non-generi
+00000a30: 6320 7479 7065 0a20 2020 2020 2020 2020  c type.         
+00000a40: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
+00000a50: 616e 6365 2876 616c 7565 2c20 7429 3a0a  ance(value, t):.
+00000a60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000a70: 2020 2020 6966 2062 6573 745f 6d61 7463      if best_matc
+00000a80: 6820 6973 204e 6f6e 6520 6f72 2028 6973  h is None or (is
+00000a90: 696e 7374 616e 6365 2876 616c 7565 2c20  instance(value, 
+00000aa0: 7479 7065 2920 616e 6420 6973 7375 6263  type) and issubc
+00000ab0: 6c61 7373 2862 6573 745f 6d61 7463 682c  lass(best_match,
+00000ac0: 2074 2929 3a0a 2020 2020 2020 2020 2020   t)):.          
+00000ad0: 2020 2020 2020 2020 2020 2020 2020 6265                be
+00000ae0: 7374 5f6d 6174 6368 203d 2074 0a20 2020  st_match = t.   
+00000af0: 2020 2020 2020 2020 2020 2020 2063 6f6e               con
+00000b00: 7469 6e75 650a 0a20 2020 2020 2020 2023  tinue..        #
+00000b10: 2043 6865 636b 2066 6f72 2067 656e 6572   Check for gener
+00000b20: 6963 206c 6973 7420 7479 7065 0a20 2020  ic list type.   
+00000b30: 2020 2020 2069 6620 6f72 6967 696e 203d       if origin =
+00000b40: 3d20 6c69 7374 2061 6e64 2069 7369 6e73  = list and isins
+00000b50: 7461 6e63 6528 7661 6c75 652c 206c 6973  tance(value, lis
+00000b60: 7429 3a0a 2020 2020 2020 2020 2020 2020  t):.            
+00000b70: 6265 7374 5f6d 6174 6368 203d 2074 0a0a  best_match = t..
+00000b80: 2020 2020 7265 7475 726e 2062 6573 745f      return best_
+00000b90: 6d61 7463 680a 0a0a 6465 6620 636f 6e73  match...def cons
+00000ba0: 7472 7563 745f 6d6f 6465 6c5f 696e 7374  truct_model_inst
+00000bb0: 616e 6365 286d 6f64 656c 3a20 7479 7069  ance(model: typi
+00000bc0: 6e67 2e54 7970 655b 545d 2c20 6461 7461  ng.Type[T], data
+00000bd0: 3a20 7479 7069 6e67 2e41 6e79 2920 2d3e  : typing.Any) ->
+00000be0: 2054 3a0a 2020 2020 2222 220a 2020 2020   T:.    """.    
+00000bf0: 5265 6375 7273 6976 656c 7920 636f 6e73  Recursively cons
+00000c00: 7472 7563 7420 616e 2069 6e73 7461 6e63  truct an instanc
+00000c10: 6520 6f66 2061 2050 7964 616e 7469 6320  e of a Pydantic 
+00000c20: 6d6f 6465 6c20 616c 6f6e 6720 7769 7468  model along with
+00000c30: 2069 7473 206e 6573 7465 6420 6d6f 6465   its nested mode
+00000c40: 6c73 2e0a 2020 2020 2222 220a 0a20 2020  ls..    """..   
+00000c50: 2023 2069 6620 6d6f 6465 6c20 6973 2055   # if model is U
+00000c60: 6e69 6f6e 2c0a 2020 2020 6966 2074 7970  nion,.    if typ
+00000c70: 696e 675f 6578 7465 6e73 696f 6e73 2e67  ing_extensions.g
+00000c80: 6574 5f6f 7269 6769 6e28 6d6f 6465 6c29  et_origin(model)
+00000c90: 2069 7320 7479 7069 6e67 2e55 6e69 6f6e   is typing.Union
+00000ca0: 3a0a 2020 2020 2020 2020 6265 7374 5f74  :.        best_t
+00000cb0: 7970 6520 3d20 636c 6f73 6573 745f 7479  ype = closest_ty
+00000cc0: 7065 5f6d 6174 6368 2864 6174 612c 206d  pe_match(data, m
+00000cd0: 6f64 656c 2e5f 5f61 7267 735f 5f29 0a20  odel.__args__). 
+00000ce0: 2020 2020 2020 2072 6574 7572 6e20 636f         return co
+00000cf0: 6e73 7472 7563 745f 6d6f 6465 6c5f 696e  nstruct_model_in
+00000d00: 7374 616e 6365 2862 6573 745f 7479 7065  stance(best_type
+00000d10: 2c20 6461 7461 290a 2020 2020 656c 6966  , data).    elif
+00000d20: 206d 6f64 656c 2069 7320 4e6f 6e65 206f   model is None o
+00000d30: 7220 6d6f 6465 6c20 6973 2074 7970 6528  r model is type(
+00000d40: 4e6f 6e65 293a 0a20 2020 2020 2020 2072  None):.        r
+00000d50: 6574 7572 6e20 6461 7461 0a20 2020 2023  eturn data.    #
+00000d60: 2069 6620 6d6f 6465 6c20 6973 2073 6361   if model is sca
+00000d70: 6c61 7220 7661 6c75 6520 6c69 6b65 2073  lar value like s
+00000d80: 7472 2c20 6e75 6d62 6572 2c20 6574 632e  tr, number, etc.
+00000d90: 206a 7573 7420 7265 7475 726e 2074 6865   just return the
+00000da0: 2076 616c 7565 0a20 2020 2065 6c69 6620   value.    elif 
+00000db0: 6973 696e 7374 616e 6365 2864 6174 612c  isinstance(data,
+00000dc0: 2028 7374 722c 2066 6c6f 6174 2c20 696e   (str, float, in
+00000dd0: 742c 2062 7974 6573 2c20 626f 6f6c 2929  t, bytes, bool))
+00000de0: 3a0a 2020 2020 2020 2020 7265 7475 726e  :.        return
+00000df0: 2064 6174 610a 2020 2020 656c 6966 2064   data.    elif d
+00000e00: 6174 6120 6973 204e 6f6e 653a 0a20 2020  ata is None:.   
+00000e10: 2020 2020 2072 6574 7572 6e20 6461 7461       return data
+00000e20: 0a20 2020 2023 2069 6620 6d6f 6465 6c20  .    # if model 
+00000e30: 6973 206c 6973 742c 2069 7465 7261 7465  is list, iterate
+00000e40: 206f 7665 7220 6c69 7374 2061 6e64 2072   over list and r
+00000e50: 6563 7572 7369 7665 6c79 2063 616c 6c0a  ecursively call.
+00000e60: 2020 2020 656c 6966 2074 7970 696e 675f      elif typing_
+00000e70: 6578 7465 6e73 696f 6e73 2e67 6574 5f6f  extensions.get_o
+00000e80: 7269 6769 6e28 6d6f 6465 6c29 2069 7320  rigin(model) is 
+00000e90: 6c69 7374 3a0a 2020 2020 2020 2020 6974  list:.        it
+00000ea0: 656d 5f6d 6f64 656c 203d 2074 7970 696e  em_model = typin
+00000eb0: 675f 6578 7465 6e73 696f 6e73 2e67 6574  g_extensions.get
+00000ec0: 5f61 7267 7328 6d6f 6465 6c29 5b30 5d0a  _args(model)[0].
+00000ed0: 2020 2020 2020 2020 7265 7475 726e 205b          return [
+00000ee0: 636f 6e73 7472 7563 745f 6d6f 6465 6c5f  construct_model_
+00000ef0: 696e 7374 616e 6365 2869 7465 6d5f 6d6f  instance(item_mo
+00000f00: 6465 6c2c 2069 7465 6d29 2066 6f72 2069  del, item) for i
+00000f10: 7465 6d20 696e 2064 6174 615d 0a20 2020  tem in data].   
+00000f20: 2023 2069 6620 6d6f 6465 6c20 6973 2066   # if model is f
+00000f30: 7265 6520 666f 726d 206f 626a 6563 742c  ree form object,
+00000f40: 206a 7573 7420 7265 7475 726e 2074 6865   just return the
+00000f50: 2076 616c 7565 0a20 2020 2065 6c69 6620   value.    elif 
+00000f60: 7479 7069 6e67 5f65 7874 656e 7369 6f6e  typing_extension
+00000f70: 732e 6765 745f 6f72 6967 696e 286d 6f64  s.get_origin(mod
+00000f80: 656c 2920 6973 2064 6963 743a 0a20 2020  el) is dict:.   
+00000f90: 2020 2020 2072 6574 7572 6e20 6461 7461       return data
+00000fa0: 0a20 2020 2065 6c69 6620 6d6f 6465 6c20  .    elif model 
+00000fb0: 6973 2064 6963 743a 0a20 2020 2020 2020  is dict:.       
+00000fc0: 2072 6574 7572 6e20 6461 7461 0a20 2020   return data.   
+00000fd0: 2065 6c69 6620 6d6f 6465 6c20 6973 206f   elif model is o
+00000fe0: 626a 6563 743a 0a20 2020 2020 2020 2072  bject:.        r
+00000ff0: 6574 7572 6e20 6461 7461 0a20 2020 2023  eturn data.    #
+00001000: 2069 6620 6d6f 6465 6c20 6973 2042 6173   if model is Bas
+00001010: 654d 6f64 656c 2c20 6974 6572 6174 6520  eModel, iterate 
+00001020: 6f76 6572 2066 6965 6c64 7320 616e 6420  over fields and 
+00001030: 7265 6375 7273 6976 656c 7920 6361 6c6c  recursively call
+00001040: 0a20 2020 2065 6c69 6620 6973 7375 6263  .    elif issubc
+00001050: 6c61 7373 286d 6f64 656c 2c20 4261 7365  lass(model, Base
+00001060: 4d6f 6465 6c29 3a0a 2020 2020 2020 2020  Model):.        
+00001070: 6e65 775f 6461 7461 203d 207b 7d0a 2020  new_data = {}.  
+00001080: 2020 2020 2020 666f 7220 6669 656c 645f        for field_
+00001090: 6e61 6d65 2c20 6669 656c 645f 7479 7065  name, field_type
+000010a0: 2069 6e20 6d6f 6465 6c2e 5f5f 616e 6e6f   in model.__anno
+000010b0: 7461 7469 6f6e 735f 5f2e 6974 656d 7328  tations__.items(
+000010c0: 293a 0a20 2020 2020 2020 2020 2020 2023  ):.            #
+000010d0: 2067 6574 2061 6c69 6173 0a20 2020 2020   get alias.     
+000010e0: 2020 2020 2020 2061 6c69 6173 203d 206d         alias = m
+000010f0: 6f64 656c 2e6d 6f64 656c 5f66 6965 6c64  odel.model_field
+00001100: 735b 6669 656c 645f 6e61 6d65 5d2e 616c  s[field_name].al
+00001110: 6961 730a 2020 2020 2020 2020 2020 2020  ias.            
+00001120: 6966 2061 6c69 6173 2069 6e20 6461 7461  if alias in data
+00001130: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00001140: 2020 6e65 775f 6461 7461 5b61 6c69 6173    new_data[alias
+00001150: 5d20 3d20 636f 6e73 7472 7563 745f 6d6f  ] = construct_mo
+00001160: 6465 6c5f 696e 7374 616e 6365 2866 6965  del_instance(fie
+00001170: 6c64 5f74 7970 652c 2064 6174 615b 616c  ld_type, data[al
+00001180: 6961 735d 290a 2020 2020 2020 2020 7265  ias]).        re
+00001190: 7475 726e 206d 6f64 656c 2e6d 6f64 656c  turn model.model
+000011a0: 5f63 6f6e 7374 7275 6374 282a 2a6e 6577  _construct(**new
+000011b0: 5f64 6174 6129 0a20 2020 2072 6169 7365  _data).    raise
+000011c0: 2041 7069 5479 7065 4572 726f 7228 6622   ApiTypeError(f"
+000011d0: 556e 6162 6c65 2074 6f20 636f 6e73 7472  Unable to constr
+000011e0: 7563 7420 6d6f 6465 6c20 696e 7374 616e  uct model instan
+000011f0: 6365 206f 6620 7479 7065 207b 6d6f 6465  ce of type {mode
+00001200: 6c7d 2229 0a0a 0a63 6c61 7373 2044 6963  l}")...class Dic
+00001210: 7469 6f6e 6172 7928 4261 7365 4d6f 6465  tionary(BaseMode
+00001220: 6c29 3a0a 2020 2020 2222 220a 2020 2020  l):.    """.    
+00001230: 466f 7220 6672 6565 2d66 6f72 6d20 6f62  For free-form ob
+00001240: 6a65 6374 7320 7468 6174 2063 616e 2068  jects that can h
+00001250: 6176 6520 616e 7920 6b65 7973 2061 6e64  ave any keys and
+00001260: 2076 616c 7565 730a 2020 2020 2869 2e65   values.    (i.e
+00001270: 2e20 2274 7970 653a 206f 626a 6563 7422  . "type: object"
+00001280: 2077 6974 6820 6e6f 2070 726f 7065 7274   with no propert
+00001290: 6965 7329 0a20 2020 2022 2222 0a20 2020  ies).    """.   
+000012a0: 206d 6f64 656c 5f63 6f6e 6669 6720 3d20   model_config = 
+000012b0: 436f 6e66 6967 4469 6374 280a 2020 2020  ConfigDict(.    
+000012c0: 2020 2020 6578 7472 613d 2261 6c6c 6f77      extra="allow
+000012d0: 220a 2020 2020 290a 0a0a 6465 6620 4465  ".    )...def De
+000012e0: 7072 6563 6174 696f 6e57 6172 6e69 6e67  precationWarning
+000012f0: 4f6e 6365 2866 756e 633d 4e6f 6e65 2c20  Once(func=None, 
+00001300: 2a2c 2070 7265 6669 783d 4e6f 6e65 293a  *, prefix=None):
+00001310: 0a20 2020 2064 6566 2064 6563 6f72 6174  .    def decorat
+00001320: 6f72 2866 756e 6329 3a0a 2020 2020 2020  or(func):.      
+00001330: 2020 7761 726e 6564 203d 2046 616c 7365    warned = False
+00001340: 0a20 2020 2020 2020 2064 6566 2077 7261  .        def wra
+00001350: 7070 6572 2869 6e73 7461 6e63 652c 202a  pper(instance, *
+00001360: 6172 6773 2c20 2a2a 6b77 6172 6773 293a  args, **kwargs):
+00001370: 0a20 2020 2020 2020 2020 2020 206e 6f6e  .            non
+00001380: 6c6f 6361 6c20 7761 726e 6564 0a20 2020  local warned.   
+00001390: 2020 2020 2020 2020 2069 6620 6e6f 7420           if not 
+000013a0: 7761 726e 6564 3a0a 2020 2020 2020 2020  warned:.        
+000013b0: 2020 2020 2020 2020 6d73 6720 3d20 6622          msg = f"
+000013c0: 7b66 756e 632e 5f5f 6e61 6d65 5f5f 7d20  {func.__name__} 
+000013d0: 6973 2064 6570 7265 6361 7465 6422 0a20  is deprecated". 
+000013e0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+000013f0: 6620 7072 6566 6978 3a0a 2020 2020 2020  f prefix:.      
+00001400: 2020 2020 2020 2020 2020 2020 2020 6d73                ms
+00001410: 6720 3d20 6622 7b70 7265 6669 787d 2e7b  g = f"{prefix}.{
+00001420: 6d73 677d 220a 2020 2020 2020 2020 2020  msg}".          
+00001430: 2020 2020 2020 696e 7374 616e 6365 2e61        instance.a
+00001440: 7069 5f63 6c69 656e 742e 636f 6e66 6967  pi_client.config
+00001450: 7572 6174 696f 6e2e 6c6f 6767 6572 2e77  uration.logger.w
+00001460: 6172 6e69 6e67 286d 7367 290a 2020 2020  arning(msg).    
+00001470: 2020 2020 2020 2020 2020 2020 7761 726e              warn
+00001480: 6564 203d 2054 7275 650a 2020 2020 2020  ed = True.      
+00001490: 2020 2020 2020 7265 7475 726e 2066 756e        return fun
+000014a0: 6328 696e 7374 616e 6365 2c20 2a61 7267  c(instance, *arg
+000014b0: 732c 202a 2a6b 7761 7267 7329 0a20 2020  s, **kwargs).   
+000014c0: 2020 2020 2072 6574 7572 6e20 7772 6170       return wrap
+000014d0: 7065 720a 2020 2020 6966 2066 756e 6320  per.    if func 
+000014e0: 6973 204e 6f6e 653a 0a20 2020 2020 2020  is None:.       
+000014f0: 2072 6574 7572 6e20 6465 636f 7261 746f   return decorato
+00001500: 720a 2020 2020 656c 7365 3a0a 2020 2020  r.    else:.    
+00001510: 2020 2020 7265 7475 726e 2064 6563 6f72      return decor
+00001520: 6174 6f72 2866 756e 6329 0a0a 636c 6173  ator(func)..clas
+00001530: 7320 4a53 4f4e 456e 636f 6465 7228 6a73  s JSONEncoder(js
+00001540: 6f6e 2e4a 534f 4e45 6e63 6f64 6572 293a  on.JSONEncoder):
+00001550: 0a20 2020 2063 6f6d 7061 6374 5f73 6570  .    compact_sep
+00001560: 6172 6174 6f72 7320 3d20 2827 2c27 2c20  arators = (',', 
+00001570: 273a 2729 0a0a 2020 2020 6465 6620 6465  ':')..    def de
+00001580: 6661 756c 7428 7365 6c66 2c20 6f62 6a29  fault(self, obj)
+00001590: 3a0a 2020 2020 2020 2020 6966 2069 7369  :.        if isi
+000015a0: 6e73 7461 6e63 6528 6f62 6a2c 2073 7472  nstance(obj, str
+000015b0: 293a 0a20 2020 2020 2020 2020 2020 2072  ):.            r
+000015c0: 6574 7572 6e20 7374 7228 6f62 6a29 0a20  eturn str(obj). 
+000015d0: 2020 2020 2020 2065 6c69 6620 6973 696e         elif isin
+000015e0: 7374 616e 6365 286f 626a 2c20 666c 6f61  stance(obj, floa
+000015f0: 7429 3a0a 2020 2020 2020 2020 2020 2020  t):.            
+00001600: 7265 7475 726e 2066 6c6f 6174 286f 626a  return float(obj
+00001610: 290a 2020 2020 2020 2020 656c 6966 2069  ).        elif i
+00001620: 7369 6e73 7461 6e63 6528 6f62 6a2c 2069  sinstance(obj, i
+00001630: 6e74 293a 0a20 2020 2020 2020 2020 2020  nt):.           
+00001640: 2072 6574 7572 6e20 696e 7428 6f62 6a29   return int(obj)
+00001650: 0a20 2020 2020 2020 2065 6c69 6620 6973  .        elif is
+00001660: 696e 7374 616e 6365 286f 626a 2c20 4465  instance(obj, De
+00001670: 6369 6d61 6c29 3a0a 2020 2020 2020 2020  cimal):.        
+00001680: 2020 2020 6966 206f 626a 2e61 735f 7475      if obj.as_tu
+00001690: 706c 6528 292e 6578 706f 6e65 6e74 203e  ple().exponent >
+000016a0: 3d20 303a 0a20 2020 2020 2020 2020 2020  = 0:.           
+000016b0: 2020 2020 2072 6574 7572 6e20 696e 7428       return int(
+000016c0: 6f62 6a29 0a20 2020 2020 2020 2020 2020  obj).           
+000016d0: 2072 6574 7572 6e20 666c 6f61 7428 6f62   return float(ob
+000016e0: 6a29 0a20 2020 2020 2020 2065 6c69 6620  j).        elif 
+000016f0: 6973 696e 7374 616e 6365 286f 626a 2c20  isinstance(obj, 
+00001700: 4e6f 6e65 436c 6173 7329 3a0a 2020 2020  NoneClass):.    
+00001710: 2020 2020 2020 2020 7265 7475 726e 204e          return N
+00001720: 6f6e 650a 2020 2020 2020 2020 656c 6966  one.        elif
+00001730: 2069 7369 6e73 7461 6e63 6528 6f62 6a2c   isinstance(obj,
+00001740: 2042 6f6f 6c43 6c61 7373 293a 0a20 2020   BoolClass):.   
+00001750: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00001760: 626f 6f6c 286f 626a 290a 2020 2020 2020  bool(obj).      
+00001770: 2020 656c 6966 2069 7369 6e73 7461 6e63    elif isinstanc
+00001780: 6528 6f62 6a2c 2028 6469 6374 2c20 6672  e(obj, (dict, fr
+00001790: 6f7a 656e 6469 6374 2e66 726f 7a65 6e64  ozendict.frozend
+000017a0: 6963 7429 293a 0a20 2020 2020 2020 2020  ict)):.         
+000017b0: 2020 2072 6574 7572 6e20 7b6b 6579 3a20     return {key: 
+000017c0: 7365 6c66 2e64 6566 6175 6c74 2876 616c  self.default(val
+000017d0: 2920 666f 7220 6b65 792c 2076 616c 2069  ) for key, val i
+000017e0: 6e20 6f62 6a2e 6974 656d 7328 297d 0a20  n obj.items()}. 
+000017f0: 2020 2020 2020 2065 6c69 6620 6973 696e         elif isin
+00001800: 7374 616e 6365 286f 626a 2c20 286c 6973  stance(obj, (lis
+00001810: 742c 2074 7570 6c65 2929 3a0a 2020 2020  t, tuple)):.    
+00001820: 2020 2020 2020 2020 7265 7475 726e 205b          return [
+00001830: 7365 6c66 2e64 6566 6175 6c74 2869 7465  self.default(ite
+00001840: 6d29 2066 6f72 2069 7465 6d20 696e 206f  m) for item in o
+00001850: 626a 5d0a 2020 2020 2020 2020 7261 6973  bj].        rais
+00001860: 6520 4170 6956 616c 7565 4572 726f 7228  e ApiValueError(
+00001870: 2755 6e61 626c 6520 746f 2070 7265 7061  'Unable to prepa
+00001880: 7265 2074 7970 6520 7b7d 2066 6f72 2073  re type {} for s
+00001890: 6572 6961 6c69 7a61 7469 6f6e 272e 666f  erialization'.fo
+000018a0: 726d 6174 286f 626a 2e5f 5f63 6c61 7373  rmat(obj.__class
+000018b0: 5f5f 2e5f 5f6e 616d 655f 5f29 290a 0a0a  __.__name__))...
+000018c0: 636c 6173 7320 5061 7261 6d65 7465 7249  class ParameterI
+000018d0: 6e54 7970 6528 656e 756d 2e45 6e75 6d29  nType(enum.Enum)
+000018e0: 3a0a 2020 2020 5155 4552 5920 3d20 2771  :.    QUERY = 'q
+000018f0: 7565 7279 270a 2020 2020 4845 4144 4552  uery'.    HEADER
+00001900: 203d 2027 6865 6164 6572 270a 2020 2020   = 'header'.    
+00001910: 5041 5448 203d 2027 7061 7468 270a 2020  PATH = 'path'.  
+00001920: 2020 434f 4f4b 4945 203d 2027 636f 6f6b    COOKIE = 'cook
+00001930: 6965 270a 0a0a 636c 6173 7320 5061 7261  ie'...class Para
+00001940: 6d65 7465 7253 7479 6c65 2865 6e75 6d2e  meterStyle(enum.
+00001950: 456e 756d 293a 0a20 2020 204d 4154 5249  Enum):.    MATRI
+00001960: 5820 3d20 276d 6174 7269 7827 0a20 2020  X = 'matrix'.   
+00001970: 204c 4142 454c 203d 2027 6c61 6265 6c27   LABEL = 'label'
+00001980: 0a20 2020 2046 4f52 4d20 3d20 2766 6f72  .    FORM = 'for
+00001990: 6d27 0a20 2020 2053 494d 504c 4520 3d20  m'.    SIMPLE = 
+000019a0: 2773 696d 706c 6527 0a20 2020 2053 5041  'simple'.    SPA
+000019b0: 4345 5f44 454c 494d 4954 4544 203d 2027  CE_DELIMITED = '
+000019c0: 7370 6163 6544 656c 696d 6974 6564 270a  spaceDelimited'.
+000019d0: 2020 2020 5049 5045 5f44 454c 494d 4954      PIPE_DELIMIT
+000019e0: 4544 203d 2027 7069 7065 4465 6c69 6d69  ED = 'pipeDelimi
+000019f0: 7465 6427 0a20 2020 2044 4545 505f 4f42  ted'.    DEEP_OB
+00001a00: 4a45 4354 203d 2027 6465 6570 4f62 6a65  JECT = 'deepObje
+00001a10: 6374 270a 0a0a 636c 6173 7320 5072 6566  ct'...class Pref
+00001a20: 6978 5365 7061 7261 746f 7249 7465 7261  ixSeparatorItera
+00001a30: 746f 723a 0a20 2020 2023 2041 2063 6c61  tor:.    # A cla
+00001a40: 7373 2074 6f20 7374 6f72 6520 7072 6566  ss to store pref
+00001a50: 6978 6573 2061 6e64 2073 6570 6172 6174  ixes and separat
+00001a60: 6f72 7320 666f 7220 7266 6336 3537 3020  ors for rfc6570 
+00001a70: 6578 7061 6e73 696f 6e73 0a0a 2020 2020  expansions..    
+00001a80: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
+00001a90: 662c 2070 7265 6669 783a 2073 7472 2c20  f, prefix: str, 
+00001aa0: 7365 7061 7261 746f 723a 2073 7472 293a  separator: str):
+00001ab0: 0a20 2020 2020 2020 2073 656c 662e 7072  .        self.pr
+00001ac0: 6566 6978 203d 2070 7265 6669 780a 2020  efix = prefix.  
+00001ad0: 2020 2020 2020 7365 6c66 2e73 6570 6172        self.separ
+00001ae0: 6174 6f72 203d 2073 6570 6172 6174 6f72  ator = separator
+00001af0: 0a20 2020 2020 2020 2073 656c 662e 6669  .        self.fi
+00001b00: 7273 7420 3d20 5472 7565 0a20 2020 2020  rst = True.     
+00001b10: 2020 2069 6620 7365 7061 7261 746f 7220     if separator 
+00001b20: 696e 207b 272e 272c 2027 7c27 2c20 2725  in {'.', '|', '%
+00001b30: 3230 277d 3a0a 2020 2020 2020 2020 2020  20'}:.          
+00001b40: 2020 6974 656d 5f73 6570 6172 6174 6f72    item_separator
+00001b50: 203d 2073 6570 6172 6174 6f72 0a20 2020   = separator.   
+00001b60: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00001b70: 2020 2020 2020 2069 7465 6d5f 7365 7061         item_sepa
+00001b80: 7261 746f 7220 3d20 272c 270a 2020 2020  rator = ','.    
+00001b90: 2020 2020 7365 6c66 2e69 7465 6d5f 7365      self.item_se
+00001ba0: 7061 7261 746f 7220 3d20 6974 656d 5f73  parator = item_s
+00001bb0: 6570 6172 6174 6f72 0a0a 2020 2020 6465  eparator..    de
+00001bc0: 6620 5f5f 6974 6572 5f5f 2873 656c 6629  f __iter__(self)
+00001bd0: 3a0a 2020 2020 2020 2020 7265 7475 726e  :.        return
+00001be0: 2073 656c 660a 0a20 2020 2064 6566 205f   self..    def _
+00001bf0: 5f6e 6578 745f 5f28 7365 6c66 293a 0a20  _next__(self):. 
+00001c00: 2020 2020 2020 2069 6620 7365 6c66 2e66         if self.f
+00001c10: 6972 7374 3a0a 2020 2020 2020 2020 2020  irst:.          
+00001c20: 2020 7365 6c66 2e66 6972 7374 203d 2046    self.first = F
+00001c30: 616c 7365 0a20 2020 2020 2020 2020 2020  alse.           
+00001c40: 2072 6574 7572 6e20 7365 6c66 2e70 7265   return self.pre
+00001c50: 6669 780a 2020 2020 2020 2020 7265 7475  fix.        retu
+00001c60: 726e 2073 656c 662e 7365 7061 7261 746f  rn self.separato
+00001c70: 720a 0a0a 636c 6173 7320 5061 7261 6d65  r...class Parame
+00001c80: 7465 7253 6572 6961 6c69 7a65 7242 6173  terSerializerBas
+00001c90: 653a 0a20 2020 2040 636c 6173 736d 6574  e:.    @classmet
+00001ca0: 686f 640a 2020 2020 6465 6620 5f67 6574  hod.    def _get
+00001cb0: 5f64 6566 6175 6c74 5f65 7870 6c6f 6465  _default_explode
+00001cc0: 2863 6c73 2c20 7374 796c 653a 2050 6172  (cls, style: Par
+00001cd0: 616d 6574 6572 5374 796c 6529 202d 3e20  ameterStyle) -> 
+00001ce0: 626f 6f6c 3a0a 2020 2020 2020 2020 7265  bool:.        re
+00001cf0: 7475 726e 2046 616c 7365 0a0a 2020 2020  turn False..    
+00001d00: 4073 7461 7469 636d 6574 686f 640a 2020  @staticmethod.  
+00001d10: 2020 6465 6620 5f5f 7265 6636 3537 305f    def __ref6570_
+00001d20: 6974 656d 5f76 616c 7565 2869 6e5f 6461  item_value(in_da
+00001d30: 7461 3a20 7479 7069 6e67 2e41 6e79 2c20  ta: typing.Any, 
+00001d40: 7065 7263 656e 745f 656e 636f 6465 3a20  percent_encode: 
+00001d50: 626f 6f6c 293a 0a20 2020 2020 2020 2022  bool):.        "
+00001d60: 2222 0a20 2020 2020 2020 2047 6574 2072  "".        Get r
+00001d70: 6570 7265 7365 6e74 6174 696f 6e20 6966  epresentation if
+00001d80: 2073 7472 2f66 6c6f 6174 2f69 6e74 2f4e   str/float/int/N
+00001d90: 6f6e 652f 6974 656d 7320 696e 206c 6973  one/items in lis
+00001da0: 742f 2076 616c 7565 7320 696e 2064 6963  t/ values in dic
+00001db0: 740a 2020 2020 2020 2020 4e6f 6e65 2069  t.        None i
+00001dc0: 7320 7265 7475 726e 6564 2069 6620 616e  s returned if an
+00001dd0: 2069 7465 6d20 6973 2075 6e64 6566 696e   item is undefin
+00001de0: 6564 2c20 7573 6520 6361 7365 7320 6172  ed, use cases ar
+00001df0: 6520 7661 6c75 653d 0a20 2020 2020 2020  e value=.       
+00001e00: 202d 204e 6f6e 650a 2020 2020 2020 2020   - None.        
+00001e10: 2d20 5b5d 0a20 2020 2020 2020 202d 207b  - [].        - {
+00001e20: 7d0a 2020 2020 2020 2020 2d20 5b4e 6f6e  }.        - [Non
+00001e30: 652c 204e 6f6e 6520 4e6f 6e65 5d0a 2020  e, None None].  
+00001e40: 2020 2020 2020 2d20 7b27 6127 3a20 4e6f        - {'a': No
+00001e50: 6e65 2c20 2762 273a 204e 6f6e 657d 0a20  ne, 'b': None}. 
+00001e60: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+00001e70: 2020 2069 6620 7479 7065 2869 6e5f 6461     if type(in_da
+00001e80: 7461 2920 696e 207b 7374 722c 2066 6c6f  ta) in {str, flo
+00001e90: 6174 2c20 696e 747d 3a0a 2020 2020 2020  at, int}:.      
+00001ea0: 2020 2020 2020 6966 2070 6572 6365 6e74        if percent
+00001eb0: 5f65 6e63 6f64 653a 0a20 2020 2020 2020  _encode:.       
+00001ec0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00001ed0: 7175 6f74 6528 7374 7228 696e 5f64 6174  quote(str(in_dat
+00001ee0: 6129 290a 2020 2020 2020 2020 2020 2020  a)).            
+00001ef0: 7265 7475 726e 2073 7472 2869 6e5f 6461  return str(in_da
+00001f00: 7461 290a 2020 2020 2020 2020 656c 6966  ta).        elif
+00001f10: 2069 7369 6e73 7461 6e63 6528 696e 5f64   isinstance(in_d
+00001f20: 6174 612c 206e 6f6e 655f 7479 7065 293a  ata, none_type):
+00001f30: 0a20 2020 2020 2020 2020 2020 2023 2069  .            # i
+00001f40: 676e 6f72 6564 2062 7920 7468 6520 6578  gnored by the ex
+00001f50: 7061 6e73 696f 6e20 7072 6f63 6573 7320  pansion process 
+00001f60: 6874 7470 733a 2f2f 6461 7461 7472 6163  https://datatrac
+00001f70: 6b65 722e 6965 7466 2e6f 7267 2f64 6f63  ker.ietf.org/doc
+00001f80: 2f68 746d 6c2f 7266 6336 3537 3023 7365  /html/rfc6570#se
+00001f90: 6374 696f 6e2d 332e 322e 310a 2020 2020  ction-3.2.1.    
+00001fa0: 2020 2020 2020 2020 7265 7475 726e 204e          return N
+00001fb0: 6f6e 650a 2020 2020 2020 2020 656c 6966  one.        elif
+00001fc0: 2069 7369 6e73 7461 6e63 6528 696e 5f64   isinstance(in_d
+00001fd0: 6174 612c 206c 6973 7429 2061 6e64 206e  ata, list) and n
+00001fe0: 6f74 2069 6e5f 6461 7461 3a0a 2020 2020  ot in_data:.    
+00001ff0: 2020 2020 2020 2020 2320 6967 6e6f 7265          # ignore
+00002000: 6420 6279 2074 6865 2065 7870 616e 7369  d by the expansi
+00002010: 6f6e 2070 726f 6365 7373 2068 7474 7073  on process https
+00002020: 3a2f 2f64 6174 6174 7261 636b 6572 2e69  ://datatracker.i
+00002030: 6574 662e 6f72 672f 646f 632f 6874 6d6c  etf.org/doc/html
+00002040: 2f72 6663 3635 3730 2373 6563 7469 6f6e  /rfc6570#section
+00002050: 2d33 2e32 2e31 0a20 2020 2020 2020 2020  -3.2.1.         
+00002060: 2020 2072 6574 7572 6e20 4e6f 6e65 0a20     return None. 
+00002070: 2020 2020 2020 2065 6c69 6620 6973 696e         elif isin
+00002080: 7374 616e 6365 2869 6e5f 6461 7461 2c20  stance(in_data, 
+00002090: 6469 6374 2920 616e 6420 6e6f 7420 696e  dict) and not in
+000020a0: 5f64 6174 613a 0a20 2020 2020 2020 2020  _data:.         
+000020b0: 2020 2023 2069 676e 6f72 6564 2062 7920     # ignored by 
+000020c0: 7468 6520 6578 7061 6e73 696f 6e20 7072  the expansion pr
+000020d0: 6f63 6573 7320 6874 7470 733a 2f2f 6461  ocess https://da
+000020e0: 7461 7472 6163 6b65 722e 6965 7466 2e6f  tatracker.ietf.o
+000020f0: 7267 2f64 6f63 2f68 746d 6c2f 7266 6336  rg/doc/html/rfc6
+00002100: 3537 3023 7365 6374 696f 6e2d 332e 322e  570#section-3.2.
+00002110: 310a 2020 2020 2020 2020 2020 2020 7265  1.            re
+00002120: 7475 726e 204e 6f6e 650a 2020 2020 2020  turn None.      
+00002130: 2020 7261 6973 6520 4170 6956 616c 7565    raise ApiValue
+00002140: 4572 726f 7228 2755 6e61 626c 6520 746f  Error('Unable to
+00002150: 2067 656e 6572 6174 6520 6120 7265 6636   generate a ref6
+00002160: 3537 3020 6974 656d 2072 6570 7265 7365  570 item represe
+00002170: 6e74 6174 696f 6e20 6f66 207b 7d27 2e66  ntation of {}'.f
+00002180: 6f72 6d61 7428 696e 5f64 6174 6129 290a  ormat(in_data)).
+00002190: 0a20 2020 2040 7374 6174 6963 6d65 7468  .    @staticmeth
+000021a0: 6f64 0a20 2020 2064 6566 205f 746f 5f64  od.    def _to_d
+000021b0: 6963 7428 6e61 6d65 3a20 7374 722c 2076  ict(name: str, v
+000021c0: 616c 7565 3a20 7374 7229 3a0a 2020 2020  alue: str):.    
+000021d0: 2020 2020 7265 7475 726e 207b 6e61 6d65      return {name
+000021e0: 3a20 7661 6c75 657d 0a0a 2020 2020 2222  : value}..    ""
+000021f0: 220a 2020 2020 7266 6336 3537 3020 646f  ".    rfc6570 do
+00002200: 6573 206e 6f74 2073 7065 6369 6679 2068  es not specify h
+00002210: 6f77 2062 6f6f 6c65 616e 2076 616c 7565  ow boolean value
+00002220: 7320 6172 6520 7365 7269 616c 697a 6564  s are serialized
+00002230: 2073 6f20 7765 2075 7365 206c 6f77 6572   so we use lower
+00002240: 6361 7365 2022 7472 7565 2220 616e 6420  case "true" and 
+00002250: 2266 616c 7365 0a20 2020 2022 2222 0a20  "false.    """. 
+00002260: 2020 2040 636c 6173 736d 6574 686f 640a     @classmethod.
+00002270: 2020 2020 6465 6620 5f5f 6b6f 6e66 6967      def __konfig
+00002280: 5f62 6f6f 6c5f 6578 7061 6e73 696f 6e28  _bool_expansion(
+00002290: 0a20 2020 2020 2020 2063 6c73 2c0a 2020  .        cls,.  
+000022a0: 2020 2020 2020 696e 5f64 6174 613a 2074        in_data: t
+000022b0: 7970 696e 672e 416e 792c 0a20 2020 2020  yping.Any,.     
+000022c0: 2020 2070 7265 6669 785f 7365 7061 7261     prefix_separa
+000022d0: 746f 725f 6974 6572 6174 6f72 3a20 5072  tor_iterator: Pr
+000022e0: 6566 6978 5365 7061 7261 746f 7249 7465  efixSeparatorIte
+000022f0: 7261 746f 722c 0a20 2020 2020 2020 2076  rator,.        v
+00002300: 6172 5f6e 616d 655f 7069 6563 653a 2073  ar_name_piece: s
+00002310: 7472 2c0a 2020 2020 2020 2020 6e61 6d65  tr,.        name
+00002320: 645f 7061 7261 6d65 7465 725f 6578 7061  d_parameter_expa
+00002330: 6e73 696f 6e3a 2062 6f6f 6c0a 2020 2020  nsion: bool.    
+00002340: 2920 2d3e 2073 7472 3a0a 2020 2020 2020  ) -> str:.      
+00002350: 2020 6974 656d 5f76 616c 7565 203d 2022    item_value = "
+00002360: 7472 7565 2220 6966 2069 6e5f 6461 7461  true" if in_data
+00002370: 2069 7320 5472 7565 2065 6c73 6520 2266   is True else "f
+00002380: 616c 7365 220a 2020 2020 2020 2020 6966  alse".        if
+00002390: 2069 7465 6d5f 7661 6c75 6520 6973 204e   item_value is N
+000023a0: 6f6e 6520 6f72 2028 6974 656d 5f76 616c  one or (item_val
+000023b0: 7565 203d 3d20 2727 2061 6e64 2070 7265  ue == '' and pre
+000023c0: 6669 785f 7365 7061 7261 746f 725f 6974  fix_separator_it
+000023d0: 6572 6174 6f72 2e73 6570 6172 6174 6f72  erator.separator
+000023e0: 203d 3d20 273b 2729 3a0a 2020 2020 2020   == ';'):.      
+000023f0: 2020 2020 2020 7265 7475 726e 206e 6578        return nex
+00002400: 7428 7072 6566 6978 5f73 6570 6172 6174  t(prefix_separat
+00002410: 6f72 5f69 7465 7261 746f 7229 202b 2076  or_iterator) + v
+00002420: 6172 5f6e 616d 655f 7069 6563 650a 2020  ar_name_piece.  
+00002430: 2020 2020 2020 7661 6c75 655f 7061 6972        value_pair
+00002440: 5f65 7175 616c 7320 3d20 273d 2720 6966  _equals = '=' if
+00002450: 206e 616d 6564 5f70 6172 616d 6574 6572   named_parameter
+00002460: 5f65 7870 616e 7369 6f6e 2065 6c73 6520  _expansion else 
+00002470: 2727 0a20 2020 2020 2020 2072 6574 7572  ''.        retur
+00002480: 6e20 6e65 7874 2870 7265 6669 785f 7365  n next(prefix_se
+00002490: 7061 7261 746f 725f 6974 6572 6174 6f72  parator_iterator
+000024a0: 2920 2b20 7661 725f 6e61 6d65 5f70 6965  ) + var_name_pie
+000024b0: 6365 202b 2076 616c 7565 5f70 6169 725f  ce + value_pair_
+000024c0: 6571 7561 6c73 202b 2069 7465 6d5f 7661  equals + item_va
+000024d0: 6c75 650a 0a20 2020 2040 636c 6173 736d  lue..    @classm
+000024e0: 6574 686f 640a 2020 2020 6465 6620 5f5f  ethod.    def __
+000024f0: 7265 6636 3537 305f 7374 725f 666c 6f61  ref6570_str_floa
+00002500: 745f 696e 745f 6578 7061 6e73 696f 6e28  t_int_expansion(
+00002510: 0a20 2020 2020 2020 2063 6c73 2c0a 2020  .        cls,.  
+00002520: 2020 2020 2020 7661 7269 6162 6c65 5f6e        variable_n
+00002530: 616d 653a 2073 7472 2c0a 2020 2020 2020  ame: str,.      
+00002540: 2020 696e 5f64 6174 613a 2074 7970 696e    in_data: typin
+00002550: 672e 416e 792c 0a20 2020 2020 2020 2065  g.Any,.        e
+00002560: 7870 6c6f 6465 3a20 626f 6f6c 2c0a 2020  xplode: bool,.  
+00002570: 2020 2020 2020 7065 7263 656e 745f 656e        percent_en
+00002580: 636f 6465 3a20 626f 6f6c 2c0a 2020 2020  code: bool,.    
+00002590: 2020 2020 7072 6566 6978 5f73 6570 6172      prefix_separ
+000025a0: 6174 6f72 5f69 7465 7261 746f 723a 2050  ator_iterator: P
+000025b0: 7265 6669 7853 6570 6172 6174 6f72 4974  refixSeparatorIt
+000025c0: 6572 6174 6f72 2c0a 2020 2020 2020 2020  erator,.        
+000025d0: 7661 725f 6e61 6d65 5f70 6965 6365 3a20  var_name_piece: 
+000025e0: 7374 722c 0a20 2020 2020 2020 206e 616d  str,.        nam
+000025f0: 6564 5f70 6172 616d 6574 6572 5f65 7870  ed_parameter_exp
+00002600: 616e 7369 6f6e 3a20 626f 6f6c 0a20 2020  ansion: bool.   
+00002610: 2029 202d 3e20 7374 723a 0a20 2020 2020   ) -> str:.     
+00002620: 2020 2069 7465 6d5f 7661 6c75 6520 3d20     item_value = 
+00002630: 636c 732e 5f5f 7265 6636 3537 305f 6974  cls.__ref6570_it
+00002640: 656d 5f76 616c 7565 2869 6e5f 6461 7461  em_value(in_data
+00002650: 2c20 7065 7263 656e 745f 656e 636f 6465  , percent_encode
+00002660: 290a 2020 2020 2020 2020 6966 2069 7465  ).        if ite
+00002670: 6d5f 7661 6c75 6520 6973 204e 6f6e 6520  m_value is None 
+00002680: 6f72 2028 6974 656d 5f76 616c 7565 203d  or (item_value =
+00002690: 3d20 2727 2061 6e64 2070 7265 6669 785f  = '' and prefix_
+000026a0: 7365 7061 7261 746f 725f 6974 6572 6174  separator_iterat
+000026b0: 6f72 2e73 6570 6172 6174 6f72 203d 3d20  or.separator == 
+000026c0: 273b 2729 3a0a 2020 2020 2020 2020 2020  ';'):.          
+000026d0: 2020 7265 7475 726e 206e 6578 7428 7072    return next(pr
+000026e0: 6566 6978 5f73 6570 6172 6174 6f72 5f69  efix_separator_i
+000026f0: 7465 7261 746f 7229 202b 2076 6172 5f6e  terator) + var_n
+00002700: 616d 655f 7069 6563 650a 2020 2020 2020  ame_piece.      
+00002710: 2020 7661 6c75 655f 7061 6972 5f65 7175    value_pair_equ
+00002720: 616c 7320 3d20 273d 2720 6966 206e 616d  als = '=' if nam
+00002730: 6564 5f70 6172 616d 6574 6572 5f65 7870  ed_parameter_exp
+00002740: 616e 7369 6f6e 2065 6c73 6520 2727 0a20  ansion else ''. 
+00002750: 2020 2020 2020 2072 6574 7572 6e20 6e65         return ne
+00002760: 7874 2870 7265 6669 785f 7365 7061 7261  xt(prefix_separa
+00002770: 746f 725f 6974 6572 6174 6f72 2920 2b20  tor_iterator) + 
+00002780: 7661 725f 6e61 6d65 5f70 6965 6365 202b  var_name_piece +
+00002790: 2076 616c 7565 5f70 6169 725f 6571 7561   value_pair_equa
+000027a0: 6c73 202b 2069 7465 6d5f 7661 6c75 650a  ls + item_value.
+000027b0: 0a20 2020 2040 636c 6173 736d 6574 686f  .    @classmetho
+000027c0: 640a 2020 2020 6465 6620 5f5f 7265 6636  d.    def __ref6
+000027d0: 3537 305f 6c69 7374 5f65 7870 616e 7369  570_list_expansi
+000027e0: 6f6e 280a 2020 2020 2020 2020 636c 732c  on(.        cls,
+000027f0: 0a20 2020 2020 2020 2076 6172 6961 626c  .        variabl
+00002800: 655f 6e61 6d65 3a20 7374 722c 0a20 2020  e_name: str,.   
+00002810: 2020 2020 2069 6e5f 6461 7461 3a20 7479       in_data: ty
+00002820: 7069 6e67 2e41 6e79 2c0a 2020 2020 2020  ping.Any,.      
+00002830: 2020 6578 706c 6f64 653a 2062 6f6f 6c2c    explode: bool,
+00002840: 0a20 2020 2020 2020 2070 6572 6365 6e74  .        percent
+00002850: 5f65 6e63 6f64 653a 2062 6f6f 6c2c 0a20  _encode: bool,. 
+00002860: 2020 2020 2020 2070 7265 6669 785f 7365         prefix_se
+00002870: 7061 7261 746f 725f 6974 6572 6174 6f72  parator_iterator
+00002880: 3a20 5072 6566 6978 5365 7061 7261 746f  : PrefixSeparato
+00002890: 7249 7465 7261 746f 722c 0a20 2020 2020  rIterator,.     
+000028a0: 2020 2076 6172 5f6e 616d 655f 7069 6563     var_name_piec
+000028b0: 653a 2073 7472 2c0a 2020 2020 2020 2020  e: str,.        
+000028c0: 6e61 6d65 645f 7061 7261 6d65 7465 725f  named_parameter_
+000028d0: 6578 7061 6e73 696f 6e3a 2062 6f6f 6c0a  expansion: bool.
+000028e0: 2020 2020 2920 2d3e 2073 7472 3a0a 2020      ) -> str:.  
+000028f0: 2020 2020 2020 6974 656d 5f76 616c 7565        item_value
+00002900: 7320 3d20 5b63 6c73 2e5f 5f72 6566 3635  s = [cls.__ref65
+00002910: 3730 5f69 7465 6d5f 7661 6c75 6528 762c  70_item_value(v,
+00002920: 2070 6572 6365 6e74 5f65 6e63 6f64 6529   percent_encode)
+00002930: 2066 6f72 2076 2069 6e20 696e 5f64 6174   for v in in_dat
+00002940: 615d 0a20 2020 2020 2020 2069 7465 6d5f  a].        item_
+00002950: 7661 6c75 6573 203d 205b 7620 666f 7220  values = [v for 
+00002960: 7620 696e 2069 7465 6d5f 7661 6c75 6573  v in item_values
+00002970: 2069 6620 7620 6973 206e 6f74 204e 6f6e   if v is not Non
+00002980: 655d 0a20 2020 2020 2020 2069 6620 6e6f  e].        if no
+00002990: 7420 6974 656d 5f76 616c 7565 733a 0a20  t item_values:. 
+000029a0: 2020 2020 2020 2020 2020 2023 2069 676e             # ign
+000029b0: 6f72 6564 2062 7920 7468 6520 6578 7061  ored by the expa
+000029c0: 6e73 696f 6e20 7072 6f63 6573 7320 6874  nsion process ht
+000029d0: 7470 733a 2f2f 6461 7461 7472 6163 6b65  tps://datatracke
+000029e0: 722e 6965 7466 2e6f 7267 2f64 6f63 2f68  r.ietf.org/doc/h
+000029f0: 746d 6c2f 7266 6336 3537 3023 7365 6374  tml/rfc6570#sect
+00002a00: 696f 6e2d 332e 322e 310a 2020 2020 2020  ion-3.2.1.      
+00002a10: 2020 2020 2020 7265 7475 726e 2022 220a        return "".
+00002a20: 2020 2020 2020 2020 7661 6c75 655f 7061          value_pa
+00002a30: 6972 5f65 7175 616c 7320 3d20 273d 2720  ir_equals = '=' 
+00002a40: 6966 206e 616d 6564 5f70 6172 616d 6574  if named_paramet
+00002a50: 6572 5f65 7870 616e 7369 6f6e 2065 6c73  er_expansion els
+00002a60: 6520 2727 0a20 2020 2020 2020 2069 6620  e ''.        if 
+00002a70: 6e6f 7420 6578 706c 6f64 653a 0a20 2020  not explode:.   
+00002a80: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00002a90: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+00002aa0: 2020 6e65 7874 2870 7265 6669 785f 7365    next(prefix_se
+00002ab0: 7061 7261 746f 725f 6974 6572 6174 6f72  parator_iterator
+00002ac0: 2920 2b0a 2020 2020 2020 2020 2020 2020  ) +.            
+00002ad0: 2020 2020 7661 725f 6e61 6d65 5f70 6965      var_name_pie
+00002ae0: 6365 202b 0a20 2020 2020 2020 2020 2020  ce +.           
+00002af0: 2020 2020 2076 616c 7565 5f70 6169 725f       value_pair_
+00002b00: 6571 7561 6c73 202b 0a20 2020 2020 2020  equals +.       
+00002b10: 2020 2020 2020 2020 2070 7265 6669 785f           prefix_
+00002b20: 7365 7061 7261 746f 725f 6974 6572 6174  separator_iterat
+00002b30: 6f72 2e69 7465 6d5f 7365 7061 7261 746f  or.item_separato
+00002b40: 722e 6a6f 696e 2869 7465 6d5f 7661 6c75  r.join(item_valu
+00002b50: 6573 290a 2020 2020 2020 2020 2020 2020  es).            
+00002b60: 290a 2020 2020 2020 2020 2320 6578 706c  ).        # expl
+00002b70: 6f64 6564 0a20 2020 2020 2020 2072 6574  oded.        ret
+00002b80: 7572 6e20 6e65 7874 2870 7265 6669 785f  urn next(prefix_
+00002b90: 7365 7061 7261 746f 725f 6974 6572 6174  separator_iterat
+00002ba0: 6f72 2920 2b20 6e65 7874 2870 7265 6669  or) + next(prefi
+00002bb0: 785f 7365 7061 7261 746f 725f 6974 6572  x_separator_iter
+00002bc0: 6174 6f72 292e 6a6f 696e 280a 2020 2020  ator).join(.    
+00002bd0: 2020 2020 2020 2020 5b76 6172 5f6e 616d          [var_nam
+00002be0: 655f 7069 6563 6520 2b20 7661 6c75 655f  e_piece + value_
+00002bf0: 7061 6972 5f65 7175 616c 7320 2b20 7661  pair_equals + va
+00002c00: 6c20 666f 7220 7661 6c20 696e 2069 7465  l for val in ite
+00002c10: 6d5f 7661 6c75 6573 5d0a 2020 2020 2020  m_values].      
+00002c20: 2020 290a 0a20 2020 2040 636c 6173 736d    )..    @classm
+00002c30: 6574 686f 640a 2020 2020 6465 6620 5f5f  ethod.    def __
+00002c40: 7265 6636 3537 305f 6469 6374 5f65 7870  ref6570_dict_exp
+00002c50: 616e 7369 6f6e 280a 2020 2020 2020 2020  ansion(.        
+00002c60: 636c 732c 0a20 2020 2020 2020 2076 6172  cls,.        var
+00002c70: 6961 626c 655f 6e61 6d65 3a20 7374 722c  iable_name: str,
+00002c80: 0a20 2020 2020 2020 2069 6e5f 6461 7461  .        in_data
+00002c90: 3a20 7479 7069 6e67 2e41 6e79 2c0a 2020  : typing.Any,.  
+00002ca0: 2020 2020 2020 6578 706c 6f64 653a 2062        explode: b
+00002cb0: 6f6f 6c2c 0a20 2020 2020 2020 2070 6572  ool,.        per
+00002cc0: 6365 6e74 5f65 6e63 6f64 653a 2062 6f6f  cent_encode: boo
+00002cd0: 6c2c 0a20 2020 2020 2020 2070 7265 6669  l,.        prefi
+00002ce0: 785f 7365 7061 7261 746f 725f 6974 6572  x_separator_iter
+00002cf0: 6174 6f72 3a20 5072 6566 6978 5365 7061  ator: PrefixSepa
+00002d00: 7261 746f 7249 7465 7261 746f 722c 0a20  ratorIterator,. 
+00002d10: 2020 2020 2020 2076 6172 5f6e 616d 655f         var_name_
+00002d20: 7069 6563 653a 2073 7472 2c0a 2020 2020  piece: str,.    
+00002d30: 2020 2020 6e61 6d65 645f 7061 7261 6d65      named_parame
+00002d40: 7465 725f 6578 7061 6e73 696f 6e3a 2062  ter_expansion: b
+00002d50: 6f6f 6c0a 2020 2020 2920 2d3e 2073 7472  ool.    ) -> str
+00002d60: 3a0a 2020 2020 2020 2020 696e 5f64 6174  :.        in_dat
+00002d70: 615f 7472 616e 7366 6f72 6d65 6420 3d20  a_transformed = 
+00002d80: 7b6b 6579 3a20 636c 732e 5f5f 7265 6636  {key: cls.__ref6
+00002d90: 3537 305f 6974 656d 5f76 616c 7565 2876  570_item_value(v
+00002da0: 616c 2c20 7065 7263 656e 745f 656e 636f  al, percent_enco
+00002db0: 6465 2920 666f 7220 6b65 792c 2076 616c  de) for key, val
+00002dc0: 2069 6e20 696e 5f64 6174 612e 6974 656d   in in_data.item
+00002dd0: 7328 297d 0a20 2020 2020 2020 2069 6e5f  s()}.        in_
+00002de0: 6461 7461 5f74 7261 6e73 666f 726d 6564  data_transformed
+00002df0: 203d 207b 6b65 793a 2076 616c 2066 6f72   = {key: val for
+00002e00: 206b 6579 2c20 7661 6c20 696e 2069 6e5f   key, val in in_
+00002e10: 6461 7461 5f74 7261 6e73 666f 726d 6564  data_transformed
+00002e20: 2e69 7465 6d73 2829 2069 6620 7661 6c20  .items() if val 
+00002e30: 6973 206e 6f74 204e 6f6e 657d 0a20 2020  is not None}.   
+00002e40: 2020 2020 2069 6620 6e6f 7420 696e 5f64       if not in_d
+00002e50: 6174 615f 7472 616e 7366 6f72 6d65 643a  ata_transformed:
+00002e60: 0a20 2020 2020 2020 2020 2020 2023 2069  .            # i
+00002e70: 676e 6f72 6564 2062 7920 7468 6520 6578  gnored by the ex
+00002e80: 7061 6e73 696f 6e20 7072 6f63 6573 7320  pansion process 
+00002e90: 6874 7470 733a 2f2f 6461 7461 7472 6163  https://datatrac
+00002ea0: 6b65 722e 6965 7466 2e6f 7267 2f64 6f63  ker.ietf.org/doc
+00002eb0: 2f68 746d 6c2f 7266 6336 3537 3023 7365  /html/rfc6570#se
+00002ec0: 6374 696f 6e2d 332e 322e 310a 2020 2020  ction-3.2.1.    
+00002ed0: 2020 2020 2020 2020 7265 7475 726e 2022          return "
+00002ee0: 220a 2020 2020 2020 2020 7661 6c75 655f  ".        value_
+00002ef0: 7061 6972 5f65 7175 616c 7320 3d20 273d  pair_equals = '=
+00002f00: 2720 6966 206e 616d 6564 5f70 6172 616d  ' if named_param
+00002f10: 6574 6572 5f65 7870 616e 7369 6f6e 2065  eter_expansion e
+00002f20: 6c73 6520 2727 0a20 2020 2020 2020 2069  lse ''.        i
+00002f30: 6620 6e6f 7420 6578 706c 6f64 653a 0a20  f not explode:. 
+00002f40: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+00002f50: 6e20 280a 2020 2020 2020 2020 2020 2020  n (.            
+00002f60: 2020 2020 6e65 7874 2870 7265 6669 785f      next(prefix_
+00002f70: 7365 7061 7261 746f 725f 6974 6572 6174  separator_iterat
+00002f80: 6f72 2920 2b0a 2020 2020 2020 2020 2020  or) +.          
+00002f90: 2020 2020 2020 7661 725f 6e61 6d65 5f70        var_name_p
+00002fa0: 6965 6365 202b 2076 616c 7565 5f70 6169  iece + value_pai
+00002fb0: 725f 6571 7561 6c73 202b 0a20 2020 2020  r_equals +.     
+00002fc0: 2020 2020 2020 2020 2020 2070 7265 6669             prefi
+00002fd0: 785f 7365 7061 7261 746f 725f 6974 6572  x_separator_iter
+00002fe0: 6174 6f72 2e69 7465 6d5f 7365 7061 7261  ator.item_separa
+00002ff0: 746f 722e 6a6f 696e 280a 2020 2020 2020  tor.join(.      
+00003000: 2020 2020 2020 2020 2020 2020 2020 7072                pr
+00003010: 6566 6978 5f73 6570 6172 6174 6f72 5f69  efix_separator_i
+00003020: 7465 7261 746f 722e 6974 656d 5f73 6570  terator.item_sep
+00003030: 6172 6174 6f72 2e6a 6f69 6e28 0a20 2020  arator.join(.   
+00003040: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003050: 2020 2020 2069 7465 6d5f 7061 6972 0a20       item_pair. 
+00003060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003070: 2020 2029 2066 6f72 2069 7465 6d5f 7061     ) for item_pa
+00003080: 6972 2069 6e20 696e 5f64 6174 615f 7472  ir in in_data_tr
+00003090: 616e 7366 6f72 6d65 642e 6974 656d 7328  ansformed.items(
+000030a0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+000030b0: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
+000030c0: 290a 2020 2020 2020 2020 2320 6578 706c  ).        # expl
+000030d0: 6f64 6564 0a20 2020 2020 2020 2072 6574  oded.        ret
+000030e0: 7572 6e20 6e65 7874 2870 7265 6669 785f  urn next(prefix_
+000030f0: 7365 7061 7261 746f 725f 6974 6572 6174  separator_iterat
+00003100: 6f72 2920 2b20 6e65 7874 2870 7265 6669  or) + next(prefi
+00003110: 785f 7365 7061 7261 746f 725f 6974 6572  x_separator_iter
+00003120: 6174 6f72 292e 6a6f 696e 280a 2020 2020  ator).join(.    
+00003130: 2020 2020 2020 2020 5b6b 6579 202b 2027          [key + '
+00003140: 3d27 202b 2076 616c 2066 6f72 206b 6579  =' + val for key
+00003150: 2c20 7661 6c20 696e 2069 6e5f 6461 7461  , val in in_data
+00003160: 5f74 7261 6e73 666f 726d 6564 2e69 7465  _transformed.ite
+00003170: 6d73 2829 5d0a 2020 2020 2020 2020 290a  ms()].        ).
+00003180: 0a20 2020 2040 636c 6173 736d 6574 686f  .    @classmetho
+00003190: 640a 2020 2020 6465 6620 5f72 6566 3635  d.    def _ref65
+000031a0: 3730 5f65 7870 616e 7369 6f6e 280a 2020  70_expansion(.  
+000031b0: 2020 2020 2020 636c 732c 0a20 2020 2020        cls,.     
+000031c0: 2020 2076 6172 6961 626c 655f 6e61 6d65     variable_name
+000031d0: 3a20 7374 722c 0a20 2020 2020 2020 2069  : str,.        i
+000031e0: 6e5f 6461 7461 3a20 7479 7069 6e67 2e41  n_data: typing.A
+000031f0: 6e79 2c0a 2020 2020 2020 2020 6578 706c  ny,.        expl
+00003200: 6f64 653a 2062 6f6f 6c2c 0a20 2020 2020  ode: bool,.     
+00003210: 2020 2070 6572 6365 6e74 5f65 6e63 6f64     percent_encod
+00003220: 653a 2062 6f6f 6c2c 0a20 2020 2020 2020  e: bool,.       
+00003230: 2070 7265 6669 785f 7365 7061 7261 746f   prefix_separato
+00003240: 725f 6974 6572 6174 6f72 3a20 5072 6566  r_iterator: Pref
+00003250: 6978 5365 7061 7261 746f 7249 7465 7261  ixSeparatorItera
+00003260: 746f 720a 2020 2020 2920 2d3e 2073 7472  tor.    ) -> str
+00003270: 3a0a 2020 2020 2020 2020 2222 220a 2020  :.        """.  
+00003280: 2020 2020 2020 5365 7061 7261 746f 7220        Separator 
+00003290: 6973 2066 6f72 2073 6570 6172 6174 6520  is for separate 
+000032a0: 7661 7269 6162 6c65 7320 6c69 6b65 2064  variables like d
+000032b0: 6963 7420 7769 7468 2065 7870 6c6f 6465  ict with explode
+000032c0: 2074 7275 652c 206e 6f74 2066 6f72 2061   true, not for a
+000032d0: 7272 6179 2069 7465 6d20 7365 7061 7261  rray item separa
+000032e0: 7469 6f6e 0a20 2020 2020 2020 2022 2222  tion.        """
+000032f0: 0a20 2020 2020 2020 206e 616d 6564 5f70  .        named_p
+00003300: 6172 616d 6574 6572 5f65 7870 616e 7369  arameter_expansi
+00003310: 6f6e 203d 2070 7265 6669 785f 7365 7061  on = prefix_sepa
+00003320: 7261 746f 725f 6974 6572 6174 6f72 2e73  rator_iterator.s
+00003330: 6570 6172 6174 6f72 2069 6e20 7b27 2627  eparator in {'&'
+00003340: 2c20 273b 277d 0a20 2020 2020 2020 2076  , ';'}.        v
+00003350: 6172 5f6e 616d 655f 7069 6563 6520 3d20  ar_name_piece = 
+00003360: 7661 7269 6162 6c65 5f6e 616d 6520 6966  variable_name if
+00003370: 206e 616d 6564 5f70 6172 616d 6574 6572   named_parameter
+00003380: 5f65 7870 616e 7369 6f6e 2065 6c73 6520  _expansion else 
+00003390: 2727 0a20 2020 2020 2020 2069 6620 7479  ''.        if ty
+000033a0: 7065 2869 6e5f 6461 7461 2920 696e 207b  pe(in_data) in {
+000033b0: 7374 722c 2066 6c6f 6174 2c20 696e 747d  str, float, int}
+000033c0: 3a0a 2020 2020 2020 2020 2020 2020 7265  :.            re
+000033d0: 7475 726e 2063 6c73 2e5f 5f72 6566 3635  turn cls.__ref65
+000033e0: 3730 5f73 7472 5f66 6c6f 6174 5f69 6e74  70_str_float_int
+000033f0: 5f65 7870 616e 7369 6f6e 280a 2020 2020  _expansion(.    
+00003400: 2020 2020 2020 2020 2020 2020 7661 7269              vari
+00003410: 6162 6c65 5f6e 616d 652c 0a20 2020 2020  able_name,.     
+00003420: 2020 2020 2020 2020 2020 2069 6e5f 6461             in_da
+00003430: 7461 2c0a 2020 2020 2020 2020 2020 2020  ta,.            
+00003440: 2020 2020 6578 706c 6f64 652c 0a20 2020      explode,.   
+00003450: 2020 2020 2020 2020 2020 2020 2070 6572               per
+00003460: 6365 6e74 5f65 6e63 6f64 652c 0a20 2020  cent_encode,.   
+00003470: 2020 2020 2020 2020 2020 2020 2070 7265               pre
+00003480: 6669 785f 7365 7061 7261 746f 725f 6974  fix_separator_it
+00003490: 6572 6174 6f72 2c0a 2020 2020 2020 2020  erator,.        
+000034a0: 2020 2020 2020 2020 7661 725f 6e61 6d65          var_name
+000034b0: 5f70 6965 6365 2c0a 2020 2020 2020 2020  _piece,.        
+000034c0: 2020 2020 2020 2020 6e61 6d65 645f 7061          named_pa
+000034d0: 7261 6d65 7465 725f 6578 7061 6e73 696f  rameter_expansio
+000034e0: 6e0a 2020 2020 2020 2020 2020 2020 290a  n.            ).
+000034f0: 2020 2020 2020 2020 656c 6966 2069 7369          elif isi
+00003500: 6e73 7461 6e63 6528 696e 5f64 6174 612c  nstance(in_data,
+00003510: 206e 6f6e 655f 7479 7065 293a 0a20 2020   none_type):.   
+00003520: 2020 2020 2020 2020 2023 2069 676e 6f72           # ignor
+00003530: 6564 2062 7920 7468 6520 6578 7061 6e73  ed by the expans
+00003540: 696f 6e20 7072 6f63 6573 7320 6874 7470  ion process http
+00003550: 733a 2f2f 6461 7461 7472 6163 6b65 722e  s://datatracker.
+00003560: 6965 7466 2e6f 7267 2f64 6f63 2f68 746d  ietf.org/doc/htm
+00003570: 6c2f 7266 6336 3537 3023 7365 6374 696f  l/rfc6570#sectio
+00003580: 6e2d 332e 322e 310a 2020 2020 2020 2020  n-3.2.1.        
+00003590: 2020 2020 7265 7475 726e 2022 220a 2020      return "".  
+000035a0: 2020 2020 2020 656c 6966 2069 7369 6e73        elif isins
+000035b0: 7461 6e63 6528 696e 5f64 6174 612c 206c  tance(in_data, l
+000035c0: 6973 7429 3a0a 2020 2020 2020 2020 2020  ist):.          
+000035d0: 2020 7265 7475 726e 2063 6c73 2e5f 5f72    return cls.__r
+000035e0: 6566 3635 3730 5f6c 6973 745f 6578 7061  ef6570_list_expa
+000035f0: 6e73 696f 6e28 0a20 2020 2020 2020 2020  nsion(.         
+00003600: 2020 2020 2020 2076 6172 6961 626c 655f         variable_
+00003610: 6e61 6d65 2c0a 2020 2020 2020 2020 2020  name,.          
+00003620: 2020 2020 2020 696e 5f64 6174 612c 0a20        in_data,. 
+00003630: 2020 2020 2020 2020 2020 2020 2020 2065                 e
+00003640: 7870 6c6f 6465 2c0a 2020 2020 2020 2020  xplode,.        
+00003650: 2020 2020 2020 2020 7065 7263 656e 745f          percent_
+00003660: 656e 636f 6465 2c0a 2020 2020 2020 2020  encode,.        
+00003670: 2020 2020 2020 2020 7072 6566 6978 5f73          prefix_s
+00003680: 6570 6172 6174 6f72 5f69 7465 7261 746f  eparator_iterato
+00003690: 722c 0a20 2020 2020 2020 2020 2020 2020  r,.             
+000036a0: 2020 2076 6172 5f6e 616d 655f 7069 6563     var_name_piec
+000036b0: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
+000036c0: 2020 206e 616d 6564 5f70 6172 616d 6574     named_paramet
+000036d0: 6572 5f65 7870 616e 7369 6f6e 0a20 2020  er_expansion.   
+000036e0: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
+000036f0: 2020 2065 6c69 6620 6973 696e 7374 616e     elif isinstan
+00003700: 6365 2869 6e5f 6461 7461 2c20 6469 6374  ce(in_data, dict
+00003710: 293a 0a20 2020 2020 2020 2020 2020 2072  ):.            r
+00003720: 6574 7572 6e20 636c 732e 5f5f 7265 6636  eturn cls.__ref6
+00003730: 3537 305f 6469 6374 5f65 7870 616e 7369  570_dict_expansi
+00003740: 6f6e 280a 2020 2020 2020 2020 2020 2020  on(.            
+00003750: 2020 2020 7661 7269 6162 6c65 5f6e 616d      variable_nam
+00003760: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
+00003770: 2020 2069 6e5f 6461 7461 2c0a 2020 2020     in_data,.    
+00003780: 2020 2020 2020 2020 2020 2020 6578 706c              expl
+00003790: 6f64 652c 0a20 2020 2020 2020 2020 2020  ode,.           
+000037a0: 2020 2020 2070 6572 6365 6e74 5f65 6e63       percent_enc
+000037b0: 6f64 652c 0a20 2020 2020 2020 2020 2020  ode,.           
+000037c0: 2020 2020 2070 7265 6669 785f 7365 7061       prefix_sepa
+000037d0: 7261 746f 725f 6974 6572 6174 6f72 2c0a  rator_iterator,.
+000037e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000037f0: 7661 725f 6e61 6d65 5f70 6965 6365 2c0a  var_name_piece,.
+00003800: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003810: 6e61 6d65 645f 7061 7261 6d65 7465 725f  named_parameter_
+00003820: 6578 7061 6e73 696f 6e0a 2020 2020 2020  expansion.      
+00003830: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+00003840: 656c 6966 2069 7369 6e73 7461 6e63 6528  elif isinstance(
+00003850: 696e 5f64 6174 612c 2062 6f6f 6c29 3a0a  in_data, bool):.
+00003860: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+00003870: 726e 2063 6c73 2e5f 5f6b 6f6e 6669 675f  rn cls.__konfig_
+00003880: 626f 6f6c 5f65 7870 616e 7369 6f6e 280a  bool_expansion(.
+00003890: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000038a0: 696e 5f64 6174 612c 0a20 2020 2020 2020  in_data,.       
+000038b0: 2020 2020 2020 2020 2070 7265 6669 785f           prefix_
+000038c0: 7365 7061 7261 746f 725f 6974 6572 6174  separator_iterat
+000038d0: 6f72 2c0a 2020 2020 2020 2020 2020 2020  or,.            
+000038e0: 2020 2020 7661 725f 6e61 6d65 5f70 6965      var_name_pie
+000038f0: 6365 2c0a 2020 2020 2020 2020 2020 2020  ce,.            
+00003900: 2020 2020 6e61 6d65 645f 7061 7261 6d65      named_parame
+00003910: 7465 725f 6578 7061 6e73 696f 6e0a 2020  ter_expansion.  
+00003920: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
+00003930: 2020 2020 2320 6279 7465 732c 2065 7463      # bytes, etc
+00003940: 0a20 2020 2020 2020 2072 6169 7365 2041  .        raise A
+00003950: 7069 5661 6c75 6545 7272 6f72 2827 556e  piValueError('Un
+00003960: 6162 6c65 2074 6f20 6765 6e65 7261 7465  able to generate
+00003970: 2061 2072 6566 3635 3730 2072 6570 7265   a ref6570 repre
+00003980: 7365 6e74 6174 696f 6e20 6f66 207b 7d27  sentation of {}'
+00003990: 2e66 6f72 6d61 7428 696e 5f64 6174 6129  .format(in_data)
+000039a0: 290a 0a0a 636c 6173 7320 5374 796c 6546  )...class StyleF
+000039b0: 6f72 6d53 6572 6961 6c69 7a65 7228 5061  ormSerializer(Pa
+000039c0: 7261 6d65 7465 7253 6572 6961 6c69 7a65  rameterSerialize
+000039d0: 7242 6173 6529 3a0a 2020 2020 4063 6c61  rBase):.    @cla
+000039e0: 7373 6d65 7468 6f64 0a20 2020 2064 6566  ssmethod.    def
+000039f0: 205f 6765 745f 6465 6661 756c 745f 6578   _get_default_ex
+00003a00: 706c 6f64 6528 636c 732c 2073 7479 6c65  plode(cls, style
+00003a10: 3a20 5061 7261 6d65 7465 7253 7479 6c65  : ParameterStyle
+00003a20: 2920 2d3e 2062 6f6f 6c3a 0a20 2020 2020  ) -> bool:.     
+00003a30: 2020 2069 6620 7374 796c 6520 6973 2050     if style is P
+00003a40: 6172 616d 6574 6572 5374 796c 652e 464f  arameterStyle.FO
+00003a50: 524d 3a0a 2020 2020 2020 2020 2020 2020  RM:.            
+00003a60: 7265 7475 726e 2054 7275 650a 2020 2020  return True.    
+00003a70: 2020 2020 7265 7475 726e 2073 7570 6572      return super
+00003a80: 2829 2e5f 6765 745f 6465 6661 756c 745f  ()._get_default_
+00003a90: 6578 706c 6f64 6528 7374 796c 6529 0a0a  explode(style)..
+00003aa0: 2020 2020 6465 6620 5f73 6572 6961 6c69      def _seriali
+00003ab0: 7a65 5f66 6f72 6d28 0a20 2020 2020 2020  ze_form(.       
+00003ac0: 2073 656c 662c 0a20 2020 2020 2020 2069   self,.        i
+00003ad0: 6e5f 6461 7461 3a20 7479 7069 6e67 2e55  n_data: typing.U
+00003ae0: 6e69 6f6e 5b4e 6f6e 652c 2069 6e74 2c20  nion[None, int, 
+00003af0: 666c 6f61 742c 2073 7472 2c20 626f 6f6c  float, str, bool
+00003b00: 2c20 6469 6374 2c20 6c69 7374 5d2c 0a20  , dict, list],. 
+00003b10: 2020 2020 2020 206e 616d 653a 2073 7472         name: str
+00003b20: 2c0a 2020 2020 2020 2020 6578 706c 6f64  ,.        explod
+00003b30: 653a 2062 6f6f 6c2c 0a20 2020 2020 2020  e: bool,.       
+00003b40: 2070 6572 6365 6e74 5f65 6e63 6f64 653a   percent_encode:
+00003b50: 2062 6f6f 6c2c 0a20 2020 2020 2020 2070   bool,.        p
+00003b60: 7265 6669 785f 7365 7061 7261 746f 725f  refix_separator_
+00003b70: 6974 6572 6174 6f72 3a20 7479 7069 6e67  iterator: typing
+00003b80: 2e4f 7074 696f 6e61 6c5b 5072 6566 6978  .Optional[Prefix
+00003b90: 5365 7061 7261 746f 7249 7465 7261 746f  SeparatorIterato
+00003ba0: 725d 203d 204e 6f6e 650a 2020 2020 2920  r] = None.    ) 
+00003bb0: 2d3e 2073 7472 3a0a 2020 2020 2020 2020  -> str:.        
+00003bc0: 6966 2070 7265 6669 785f 7365 7061 7261  if prefix_separa
+00003bd0: 746f 725f 6974 6572 6174 6f72 2069 7320  tor_iterator is 
+00003be0: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+00003bf0: 2020 7072 6566 6978 5f73 6570 6172 6174    prefix_separat
+00003c00: 6f72 5f69 7465 7261 746f 7220 3d20 5072  or_iterator = Pr
+00003c10: 6566 6978 5365 7061 7261 746f 7249 7465  efixSeparatorIte
+00003c20: 7261 746f 7228 2727 2c20 2726 2729 0a20  rator('', '&'). 
+00003c30: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
+00003c40: 6c66 2e5f 7265 6636 3537 305f 6578 7061  lf._ref6570_expa
+00003c50: 6e73 696f 6e28 0a20 2020 2020 2020 2020  nsion(.         
+00003c60: 2020 2076 6172 6961 626c 655f 6e61 6d65     variable_name
+00003c70: 3d6e 616d 652c 0a20 2020 2020 2020 2020  =name,.         
+00003c80: 2020 2069 6e5f 6461 7461 3d69 6e5f 6461     in_data=in_da
+00003c90: 7461 2c0a 2020 2020 2020 2020 2020 2020  ta,.            
+00003ca0: 6578 706c 6f64 653d 6578 706c 6f64 652c  explode=explode,
+00003cb0: 0a20 2020 2020 2020 2020 2020 2070 6572  .            per
+00003cc0: 6365 6e74 5f65 6e63 6f64 653d 7065 7263  cent_encode=perc
+00003cd0: 656e 745f 656e 636f 6465 2c0a 2020 2020  ent_encode,.    
+00003ce0: 2020 2020 2020 2020 7072 6566 6978 5f73          prefix_s
+00003cf0: 6570 6172 6174 6f72 5f69 7465 7261 746f  eparator_iterato
+00003d00: 723d 7072 6566 6978 5f73 6570 6172 6174  r=prefix_separat
+00003d10: 6f72 5f69 7465 7261 746f 720a 2020 2020  or_iterator.    
+00003d20: 2020 2020 290a 0a0a 636c 6173 7320 5374      )...class St
+00003d30: 796c 6553 696d 706c 6553 6572 6961 6c69  yleSimpleSeriali
+00003d40: 7a65 7228 5061 7261 6d65 7465 7253 6572  zer(ParameterSer
+00003d50: 6961 6c69 7a65 7242 6173 6529 3a0a 0a20  ializerBase):.. 
+00003d60: 2020 2064 6566 205f 7365 7269 616c 697a     def _serializ
+00003d70: 655f 7369 6d70 6c65 280a 2020 2020 2020  e_simple(.      
+00003d80: 2020 7365 6c66 2c0a 2020 2020 2020 2020    self,.        
+00003d90: 696e 5f64 6174 613a 2074 7970 696e 672e  in_data: typing.
+00003da0: 556e 696f 6e5b 4e6f 6e65 2c20 696e 742c  Union[None, int,
+00003db0: 2066 6c6f 6174 2c20 7374 722c 2062 6f6f   float, str, boo
+00003dc0: 6c2c 2064 6963 742c 206c 6973 745d 2c0a  l, dict, list],.
+00003dd0: 2020 2020 2020 2020 6e61 6d65 3a20 7374          name: st
+00003de0: 722c 0a20 2020 2020 2020 2065 7870 6c6f  r,.        explo
+00003df0: 6465 3a20 626f 6f6c 2c0a 2020 2020 2020  de: bool,.      
+00003e00: 2020 7065 7263 656e 745f 656e 636f 6465    percent_encode
+00003e10: 3a20 626f 6f6c 0a20 2020 2029 202d 3e20  : bool.    ) -> 
+00003e20: 7374 723a 0a20 2020 2020 2020 2070 7265  str:.        pre
+00003e30: 6669 785f 7365 7061 7261 746f 725f 6974  fix_separator_it
+00003e40: 6572 6174 6f72 203d 2050 7265 6669 7853  erator = PrefixS
+00003e50: 6570 6172 6174 6f72 4974 6572 6174 6f72  eparatorIterator
+00003e60: 2827 272c 2027 2c27 290a 2020 2020 2020  ('', ',').      
+00003e70: 2020 7265 7475 726e 2073 656c 662e 5f72    return self._r
+00003e80: 6566 3635 3730 5f65 7870 616e 7369 6f6e  ef6570_expansion
+00003e90: 280a 2020 2020 2020 2020 2020 2020 7661  (.            va
+00003ea0: 7269 6162 6c65 5f6e 616d 653d 6e61 6d65  riable_name=name
+00003eb0: 2c0a 2020 2020 2020 2020 2020 2020 696e  ,.            in
+00003ec0: 5f64 6174 613d 696e 5f64 6174 612c 0a20  _data=in_data,. 
+00003ed0: 2020 2020 2020 2020 2020 2065 7870 6c6f             explo
+00003ee0: 6465 3d65 7870 6c6f 6465 2c0a 2020 2020  de=explode,.    
+00003ef0: 2020 2020 2020 2020 7065 7263 656e 745f          percent_
+00003f00: 656e 636f 6465 3d70 6572 6365 6e74 5f65  encode=percent_e
+00003f10: 6e63 6f64 652c 0a20 2020 2020 2020 2020  ncode,.         
+00003f20: 2020 2070 7265 6669 785f 7365 7061 7261     prefix_separa
+00003f30: 746f 725f 6974 6572 6174 6f72 3d70 7265  tor_iterator=pre
+00003f40: 6669 785f 7365 7061 7261 746f 725f 6974  fix_separator_it
+00003f50: 6572 6174 6f72 0a20 2020 2020 2020 2029  erator.        )
+00003f60: 0a0a 0a63 6c61 7373 204a 534f 4e44 6574  ...class JSONDet
+00003f70: 6563 746f 723a 0a20 2020 2022 2222 0a20  ector:.    """. 
+00003f80: 2020 2057 6f72 6b73 2066 6f72 3a0a 2020     Works for:.  
+00003f90: 2020 6170 706c 6963 6174 696f 6e2f 6a73    application/js
+00003fa0: 6f6e 0a20 2020 2061 7070 6c69 6361 7469  on.    applicati
+00003fb0: 6f6e 2f6a 736f 6e3b 2063 6861 7273 6574  on/json; charset
+00003fc0: 3d55 5446 2d38 0a20 2020 2061 7070 6c69  =UTF-8.    appli
+00003fd0: 6361 7469 6f6e 2f6a 736f 6e2d 7061 7463  cation/json-patc
+00003fe0: 682b 6a73 6f6e 0a20 2020 2061 7070 6c69  h+json.    appli
+00003ff0: 6361 7469 6f6e 2f67 656f 2b6a 736f 6e0a  cation/geo+json.
+00004000: 2020 2020 2222 220a 2020 2020 5f5f 6a73      """.    __js
+00004010: 6f6e 5f63 6f6e 7465 6e74 5f74 7970 655f  on_content_type_
+00004020: 7061 7474 6572 6e20 3d20 7265 2e63 6f6d  pattern = re.com
+00004030: 7069 6c65 2822 6170 706c 6963 6174 696f  pile("applicatio
+00004040: 6e2f 5b5e 2b5d 2a5b 2b5d 3f28 6a73 6f6e  n/[^+]*[+]?(json
+00004050: 293b 3f2e 2a22 290a 0a20 2020 2040 636c  );?.*")..    @cl
+00004060: 6173 736d 6574 686f 640a 2020 2020 6465  assmethod.    de
+00004070: 6620 5f63 6f6e 7465 6e74 5f74 7970 655f  f _content_type_
+00004080: 6973 5f6a 736f 6e28 636c 732c 2063 6f6e  is_json(cls, con
+00004090: 7465 6e74 5f74 7970 653a 2073 7472 2920  tent_type: str) 
+000040a0: 2d3e 2062 6f6f 6c3a 0a20 2020 2020 2020  -> bool:.       
+000040b0: 2069 6620 636c 732e 5f5f 6a73 6f6e 5f63   if cls.__json_c
+000040c0: 6f6e 7465 6e74 5f74 7970 655f 7061 7474  ontent_type_patt
+000040d0: 6572 6e2e 6d61 7463 6828 636f 6e74 656e  ern.match(conten
+000040e0: 745f 7479 7065 293a 0a20 2020 2020 2020  t_type):.       
+000040f0: 2020 2020 2072 6574 7572 6e20 5472 7565       return True
+00004100: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00004110: 4661 6c73 650a 0a0a 4064 6174 6163 6c61  False...@datacla
+00004120: 7373 0a63 6c61 7373 2050 6172 616d 6574  ss.class Paramet
+00004130: 6572 4261 7365 284a 534f 4e44 6574 6563  erBase(JSONDetec
+00004140: 746f 7229 3a0a 2020 2020 6e61 6d65 3a20  tor):.    name: 
+00004150: 7374 720a 2020 2020 696e 5f74 7970 653a  str.    in_type:
+00004160: 2050 6172 616d 6574 6572 496e 5479 7065   ParameterInType
+00004170: 0a20 2020 2072 6571 7569 7265 643a 2062  .    required: b
+00004180: 6f6f 6c0a 2020 2020 7374 796c 653a 2074  ool.    style: t
+00004190: 7970 696e 672e 4f70 7469 6f6e 616c 5b50  yping.Optional[P
+000041a0: 6172 616d 6574 6572 5374 796c 655d 0a20  arameterStyle]. 
+000041b0: 2020 2065 7870 6c6f 6465 3a20 7479 7069     explode: typi
+000041c0: 6e67 2e4f 7074 696f 6e61 6c5b 626f 6f6c  ng.Optional[bool
+000041d0: 5d0a 2020 2020 616c 6c6f 775f 7265 7365  ].    allow_rese
+000041e0: 7276 6564 3a20 7479 7069 6e67 2e4f 7074  rved: typing.Opt
+000041f0: 696f 6e61 6c5b 626f 6f6c 5d0a 2020 2020  ional[bool].    
+00004200: 7363 6865 6d61 3a20 7479 7069 6e67 2e4f  schema: typing.O
+00004210: 7074 696f 6e61 6c5b 7479 7069 6e67 2e54  ptional[typing.T
+00004220: 7970 655b 5363 6865 6d61 5d5d 0a20 2020  ype[Schema]].   
+00004230: 2063 6f6e 7465 6e74 3a20 7479 7069 6e67   content: typing
+00004240: 2e4f 7074 696f 6e61 6c5b 7479 7069 6e67  .Optional[typing
+00004250: 2e44 6963 745b 7374 722c 2074 7970 696e  .Dict[str, typin
+00004260: 672e 5479 7065 5b53 6368 656d 615d 5d5d  g.Type[Schema]]]
+00004270: 0a0a 2020 2020 5f5f 7374 796c 655f 746f  ..    __style_to
+00004280: 5f69 6e5f 7479 7065 203d 207b 0a20 2020  _in_type = {.   
+00004290: 2020 2020 2050 6172 616d 6574 6572 5374       ParameterSt
+000042a0: 796c 652e 4d41 5452 4958 3a20 7b50 6172  yle.MATRIX: {Par
+000042b0: 616d 6574 6572 496e 5479 7065 2e50 4154  ameterInType.PAT
+000042c0: 487d 2c0a 2020 2020 2020 2020 5061 7261  H},.        Para
+000042d0: 6d65 7465 7253 7479 6c65 2e4c 4142 454c  meterStyle.LABEL
+000042e0: 3a20 7b50 6172 616d 6574 6572 496e 5479  : {ParameterInTy
+000042f0: 7065 2e50 4154 487d 2c0a 2020 2020 2020  pe.PATH},.      
+00004300: 2020 5061 7261 6d65 7465 7253 7479 6c65    ParameterStyle
+00004310: 2e46 4f52 4d3a 207b 5061 7261 6d65 7465  .FORM: {Paramete
+00004320: 7249 6e54 7970 652e 5155 4552 592c 2050  rInType.QUERY, P
+00004330: 6172 616d 6574 6572 496e 5479 7065 2e43  arameterInType.C
+00004340: 4f4f 4b49 457d 2c0a 2020 2020 2020 2020  OOKIE},.        
+00004350: 5061 7261 6d65 7465 7253 7479 6c65 2e53  ParameterStyle.S
+00004360: 494d 504c 453a 207b 5061 7261 6d65 7465  IMPLE: {Paramete
+00004370: 7249 6e54 7970 652e 5041 5448 2c20 5061  rInType.PATH, Pa
+00004380: 7261 6d65 7465 7249 6e54 7970 652e 4845  rameterInType.HE
+00004390: 4144 4552 7d2c 0a20 2020 2020 2020 2050  ADER},.        P
+000043a0: 6172 616d 6574 6572 5374 796c 652e 5350  arameterStyle.SP
+000043b0: 4143 455f 4445 4c49 4d49 5445 443a 207b  ACE_DELIMITED: {
+000043c0: 5061 7261 6d65 7465 7249 6e54 7970 652e  ParameterInType.
+000043d0: 5155 4552 597d 2c0a 2020 2020 2020 2020  QUERY},.        
+000043e0: 5061 7261 6d65 7465 7253 7479 6c65 2e50  ParameterStyle.P
+000043f0: 4950 455f 4445 4c49 4d49 5445 443a 207b  IPE_DELIMITED: {
+00004400: 5061 7261 6d65 7465 7249 6e54 7970 652e  ParameterInType.
+00004410: 5155 4552 597d 2c0a 2020 2020 2020 2020  QUERY},.        
+00004420: 5061 7261 6d65 7465 7253 7479 6c65 2e44  ParameterStyle.D
+00004430: 4545 505f 4f42 4a45 4354 3a20 7b50 6172  EEP_OBJECT: {Par
+00004440: 616d 6574 6572 496e 5479 7065 2e51 5545  ameterInType.QUE
+00004450: 5259 7d2c 0a20 2020 207d 0a20 2020 205f  RY},.    }.    _
+00004460: 5f69 6e5f 7479 7065 5f74 6f5f 6465 6661  _in_type_to_defa
+00004470: 756c 745f 7374 796c 6520 3d20 7b0a 2020  ult_style = {.  
+00004480: 2020 2020 2020 5061 7261 6d65 7465 7249        ParameterI
+00004490: 6e54 7970 652e 5155 4552 593a 2050 6172  nType.QUERY: Par
+000044a0: 616d 6574 6572 5374 796c 652e 464f 524d  ameterStyle.FORM
+000044b0: 2c0a 2020 2020 2020 2020 5061 7261 6d65  ,.        Parame
+000044c0: 7465 7249 6e54 7970 652e 5041 5448 3a20  terInType.PATH: 
+000044d0: 5061 7261 6d65 7465 7253 7479 6c65 2e53  ParameterStyle.S
+000044e0: 494d 504c 452c 0a20 2020 2020 2020 2050  IMPLE,.        P
+000044f0: 6172 616d 6574 6572 496e 5479 7065 2e48  arameterInType.H
+00004500: 4541 4445 523a 2050 6172 616d 6574 6572  EADER: Parameter
+00004510: 5374 796c 652e 5349 4d50 4c45 2c0a 2020  Style.SIMPLE,.  
+00004520: 2020 2020 2020 5061 7261 6d65 7465 7249        ParameterI
+00004530: 6e54 7970 652e 434f 4f4b 4945 3a20 5061  nType.COOKIE: Pa
+00004540: 7261 6d65 7465 7253 7479 6c65 2e46 4f52  rameterStyle.FOR
+00004550: 4d2c 0a20 2020 207d 0a20 2020 205f 5f64  M,.    }.    __d
+00004560: 6973 616c 6c6f 7765 645f 6865 6164 6572  isallowed_header
+00004570: 5f6e 616d 6573 203d 207b 2741 6363 6570  _names = {'Accep
+00004580: 7427 2c20 2743 6f6e 7465 6e74 2d54 7970  t', 'Content-Typ
+00004590: 6527 2c20 2741 7574 686f 7269 7a61 7469  e', 'Authorizati
+000045a0: 6f6e 277d 0a20 2020 205f 6a73 6f6e 5f65  on'}.    _json_e
+000045b0: 6e63 6f64 6572 203d 204a 534f 4e45 6e63  ncoder = JSONEnc
+000045c0: 6f64 6572 2829 0a0a 2020 2020 4063 6c61  oder()..    @cla
+000045d0: 7373 6d65 7468 6f64 0a20 2020 2064 6566  ssmethod.    def
+000045e0: 205f 5f76 6572 6966 795f 7374 796c 655f   __verify_style_
+000045f0: 746f 5f69 6e5f 7479 7065 2863 6c73 2c20  to_in_type(cls, 
+00004600: 7374 796c 653a 2074 7970 696e 672e 4f70  style: typing.Op
+00004610: 7469 6f6e 616c 5b50 6172 616d 6574 6572  tional[Parameter
+00004620: 5374 796c 655d 2c20 696e 5f74 7970 653a  Style], in_type:
+00004630: 2050 6172 616d 6574 6572 496e 5479 7065   ParameterInType
+00004640: 293a 0a20 2020 2020 2020 2069 6620 7374  ):.        if st
+00004650: 796c 6520 6973 204e 6f6e 653a 0a20 2020  yle is None:.   
+00004660: 2020 2020 2020 2020 2072 6574 7572 6e0a           return.
+00004670: 2020 2020 2020 2020 696e 5f74 7970 655f          in_type_
+00004680: 7365 7420 3d20 636c 732e 5f5f 7374 796c  set = cls.__styl
+00004690: 655f 746f 5f69 6e5f 7479 7065 5b73 7479  e_to_in_type[sty
+000046a0: 6c65 5d0a 2020 2020 2020 2020 6966 2069  le].        if i
+000046b0: 6e5f 7479 7065 206e 6f74 2069 6e20 696e  n_type not in in
+000046c0: 5f74 7970 655f 7365 743a 0a20 2020 2020  _type_set:.     
+000046d0: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
+000046e0: 7565 4572 726f 7228 0a20 2020 2020 2020  ueError(.       
+000046f0: 2020 2020 2020 2020 2027 496e 7661 6c69           'Invali
+00004700: 6420 7374 796c 6520 616e 6420 696e 5f74  d style and in_t
+00004710: 7970 6520 636f 6d62 696e 6174 696f 6e2e  ype combination.
+00004720: 2046 6f72 2073 7479 6c65 3d7b 7d20 6f6e   For style={} on
+00004730: 6c79 2069 6e5f 7479 7065 3d7b 7d20 6172  ly in_type={} ar
+00004740: 6520 616c 6c6f 7765 6427 2e66 6f72 6d61  e allowed'.forma
+00004750: 7428 0a20 2020 2020 2020 2020 2020 2020  t(.             
+00004760: 2020 2020 2020 2073 7479 6c65 2c20 696e         style, in
+00004770: 5f74 7970 655f 7365 740a 2020 2020 2020  _type_set.      
+00004780: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
+00004790: 2020 2020 2020 2020 290a 0a20 2020 2064          )..    d
+000047a0: 6566 205f 5f69 6e69 745f 5f28 0a20 2020  ef __init__(.   
+000047b0: 2020 2020 2073 656c 662c 0a20 2020 2020       self,.     
+000047c0: 2020 206e 616d 653a 2073 7472 2c0a 2020     name: str,.  
+000047d0: 2020 2020 2020 696e 5f74 7970 653a 2050        in_type: P
+000047e0: 6172 616d 6574 6572 496e 5479 7065 2c0a  arameterInType,.
+000047f0: 2020 2020 2020 2020 7265 7175 6972 6564          required
+00004800: 3a20 626f 6f6c 203d 2046 616c 7365 2c0a  : bool = False,.
+00004810: 2020 2020 2020 2020 7374 796c 653a 2074          style: t
+00004820: 7970 696e 672e 4f70 7469 6f6e 616c 5b50  yping.Optional[P
+00004830: 6172 616d 6574 6572 5374 796c 655d 203d  arameterStyle] =
+00004840: 204e 6f6e 652c 0a20 2020 2020 2020 2065   None,.        e
+00004850: 7870 6c6f 6465 3a20 626f 6f6c 203d 2046  xplode: bool = F
+00004860: 616c 7365 2c0a 2020 2020 2020 2020 616c  alse,.        al
+00004870: 6c6f 775f 7265 7365 7276 6564 3a20 7479  low_reserved: ty
+00004880: 7069 6e67 2e4f 7074 696f 6e61 6c5b 626f  ping.Optional[bo
+00004890: 6f6c 5d20 3d20 4e6f 6e65 2c0a 2020 2020  ol] = None,.    
+000048a0: 2020 2020 7363 6865 6d61 3a20 7479 7069      schema: typi
+000048b0: 6e67 2e4f 7074 696f 6e61 6c5b 7479 7069  ng.Optional[typi
+000048c0: 6e67 2e54 7970 655b 5363 6865 6d61 5d5d  ng.Type[Schema]]
+000048d0: 203d 204e 6f6e 652c 0a20 2020 2020 2020   = None,.       
+000048e0: 2063 6f6e 7465 6e74 3a20 7479 7069 6e67   content: typing
+000048f0: 2e4f 7074 696f 6e61 6c5b 7479 7069 6e67  .Optional[typing
+00004900: 2e44 6963 745b 7374 722c 2074 7970 696e  .Dict[str, typin
+00004910: 672e 5479 7065 5b53 6368 656d 615d 5d5d  g.Type[Schema]]]
+00004920: 203d 204e 6f6e 650a 2020 2020 293a 0a20   = None.    ):. 
+00004930: 2020 2020 2020 2069 6620 7363 6865 6d61         if schema
+00004940: 2069 7320 4e6f 6e65 2061 6e64 2063 6f6e   is None and con
+00004950: 7465 6e74 2069 7320 4e6f 6e65 3a0a 2020  tent is None:.  
+00004960: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+00004970: 5661 6c75 6545 7272 6f72 2827 5661 6c75  ValueError('Valu
+00004980: 6520 6d69 7373 696e 673b 2050 6173 7320  e missing; Pass 
+00004990: 696e 2065 6974 6865 7220 7363 6865 6d61  in either schema
+000049a0: 206f 7220 636f 6e74 656e 7427 290a 2020   or content').  
+000049b0: 2020 2020 2020 6966 2073 6368 656d 6120        if schema 
+000049c0: 616e 6420 636f 6e74 656e 743a 0a20 2020  and content:.   
+000049d0: 2020 2020 2020 2020 2072 6169 7365 2056           raise V
+000049e0: 616c 7565 4572 726f 7228 2754 6f6f 206d  alueError('Too m
+000049f0: 616e 7920 7661 6c75 6573 2070 726f 7669  any values provi
+00004a00: 6465 642e 2042 6f74 6820 7363 6865 6d61  ded. Both schema
+00004a10: 2061 6e64 2063 6f6e 7465 6e74 2077 6572   and content wer
+00004a20: 6520 7072 6f76 6964 6564 2e20 4f6e 6c79  e provided. Only
+00004a30: 206f 6e65 206d 6179 2062 6520 696e 7075   one may be inpu
+00004a40: 7427 290a 2020 2020 2020 2020 6966 206e  t').        if n
+00004a50: 616d 6520 696e 2073 656c 662e 5f5f 6469  ame in self.__di
+00004a60: 7361 6c6c 6f77 6564 5f68 6561 6465 725f  sallowed_header_
+00004a70: 6e61 6d65 7320 616e 6420 696e 5f74 7970  names and in_typ
+00004a80: 6520 6973 2050 6172 616d 6574 6572 496e  e is ParameterIn
+00004a90: 5479 7065 2e48 4541 4445 523a 0a20 2020  Type.HEADER:.   
+00004aa0: 2020 2020 2020 2020 2072 6169 7365 2056           raise V
+00004ab0: 616c 7565 4572 726f 7228 2749 6e76 616c  alueError('Inval
+00004ac0: 6964 206e 616d 652c 206e 616d 6520 6d61  id name, name ma
+00004ad0: 7920 6e6f 7420 6265 206f 6e65 206f 6620  y not be one of 
+00004ae0: 7b7d 272e 666f 726d 6174 2873 656c 662e  {}'.format(self.
+00004af0: 5f5f 6469 7361 6c6c 6f77 6564 5f68 6561  __disallowed_hea
+00004b00: 6465 725f 6e61 6d65 7329 290a 2020 2020  der_names)).    
+00004b10: 2020 2020 7365 6c66 2e5f 5f76 6572 6966      self.__verif
+00004b20: 795f 7374 796c 655f 746f 5f69 6e5f 7479  y_style_to_in_ty
+00004b30: 7065 2873 7479 6c65 2c20 696e 5f74 7970  pe(style, in_typ
+00004b40: 6529 0a20 2020 2020 2020 2069 6620 636f  e).        if co
+00004b50: 6e74 656e 7420 6973 204e 6f6e 6520 616e  ntent is None an
+00004b60: 6420 7374 796c 6520 6973 204e 6f6e 653a  d style is None:
+00004b70: 0a20 2020 2020 2020 2020 2020 2073 7479  .            sty
+00004b80: 6c65 203d 2073 656c 662e 5f5f 696e 5f74  le = self.__in_t
+00004b90: 7970 655f 746f 5f64 6566 6175 6c74 5f73  ype_to_default_s
+00004ba0: 7479 6c65 5b69 6e5f 7479 7065 5d0a 2020  tyle[in_type].  
+00004bb0: 2020 2020 2020 6966 2063 6f6e 7465 6e74        if content
+00004bc0: 2069 7320 6e6f 7420 4e6f 6e65 2061 6e64   is not None and
+00004bd0: 2069 6e5f 7479 7065 2069 6e20 7365 6c66   in_type in self
+00004be0: 2e5f 5f69 6e5f 7479 7065 5f74 6f5f 6465  .__in_type_to_de
+00004bf0: 6661 756c 745f 7374 796c 6520 616e 6420  fault_style and 
+00004c00: 6c65 6e28 636f 6e74 656e 7429 2021 3d20  len(content) != 
+00004c10: 313a 0a20 2020 2020 2020 2020 2020 2072  1:.            r
+00004c20: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
+00004c30: 2749 6e76 616c 6964 2063 6f6e 7465 6e74  'Invalid content
+00004c40: 206c 656e 6774 682c 2063 6f6e 7465 6e74   length, content
+00004c50: 206c 656e 6774 6820 6d75 7374 2065 7175   length must equ
+00004c60: 616c 2031 2729 0a20 2020 2020 2020 2073  al 1').        s
+00004c70: 656c 662e 696e 5f74 7970 6520 3d20 696e  elf.in_type = in
+00004c80: 5f74 7970 650a 2020 2020 2020 2020 7365  _type.        se
+00004c90: 6c66 2e6e 616d 6520 3d20 6e61 6d65 0a20  lf.name = name. 
+00004ca0: 2020 2020 2020 2073 656c 662e 7265 7175         self.requ
+00004cb0: 6972 6564 203d 2072 6571 7569 7265 640a  ired = required.
+00004cc0: 2020 2020 2020 2020 7365 6c66 2e73 7479          self.sty
+00004cd0: 6c65 203d 2073 7479 6c65 0a20 2020 2020  le = style.     
+00004ce0: 2020 2073 656c 662e 6578 706c 6f64 6520     self.explode 
+00004cf0: 3d20 6578 706c 6f64 650a 2020 2020 2020  = explode.      
+00004d00: 2020 7365 6c66 2e61 6c6c 6f77 5f72 6573    self.allow_res
+00004d10: 6572 7665 6420 3d20 616c 6c6f 775f 7265  erved = allow_re
+00004d20: 7365 7276 6564 0a20 2020 2020 2020 2073  served.        s
+00004d30: 656c 662e 7363 6865 6d61 203d 2073 6368  elf.schema = sch
+00004d40: 656d 610a 2020 2020 2020 2020 7365 6c66  ema.        self
+00004d50: 2e63 6f6e 7465 6e74 203d 2063 6f6e 7465  .content = conte
+00004d60: 6e74 0a0a 2020 2020 6465 6620 5f73 6572  nt..    def _ser
+00004d70: 6961 6c69 7a65 5f6a 736f 6e28 0a20 2020  ialize_json(.   
+00004d80: 2020 2020 2073 656c 662c 0a20 2020 2020       self,.     
+00004d90: 2020 2069 6e5f 6461 7461 3a20 7479 7069     in_data: typi
+00004da0: 6e67 2e55 6e69 6f6e 5b4e 6f6e 652c 2069  ng.Union[None, i
+00004db0: 6e74 2c20 666c 6f61 742c 2073 7472 2c20  nt, float, str, 
+00004dc0: 626f 6f6c 2c20 6469 6374 2c20 6c69 7374  bool, dict, list
+00004dd0: 5d2c 0a20 2020 2020 2020 2065 6c69 6d69  ],.        elimi
+00004de0: 6e61 7465 5f77 6869 7465 7370 6163 653a  nate_whitespace:
+00004df0: 2062 6f6f 6c20 3d20 4661 6c73 650a 2020   bool = False.  
+00004e00: 2020 2920 2d3e 2073 7472 3a0a 2020 2020    ) -> str:.    
+00004e10: 2020 2020 6966 2065 6c69 6d69 6e61 7465      if eliminate
+00004e20: 5f77 6869 7465 7370 6163 653a 0a20 2020  _whitespace:.   
+00004e30: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00004e40: 6a73 6f6e 2e64 756d 7073 2869 6e5f 6461  json.dumps(in_da
+00004e50: 7461 2c20 7365 7061 7261 746f 7273 3d73  ta, separators=s
+00004e60: 656c 662e 5f6a 736f 6e5f 656e 636f 6465  elf._json_encode
+00004e70: 722e 636f 6d70 6163 745f 7365 7061 7261  r.compact_separa
+00004e80: 746f 7273 290a 2020 2020 2020 2020 7265  tors).        re
+00004e90: 7475 726e 206a 736f 6e2e 6475 6d70 7328  turn json.dumps(
+00004ea0: 696e 5f64 6174 6129 0a0a 0a63 6c61 7373  in_data)...class
+00004eb0: 2050 6174 6850 6172 616d 6574 6572 2850   PathParameter(P
+00004ec0: 6172 616d 6574 6572 4261 7365 2c20 5374  arameterBase, St
+00004ed0: 796c 6553 696d 706c 6553 6572 6961 6c69  yleSimpleSeriali
+00004ee0: 7a65 7229 3a0a 0a20 2020 2064 6566 205f  zer):..    def _
+00004ef0: 5f69 6e69 745f 5f28 0a20 2020 2020 2020  _init__(.       
+00004f00: 2073 656c 662c 0a20 2020 2020 2020 206e   self,.        n
+00004f10: 616d 653a 2073 7472 2c0a 2020 2020 2020  ame: str,.      
+00004f20: 2020 7265 7175 6972 6564 3a20 626f 6f6c    required: bool
+00004f30: 203d 2046 616c 7365 2c0a 2020 2020 2020   = False,.      
+00004f40: 2020 7374 796c 653a 2074 7970 696e 672e    style: typing.
+00004f50: 4f70 7469 6f6e 616c 5b50 6172 616d 6574  Optional[Paramet
+00004f60: 6572 5374 796c 655d 203d 204e 6f6e 652c  erStyle] = None,
+00004f70: 0a20 2020 2020 2020 2065 7870 6c6f 6465  .        explode
+00004f80: 3a20 626f 6f6c 203d 2046 616c 7365 2c0a  : bool = False,.
+00004f90: 2020 2020 2020 2020 616c 6c6f 775f 7265          allow_re
+00004fa0: 7365 7276 6564 3a20 7479 7069 6e67 2e4f  served: typing.O
+00004fb0: 7074 696f 6e61 6c5b 626f 6f6c 5d20 3d20  ptional[bool] = 
+00004fc0: 4e6f 6e65 2c0a 2020 2020 2020 2020 7363  None,.        sc
+00004fd0: 6865 6d61 3a20 7479 7069 6e67 2e4f 7074  hema: typing.Opt
+00004fe0: 696f 6e61 6c5b 7479 7069 6e67 2e54 7970  ional[typing.Typ
+00004ff0: 655b 5363 6865 6d61 5d5d 203d 204e 6f6e  e[Schema]] = Non
+00005000: 652c 0a20 2020 2020 2020 2063 6f6e 7465  e,.        conte
+00005010: 6e74 3a20 7479 7069 6e67 2e4f 7074 696f  nt: typing.Optio
+00005020: 6e61 6c5b 7479 7069 6e67 2e44 6963 745b  nal[typing.Dict[
+00005030: 7374 722c 2074 7970 696e 672e 5479 7065  str, typing.Type
+00005040: 5b53 6368 656d 615d 5d5d 203d 204e 6f6e  [Schema]]] = Non
+00005050: 650a 2020 2020 293a 0a20 2020 2020 2020  e.    ):.       
+00005060: 2073 7570 6572 2829 2e5f 5f69 6e69 745f   super().__init_
+00005070: 5f28 0a20 2020 2020 2020 2020 2020 206e  _(.            n
+00005080: 616d 652c 0a20 2020 2020 2020 2020 2020  ame,.           
+00005090: 2069 6e5f 7479 7065 3d50 6172 616d 6574   in_type=Paramet
+000050a0: 6572 496e 5479 7065 2e50 4154 482c 0a20  erInType.PATH,. 
+000050b0: 2020 2020 2020 2020 2020 2072 6571 7569             requi
+000050c0: 7265 643d 7265 7175 6972 6564 2c0a 2020  red=required,.  
+000050d0: 2020 2020 2020 2020 2020 7374 796c 653d            style=
+000050e0: 7374 796c 652c 0a20 2020 2020 2020 2020  style,.         
+000050f0: 2020 2065 7870 6c6f 6465 3d65 7870 6c6f     explode=explo
+00005100: 6465 2c0a 2020 2020 2020 2020 2020 2020  de,.            
+00005110: 616c 6c6f 775f 7265 7365 7276 6564 3d61  allow_reserved=a
+00005120: 6c6c 6f77 5f72 6573 6572 7665 642c 0a20  llow_reserved,. 
+00005130: 2020 2020 2020 2020 2020 2073 6368 656d             schem
+00005140: 613d 7363 6865 6d61 2c0a 2020 2020 2020  a=schema,.      
+00005150: 2020 2020 2020 636f 6e74 656e 743d 636f        content=co
+00005160: 6e74 656e 740a 2020 2020 2020 2020 290a  ntent.        ).
+00005170: 0a20 2020 2064 6566 205f 5f73 6572 6961  .    def __seria
+00005180: 6c69 7a65 5f6c 6162 656c 280a 2020 2020  lize_label(.    
+00005190: 2020 2020 7365 6c66 2c0a 2020 2020 2020      self,.      
+000051a0: 2020 696e 5f64 6174 613a 2074 7970 696e    in_data: typin
+000051b0: 672e 556e 696f 6e5b 4e6f 6e65 2c20 696e  g.Union[None, in
+000051c0: 742c 2066 6c6f 6174 2c20 7374 722c 2062  t, float, str, b
+000051d0: 6f6f 6c2c 2064 6963 742c 206c 6973 745d  ool, dict, list]
+000051e0: 0a20 2020 2029 202d 3e20 7479 7069 6e67  .    ) -> typing
+000051f0: 2e44 6963 745b 7374 722c 2073 7472 5d3a  .Dict[str, str]:
+00005200: 0a20 2020 2020 2020 2070 7265 6669 785f  .        prefix_
+00005210: 7365 7061 7261 746f 725f 6974 6572 6174  separator_iterat
+00005220: 6f72 203d 2050 7265 6669 7853 6570 6172  or = PrefixSepar
+00005230: 6174 6f72 4974 6572 6174 6f72 2827 2e27  atorIterator('.'
+00005240: 2c20 272e 2729 0a20 2020 2020 2020 2076  , '.').        v
+00005250: 616c 7565 203d 2073 656c 662e 5f72 6566  alue = self._ref
+00005260: 3635 3730 5f65 7870 616e 7369 6f6e 280a  6570_expansion(.
+00005270: 2020 2020 2020 2020 2020 2020 7661 7269              vari
+00005280: 6162 6c65 5f6e 616d 653d 7365 6c66 2e6e  able_name=self.n
+00005290: 616d 652c 0a20 2020 2020 2020 2020 2020  ame,.           
+000052a0: 2069 6e5f 6461 7461 3d69 6e5f 6461 7461   in_data=in_data
+000052b0: 2c0a 2020 2020 2020 2020 2020 2020 6578  ,.            ex
+000052c0: 706c 6f64 653d 7365 6c66 2e65 7870 6c6f  plode=self.explo
+000052d0: 6465 2c0a 2020 2020 2020 2020 2020 2020  de,.            
+000052e0: 7065 7263 656e 745f 656e 636f 6465 3d54  percent_encode=T
+000052f0: 7275 652c 0a20 2020 2020 2020 2020 2020  rue,.           
+00005300: 2070 7265 6669 785f 7365 7061 7261 746f   prefix_separato
+00005310: 725f 6974 6572 6174 6f72 3d70 7265 6669  r_iterator=prefi
+00005320: 785f 7365 7061 7261 746f 725f 6974 6572  x_separator_iter
+00005330: 6174 6f72 0a20 2020 2020 2020 2029 0a20  ator.        ). 
+00005340: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
+00005350: 6c66 2e5f 746f 5f64 6963 7428 7365 6c66  lf._to_dict(self
+00005360: 2e6e 616d 652c 2076 616c 7565 290a 0a20  .name, value).. 
+00005370: 2020 2064 6566 205f 5f73 6572 6961 6c69     def __seriali
+00005380: 7a65 5f6d 6174 7269 7828 0a20 2020 2020  ze_matrix(.     
+00005390: 2020 2073 656c 662c 0a20 2020 2020 2020     self,.       
+000053a0: 2069 6e5f 6461 7461 3a20 7479 7069 6e67   in_data: typing
+000053b0: 2e55 6e69 6f6e 5b4e 6f6e 652c 2069 6e74  .Union[None, int
+000053c0: 2c20 666c 6f61 742c 2073 7472 2c20 626f  , float, str, bo
+000053d0: 6f6c 2c20 6469 6374 2c20 6c69 7374 5d0a  ol, dict, list].
+000053e0: 2020 2020 2920 2d3e 2074 7970 696e 672e      ) -> typing.
+000053f0: 4469 6374 5b73 7472 2c20 7374 725d 3a0a  Dict[str, str]:.
+00005400: 2020 2020 2020 2020 7072 6566 6978 5f73          prefix_s
+00005410: 6570 6172 6174 6f72 5f69 7465 7261 746f  eparator_iterato
+00005420: 7220 3d20 5072 6566 6978 5365 7061 7261  r = PrefixSepara
+00005430: 746f 7249 7465 7261 746f 7228 273b 272c  torIterator(';',
+00005440: 2027 3b27 290a 2020 2020 2020 2020 7661   ';').        va
+00005450: 6c75 6520 3d20 7365 6c66 2e5f 7265 6636  lue = self._ref6
+00005460: 3537 305f 6578 7061 6e73 696f 6e28 0a20  570_expansion(. 
+00005470: 2020 2020 2020 2020 2020 2076 6172 6961             varia
+00005480: 626c 655f 6e61 6d65 3d73 656c 662e 6e61  ble_name=self.na
+00005490: 6d65 2c0a 2020 2020 2020 2020 2020 2020  me,.            
+000054a0: 696e 5f64 6174 613d 696e 5f64 6174 612c  in_data=in_data,
+000054b0: 0a20 2020 2020 2020 2020 2020 2065 7870  .            exp
+000054c0: 6c6f 6465 3d73 656c 662e 6578 706c 6f64  lode=self.explod
+000054d0: 652c 0a20 2020 2020 2020 2020 2020 2070  e,.            p
+000054e0: 6572 6365 6e74 5f65 6e63 6f64 653d 5472  ercent_encode=Tr
+000054f0: 7565 2c0a 2020 2020 2020 2020 2020 2020  ue,.            
+00005500: 7072 6566 6978 5f73 6570 6172 6174 6f72  prefix_separator
+00005510: 5f69 7465 7261 746f 723d 7072 6566 6978  _iterator=prefix
+00005520: 5f73 6570 6172 6174 6f72 5f69 7465 7261  _separator_itera
+00005530: 746f 720a 2020 2020 2020 2020 290a 2020  tor.        ).  
+00005540: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
+00005550: 662e 5f74 6f5f 6469 6374 2873 656c 662e  f._to_dict(self.
+00005560: 6e61 6d65 2c20 7661 6c75 6529 0a0a 2020  name, value)..  
+00005570: 2020 6465 6620 5f5f 7365 7269 616c 697a    def __serializ
+00005580: 655f 7369 6d70 6c65 280a 2020 2020 2020  e_simple(.      
+00005590: 2020 7365 6c66 2c0a 2020 2020 2020 2020    self,.        
+000055a0: 696e 5f64 6174 613a 2074 7970 696e 672e  in_data: typing.
+000055b0: 556e 696f 6e5b 4e6f 6e65 2c20 696e 742c  Union[None, int,
+000055c0: 2066 6c6f 6174 2c20 7374 722c 2062 6f6f   float, str, boo
+000055d0: 6c2c 2064 6963 742c 206c 6973 745d 2c0a  l, dict, list],.
+000055e0: 2020 2020 2920 2d3e 2074 7970 696e 672e      ) -> typing.
+000055f0: 4469 6374 5b73 7472 2c20 7374 725d 3a0a  Dict[str, str]:.
+00005600: 2020 2020 2020 2020 7661 6c75 6520 3d20          value = 
+00005610: 7365 6c66 2e5f 7365 7269 616c 697a 655f  self._serialize_
+00005620: 7369 6d70 6c65 280a 2020 2020 2020 2020  simple(.        
+00005630: 2020 2020 696e 5f64 6174 613d 696e 5f64      in_data=in_d
+00005640: 6174 612c 0a20 2020 2020 2020 2020 2020  ata,.           
+00005650: 206e 616d 653d 7365 6c66 2e6e 616d 652c   name=self.name,
+00005660: 0a20 2020 2020 2020 2020 2020 2065 7870  .            exp
+00005670: 6c6f 6465 3d73 656c 662e 6578 706c 6f64  lode=self.explod
+00005680: 652c 0a20 2020 2020 2020 2020 2020 2070  e,.            p
+00005690: 6572 6365 6e74 5f65 6e63 6f64 653d 5472  ercent_encode=Tr
+000056a0: 7565 0a20 2020 2020 2020 2029 0a20 2020  ue.        ).   
+000056b0: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
+000056c0: 2e5f 746f 5f64 6963 7428 7365 6c66 2e6e  ._to_dict(self.n
+000056d0: 616d 652c 2076 616c 7565 290a 0a20 2020  ame, value)..   
+000056e0: 2064 6566 2073 6572 6961 6c69 7a65 280a   def serialize(.
+000056f0: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
+00005700: 2020 2020 2020 696e 5f64 6174 613a 2074        in_data: t
+00005710: 7970 696e 672e 556e 696f 6e5b 0a20 2020  yping.Union[.   
+00005720: 2020 2020 2020 2020 2053 6368 656d 612c           Schema,
+00005730: 2044 6563 696d 616c 2c20 696e 742c 2066   Decimal, int, f
+00005740: 6c6f 6174 2c20 7374 722c 2064 6174 652c  loat, str, date,
+00005750: 2064 6174 6574 696d 652c 204e 6f6e 652c   datetime, None,
+00005760: 2062 6f6f 6c2c 206c 6973 742c 2074 7570   bool, list, tup
+00005770: 6c65 2c20 6469 6374 2c20 6672 6f7a 656e  le, dict, frozen
+00005780: 6469 6374 2e66 726f 7a65 6e64 6963 745d  dict.frozendict]
+00005790: 0a20 2020 2029 202d 3e20 7479 7069 6e67  .    ) -> typing
+000057a0: 2e44 6963 745b 7374 722c 2073 7472 5d3a  .Dict[str, str]:
+000057b0: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+000057c0: 2e73 6368 656d 613a 0a20 2020 2020 2020  .schema:.       
+000057d0: 2020 2020 2063 6173 745f 696e 5f64 6174       cast_in_dat
+000057e0: 6120 3d20 7365 6c66 2e73 6368 656d 6128  a = self.schema(
+000057f0: 696e 5f64 6174 6129 0a20 2020 2020 2020  in_data).       
+00005800: 2020 2020 2063 6173 745f 696e 5f64 6174       cast_in_dat
+00005810: 6120 3d20 7365 6c66 2e5f 6a73 6f6e 5f65  a = self._json_e
+00005820: 6e63 6f64 6572 2e64 6566 6175 6c74 2863  ncoder.default(c
+00005830: 6173 745f 696e 5f64 6174 6129 0a20 2020  ast_in_data).   
+00005840: 2020 2020 2020 2020 2022 2222 0a20 2020           """.   
+00005850: 2020 2020 2020 2020 2073 696d 706c 6520           simple 
+00005860: 2d3e 2070 6174 680a 2020 2020 2020 2020  -> path.        
+00005870: 2020 2020 2020 2020 7061 7468 3a0a 2020          path:.  
+00005880: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005890: 2020 7265 7475 726e 7320 7061 7468 5f70    returns path_p
+000058a0: 6172 616d 733a 2064 6963 740a 2020 2020  arams: dict.    
+000058b0: 2020 2020 2020 2020 6c61 6265 6c20 2d3e          label ->
+000058c0: 2070 6174 680a 2020 2020 2020 2020 2020   path.          
+000058d0: 2020 2020 2020 7265 7475 726e 7320 7061        returns pa
+000058e0: 7468 5f70 6172 616d 730a 2020 2020 2020  th_params.      
+000058f0: 2020 2020 2020 6d61 7472 6978 202d 3e20        matrix -> 
+00005900: 7061 7468 0a20 2020 2020 2020 2020 2020  path.           
+00005910: 2020 2020 2072 6574 7572 6e73 2070 6174       returns pat
+00005920: 685f 7061 7261 6d73 0a20 2020 2020 2020  h_params.       
+00005930: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
+00005940: 2020 2020 2069 6620 7365 6c66 2e73 7479       if self.sty
+00005950: 6c65 3a0a 2020 2020 2020 2020 2020 2020  le:.            
+00005960: 2020 2020 6966 2073 656c 662e 7374 796c      if self.styl
+00005970: 6520 6973 2050 6172 616d 6574 6572 5374  e is ParameterSt
+00005980: 796c 652e 5349 4d50 4c45 3a0a 2020 2020  yle.SIMPLE:.    
+00005990: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000059a0: 7265 7475 726e 2073 656c 662e 5f5f 7365  return self.__se
+000059b0: 7269 616c 697a 655f 7369 6d70 6c65 2863  rialize_simple(c
+000059c0: 6173 745f 696e 5f64 6174 6129 0a20 2020  ast_in_data).   
+000059d0: 2020 2020 2020 2020 2020 2020 2065 6c69               eli
+000059e0: 6620 7365 6c66 2e73 7479 6c65 2069 7320  f self.style is 
+000059f0: 5061 7261 6d65 7465 7253 7479 6c65 2e4c  ParameterStyle.L
+00005a00: 4142 454c 3a0a 2020 2020 2020 2020 2020  ABEL:.          
+00005a10: 2020 2020 2020 2020 2020 7265 7475 726e            return
+00005a20: 2073 656c 662e 5f5f 7365 7269 616c 697a   self.__serializ
+00005a30: 655f 6c61 6265 6c28 6361 7374 5f69 6e5f  e_label(cast_in_
+00005a40: 6461 7461 290a 2020 2020 2020 2020 2020  data).          
+00005a50: 2020 2020 2020 656c 6966 2073 656c 662e        elif self.
+00005a60: 7374 796c 6520 6973 2050 6172 616d 6574  style is Paramet
+00005a70: 6572 5374 796c 652e 4d41 5452 4958 3a0a  erStyle.MATRIX:.
+00005a80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005a90: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
+00005aa0: 5f5f 7365 7269 616c 697a 655f 6d61 7472  __serialize_matr
+00005ab0: 6978 2863 6173 745f 696e 5f64 6174 6129  ix(cast_in_data)
+00005ac0: 0a20 2020 2020 2020 2023 2073 656c 662e  .        # self.
+00005ad0: 636f 6e74 656e 7420 7769 6c6c 2062 6520  content will be 
+00005ae0: 6c65 6e67 7468 206f 6e65 0a20 2020 2020  length one.     
+00005af0: 2020 2066 6f72 2063 6f6e 7465 6e74 5f74     for content_t
+00005b00: 7970 652c 2073 6368 656d 6120 696e 2073  ype, schema in s
+00005b10: 656c 662e 636f 6e74 656e 742e 6974 656d  elf.content.item
+00005b20: 7328 293a 0a20 2020 2020 2020 2020 2020  s():.           
+00005b30: 2063 6173 745f 696e 5f64 6174 6120 3d20   cast_in_data = 
+00005b40: 7363 6865 6d61 2869 6e5f 6461 7461 290a  schema(in_data).
+00005b50: 2020 2020 2020 2020 2020 2020 6361 7374              cast
+00005b60: 5f69 6e5f 6461 7461 203d 2073 656c 662e  _in_data = self.
+00005b70: 5f6a 736f 6e5f 656e 636f 6465 722e 6465  _json_encoder.de
+00005b80: 6661 756c 7428 6361 7374 5f69 6e5f 6461  fault(cast_in_da
+00005b90: 7461 290a 2020 2020 2020 2020 2020 2020  ta).            
+00005ba0: 6966 2073 656c 662e 5f63 6f6e 7465 6e74  if self._content
+00005bb0: 5f74 7970 655f 6973 5f6a 736f 6e28 636f  _type_is_json(co
+00005bc0: 6e74 656e 745f 7479 7065 293a 0a20 2020  ntent_type):.   
+00005bd0: 2020 2020 2020 2020 2020 2020 2076 616c               val
+00005be0: 7565 203d 2073 656c 662e 5f73 6572 6961  ue = self._seria
+00005bf0: 6c69 7a65 5f6a 736f 6e28 6361 7374 5f69  lize_json(cast_i
+00005c00: 6e5f 6461 7461 290a 2020 2020 2020 2020  n_data).        
+00005c10: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+00005c20: 656c 662e 5f74 6f5f 6469 6374 2873 656c  elf._to_dict(sel
+00005c30: 662e 6e61 6d65 2c20 7661 6c75 6529 0a20  f.name, value). 
+00005c40: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00005c50: 204e 6f74 496d 706c 656d 656e 7465 6445   NotImplementedE
+00005c60: 7272 6f72 2827 5365 7269 616c 697a 6174  rror('Serializat
+00005c70: 696f 6e20 6f66 207b 7d20 6861 7320 6e6f  ion of {} has no
+00005c80: 7420 7965 7420 6265 656e 2069 6d70 6c65  t yet been imple
+00005c90: 6d65 6e74 6564 272e 666f 726d 6174 2863  mented'.format(c
+00005ca0: 6f6e 7465 6e74 5f74 7970 6529 290a 0a0a  ontent_type))...
+00005cb0: 636c 6173 7320 5175 6572 7950 6172 616d  class QueryParam
+00005cc0: 6574 6572 2850 6172 616d 6574 6572 4261  eter(ParameterBa
+00005cd0: 7365 2c20 5374 796c 6546 6f72 6d53 6572  se, StyleFormSer
+00005ce0: 6961 6c69 7a65 7229 3a0a 0a20 2020 2064  ializer):..    d
+00005cf0: 6566 205f 5f69 6e69 745f 5f28 0a20 2020  ef __init__(.   
+00005d00: 2020 2020 2073 656c 662c 0a20 2020 2020       self,.     
+00005d10: 2020 206e 616d 653a 2073 7472 2c0a 2020     name: str,.  
+00005d20: 2020 2020 2020 7265 7175 6972 6564 3a20        required: 
+00005d30: 626f 6f6c 203d 2046 616c 7365 2c0a 2020  bool = False,.  
+00005d40: 2020 2020 2020 7374 796c 653a 2074 7970        style: typ
+00005d50: 696e 672e 4f70 7469 6f6e 616c 5b50 6172  ing.Optional[Par
+00005d60: 616d 6574 6572 5374 796c 655d 203d 204e  ameterStyle] = N
+00005d70: 6f6e 652c 0a20 2020 2020 2020 2065 7870  one,.        exp
+00005d80: 6c6f 6465 3a20 7479 7069 6e67 2e4f 7074  lode: typing.Opt
+00005d90: 696f 6e61 6c5b 626f 6f6c 5d20 3d20 4e6f  ional[bool] = No
+00005da0: 6e65 2c0a 2020 2020 2020 2020 616c 6c6f  ne,.        allo
+00005db0: 775f 7265 7365 7276 6564 3a20 7479 7069  w_reserved: typi
+00005dc0: 6e67 2e4f 7074 696f 6e61 6c5b 626f 6f6c  ng.Optional[bool
+00005dd0: 5d20 3d20 4e6f 6e65 2c0a 2020 2020 2020  ] = None,.      
+00005de0: 2020 7363 6865 6d61 3a20 7479 7069 6e67    schema: typing
+00005df0: 2e4f 7074 696f 6e61 6c5b 7479 7069 6e67  .Optional[typing
+00005e00: 2e54 7970 655b 5363 6865 6d61 5d5d 203d  .Type[Schema]] =
+00005e10: 204e 6f6e 652c 0a20 2020 2020 2020 2063   None,.        c
+00005e20: 6f6e 7465 6e74 3a20 7479 7069 6e67 2e4f  ontent: typing.O
+00005e30: 7074 696f 6e61 6c5b 7479 7069 6e67 2e44  ptional[typing.D
+00005e40: 6963 745b 7374 722c 2074 7970 696e 672e  ict[str, typing.
+00005e50: 5479 7065 5b53 6368 656d 615d 5d5d 203d  Type[Schema]]] =
+00005e60: 204e 6f6e 650a 2020 2020 293a 0a20 2020   None.    ):.   
+00005e70: 2020 2020 2075 7365 645f 7374 796c 6520       used_style 
+00005e80: 3d20 5061 7261 6d65 7465 7253 7479 6c65  = ParameterStyle
+00005e90: 2e46 4f52 4d20 6966 2073 7479 6c65 2069  .FORM if style i
+00005ea0: 7320 4e6f 6e65 2065 6c73 6520 7374 796c  s None else styl
+00005eb0: 650a 2020 2020 2020 2020 7573 6564 5f65  e.        used_e
+00005ec0: 7870 6c6f 6465 203d 2073 656c 662e 5f67  xplode = self._g
+00005ed0: 6574 5f64 6566 6175 6c74 5f65 7870 6c6f  et_default_explo
+00005ee0: 6465 2875 7365 645f 7374 796c 6529 2069  de(used_style) i
+00005ef0: 6620 6578 706c 6f64 6520 6973 204e 6f6e  f explode is Non
+00005f00: 6520 656c 7365 2065 7870 6c6f 6465 0a0a  e else explode..
+00005f10: 2020 2020 2020 2020 7375 7065 7228 292e          super().
+00005f20: 5f5f 696e 6974 5f5f 280a 2020 2020 2020  __init__(.      
+00005f30: 2020 2020 2020 6e61 6d65 2c0a 2020 2020        name,.    
+00005f40: 2020 2020 2020 2020 696e 5f74 7970 653d          in_type=
+00005f50: 5061 7261 6d65 7465 7249 6e54 7970 652e  ParameterInType.
+00005f60: 5155 4552 592c 0a20 2020 2020 2020 2020  QUERY,.         
+00005f70: 2020 2072 6571 7569 7265 643d 7265 7175     required=requ
+00005f80: 6972 6564 2c0a 2020 2020 2020 2020 2020  ired,.          
+00005f90: 2020 7374 796c 653d 7573 6564 5f73 7479    style=used_sty
+00005fa0: 6c65 2c0a 2020 2020 2020 2020 2020 2020  le,.            
+00005fb0: 6578 706c 6f64 653d 7573 6564 5f65 7870  explode=used_exp
+00005fc0: 6c6f 6465 2c0a 2020 2020 2020 2020 2020  lode,.          
+00005fd0: 2020 616c 6c6f 775f 7265 7365 7276 6564    allow_reserved
+00005fe0: 3d61 6c6c 6f77 5f72 6573 6572 7665 642c  =allow_reserved,
+00005ff0: 0a20 2020 2020 2020 2020 2020 2073 6368  .            sch
+00006000: 656d 613d 7363 6865 6d61 2c0a 2020 2020  ema=schema,.    
+00006010: 2020 2020 2020 2020 636f 6e74 656e 743d          content=
+00006020: 636f 6e74 656e 740a 2020 2020 2020 2020  content.        
+00006030: 290a 0a20 2020 2064 6566 205f 5f73 6572  )..    def __ser
+00006040: 6961 6c69 7a65 5f73 7061 6365 5f64 656c  ialize_space_del
+00006050: 696d 6974 6564 280a 2020 2020 2020 2020  imited(.        
+00006060: 7365 6c66 2c0a 2020 2020 2020 2020 696e  self,.        in
+00006070: 5f64 6174 613a 2074 7970 696e 672e 556e  _data: typing.Un
+00006080: 696f 6e5b 4e6f 6e65 2c20 696e 742c 2066  ion[None, int, f
+00006090: 6c6f 6174 2c20 7374 722c 2062 6f6f 6c2c  loat, str, bool,
+000060a0: 2064 6963 742c 206c 6973 745d 2c0a 2020   dict, list],.  
+000060b0: 2020 2020 2020 7072 6566 6978 5f73 6570        prefix_sep
+000060c0: 6172 6174 6f72 5f69 7465 7261 746f 723a  arator_iterator:
+000060d0: 2074 7970 696e 672e 4f70 7469 6f6e 616c   typing.Optional
+000060e0: 5b50 7265 6669 7853 6570 6172 6174 6f72  [PrefixSeparator
+000060f0: 4974 6572 6174 6f72 5d0a 2020 2020 2920  Iterator].    ) 
+00006100: 2d3e 2074 7970 696e 672e 4469 6374 5b73  -> typing.Dict[s
+00006110: 7472 2c20 7374 725d 3a0a 2020 2020 2020  tr, str]:.      
+00006120: 2020 6966 2070 7265 6669 785f 7365 7061    if prefix_sepa
+00006130: 7261 746f 725f 6974 6572 6174 6f72 2069  rator_iterator i
+00006140: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
+00006150: 2020 2020 7072 6566 6978 5f73 6570 6172      prefix_separ
+00006160: 6174 6f72 5f69 7465 7261 746f 7220 3d20  ator_iterator = 
+00006170: 7365 6c66 2e67 6574 5f70 7265 6669 785f  self.get_prefix_
+00006180: 7365 7061 7261 746f 725f 6974 6572 6174  separator_iterat
+00006190: 6f72 2829 0a20 2020 2020 2020 2076 616c  or().        val
+000061a0: 7565 203d 2073 656c 662e 5f72 6566 3635  ue = self._ref65
+000061b0: 3730 5f65 7870 616e 7369 6f6e 280a 2020  70_expansion(.  
+000061c0: 2020 2020 2020 2020 2020 7661 7269 6162            variab
+000061d0: 6c65 5f6e 616d 653d 7365 6c66 2e6e 616d  le_name=self.nam
+000061e0: 652c 0a20 2020 2020 2020 2020 2020 2069  e,.            i
+000061f0: 6e5f 6461 7461 3d69 6e5f 6461 7461 2c0a  n_data=in_data,.
+00006200: 2020 2020 2020 2020 2020 2020 6578 706c              expl
+00006210: 6f64 653d 7365 6c66 2e65 7870 6c6f 6465  ode=self.explode
+00006220: 2c0a 2020 2020 2020 2020 2020 2020 7065  ,.            pe
+00006230: 7263 656e 745f 656e 636f 6465 3d54 7275  rcent_encode=Tru
+00006240: 652c 0a20 2020 2020 2020 2020 2020 2070  e,.            p
+00006250: 7265 6669 785f 7365 7061 7261 746f 725f  refix_separator_
+00006260: 6974 6572 6174 6f72 3d70 7265 6669 785f  iterator=prefix_
+00006270: 7365 7061 7261 746f 725f 6974 6572 6174  separator_iterat
+00006280: 6f72 0a20 2020 2020 2020 2029 0a20 2020  or.        ).   
+00006290: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
+000062a0: 2e5f 746f 5f64 6963 7428 7365 6c66 2e6e  ._to_dict(self.n
+000062b0: 616d 652c 2076 616c 7565 290a 0a20 2020  ame, value)..   
+000062c0: 2064 6566 205f 5f73 6572 6961 6c69 7a65   def __serialize
+000062d0: 5f70 6970 655f 6465 6c69 6d69 7465 6428  _pipe_delimited(
+000062e0: 0a20 2020 2020 2020 2073 656c 662c 0a20  .        self,. 
+000062f0: 2020 2020 2020 2069 6e5f 6461 7461 3a20         in_data: 
+00006300: 7479 7069 6e67 2e55 6e69 6f6e 5b4e 6f6e  typing.Union[Non
+00006310: 652c 2069 6e74 2c20 666c 6f61 742c 2073  e, int, float, s
+00006320: 7472 2c20 626f 6f6c 2c20 6469 6374 2c20  tr, bool, dict, 
+00006330: 6c69 7374 5d2c 0a20 2020 2020 2020 2070  list],.        p
+00006340: 7265 6669 785f 7365 7061 7261 746f 725f  refix_separator_
+00006350: 6974 6572 6174 6f72 3a20 7479 7069 6e67  iterator: typing
+00006360: 2e4f 7074 696f 6e61 6c5b 5072 6566 6978  .Optional[Prefix
+00006370: 5365 7061 7261 746f 7249 7465 7261 746f  SeparatorIterato
+00006380: 725d 0a20 2020 2029 202d 3e20 7479 7069  r].    ) -> typi
+00006390: 6e67 2e44 6963 745b 7374 722c 2073 7472  ng.Dict[str, str
+000063a0: 5d3a 0a20 2020 2020 2020 2069 6620 7072  ]:.        if pr
+000063b0: 6566 6978 5f73 6570 6172 6174 6f72 5f69  efix_separator_i
+000063c0: 7465 7261 746f 7220 6973 204e 6f6e 653a  terator is None:
+000063d0: 0a20 2020 2020 2020 2020 2020 2070 7265  .            pre
+000063e0: 6669 785f 7365 7061 7261 746f 725f 6974  fix_separator_it
+000063f0: 6572 6174 6f72 203d 2073 656c 662e 6765  erator = self.ge
+00006400: 745f 7072 6566 6978 5f73 6570 6172 6174  t_prefix_separat
+00006410: 6f72 5f69 7465 7261 746f 7228 290a 2020  or_iterator().  
+00006420: 2020 2020 2020 7661 6c75 6520 3d20 7365        value = se
+00006430: 6c66 2e5f 7265 6636 3537 305f 6578 7061  lf._ref6570_expa
+00006440: 6e73 696f 6e28 0a20 2020 2020 2020 2020  nsion(.         
+00006450: 2020 2076 6172 6961 626c 655f 6e61 6d65     variable_name
+00006460: 3d73 656c 662e 6e61 6d65 2c0a 2020 2020  =self.name,.    
+00006470: 2020 2020 2020 2020 696e 5f64 6174 613d          in_data=
+00006480: 696e 5f64 6174 612c 0a20 2020 2020 2020  in_data,.       
+00006490: 2020 2020 2065 7870 6c6f 6465 3d73 656c       explode=sel
+000064a0: 662e 6578 706c 6f64 652c 0a20 2020 2020  f.explode,.     
+000064b0: 2020 2020 2020 2070 6572 6365 6e74 5f65         percent_e
+000064c0: 6e63 6f64 653d 5472 7565 2c0a 2020 2020  ncode=True,.    
+000064d0: 2020 2020 2020 2020 7072 6566 6978 5f73          prefix_s
+000064e0: 6570 6172 6174 6f72 5f69 7465 7261 746f  eparator_iterato
+000064f0: 723d 7072 6566 6978 5f73 6570 6172 6174  r=prefix_separat
+00006500: 6f72 5f69 7465 7261 746f 720a 2020 2020  or_iterator.    
+00006510: 2020 2020 290a 2020 2020 2020 2020 7265      ).        re
+00006520: 7475 726e 2073 656c 662e 5f74 6f5f 6469  turn self._to_di
+00006530: 6374 2873 656c 662e 6e61 6d65 2c20 7661  ct(self.name, va
+00006540: 6c75 6529 0a0a 2020 2020 6465 6620 5f5f  lue)..    def __
+00006550: 7365 7269 616c 697a 655f 666f 726d 280a  serialize_form(.
+00006560: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
+00006570: 2020 2020 2020 696e 5f64 6174 613a 2074        in_data: t
+00006580: 7970 696e 672e 556e 696f 6e5b 4e6f 6e65  yping.Union[None
+00006590: 2c20 696e 742c 2066 6c6f 6174 2c20 7374  , int, float, st
+000065a0: 722c 2062 6f6f 6c2c 2064 6963 742c 206c  r, bool, dict, l
+000065b0: 6973 745d 2c0a 2020 2020 2020 2020 7072  ist],.        pr
+000065c0: 6566 6978 5f73 6570 6172 6174 6f72 5f69  efix_separator_i
+000065d0: 7465 7261 746f 723a 2074 7970 696e 672e  terator: typing.
+000065e0: 4f70 7469 6f6e 616c 5b50 7265 6669 7853  Optional[PrefixS
+000065f0: 6570 6172 6174 6f72 4974 6572 6174 6f72  eparatorIterator
+00006600: 5d0a 2020 2020 2920 2d3e 2074 7970 696e  ].    ) -> typin
+00006610: 672e 4469 6374 5b73 7472 2c20 7374 725d  g.Dict[str, str]
+00006620: 3a0a 2020 2020 2020 2020 6966 2070 7265  :.        if pre
+00006630: 6669 785f 7365 7061 7261 746f 725f 6974  fix_separator_it
+00006640: 6572 6174 6f72 2069 7320 4e6f 6e65 3a0a  erator is None:.
+00006650: 2020 2020 2020 2020 2020 2020 7072 6566              pref
+00006660: 6978 5f73 6570 6172 6174 6f72 5f69 7465  ix_separator_ite
+00006670: 7261 746f 7220 3d20 7365 6c66 2e67 6574  rator = self.get
+00006680: 5f70 7265 6669 785f 7365 7061 7261 746f  _prefix_separato
+00006690: 725f 6974 6572 6174 6f72 2829 0a20 2020  r_iterator().   
+000066a0: 2020 2020 2076 616c 7565 203d 2073 656c       value = sel
+000066b0: 662e 5f73 6572 6961 6c69 7a65 5f66 6f72  f._serialize_for
+000066c0: 6d28 0a20 2020 2020 2020 2020 2020 2069  m(.            i
+000066d0: 6e5f 6461 7461 2c0a 2020 2020 2020 2020  n_data,.        
+000066e0: 2020 2020 6e61 6d65 3d73 656c 662e 6e61      name=self.na
+000066f0: 6d65 2c0a 2020 2020 2020 2020 2020 2020  me,.            
+00006700: 6578 706c 6f64 653d 7365 6c66 2e65 7870  explode=self.exp
+00006710: 6c6f 6465 2c0a 2020 2020 2020 2020 2020  lode,.          
+00006720: 2020 7065 7263 656e 745f 656e 636f 6465    percent_encode
+00006730: 3d54 7275 652c 0a20 2020 2020 2020 2020  =True,.         
+00006740: 2020 2070 7265 6669 785f 7365 7061 7261     prefix_separa
+00006750: 746f 725f 6974 6572 6174 6f72 3d70 7265  tor_iterator=pre
+00006760: 6669 785f 7365 7061 7261 746f 725f 6974  fix_separator_it
+00006770: 6572 6174 6f72 0a20 2020 2020 2020 2029  erator.        )
+00006780: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00006790: 7365 6c66 2e5f 746f 5f64 6963 7428 7365  self._to_dict(se
+000067a0: 6c66 2e6e 616d 652c 2076 616c 7565 290a  lf.name, value).
+000067b0: 0a20 2020 2064 6566 2067 6574 5f70 7265  .    def get_pre
+000067c0: 6669 785f 7365 7061 7261 746f 725f 6974  fix_separator_it
+000067d0: 6572 6174 6f72 2873 656c 6629 202d 3e20  erator(self) -> 
+000067e0: 7479 7069 6e67 2e4f 7074 696f 6e61 6c5b  typing.Optional[
+000067f0: 5072 6566 6978 5365 7061 7261 746f 7249  PrefixSeparatorI
+00006800: 7465 7261 746f 725d 3a0a 2020 2020 2020  terator]:.      
+00006810: 2020 6966 2073 656c 662e 7374 796c 6520    if self.style 
+00006820: 6973 2050 6172 616d 6574 6572 5374 796c  is ParameterStyl
+00006830: 652e 464f 524d 3a0a 2020 2020 2020 2020  e.FORM:.        
+00006840: 2020 2020 7265 7475 726e 2050 7265 6669      return Prefi
+00006850: 7853 6570 6172 6174 6f72 4974 6572 6174  xSeparatorIterat
+00006860: 6f72 2827 3f27 2c20 2726 2729 0a20 2020  or('?', '&').   
+00006870: 2020 2020 2065 6c69 6620 7365 6c66 2e73       elif self.s
+00006880: 7479 6c65 2069 7320 5061 7261 6d65 7465  tyle is Paramete
+00006890: 7253 7479 6c65 2e53 5041 4345 5f44 454c  rStyle.SPACE_DEL
+000068a0: 494d 4954 4544 3a0a 2020 2020 2020 2020  IMITED:.        
+000068b0: 2020 2020 7265 7475 726e 2050 7265 6669      return Prefi
+000068c0: 7853 6570 6172 6174 6f72 4974 6572 6174  xSeparatorIterat
+000068d0: 6f72 2827 272c 2027 2532 3027 290a 2020  or('', '%20').  
+000068e0: 2020 2020 2020 656c 6966 2073 656c 662e        elif self.
+000068f0: 7374 796c 6520 6973 2050 6172 616d 6574  style is Paramet
+00006900: 6572 5374 796c 652e 5049 5045 5f44 454c  erStyle.PIPE_DEL
+00006910: 494d 4954 4544 3a0a 2020 2020 2020 2020  IMITED:.        
+00006920: 2020 2020 7265 7475 726e 2050 7265 6669      return Prefi
+00006930: 7853 6570 6172 6174 6f72 4974 6572 6174  xSeparatorIterat
+00006940: 6f72 2827 272c 2027 7c27 290a 0a20 2020  or('', '|')..   
+00006950: 2064 6566 2073 6572 6961 6c69 7a65 280a   def serialize(.
+00006960: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
+00006970: 2020 2020 2020 696e 5f64 6174 613a 2074        in_data: t
+00006980: 7970 696e 672e 556e 696f 6e5b 0a20 2020  yping.Union[.   
+00006990: 2020 2020 2020 2020 2053 6368 656d 612c           Schema,
+000069a0: 2044 6563 696d 616c 2c20 696e 742c 2066   Decimal, int, f
+000069b0: 6c6f 6174 2c20 7374 722c 2064 6174 652c  loat, str, date,
+000069c0: 2064 6174 6574 696d 652c 204e 6f6e 652c   datetime, None,
+000069d0: 2062 6f6f 6c2c 206c 6973 742c 2074 7570   bool, list, tup
+000069e0: 6c65 2c20 6469 6374 2c20 6672 6f7a 656e  le, dict, frozen
+000069f0: 6469 6374 2e66 726f 7a65 6e64 6963 745d  dict.frozendict]
+00006a00: 2c0a 2020 2020 2020 2020 7072 6566 6978  ,.        prefix
+00006a10: 5f73 6570 6172 6174 6f72 5f69 7465 7261  _separator_itera
+00006a20: 746f 723a 2074 7970 696e 672e 4f70 7469  tor: typing.Opti
+00006a30: 6f6e 616c 5b50 7265 6669 7853 6570 6172  onal[PrefixSepar
+00006a40: 6174 6f72 4974 6572 6174 6f72 5d20 3d20  atorIterator] = 
+00006a50: 4e6f 6e65 0a20 2020 2029 202d 3e20 7479  None.    ) -> ty
+00006a60: 7069 6e67 2e44 6963 745b 7374 722c 2073  ping.Dict[str, s
+00006a70: 7472 5d3a 0a20 2020 2020 2020 2069 6620  tr]:.        if 
+00006a80: 7365 6c66 2e73 6368 656d 613a 0a20 2020  self.schema:.   
+00006a90: 2020 2020 2020 2020 2063 6173 745f 696e           cast_in
+00006aa0: 5f64 6174 6120 3d20 7365 6c66 2e73 6368  _data = self.sch
+00006ab0: 656d 6128 696e 5f64 6174 6129 0a20 2020  ema(in_data).   
+00006ac0: 2020 2020 2020 2020 2063 6173 745f 696e           cast_in
+00006ad0: 5f64 6174 6120 3d20 7365 6c66 2e5f 6a73  _data = self._js
+00006ae0: 6f6e 5f65 6e63 6f64 6572 2e64 6566 6175  on_encoder.defau
+00006af0: 6c74 2863 6173 745f 696e 5f64 6174 6129  lt(cast_in_data)
+00006b00: 0a20 2020 2020 2020 2020 2020 2022 2222  .            """
+00006b10: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
+00006b20: 6d20 2d3e 2071 7565 7279 0a20 2020 2020  m -> query.     
+00006b30: 2020 2020 2020 2020 2020 2071 7565 7279             query
+00006b40: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00006b50: 2020 2020 2020 2d20 4745 542f 4845 4144        - GET/HEAD
+00006b60: 2f44 454c 4554 453a 2063 6f75 6c64 2075  /DELETE: could u
+00006b70: 7365 2066 6965 6c64 730a 2020 2020 2020  se fields.      
+00006b80: 2020 2020 2020 2020 2020 2020 2020 2d20                - 
+00006b90: 5055 542f 504f 5354 3a20 6d75 7374 2075  PUT/POST: must u
+00006ba0: 7365 2075 726c 656e 636f 6465 2074 6f20  se urlencode to 
+00006bb0: 7365 6e64 2070 6172 616d 6574 6572 730a  send parameters.
+00006bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006bd0: 2020 2020 7265 7475 726e 7320 6669 656c      returns fiel
+00006be0: 6473 3a20 7475 706c 650a 2020 2020 2020  ds: tuple.      
+00006bf0: 2020 2020 2020 7370 6163 6544 656c 696d        spaceDelim
+00006c00: 6974 6564 202d 3e20 7175 6572 790a 2020  ited -> query.  
+00006c10: 2020 2020 2020 2020 2020 2020 2020 7265                re
+00006c20: 7475 726e 7320 6669 656c 6473 0a20 2020  turns fields.   
+00006c30: 2020 2020 2020 2020 2070 6970 6544 656c           pipeDel
+00006c40: 696d 6974 6564 202d 3e20 7175 6572 790a  imited -> query.
+00006c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006c60: 7265 7475 726e 7320 6669 656c 6473 0a20  returns fields. 
+00006c70: 2020 2020 2020 2020 2020 2064 6565 704f             deepO
+00006c80: 626a 6563 7420 2d3e 2071 7565 7279 2c20  bject -> query, 
+00006c90: 6874 7470 733a 2f2f 6769 7468 7562 2e63  https://github.c
+00006ca0: 6f6d 2f4f 4149 2f4f 7065 6e41 5049 2d53  om/OAI/OpenAPI-S
+00006cb0: 7065 6369 6669 6361 7469 6f6e 2f69 7373  pecification/iss
+00006cc0: 7565 732f 3137 3036 0a20 2020 2020 2020  ues/1706.       
+00006cd0: 2020 2020 2020 2020 2072 6574 7572 6e73           returns
+00006ce0: 2066 6965 6c64 730a 2020 2020 2020 2020   fields.        
+00006cf0: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+00006d00: 2020 2020 6966 2073 656c 662e 7374 796c      if self.styl
+00006d10: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+00006d20: 2020 2023 2054 4f44 4f20 7570 6461 7465     # TODO update
+00006d30: 2071 7565 7279 206f 6e65 7320 746f 206f   query ones to o
+00006d40: 6d69 7420 7365 7474 696e 6720 7661 6c75  mit setting valu
+00006d50: 6573 2077 6865 6e20 5b5d 207b 7d20 6f72  es when [] {} or
+00006d60: 204e 6f6e 6520 6973 2069 6e70 7574 0a20   None is input. 
+00006d70: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00006d80: 6620 7365 6c66 2e73 7479 6c65 2069 7320  f self.style is 
+00006d90: 5061 7261 6d65 7465 7253 7479 6c65 2e46  ParameterStyle.F
+00006da0: 4f52 4d3a 0a20 2020 2020 2020 2020 2020  ORM:.           
+00006db0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00006dc0: 7365 6c66 2e5f 5f73 6572 6961 6c69 7a65  self.__serialize
+00006dd0: 5f66 6f72 6d28 6361 7374 5f69 6e5f 6461  _form(cast_in_da
+00006de0: 7461 2c20 7072 6566 6978 5f73 6570 6172  ta, prefix_separ
+00006df0: 6174 6f72 5f69 7465 7261 746f 7229 0a20  ator_iterator). 
+00006e00: 2020 2020 2020 2020 2020 2020 2020 2065                 e
+00006e10: 6c69 6620 7365 6c66 2e73 7479 6c65 2069  lif self.style i
+00006e20: 7320 5061 7261 6d65 7465 7253 7479 6c65  s ParameterStyle
+00006e30: 2e53 5041 4345 5f44 454c 494d 4954 4544  .SPACE_DELIMITED
+00006e40: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00006e50: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
+00006e60: 662e 5f5f 7365 7269 616c 697a 655f 7370  f.__serialize_sp
+00006e70: 6163 655f 6465 6c69 6d69 7465 6428 6361  ace_delimited(ca
+00006e80: 7374 5f69 6e5f 6461 7461 2c20 7072 6566  st_in_data, pref
+00006e90: 6978 5f73 6570 6172 6174 6f72 5f69 7465  ix_separator_ite
+00006ea0: 7261 746f 7229 0a20 2020 2020 2020 2020  rator).         
+00006eb0: 2020 2020 2020 2065 6c69 6620 7365 6c66         elif self
+00006ec0: 2e73 7479 6c65 2069 7320 5061 7261 6d65  .style is Parame
+00006ed0: 7465 7253 7479 6c65 2e50 4950 455f 4445  terStyle.PIPE_DE
+00006ee0: 4c49 4d49 5445 443a 0a20 2020 2020 2020  LIMITED:.       
+00006ef0: 2020 2020 2020 2020 2020 2020 2072 6574               ret
+00006f00: 7572 6e20 7365 6c66 2e5f 5f73 6572 6961  urn self.__seria
+00006f10: 6c69 7a65 5f70 6970 655f 6465 6c69 6d69  lize_pipe_delimi
+00006f20: 7465 6428 6361 7374 5f69 6e5f 6461 7461  ted(cast_in_data
+00006f30: 2c20 7072 6566 6978 5f73 6570 6172 6174  , prefix_separat
+00006f40: 6f72 5f69 7465 7261 746f 7229 0a20 2020  or_iterator).   
+00006f50: 2020 2020 2023 2073 656c 662e 636f 6e74       # self.cont
+00006f60: 656e 7420 7769 6c6c 2062 6520 6c65 6e67  ent will be leng
+00006f70: 7468 206f 6e65 0a20 2020 2020 2020 2069  th one.        i
+00006f80: 6620 7072 6566 6978 5f73 6570 6172 6174  f prefix_separat
+00006f90: 6f72 5f69 7465 7261 746f 7220 6973 204e  or_iterator is N
+00006fa0: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
+00006fb0: 2070 7265 6669 785f 7365 7061 7261 746f   prefix_separato
+00006fc0: 725f 6974 6572 6174 6f72 203d 2073 656c  r_iterator = sel
+00006fd0: 662e 6765 745f 7072 6566 6978 5f73 6570  f.get_prefix_sep
+00006fe0: 6172 6174 6f72 5f69 7465 7261 746f 7228  arator_iterator(
+00006ff0: 290a 2020 2020 2020 2020 666f 7220 636f  ).        for co
+00007000: 6e74 656e 745f 7479 7065 2c20 7363 6865  ntent_type, sche
+00007010: 6d61 2069 6e20 7365 6c66 2e63 6f6e 7465  ma in self.conte
+00007020: 6e74 2e69 7465 6d73 2829 3a0a 2020 2020  nt.items():.    
+00007030: 2020 2020 2020 2020 6361 7374 5f69 6e5f          cast_in_
+00007040: 6461 7461 203d 2073 6368 656d 6128 696e  data = schema(in
+00007050: 5f64 6174 6129 0a20 2020 2020 2020 2020  _data).         
+00007060: 2020 2063 6173 745f 696e 5f64 6174 6120     cast_in_data 
+00007070: 3d20 7365 6c66 2e5f 6a73 6f6e 5f65 6e63  = self._json_enc
+00007080: 6f64 6572 2e64 6566 6175 6c74 2863 6173  oder.default(cas
+00007090: 745f 696e 5f64 6174 6129 0a20 2020 2020  t_in_data).     
+000070a0: 2020 2020 2020 2069 6620 7365 6c66 2e5f         if self._
+000070b0: 636f 6e74 656e 745f 7479 7065 5f69 735f  content_type_is_
+000070c0: 6a73 6f6e 2863 6f6e 7465 6e74 5f74 7970  json(content_typ
+000070d0: 6529 3a0a 2020 2020 2020 2020 2020 2020  e):.            
+000070e0: 2020 2020 7661 6c75 6520 3d20 7365 6c66      value = self
+000070f0: 2e5f 7365 7269 616c 697a 655f 6a73 6f6e  ._serialize_json
+00007100: 2863 6173 745f 696e 5f64 6174 612c 2065  (cast_in_data, e
+00007110: 6c69 6d69 6e61 7465 5f77 6869 7465 7370  liminate_whitesp
+00007120: 6163 653d 5472 7565 290a 2020 2020 2020  ace=True).      
+00007130: 2020 2020 2020 2020 2020 7265 7475 726e            return
+00007140: 2073 656c 662e 5f74 6f5f 6469 6374 280a   self._to_dict(.
+00007150: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007160: 2020 2020 7365 6c66 2e6e 616d 652c 0a20      self.name,. 
+00007170: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007180: 2020 206e 6578 7428 7072 6566 6978 5f73     next(prefix_s
+00007190: 6570 6172 6174 6f72 5f69 7465 7261 746f  eparator_iterato
+000071a0: 7229 202b 2073 656c 662e 6e61 6d65 202b  r) + self.name +
+000071b0: 2027 3d27 202b 2071 756f 7465 2876 616c   '=' + quote(val
+000071c0: 7565 290a 2020 2020 2020 2020 2020 2020  ue).            
+000071d0: 2020 2020 290a 2020 2020 2020 2020 2020      ).          
+000071e0: 2020 7261 6973 6520 4e6f 7449 6d70 6c65    raise NotImple
+000071f0: 6d65 6e74 6564 4572 726f 7228 2753 6572  mentedError('Ser
+00007200: 6961 6c69 7a61 7469 6f6e 206f 6620 7b7d  ialization of {}
+00007210: 2068 6173 206e 6f74 2079 6574 2062 6565   has not yet bee
+00007220: 6e20 696d 706c 656d 656e 7465 6427 2e66  n implemented'.f
+00007230: 6f72 6d61 7428 636f 6e74 656e 745f 7479  ormat(content_ty
+00007240: 7065 2929 0a0a 0a63 6c61 7373 2043 6f6f  pe))...class Coo
+00007250: 6b69 6550 6172 616d 6574 6572 2850 6172  kieParameter(Par
+00007260: 616d 6574 6572 4261 7365 2c20 5374 796c  ameterBase, Styl
+00007270: 6546 6f72 6d53 6572 6961 6c69 7a65 7229  eFormSerializer)
+00007280: 3a0a 0a20 2020 2064 6566 205f 5f69 6e69  :..    def __ini
+00007290: 745f 5f28 0a20 2020 2020 2020 2073 656c  t__(.        sel
+000072a0: 662c 0a20 2020 2020 2020 206e 616d 653a  f,.        name:
+000072b0: 2073 7472 2c0a 2020 2020 2020 2020 7265   str,.        re
+000072c0: 7175 6972 6564 3a20 626f 6f6c 203d 2046  quired: bool = F
+000072d0: 616c 7365 2c0a 2020 2020 2020 2020 7374  alse,.        st
+000072e0: 796c 653a 2074 7970 696e 672e 4f70 7469  yle: typing.Opti
+000072f0: 6f6e 616c 5b50 6172 616d 6574 6572 5374  onal[ParameterSt
+00007300: 796c 655d 203d 204e 6f6e 652c 0a20 2020  yle] = None,.   
+00007310: 2020 2020 2065 7870 6c6f 6465 3a20 7479       explode: ty
+00007320: 7069 6e67 2e4f 7074 696f 6e61 6c5b 626f  ping.Optional[bo
+00007330: 6f6c 5d20 3d20 4e6f 6e65 2c0a 2020 2020  ol] = None,.    
+00007340: 2020 2020 616c 6c6f 775f 7265 7365 7276      allow_reserv
+00007350: 6564 3a20 7479 7069 6e67 2e4f 7074 696f  ed: typing.Optio
+00007360: 6e61 6c5b 626f 6f6c 5d20 3d20 4e6f 6e65  nal[bool] = None
+00007370: 2c0a 2020 2020 2020 2020 7363 6865 6d61  ,.        schema
+00007380: 3a20 7479 7069 6e67 2e4f 7074 696f 6e61  : typing.Optiona
+00007390: 6c5b 7479 7069 6e67 2e54 7970 655b 5363  l[typing.Type[Sc
+000073a0: 6865 6d61 5d5d 203d 204e 6f6e 652c 0a20  hema]] = None,. 
+000073b0: 2020 2020 2020 2063 6f6e 7465 6e74 3a20         content: 
+000073c0: 7479 7069 6e67 2e4f 7074 696f 6e61 6c5b  typing.Optional[
+000073d0: 7479 7069 6e67 2e44 6963 745b 7374 722c  typing.Dict[str,
+000073e0: 2074 7970 696e 672e 5479 7065 5b53 6368   typing.Type[Sch
+000073f0: 656d 615d 5d5d 203d 204e 6f6e 650a 2020  ema]]] = None.  
+00007400: 2020 293a 0a20 2020 2020 2020 2075 7365    ):.        use
+00007410: 645f 7374 796c 6520 3d20 5061 7261 6d65  d_style = Parame
+00007420: 7465 7253 7479 6c65 2e46 4f52 4d20 6966  terStyle.FORM if
+00007430: 2073 7479 6c65 2069 7320 4e6f 6e65 2061   style is None a
+00007440: 6e64 2063 6f6e 7465 6e74 2069 7320 4e6f  nd content is No
+00007450: 6e65 2061 6e64 2073 6368 656d 6120 656c  ne and schema el
+00007460: 7365 2073 7479 6c65 0a20 2020 2020 2020  se style.       
+00007470: 2075 7365 645f 6578 706c 6f64 6520 3d20   used_explode = 
+00007480: 7365 6c66 2e5f 6765 745f 6465 6661 756c  self._get_defaul
+00007490: 745f 6578 706c 6f64 6528 7573 6564 5f73  t_explode(used_s
+000074a0: 7479 6c65 2920 6966 2065 7870 6c6f 6465  tyle) if explode
+000074b0: 2069 7320 4e6f 6e65 2065 6c73 6520 6578   is None else ex
+000074c0: 706c 6f64 650a 0a20 2020 2020 2020 2073  plode..        s
+000074d0: 7570 6572 2829 2e5f 5f69 6e69 745f 5f28  uper().__init__(
+000074e0: 0a20 2020 2020 2020 2020 2020 206e 616d  .            nam
+000074f0: 652c 0a20 2020 2020 2020 2020 2020 2069  e,.            i
+00007500: 6e5f 7479 7065 3d50 6172 616d 6574 6572  n_type=Parameter
+00007510: 496e 5479 7065 2e43 4f4f 4b49 452c 0a20  InType.COOKIE,. 
+00007520: 2020 2020 2020 2020 2020 2072 6571 7569             requi
+00007530: 7265 643d 7265 7175 6972 6564 2c0a 2020  red=required,.  
+00007540: 2020 2020 2020 2020 2020 7374 796c 653d            style=
+00007550: 7573 6564 5f73 7479 6c65 2c0a 2020 2020  used_style,.    
+00007560: 2020 2020 2020 2020 6578 706c 6f64 653d          explode=
+00007570: 7573 6564 5f65 7870 6c6f 6465 2c0a 2020  used_explode,.  
+00007580: 2020 2020 2020 2020 2020 616c 6c6f 775f            allow_
+00007590: 7265 7365 7276 6564 3d61 6c6c 6f77 5f72  reserved=allow_r
+000075a0: 6573 6572 7665 642c 0a20 2020 2020 2020  eserved,.       
+000075b0: 2020 2020 2073 6368 656d 613d 7363 6865       schema=sche
+000075c0: 6d61 2c0a 2020 2020 2020 2020 2020 2020  ma,.            
+000075d0: 636f 6e74 656e 743d 636f 6e74 656e 740a  content=content.
+000075e0: 2020 2020 2020 2020 290a 0a20 2020 2064          )..    d
+000075f0: 6566 2073 6572 6961 6c69 7a65 280a 2020  ef serialize(.  
+00007600: 2020 2020 2020 7365 6c66 2c0a 2020 2020        self,.    
+00007610: 2020 2020 696e 5f64 6174 613a 2074 7970      in_data: typ
+00007620: 696e 672e 556e 696f 6e5b 0a20 2020 2020  ing.Union[.     
+00007630: 2020 2020 2020 2053 6368 656d 612c 2044         Schema, D
+00007640: 6563 696d 616c 2c20 696e 742c 2066 6c6f  ecimal, int, flo
+00007650: 6174 2c20 7374 722c 2064 6174 652c 2064  at, str, date, d
+00007660: 6174 6574 696d 652c 204e 6f6e 652c 2062  atetime, None, b
+00007670: 6f6f 6c2c 206c 6973 742c 2074 7570 6c65  ool, list, tuple
+00007680: 2c20 6469 6374 2c20 6672 6f7a 656e 6469  , dict, frozendi
+00007690: 6374 2e66 726f 7a65 6e64 6963 745d 0a20  ct.frozendict]. 
+000076a0: 2020 2029 202d 3e20 7479 7069 6e67 2e44     ) -> typing.D
+000076b0: 6963 745b 7374 722c 2073 7472 5d3a 0a20  ict[str, str]:. 
+000076c0: 2020 2020 2020 2069 6620 7365 6c66 2e73         if self.s
+000076d0: 6368 656d 613a 0a20 2020 2020 2020 2020  chema:.         
+000076e0: 2020 2063 6173 745f 696e 5f64 6174 6120     cast_in_data 
+000076f0: 3d20 7365 6c66 2e73 6368 656d 6128 696e  = self.schema(in
+00007700: 5f64 6174 6129 0a20 2020 2020 2020 2020  _data).         
+00007710: 2020 2063 6173 745f 696e 5f64 6174 6120     cast_in_data 
+00007720: 3d20 7365 6c66 2e5f 6a73 6f6e 5f65 6e63  = self._json_enc
+00007730: 6f64 6572 2e64 6566 6175 6c74 2863 6173  oder.default(cas
+00007740: 745f 696e 5f64 6174 6129 0a20 2020 2020  t_in_data).     
+00007750: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+00007760: 2020 2020 2020 2066 6f72 6d20 2d3e 2063         form -> c
+00007770: 6f6f 6b69 650a 2020 2020 2020 2020 2020  ookie.          
+00007780: 2020 2020 2020 7265 7475 726e 7320 6669        returns fi
+00007790: 656c 6473 3a20 7475 706c 650a 2020 2020  elds: tuple.    
+000077a0: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
+000077b0: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+000077c0: 7374 796c 653a 0a20 2020 2020 2020 2020  style:.         
+000077d0: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+000077e0: 2020 2020 2020 2020 2020 2054 4f44 4f20             TODO 
+000077f0: 6164 6420 6573 6361 7069 6e67 206f 6620  add escaping of 
+00007800: 636f 6d6d 612c 2073 7061 6365 2c20 6571  comma, space, eq
+00007810: 7561 6c73 0a20 2020 2020 2020 2020 2020  uals.           
+00007820: 2020 2020 206f 7220 7475 726e 2065 6e63       or turn enc
+00007830: 6f64 696e 6720 6f6e 0a20 2020 2020 2020  oding on.       
+00007840: 2020 2020 2020 2020 2022 2222 0a20 2020           """.   
+00007850: 2020 2020 2020 2020 2020 2020 2076 616c               val
+00007860: 7565 203d 2073 656c 662e 5f73 6572 6961  ue = self._seria
+00007870: 6c69 7a65 5f66 6f72 6d28 0a20 2020 2020  lize_form(.     
+00007880: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+00007890: 6173 745f 696e 5f64 6174 612c 0a20 2020  ast_in_data,.   
+000078a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000078b0: 2065 7870 6c6f 6465 3d73 656c 662e 6578   explode=self.ex
+000078c0: 706c 6f64 652c 0a20 2020 2020 2020 2020  plode,.         
+000078d0: 2020 2020 2020 2020 2020 206e 616d 653d             name=
+000078e0: 7365 6c66 2e6e 616d 652c 0a20 2020 2020  self.name,.     
+000078f0: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+00007900: 6572 6365 6e74 5f65 6e63 6f64 653d 4661  ercent_encode=Fa
+00007910: 6c73 652c 0a20 2020 2020 2020 2020 2020  lse,.           
+00007920: 2020 2020 2020 2020 2070 7265 6669 785f           prefix_
+00007930: 7365 7061 7261 746f 725f 6974 6572 6174  separator_iterat
+00007940: 6f72 3d50 7265 6669 7853 6570 6172 6174  or=PrefixSeparat
+00007950: 6f72 4974 6572 6174 6f72 2827 272c 2027  orIterator('', '
+00007960: 2627 290a 2020 2020 2020 2020 2020 2020  &').            
+00007970: 2020 2020 290a 2020 2020 2020 2020 2020      ).          
+00007980: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
+00007990: 662e 5f74 6f5f 6469 6374 2873 656c 662e  f._to_dict(self.
+000079a0: 6e61 6d65 2c20 7661 6c75 6529 0a20 2020  name, value).   
+000079b0: 2020 2020 2023 2073 656c 662e 636f 6e74       # self.cont
+000079c0: 656e 7420 7769 6c6c 2062 6520 6c65 6e67  ent will be leng
+000079d0: 7468 206f 6e65 0a20 2020 2020 2020 2066  th one.        f
+000079e0: 6f72 2063 6f6e 7465 6e74 5f74 7970 652c  or content_type,
+000079f0: 2073 6368 656d 6120 696e 2073 656c 662e   schema in self.
+00007a00: 636f 6e74 656e 742e 6974 656d 7328 293a  content.items():
+00007a10: 0a20 2020 2020 2020 2020 2020 2063 6173  .            cas
+00007a20: 745f 696e 5f64 6174 6120 3d20 7363 6865  t_in_data = sche
+00007a30: 6d61 2869 6e5f 6461 7461 290a 2020 2020  ma(in_data).    
+00007a40: 2020 2020 2020 2020 6361 7374 5f69 6e5f          cast_in_
+00007a50: 6461 7461 203d 2073 656c 662e 5f6a 736f  data = self._jso
+00007a60: 6e5f 656e 636f 6465 722e 6465 6661 756c  n_encoder.defaul
+00007a70: 7428 6361 7374 5f69 6e5f 6461 7461 290a  t(cast_in_data).
+00007a80: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+00007a90: 656c 662e 5f63 6f6e 7465 6e74 5f74 7970  elf._content_typ
+00007aa0: 655f 6973 5f6a 736f 6e28 636f 6e74 656e  e_is_json(conten
+00007ab0: 745f 7479 7065 293a 0a20 2020 2020 2020  t_type):.       
+00007ac0: 2020 2020 2020 2020 2076 616c 7565 203d           value =
+00007ad0: 2073 656c 662e 5f73 6572 6961 6c69 7a65   self._serialize
+00007ae0: 5f6a 736f 6e28 6361 7374 5f69 6e5f 6461  _json(cast_in_da
+00007af0: 7461 290a 2020 2020 2020 2020 2020 2020  ta).            
+00007b00: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
+00007b10: 5f74 6f5f 6469 6374 2873 656c 662e 6e61  _to_dict(self.na
+00007b20: 6d65 2c20 7661 6c75 6529 0a20 2020 2020  me, value).     
+00007b30: 2020 2020 2020 2072 6169 7365 204e 6f74         raise Not
+00007b40: 496d 706c 656d 656e 7465 6445 7272 6f72  ImplementedError
+00007b50: 2827 5365 7269 616c 697a 6174 696f 6e20  ('Serialization 
+00007b60: 6f66 207b 7d20 6861 7320 6e6f 7420 7965  of {} has not ye
+00007b70: 7420 6265 656e 2069 6d70 6c65 6d65 6e74  t been implement
+00007b80: 6564 272e 666f 726d 6174 2863 6f6e 7465  ed'.format(conte
+00007b90: 6e74 5f74 7970 6529 290a 0a0a 636c 6173  nt_type))...clas
+00007ba0: 7320 4865 6164 6572 5061 7261 6d65 7465  s HeaderParamete
+00007bb0: 7228 5061 7261 6d65 7465 7242 6173 652c  r(ParameterBase,
+00007bc0: 2053 7479 6c65 5369 6d70 6c65 5365 7269   StyleSimpleSeri
+00007bd0: 616c 697a 6572 293a 0a20 2020 2064 6566  alizer):.    def
+00007be0: 205f 5f69 6e69 745f 5f28 0a20 2020 2020   __init__(.     
+00007bf0: 2020 2073 656c 662c 0a20 2020 2020 2020     self,.       
+00007c00: 206e 616d 653a 2073 7472 2c0a 2020 2020   name: str,.    
+00007c10: 2020 2020 7265 7175 6972 6564 3a20 626f      required: bo
+00007c20: 6f6c 203d 2046 616c 7365 2c0a 2020 2020  ol = False,.    
+00007c30: 2020 2020 7374 796c 653a 2074 7970 696e      style: typin
+00007c40: 672e 4f70 7469 6f6e 616c 5b50 6172 616d  g.Optional[Param
+00007c50: 6574 6572 5374 796c 655d 203d 204e 6f6e  eterStyle] = Non
+00007c60: 652c 0a20 2020 2020 2020 2065 7870 6c6f  e,.        explo
+00007c70: 6465 3a20 626f 6f6c 203d 2046 616c 7365  de: bool = False
+00007c80: 2c0a 2020 2020 2020 2020 616c 6c6f 775f  ,.        allow_
+00007c90: 7265 7365 7276 6564 3a20 7479 7069 6e67  reserved: typing
+00007ca0: 2e4f 7074 696f 6e61 6c5b 626f 6f6c 5d20  .Optional[bool] 
+00007cb0: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
+00007cc0: 7363 6865 6d61 3a20 7479 7069 6e67 2e4f  schema: typing.O
+00007cd0: 7074 696f 6e61 6c5b 7479 7069 6e67 2e54  ptional[typing.T
+00007ce0: 7970 655b 5363 6865 6d61 5d5d 203d 204e  ype[Schema]] = N
+00007cf0: 6f6e 652c 0a20 2020 2020 2020 2063 6f6e  one,.        con
+00007d00: 7465 6e74 3a20 7479 7069 6e67 2e4f 7074  tent: typing.Opt
+00007d10: 696f 6e61 6c5b 7479 7069 6e67 2e44 6963  ional[typing.Dic
+00007d20: 745b 7374 722c 2074 7970 696e 672e 5479  t[str, typing.Ty
+00007d30: 7065 5b53 6368 656d 615d 5d5d 203d 204e  pe[Schema]]] = N
+00007d40: 6f6e 650a 2020 2020 293a 0a20 2020 2020  one.    ):.     
+00007d50: 2020 2073 7570 6572 2829 2e5f 5f69 6e69     super().__ini
+00007d60: 745f 5f28 0a20 2020 2020 2020 2020 2020  t__(.           
+00007d70: 206e 616d 652c 0a20 2020 2020 2020 2020   name,.         
+00007d80: 2020 2069 6e5f 7479 7065 3d50 6172 616d     in_type=Param
+00007d90: 6574 6572 496e 5479 7065 2e48 4541 4445  eterInType.HEADE
+00007da0: 522c 0a20 2020 2020 2020 2020 2020 2072  R,.            r
+00007db0: 6571 7569 7265 643d 7265 7175 6972 6564  equired=required
+00007dc0: 2c0a 2020 2020 2020 2020 2020 2020 7374  ,.            st
+00007dd0: 796c 653d 7374 796c 652c 0a20 2020 2020  yle=style,.     
+00007de0: 2020 2020 2020 2065 7870 6c6f 6465 3d65         explode=e
+00007df0: 7870 6c6f 6465 2c0a 2020 2020 2020 2020  xplode,.        
+00007e00: 2020 2020 616c 6c6f 775f 7265 7365 7276      allow_reserv
+00007e10: 6564 3d61 6c6c 6f77 5f72 6573 6572 7665  ed=allow_reserve
+00007e20: 642c 0a20 2020 2020 2020 2020 2020 2073  d,.            s
+00007e30: 6368 656d 613d 7363 6865 6d61 2c0a 2020  chema=schema,.  
+00007e40: 2020 2020 2020 2020 2020 636f 6e74 656e            conten
+00007e50: 743d 636f 6e74 656e 740a 2020 2020 2020  t=content.      
+00007e60: 2020 290a 0a20 2020 2040 7374 6174 6963    )..    @static
+00007e70: 6d65 7468 6f64 0a20 2020 2064 6566 205f  method.    def _
+00007e80: 5f74 6f5f 6865 6164 6572 7328 696e 5f64  _to_headers(in_d
+00007e90: 6174 613a 2074 7970 696e 672e 5475 706c  ata: typing.Tupl
+00007ea0: 655b 7479 7069 6e67 2e54 7570 6c65 5b73  e[typing.Tuple[s
+00007eb0: 7472 2c20 7374 725d 2c20 2e2e 2e5d 2920  tr, str], ...]) 
+00007ec0: 2d3e 2048 5454 5048 6561 6465 7244 6963  -> HTTPHeaderDic
+00007ed0: 743a 0a20 2020 2020 2020 2064 6174 6120  t:.        data 
+00007ee0: 3d20 7475 706c 6528 7420 666f 7220 7420  = tuple(t for t 
+00007ef0: 696e 2069 6e5f 6461 7461 2069 6620 7429  in in_data if t)
+00007f00: 0a20 2020 2020 2020 2068 6561 6465 7273  .        headers
+00007f10: 203d 2048 5454 5048 6561 6465 7244 6963   = HTTPHeaderDic
+00007f20: 7428 290a 2020 2020 2020 2020 6966 206e  t().        if n
+00007f30: 6f74 2064 6174 613a 0a20 2020 2020 2020  ot data:.       
+00007f40: 2020 2020 2072 6574 7572 6e20 6865 6164       return head
+00007f50: 6572 730a 2020 2020 2020 2020 6865 6164  ers.        head
+00007f60: 6572 732e 6578 7465 6e64 2864 6174 6129  ers.extend(data)
+00007f70: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00007f80: 6865 6164 6572 730a 0a20 2020 2064 6566  headers..    def
+00007f90: 2073 6572 6961 6c69 7a65 280a 2020 2020   serialize(.    
+00007fa0: 2020 2020 7365 6c66 2c0a 2020 2020 2020      self,.      
+00007fb0: 2020 696e 5f64 6174 613a 2074 7970 696e    in_data: typin
+00007fc0: 672e 556e 696f 6e5b 0a20 2020 2020 2020  g.Union[.       
+00007fd0: 2020 2020 2053 6368 656d 612c 2044 6563       Schema, Dec
+00007fe0: 696d 616c 2c20 696e 742c 2066 6c6f 6174  imal, int, float
+00007ff0: 2c20 7374 722c 2064 6174 652c 2064 6174  , str, date, dat
+00008000: 6574 696d 652c 204e 6f6e 652c 2062 6f6f  etime, None, boo
+00008010: 6c2c 206c 6973 742c 2074 7570 6c65 2c20  l, list, tuple, 
+00008020: 6469 6374 2c20 6672 6f7a 656e 6469 6374  dict, frozendict
+00008030: 2e66 726f 7a65 6e64 6963 745d 0a20 2020  .frozendict].   
+00008040: 2029 202d 3e20 4854 5450 4865 6164 6572   ) -> HTTPHeader
+00008050: 4469 6374 3a0a 2020 2020 2020 2020 6966  Dict:.        if
+00008060: 2073 656c 662e 7363 6865 6d61 3a0a 2020   self.schema:.  
+00008070: 2020 2020 2020 2020 2020 6361 7374 5f69            cast_i
+00008080: 6e5f 6461 7461 203d 2073 656c 662e 7363  n_data = self.sc
+00008090: 6865 6d61 2869 6e5f 6461 7461 290a 2020  hema(in_data).  
+000080a0: 2020 2020 2020 2020 2020 6361 7374 5f69            cast_i
+000080b0: 6e5f 6461 7461 203d 2073 656c 662e 5f6a  n_data = self._j
+000080c0: 736f 6e5f 656e 636f 6465 722e 6465 6661  son_encoder.defa
+000080d0: 756c 7428 6361 7374 5f69 6e5f 6461 7461  ult(cast_in_data
+000080e0: 290a 2020 2020 2020 2020 2020 2020 2222  ).            ""
+000080f0: 220a 2020 2020 2020 2020 2020 2020 7369  ".            si
+00008100: 6d70 6c65 202d 3e20 6865 6164 6572 0a20  mple -> header. 
+00008110: 2020 2020 2020 2020 2020 2020 2020 2068                 h
+00008120: 6561 6465 7273 3a20 506f 6f6c 4d61 6e61  eaders: PoolMana
+00008130: 6765 7220 6e65 6564 7320 6120 6d61 7070  ger needs a mapp
+00008140: 696e 672c 2074 7570 6c65 2069 7320 636c  ing, tuple is cl
+00008150: 6f73 650a 2020 2020 2020 2020 2020 2020  ose.            
+00008160: 2020 2020 2020 2020 7265 7475 726e 7320          returns 
+00008170: 6865 6164 6572 733a 2064 6963 740a 2020  headers: dict.  
+00008180: 2020 2020 2020 2020 2020 2222 220a 2020            """.  
+00008190: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
+000081a0: 662e 7374 796c 653a 0a20 2020 2020 2020  f.style:.       
+000081b0: 2020 2020 2020 2020 2076 616c 7565 203d           value =
+000081c0: 2073 656c 662e 5f73 6572 6961 6c69 7a65   self._serialize
+000081d0: 5f73 696d 706c 6528 6361 7374 5f69 6e5f  _simple(cast_in_
+000081e0: 6461 7461 2c20 7365 6c66 2e6e 616d 652c  data, self.name,
+000081f0: 2073 656c 662e 6578 706c 6f64 652c 2046   self.explode, F
+00008200: 616c 7365 290a 2020 2020 2020 2020 2020  alse).          
+00008210: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
+00008220: 662e 5f5f 746f 5f68 6561 6465 7273 2828  f.__to_headers((
+00008230: 2873 656c 662e 6e61 6d65 2c20 7661 6c75  (self.name, valu
+00008240: 6529 2c29 290a 2020 2020 2020 2020 2320  e),)).        # 
+00008250: 7365 6c66 2e63 6f6e 7465 6e74 2077 696c  self.content wil
+00008260: 6c20 6265 206c 656e 6774 6820 6f6e 650a  l be length one.
+00008270: 2020 2020 2020 2020 666f 7220 636f 6e74          for cont
+00008280: 656e 745f 7479 7065 2c20 7363 6865 6d61  ent_type, schema
+00008290: 2069 6e20 7365 6c66 2e63 6f6e 7465 6e74   in self.content
+000082a0: 2e69 7465 6d73 2829 3a0a 2020 2020 2020  .items():.      
+000082b0: 2020 2020 2020 6361 7374 5f69 6e5f 6461        cast_in_da
+000082c0: 7461 203d 2073 6368 656d 6128 696e 5f64  ta = schema(in_d
+000082d0: 6174 6129 0a20 2020 2020 2020 2020 2020  ata).           
+000082e0: 2063 6173 745f 696e 5f64 6174 6120 3d20   cast_in_data = 
+000082f0: 7365 6c66 2e5f 6a73 6f6e 5f65 6e63 6f64  self._json_encod
+00008300: 6572 2e64 6566 6175 6c74 2863 6173 745f  er.default(cast_
+00008310: 696e 5f64 6174 6129 0a20 2020 2020 2020  in_data).       
+00008320: 2020 2020 2069 6620 7365 6c66 2e5f 636f       if self._co
+00008330: 6e74 656e 745f 7479 7065 5f69 735f 6a73  ntent_type_is_js
+00008340: 6f6e 2863 6f6e 7465 6e74 5f74 7970 6529  on(content_type)
+00008350: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00008360: 2020 7661 6c75 6520 3d20 7365 6c66 2e5f    value = self._
+00008370: 7365 7269 616c 697a 655f 6a73 6f6e 2863  serialize_json(c
+00008380: 6173 745f 696e 5f64 6174 6129 0a20 2020  ast_in_data).   
+00008390: 2020 2020 2020 2020 2020 2020 2072 6574               ret
+000083a0: 7572 6e20 7365 6c66 2e5f 5f74 6f5f 6865  urn self.__to_he
+000083b0: 6164 6572 7328 2828 7365 6c66 2e6e 616d  aders(((self.nam
+000083c0: 652c 2076 616c 7565 292c 2929 0a20 2020  e, value),)).   
+000083d0: 2020 2020 2020 2020 2072 6169 7365 204e           raise N
+000083e0: 6f74 496d 706c 656d 656e 7465 6445 7272  otImplementedErr
+000083f0: 6f72 2827 5365 7269 616c 697a 6174 696f  or('Serializatio
+00008400: 6e20 6f66 207b 7d20 6861 7320 6e6f 7420  n of {} has not 
+00008410: 7965 7420 6265 656e 2069 6d70 6c65 6d65  yet been impleme
+00008420: 6e74 6564 272e 666f 726d 6174 2863 6f6e  nted'.format(con
+00008430: 7465 6e74 5f74 7970 6529 290a 0a0a 636c  tent_type))...cl
+00008440: 6173 7320 456e 636f 6469 6e67 3a0a 2020  ass Encoding:.  
+00008450: 2020 6465 6620 5f5f 696e 6974 5f5f 280a    def __init__(.
+00008460: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
+00008470: 2020 2020 2020 636f 6e74 656e 745f 7479        content_ty
+00008480: 7065 3a20 7374 722c 0a20 2020 2020 2020  pe: str,.       
+00008490: 2068 6561 6465 7273 3a20 7479 7069 6e67   headers: typing
+000084a0: 2e4f 7074 696f 6e61 6c5b 7479 7069 6e67  .Optional[typing
+000084b0: 2e44 6963 745b 7374 722c 2048 6561 6465  .Dict[str, Heade
+000084c0: 7250 6172 616d 6574 6572 5d5d 203d 204e  rParameter]] = N
+000084d0: 6f6e 652c 0a20 2020 2020 2020 2073 7479  one,.        sty
+000084e0: 6c65 3a20 7479 7069 6e67 2e4f 7074 696f  le: typing.Optio
+000084f0: 6e61 6c5b 5061 7261 6d65 7465 7253 7479  nal[ParameterSty
+00008500: 6c65 5d20 3d20 4e6f 6e65 2c0a 2020 2020  le] = None,.    
+00008510: 2020 2020 6578 706c 6f64 653a 2062 6f6f      explode: boo
+00008520: 6c20 3d20 4661 6c73 652c 0a20 2020 2020  l = False,.     
+00008530: 2020 2061 6c6c 6f77 5f72 6573 6572 7665     allow_reserve
+00008540: 643a 2062 6f6f 6c20 3d20 4661 6c73 652c  d: bool = False,
+00008550: 0a20 2020 2029 3a0a 2020 2020 2020 2020  .    ):.        
+00008560: 7365 6c66 2e63 6f6e 7465 6e74 5f74 7970  self.content_typ
+00008570: 6520 3d20 636f 6e74 656e 745f 7479 7065  e = content_type
+00008580: 0a20 2020 2020 2020 2073 656c 662e 6865  .        self.he
+00008590: 6164 6572 7320 3d20 6865 6164 6572 730a  aders = headers.
+000085a0: 2020 2020 2020 2020 7365 6c66 2e73 7479          self.sty
+000085b0: 6c65 203d 2073 7479 6c65 0a20 2020 2020  le = style.     
+000085c0: 2020 2073 656c 662e 6578 706c 6f64 6520     self.explode 
+000085d0: 3d20 6578 706c 6f64 650a 2020 2020 2020  = explode.      
+000085e0: 2020 7365 6c66 2e61 6c6c 6f77 5f72 6573    self.allow_res
+000085f0: 6572 7665 6420 3d20 616c 6c6f 775f 7265  erved = allow_re
+00008600: 7365 7276 6564 0a0a 0a40 6461 7461 636c  served...@datacl
+00008610: 6173 730a 636c 6173 7320 4d65 6469 6154  ass.class MediaT
+00008620: 7970 653a 0a20 2020 2022 2222 0a20 2020  ype:.    """.   
+00008630: 2055 7365 6420 746f 2073 746f 7265 2072   Used to store r
+00008640: 6571 7565 7374 2061 6e64 2072 6573 706f  equest and respo
+00008650: 6e73 6520 626f 6479 2073 6368 656d 6120  nse body schema 
+00008660: 696e 666f 726d 6174 696f 6e0a 2020 2020  information.    
+00008670: 656e 636f 6469 6e67 3a0a 2020 2020 2020  encoding:.      
+00008680: 2020 4120 6d61 7020 6265 7477 6565 6e20    A map between 
+00008690: 6120 7072 6f70 6572 7479 206e 616d 6520  a property name 
+000086a0: 616e 6420 6974 7320 656e 636f 6469 6e67  and its encoding
+000086b0: 2069 6e66 6f72 6d61 7469 6f6e 2e0a 2020   information..  
+000086c0: 2020 2020 2020 5468 6520 6b65 792c 2062        The key, b
+000086d0: 6569 6e67 2074 6865 2070 726f 7065 7274  eing the propert
+000086e0: 7920 6e61 6d65 2c20 4d55 5354 2065 7869  y name, MUST exi
+000086f0: 7374 2069 6e20 7468 6520 7363 6865 6d61  st in the schema
+00008700: 2061 7320 6120 7072 6f70 6572 7479 2e0a   as a property..
+00008710: 2020 2020 2020 2020 5468 6520 656e 636f          The enco
+00008720: 6469 6e67 206f 626a 6563 7420 5348 414c  ding object SHAL
+00008730: 4c20 6f6e 6c79 2061 7070 6c79 2074 6f20  L only apply to 
+00008740: 7265 7175 6573 7442 6f64 7920 6f62 6a65  requestBody obje
+00008750: 6374 7320 7768 656e 2074 6865 206d 6564  cts when the med
+00008760: 6961 2074 7970 6520 6973 0a20 2020 2020  ia type is.     
+00008770: 2020 206d 756c 7469 7061 7274 206f 7220     multipart or 
+00008780: 6170 706c 6963 6174 696f 6e2f 782d 7777  application/x-ww
+00008790: 772d 666f 726d 2d75 726c 656e 636f 6465  w-form-urlencode
+000087a0: 642e 0a20 2020 2022 2222 0a20 2020 2073  d..    """.    s
+000087b0: 6368 656d 613a 2074 7970 696e 672e 4f70  chema: typing.Op
+000087c0: 7469 6f6e 616c 5b74 7970 696e 672e 5479  tional[typing.Ty
+000087d0: 7065 5b53 6368 656d 615d 5d20 3d20 4e6f  pe[Schema]] = No
+000087e0: 6e65 0a20 2020 2065 6e63 6f64 696e 673a  ne.    encoding:
+000087f0: 2074 7970 696e 672e 4f70 7469 6f6e 616c   typing.Optional
+00008800: 5b74 7970 696e 672e 4469 6374 5b73 7472  [typing.Dict[str
+00008810: 2c20 456e 636f 6469 6e67 5d5d 203d 204e  , Encoding]] = N
+00008820: 6f6e 650a 0a0a 4064 6174 6163 6c61 7373  one...@dataclass
+00008830: 0a63 6c61 7373 2041 7069 5265 7370 6f6e  .class ApiRespon
+00008840: 7365 5769 7468 6f75 7444 6573 6572 6961  seWithoutDeseria
+00008850: 6c69 7a61 7469 6f6e 2841 7069 5265 7370  lization(ApiResp
+00008860: 6f6e 7365 293a 0a20 2020 2070 6173 730a  onse):.    pass.
+00008870: 0a40 6461 7461 636c 6173 730a 636c 6173  .@dataclass.clas
+00008880: 7320 4170 6952 6573 706f 6e73 6557 6974  s ApiResponseWit
+00008890: 686f 7574 4465 7365 7269 616c 697a 6174  houtDeserializat
+000088a0: 696f 6e41 7379 6e63 2841 7379 6e63 4170  ionAsync(AsyncAp
+000088b0: 6952 6573 706f 6e73 6529 3a0a 2020 2020  iResponse):.    
+000088c0: 7061 7373 0a0a 0a63 6c61 7373 204f 7065  pass...class Ope
+000088d0: 6e41 7069 5265 7370 6f6e 7365 284a 534f  nApiResponse(JSO
+000088e0: 4e44 6574 6563 746f 7229 3a0a 2020 2020  NDetector):.    
+000088f0: 5f5f 6669 6c65 6e61 6d65 5f63 6f6e 7465  __filename_conte
+00008900: 6e74 5f64 6973 706f 7369 7469 6f6e 5f70  nt_disposition_p
+00008910: 6174 7465 726e 203d 2072 652e 636f 6d70  attern = re.comp
+00008920: 696c 6528 2766 696c 656e 616d 653d 2228  ile('filename="(
+00008930: 2e2b 3f29 2227 290a 0a20 2020 2064 6566  .+?)"')..    def
+00008940: 205f 5f69 6e69 745f 5f28 0a20 2020 2020   __init__(.     
+00008950: 2020 2073 656c 662c 0a20 2020 2020 2020     self,.       
+00008960: 2072 6573 706f 6e73 655f 636c 733a 2074   response_cls: t
+00008970: 7970 696e 672e 5479 7065 5b41 7069 5265  yping.Type[ApiRe
+00008980: 7370 6f6e 7365 5d20 3d20 4170 6952 6573  sponse] = ApiRes
+00008990: 706f 6e73 652c 0a20 2020 2020 2020 2072  ponse,.        r
+000089a0: 6573 706f 6e73 655f 636c 735f 6173 796e  esponse_cls_asyn
+000089b0: 633a 2074 7970 696e 672e 5479 7065 5b41  c: typing.Type[A
+000089c0: 7379 6e63 4170 6952 6573 706f 6e73 655d  syncApiResponse]
+000089d0: 203d 2041 7379 6e63 4170 6952 6573 706f   = AsyncApiRespo
+000089e0: 6e73 652c 0a20 2020 2020 2020 2063 6f6e  nse,.        con
+000089f0: 7465 6e74 3a20 7479 7069 6e67 2e4f 7074  tent: typing.Opt
+00008a00: 696f 6e61 6c5b 7479 7069 6e67 2e44 6963  ional[typing.Dic
+00008a10: 745b 7374 722c 204d 6564 6961 5479 7065  t[str, MediaType
+00008a20: 5d5d 203d 204e 6f6e 652c 0a20 2020 2020  ]] = None,.     
+00008a30: 2020 2068 6561 6465 7273 3a20 7479 7069     headers: typi
+00008a40: 6e67 2e4f 7074 696f 6e61 6c5b 7479 7069  ng.Optional[typi
+00008a50: 6e67 2e4c 6973 745b 4865 6164 6572 5061  ng.List[HeaderPa
+00008a60: 7261 6d65 7465 725d 5d20 3d20 4e6f 6e65  rameter]] = None
+00008a70: 2c0a 2020 2020 293a 0a20 2020 2020 2020  ,.    ):.       
+00008a80: 2073 656c 662e 6865 6164 6572 7320 3d20   self.headers = 
+00008a90: 6865 6164 6572 730a 2020 2020 2020 2020  headers.        
+00008aa0: 6966 2063 6f6e 7465 6e74 2069 7320 6e6f  if content is no
+00008ab0: 7420 4e6f 6e65 2061 6e64 206c 656e 2863  t None and len(c
+00008ac0: 6f6e 7465 6e74 2920 3d3d 2030 3a0a 2020  ontent) == 0:.  
+00008ad0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+00008ae0: 5661 6c75 6545 7272 6f72 2827 496e 7661  ValueError('Inva
+00008af0: 6c69 6420 7661 6c75 6520 666f 7220 636f  lid value for co
+00008b00: 6e74 656e 742c 2074 6865 2063 6f6e 7465  ntent, the conte
+00008b10: 6e74 2064 6963 7420 6d75 7374 2068 6176  nt dict must hav
+00008b20: 6520 3e3d 2031 2065 6e74 7279 2729 0a20  e >= 1 entry'). 
+00008b30: 2020 2020 2020 2073 656c 662e 636f 6e74         self.cont
+00008b40: 656e 7420 3d20 636f 6e74 656e 740a 2020  ent = content.  
+00008b50: 2020 2020 2020 7365 6c66 2e72 6573 706f        self.respo
+00008b60: 6e73 655f 636c 7320 3d20 7265 7370 6f6e  nse_cls = respon
+00008b70: 7365 5f63 6c73 0a20 2020 2020 2020 2073  se_cls.        s
+00008b80: 656c 662e 7265 7370 6f6e 7365 5f63 6c73  elf.response_cls
+00008b90: 5f61 7379 6e63 203d 2072 6573 706f 6e73  _async = respons
+00008ba0: 655f 636c 735f 6173 796e 630a 0a20 2020  e_cls_async..   
+00008bb0: 2040 7374 6174 6963 6d65 7468 6f64 0a20   @staticmethod. 
+00008bc0: 2020 2064 6566 205f 5f64 6573 6572 6961     def __deseria
+00008bd0: 6c69 7a65 5f6a 736f 6e28 7265 7370 6f6e  lize_json(respon
+00008be0: 7365 3a20 6279 7465 7329 202d 3e20 7479  se: bytes) -> ty
+00008bf0: 7069 6e67 2e41 6e79 3a0a 2020 2020 2020  ping.Any:.      
+00008c00: 2020 2320 7079 7468 6f6e 206d 7573 7420    # python must 
+00008c10: 6265 203e 3d20 332e 3920 736f 2077 6520  be >= 3.9 so we 
+00008c20: 6361 6e20 7061 7373 2069 6e20 6279 7465  can pass in byte
+00008c30: 7320 696e 746f 206a 736f 6e2e 6c6f 6164  s into json.load
+00008c40: 730a 2020 2020 2020 2020 7265 7475 726e  s.        return
+00008c50: 206a 736f 6e2e 6c6f 6164 7328 7265 7370   json.loads(resp
+00008c60: 6f6e 7365 290a 0a20 2020 2040 7374 6174  onse)..    @stat
+00008c70: 6963 6d65 7468 6f64 0a20 2020 2064 6566  icmethod.    def
+00008c80: 205f 5f66 696c 655f 6e61 6d65 5f66 726f   __file_name_fro
+00008c90: 6d5f 7265 7370 6f6e 7365 5f75 726c 2872  m_response_url(r
+00008ca0: 6573 706f 6e73 655f 7572 6c3a 2074 7970  esponse_url: typ
+00008cb0: 696e 672e 4f70 7469 6f6e 616c 5b73 7472  ing.Optional[str
+00008cc0: 5d29 202d 3e20 7479 7069 6e67 2e4f 7074  ]) -> typing.Opt
+00008cd0: 696f 6e61 6c5b 7374 725d 3a0a 2020 2020  ional[str]:.    
+00008ce0: 2020 2020 6966 2072 6573 706f 6e73 655f      if response_
+00008cf0: 7572 6c20 6973 204e 6f6e 653a 0a20 2020  url is None:.   
+00008d00: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00008d10: 4e6f 6e65 0a20 2020 2020 2020 2075 726c  None.        url
+00008d20: 5f70 6174 6820 3d20 7572 6c70 6172 7365  _path = urlparse
+00008d30: 2872 6573 706f 6e73 655f 7572 6c29 2e70  (response_url).p
+00008d40: 6174 680a 2020 2020 2020 2020 6966 2075  ath.        if u
+00008d50: 726c 5f70 6174 683a 0a20 2020 2020 2020  rl_path:.       
+00008d60: 2020 2020 2070 6174 685f 6261 7365 6e61       path_basena
+00008d70: 6d65 203d 206f 732e 7061 7468 2e62 6173  me = os.path.bas
+00008d80: 656e 616d 6528 7572 6c5f 7061 7468 290a  ename(url_path).
+00008d90: 2020 2020 2020 2020 2020 2020 6966 2070              if p
+00008da0: 6174 685f 6261 7365 6e61 6d65 3a0a 2020  ath_basename:.  
+00008db0: 2020 2020 2020 2020 2020 2020 2020 5f66                _f
+00008dc0: 696c 656e 616d 652c 2065 7874 203d 206f  ilename, ext = o
+00008dd0: 732e 7061 7468 2e73 706c 6974 6578 7428  s.path.splitext(
+00008de0: 7061 7468 5f62 6173 656e 616d 6529 0a20  path_basename). 
+00008df0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00008e00: 6620 6578 743a 0a20 2020 2020 2020 2020  f ext:.         
+00008e10: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+00008e20: 6e20 7061 7468 5f62 6173 656e 616d 650a  n path_basename.
+00008e30: 2020 2020 2020 2020 7265 7475 726e 204e          return N
+00008e40: 6f6e 650a 0a20 2020 2040 636c 6173 736d  one..    @classm
+00008e50: 6574 686f 640a 2020 2020 6465 6620 5f5f  ethod.    def __
+00008e60: 6669 6c65 5f6e 616d 655f 6672 6f6d 5f63  file_name_from_c
+00008e70: 6f6e 7465 6e74 5f64 6973 706f 7369 7469  ontent_dispositi
+00008e80: 6f6e 2863 6c73 2c20 636f 6e74 656e 745f  on(cls, content_
+00008e90: 6469 7370 6f73 6974 696f 6e3a 2074 7970  disposition: typ
+00008ea0: 696e 672e 4f70 7469 6f6e 616c 5b73 7472  ing.Optional[str
+00008eb0: 5d29 202d 3e20 7479 7069 6e67 2e4f 7074  ]) -> typing.Opt
+00008ec0: 696f 6e61 6c5b 7374 725d 3a0a 2020 2020  ional[str]:.    
+00008ed0: 2020 2020 6966 2063 6f6e 7465 6e74 5f64      if content_d
+00008ee0: 6973 706f 7369 7469 6f6e 2069 7320 4e6f  isposition is No
+00008ef0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+00008f00: 7265 7475 726e 204e 6f6e 650a 2020 2020  return None.    
+00008f10: 2020 2020 6d61 7463 6820 3d20 636c 732e      match = cls.
+00008f20: 5f5f 6669 6c65 6e61 6d65 5f63 6f6e 7465  __filename_conte
+00008f30: 6e74 5f64 6973 706f 7369 7469 6f6e 5f70  nt_disposition_p
+00008f40: 6174 7465 726e 2e73 6561 7263 6828 636f  attern.search(co
+00008f50: 6e74 656e 745f 6469 7370 6f73 6974 696f  ntent_dispositio
+00008f60: 6e29 0a20 2020 2020 2020 2069 6620 6e6f  n).        if no
+00008f70: 7420 6d61 7463 683a 0a20 2020 2020 2020  t match:.       
+00008f80: 2020 2020 2072 6574 7572 6e20 4e6f 6e65       return None
+00008f90: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00008fa0: 6d61 7463 682e 6772 6f75 7028 3129 0a0a  match.group(1)..
+00008fb0: 2020 2020 6465 6620 5f5f 6465 7365 7269      def __deseri
+00008fc0: 616c 697a 655f 6170 706c 6963 6174 696f  alize_applicatio
+00008fd0: 6e5f 6f63 7465 745f 7374 7265 616d 280a  n_octet_stream(.
+00008fe0: 2020 2020 2020 2020 7365 6c66 2c20 7265          self, re
+00008ff0: 7370 6f6e 7365 3a20 7572 6c6c 6962 332e  sponse: urllib3.
+00009000: 4854 5450 5265 7370 6f6e 7365 0a20 2020  HTTPResponse.   
+00009010: 2029 202d 3e20 7479 7069 6e67 2e55 6e69   ) -> typing.Uni
+00009020: 6f6e 5b62 7974 6573 2c20 696f 2e42 7566  on[bytes, io.Buf
+00009030: 6665 7265 6452 6561 6465 725d 3a0a 2020  feredReader]:.  
+00009040: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+00009050: 2020 7572 6c6c 6962 3320 7573 6520 6361    urllib3 use ca
+00009060: 7365 733a 0a20 2020 2020 2020 2031 2e20  ses:.        1. 
+00009070: 7768 656e 2070 7265 6c6f 6164 5f63 6f6e  when preload_con
+00009080: 7465 6e74 3d54 7275 6520 2873 7472 6561  tent=True (strea
+00009090: 6d3d 4661 6c73 6529 2074 6865 6e20 7375  m=False) then su
+000090a0: 7070 6f72 7473 5f63 6875 6e6b 6564 5f72  pports_chunked_r
+000090b0: 6561 6473 2069 7320 4661 6c73 6520 616e  eads is False an
+000090c0: 6420 6279 7465 7320 6172 6520 7265 7475  d bytes are retu
+000090d0: 726e 6564 0a20 2020 2020 2020 2032 2e20  rned.        2. 
+000090e0: 7768 656e 2070 7265 6c6f 6164 5f63 6f6e  when preload_con
+000090f0: 7465 6e74 3d46 616c 7365 2028 7374 7265  tent=False (stre
+00009100: 616d 3d54 7275 6529 2074 6865 6e20 7375  am=True) then su
+00009110: 7070 6f72 7473 5f63 6875 6e6b 6564 5f72  pports_chunked_r
+00009120: 6561 6473 2069 7320 5472 7565 2061 6e64  eads is True and
+00009130: 0a20 2020 2020 2020 2020 2020 2061 2066  .            a f
+00009140: 696c 6520 7769 6c6c 2062 6520 7772 6974  ile will be writ
+00009150: 7465 6e20 616e 6420 7265 7475 726e 6564  ten and returned
+00009160: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+00009170: 2020 2020 2069 6620 7265 7370 6f6e 7365       if response
+00009180: 2e73 7570 706f 7274 735f 6368 756e 6b65  .supports_chunke
+00009190: 645f 7265 6164 7328 293a 0a20 2020 2020  d_reads():.     
+000091a0: 2020 2020 2020 2066 696c 655f 6e61 6d65         file_name
+000091b0: 203d 2028 0a20 2020 2020 2020 2020 2020   = (.           
+000091c0: 2020 2020 2073 656c 662e 5f5f 6669 6c65       self.__file
+000091d0: 5f6e 616d 655f 6672 6f6d 5f63 6f6e 7465  _name_from_conte
+000091e0: 6e74 5f64 6973 706f 7369 7469 6f6e 2872  nt_disposition(r
+000091f0: 6573 706f 6e73 652e 6865 6164 6572 732e  esponse.headers.
+00009200: 6765 7428 2763 6f6e 7465 6e74 2d64 6973  get('content-dis
+00009210: 706f 7369 7469 6f6e 2729 290a 2020 2020  position')).    
+00009220: 2020 2020 2020 2020 2020 2020 6f72 2073              or s
+00009230: 656c 662e 5f5f 6669 6c65 5f6e 616d 655f  elf.__file_name_
+00009240: 6672 6f6d 5f72 6573 706f 6e73 655f 7572  from_response_ur
+00009250: 6c28 7265 7370 6f6e 7365 2e67 6574 7572  l(response.getur
+00009260: 6c28 2929 0a20 2020 2020 2020 2020 2020  l()).           
+00009270: 2029 0a0a 2020 2020 2020 2020 2020 2020   )..            
+00009280: 6966 2066 696c 655f 6e61 6d65 2069 7320  if file_name is 
+00009290: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+000092a0: 2020 2020 2020 5f66 642c 2070 6174 6820        _fd, path 
+000092b0: 3d20 7465 6d70 6669 6c65 2e6d 6b73 7465  = tempfile.mkste
+000092c0: 6d70 2829 0a20 2020 2020 2020 2020 2020  mp().           
+000092d0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+000092e0: 2020 2020 2020 2070 6174 6820 3d20 6f73         path = os
+000092f0: 2e70 6174 682e 6a6f 696e 2874 656d 7066  .path.join(tempf
+00009300: 696c 652e 6765 7474 656d 7064 6972 2829  ile.gettempdir()
+00009310: 2c20 6669 6c65 5f6e 616d 6529 0a0a 2020  , file_name)..  
+00009320: 2020 2020 2020 2020 2020 7769 7468 206f            with o
+00009330: 7065 6e28 7061 7468 2c20 2777 6227 2920  pen(path, 'wb') 
+00009340: 6173 206e 6577 5f66 696c 653a 0a20 2020  as new_file:.   
+00009350: 2020 2020 2020 2020 2020 2020 2063 6875               chu
+00009360: 6e6b 5f73 697a 6520 3d20 3130 3234 0a20  nk_size = 1024. 
+00009370: 2020 2020 2020 2020 2020 2020 2020 2077                 w
+00009380: 6869 6c65 2054 7275 653a 0a20 2020 2020  hile True:.     
+00009390: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+000093a0: 6174 6120 3d20 7265 7370 6f6e 7365 2e72  ata = response.r
+000093b0: 6561 6428 6368 756e 6b5f 7369 7a65 290a  ead(chunk_size).
+000093c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000093d0: 2020 2020 6966 206e 6f74 2064 6174 613a      if not data:
+000093e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000093f0: 2020 2020 2020 2020 2062 7265 616b 0a20           break. 
+00009400: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009410: 2020 206e 6577 5f66 696c 652e 7772 6974     new_file.writ
+00009420: 6528 6461 7461 290a 2020 2020 2020 2020  e(data).        
+00009430: 2020 2020 2320 7265 6c65 6173 655f 636f      # release_co
+00009440: 6e6e 2069 7320 6e65 6564 6564 2066 6f72  nn is needed for
+00009450: 2073 7472 6561 6d69 6e67 2063 6f6e 6e65   streaming conne
+00009460: 6374 696f 6e73 206f 6e6c 790a 2020 2020  ctions only.    
+00009470: 2020 2020 2020 2020 7265 7370 6f6e 7365          response
+00009480: 2e72 656c 6561 7365 5f63 6f6e 6e28 290a  .release_conn().
+00009490: 2020 2020 2020 2020 2020 2020 6e65 775f              new_
+000094a0: 6669 6c65 203d 206f 7065 6e28 7061 7468  file = open(path
+000094b0: 2c20 2772 6227 290a 2020 2020 2020 2020  , 'rb').        
+000094c0: 2020 2020 7265 7475 726e 206e 6577 5f66      return new_f
+000094d0: 696c 650a 2020 2020 2020 2020 656c 7365  ile.        else
+000094e0: 3a0a 2020 2020 2020 2020 2020 2020 7265  :.            re
+000094f0: 7475 726e 2072 6573 706f 6e73 652e 6461  turn response.da
+00009500: 7461 0a0a 2020 2020 4073 7461 7469 636d  ta..    @staticm
+00009510: 6574 686f 640a 2020 2020 6465 6620 5f5f  ethod.    def __
+00009520: 6465 7365 7269 616c 697a 655f 6d75 6c74  deserialize_mult
+00009530: 6970 6172 745f 666f 726d 5f64 6174 6128  ipart_form_data(
+00009540: 0a20 2020 2020 2020 2072 6573 706f 6e73  .        respons
+00009550: 653a 2062 7974 6573 0a20 2020 2029 202d  e: bytes.    ) -
+00009560: 3e20 7479 7069 6e67 2e44 6963 745b 7374  > typing.Dict[st
+00009570: 722c 2074 7970 696e 672e 416e 795d 3a0a  r, typing.Any]:.
+00009580: 2020 2020 2020 2020 6d73 6720 3d20 656d          msg = em
+00009590: 6169 6c2e 6d65 7373 6167 655f 6672 6f6d  ail.message_from
+000095a0: 5f62 7974 6573 2872 6573 706f 6e73 6529  _bytes(response)
+000095b0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+000095c0: 7b0a 2020 2020 2020 2020 2020 2020 7061  {.            pa
+000095d0: 7274 2e67 6574 5f70 6172 616d 2822 6e61  rt.get_param("na
+000095e0: 6d65 222c 2068 6561 6465 723d 2243 6f6e  me", header="Con
+000095f0: 7465 6e74 2d44 6973 706f 7369 7469 6f6e  tent-Disposition
+00009600: 2229 3a20 7061 7274 2e67 6574 5f70 6179  "): part.get_pay
+00009610: 6c6f 6164 280a 2020 2020 2020 2020 2020  load(.          
+00009620: 2020 2020 2020 6465 636f 6465 3d54 7275        decode=Tru
+00009630: 650a 2020 2020 2020 2020 2020 2020 292e  e.            ).
+00009640: 6465 636f 6465 2870 6172 742e 6765 745f  decode(part.get_
+00009650: 636f 6e74 656e 745f 6368 6172 7365 7428  content_charset(
+00009660: 2929 0a20 2020 2020 2020 2020 2020 2069  )).            i
+00009670: 6620 7061 7274 2e67 6574 5f63 6f6e 7465  f part.get_conte
+00009680: 6e74 5f63 6861 7273 6574 2829 0a20 2020  nt_charset().   
+00009690: 2020 2020 2020 2020 2065 6c73 6520 7061           else pa
+000096a0: 7274 2e67 6574 5f70 6179 6c6f 6164 2829  rt.get_payload()
+000096b0: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
+000096c0: 2070 6172 7420 696e 206d 7367 2e67 6574   part in msg.get
+000096d0: 5f70 6179 6c6f 6164 2829 0a20 2020 2020  _payload().     
+000096e0: 2020 207d 0a0a 2020 2020 6465 6620 5f5f     }..    def __
+000096f0: 6765 745f 7363 6865 6d61 5f66 6f72 5f63  get_schema_for_c
+00009700: 6f6e 7465 6e74 5f74 7970 6528 0a20 2020  ontent_type(.   
+00009710: 2020 2020 2073 656c 662c 0a20 2020 2020       self,.     
+00009720: 2020 2063 6f6e 7465 6e74 5f74 7970 650a     content_type.
+00009730: 2020 2020 2920 2d3e 2074 7970 696e 672e      ) -> typing.
+00009740: 4f70 7469 6f6e 616c 5b74 7970 696e 672e  Optional[typing.
+00009750: 5479 7065 5b53 6368 656d 615d 5d3a 0a20  Type[Schema]]:. 
+00009760: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+00009770: 2020 2046 696e 6473 2074 6865 2063 6f72     Finds the cor
+00009780: 7265 6374 2053 6368 656d 614f 626a 6563  rect SchemaObjec
+00009790: 7420 666f 7220 6120 7061 7274 6963 756c  t for a particul
+000097a0: 6172 2063 6f6e 7465 6e74 2074 7970 652e  ar content type.
+000097b0: 2048 616e 646c 6573 0a20 2020 2020 2020   Handles.       
+000097c0: 2074 6865 2061 7374 6572 6973 6b20 222a   the asterisk "*
+000097d0: 2220 6368 6172 6163 7465 7220 7468 6174  " character that
+000097e0: 2069 7320 7573 6564 2074 6f20 6772 6f75   is used to grou
+000097f0: 7020 6d65 6469 6120 7479 7065 7320 696e  p media types in
+00009800: 746f 2072 616e 6765 730a 2020 2020 2020  to ranges.      
+00009810: 2020 2868 7474 7073 3a2f 2f77 7777 2e72    (https://www.r
+00009820: 6663 2d65 6469 746f 722e 6f72 672f 7266  fc-editor.org/rf
+00009830: 632f 7266 6337 3233 3123 7365 6374 696f  c/rfc7231#sectio
+00009840: 6e2d 352e 332e 3229 2e20 416c 736f 2068  n-5.3.2). Also h
+00009850: 616e 646c 6573 0a20 2020 2020 2020 2070  andles.        p
+00009860: 6172 616d 6574 6572 7320 696e 2074 6865  arameters in the
+00009870: 2066 6f72 6d20 6f66 206e 616d 653d 7661   form of name=va
+00009880: 6c75 6520 7061 6972 732e 0a20 2020 2020  lue pairs..     
+00009890: 2020 2022 2222 0a20 2020 2020 2020 206d     """.        m
+000098a0: 6564 6961 5f74 7970 6573 203d 2073 656c  edia_types = sel
+000098b0: 662e 636f 6e74 656e 742e 6b65 7973 2829  f.content.keys()
+000098c0: 0a20 2020 2020 2020 206d 6174 6368 6564  .        matched
+000098d0: 5f6d 6564 6961 5f74 7970 6520 3d20 4f70  _media_type = Op
+000098e0: 656e 4170 6952 6573 706f 6e73 652e 6d61  enApiResponse.ma
+000098f0: 7463 685f 636f 6e74 656e 745f 7479 7065  tch_content_type
+00009900: 280a 2020 2020 2020 2020 2020 2020 636f  (.            co
+00009910: 6e74 656e 745f 7479 7065 3d63 6f6e 7465  ntent_type=conte
+00009920: 6e74 5f74 7970 652c 0a20 2020 2020 2020  nt_type,.       
+00009930: 2020 2020 206d 6564 6961 5f74 7970 6573       media_types
+00009940: 3d6d 6564 6961 5f74 7970 6573 0a20 2020  =media_types.   
+00009950: 2020 2020 2029 0a20 2020 2020 2020 2069       ).        i
+00009960: 6620 6d61 7463 6865 645f 6d65 6469 615f  f matched_media_
+00009970: 7479 7065 2069 7320 4e6f 6e65 3a0a 2020  type is None:.  
+00009980: 2020 2020 2020 2020 2020 7265 7475 726e            return
+00009990: 204e 6f6e 650a 2020 2020 2020 2020 7265   None.        re
+000099a0: 7475 726e 2073 656c 662e 636f 6e74 656e  turn self.conten
+000099b0: 745b 6d61 7463 6865 645f 6d65 6469 615f  t[matched_media_
+000099c0: 7479 7065 5d2e 7363 6865 6d61 0a0a 2020  type].schema..  
+000099d0: 2020 4073 7461 7469 636d 6574 686f 640a    @staticmethod.
+000099e0: 2020 2020 6465 6620 6d61 7463 685f 636f      def match_co
+000099f0: 6e74 656e 745f 7479 7065 2863 6f6e 7465  ntent_type(conte
+00009a00: 6e74 5f74 7970 653a 2073 7472 2c20 6d65  nt_type: str, me
+00009a10: 6469 615f 7479 7065 733a 2074 7970 696e  dia_types: typin
+00009a20: 672e 4c69 7374 5b73 7472 5d29 202d 3e20  g.List[str]) -> 
+00009a30: 7479 7069 6e67 2e4f 7074 696f 6e61 6c5b  typing.Optional[
+00009a40: 7374 725d 3a0a 2020 2020 2020 2020 2222  str]:.        ""
+00009a50: 220a 2020 2020 2020 2020 4d61 7463 6865  ".        Matche
+00009a60: 7320 6120 636f 6e74 656e 7420 7479 7065  s a content type
+00009a70: 2074 6f20 6120 6d65 6469 6120 7479 7065   to a media type
+00009a80: 2069 6e20 6120 6c69 7374 206f 6620 6d65   in a list of me
+00009a90: 6469 6120 7479 7065 732c 2068 616e 646c  dia types, handl
+00009aa0: 696e 6720 6d65 6469 6120 7479 7065 2072  ing media type r
+00009ab0: 616e 6765 7320 6173 2064 6566 696e 6564  anges as defined
+00009ac0: 2069 6e20 5246 4337 3233 312e 0a0a 2020   in RFC7231...  
+00009ad0: 2020 2020 2020 5061 7261 6d65 7465 7273        Parameters
+00009ae0: 3a0a 2020 2020 2020 2020 636f 6e74 656e  :.        conten
+00009af0: 745f 7479 7065 2028 7374 7229 3a20 5468  t_type (str): Th
+00009b00: 6520 636f 6e74 656e 7420 7479 7065 2074  e content type t
+00009b10: 6f20 6d61 7463 682e 0a20 2020 2020 2020  o match..       
+00009b20: 206d 6564 6961 5f74 7970 6573 2028 6c69   media_types (li
+00009b30: 7374 293a 2054 6865 206c 6973 7420 6f66  st): The list of
+00009b40: 206d 6564 6961 2074 7970 6573 2074 6f20   media types to 
+00009b50: 7365 6172 6368 2e0a 0a20 2020 2020 2020  search...       
+00009b60: 2052 6574 7572 6e73 3a0a 2020 2020 2020   Returns:.      
+00009b70: 2020 7374 723a 2054 6865 2066 6972 7374    str: The first
+00009b80: 206d 6564 6961 2074 7970 6520 7468 6174   media type that
+00009b90: 206d 6174 6368 6573 2074 6865 2063 6f6e   matches the con
+00009ba0: 7465 6e74 2074 7970 652c 206f 7220 4e6f  tent type, or No
+00009bb0: 6e65 2069 6620 6e6f 206d 6174 6368 2069  ne if no match i
+00009bc0: 7320 666f 756e 642e 0a20 2020 2020 2020  s found..       
+00009bd0: 2022 2222 0a20 2020 2020 2020 2066 6f72   """.        for
+00009be0: 206d 6564 6961 5f74 7970 6520 696e 206d   media_type in m
+00009bf0: 6564 6961 5f74 7970 6573 3a0a 2020 2020  edia_types:.    
+00009c00: 2020 2020 2020 2020 6966 206d 6564 6961          if media
+00009c10: 5f74 7970 6520 3d3d 2027 2a2f 2a27 206f  _type == '*/*' o
+00009c20: 7220 6d65 6469 615f 7479 7065 203d 3d20  r media_type == 
+00009c30: 636f 6e74 656e 745f 7479 7065 3a0a 2020  content_type:.  
+00009c40: 2020 2020 2020 2020 2020 2020 2020 7265                re
+00009c50: 7475 726e 206d 6564 6961 5f74 7970 650a  turn media_type.
+00009c60: 2020 2020 2020 2020 2020 2020 656c 6966              elif
+00009c70: 2027 2f27 2069 6e20 6d65 6469 615f 7479   '/' in media_ty
+00009c80: 7065 3a0a 2020 2020 2020 2020 2020 2020  pe:.            
+00009c90: 2020 2020 7479 7065 5f2c 2073 7562 7479      type_, subty
+00009ca0: 7065 203d 206d 6564 6961 5f74 7970 652e  pe = media_type.
+00009cb0: 7370 6c69 7428 272f 2729 0a20 2020 2020  split('/').     
+00009cc0: 2020 2020 2020 2020 2020 2069 6620 2874             if (t
+00009cd0: 7970 655f 203d 3d20 272a 2720 6f72 2074  ype_ == '*' or t
+00009ce0: 7970 655f 203d 3d20 636f 6e74 656e 745f  ype_ == content_
+00009cf0: 7479 7065 2e73 706c 6974 2827 2f27 295b  type.split('/')[
+00009d00: 305d 2920 616e 6420 5c0a 2020 2020 2020  0]) and \.      
+00009d10: 2020 2020 2020 2020 2020 2873 7562 7479            (subty
+00009d20: 7065 203d 3d20 272a 2720 6f72 2073 7562  pe == '*' or sub
+00009d30: 7479 7065 203d 3d20 636f 6e74 656e 745f  type == content_
+00009d40: 7479 7065 2e73 706c 6974 2827 2f27 295b  type.split('/')[
+00009d50: 315d 2e73 706c 6974 2827 3b27 295b 305d  1].split(';')[0]
+00009d60: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
+00009d70: 2020 2020 2020 2072 6574 7572 6e20 6d65         return me
+00009d80: 6469 615f 7479 7065 0a0a 2020 2020 2020  dia_type..      
+00009d90: 2020 7265 7475 726e 204e 6f6e 650a 0a20    return None.. 
+00009da0: 2020 2061 7379 6e63 2064 6566 2064 6573     async def des
+00009db0: 6572 6961 6c69 7a65 5f61 7379 6e63 2873  erialize_async(s
+00009dc0: 656c 662c 2072 6573 706f 6e73 653a 2041  elf, response: A
+00009dd0: 7379 6e63 5265 7370 6f6e 7365 5772 6170  syncResponseWrap
+00009de0: 7065 722c 2063 6f6e 6669 6775 7261 7469  per, configurati
+00009df0: 6f6e 3a20 436f 6e66 6967 7572 6174 696f  on: Configuratio
+00009e00: 6e2c 2073 6b69 705f 6465 7365 7269 616c  n, skip_deserial
+00009e10: 697a 6174 696f 6e20 3d20 4661 6c73 6529  ization = False)
+00009e20: 202d 3e20 4173 796e 6341 7069 5265 7370   -> AsyncApiResp
+00009e30: 6f6e 7365 3a0a 2020 2020 2020 2020 2222  onse:.        ""
+00009e40: 220a 2020 2020 2020 2020 4465 7365 7269  ".        Deseri
+00009e50: 616c 697a 6573 2061 6e20 4854 5450 2072  alizes an HTTP r
+00009e60: 6573 706f 6e73 6520 626f 6479 2069 6e74  esponse body int
+00009e70: 6f20 616e 206f 626a 6563 742e 0a20 2020  o an object..   
+00009e80: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
+00009e90: 2063 6f6e 7465 6e74 5f74 7970 6520 3d20   content_type = 
+00009ea0: 7265 7370 6f6e 7365 2e68 7474 705f 7265  response.http_re
+00009eb0: 7370 6f6e 7365 2e63 6f6e 7465 6e74 5f74  sponse.content_t
+00009ec0: 7970 650a 2020 2020 2020 2020 6465 7365  ype.        dese
+00009ed0: 7269 616c 697a 6564 5f62 6f64 7920 3d20  rialized_body = 
+00009ee0: 756e 7365 740a 2020 2020 2020 2020 6966  unset.        if
+00009ef0: 2073 656c 662e 636f 6e74 656e 7420 6973   self.content is
+00009f00: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
+00009f10: 2020 2020 2020 2069 6620 6c65 6e28 7365         if len(se
+00009f20: 6c66 2e63 6f6e 7465 6e74 2920 3d3d 2030  lf.content) == 0
+00009f30: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00009f40: 2020 2320 736f 6d65 2073 7065 6373 2064    # some specs d
+00009f50: 6f20 6e6f 7420 6465 6669 6e65 2072 6573  o not define res
+00009f60: 706f 6e73 6520 636f 6e74 656e 7420 6d65  ponse content me
+00009f70: 6469 6120 7479 7065 2073 6368 656d 6173  dia type schemas
+00009f80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00009f90: 2072 6574 7572 6e20 7365 6c66 2e72 6573   return self.res
+00009fa0: 706f 6e73 655f 636c 735f 6173 796e 6328  ponse_cls_async(
+00009fb0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00009fc0: 2020 2020 2072 6f75 6e64 5f74 7269 705f       round_trip_
+00009fd0: 7469 6d65 3d72 6573 706f 6e73 652e 726f  time=response.ro
+00009fe0: 756e 645f 7472 6970 5f74 696d 652c 0a20  und_trip_time,. 
+00009ff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a000: 2020 2072 6573 706f 6e73 653d 7265 7370     response=resp
+0000a010: 6f6e 7365 2e68 7474 705f 7265 7370 6f6e  onse.http_respon
+0000a020: 7365 2c0a 2020 2020 2020 2020 2020 2020  se,.            
+0000a030: 2020 2020 2020 2020 626f 6479 3d75 6e73          body=uns
+0000a040: 6574 2c0a 2020 2020 2020 2020 2020 2020  et,.            
+0000a050: 2020 2020 2020 2020 6865 6164 6572 733d          headers=
+0000a060: 7265 7370 6f6e 7365 2e68 7474 705f 7265  response.http_re
+0000a070: 7370 6f6e 7365 2e68 6561 6465 7273 2c0a  sponse.headers,.
+0000a080: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a090: 2020 2020 7374 6174 7573 3d72 6573 706f      status=respo
+0000a0a0: 6e73 652e 6874 7470 5f72 6573 706f 6e73  nse.http_respons
+0000a0b0: 652e 7374 6174 7573 0a20 2020 2020 2020  e.status.       
+0000a0c0: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
+0000a0d0: 2020 2020 2020 2062 6f64 795f 7363 6865         body_sche
+0000a0e0: 6d61 203d 2073 656c 662e 5f5f 6765 745f  ma = self.__get_
+0000a0f0: 7363 6865 6d61 5f66 6f72 5f63 6f6e 7465  schema_for_conte
+0000a100: 6e74 5f74 7970 6528 636f 6e74 656e 745f  nt_type(content_
+0000a110: 7479 7065 290a 2020 2020 2020 2020 2020  type).          
+0000a120: 2020 6966 2062 6f64 795f 7363 6865 6d61    if body_schema
+0000a130: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+0000a140: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+0000a150: 4170 6956 616c 7565 4572 726f 7228 0a20  ApiValueError(. 
+0000a160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a170: 2020 2066 2249 6e76 616c 6964 2063 6f6e     f"Invalid con
+0000a180: 7465 6e74 5f74 7970 6520 7265 7475 726e  tent_type return
+0000a190: 6564 2e20 436f 6e74 656e 745f 7479 7065  ed. Content_type
+0000a1a0: 3d27 7b63 6f6e 7465 6e74 5f74 7970 657d  ='{content_type}
+0000a1b0: 2720 7761 7320 7265 7475 726e 6564 2022  ' was returned "
+0000a1c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000a1d0: 2020 2020 2066 2277 6865 6e20 6f6e 6c79       f"when only
+0000a1e0: 207b 7374 7228 7365 7428 7365 6c66 2e63   {str(set(self.c
+0000a1f0: 6f6e 7465 6e74 2929 7d20 6172 6520 6465  ontent))} are de
+0000a200: 6669 6e65 6420 666f 7220 7374 6174 7573  fined for status
+0000a210: 5f63 6f64 653d 7b73 7472 2872 6573 706f  _code={str(respo
+0000a220: 6e73 652e 6874 7470 5f72 6573 706f 6e73  nse.http_respons
+0000a230: 652e 7374 6174 7573 297d 220a 2020 2020  e.status)}".    
+0000a240: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+0000a250: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
+0000a260: 662e 5f63 6f6e 7465 6e74 5f74 7970 655f  f._content_type_
+0000a270: 6973 5f6a 736f 6e28 636f 6e74 656e 745f  is_json(content_
+0000a280: 7479 7065 293a 0a20 2020 2020 2020 2020  type):.         
+0000a290: 2020 2020 2020 2062 6f64 795f 6461 7461         body_data
+0000a2a0: 203d 2073 656c 662e 5f5f 6465 7365 7269   = self.__deseri
+0000a2b0: 616c 697a 655f 6a73 6f6e 2861 7761 6974  alize_json(await
+0000a2c0: 2072 6573 706f 6e73 652e 6874 7470 5f72   response.http_r
+0000a2d0: 6573 706f 6e73 652e 7265 6164 2829 290a  esponse.read()).
+0000a2e0: 2020 2020 2020 2020 2020 2020 656c 6966              elif
+0000a2f0: 2063 6f6e 7465 6e74 5f74 7970 652e 7374   content_type.st
+0000a300: 6172 7473 7769 7468 2827 6d75 6c74 6970  artswith('multip
+0000a310: 6172 742f 666f 726d 2d64 6174 6127 293a  art/form-data'):
+0000a320: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000a330: 2062 6f64 795f 6461 7461 203d 2073 656c   body_data = sel
+0000a340: 662e 5f5f 6465 7365 7269 616c 697a 655f  f.__deserialize_
+0000a350: 6d75 6c74 6970 6172 745f 666f 726d 5f64  multipart_form_d
+0000a360: 6174 6128 6177 6169 7420 7265 7370 6f6e  ata(await respon
+0000a370: 7365 2e68 7474 705f 7265 7370 6f6e 7365  se.http_response
+0000a380: 2e72 6561 6428 2929 0a20 2020 2020 2020  .read()).       
+0000a390: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+0000a3a0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+0000a3b0: 204e 6f74 496d 706c 656d 656e 7465 6445   NotImplementedE
+0000a3c0: 7272 6f72 2827 4465 7365 7269 616c 697a  rror('Deserializ
+0000a3d0: 6174 696f 6e20 6f66 207b 7d20 6861 7320  ation of {} has 
+0000a3e0: 6e6f 7420 7965 7420 6265 656e 2069 6d70  not yet been imp
+0000a3f0: 6c65 6d65 6e74 6564 272e 666f 726d 6174  lemented'.format
+0000a400: 2863 6f6e 7465 6e74 5f74 7970 6529 290a  (content_type)).
+0000a410: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+0000a420: 6b69 705f 6465 7365 7269 616c 697a 6174  kip_deserializat
+0000a430: 696f 6e3a 0a20 2020 2020 2020 2020 2020  ion:.           
+0000a440: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
+0000a450: 2e72 6573 706f 6e73 655f 636c 735f 6173  .response_cls_as
+0000a460: 796e 6328 0a20 2020 2020 2020 2020 2020  ync(.           
+0000a470: 2020 2020 2020 2020 2072 6f75 6e64 5f74           round_t
+0000a480: 7269 705f 7469 6d65 3d72 6573 706f 6e73  rip_time=respons
+0000a490: 652e 726f 756e 645f 7472 6970 5f74 696d  e.round_trip_tim
+0000a4a0: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
+0000a4b0: 2020 2020 2020 2072 6573 706f 6e73 653d         response=
+0000a4c0: 7265 7370 6f6e 7365 2e68 7474 705f 7265  response.http_re
+0000a4d0: 7370 6f6e 7365 2c0a 2020 2020 2020 2020  sponse,.        
+0000a4e0: 2020 2020 2020 2020 2020 2020 626f 6479              body
+0000a4f0: 3d62 6f64 795f 6461 7461 2c0a 2020 2020  =body_data,.    
+0000a500: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a510: 6865 6164 6572 733d 7265 7370 6f6e 7365  headers=response
+0000a520: 2e68 7474 705f 7265 7370 6f6e 7365 2e68  .http_response.h
+0000a530: 6561 6465 7273 2c0a 2020 2020 2020 2020  eaders,.        
+0000a540: 2020 2020 2020 2020 2020 2020 7374 6174              stat
+0000a550: 7573 3d72 6573 706f 6e73 652e 6874 7470  us=response.http
+0000a560: 5f72 6573 706f 6e73 652e 7374 6174 7573  _response.status
+0000a570: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000a580: 2029 0a20 2020 2020 2020 2020 2020 2023   ).            #
+0000a590: 2045 7865 6375 7465 2076 616c 6964 6174   Execute validat
+0000a5a0: 696f 6e20 616e 6420 7468 726f 7720 6173  ion and throw as
+0000a5b0: 2061 2073 6964 6520 6566 6665 6374 2069   a side effect i
+0000a5c0: 6620 7661 6c69 6461 7469 6f6e 2066 6169  f validation fai
+0000a5d0: 6c73 0a20 2020 2020 2020 2020 2020 2062  ls.            b
+0000a5e0: 6f64 795f 7363 6865 6d61 2e66 726f 6d5f  ody_schema.from_
+0000a5f0: 6f70 656e 6170 695f 6461 7461 5f6f 6170  openapi_data_oap
+0000a600: 6728 0a20 2020 2020 2020 2020 2020 2020  g(.             
+0000a610: 2020 2062 6f64 795f 6461 7461 2c0a 2020     body_data,.  
+0000a620: 2020 2020 2020 2020 2020 2020 2020 5f63                _c
+0000a630: 6f6e 6669 6775 7261 7469 6f6e 3d63 6f6e  onfiguration=con
+0000a640: 6669 6775 7261 7469 6f6e 0a20 2020 2020  figuration.     
+0000a650: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+0000a660: 2020 2020 2023 2056 616c 6964 6174 696f       # Validatio
+0000a670: 6e20 7061 7373 6564 2c20 7365 7420 6465  n passed, set de
+0000a680: 7365 7269 616c 697a 6564 5f62 6f64 7920  serialized_body 
+0000a690: 746f 2070 6c61 696e 206f 6c64 2064 6573  to plain old des
+0000a6a0: 6572 6961 6c69 7a65 6420 6461 7461 0a20  erialized data. 
+0000a6b0: 2020 2020 2020 2020 2020 2064 6573 6572             deser
+0000a6c0: 6961 6c69 7a65 645f 626f 6479 203d 2062  ialized_body = b
+0000a6d0: 6f64 795f 6461 7461 0a0a 2020 2020 2020  ody_data..      
+0000a6e0: 2020 7265 7475 726e 2073 656c 662e 7265    return self.re
+0000a6f0: 7370 6f6e 7365 5f63 6c73 5f61 7379 6e63  sponse_cls_async
+0000a700: 280a 2020 2020 2020 2020 2020 2020 726f  (.            ro
+0000a710: 756e 645f 7472 6970 5f74 696d 653d 7265  und_trip_time=re
+0000a720: 7370 6f6e 7365 2e72 6f75 6e64 5f74 7269  sponse.round_tri
+0000a730: 705f 7469 6d65 2c0a 2020 2020 2020 2020  p_time,.        
+0000a740: 2020 2020 7265 7370 6f6e 7365 3d72 6573      response=res
+0000a750: 706f 6e73 652e 6874 7470 5f72 6573 706f  ponse.http_respo
+0000a760: 6e73 652c 0a20 2020 2020 2020 2020 2020  nse,.           
+0000a770: 2062 6f64 793d 6465 7365 7269 616c 697a   body=deserializ
+0000a780: 6564 5f62 6f64 792c 0a20 2020 2020 2020  ed_body,.       
+0000a790: 2020 2020 2068 6561 6465 7273 3d72 6573       headers=res
+0000a7a0: 706f 6e73 652e 6874 7470 5f72 6573 706f  ponse.http_respo
+0000a7b0: 6e73 652e 6865 6164 6572 732c 0a20 2020  nse.headers,.   
+0000a7c0: 2020 2020 2020 2020 2073 7461 7475 733d           status=
+0000a7d0: 7265 7370 6f6e 7365 2e68 7474 705f 7265  response.http_re
+0000a7e0: 7370 6f6e 7365 2e73 7461 7475 730a 2020  sponse.status.  
+0000a7f0: 2020 2020 2020 290a 0a20 2020 2064 6566        )..    def
+0000a800: 2064 6573 6572 6961 6c69 7a65 5f62 6f64   deserialize_bod
+0000a810: 7928 7365 6c66 2c20 7265 7370 6f6e 7365  y(self, response
+0000a820: 3a20 5265 7370 6f6e 7365 5772 6170 7065  : ResponseWrappe
+0000a830: 722c 2063 6f6e 7465 6e74 5f74 7970 653a  r, content_type:
+0000a840: 2073 7472 2920 2d3e 2028 616e 792c 2073   str) -> (any, s
+0000a850: 7472 293a 0a20 2020 2020 2020 2069 6620  tr):.        if 
+0000a860: 7365 6c66 2e5f 636f 6e74 656e 745f 7479  self._content_ty
+0000a870: 7065 5f69 735f 6a73 6f6e 2863 6f6e 7465  pe_is_json(conte
+0000a880: 6e74 5f74 7970 6529 3a0a 2020 2020 2020  nt_type):.      
+0000a890: 2020 2020 2020 6465 7365 7269 616c 697a        deserializ
+0000a8a0: 6564 5f62 6f64 7920 3d20 7365 6c66 2e5f  ed_body = self._
+0000a8b0: 5f64 6573 6572 6961 6c69 7a65 5f6a 736f  _deserialize_jso
+0000a8c0: 6e28 7265 7370 6f6e 7365 2e68 7474 705f  n(response.http_
+0000a8d0: 7265 7370 6f6e 7365 2e64 6174 6129 0a20  response.data). 
+0000a8e0: 2020 2020 2020 2065 6c69 6620 636f 6e74         elif cont
+0000a8f0: 656e 745f 7479 7065 203d 3d20 2761 7070  ent_type == 'app
+0000a900: 6c69 6361 7469 6f6e 2f6f 6374 6574 2d73  lication/octet-s
+0000a910: 7472 6561 6d27 3a0a 2020 2020 2020 2020  tream':.        
+0000a920: 2020 2020 6465 7365 7269 616c 697a 6564      deserialized
+0000a930: 5f62 6f64 7920 3d20 7365 6c66 2e5f 5f64  _body = self.__d
+0000a940: 6573 6572 6961 6c69 7a65 5f61 7070 6c69  eserialize_appli
+0000a950: 6361 7469 6f6e 5f6f 6374 6574 5f73 7472  cation_octet_str
+0000a960: 6561 6d28 7265 7370 6f6e 7365 2e68 7474  eam(response.htt
+0000a970: 705f 7265 7370 6f6e 7365 290a 2020 2020  p_response).    
+0000a980: 2020 2020 656c 6966 2063 6f6e 7465 6e74      elif content
+0000a990: 5f74 7970 652e 7374 6172 7473 7769 7468  _type.startswith
+0000a9a0: 2827 6d75 6c74 6970 6172 742f 666f 726d  ('multipart/form
+0000a9b0: 2d64 6174 6127 293a 0a20 2020 2020 2020  -data'):.       
+0000a9c0: 2020 2020 2064 6573 6572 6961 6c69 7a65       deserialize
+0000a9d0: 645f 626f 6479 203d 2073 656c 662e 5f5f  d_body = self.__
+0000a9e0: 6465 7365 7269 616c 697a 655f 6d75 6c74  deserialize_mult
+0000a9f0: 6970 6172 745f 666f 726d 5f64 6174 6128  ipart_form_data(
+0000aa00: 7265 7370 6f6e 7365 2e68 7474 705f 7265  response.http_re
+0000aa10: 7370 6f6e 7365 2e64 6174 6129 0a20 2020  sponse.data).   
+0000aa20: 2020 2020 2020 2020 2063 6f6e 7465 6e74           content
+0000aa30: 5f74 7970 6520 3d20 276d 756c 7469 7061  _type = 'multipa
+0000aa40: 7274 2f66 6f72 6d2d 6461 7461 270a 2020  rt/form-data'.  
+0000aa50: 2020 2020 2020 656c 7365 3a20 2320 4966        else: # If
+0000aa60: 2077 6520 646f 6e27 7420 6b6e 6f77 2068   we don't know h
+0000aa70: 6f77 2074 6f20 6465 7365 7269 616c 697a  ow to deserializ
+0000aa80: 652c 2075 7365 2072 6177 2062 6f64 7920  e, use raw body 
+0000aa90: 7374 7269 6e67 0a20 2020 2020 2020 2020  string.         
+0000aaa0: 2020 2064 6573 6572 6961 6c69 7a65 645f     deserialized_
+0000aab0: 626f 6479 203d 2072 6573 706f 6e73 652e  body = response.
+0000aac0: 6874 7470 5f72 6573 706f 6e73 652e 6461  http_response.da
+0000aad0: 7461 2e64 6563 6f64 6528 290a 2020 2020  ta.decode().    
+0000aae0: 2020 2020 7265 7475 726e 2064 6573 6572      return deser
+0000aaf0: 6961 6c69 7a65 645f 626f 6479 2c20 636f  ialized_body, co
+0000ab00: 6e74 656e 745f 7479 7065 0a0a 2020 2020  ntent_type..    
+0000ab10: 6465 6620 6465 7365 7269 616c 697a 6528  def deserialize(
+0000ab20: 7365 6c66 2c20 7265 7370 6f6e 7365 3a20  self, response: 
+0000ab30: 5265 7370 6f6e 7365 5772 6170 7065 722c  ResponseWrapper,
+0000ab40: 2063 6f6e 6669 6775 7261 7469 6f6e 3a20   configuration: 
+0000ab50: 436f 6e66 6967 7572 6174 696f 6e2c 2073  Configuration, s
+0000ab60: 6b69 705f 6465 7365 7269 616c 697a 6174  kip_deserializat
+0000ab70: 696f 6e20 3d20 4661 6c73 6529 202d 3e20  ion = False) -> 
+0000ab80: 4170 6952 6573 706f 6e73 653a 0a20 2020  ApiResponse:.   
+0000ab90: 2020 2020 2063 6f6e 7465 6e74 5f74 7970       content_typ
+0000aba0: 6520 3d20 7265 7370 6f6e 7365 2e68 7474  e = response.htt
+0000abb0: 705f 7265 7370 6f6e 7365 2e68 6561 6465  p_response.heade
+0000abc0: 7273 2e67 6574 2827 636f 6e74 656e 742d  rs.get('content-
+0000abd0: 7479 7065 2729 0a20 2020 2020 2020 2073  type').        s
+0000abe0: 7472 6561 6d65 6420 3d20 7265 7370 6f6e  treamed = respon
+0000abf0: 7365 2e68 7474 705f 7265 7370 6f6e 7365  se.http_response
+0000ac00: 2e73 7570 706f 7274 735f 6368 756e 6b65  .supports_chunke
+0000ac10: 645f 7265 6164 7328 290a 0a20 2020 2020  d_reads()..     
+0000ac20: 2020 2064 6573 6572 6961 6c69 7a65 645f     deserialized_
+0000ac30: 6865 6164 6572 7320 3d20 756e 7365 740a  headers = unset.
+0000ac40: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+0000ac50: 6865 6164 6572 7320 6973 206e 6f74 204e  headers is not N
+0000ac60: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
+0000ac70: 2023 2054 4f44 4f20 6164 6420 6865 6164   # TODO add head
+0000ac80: 6572 2064 6573 6572 6961 6c69 7a61 7469  er deserializati
+0000ac90: 6f6e 2068 6572 650a 2020 2020 2020 2020  on here.        
+0000aca0: 2020 2020 7061 7373 0a0a 2020 2020 2020      pass..      
+0000acb0: 2020 6966 2073 656c 662e 636f 6e74 656e    if self.conten
+0000acc0: 7420 6973 206e 6f74 204e 6f6e 6520 616e  t is not None an
+0000acd0: 6420 6c65 6e28 7365 6c66 2e63 6f6e 7465  d len(self.conte
+0000ace0: 6e74 2920 3d3d 2030 3a0a 2020 2020 2020  nt) == 0:.      
+0000acf0: 2020 2020 2020 2320 736f 6d65 2073 7065        # some spe
+0000ad00: 6373 2064 6f20 6e6f 7420 6465 6669 6e65  cs do not define
+0000ad10: 2072 6573 706f 6e73 6520 636f 6e74 656e   response conten
+0000ad20: 7420 6d65 6469 6120 7479 7065 2073 6368  t media type sch
+0000ad30: 656d 6173 0a20 2020 2020 2020 2020 2020  emas.           
+0000ad40: 2072 6574 7572 6e20 7365 6c66 2e72 6573   return self.res
+0000ad50: 706f 6e73 655f 636c 7328 0a20 2020 2020  ponse_cls(.     
+0000ad60: 2020 2020 2020 2020 2020 2072 6f75 6e64             round
+0000ad70: 5f74 7269 705f 7469 6d65 3d72 6573 706f  _trip_time=respo
+0000ad80: 6e73 652e 726f 756e 645f 7472 6970 5f74  nse.round_trip_t
+0000ad90: 696d 652c 0a20 2020 2020 2020 2020 2020  ime,.           
+0000ada0: 2020 2020 2072 6573 706f 6e73 653d 7265       response=re
+0000adb0: 7370 6f6e 7365 2e68 7474 705f 7265 7370  sponse.http_resp
+0000adc0: 6f6e 7365 2c0a 2020 2020 2020 2020 2020  onse,.          
+0000add0: 2020 2020 2020 626f 6479 3d75 6e73 6574        body=unset
+0000ade0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000adf0: 2020 6865 6164 6572 733d 7265 7370 6f6e    headers=respon
+0000ae00: 7365 2e68 7474 705f 7265 7370 6f6e 7365  se.http_response
+0000ae10: 2e68 6561 6465 7273 2c0a 2020 2020 2020  .headers,.      
+0000ae20: 2020 2020 2020 2020 2020 7374 6174 7573            status
+0000ae30: 3d72 6573 706f 6e73 652e 6874 7470 5f72  =response.http_r
+0000ae40: 6573 706f 6e73 652e 7374 6174 7573 0a20  esponse.status. 
+0000ae50: 2020 2020 2020 2020 2020 2029 0a0a 2020             )..  
+0000ae60: 2020 2020 2020 7472 793a 0a20 2020 2020        try:.     
+0000ae70: 2020 2020 2020 2064 6573 6572 6961 6c69         deseriali
+0000ae80: 7a65 645f 626f 6479 2c20 636f 6e74 656e  zed_body, conten
+0000ae90: 745f 7479 7065 203d 2073 656c 662e 6465  t_type = self.de
+0000aea0: 7365 7269 616c 697a 655f 626f 6479 2872  serialize_body(r
+0000aeb0: 6573 706f 6e73 652c 2063 6f6e 7465 6e74  esponse, content
+0000aec0: 5f74 7970 6529 0a20 2020 2020 2020 2065  _type).        e
+0000aed0: 7863 6570 7420 4578 6365 7074 696f 6e3a  xcept Exception:
+0000aee0: 0a20 2020 2020 2020 2020 2020 2023 204d  .            # M
+0000aef0: 6f73 7420 6c69 6b65 6c79 2063 6f6e 7465  ost likely conte
+0000af00: 6e74 2d74 7970 6520 6469 6420 6e6f 7420  nt-type did not 
+0000af10: 6d61 7463 6820 6163 7475 616c 2062 6f64  match actual bod
+0000af20: 790a 2020 2020 2020 2020 2020 2020 6465  y.            de
+0000af30: 7365 7269 616c 697a 6564 5f62 6f64 7920  serialized_body 
+0000af40: 3d20 756e 7365 740a 0a20 2020 2020 2020  = unset..       
+0000af50: 2069 6620 6e6f 7420 736b 6970 5f64 6573   if not skip_des
+0000af60: 6572 6961 6c69 7a61 7469 6f6e 3a0a 2020  erialization:.  
+0000af70: 2020 2020 2020 2020 2020 626f 6479 5f73            body_s
+0000af80: 6368 656d 6120 3d20 7365 6c66 2e5f 5f67  chema = self.__g
+0000af90: 6574 5f73 6368 656d 615f 666f 725f 636f  et_schema_for_co
+0000afa0: 6e74 656e 745f 7479 7065 2863 6f6e 7465  ntent_type(conte
+0000afb0: 6e74 5f74 7970 6529 0a20 2020 2020 2020  nt_type).       
+0000afc0: 2020 2020 2069 6620 626f 6479 5f73 6368       if body_sch
+0000afd0: 656d 6120 6973 204e 6f6e 653a 0a20 2020  ema is None:.   
+0000afe0: 2020 2020 2020 2020 2020 2020 2072 6169               rai
+0000aff0: 7365 2041 7069 5661 6c75 6545 7272 6f72  se ApiValueError
+0000b000: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+0000b010: 2020 2020 2020 6622 496e 7661 6c69 6420        f"Invalid 
+0000b020: 636f 6e74 656e 745f 7479 7065 2072 6574  content_type ret
+0000b030: 7572 6e65 642e 2043 6f6e 7465 6e74 5f74  urned. Content_t
+0000b040: 7970 653d 277b 636f 6e74 656e 745f 7479  ype='{content_ty
+0000b050: 7065 7d27 2077 6173 2072 6574 7572 6e65  pe}' was returne
+0000b060: 6420 220a 2020 2020 2020 2020 2020 2020  d ".            
+0000b070: 2020 2020 2020 2020 6622 7768 656e 206f          f"when o
+0000b080: 6e6c 7920 7b73 7472 2873 6574 2873 656c  nly {str(set(sel
+0000b090: 662e 636f 6e74 656e 7429 297d 2061 7265  f.content))} are
+0000b0a0: 2064 6566 696e 6564 2066 6f72 2073 7461   defined for sta
+0000b0b0: 7475 735f 636f 6465 3d7b 7374 7228 7265  tus_code={str(re
+0000b0c0: 7370 6f6e 7365 2e68 7474 705f 7265 7370  sponse.http_resp
+0000b0d0: 6f6e 7365 2e73 7461 7475 7329 7d22 0a20  onse.status)}". 
+0000b0e0: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+0000b0f0: 0a20 2020 2020 2020 2020 2020 2023 2045  .            # E
+0000b100: 7865 6375 7465 2076 616c 6964 6174 696f  xecute validatio
+0000b110: 6e20 616e 6420 7468 726f 7720 6173 2061  n and throw as a
+0000b120: 2073 6964 6520 6566 6665 6374 2069 6620   side effect if 
+0000b130: 7661 6c69 6461 7469 6f6e 2066 6169 6c73  validation fails
+0000b140: 0a20 2020 2020 2020 2020 2020 2062 6f64  .            bod
+0000b150: 795f 7363 6865 6d61 2e66 726f 6d5f 6f70  y_schema.from_op
+0000b160: 656e 6170 695f 6461 7461 5f6f 6170 6728  enapi_data_oapg(
+0000b170: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000b180: 2062 6f64 795f 6461 7461 2c0a 2020 2020   body_data,.    
+0000b190: 2020 2020 2020 2020 2020 2020 5f63 6f6e              _con
+0000b1a0: 6669 6775 7261 7469 6f6e 3d63 6f6e 6669  figuration=confi
+0000b1b0: 6775 7261 7469 6f6e 0a20 2020 2020 2020  guration.       
+0000b1c0: 2020 2020 2029 0a0a 2020 2020 2020 2020       )..        
+0000b1d0: 6966 2073 7472 6561 6d65 643a 0a20 2020  if streamed:.   
+0000b1e0: 2020 2020 2020 2020 2072 6573 706f 6e73           respons
+0000b1f0: 652e 6874 7470 5f72 6573 706f 6e73 652e  e.http_response.
+0000b200: 7265 6c65 6173 655f 636f 6e6e 2829 0a0a  release_conn()..
+0000b210: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+0000b220: 656c 662e 7265 7370 6f6e 7365 5f63 6c73  elf.response_cls
+0000b230: 280a 2020 2020 2020 2020 2020 2020 726f  (.            ro
+0000b240: 756e 645f 7472 6970 5f74 696d 653d 7265  und_trip_time=re
+0000b250: 7370 6f6e 7365 2e72 6f75 6e64 5f74 7269  sponse.round_tri
+0000b260: 705f 7469 6d65 2c0a 2020 2020 2020 2020  p_time,.        
+0000b270: 2020 2020 7265 7370 6f6e 7365 3d72 6573      response=res
+0000b280: 706f 6e73 652e 6874 7470 5f72 6573 706f  ponse.http_respo
+0000b290: 6e73 652c 0a20 2020 2020 2020 2020 2020  nse,.           
+0000b2a0: 2062 6f64 793d 6465 7365 7269 616c 697a   body=deserializ
+0000b2b0: 6564 5f62 6f64 792c 0a20 2020 2020 2020  ed_body,.       
+0000b2c0: 2020 2020 2068 6561 6465 7273 3d72 6573       headers=res
+0000b2d0: 706f 6e73 652e 6874 7470 5f72 6573 706f  ponse.http_respo
+0000b2e0: 6e73 652e 6865 6164 6572 732c 0a20 2020  nse.headers,.   
+0000b2f0: 2020 2020 2020 2020 2073 7461 7475 733d           status=
+0000b300: 7265 7370 6f6e 7365 2e68 7474 705f 7265  response.http_re
+0000b310: 7370 6f6e 7365 2e73 7461 7475 730a 2020  sponse.status.  
+0000b320: 2020 2020 2020 290a 0a0a 636c 6173 7320        )...class 
+0000b330: 4170 6943 6c69 656e 743a 0a20 2020 2022  ApiClient:.    "
+0000b340: 2222 4765 6e65 7269 6320 4150 4920 636c  ""Generic API cl
+0000b350: 6965 6e74 2066 6f72 204f 7065 6e41 5049  ient for OpenAPI
+0000b360: 2063 6c69 656e 7420 6c69 6272 6172 7920   client library 
+0000b370: 6275 696c 6473 2e0a 0a20 2020 204f 7065  builds...    Ope
+0000b380: 6e41 5049 2067 656e 6572 6963 2041 5049  nAPI generic API
+0000b390: 2063 6c69 656e 742e 2054 6869 7320 636c   client. This cl
+0000b3a0: 6965 6e74 2068 616e 646c 6573 2074 6865  ient handles the
+0000b3b0: 2063 6c69 656e 742d 0a20 2020 2073 6572   client-.    ser
+0000b3c0: 7665 7220 636f 6d6d 756e 6963 6174 696f  ver communicatio
+0000b3d0: 6e2c 2061 6e64 2069 7320 696e 7661 7269  n, and is invari
+0000b3e0: 616e 7420 6163 726f 7373 2069 6d70 6c65  ant across imple
+0000b3f0: 6d65 6e74 6174 696f 6e73 2e20 5370 6563  mentations. Spec
+0000b400: 6966 6963 7320 6f66 0a20 2020 2074 6865  ifics of.    the
+0000b410: 206d 6574 686f 6473 2061 6e64 206d 6f64   methods and mod
+0000b420: 656c 7320 666f 7220 6561 6368 2061 7070  els for each app
+0000b430: 6c69 6361 7469 6f6e 2061 7265 2067 656e  lication are gen
+0000b440: 6572 6174 6564 2066 726f 6d20 7468 6520  erated from the 
+0000b450: 4f70 656e 4150 490a 2020 2020 7465 6d70  OpenAPI.    temp
+0000b460: 6c61 7465 732e 0a0a 2020 2020 5468 6973  lates...    This
+0000b470: 2063 6c61 7373 2069 7320 6175 746f 2067   class is auto g
+0000b480: 656e 6572 6174 6564 2062 7920 4b6f 6e66  enerated by Konf
+0000b490: 6967 2028 6874 7470 733a 2f2f 6b6f 6e66  ig (https://konf
+0000b4a0: 6967 7468 6973 2e63 6f6d 290a 0a20 2020  igthis.com)..   
+0000b4b0: 203a 7061 7261 6d20 636f 6e66 6967 7572   :param configur
+0000b4c0: 6174 696f 6e3a 202e 436f 6e66 6967 7572  ation: .Configur
+0000b4d0: 6174 696f 6e20 6f62 6a65 6374 2066 6f72  ation object for
+0000b4e0: 2074 6869 7320 636c 6965 6e74 0a20 2020   this client.   
+0000b4f0: 203a 7061 7261 6d20 6865 6164 6572 5f6e   :param header_n
+0000b500: 616d 653a 2061 2068 6561 6465 7220 746f  ame: a header to
+0000b510: 2070 6173 7320 7768 656e 206d 616b 696e   pass when makin
+0000b520: 6720 6361 6c6c 7320 746f 2074 6865 2041  g calls to the A
+0000b530: 5049 2e0a 2020 2020 3a70 6172 616d 2068  PI..    :param h
+0000b540: 6561 6465 725f 7661 6c75 653a 2061 2068  eader_value: a h
+0000b550: 6561 6465 7220 7661 6c75 6520 746f 2070  eader value to p
+0000b560: 6173 7320 7768 656e 206d 616b 696e 6720  ass when making 
+0000b570: 6361 6c6c 7320 746f 0a20 2020 2020 2020  calls to.       
+0000b580: 2074 6865 2041 5049 2e0a 2020 2020 3a70   the API..    :p
+0000b590: 6172 616d 2063 6f6f 6b69 653a 2061 2063  aram cookie: a c
+0000b5a0: 6f6f 6b69 6520 746f 2069 6e63 6c75 6465  ookie to include
+0000b5b0: 2069 6e20 7468 6520 6865 6164 6572 2077   in the header w
+0000b5c0: 6865 6e20 6d61 6b69 6e67 2063 616c 6c73  hen making calls
+0000b5d0: 0a20 2020 2020 2020 2074 6f20 7468 6520  .        to the 
+0000b5e0: 4150 490a 2020 2020 3a70 6172 616d 2070  API.    :param p
+0000b5f0: 6f6f 6c5f 7468 7265 6164 733a 2054 6865  ool_threads: The
+0000b600: 206e 756d 6265 7220 6f66 2074 6872 6561   number of threa
+0000b610: 6473 2074 6f20 7573 6520 666f 7220 6173  ds to use for as
+0000b620: 796e 6320 7265 7175 6573 7473 0a20 2020  ync requests.   
+0000b630: 2020 2020 2074 6f20 7468 6520 4150 492e       to the API.
+0000b640: 204d 6f72 6520 7468 7265 6164 7320 6d65   More threads me
+0000b650: 616e 7320 6d6f 7265 2063 6f6e 6375 7272  ans more concurr
+0000b660: 656e 7420 4150 4920 7265 7175 6573 7473  ent API requests
+0000b670: 2e0a 2020 2020 2222 220a 0a20 2020 205f  ..    """..    _
+0000b680: 706f 6f6c 203d 204e 6f6e 650a 0a20 2020  pool = None..   
+0000b690: 2064 6566 205f 5f69 6e69 745f 5f28 0a20   def __init__(. 
+0000b6a0: 2020 2020 2020 2073 656c 662c 0a20 2020         self,.   
+0000b6b0: 2020 2020 2063 6f6e 6669 6775 7261 7469       configurati
+0000b6c0: 6f6e 3a20 7479 7069 6e67 2e4f 7074 696f  on: typing.Optio
+0000b6d0: 6e61 6c5b 436f 6e66 6967 7572 6174 696f  nal[Configuratio
+0000b6e0: 6e5d 203d 204e 6f6e 652c 0a20 2020 2020  n] = None,.     
+0000b6f0: 2020 2068 6561 6465 725f 6e61 6d65 3a20     header_name: 
+0000b700: 7479 7069 6e67 2e4f 7074 696f 6e61 6c5b  typing.Optional[
+0000b710: 7374 725d 203d 204e 6f6e 652c 0a20 2020  str] = None,.   
+0000b720: 2020 2020 2068 6561 6465 725f 7661 6c75       header_valu
+0000b730: 653a 2074 7970 696e 672e 4f70 7469 6f6e  e: typing.Option
+0000b740: 616c 5b73 7472 5d20 3d20 4e6f 6e65 2c0a  al[str] = None,.
+0000b750: 2020 2020 2020 2020 636f 6f6b 6965 3a20          cookie: 
+0000b760: 7479 7069 6e67 2e4f 7074 696f 6e61 6c5b  typing.Optional[
+0000b770: 7374 725d 203d 204e 6f6e 652c 0a20 2020  str] = None,.   
+0000b780: 2020 2020 2070 6f6f 6c5f 7468 7265 6164       pool_thread
+0000b790: 733a 2069 6e74 203d 2031 0a20 2020 2029  s: int = 1.    )
+0000b7a0: 3a0a 2020 2020 2020 2020 6966 2063 6f6e  :.        if con
+0000b7b0: 6669 6775 7261 7469 6f6e 2069 7320 4e6f  figuration is No
+0000b7c0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+0000b7d0: 636f 6e66 6967 7572 6174 696f 6e20 3d20  configuration = 
+0000b7e0: 436f 6e66 6967 7572 6174 696f 6e28 290a  Configuration().
+0000b7f0: 2020 2020 2020 2020 7365 6c66 2e63 6f6e          self.con
+0000b800: 6669 6775 7261 7469 6f6e 203d 2063 6f6e  figuration = con
+0000b810: 6669 6775 7261 7469 6f6e 0a20 2020 2020  figuration.     
+0000b820: 2020 2073 656c 662e 706f 6f6c 5f74 6872     self.pool_thr
+0000b830: 6561 6473 203d 2070 6f6f 6c5f 7468 7265  eads = pool_thre
+0000b840: 6164 730a 0a20 2020 2020 2020 2073 656c  ads..        sel
+0000b850: 662e 7265 7374 5f63 6c69 656e 7420 3d20  f.rest_client = 
+0000b860: 7265 7374 2e52 4553 5443 6c69 656e 744f  rest.RESTClientO
+0000b870: 626a 6563 7428 636f 6e66 6967 7572 6174  bject(configurat
+0000b880: 696f 6e29 0a20 2020 2020 2020 2073 656c  ion).        sel
+0000b890: 662e 6465 6661 756c 745f 6865 6164 6572  f.default_header
+0000b8a0: 7320 3d20 4854 5450 4865 6164 6572 4469  s = HTTPHeaderDi
+0000b8b0: 6374 2829 0a20 2020 2020 2020 2069 6620  ct().        if 
+0000b8c0: 6865 6164 6572 5f6e 616d 6520 6973 206e  header_name is n
+0000b8d0: 6f74 204e 6f6e 653a 0a20 2020 2020 2020  ot None:.       
+0000b8e0: 2020 2020 2073 656c 662e 6465 6661 756c       self.defaul
+0000b8f0: 745f 6865 6164 6572 735b 6865 6164 6572  t_headers[header
+0000b900: 5f6e 616d 655d 203d 2068 6561 6465 725f  _name] = header_
+0000b910: 7661 6c75 650a 2020 2020 2020 2020 7365  value.        se
+0000b920: 6c66 2e63 6f6f 6b69 6520 3d20 636f 6f6b  lf.cookie = cook
+0000b930: 6965 0a20 2020 2020 2020 2023 2053 6574  ie.        # Set
+0000b940: 2064 6566 6175 6c74 2055 7365 722d 4167   default User-Ag
+0000b950: 656e 742e 0a20 2020 2020 2020 2073 656c  ent..        sel
+0000b960: 662e 7573 6572 5f61 6765 6e74 203d 2027  f.user_agent = '
+0000b970: 4b6f 6e66 6967 2f30 2e32 2e30 2f70 7974  Konfig/0.2.0/pyt
+0000b980: 686f 6e27 0a0a 2020 2020 6465 6620 5f5f  hon'..    def __
+0000b990: 656e 7465 725f 5f28 7365 6c66 293a 0a20  enter__(self):. 
+0000b9a0: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
+0000b9b0: 6c66 0a0a 2020 2020 6465 6620 5f5f 6578  lf..    def __ex
+0000b9c0: 6974 5f5f 2873 656c 662c 2065 7863 5f74  it__(self, exc_t
+0000b9d0: 7970 652c 2065 7863 5f76 616c 7565 2c20  ype, exc_value, 
+0000b9e0: 7472 6163 6562 6163 6b29 3a0a 2020 2020  traceback):.    
+0000b9f0: 2020 2020 7365 6c66 2e63 6c6f 7365 2829      self.close()
+0000ba00: 0a0a 2020 2020 6465 6620 636c 6f73 6528  ..    def close(
+0000ba10: 7365 6c66 293a 0a20 2020 2020 2020 2069  self):.        i
+0000ba20: 6620 7365 6c66 2e5f 706f 6f6c 3a0a 2020  f self._pool:.  
+0000ba30: 2020 2020 2020 2020 2020 7365 6c66 2e5f            self._
+0000ba40: 706f 6f6c 2e63 6c6f 7365 2829 0a20 2020  pool.close().   
+0000ba50: 2020 2020 2020 2020 2073 656c 662e 5f70           self._p
+0000ba60: 6f6f 6c2e 6a6f 696e 2829 0a20 2020 2020  ool.join().     
+0000ba70: 2020 2020 2020 2073 656c 662e 5f70 6f6f         self._poo
+0000ba80: 6c20 3d20 4e6f 6e65 0a20 2020 2020 2020  l = None.       
+0000ba90: 2020 2020 2069 6620 6861 7361 7474 7228       if hasattr(
+0000baa0: 6174 6578 6974 2c20 2775 6e72 6567 6973  atexit, 'unregis
+0000bab0: 7465 7227 293a 0a20 2020 2020 2020 2020  ter'):.         
+0000bac0: 2020 2020 2020 2061 7465 7869 742e 756e         atexit.un
+0000bad0: 7265 6769 7374 6572 2873 656c 662e 636c  register(self.cl
+0000bae0: 6f73 6529 0a0a 2020 2020 4070 726f 7065  ose)..    @prope
+0000baf0: 7274 790a 2020 2020 6465 6620 706f 6f6c  rty.    def pool
+0000bb00: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+0000bb10: 2222 2243 7265 6174 6520 7468 7265 6164  """Create thread
+0000bb20: 2070 6f6f 6c20 6f6e 2066 6972 7374 2072   pool on first r
+0000bb30: 6571 7565 7374 0a20 2020 2020 2020 2020  equest.         
+0000bb40: 6176 6f69 6473 2069 6e73 7461 6e74 6961  avoids instantia
+0000bb50: 7469 6e67 2075 6e75 7365 6420 7468 7265  ting unused thre
+0000bb60: 6164 706f 6f6c 2066 6f72 2062 6c6f 636b  adpool for block
+0000bb70: 696e 6720 636c 6965 6e74 732e 0a20 2020  ing clients..   
+0000bb80: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
+0000bb90: 2069 6620 7365 6c66 2e5f 706f 6f6c 2069   if self._pool i
+0000bba0: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
+0000bbb0: 2020 2020 6174 6578 6974 2e72 6567 6973      atexit.regis
+0000bbc0: 7465 7228 7365 6c66 2e63 6c6f 7365 290a  ter(self.close).
+0000bbd0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+0000bbe0: 2e5f 706f 6f6c 203d 2054 6872 6561 6450  ._pool = ThreadP
+0000bbf0: 6f6f 6c28 7365 6c66 2e70 6f6f 6c5f 7468  ool(self.pool_th
+0000bc00: 7265 6164 7329 0a20 2020 2020 2020 2072  reads).        r
+0000bc10: 6574 7572 6e20 7365 6c66 2e5f 706f 6f6c  eturn self._pool
+0000bc20: 0a0a 2020 2020 4070 726f 7065 7274 790a  ..    @property.
+0000bc30: 2020 2020 6465 6620 7573 6572 5f61 6765      def user_age
+0000bc40: 6e74 2873 656c 6629 3a0a 2020 2020 2020  nt(self):.      
+0000bc50: 2020 2222 2255 7365 7220 6167 656e 7420    """User agent 
+0000bc60: 666f 7220 7468 6973 2041 5049 2063 6c69  for this API cli
+0000bc70: 656e 7422 2222 0a20 2020 2020 2020 2072  ent""".        r
+0000bc80: 6574 7572 6e20 7365 6c66 2e64 6566 6175  eturn self.defau
+0000bc90: 6c74 5f68 6561 6465 7273 5b27 5573 6572  lt_headers['User
+0000bca0: 2d41 6765 6e74 275d 0a0a 2020 2020 4075  -Agent']..    @u
+0000bcb0: 7365 725f 6167 656e 742e 7365 7474 6572  ser_agent.setter
+0000bcc0: 0a20 2020 2064 6566 2075 7365 725f 6167  .    def user_ag
+0000bcd0: 656e 7428 7365 6c66 2c20 7661 6c75 6529  ent(self, value)
+0000bce0: 3a0a 2020 2020 2020 2020 7365 6c66 2e64  :.        self.d
+0000bcf0: 6566 6175 6c74 5f68 6561 6465 7273 5b27  efault_headers['
+0000bd00: 5573 6572 2d41 6765 6e74 275d 203d 2076  User-Agent'] = v
+0000bd10: 616c 7565 0a0a 2020 2020 6465 6620 7365  alue..    def se
+0000bd20: 745f 6465 6661 756c 745f 6865 6164 6572  t_default_header
+0000bd30: 2873 656c 662c 2068 6561 6465 725f 6e61  (self, header_na
+0000bd40: 6d65 2c20 6865 6164 6572 5f76 616c 7565  me, header_value
+0000bd50: 293a 0a20 2020 2020 2020 2073 656c 662e  ):.        self.
+0000bd60: 6465 6661 756c 745f 6865 6164 6572 735b  default_headers[
+0000bd70: 6865 6164 6572 5f6e 616d 655d 203d 2068  header_name] = h
+0000bd80: 6561 6465 725f 7661 6c75 650a 0a20 2020  eader_value..   
+0000bd90: 2061 7379 6e63 2064 6566 205f 5f61 7379   async def __asy
+0000bda0: 6e63 5f63 616c 6c5f 6170 6928 0a20 2020  nc_call_api(.   
+0000bdb0: 2020 2020 2073 656c 662c 0a20 2020 2020       self,.     
+0000bdc0: 2020 2072 6573 6f75 7263 655f 7061 7468     resource_path
+0000bdd0: 3a20 7374 722c 0a20 2020 2020 2020 206d  : str,.        m
+0000bde0: 6574 686f 643a 2073 7472 2c0a 2020 2020  ethod: str,.    
+0000bdf0: 2020 2020 6865 6164 6572 733a 2074 7970      headers: typ
+0000be00: 696e 672e 4f70 7469 6f6e 616c 5b48 5454  ing.Optional[HTT
+0000be10: 5048 6561 6465 7244 6963 745d 203d 204e  PHeaderDict] = N
+0000be20: 6f6e 652c 0a20 2020 2020 2020 2073 6572  one,.        ser
+0000be30: 6961 6c69 7a65 645f 626f 6479 3a20 7479  ialized_body: ty
+0000be40: 7069 6e67 2e4f 7074 696f 6e61 6c5b 7479  ping.Optional[ty
+0000be50: 7069 6e67 2e55 6e69 6f6e 5b73 7472 2c20  ping.Union[str, 
+0000be60: 6279 7465 735d 5d20 3d20 4e6f 6e65 2c0a  bytes]] = None,.
+0000be70: 2020 2020 2020 2020 626f 6479 3a20 7479          body: ty
+0000be80: 7069 6e67 2e41 6e79 203d 204e 6f6e 652c  ping.Any = None,
+0000be90: 0a20 2020 2020 2020 2066 6965 6c64 733a  .        fields:
+0000bea0: 2074 7970 696e 672e 4f70 7469 6f6e 616c   typing.Optional
+0000beb0: 5b74 7970 696e 672e 5475 706c 655b 7479  [typing.Tuple[ty
+0000bec0: 7069 6e67 2e54 7570 6c65 5b73 7472 2c20  ping.Tuple[str, 
+0000bed0: 7374 725d 2c20 2e2e 2e5d 5d20 3d20 4e6f  str], ...]] = No
+0000bee0: 6e65 2c0a 2020 2020 2020 2020 6175 7468  ne,.        auth
+0000bef0: 5f73 6574 7469 6e67 733a 2074 7970 696e  _settings: typin
+0000bf00: 672e 4f70 7469 6f6e 616c 5b74 7970 696e  g.Optional[typin
+0000bf10: 672e 4c69 7374 5b73 7472 5d5d 203d 204e  g.List[str]] = N
+0000bf20: 6f6e 652c 0a20 2020 2020 2020 2073 7472  one,.        str
+0000bf30: 6561 6d3a 2062 6f6f 6c20 3d20 4661 6c73  eam: bool = Fals
+0000bf40: 652c 0a20 2020 2020 2020 2074 696d 656f  e,.        timeo
+0000bf50: 7574 3a20 7479 7069 6e67 2e4f 7074 696f  ut: typing.Optio
+0000bf60: 6e61 6c5b 7479 7069 6e67 2e55 6e69 6f6e  nal[typing.Union
+0000bf70: 5b66 6c6f 6174 2c20 7479 7069 6e67 2e54  [float, typing.T
+0000bf80: 7570 6c65 5d5d 203d 204e 6f6e 652c 0a20  uple]] = None,. 
+0000bf90: 2020 2020 2020 2068 6f73 743a 2074 7970         host: typ
+0000bfa0: 696e 672e 4f70 7469 6f6e 616c 5b73 7472  ing.Optional[str
+0000bfb0: 5d20 3d20 4e6f 6e65 2c0a 2020 2020 2020  ] = None,.      
+0000bfc0: 2020 7072 6566 6978 5f73 6570 6172 6174    prefix_separat
+0000bfd0: 6f72 5f69 7465 7261 746f 723a 2050 7265  or_iterator: Pre
+0000bfe0: 6669 7853 6570 6172 6174 6f72 4974 6572  fixSeparatorIter
+0000bff0: 6174 6f72 203d 204e 6f6e 652c 0a20 2020  ator = None,.   
+0000c000: 2020 2020 202a 2a6b 7761 7267 730a 2020       **kwargs.  
+0000c010: 2020 2920 2d3e 2041 7379 6e63 5265 7370    ) -> AsyncResp
+0000c020: 6f6e 7365 5772 6170 7065 723a 0a0a 2020  onseWrapper:..  
+0000c030: 2020 2020 2020 2320 6865 6164 6572 2070        # header p
+0000c040: 6172 616d 6574 6572 730a 2020 2020 2020  arameters.      
+0000c050: 2020 7573 6564 5f68 6561 6465 7273 203d    used_headers =
+0000c060: 2048 5454 5048 6561 6465 7244 6963 7428   HTTPHeaderDict(
+0000c070: 7365 6c66 2e64 6566 6175 6c74 5f68 6561  self.default_hea
+0000c080: 6465 7273 290a 2020 2020 2020 2020 6966  ders).        if
+0000c090: 2073 656c 662e 636f 6f6b 6965 3a0a 2020   self.cookie:.  
+0000c0a0: 2020 2020 2020 2020 2020 6865 6164 6572            header
+0000c0b0: 735b 2743 6f6f 6b69 6527 5d20 3d20 7365  s['Cookie'] = se
+0000c0c0: 6c66 2e63 6f6f 6b69 650a 0a20 2020 2020  lf.cookie..     
+0000c0d0: 2020 2023 2061 7574 6820 7365 7474 696e     # auth settin
+0000c0e0: 670a 2020 2020 2020 2020 7265 736f 7572  g.        resour
+0000c0f0: 6365 5f70 6174 685f 7265 6620 3d20 5b73  ce_path_ref = [s
+0000c100: 656c 662e 7570 6461 7465 5f70 6172 616d  elf.update_param
+0000c110: 735f 666f 725f 6175 7468 280a 2020 2020  s_for_auth(.    
+0000c120: 2020 2020 2020 2020 7573 6564 5f68 6561          used_hea
+0000c130: 6465 7273 2c0a 2020 2020 2020 2020 2020  ders,.          
+0000c140: 2020 6175 7468 5f73 6574 7469 6e67 732c    auth_settings,
+0000c150: 0a20 2020 2020 2020 2020 2020 2072 6573  .            res
+0000c160: 6f75 7263 655f 7061 7468 2c0a 2020 2020  ource_path,.    
+0000c170: 2020 2020 2020 2020 6d65 7468 6f64 2c0a          method,.
+0000c180: 2020 2020 2020 2020 2020 2020 626f 6479              body
+0000c190: 2c0a 2020 2020 2020 2020 2020 2020 7072  ,.            pr
+0000c1a0: 6566 6978 5f73 6570 6172 6174 6f72 5f69  efix_separator_i
+0000c1b0: 7465 7261 746f 720a 2020 2020 2020 2020  terator.        
+0000c1c0: 295d 0a0a 2020 2020 2020 2020 2320 6d75  )]..        # mu
+0000c1d0: 7374 2068 6170 7065 6e20 6166 7465 7220  st happen after 
+0000c1e0: 636f 6f6b 6965 2073 6574 7469 6e67 2061  cookie setting a
+0000c1f0: 6e64 2061 7574 6820 7365 7474 696e 6720  nd auth setting 
+0000c200: 696e 2063 6173 6520 7573 6572 2069 7320  in case user is 
+0000c210: 6f76 6572 7269 6469 6e67 2074 686f 7365  overriding those
+0000c220: 0a20 2020 2020 2020 2069 6620 6865 6164  .        if head
+0000c230: 6572 733a 0a20 2020 2020 2020 2020 2020  ers:.           
+0000c240: 2075 7365 645f 6865 6164 6572 732e 7570   used_headers.up
+0000c250: 6461 7465 2868 6561 6465 7273 290a 0a20  date(headers).. 
+0000c260: 2020 2020 2020 2072 6571 7565 7374 5f62         request_b
+0000c270: 6566 6f72 655f 7572 6c5f 686f 6f6b 280a  efore_url_hook(.
+0000c280: 2020 2020 2020 2020 2020 2020 7265 736f              reso
+0000c290: 7572 6365 5f70 6174 685f 7265 663d 7265  urce_path_ref=re
+0000c2a0: 736f 7572 6365 5f70 6174 685f 7265 662c  source_path_ref,
+0000c2b0: 0a20 2020 2020 2020 2020 2020 206d 6574  .            met
+0000c2c0: 686f 643d 6d65 7468 6f64 2c0a 2020 2020  hod=method,.    
+0000c2d0: 2020 2020 2020 2020 636f 6e66 6967 7572          configur
+0000c2e0: 6174 696f 6e3d 7365 6c66 2e63 6f6e 6669  ation=self.confi
+0000c2f0: 6775 7261 7469 6f6e 2c0a 2020 2020 2020  guration,.      
+0000c300: 2020 2020 2020 626f 6479 3d62 6f64 792c        body=body,
+0000c310: 0a20 2020 2020 2020 2020 2020 2066 6965  .            fie
+0000c320: 6c64 733d 6669 656c 6473 2c0a 2020 2020  lds=fields,.    
+0000c330: 2020 2020 2020 2020 6175 7468 5f73 6574          auth_set
+0000c340: 7469 6e67 733d 6175 7468 5f73 6574 7469  tings=auth_setti
+0000c350: 6e67 732c 0a20 2020 2020 2020 2020 2020  ngs,.           
+0000c360: 2068 6561 6465 7273 3d75 7365 645f 6865   headers=used_he
+0000c370: 6164 6572 732c 0a20 2020 2020 2020 2029  aders,.        )
+0000c380: 0a0a 2020 2020 2020 2020 2320 7265 7175  ..        # requ
+0000c390: 6573 7420 7572 6c0a 2020 2020 2020 2020  est url.        
+0000c3a0: 6966 2068 6f73 7420 6973 204e 6f6e 653a  if host is None:
+0000c3b0: 0a20 2020 2020 2020 2020 2020 2075 726c  .            url
+0000c3c0: 203d 2073 656c 662e 636f 6e66 6967 7572   = self.configur
+0000c3d0: 6174 696f 6e2e 686f 7374 202b 2072 6573  ation.host + res
+0000c3e0: 6f75 7263 655f 7061 7468 5f72 6566 5b30  ource_path_ref[0
+0000c3f0: 5d0a 2020 2020 2020 2020 656c 7365 3a0a  ].        else:.
+0000c400: 2020 2020 2020 2020 2020 2020 2320 7573              # us
+0000c410: 6520 7365 7276 6572 2f68 6f73 7420 6465  e server/host de
+0000c420: 6669 6e65 6420 696e 2070 6174 6820 6f72  fined in path or
+0000c430: 206f 7065 7261 7469 6f6e 2069 6e73 7465   operation inste
+0000c440: 6164 0a20 2020 2020 2020 2020 2020 2075  ad.            u
+0000c450: 726c 203d 2068 6f73 7420 2b20 7265 736f  rl = host + reso
+0000c460: 7572 6365 5f70 6174 685f 7265 665b 305d  urce_path_ref[0]
+0000c470: 0a0a 2020 2020 2020 2020 7265 7175 6573  ..        reques
+0000c480: 745f 6166 7465 725f 686f 6f6b 280a 2020  t_after_hook(.  
+0000c490: 2020 2020 2020 2020 2020 7265 736f 7572            resour
+0000c4a0: 6365 5f70 6174 683d 7265 736f 7572 6365  ce_path=resource
+0000c4b0: 5f70 6174 685f 7265 665b 305d 2c0a 2020  _path_ref[0],.  
+0000c4c0: 2020 2020 2020 2020 2020 6d65 7468 6f64            method
+0000c4d0: 3d6d 6574 686f 642c 0a20 2020 2020 2020  =method,.       
+0000c4e0: 2020 2020 2063 6f6e 6669 6775 7261 7469       configurati
+0000c4f0: 6f6e 3d73 656c 662e 636f 6e66 6967 7572  on=self.configur
+0000c500: 6174 696f 6e2c 0a20 2020 2020 2020 2020  ation,.         
+0000c510: 2020 2062 6f64 793d 626f 6479 2c0a 2020     body=body,.  
+0000c520: 2020 2020 2020 2020 2020 6669 656c 6473            fields
+0000c530: 3d66 6965 6c64 732c 0a20 2020 2020 2020  =fields,.       
+0000c540: 2020 2020 2061 7574 685f 7365 7474 696e       auth_settin
+0000c550: 6773 3d61 7574 685f 7365 7474 696e 6773  gs=auth_settings
+0000c560: 2c0a 2020 2020 2020 2020 2020 2020 6865  ,.            he
+0000c570: 6164 6572 733d 7573 6564 5f68 6561 6465  aders=used_heade
+0000c580: 7273 2c0a 2020 2020 2020 2020 290a 0a20  rs,.        ).. 
+0000c590: 2020 2020 2020 2023 2070 6572 666f 726d         # perform
+0000c5a0: 2072 6571 7565 7374 2061 6e64 2072 6574   request and ret
+0000c5b0: 7572 6e20 7265 7370 6f6e 7365 0a20 2020  urn response.   
+0000c5c0: 2020 2020 2072 6573 706f 6e73 6520 3d20       response = 
+0000c5d0: 6177 6169 7420 7365 6c66 2e61 7379 6e63  await self.async
+0000c5e0: 5f72 6571 7565 7374 280a 2020 2020 2020  _request(.      
+0000c5f0: 2020 2020 2020 6d65 7468 6f64 2c0a 2020        method,.  
+0000c600: 2020 2020 2020 2020 2020 7572 6c2c 0a20            url,. 
+0000c610: 2020 2020 2020 2020 2020 2068 6561 6465             heade
+0000c620: 7273 3d75 7365 645f 6865 6164 6572 732c  rs=used_headers,
+0000c630: 0a20 2020 2020 2020 2020 2020 2066 6965  .            fie
+0000c640: 6c64 733d 6669 656c 6473 2c0a 2020 2020  lds=fields,.    
+0000c650: 2020 2020 2020 2020 626f 6479 3d73 6572          body=ser
+0000c660: 6961 6c69 7a65 645f 626f 6479 2c0a 2020  ialized_body,.  
+0000c670: 2020 2020 2020 2020 2020 7374 7265 616d            stream
+0000c680: 3d73 7472 6561 6d2c 0a20 2020 2020 2020  =stream,.       
+0000c690: 2020 2020 2074 696d 656f 7574 3d74 696d       timeout=tim
+0000c6a0: 656f 7574 2c0a 2020 2020 2020 2020 2020  eout,.          
+0000c6b0: 2020 2a2a 6b77 6172 6773 0a20 2020 2020    **kwargs.     
+0000c6c0: 2020 2029 0a0a 0a20 2020 2020 2020 2072     )...        r
+0000c6d0: 6574 7572 6e20 7265 7370 6f6e 7365 0a0a  eturn response..
+0000c6e0: 2020 2020 6465 6620 5f5f 6361 6c6c 5f61      def __call_a
+0000c6f0: 7069 280a 2020 2020 2020 2020 7365 6c66  pi(.        self
+0000c700: 2c0a 2020 2020 2020 2020 7265 736f 7572  ,.        resour
+0000c710: 6365 5f70 6174 683a 2073 7472 2c0a 2020  ce_path: str,.  
+0000c720: 2020 2020 2020 6d65 7468 6f64 3a20 7374        method: st
+0000c730: 722c 0a20 2020 2020 2020 2068 6561 6465  r,.        heade
+0000c740: 7273 3a20 7479 7069 6e67 2e4f 7074 696f  rs: typing.Optio
+0000c750: 6e61 6c5b 4854 5450 4865 6164 6572 4469  nal[HTTPHeaderDi
+0000c760: 6374 5d20 3d20 4e6f 6e65 2c0a 2020 2020  ct] = None,.    
+0000c770: 2020 2020 7365 7269 616c 697a 6564 5f62      serialized_b
+0000c780: 6f64 793a 2074 7970 696e 672e 4f70 7469  ody: typing.Opti
+0000c790: 6f6e 616c 5b74 7970 696e 672e 556e 696f  onal[typing.Unio
+0000c7a0: 6e5b 7374 722c 2062 7974 6573 5d5d 203d  n[str, bytes]] =
+0000c7b0: 204e 6f6e 652c 0a20 2020 2020 2020 2062   None,.        b
+0000c7c0: 6f64 793a 2074 7970 696e 672e 416e 7920  ody: typing.Any 
+0000c7d0: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
+0000c7e0: 6669 656c 6473 3a20 7479 7069 6e67 2e4f  fields: typing.O
+0000c7f0: 7074 696f 6e61 6c5b 7479 7069 6e67 2e54  ptional[typing.T
+0000c800: 7570 6c65 5b74 7970 696e 672e 5475 706c  uple[typing.Tupl
+0000c810: 655b 7374 722c 2073 7472 5d2c 202e 2e2e  e[str, str], ...
+0000c820: 5d5d 203d 204e 6f6e 652c 0a20 2020 2020  ]] = None,.     
+0000c830: 2020 2061 7574 685f 7365 7474 696e 6773     auth_settings
+0000c840: 3a20 7479 7069 6e67 2e4f 7074 696f 6e61  : typing.Optiona
+0000c850: 6c5b 7479 7069 6e67 2e4c 6973 745b 7374  l[typing.List[st
+0000c860: 725d 5d20 3d20 4e6f 6e65 2c0a 2020 2020  r]] = None,.    
+0000c870: 2020 2020 7374 7265 616d 3a20 626f 6f6c      stream: bool
+0000c880: 203d 2046 616c 7365 2c0a 2020 2020 2020   = False,.      
+0000c890: 2020 7469 6d65 6f75 743a 2074 7970 696e    timeout: typin
+0000c8a0: 672e 4f70 7469 6f6e 616c 5b74 7970 696e  g.Optional[typin
+0000c8b0: 672e 556e 696f 6e5b 666c 6f61 742c 2074  g.Union[float, t
+0000c8c0: 7970 696e 672e 5475 706c 655d 5d20 3d20  yping.Tuple]] = 
+0000c8d0: 4e6f 6e65 2c0a 2020 2020 2020 2020 686f  None,.        ho
+0000c8e0: 7374 3a20 7479 7069 6e67 2e4f 7074 696f  st: typing.Optio
+0000c8f0: 6e61 6c5b 7374 725d 203d 204e 6f6e 652c  nal[str] = None,
+0000c900: 0a20 2020 2020 2020 2070 7265 6669 785f  .        prefix_
+0000c910: 7365 7061 7261 746f 725f 6974 6572 6174  separator_iterat
+0000c920: 6f72 3a20 5072 6566 6978 5365 7061 7261  or: PrefixSepara
+0000c930: 746f 7249 7465 7261 746f 7220 3d20 4e6f  torIterator = No
+0000c940: 6e65 2c0a 2020 2020 2920 2d3e 2052 6573  ne,.    ) -> Res
+0000c950: 706f 6e73 6557 7261 7070 6572 3a0a 0a20  ponseWrapper:.. 
+0000c960: 2020 2020 2020 2023 2068 6561 6465 7220         # header 
+0000c970: 7061 7261 6d65 7465 7273 0a20 2020 2020  parameters.     
+0000c980: 2020 2075 7365 645f 6865 6164 6572 7320     used_headers 
+0000c990: 3d20 4854 5450 4865 6164 6572 4469 6374  = HTTPHeaderDict
+0000c9a0: 2873 656c 662e 6465 6661 756c 745f 6865  (self.default_he
+0000c9b0: 6164 6572 7329 0a20 2020 2020 2020 2069  aders).        i
+0000c9c0: 6620 7365 6c66 2e63 6f6f 6b69 653a 0a20  f self.cookie:. 
+0000c9d0: 2020 2020 2020 2020 2020 2068 6561 6465             heade
+0000c9e0: 7273 5b27 436f 6f6b 6965 275d 203d 2073  rs['Cookie'] = s
+0000c9f0: 656c 662e 636f 6f6b 6965 0a0a 2020 2020  elf.cookie..    
+0000ca00: 2020 2020 2320 6175 7468 2073 6574 7469      # auth setti
+0000ca10: 6e67 0a20 2020 2020 2020 2072 6573 6f75  ng.        resou
+0000ca20: 7263 655f 7061 7468 5f72 6566 203d 205b  rce_path_ref = [
+0000ca30: 7365 6c66 2e75 7064 6174 655f 7061 7261  self.update_para
+0000ca40: 6d73 5f66 6f72 5f61 7574 6828 0a20 2020  ms_for_auth(.   
+0000ca50: 2020 2020 2020 2020 2075 7365 645f 6865           used_he
+0000ca60: 6164 6572 732c 0a20 2020 2020 2020 2020  aders,.         
+0000ca70: 2020 2061 7574 685f 7365 7474 696e 6773     auth_settings
+0000ca80: 2c0a 2020 2020 2020 2020 2020 2020 7265  ,.            re
+0000ca90: 736f 7572 6365 5f70 6174 682c 0a20 2020  source_path,.   
+0000caa0: 2020 2020 2020 2020 206d 6574 686f 642c           method,
+0000cab0: 0a20 2020 2020 2020 2020 2020 2062 6f64  .            bod
+0000cac0: 792c 0a20 2020 2020 2020 2020 2020 2070  y,.            p
+0000cad0: 7265 6669 785f 7365 7061 7261 746f 725f  refix_separator_
+0000cae0: 6974 6572 6174 6f72 0a20 2020 2020 2020  iterator.       
+0000caf0: 2029 5d0a 0a20 2020 2020 2020 2023 206d   )]..        # m
+0000cb00: 7573 7420 6861 7070 656e 2061 6674 6572  ust happen after
+0000cb10: 2063 6f6f 6b69 6520 7365 7474 696e 6720   cookie setting 
+0000cb20: 616e 6420 6175 7468 2073 6574 7469 6e67  and auth setting
+0000cb30: 2069 6e20 6361 7365 2075 7365 7220 6973   in case user is
+0000cb40: 206f 7665 7272 6964 696e 6720 7468 6f73   overriding thos
+0000cb50: 650a 2020 2020 2020 2020 6966 2068 6561  e.        if hea
+0000cb60: 6465 7273 3a0a 2020 2020 2020 2020 2020  ders:.          
+0000cb70: 2020 7573 6564 5f68 6561 6465 7273 2e75    used_headers.u
+0000cb80: 7064 6174 6528 6865 6164 6572 7329 0a0a  pdate(headers)..
+0000cb90: 2020 2020 2020 2020 7265 7175 6573 745f          request_
+0000cba0: 6265 666f 7265 5f75 726c 5f68 6f6f 6b28  before_url_hook(
+0000cbb0: 0a20 2020 2020 2020 2020 2020 2072 6573  .            res
+0000cbc0: 6f75 7263 655f 7061 7468 5f72 6566 3d72  ource_path_ref=r
+0000cbd0: 6573 6f75 7263 655f 7061 7468 5f72 6566  esource_path_ref
+0000cbe0: 2c0a 2020 2020 2020 2020 2020 2020 6d65  ,.            me
+0000cbf0: 7468 6f64 3d6d 6574 686f 642c 0a20 2020  thod=method,.   
+0000cc00: 2020 2020 2020 2020 2063 6f6e 6669 6775           configu
+0000cc10: 7261 7469 6f6e 3d73 656c 662e 636f 6e66  ration=self.conf
+0000cc20: 6967 7572 6174 696f 6e2c 0a20 2020 2020  iguration,.     
+0000cc30: 2020 2020 2020 2062 6f64 793d 626f 6479         body=body
+0000cc40: 2c0a 2020 2020 2020 2020 2020 2020 6669  ,.            fi
+0000cc50: 656c 6473 3d66 6965 6c64 732c 0a20 2020  elds=fields,.   
+0000cc60: 2020 2020 2020 2020 2061 7574 685f 7365           auth_se
+0000cc70: 7474 696e 6773 3d61 7574 685f 7365 7474  ttings=auth_sett
+0000cc80: 696e 6773 2c0a 2020 2020 2020 2020 2020  ings,.          
+0000cc90: 2020 6865 6164 6572 733d 7573 6564 5f68    headers=used_h
+0000cca0: 6561 6465 7273 2c0a 2020 2020 2020 2020  eaders,.        
+0000ccb0: 290a 0a20 2020 2020 2020 2023 2072 6571  )..        # req
+0000ccc0: 7565 7374 2075 726c 0a20 2020 2020 2020  uest url.       
+0000ccd0: 2069 6620 686f 7374 2069 7320 4e6f 6e65   if host is None
+0000cce0: 3a0a 2020 2020 2020 2020 2020 2020 7572  :.            ur
+0000ccf0: 6c20 3d20 7365 6c66 2e63 6f6e 6669 6775  l = self.configu
+0000cd00: 7261 7469 6f6e 2e68 6f73 7420 2b20 7265  ration.host + re
+0000cd10: 736f 7572 6365 5f70 6174 685f 7265 665b  source_path_ref[
+0000cd20: 305d 0a20 2020 2020 2020 2065 6c73 653a  0].        else:
+0000cd30: 0a20 2020 2020 2020 2020 2020 2023 2075  .            # u
+0000cd40: 7365 2073 6572 7665 722f 686f 7374 2064  se server/host d
+0000cd50: 6566 696e 6564 2069 6e20 7061 7468 206f  efined in path o
+0000cd60: 7220 6f70 6572 6174 696f 6e20 696e 7374  r operation inst
+0000cd70: 6561 640a 2020 2020 2020 2020 2020 2020  ead.            
+0000cd80: 7572 6c20 3d20 686f 7374 202b 2072 6573  url = host + res
+0000cd90: 6f75 7263 655f 7061 7468 5f72 6566 5b30  ource_path_ref[0
+0000cda0: 5d0a 0a20 2020 2020 2020 2072 6571 7565  ]..        reque
+0000cdb0: 7374 5f61 6674 6572 5f68 6f6f 6b28 0a20  st_after_hook(. 
+0000cdc0: 2020 2020 2020 2020 2020 2072 6573 6f75             resou
+0000cdd0: 7263 655f 7061 7468 3d72 6573 6f75 7263  rce_path=resourc
+0000cde0: 655f 7061 7468 5f72 6566 5b30 5d2c 0a20  e_path_ref[0],. 
+0000cdf0: 2020 2020 2020 2020 2020 206d 6574 686f             metho
+0000ce00: 643d 6d65 7468 6f64 2c0a 2020 2020 2020  d=method,.      
+0000ce10: 2020 2020 2020 636f 6e66 6967 7572 6174        configurat
+0000ce20: 696f 6e3d 7365 6c66 2e63 6f6e 6669 6775  ion=self.configu
+0000ce30: 7261 7469 6f6e 2c0a 2020 2020 2020 2020  ration,.        
+0000ce40: 2020 2020 626f 6479 3d62 6f64 792c 0a20      body=body,. 
+0000ce50: 2020 2020 2020 2020 2020 2066 6965 6c64             field
+0000ce60: 733d 6669 656c 6473 2c0a 2020 2020 2020  s=fields,.      
+0000ce70: 2020 2020 2020 6175 7468 5f73 6574 7469        auth_setti
+0000ce80: 6e67 733d 6175 7468 5f73 6574 7469 6e67  ngs=auth_setting
+0000ce90: 732c 0a20 2020 2020 2020 2020 2020 2068  s,.            h
+0000cea0: 6561 6465 7273 3d75 7365 645f 6865 6164  eaders=used_head
+0000ceb0: 6572 732c 0a20 2020 2020 2020 2029 0a0a  ers,.        )..
+0000cec0: 2020 2020 2020 2020 2320 7065 7266 6f72          # perfor
+0000ced0: 6d20 7265 7175 6573 7420 616e 6420 7265  m request and re
+0000cee0: 7475 726e 2072 6573 706f 6e73 650a 2020  turn response.  
+0000cef0: 2020 2020 2020 7265 7370 6f6e 7365 203d        response =
+0000cf00: 2073 656c 662e 7265 7175 6573 7428 0a20   self.request(. 
+0000cf10: 2020 2020 2020 2020 2020 206d 6574 686f             metho
+0000cf20: 642c 0a20 2020 2020 2020 2020 2020 2075  d,.            u
+0000cf30: 726c 2c0a 2020 2020 2020 2020 2020 2020  rl,.            
+0000cf40: 6865 6164 6572 733d 7573 6564 5f68 6561  headers=used_hea
+0000cf50: 6465 7273 2c0a 2020 2020 2020 2020 2020  ders,.          
+0000cf60: 2020 6669 656c 6473 3d66 6965 6c64 732c    fields=fields,
+0000cf70: 0a20 2020 2020 2020 2020 2020 2062 6f64  .            bod
+0000cf80: 793d 7365 7269 616c 697a 6564 5f62 6f64  y=serialized_bod
+0000cf90: 792c 0a20 2020 2020 2020 2020 2020 2073  y,.            s
+0000cfa0: 7472 6561 6d3d 7374 7265 616d 2c0a 2020  tream=stream,.  
+0000cfb0: 2020 2020 2020 2020 2020 7469 6d65 6f75            timeou
+0000cfc0: 743d 7469 6d65 6f75 742c 0a20 2020 2020  t=timeout,.     
+0000cfd0: 2020 2029 0a0a 0a20 2020 2020 2020 2072     )...        r
+0000cfe0: 6574 7572 6e20 7265 7370 6f6e 7365 0a0a  eturn response..
+0000cff0: 2020 2020 6173 796e 6320 6465 6620 6173      async def as
+0000d000: 796e 635f 6361 6c6c 5f61 7069 280a 2020  ync_call_api(.  
+0000d010: 2020 2020 2020 7365 6c66 2c0a 2020 2020        self,.    
+0000d020: 2020 2020 7265 736f 7572 6365 5f70 6174      resource_pat
+0000d030: 683a 2073 7472 2c0a 2020 2020 2020 2020  h: str,.        
+0000d040: 6d65 7468 6f64 3a20 7374 722c 0a20 2020  method: str,.   
+0000d050: 2020 2020 2068 6561 6465 7273 3a20 7479       headers: ty
+0000d060: 7069 6e67 2e4f 7074 696f 6e61 6c5b 4854  ping.Optional[HT
+0000d070: 5450 4865 6164 6572 4469 6374 5d20 3d20  TPHeaderDict] = 
+0000d080: 4e6f 6e65 2c0a 2020 2020 2020 2020 7365  None,.        se
+0000d090: 7269 616c 697a 6564 5f62 6f64 793a 2074  rialized_body: t
+0000d0a0: 7970 696e 672e 4f70 7469 6f6e 616c 5b74  yping.Optional[t
+0000d0b0: 7970 696e 672e 556e 696f 6e5b 7374 722c  yping.Union[str,
+0000d0c0: 2062 7974 6573 5d5d 203d 204e 6f6e 652c   bytes]] = None,
+0000d0d0: 0a20 2020 2020 2020 2062 6f64 793a 2074  .        body: t
+0000d0e0: 7970 696e 672e 416e 7920 3d20 4e6f 6e65  yping.Any = None
+0000d0f0: 2c0a 2020 2020 2020 2020 6669 656c 6473  ,.        fields
+0000d100: 3a20 7479 7069 6e67 2e4f 7074 696f 6e61  : typing.Optiona
+0000d110: 6c5b 7479 7069 6e67 2e54 7570 6c65 5b74  l[typing.Tuple[t
+0000d120: 7970 696e 672e 5475 706c 655b 7374 722c  yping.Tuple[str,
+0000d130: 2073 7472 5d2c 202e 2e2e 5d5d 203d 204e   str], ...]] = N
+0000d140: 6f6e 652c 0a20 2020 2020 2020 2061 7574  one,.        aut
+0000d150: 685f 7365 7474 696e 6773 3a20 7479 7069  h_settings: typi
+0000d160: 6e67 2e4f 7074 696f 6e61 6c5b 7479 7069  ng.Optional[typi
+0000d170: 6e67 2e4c 6973 745b 7374 725d 5d20 3d20  ng.List[str]] = 
+0000d180: 4e6f 6e65 2c0a 2020 2020 2020 2020 7374  None,.        st
+0000d190: 7265 616d 3a20 626f 6f6c 203d 2046 616c  ream: bool = Fal
+0000d1a0: 7365 2c0a 2020 2020 2020 2020 7469 6d65  se,.        time
+0000d1b0: 6f75 743a 2074 7970 696e 672e 4f70 7469  out: typing.Opti
+0000d1c0: 6f6e 616c 5b74 7970 696e 672e 556e 696f  onal[typing.Unio
+0000d1d0: 6e5b 666c 6f61 742c 2074 7970 696e 672e  n[float, typing.
+0000d1e0: 5475 706c 655d 5d20 3d20 4e6f 6e65 2c0a  Tuple]] = None,.
+0000d1f0: 2020 2020 2020 2020 686f 7374 3a20 7479          host: ty
+0000d200: 7069 6e67 2e4f 7074 696f 6e61 6c5b 7374  ping.Optional[st
+0000d210: 725d 203d 204e 6f6e 652c 0a20 2020 2020  r] = None,.     
+0000d220: 2020 2070 7265 6669 785f 7365 7061 7261     prefix_separa
+0000d230: 746f 725f 6974 6572 6174 6f72 3a20 5072  tor_iterator: Pr
+0000d240: 6566 6978 5365 7061 7261 746f 7249 7465  efixSeparatorIte
+0000d250: 7261 746f 7220 3d20 4e6f 6e65 2c0a 2020  rator = None,.  
+0000d260: 2020 2020 2020 2a2a 6b77 6172 6773 0a20        **kwargs. 
+0000d270: 2020 2029 202d 3e20 4173 796e 6352 6573     ) -> AsyncRes
+0000d280: 706f 6e73 6557 7261 7070 6572 3a0a 2020  ponseWrapper:.  
+0000d290: 2020 2020 2020 2222 224d 616b 6573 2074        """Makes t
+0000d2a0: 6865 2048 5454 5020 7265 7175 6573 7420  he HTTP request 
+0000d2b0: 2873 796e 6368 726f 6e6f 7573 2920 616e  (synchronous) an
+0000d2c0: 6420 7265 7475 726e 7320 6465 7365 7269  d returns deseri
+0000d2d0: 616c 697a 6564 2064 6174 612e 0a0a 2020  alized data...  
+0000d2e0: 2020 2020 2020 3a70 6172 616d 2072 6573        :param res
+0000d2f0: 6f75 7263 655f 7061 7468 3a20 5061 7468  ource_path: Path
+0000d300: 2074 6f20 6d65 7468 6f64 2065 6e64 706f   to method endpo
+0000d310: 696e 742e 0a20 2020 2020 2020 203a 7061  int..        :pa
+0000d320: 7261 6d20 6d65 7468 6f64 3a20 4d65 7468  ram method: Meth
+0000d330: 6f64 2074 6f20 6361 6c6c 2e0a 2020 2020  od to call..    
+0000d340: 2020 2020 3a70 6172 616d 2068 6561 6465      :param heade
+0000d350: 7273 3a20 4865 6164 6572 2070 6172 616d  rs: Header param
+0000d360: 6574 6572 7320 746f 2062 650a 2020 2020  eters to be.    
+0000d370: 2020 2020 2020 2020 706c 6163 6564 2069          placed i
+0000d380: 6e20 7468 6520 7265 7175 6573 7420 6865  n the request he
+0000d390: 6164 6572 2e0a 2020 2020 2020 2020 3a70  ader..        :p
+0000d3a0: 6172 616d 2062 6f64 793a 2052 6571 7565  aram body: Reque
+0000d3b0: 7374 2062 6f64 792e 0a20 2020 2020 2020  st body..       
+0000d3c0: 203a 7061 7261 6d20 6669 656c 6473 3a20   :param fields: 
+0000d3d0: 5265 7175 6573 7420 706f 7374 2066 6f72  Request post for
+0000d3e0: 6d20 7061 7261 6d65 7465 7273 2c0a 2020  m parameters,.  
+0000d3f0: 2020 2020 2020 2020 2020 666f 7220 6061            for `a
+0000d400: 7070 6c69 6361 7469 6f6e 2f78 2d77 7777  pplication/x-www
+0000d410: 2d66 6f72 6d2d 7572 6c65 6e63 6f64 6564  -form-urlencoded
+0000d420: 602c 2060 6d75 6c74 6970 6172 742f 666f  `, `multipart/fo
+0000d430: 726d 2d64 6174 6160 2e0a 2020 2020 2020  rm-data`..      
+0000d440: 2020 3a70 6172 616d 2061 7574 685f 7365    :param auth_se
+0000d450: 7474 696e 6773 3a20 4175 7468 2053 6574  ttings: Auth Set
+0000d460: 7469 6e67 7320 6e61 6d65 7320 666f 7220  tings names for 
+0000d470: 7468 6520 7265 7175 6573 742e 0a20 2020  the request..   
+0000d480: 2020 2020 203a 7061 7261 6d20 7374 7265       :param stre
+0000d490: 616d 3a20 6966 2054 7275 652c 2074 6865  am: if True, the
+0000d4a0: 2075 726c 6c69 6233 2e48 5454 5052 6573   urllib3.HTTPRes
+0000d4b0: 706f 6e73 6520 6f62 6a65 6374 2077 696c  ponse object wil
+0000d4c0: 6c0a 2020 2020 2020 2020 2020 2020 2020  l.              
+0000d4d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d4e0: 2020 2062 6520 7265 7475 726e 6564 2077     be returned w
+0000d4f0: 6974 686f 7574 2072 6561 6469 6e67 2f64  ithout reading/d
+0000d500: 6563 6f64 696e 6720 7265 7370 6f6e 7365  ecoding response
+0000d510: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000d520: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d530: 2020 6461 7461 2e20 416c 736f 2077 6865    data. Also whe
+0000d540: 6e20 5472 7565 2c20 6966 2074 6865 206f  n True, if the o
+0000d550: 7065 6e61 7069 2073 7065 6320 6465 7363  penapi spec desc
+0000d560: 7269 6265 7320 6120 6669 6c65 2064 6f77  ribes a file dow
+0000d570: 6e6c 6f61 642c 0a20 2020 2020 2020 2020  nload,.         
+0000d580: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d590: 2020 2020 2020 2020 7468 6520 6461 7461          the data
+0000d5a0: 2077 696c 6c20 6265 2077 7269 7474 656e   will be written
+0000d5b0: 2074 6f20 6120 6c6f 6361 6c20 6669 6c65   to a local file
+0000d5c0: 7379 7374 6d65 2066 696c 6520 616e 6420  systme file and 
+0000d5d0: 7468 6520 4269 6e61 7279 5363 6865 6d61  the BinarySchema
+0000d5e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000d5f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d600: 2020 696e 7374 616e 6365 2077 696c 6c20    instance will 
+0000d610: 616c 736f 2069 6e68 6572 6974 2066 726f  also inherit fro
+0000d620: 6d20 4669 6c65 5363 6865 6d61 2061 6e64  m FileSchema and
+0000d630: 2046 696c 6549 4f0a 2020 2020 2020 2020   FileIO.        
+0000d640: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d650: 2020 2020 2020 2020 2044 6566 6175 6c74           Default
+0000d660: 2069 7320 4661 6c73 652e 0a20 2020 2020   is False..     
+0000d670: 2020 203a 7479 7065 2073 7472 6561 6d3a     :type stream:
+0000d680: 2062 6f6f 6c2c 206f 7074 696f 6e61 6c0a   bool, optional.
+0000d690: 2020 2020 2020 2020 3a70 6172 616d 2074          :param t
+0000d6a0: 696d 656f 7574 3a20 7469 6d65 6f75 7420  imeout: timeout 
+0000d6b0: 7365 7474 696e 6720 666f 7220 7468 6973  setting for this
+0000d6c0: 2072 6571 7565 7374 2e20 4966 206f 6e65   request. If one
+0000d6d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000d6e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d6f0: 2020 6e75 6d62 6572 2070 726f 7669 6465    number provide
+0000d700: 642c 2069 7420 7769 6c6c 2062 6520 746f  d, it will be to
+0000d710: 7461 6c20 7265 7175 6573 740a 2020 2020  tal request.    
+0000d720: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d730: 2020 2020 2020 2020 2020 2020 2074 696d               tim
+0000d740: 656f 7574 2e20 4974 2063 616e 2061 6c73  eout. It can als
+0000d750: 6f20 6265 2061 2070 6169 7220 2874 7570  o be a pair (tup
+0000d760: 6c65 2920 6f66 0a20 2020 2020 2020 2020  le) of.         
+0000d770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d780: 2020 2020 2020 2020 2863 6f6e 6e65 6374          (connect
+0000d790: 696f 6e2c 2072 6561 6429 2074 696d 656f  ion, read) timeo
+0000d7a0: 7574 732e 0a20 2020 2020 2020 203a 7061  uts..        :pa
+0000d7b0: 7261 6d20 686f 7374 3a20 6170 6920 656e  ram host: api en
+0000d7c0: 6470 6f69 6e74 2068 6f73 740a 2020 2020  dpoint host.    
+0000d7d0: 2020 2020 3a72 6574 7572 6e3a 2072 6573      :return: res
+0000d7e0: 706f 6e73 650a 2020 2020 2020 2020 2222  ponse.        ""
+0000d7f0: 220a 2020 2020 2020 2020 7265 7475 726e  ".        return
+0000d800: 2061 7761 6974 2073 656c 662e 5f5f 6173   await self.__as
+0000d810: 796e 635f 6361 6c6c 5f61 7069 280a 2020  ync_call_api(.  
+0000d820: 2020 2020 2020 2020 2020 7265 736f 7572            resour
+0000d830: 6365 5f70 6174 682c 0a20 2020 2020 2020  ce_path,.       
+0000d840: 2020 2020 206d 6574 686f 642c 0a20 2020       method,.   
+0000d850: 2020 2020 2020 2020 2068 6561 6465 7273           headers
+0000d860: 2c0a 2020 2020 2020 2020 2020 2020 7365  ,.            se
+0000d870: 7269 616c 697a 6564 5f62 6f64 792c 0a20  rialized_body,. 
+0000d880: 2020 2020 2020 2020 2020 2062 6f64 792c             body,
+0000d890: 0a20 2020 2020 2020 2020 2020 2066 6965  .            fie
+0000d8a0: 6c64 732c 0a20 2020 2020 2020 2020 2020  lds,.           
+0000d8b0: 2061 7574 685f 7365 7474 696e 6773 2c0a   auth_settings,.
+0000d8c0: 2020 2020 2020 2020 2020 2020 7374 7265              stre
+0000d8d0: 616d 2c0a 2020 2020 2020 2020 2020 2020  am,.            
+0000d8e0: 7469 6d65 6f75 742c 0a20 2020 2020 2020  timeout,.       
+0000d8f0: 2020 2020 2068 6f73 742c 0a20 2020 2020       host,.     
+0000d900: 2020 2020 2020 2070 7265 6669 785f 7365         prefix_se
+0000d910: 7061 7261 746f 725f 6974 6572 6174 6f72  parator_iterator
+0000d920: 2c0a 2020 2020 2020 2020 2020 2020 2a2a  ,.            **
+0000d930: 6b77 6172 6773 0a20 2020 2020 2020 2029  kwargs.        )
+0000d940: 0a0a 2020 2020 6465 6620 6361 6c6c 5f61  ..    def call_a
+0000d950: 7069 280a 2020 2020 2020 2020 7365 6c66  pi(.        self
+0000d960: 2c0a 2020 2020 2020 2020 7265 736f 7572  ,.        resour
+0000d970: 6365 5f70 6174 683a 2073 7472 2c0a 2020  ce_path: str,.  
+0000d980: 2020 2020 2020 6d65 7468 6f64 3a20 7374        method: st
+0000d990: 722c 0a20 2020 2020 2020 2068 6561 6465  r,.        heade
+0000d9a0: 7273 3a20 7479 7069 6e67 2e4f 7074 696f  rs: typing.Optio
+0000d9b0: 6e61 6c5b 4854 5450 4865 6164 6572 4469  nal[HTTPHeaderDi
+0000d9c0: 6374 5d20 3d20 4e6f 6e65 2c0a 2020 2020  ct] = None,.    
+0000d9d0: 2020 2020 7365 7269 616c 697a 6564 5f62      serialized_b
+0000d9e0: 6f64 793a 2074 7970 696e 672e 4f70 7469  ody: typing.Opti
+0000d9f0: 6f6e 616c 5b74 7970 696e 672e 556e 696f  onal[typing.Unio
+0000da00: 6e5b 7374 722c 2062 7974 6573 5d5d 203d  n[str, bytes]] =
+0000da10: 204e 6f6e 652c 0a20 2020 2020 2020 2062   None,.        b
+0000da20: 6f64 793a 2074 7970 696e 672e 416e 7920  ody: typing.Any 
+0000da30: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
+0000da40: 6669 656c 6473 3a20 7479 7069 6e67 2e4f  fields: typing.O
+0000da50: 7074 696f 6e61 6c5b 7479 7069 6e67 2e54  ptional[typing.T
+0000da60: 7570 6c65 5b74 7970 696e 672e 5475 706c  uple[typing.Tupl
+0000da70: 655b 7374 722c 2073 7472 5d2c 202e 2e2e  e[str, str], ...
+0000da80: 5d5d 203d 204e 6f6e 652c 0a20 2020 2020  ]] = None,.     
+0000da90: 2020 2061 7574 685f 7365 7474 696e 6773     auth_settings
+0000daa0: 3a20 7479 7069 6e67 2e4f 7074 696f 6e61  : typing.Optiona
+0000dab0: 6c5b 7479 7069 6e67 2e4c 6973 745b 7374  l[typing.List[st
+0000dac0: 725d 5d20 3d20 4e6f 6e65 2c0a 2020 2020  r]] = None,.    
+0000dad0: 2020 2020 7374 7265 616d 3a20 626f 6f6c      stream: bool
+0000dae0: 203d 2046 616c 7365 2c0a 2020 2020 2020   = False,.      
+0000daf0: 2020 7469 6d65 6f75 743a 2074 7970 696e    timeout: typin
+0000db00: 672e 4f70 7469 6f6e 616c 5b74 7970 696e  g.Optional[typin
+0000db10: 672e 556e 696f 6e5b 666c 6f61 742c 2074  g.Union[float, t
+0000db20: 7970 696e 672e 5475 706c 655d 5d20 3d20  yping.Tuple]] = 
+0000db30: 4e6f 6e65 2c0a 2020 2020 2020 2020 686f  None,.        ho
+0000db40: 7374 3a20 7479 7069 6e67 2e4f 7074 696f  st: typing.Optio
+0000db50: 6e61 6c5b 7374 725d 203d 204e 6f6e 652c  nal[str] = None,
+0000db60: 0a20 2020 2020 2020 2070 7265 6669 785f  .        prefix_
+0000db70: 7365 7061 7261 746f 725f 6974 6572 6174  separator_iterat
+0000db80: 6f72 3a20 5072 6566 6978 5365 7061 7261  or: PrefixSepara
+0000db90: 746f 7249 7465 7261 746f 7220 3d20 4e6f  torIterator = No
+0000dba0: 6e65 2c0a 2020 2020 2920 2d3e 2052 6573  ne,.    ) -> Res
+0000dbb0: 706f 6e73 6557 7261 7070 6572 3a0a 2020  ponseWrapper:.  
+0000dbc0: 2020 2020 2020 2222 224d 616b 6573 2074        """Makes t
+0000dbd0: 6865 2048 5454 5020 7265 7175 6573 7420  he HTTP request 
+0000dbe0: 2873 796e 6368 726f 6e6f 7573 2920 616e  (synchronous) an
+0000dbf0: 6420 7265 7475 726e 7320 6465 7365 7269  d returns deseri
+0000dc00: 616c 697a 6564 2064 6174 612e 0a0a 2020  alized data...  
+0000dc10: 2020 2020 2020 3a70 6172 616d 2072 6573        :param res
+0000dc20: 6f75 7263 655f 7061 7468 3a20 5061 7468  ource_path: Path
+0000dc30: 2074 6f20 6d65 7468 6f64 2065 6e64 706f   to method endpo
+0000dc40: 696e 742e 0a20 2020 2020 2020 203a 7061  int..        :pa
+0000dc50: 7261 6d20 6d65 7468 6f64 3a20 4d65 7468  ram method: Meth
+0000dc60: 6f64 2074 6f20 6361 6c6c 2e0a 2020 2020  od to call..    
+0000dc70: 2020 2020 3a70 6172 616d 2068 6561 6465      :param heade
+0000dc80: 7273 3a20 4865 6164 6572 2070 6172 616d  rs: Header param
+0000dc90: 6574 6572 7320 746f 2062 650a 2020 2020  eters to be.    
+0000dca0: 2020 2020 2020 2020 706c 6163 6564 2069          placed i
+0000dcb0: 6e20 7468 6520 7265 7175 6573 7420 6865  n the request he
+0000dcc0: 6164 6572 2e0a 2020 2020 2020 2020 3a70  ader..        :p
+0000dcd0: 6172 616d 2062 6f64 793a 2052 6571 7565  aram body: Reque
+0000dce0: 7374 2062 6f64 792e 0a20 2020 2020 2020  st body..       
+0000dcf0: 203a 7061 7261 6d20 6669 656c 6473 3a20   :param fields: 
+0000dd00: 5265 7175 6573 7420 706f 7374 2066 6f72  Request post for
+0000dd10: 6d20 7061 7261 6d65 7465 7273 2c0a 2020  m parameters,.  
+0000dd20: 2020 2020 2020 2020 2020 666f 7220 6061            for `a
+0000dd30: 7070 6c69 6361 7469 6f6e 2f78 2d77 7777  pplication/x-www
+0000dd40: 2d66 6f72 6d2d 7572 6c65 6e63 6f64 6564  -form-urlencoded
+0000dd50: 602c 2060 6d75 6c74 6970 6172 742f 666f  `, `multipart/fo
+0000dd60: 726d 2d64 6174 6160 2e0a 2020 2020 2020  rm-data`..      
+0000dd70: 2020 3a70 6172 616d 2061 7574 685f 7365    :param auth_se
+0000dd80: 7474 696e 6773 3a20 4175 7468 2053 6574  ttings: Auth Set
+0000dd90: 7469 6e67 7320 6e61 6d65 7320 666f 7220  tings names for 
+0000dda0: 7468 6520 7265 7175 6573 742e 0a20 2020  the request..   
+0000ddb0: 2020 2020 203a 7061 7261 6d20 7374 7265       :param stre
+0000ddc0: 616d 3a20 6966 2054 7275 652c 2074 6865  am: if True, the
+0000ddd0: 2075 726c 6c69 6233 2e48 5454 5052 6573   urllib3.HTTPRes
+0000dde0: 706f 6e73 6520 6f62 6a65 6374 2077 696c  ponse object wil
+0000ddf0: 6c0a 2020 2020 2020 2020 2020 2020 2020  l.              
+0000de00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000de10: 2020 2062 6520 7265 7475 726e 6564 2077     be returned w
+0000de20: 6974 686f 7574 2072 6561 6469 6e67 2f64  ithout reading/d
+0000de30: 6563 6f64 696e 6720 7265 7370 6f6e 7365  ecoding response
+0000de40: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000de50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000de60: 2020 6461 7461 2e20 416c 736f 2077 6865    data. Also whe
+0000de70: 6e20 5472 7565 2c20 6966 2074 6865 206f  n True, if the o
+0000de80: 7065 6e61 7069 2073 7065 6320 6465 7363  penapi spec desc
+0000de90: 7269 6265 7320 6120 6669 6c65 2064 6f77  ribes a file dow
+0000dea0: 6e6c 6f61 642c 0a20 2020 2020 2020 2020  nload,.         
+0000deb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000dec0: 2020 2020 2020 2020 7468 6520 6461 7461          the data
+0000ded0: 2077 696c 6c20 6265 2077 7269 7474 656e   will be written
+0000dee0: 2074 6f20 6120 6c6f 6361 6c20 6669 6c65   to a local file
+0000def0: 7379 7374 6d65 2066 696c 6520 616e 6420  systme file and 
+0000df00: 7468 6520 4269 6e61 7279 5363 6865 6d61  the BinarySchema
+0000df10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000df20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000df30: 2020 696e 7374 616e 6365 2077 696c 6c20    instance will 
+0000df40: 616c 736f 2069 6e68 6572 6974 2066 726f  also inherit fro
+0000df50: 6d20 4669 6c65 5363 6865 6d61 2061 6e64  m FileSchema and
+0000df60: 2046 696c 6549 4f0a 2020 2020 2020 2020   FileIO.        
+0000df70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000df80: 2020 2020 2020 2020 2044 6566 6175 6c74           Default
+0000df90: 2069 7320 4661 6c73 652e 0a20 2020 2020   is False..     
+0000dfa0: 2020 203a 7479 7065 2073 7472 6561 6d3a     :type stream:
+0000dfb0: 2062 6f6f 6c2c 206f 7074 696f 6e61 6c0a   bool, optional.
+0000dfc0: 2020 2020 2020 2020 3a70 6172 616d 2074          :param t
+0000dfd0: 696d 656f 7574 3a20 7469 6d65 6f75 7420  imeout: timeout 
+0000dfe0: 7365 7474 696e 6720 666f 7220 7468 6973  setting for this
+0000dff0: 2072 6571 7565 7374 2e20 4966 206f 6e65   request. If one
+0000e000: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000e010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e020: 2020 6e75 6d62 6572 2070 726f 7669 6465    number provide
+0000e030: 642c 2069 7420 7769 6c6c 2062 6520 746f  d, it will be to
+0000e040: 7461 6c20 7265 7175 6573 740a 2020 2020  tal request.    
+0000e050: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e060: 2020 2020 2020 2020 2020 2020 2074 696d               tim
+0000e070: 656f 7574 2e20 4974 2063 616e 2061 6c73  eout. It can als
+0000e080: 6f20 6265 2061 2070 6169 7220 2874 7570  o be a pair (tup
+0000e090: 6c65 2920 6f66 0a20 2020 2020 2020 2020  le) of.         
+0000e0a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e0b0: 2020 2020 2020 2020 2863 6f6e 6e65 6374          (connect
+0000e0c0: 696f 6e2c 2072 6561 6429 2074 696d 656f  ion, read) timeo
+0000e0d0: 7574 732e 0a20 2020 2020 2020 203a 7061  uts..        :pa
+0000e0e0: 7261 6d20 686f 7374 3a20 6170 6920 656e  ram host: api en
+0000e0f0: 6470 6f69 6e74 2068 6f73 740a 2020 2020  dpoint host.    
+0000e100: 2020 2020 3a72 6574 7572 6e3a 2072 6573      :return: res
+0000e110: 706f 6e73 650a 2020 2020 2020 2020 2222  ponse.        ""
+0000e120: 220a 2020 2020 2020 2020 7265 7475 726e  ".        return
+0000e130: 2073 656c 662e 5f5f 6361 6c6c 5f61 7069   self.__call_api
+0000e140: 280a 2020 2020 2020 2020 2020 2020 7265  (.            re
+0000e150: 736f 7572 6365 5f70 6174 682c 0a20 2020  source_path,.   
+0000e160: 2020 2020 2020 2020 206d 6574 686f 642c           method,
+0000e170: 0a20 2020 2020 2020 2020 2020 2068 6561  .            hea
+0000e180: 6465 7273 2c0a 2020 2020 2020 2020 2020  ders,.          
+0000e190: 2020 7365 7269 616c 697a 6564 5f62 6f64    serialized_bod
+0000e1a0: 792c 0a20 2020 2020 2020 2020 2020 2062  y,.            b
+0000e1b0: 6f64 792c 0a20 2020 2020 2020 2020 2020  ody,.           
+0000e1c0: 2066 6965 6c64 732c 0a20 2020 2020 2020   fields,.       
+0000e1d0: 2020 2020 2061 7574 685f 7365 7474 696e       auth_settin
+0000e1e0: 6773 2c0a 2020 2020 2020 2020 2020 2020  gs,.            
+0000e1f0: 7374 7265 616d 2c0a 2020 2020 2020 2020  stream,.        
+0000e200: 2020 2020 7469 6d65 6f75 742c 0a20 2020      timeout,.   
+0000e210: 2020 2020 2020 2020 2068 6f73 742c 0a20           host,. 
+0000e220: 2020 2020 2020 2020 2020 2070 7265 6669             prefi
+0000e230: 785f 7365 7061 7261 746f 725f 6974 6572  x_separator_iter
+0000e240: 6174 6f72 2c0a 2020 2020 2020 2020 290a  ator,.        ).
+0000e250: 0a20 2020 2064 6566 2066 6965 6c64 735f  .    def fields_
+0000e260: 746f 5f64 6963 7428 7365 6c66 2c20 6669  to_dict(self, fi
+0000e270: 656c 6473 3a20 7479 7069 6e67 2e4f 7074  elds: typing.Opt
+0000e280: 696f 6e61 6c5b 7479 7069 6e67 2e54 7570  ional[typing.Tup
+0000e290: 6c65 5b74 7970 696e 672e 5475 706c 655b  le[typing.Tuple[
+0000e2a0: 7374 722c 2073 7472 5d2c 202e 2e2e 5d5d  str, str], ...]]
+0000e2b0: 293a 0a20 2020 2020 2020 2022 2222 436f  ):.        """Co
+0000e2c0: 6e76 6572 7473 2066 6965 6c64 7320 746f  nverts fields to
+0000e2d0: 2064 6963 742e 0a0a 2020 2020 2020 2020   dict...        
+0000e2e0: 3a70 6172 616d 2066 6965 6c64 733a 2066  :param fields: f
+0000e2f0: 6965 6c64 730a 2020 2020 2020 2020 3a72  ields.        :r
+0000e300: 6574 7572 6e3a 2064 6963 740a 2020 2020  eturn: dict.    
+0000e310: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+0000e320: 6966 2066 6965 6c64 7320 6973 204e 6f6e  if fields is Non
+0000e330: 653a 0a20 2020 2020 2020 2020 2020 2072  e:.            r
+0000e340: 6574 7572 6e20 4e6f 6e65 0a20 2020 2020  eturn None.     
+0000e350: 2020 2072 6574 7572 6e20 7b6b 3a20 7620     return {k: v 
+0000e360: 666f 7220 6b2c 2076 2069 6e20 6669 656c  for k, v in fiel
+0000e370: 6473 7d0a 0a20 2020 2061 7379 6e63 2064  ds}..    async d
+0000e380: 6566 2061 7379 6e63 5f72 6571 7565 7374  ef async_request
+0000e390: 280a 2020 2020 2020 2020 7365 6c66 2c0a  (.        self,.
+0000e3a0: 2020 2020 2020 2020 6d65 7468 6f64 3a20          method: 
+0000e3b0: 7374 722c 0a20 2020 2020 2020 2075 726c  str,.        url
+0000e3c0: 3a20 7374 722c 0a20 2020 2020 2020 2068  : str,.        h
+0000e3d0: 6561 6465 7273 3a20 7479 7069 6e67 2e4f  eaders: typing.O
+0000e3e0: 7074 696f 6e61 6c5b 4854 5450 4865 6164  ptional[HTTPHead
+0000e3f0: 6572 4469 6374 5d20 3d20 4e6f 6e65 2c0a  erDict] = None,.
+0000e400: 2020 2020 2020 2020 6669 656c 6473 3a20          fields: 
+0000e410: 7479 7069 6e67 2e4f 7074 696f 6e61 6c5b  typing.Optional[
+0000e420: 7479 7069 6e67 2e54 7570 6c65 5b74 7970  typing.Tuple[typ
+0000e430: 696e 672e 5475 706c 655b 7374 722c 2073  ing.Tuple[str, s
+0000e440: 7472 5d2c 202e 2e2e 5d5d 203d 204e 6f6e  tr], ...]] = Non
+0000e450: 652c 0a20 2020 2020 2020 2062 6f64 793a  e,.        body:
+0000e460: 2074 7970 696e 672e 4f70 7469 6f6e 616c   typing.Optional
+0000e470: 5b74 7970 696e 672e 556e 696f 6e5b 7374  [typing.Union[st
+0000e480: 722c 2062 7974 6573 5d5d 203d 204e 6f6e  r, bytes]] = Non
+0000e490: 652c 0a20 2020 2020 2020 2073 7472 6561  e,.        strea
+0000e4a0: 6d3a 2062 6f6f 6c20 3d20 4661 6c73 652c  m: bool = False,
+0000e4b0: 0a20 2020 2020 2020 2074 696d 656f 7574  .        timeout
+0000e4c0: 3a20 7479 7069 6e67 2e4f 7074 696f 6e61  : typing.Optiona
+0000e4d0: 6c5b 7479 7069 6e67 2e55 6e69 6f6e 5b66  l[typing.Union[f
+0000e4e0: 6c6f 6174 2c20 7479 7069 6e67 2e54 7570  loat, typing.Tup
+0000e4f0: 6c65 5d5d 203d 204e 6f6e 652c 0a20 2020  le]] = None,.   
+0000e500: 2020 2020 202a 2a6b 7761 7267 730a 2020       **kwargs.  
+0000e510: 2020 2920 2d3e 2041 7379 6e63 5265 7370    ) -> AsyncResp
+0000e520: 6f6e 7365 5772 6170 7065 723a 0a20 2020  onseWrapper:.   
+0000e530: 2020 2020 2069 6620 626f 6479 2061 6e64       if body and
+0000e540: 2066 6965 6c64 733a 0a20 2020 2020 2020   fields:.       
+0000e550: 2020 2020 2072 6169 7365 2041 7069 5661       raise ApiVa
+0000e560: 6c75 6545 7272 6f72 2822 626f 6479 2070  lueError("body p
+0000e570: 6172 616d 6574 6572 2063 616e 6e6f 7420  arameter cannot 
+0000e580: 6265 2075 7365 6420 7769 7468 2066 6965  be used with fie
+0000e590: 6c64 7320 7061 7261 6d65 7465 7222 290a  lds parameter").
+0000e5a0: 2020 2020 2020 2020 6461 7461 203d 204e          data = N
+0000e5b0: 6f6e 650a 2020 2020 2020 2020 6966 2062  one.        if b
+0000e5c0: 6f64 793a 0a20 2020 2020 2020 2020 2020  ody:.           
+0000e5d0: 2064 6174 613d 626f 6479 0a20 2020 2020   data=body.     
+0000e5e0: 2020 2069 6620 6669 656c 6473 3a0a 2020     if fields:.  
+0000e5f0: 2020 2020 2020 2020 2020 6461 7461 3d73            data=s
+0000e600: 656c 662e 6669 656c 6473 5f74 6f5f 6469  elf.fields_to_di
+0000e610: 6374 2866 6965 6c64 7329 0a20 2020 2020  ct(fields).     
+0000e620: 2020 2073 6573 7369 6f6e 203d 2061 696f     session = aio
+0000e630: 6874 7470 2e43 6c69 656e 7453 6573 7369  http.ClientSessi
+0000e640: 6f6e 2829 0a20 2020 2020 2020 2074 3120  on().        t1 
+0000e650: 3d20 7469 6d65 2e74 696d 6528 290a 2020  = time.time().  
+0000e660: 2020 2020 2020 6966 206d 6574 686f 6420        if method 
+0000e670: 3d3d 2022 4745 5422 3a0a 2020 2020 2020  == "GET":.      
+0000e680: 2020 2020 2020 7265 7370 6f6e 7365 203d        response =
+0000e690: 2061 7761 6974 2073 6573 7369 6f6e 2e67   await session.g
+0000e6a0: 6574 2875 726c 2c20 6865 6164 6572 733d  et(url, headers=
+0000e6b0: 6865 6164 6572 732c 2074 696d 656f 7574  headers, timeout
+0000e6c0: 3d74 696d 656f 7574 2c20 2a2a 6b77 6172  =timeout, **kwar
+0000e6d0: 6773 290a 2020 2020 2020 2020 2020 2020  gs).            
+0000e6e0: 7265 7475 726e 2041 7379 6e63 5265 7370  return AsyncResp
+0000e6f0: 6f6e 7365 5772 6170 7065 7228 7265 7370  onseWrapper(resp
+0000e700: 6f6e 7365 2c20 7469 6d65 2e74 696d 6528  onse, time.time(
+0000e710: 2920 2d20 7431 2c20 7365 7373 696f 6e29  ) - t1, session)
+0000e720: 0a20 2020 2020 2020 2065 6c69 6620 6d65  .        elif me
+0000e730: 7468 6f64 203d 3d20 2248 4541 4422 3a0a  thod == "HEAD":.
+0000e740: 2020 2020 2020 2020 2020 2020 7265 7370              resp
+0000e750: 6f6e 7365 203d 2061 7761 6974 2073 6573  onse = await ses
+0000e760: 7369 6f6e 2e68 6561 6428 7572 6c2c 2068  sion.head(url, h
+0000e770: 6561 6465 7273 3d68 6561 6465 7273 2c20  eaders=headers, 
+0000e780: 7469 6d65 6f75 743d 7469 6d65 6f75 742c  timeout=timeout,
+0000e790: 202a 2a6b 7761 7267 7329 0a20 2020 2020   **kwargs).     
+0000e7a0: 2020 2020 2020 2072 6574 7572 6e20 4173         return As
+0000e7b0: 796e 6352 6573 706f 6e73 6557 7261 7070  yncResponseWrapp
+0000e7c0: 6572 2872 6573 706f 6e73 652c 2074 696d  er(response, tim
+0000e7d0: 652e 7469 6d65 2829 202d 2074 312c 2073  e.time() - t1, s
+0000e7e0: 6573 7369 6f6e 290a 2020 2020 2020 2020  ession).        
+0000e7f0: 656c 6966 206d 6574 686f 6420 3d3d 2022  elif method == "
+0000e800: 4f50 5449 4f4e 5322 3a0a 2020 2020 2020  OPTIONS":.      
+0000e810: 2020 2020 2020 7265 7370 6f6e 7365 203d        response =
+0000e820: 2061 7761 6974 2073 6573 7369 6f6e 2e6f   await session.o
+0000e830: 7074 696f 6e73 2875 726c 2c20 6461 7461  ptions(url, data
+0000e840: 3d64 6174 612c 2068 6561 6465 7273 3d68  =data, headers=h
+0000e850: 6561 6465 7273 2c20 7469 6d65 6f75 743d  eaders, timeout=
+0000e860: 7469 6d65 6f75 742c 202a 2a6b 7761 7267  timeout, **kwarg
+0000e870: 7329 0a20 2020 2020 2020 2020 2020 2072  s).            r
+0000e880: 6574 7572 6e20 4173 796e 6352 6573 706f  eturn AsyncRespo
+0000e890: 6e73 6557 7261 7070 6572 2872 6573 706f  nseWrapper(respo
+0000e8a0: 6e73 652c 2074 696d 652e 7469 6d65 2829  nse, time.time()
+0000e8b0: 202d 2074 312c 2073 6573 7369 6f6e 290a   - t1, session).
+0000e8c0: 2020 2020 2020 2020 656c 6966 206d 6574          elif met
+0000e8d0: 686f 6420 3d3d 2022 504f 5354 223a 0a20  hod == "POST":. 
+0000e8e0: 2020 2020 2020 2020 2020 2072 6573 706f             respo
+0000e8f0: 6e73 6520 3d20 6177 6169 7420 7365 7373  nse = await sess
+0000e900: 696f 6e2e 706f 7374 2875 726c 2c20 6461  ion.post(url, da
+0000e910: 7461 3d64 6174 612c 2068 6561 6465 7273  ta=data, headers
+0000e920: 3d68 6561 6465 7273 2c20 7469 6d65 6f75  =headers, timeou
+0000e930: 743d 7469 6d65 6f75 742c 202a 2a6b 7761  t=timeout, **kwa
+0000e940: 7267 7329 0a20 2020 2020 2020 2020 2020  rgs).           
+0000e950: 2072 6574 7572 6e20 4173 796e 6352 6573   return AsyncRes
+0000e960: 706f 6e73 6557 7261 7070 6572 2872 6573  ponseWrapper(res
+0000e970: 706f 6e73 652c 2074 696d 652e 7469 6d65  ponse, time.time
+0000e980: 2829 202d 2074 312c 2073 6573 7369 6f6e  () - t1, session
+0000e990: 290a 2020 2020 2020 2020 656c 6966 206d  ).        elif m
+0000e9a0: 6574 686f 6420 3d3d 2022 5055 5422 3a0a  ethod == "PUT":.
+0000e9b0: 2020 2020 2020 2020 2020 2020 7265 7370              resp
+0000e9c0: 6f6e 7365 203d 2061 7761 6974 2073 6573  onse = await ses
+0000e9d0: 7369 6f6e 2e70 7574 2875 726c 2c20 6461  sion.put(url, da
+0000e9e0: 7461 3d64 6174 612c 2068 6561 6465 7273  ta=data, headers
+0000e9f0: 3d68 6561 6465 7273 2c20 7469 6d65 6f75  =headers, timeou
+0000ea00: 743d 7469 6d65 6f75 742c 202a 2a6b 7761  t=timeout, **kwa
+0000ea10: 7267 7329 0a20 2020 2020 2020 2020 2020  rgs).           
+0000ea20: 2072 6574 7572 6e20 4173 796e 6352 6573   return AsyncRes
+0000ea30: 706f 6e73 6557 7261 7070 6572 2872 6573  ponseWrapper(res
+0000ea40: 706f 6e73 652c 2074 696d 652e 7469 6d65  ponse, time.time
+0000ea50: 2829 202d 2074 312c 2073 6573 7369 6f6e  () - t1, session
+0000ea60: 290a 2020 2020 2020 2020 656c 6966 206d  ).        elif m
+0000ea70: 6574 686f 6420 3d3d 2022 5041 5443 4822  ethod == "PATCH"
+0000ea80: 3a0a 2020 2020 2020 2020 2020 2020 7265  :.            re
+0000ea90: 7370 6f6e 7365 203d 2061 7761 6974 2073  sponse = await s
+0000eaa0: 6573 7369 6f6e 2e70 6174 6368 2875 726c  ession.patch(url
+0000eab0: 2c20 6461 7461 3d64 6174 612c 2068 6561  , data=data, hea
+0000eac0: 6465 7273 3d68 6561 6465 7273 2c20 7469  ders=headers, ti
+0000ead0: 6d65 6f75 743d 7469 6d65 6f75 742c 202a  meout=timeout, *
+0000eae0: 2a6b 7761 7267 7329 0a20 2020 2020 2020  *kwargs).       
+0000eaf0: 2020 2020 2072 6574 7572 6e20 4173 796e       return Asyn
+0000eb00: 6352 6573 706f 6e73 6557 7261 7070 6572  cResponseWrapper
+0000eb10: 2872 6573 706f 6e73 652c 2074 696d 652e  (response, time.
+0000eb20: 7469 6d65 2829 202d 2074 312c 2073 6573  time() - t1, ses
+0000eb30: 7369 6f6e 290a 2020 2020 2020 2020 656c  sion).        el
+0000eb40: 6966 206d 6574 686f 6420 3d3d 2022 4445  if method == "DE
+0000eb50: 4c45 5445 223a 0a20 2020 2020 2020 2020  LETE":.         
+0000eb60: 2020 2072 6573 706f 6e73 6520 3d20 6177     response = aw
+0000eb70: 6169 7420 7365 7373 696f 6e2e 6465 6c65  ait session.dele
+0000eb80: 7465 2875 726c 2c20 6461 7461 3d64 6174  te(url, data=dat
+0000eb90: 612c 2068 6561 6465 7273 3d68 6561 6465  a, headers=heade
+0000eba0: 7273 2c20 7469 6d65 6f75 743d 7469 6d65  rs, timeout=time
+0000ebb0: 6f75 742c 202a 2a6b 7761 7267 7329 0a20  out, **kwargs). 
+0000ebc0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+0000ebd0: 6e20 4173 796e 6352 6573 706f 6e73 6557  n AsyncResponseW
+0000ebe0: 7261 7070 6572 2872 6573 706f 6e73 652c  rapper(response,
+0000ebf0: 2074 696d 652e 7469 6d65 2829 202d 2074   time.time() - t
+0000ec00: 312c 2073 6573 7369 6f6e 290a 2020 2020  1, session).    
+0000ec10: 2020 2020 7261 6973 6520 4170 6956 616c      raise ApiVal
+0000ec20: 7565 4572 726f 7228 0a20 2020 2020 2020  ueError(.       
+0000ec30: 2020 2020 2022 6874 7470 206d 6574 686f       "http metho
+0000ec40: 6420 6d75 7374 2062 6520 6047 4554 602c  d must be `GET`,
+0000ec50: 2060 4845 4144 602c 2060 4f50 5449 4f4e   `HEAD`, `OPTION
+0000ec60: 5360 2c22 0a20 2020 2020 2020 2020 2020  S`,".           
+0000ec70: 2022 2060 504f 5354 602c 2060 5041 5443   " `POST`, `PATC
+0000ec80: 4860 2c20 6050 5554 6020 6f72 2060 4445  H`, `PUT` or `DE
+0000ec90: 4c45 5445 602e 220a 2020 2020 2020 2020  LETE`.".        
+0000eca0: 290a 0a20 2020 2064 6566 2072 6571 7565  )..    def reque
+0000ecb0: 7374 280a 2020 2020 2020 2020 7365 6c66  st(.        self
+0000ecc0: 2c0a 2020 2020 2020 2020 6d65 7468 6f64  ,.        method
+0000ecd0: 3a20 7374 722c 0a20 2020 2020 2020 2075  : str,.        u
+0000ece0: 726c 3a20 7374 722c 0a20 2020 2020 2020  rl: str,.       
+0000ecf0: 2068 6561 6465 7273 3a20 7479 7069 6e67   headers: typing
+0000ed00: 2e4f 7074 696f 6e61 6c5b 4854 5450 4865  .Optional[HTTPHe
+0000ed10: 6164 6572 4469 6374 5d20 3d20 4e6f 6e65  aderDict] = None
+0000ed20: 2c0a 2020 2020 2020 2020 6669 656c 6473  ,.        fields
+0000ed30: 3a20 7479 7069 6e67 2e4f 7074 696f 6e61  : typing.Optiona
+0000ed40: 6c5b 7479 7069 6e67 2e54 7570 6c65 5b74  l[typing.Tuple[t
+0000ed50: 7970 696e 672e 5475 706c 655b 7374 722c  yping.Tuple[str,
+0000ed60: 2073 7472 5d2c 202e 2e2e 5d5d 203d 204e   str], ...]] = N
+0000ed70: 6f6e 652c 0a20 2020 2020 2020 2062 6f64  one,.        bod
+0000ed80: 793a 2074 7970 696e 672e 4f70 7469 6f6e  y: typing.Option
+0000ed90: 616c 5b74 7970 696e 672e 556e 696f 6e5b  al[typing.Union[
+0000eda0: 7374 722c 2062 7974 6573 5d5d 203d 204e  str, bytes]] = N
+0000edb0: 6f6e 652c 0a20 2020 2020 2020 2073 7472  one,.        str
+0000edc0: 6561 6d3a 2062 6f6f 6c20 3d20 4661 6c73  eam: bool = Fals
+0000edd0: 652c 0a20 2020 2020 2020 2074 696d 656f  e,.        timeo
+0000ede0: 7574 3a20 7479 7069 6e67 2e4f 7074 696f  ut: typing.Optio
+0000edf0: 6e61 6c5b 7479 7069 6e67 2e55 6e69 6f6e  nal[typing.Union
+0000ee00: 5b66 6c6f 6174 2c20 7479 7069 6e67 2e54  [float, typing.T
+0000ee10: 7570 6c65 5d5d 203d 204e 6f6e 652c 0a20  uple]] = None,. 
+0000ee20: 2020 2029 202d 3e20 5265 7370 6f6e 7365     ) -> Response
+0000ee30: 5772 6170 7065 723a 0a20 2020 2020 2020  Wrapper:.       
+0000ee40: 2022 2222 4d61 6b65 7320 7468 6520 4854   """Makes the HT
+0000ee50: 5450 2072 6571 7565 7374 2075 7369 6e67  TP request using
+0000ee60: 2052 4553 5443 6c69 656e 742e 2222 220a   RESTClient.""".
+0000ee70: 2020 2020 2020 2020 6966 206d 6574 686f          if metho
+0000ee80: 6420 3d3d 2022 4745 5422 3a0a 2020 2020  d == "GET":.    
+0000ee90: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+0000eea0: 656c 662e 7265 7374 5f63 6c69 656e 742e  elf.rest_client.
+0000eeb0: 4745 5428 7572 6c2c 0a20 2020 2020 2020  GET(url,.       
+0000eec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000eed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000eee0: 2073 7472 6561 6d3d 7374 7265 616d 2c0a   stream=stream,.
+0000eef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ef00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ef10: 2020 2020 2020 2020 7469 6d65 6f75 743d          timeout=
+0000ef20: 7469 6d65 6f75 742c 0a20 2020 2020 2020  timeout,.       
+0000ef30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ef40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ef50: 2068 6561 6465 7273 3d68 6561 6465 7273   headers=headers
+0000ef60: 290a 2020 2020 2020 2020 656c 6966 206d  ).        elif m
+0000ef70: 6574 686f 6420 3d3d 2022 4845 4144 223a  ethod == "HEAD":
+0000ef80: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+0000ef90: 7572 6e20 7365 6c66 2e72 6573 745f 636c  urn self.rest_cl
+0000efa0: 6965 6e74 2e48 4541 4428 7572 6c2c 0a20  ient.HEAD(url,. 
+0000efb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000efc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000efd0: 2020 2020 2020 2020 7374 7265 616d 3d73          stream=s
+0000efe0: 7472 6561 6d2c 0a20 2020 2020 2020 2020  tream,.         
+0000eff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f000: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f010: 7469 6d65 6f75 743d 7469 6d65 6f75 742c  timeout=timeout,
+0000f020: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000f030: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f040: 2020 2020 2020 2020 2020 6865 6164 6572            header
+0000f050: 733d 6865 6164 6572 7329 0a20 2020 2020  s=headers).     
+0000f060: 2020 2065 6c69 6620 6d65 7468 6f64 203d     elif method =
+0000f070: 3d20 224f 5054 494f 4e53 223a 0a20 2020  = "OPTIONS":.   
+0000f080: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+0000f090: 7365 6c66 2e72 6573 745f 636c 6965 6e74  self.rest_client
+0000f0a0: 2e4f 5054 494f 4e53 2875 726c 2c0a 2020  .OPTIONS(url,.  
+0000f0b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f0c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f0d0: 2020 2020 2020 2020 2020 6865 6164 6572            header
+0000f0e0: 733d 6865 6164 6572 732c 0a20 2020 2020  s=headers,.     
+0000f0f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f100: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f110: 2020 2020 2020 2066 6965 6c64 733d 6669         fields=fi
+0000f120: 656c 6473 2c0a 2020 2020 2020 2020 2020  elds,.          
+0000f130: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f140: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f150: 2020 7374 7265 616d 3d73 7472 6561 6d2c    stream=stream,
+0000f160: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000f170: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f180: 2020 2020 2020 2020 2020 2020 2074 696d               tim
+0000f190: 656f 7574 3d74 696d 656f 7574 2c0a 2020  eout=timeout,.  
+0000f1a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f1b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f1c0: 2020 2020 2020 2020 2020 626f 6479 3d62            body=b
+0000f1d0: 6f64 7929 0a20 2020 2020 2020 2065 6c69  ody).        eli
+0000f1e0: 6620 6d65 7468 6f64 203d 3d20 2250 4f53  f method == "POS
+0000f1f0: 5422 3a0a 2020 2020 2020 2020 2020 2020  T":.            
+0000f200: 7265 7475 726e 2073 656c 662e 7265 7374  return self.rest
+0000f210: 5f63 6c69 656e 742e 504f 5354 2875 726c  _client.POST(url
+0000f220: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000f230: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f240: 2020 2020 2020 2020 2020 2068 6561 6465             heade
+0000f250: 7273 3d68 6561 6465 7273 2c0a 2020 2020  rs=headers,.    
+0000f260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f270: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f280: 2020 2020 2066 6965 6c64 733d 6669 656c       fields=fiel
+0000f290: 6473 2c0a 2020 2020 2020 2020 2020 2020  ds,.            
+0000f2a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f2b0: 2020 2020 2020 2020 2020 2020 2073 7472               str
+0000f2c0: 6561 6d3d 7374 7265 616d 2c0a 2020 2020  eam=stream,.    
+0000f2d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f2e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f2f0: 2020 2020 2074 696d 656f 7574 3d74 696d       timeout=tim
+0000f300: 656f 7574 2c0a 2020 2020 2020 2020 2020  eout,.          
+0000f310: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f320: 2020 2020 2020 2020 2020 2020 2020 2062                 b
+0000f330: 6f64 793d 626f 6479 290a 2020 2020 2020  ody=body).      
+0000f340: 2020 656c 6966 206d 6574 686f 6420 3d3d    elif method ==
+0000f350: 2022 5055 5422 3a0a 2020 2020 2020 2020   "PUT":.        
+0000f360: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
+0000f370: 7265 7374 5f63 6c69 656e 742e 5055 5428  rest_client.PUT(
+0000f380: 7572 6c2c 0a20 2020 2020 2020 2020 2020  url,.           
+0000f390: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f3a0: 2020 2020 2020 2020 2020 2020 2068 6561               hea
+0000f3b0: 6465 7273 3d68 6561 6465 7273 2c0a 2020  ders=headers,.  
+0000f3c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f3d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f3e0: 2020 2020 2020 6669 656c 6473 3d66 6965        fields=fie
+0000f3f0: 6c64 732c 0a20 2020 2020 2020 2020 2020  lds,.           
+0000f400: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f410: 2020 2020 2020 2020 2020 2020 2073 7472               str
+0000f420: 6561 6d3d 7374 7265 616d 2c0a 2020 2020  eam=stream,.    
+0000f430: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f450: 2020 2020 7469 6d65 6f75 743d 7469 6d65      timeout=time
+0000f460: 6f75 742c 0a20 2020 2020 2020 2020 2020  out,.           
+0000f470: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f480: 2020 2020 2020 2020 2020 2020 2062 6f64               bod
+0000f490: 793d 626f 6479 290a 2020 2020 2020 2020  y=body).        
+0000f4a0: 656c 6966 206d 6574 686f 6420 3d3d 2022  elif method == "
+0000f4b0: 5041 5443 4822 3a0a 2020 2020 2020 2020  PATCH":.        
+0000f4c0: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
+0000f4d0: 7265 7374 5f63 6c69 656e 742e 5041 5443  rest_client.PATC
+0000f4e0: 4828 7572 6c2c 0a20 2020 2020 2020 2020  H(url,.         
+0000f4f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f500: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f510: 2068 6561 6465 7273 3d68 6561 6465 7273   headers=headers
+0000f520: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000f530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f540: 2020 2020 2020 2020 2020 2020 6669 656c              fiel
+0000f550: 6473 3d66 6965 6c64 732c 0a20 2020 2020  ds=fields,.     
+0000f560: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f570: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f580: 2020 2020 2073 7472 6561 6d3d 7374 7265       stream=stre
+0000f590: 616d 2c0a 2020 2020 2020 2020 2020 2020  am,.            
+0000f5a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f5b0: 2020 2020 2020 2020 2020 2020 2020 7469                ti
+0000f5c0: 6d65 6f75 743d 7469 6d65 6f75 742c 0a20  meout=timeout,. 
+0000f5d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f5e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f5f0: 2020 2020 2020 2020 2062 6f64 793d 626f           body=bo
+0000f600: 6479 290a 2020 2020 2020 2020 656c 6966  dy).        elif
+0000f610: 206d 6574 686f 6420 3d3d 2022 4445 4c45   method == "DELE
+0000f620: 5445 223a 0a20 2020 2020 2020 2020 2020  TE":.           
+0000f630: 2072 6574 7572 6e20 7365 6c66 2e72 6573   return self.res
+0000f640: 745f 636c 6965 6e74 2e44 454c 4554 4528  t_client.DELETE(
+0000f650: 7572 6c2c 0a20 2020 2020 2020 2020 2020  url,.           
+0000f660: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f670: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f680: 6865 6164 6572 733d 6865 6164 6572 732c  headers=headers,
+0000f690: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000f6a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f6b0: 2020 2020 2020 2020 2020 2020 7374 7265              stre
+0000f6c0: 616d 3d73 7472 6561 6d2c 0a20 2020 2020  am=stream,.     
+0000f6d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f6e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f6f0: 2020 2020 2020 7469 6d65 6f75 743d 7469        timeout=ti
+0000f700: 6d65 6f75 742c 0a20 2020 2020 2020 2020  meout,.         
+0000f710: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f720: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f730: 2020 626f 6479 3d62 6f64 7929 0a20 2020    body=body).   
+0000f740: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+0000f750: 2020 2020 2020 2072 6169 7365 2041 7069         raise Api
+0000f760: 5661 6c75 6545 7272 6f72 280a 2020 2020  ValueError(.    
+0000f770: 2020 2020 2020 2020 2020 2020 2268 7474              "htt
+0000f780: 7020 6d65 7468 6f64 206d 7573 7420 6265  p method must be
+0000f790: 2060 4745 5460 2c20 6048 4541 4460 2c20   `GET`, `HEAD`, 
+0000f7a0: 604f 5054 494f 4e53 602c 220a 2020 2020  `OPTIONS`,".    
+0000f7b0: 2020 2020 2020 2020 2020 2020 2220 6050              " `P
+0000f7c0: 4f53 5460 2c20 6050 4154 4348 602c 2060  OST`, `PATCH`, `
+0000f7d0: 5055 5460 206f 7220 6044 454c 4554 4560  PUT` or `DELETE`
+0000f7e0: 2e22 0a20 2020 2020 2020 2020 2020 2029  .".            )
+0000f7f0: 0a0a 2020 2020 6465 6620 7570 6461 7465  ..    def update
+0000f800: 5f70 6172 616d 735f 666f 725f 6175 7468  _params_for_auth
+0000f810: 280a 2020 2020 2020 2020 2020 2020 7365  (.            se
+0000f820: 6c66 2c0a 2020 2020 2020 2020 2020 2020  lf,.            
+0000f830: 6865 6164 6572 732c 0a20 2020 2020 2020  headers,.       
+0000f840: 2020 2020 2061 7574 685f 7365 7474 696e       auth_settin
+0000f850: 6773 2c0a 2020 2020 2020 2020 2020 2020  gs,.            
+0000f860: 7265 736f 7572 6365 5f70 6174 682c 0a20  resource_path,. 
+0000f870: 2020 2020 2020 2020 2020 206d 6574 686f             metho
+0000f880: 642c 0a20 2020 2020 2020 2020 2020 2062  d,.            b
+0000f890: 6f64 792c 0a20 2020 2020 2020 2020 2020  ody,.           
+0000f8a0: 2070 7265 6669 785f 7365 7061 7261 746f   prefix_separato
+0000f8b0: 725f 6974 6572 6174 6f72 3a20 5072 6566  r_iterator: Pref
+0000f8c0: 6978 5365 7061 7261 746f 7249 7465 7261  ixSeparatorItera
+0000f8d0: 746f 7220 3d20 4e6f 6e65 0a20 2020 2020  tor = None.     
+0000f8e0: 2020 2029 202d 3e20 7374 723a 0a20 2020     ) -> str:.   
+0000f8f0: 2020 2020 2022 2222 5570 6461 7465 7320       """Updates 
+0000f900: 6865 6164 6572 2061 6e64 2071 7565 7279  header and query
+0000f910: 2070 6172 616d 7320 6261 7365 6420 6f6e   params based on
+0000f920: 2061 7574 6865 6e74 6963 6174 696f 6e20   authentication 
+0000f930: 7365 7474 696e 672e 0a0a 2020 2020 2020  setting...      
+0000f940: 2020 3a70 6172 616d 2068 6561 6465 7273    :param headers
+0000f950: 3a20 4865 6164 6572 2070 6172 616d 6574  : Header paramet
+0000f960: 6572 7320 6469 6374 2074 6f20 6265 2075  ers dict to be u
+0000f970: 7064 6174 6564 2e0a 2020 2020 2020 2020  pdated..        
+0000f980: 3a70 6172 616d 2061 7574 685f 7365 7474  :param auth_sett
+0000f990: 696e 6773 3a20 4175 7468 656e 7469 6361  ings: Authentica
+0000f9a0: 7469 6f6e 2073 6574 7469 6e67 2069 6465  tion setting ide
+0000f9b0: 6e74 6966 6965 7273 206c 6973 742e 0a20  ntifiers list.. 
+0000f9c0: 2020 2020 2020 203a 7061 7261 6d20 7265         :param re
+0000f9d0: 736f 7572 6365 5f70 6174 683a 2041 2073  source_path: A s
+0000f9e0: 7472 696e 6720 7265 7072 6573 656e 7461  tring representa
+0000f9f0: 7469 6f6e 206f 6620 7468 6520 4854 5450  tion of the HTTP
+0000fa00: 2072 6571 7565 7374 2072 6573 6f75 7263   request resourc
+0000fa10: 6520 7061 7468 2e0a 2020 2020 2020 2020  e path..        
+0000fa20: 3a70 6172 616d 206d 6574 686f 643a 2041  :param method: A
+0000fa30: 2073 7472 696e 6720 7265 7072 6573 656e   string represen
+0000fa40: 7461 7469 6f6e 206f 6620 7468 6520 4854  tation of the HT
+0000fa50: 5450 2072 6571 7565 7374 206d 6574 686f  TP request metho
+0000fa60: 642e 0a20 2020 2020 2020 203a 7061 7261  d..        :para
+0000fa70: 6d20 626f 6479 3a20 4120 6f62 6a65 6374  m body: A object
+0000fa80: 2072 6570 7265 7365 6e74 696e 6720 7468   representing th
+0000fa90: 6520 626f 6479 206f 6620 7468 6520 4854  e body of the HT
+0000faa0: 5450 2072 6571 7565 7374 2e0a 2020 2020  TP request..    
+0000fab0: 2020 2020 2020 2020 5468 6520 6f62 6a65          The obje
+0000fac0: 6374 2074 7970 6520 6973 2074 6865 2072  ct type is the r
+0000fad0: 6574 7572 6e20 7661 6c75 6520 6f66 205f  eturn value of _
+0000fae0: 656e 636f 6465 722e 6465 6661 756c 7428  encoder.default(
+0000faf0: 292e 0a20 2020 2020 2020 2022 2222 0a20  )..        """. 
+0000fb00: 2020 2020 2020 2069 6620 6e6f 7420 6175         if not au
+0000fb10: 7468 5f73 6574 7469 6e67 733a 0a20 2020  th_settings:.   
+0000fb20: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+0000fb30: 7265 736f 7572 6365 5f70 6174 680a 2020  resource_path.  
+0000fb40: 2020 2020 2020 6966 2070 7265 6669 785f        if prefix_
+0000fb50: 7365 7061 7261 746f 725f 6974 6572 6174  separator_iterat
+0000fb60: 6f72 2069 7320 4e6f 6e65 3a0a 2020 2020  or is None:.    
+0000fb70: 2020 2020 2020 2020 7072 6566 6978 5f73          prefix_s
+0000fb80: 6570 6172 6174 6f72 5f69 7465 7261 746f  eparator_iterato
+0000fb90: 7220 3d20 5072 6566 6978 5365 7061 7261  r = PrefixSepara
+0000fba0: 746f 7249 7465 7261 746f 7228 223f 222c  torIterator("?",
+0000fbb0: 2022 2622 290a 0a20 2020 2020 2020 2066   "&")..        f
+0000fbc0: 6f72 2061 7574 6820 696e 2061 7574 685f  or auth in auth_
+0000fbd0: 7365 7474 696e 6773 3a0a 2020 2020 2020  settings:.      
+0000fbe0: 2020 2020 2020 6175 7468 5f73 6574 7469        auth_setti
+0000fbf0: 6e67 203d 2073 656c 662e 636f 6e66 6967  ng = self.config
+0000fc00: 7572 6174 696f 6e2e 6175 7468 5f73 6574  uration.auth_set
+0000fc10: 7469 6e67 7328 292e 6765 7428 6175 7468  tings().get(auth
+0000fc20: 290a 2020 2020 2020 2020 2020 2020 6966  ).            if
+0000fc30: 206e 6f74 2061 7574 685f 7365 7474 696e   not auth_settin
+0000fc40: 673a 0a20 2020 2020 2020 2020 2020 2020  g:.             
+0000fc50: 2020 2063 6f6e 7469 6e75 650a 2020 2020     continue.    
+0000fc60: 2020 2020 2020 2020 6966 2061 7574 685f          if auth_
+0000fc70: 7365 7474 696e 675b 2769 6e27 5d20 3d3d  setting['in'] ==
+0000fc80: 2027 636f 6f6b 6965 273a 0a20 2020 2020   'cookie':.     
+0000fc90: 2020 2020 2020 2020 2020 2068 6561 6465             heade
+0000fca0: 7273 2e61 6464 2827 436f 6f6b 6965 272c  rs.add('Cookie',
+0000fcb0: 2061 7574 685f 7365 7474 696e 675b 2776   auth_setting['v
+0000fcc0: 616c 7565 275d 290a 2020 2020 2020 2020  alue']).        
+0000fcd0: 2020 2020 656c 6966 2061 7574 685f 7365      elif auth_se
+0000fce0: 7474 696e 675b 2769 6e27 5d20 3d3d 2027  tting['in'] == '
+0000fcf0: 6865 6164 6572 273a 0a20 2020 2020 2020  header':.       
+0000fd00: 2020 2020 2020 2020 2069 6620 6175 7468           if auth
+0000fd10: 5f73 6574 7469 6e67 5b27 7479 7065 275d  _setting['type']
+0000fd20: 2021 3d20 2768 7474 702d 7369 676e 6174   != 'http-signat
+0000fd30: 7572 6527 3a0a 2020 2020 2020 2020 2020  ure':.          
+0000fd40: 2020 2020 2020 2020 2020 6865 6164 6572            header
+0000fd50: 732e 6164 6428 6175 7468 5f73 6574 7469  s.add(auth_setti
+0000fd60: 6e67 5b27 6b65 7927 5d2c 2061 7574 685f  ng['key'], auth_
+0000fd70: 7365 7474 696e 675b 2776 616c 7565 275d  setting['value']
+0000fd80: 290a 2020 2020 2020 2020 2020 2020 656c  ).            el
+0000fd90: 6966 2061 7574 685f 7365 7474 696e 675b  if auth_setting[
+0000fda0: 2769 6e27 5d20 3d3d 2027 7175 6572 7927  'in'] == 'query'
+0000fdb0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0000fdc0: 2020 2222 2220 544f 444f 2069 6d70 6c65    """ TODO imple
+0000fdd0: 6d65 6e74 2061 7574 6820 696e 2071 7565  ment auth in que
+0000fde0: 7279 0a20 2020 2020 2020 2020 2020 2020  ry.             
+0000fdf0: 2020 206e 6565 6420 746f 2070 6173 7320     need to pass 
+0000fe00: 696e 2070 7265 6669 785f 7365 7061 7261  in prefix_separa
+0000fe10: 746f 725f 6974 6572 6174 6f72 0a20 2020  tor_iterator.   
+0000fe20: 2020 2020 2020 2020 2020 2020 2061 6e64               and
+0000fe30: 206e 6565 6420 746f 206f 7574 7075 7420   need to output 
+0000fe40: 7265 736f 7572 6365 5f70 6174 6820 7769  resource_path wi
+0000fe50: 7468 2071 7565 7279 2070 6172 616d 7320  th query params 
+0000fe60: 6164 6465 640a 2020 2020 2020 2020 2020  added.          
+0000fe70: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+0000fe80: 2020 2020 2020 2020 2020 7265 736f 7572            resour
+0000fe90: 6365 5f70 6174 6820 2b3d 2050 6172 616d  ce_path += Param
+0000fea0: 6574 6572 5365 7269 616c 697a 6572 4261  eterSerializerBa
+0000feb0: 7365 2e5f 7265 6636 3537 305f 6578 7061  se._ref6570_expa
+0000fec0: 6e73 696f 6e28 0a20 2020 2020 2020 2020  nsion(.         
+0000fed0: 2020 2020 2020 2020 2020 2076 6172 6961             varia
+0000fee0: 626c 655f 6e61 6d65 3d61 7574 685f 7365  ble_name=auth_se
+0000fef0: 7474 696e 675b 276b 6579 275d 2c0a 2020  tting['key'],.  
+0000ff00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ff10: 2020 696e 5f64 6174 613d 6175 7468 5f73    in_data=auth_s
+0000ff20: 6574 7469 6e67 5b27 7661 6c75 6527 5d2c  etting['value'],
+0000ff30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000ff40: 2020 2020 2065 7870 6c6f 6465 3d46 616c       explode=Fal
+0000ff50: 7365 2c0a 2020 2020 2020 2020 2020 2020  se,.            
+0000ff60: 2020 2020 2020 2020 7065 7263 656e 745f          percent_
+0000ff70: 656e 636f 6465 3d46 616c 7365 2c0a 2020  encode=False,.  
+0000ff80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ff90: 2020 7072 6566 6978 5f73 6570 6172 6174    prefix_separat
+0000ffa0: 6f72 5f69 7465 7261 746f 723d 7072 6566  or_iterator=pref
+0000ffb0: 6978 5f73 6570 6172 6174 6f72 5f69 7465  ix_separator_ite
+0000ffc0: 7261 746f 720a 2020 2020 2020 2020 2020  rator.          
+0000ffd0: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+0000ffe0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+0000fff0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+00010000: 4170 6956 616c 7565 4572 726f 7228 0a20  ApiValueError(. 
+00010010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010020: 2020 2027 4175 7468 656e 7469 6361 7469     'Authenticati
+00010030: 6f6e 2074 6f6b 656e 206d 7573 7420 6265  on token must be
+00010040: 2069 6e20 6071 7565 7279 6020 6f72 2060   in `query` or `
+00010050: 6865 6164 6572 6027 0a20 2020 2020 2020  header`'.       
+00010060: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
+00010070: 2020 2072 6574 7572 6e20 7265 736f 7572     return resour
+00010080: 6365 5f70 6174 680a 0a0a 636c 6173 7320  ce_path...class 
+00010090: 4170 693a 0a20 2020 2022 2222 4e4f 5445  Api:.    """NOTE
+000100a0: 3a0a 2020 2020 5468 6973 2063 6c61 7373  :.    This class
+000100b0: 2069 7320 6175 746f 2067 656e 6572 6174   is auto generat
+000100c0: 6564 2062 7920 4b6f 6e66 6967 2028 6874  ed by Konfig (ht
+000100d0: 7470 733a 2f2f 6b6f 6e66 6967 7468 6973  tps://konfigthis
+000100e0: 2e63 6f6d 290a 2020 2020 2222 220a 0a20  .com).    """.. 
+000100f0: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
+00010100: 7365 6c66 2c20 6170 695f 636c 6965 6e74  self, api_client
+00010110: 3a20 7479 7069 6e67 2e4f 7074 696f 6e61  : typing.Optiona
+00010120: 6c5b 4170 6943 6c69 656e 745d 203d 204e  l[ApiClient] = N
+00010130: 6f6e 6529 3a0a 2020 2020 2020 2020 6966  one):.        if
+00010140: 2061 7069 5f63 6c69 656e 7420 6973 204e   api_client is N
+00010150: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
+00010160: 2061 7069 5f63 6c69 656e 7420 3d20 4170   api_client = Ap
+00010170: 6943 6c69 656e 7428 290a 2020 2020 2020  iClient().      
+00010180: 2020 7365 6c66 2e61 7069 5f63 6c69 656e    self.api_clien
+00010190: 7420 3d20 6170 695f 636c 6965 6e74 0a0a  t = api_client..
+000101a0: 2020 2020 4073 7461 7469 636d 6574 686f      @staticmetho
+000101b0: 640a 2020 2020 6465 6620 5f76 6572 6966  d.    def _verif
+000101c0: 795f 7479 7065 645f 6469 6374 5f69 6e70  y_typed_dict_inp
+000101d0: 7574 735f 6f61 7067 2863 6c73 3a20 7479  uts_oapg(cls: ty
+000101e0: 7069 6e67 2e54 7970 655b 7479 7069 6e67  ping.Type[typing
+000101f0: 5f65 7874 656e 7369 6f6e 732e 5479 7065  _extensions.Type
+00010200: 6444 6963 745d 2c20 6461 7461 3a20 7479  dDict], data: ty
+00010210: 7069 6e67 2e44 6963 745b 7374 722c 2074  ping.Dict[str, t
+00010220: 7970 696e 672e 416e 795d 293a 0a20 2020  yping.Any]):.   
+00010230: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
+00010240: 2045 6e73 7572 6573 2074 6861 743a 0a20   Ensures that:. 
+00010250: 2020 2020 2020 202d 2072 6571 7569 7265         - require
+00010260: 6420 6b65 7973 2061 7265 2070 7265 7365  d keys are prese
+00010270: 6e74 0a20 2020 2020 2020 202d 2061 6464  nt.        - add
+00010280: 6974 696f 6e61 6c20 7072 6f70 6572 7469  itional properti
+00010290: 6573 2061 7265 206e 6f74 2069 6e70 7574  es are not input
+000102a0: 0a20 2020 2020 2020 202d 2076 616c 7565  .        - value
+000102b0: 2073 746f 7265 6420 756e 6465 7220 7265   stored under re
+000102c0: 7175 6972 6564 206b 6579 7320 646f 206e  quired keys do n
+000102d0: 6f74 2068 6176 6520 7468 6520 7661 6c75  ot have the valu
+000102e0: 6520 756e 7365 740a 2020 2020 2020 2020  e unset.        
+000102f0: 4e6f 7465 3a20 6465 7461 696c 6564 2076  Note: detailed v
+00010300: 616c 7565 2063 6865 636b 696e 6720 6973  alue checking is
+00010310: 2064 6f6e 6520 696e 2073 6368 656d 6120   done in schema 
+00010320: 636c 6173 7365 730a 2020 2020 2020 2020  classes.        
+00010330: 2222 220a 2020 2020 2020 2020 6d69 7373  """.        miss
+00010340: 696e 675f 7265 7175 6972 6564 5f6b 6579  ing_required_key
+00010350: 7320 3d20 5b5d 0a20 2020 2020 2020 2072  s = [].        r
+00010360: 6571 7569 7265 645f 6b65 7973 5f77 6974  equired_keys_wit
+00010370: 685f 756e 7365 745f 7661 6c75 6573 203d  h_unset_values =
+00010380: 205b 5d0a 2020 2020 2020 2020 666f 7220   [].        for 
+00010390: 7265 7175 6972 6564 5f6b 6579 2069 6e20  required_key in 
+000103a0: 636c 732e 5f5f 7265 7175 6972 6564 5f6b  cls.__required_k
+000103b0: 6579 735f 5f3a 0a20 2020 2020 2020 2020  eys__:.         
+000103c0: 2020 2069 6620 7265 7175 6972 6564 5f6b     if required_k
+000103d0: 6579 206e 6f74 2069 6e20 6461 7461 3a0a  ey not in data:.
+000103e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000103f0: 6d69 7373 696e 675f 7265 7175 6972 6564  missing_required
+00010400: 5f6b 6579 732e 6170 7065 6e64 2872 6571  _keys.append(req
+00010410: 7569 7265 645f 6b65 7929 0a20 2020 2020  uired_key).     
+00010420: 2020 2020 2020 2020 2020 2063 6f6e 7469             conti
+00010430: 6e75 650a 2020 2020 2020 2020 2020 2020  nue.            
+00010440: 7661 6c75 6520 3d20 6461 7461 5b72 6571  value = data[req
+00010450: 7569 7265 645f 6b65 795d 0a20 2020 2020  uired_key].     
+00010460: 2020 2020 2020 2069 6620 7661 6c75 6520         if value 
+00010470: 6973 2075 6e73 6574 3a0a 2020 2020 2020  is unset:.      
+00010480: 2020 2020 2020 2020 2020 7265 7175 6972            requir
+00010490: 6564 5f6b 6579 735f 7769 7468 5f75 6e73  ed_keys_with_uns
+000104a0: 6574 5f76 616c 7565 732e 6170 7065 6e64  et_values.append
+000104b0: 2872 6571 7569 7265 645f 6b65 7929 0a20  (required_key). 
+000104c0: 2020 2020 2020 2069 6620 6d69 7373 696e         if missin
+000104d0: 675f 7265 7175 6972 6564 5f6b 6579 733a  g_required_keys:
+000104e0: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
+000104f0: 7365 2041 7069 5479 7065 4572 726f 7228  se ApiTypeError(
+00010500: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00010510: 2027 7b7d 206d 6973 7369 6e67 207b 7d20   '{} missing {} 
+00010520: 7265 7175 6972 6564 2061 7267 756d 656e  required argumen
+00010530: 7473 3a20 7b7d 272e 666f 726d 6174 280a  ts: {}'.format(.
+00010540: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010550: 2020 2020 636c 732e 5f5f 6e61 6d65 5f5f      cls.__name__
+00010560: 2c20 6c65 6e28 6d69 7373 696e 675f 7265  , len(missing_re
+00010570: 7175 6972 6564 5f6b 6579 7329 2c20 6d69  quired_keys), mi
+00010580: 7373 696e 675f 7265 7175 6972 6564 5f6b  ssing_required_k
+00010590: 6579 730a 2020 2020 2020 2020 2020 2020  eys.            
+000105a0: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
+000105b0: 2020 2020 290a 2020 2020 2020 2020 6966      ).        if
+000105c0: 2072 6571 7569 7265 645f 6b65 7973 5f77   required_keys_w
+000105d0: 6974 685f 756e 7365 745f 7661 6c75 6573  ith_unset_values
+000105e0: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
+000105f0: 6973 6520 4170 6956 616c 7565 4572 726f  ise ApiValueErro
+00010600: 7228 0a20 2020 2020 2020 2020 2020 2020  r(.             
+00010610: 2020 2027 7b7d 2063 6f6e 7461 696e 7320     '{} contains 
+00010620: 696e 7661 6c69 6420 756e 7365 7420 7661  invalid unset va
+00010630: 6c75 6573 2066 6f72 207b 7d20 7265 7175  lues for {} requ
+00010640: 6972 6564 206b 6579 733a 207b 7d27 2e66  ired keys: {}'.f
+00010650: 6f72 6d61 7428 0a20 2020 2020 2020 2020  ormat(.         
+00010660: 2020 2020 2020 2020 2020 2063 6c73 2e5f             cls._
+00010670: 5f6e 616d 655f 5f2c 206c 656e 2872 6571  _name__, len(req
+00010680: 7569 7265 645f 6b65 7973 5f77 6974 685f  uired_keys_with_
+00010690: 756e 7365 745f 7661 6c75 6573 292c 2072  unset_values), r
+000106a0: 6571 7569 7265 645f 6b65 7973 5f77 6974  equired_keys_wit
+000106b0: 685f 756e 7365 745f 7661 6c75 6573 0a20  h_unset_values. 
+000106c0: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+000106d0: 0a20 2020 2020 2020 2020 2020 2029 0a0a  .            )..
+000106e0: 2020 2020 2020 2020 6469 7361 6c6c 6f77          disallow
+000106f0: 6564 5f61 6464 6974 696f 6e61 6c5f 6b65  ed_additional_ke
+00010700: 7973 203d 205b 5d0a 2020 2020 2020 2020  ys = [].        
+00010710: 666f 7220 6b65 7920 696e 2064 6174 613a  for key in data:
+00010720: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+00010730: 6b65 7920 696e 2063 6c73 2e5f 5f72 6571  key in cls.__req
+00010740: 7569 7265 645f 6b65 7973 5f5f 206f 7220  uired_keys__ or 
+00010750: 6b65 7920 696e 2063 6c73 2e5f 5f6f 7074  key in cls.__opt
+00010760: 696f 6e61 6c5f 6b65 7973 5f5f 3a0a 2020  ional_keys__:.  
+00010770: 2020 2020 2020 2020 2020 2020 2020 636f                co
+00010780: 6e74 696e 7565 0a20 2020 2020 2020 2020  ntinue.         
+00010790: 2020 2064 6973 616c 6c6f 7765 645f 6164     disallowed_ad
+000107a0: 6469 7469 6f6e 616c 5f6b 6579 732e 6170  ditional_keys.ap
+000107b0: 7065 6e64 286b 6579 290a 2020 2020 2020  pend(key).      
+000107c0: 2020 6966 2064 6973 616c 6c6f 7765 645f    if disallowed_
+000107d0: 6164 6469 7469 6f6e 616c 5f6b 6579 733a  additional_keys:
+000107e0: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
+000107f0: 7365 2041 7069 5479 7065 4572 726f 7228  se ApiTypeError(
+00010800: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00010810: 2027 7b7d 2067 6f74 207b 7d20 756e 6578   '{} got {} unex
+00010820: 7065 6374 6564 206b 6579 776f 7264 2061  pected keyword a
+00010830: 7267 756d 656e 7473 3a20 7b7d 272e 666f  rguments: {}'.fo
+00010840: 726d 6174 280a 2020 2020 2020 2020 2020  rmat(.          
+00010850: 2020 2020 2020 2020 2020 636c 732e 5f5f            cls.__
+00010860: 6e61 6d65 5f5f 2c20 6c65 6e28 6469 7361  name__, len(disa
 00010870: 6c6c 6f77 6564 5f61 6464 6974 696f 6e61  llowed_additiona
-00010880: 6c5f 6b65 7973 0a20 2020 2020 2020 2020  l_keys.         
-00010890: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
-000108a0: 2020 2020 2029 0a0a 2020 2020 6465 6620       )..    def 
-000108b0: 5f67 6574 5f68 6f73 745f 6f61 7067 280a  _get_host_oapg(.
-000108c0: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
-000108d0: 2020 2020 2020 6f70 6572 6174 696f 6e5f        operation_
-000108e0: 6964 3a20 7374 722c 0a20 2020 2020 2020  id: str,.       
-000108f0: 2073 6572 7665 7273 3a20 7479 7069 6e67   servers: typing
-00010900: 2e54 7570 6c65 5b74 7970 696e 672e 4469  .Tuple[typing.Di
-00010910: 6374 5b73 7472 2c20 7374 725d 2c20 2e2e  ct[str, str], ..
-00010920: 2e5d 203d 2074 7570 6c65 2829 2c0a 2020  .] = tuple(),.  
-00010930: 2020 2020 2020 686f 7374 5f69 6e64 6578        host_index
-00010940: 3a20 7479 7069 6e67 2e4f 7074 696f 6e61  : typing.Optiona
-00010950: 6c5b 696e 745d 203d 204e 6f6e 650a 2020  l[int] = None.  
-00010960: 2020 2920 2d3e 2074 7970 696e 672e 4f70    ) -> typing.Op
-00010970: 7469 6f6e 616c 5b73 7472 5d3a 0a20 2020  tional[str]:.   
-00010980: 2020 2020 2063 6f6e 6669 6775 7261 7469       configurati
-00010990: 6f6e 203d 2073 656c 662e 6170 695f 636c  on = self.api_cl
-000109a0: 6965 6e74 2e63 6f6e 6669 6775 7261 7469  ient.configurati
-000109b0: 6f6e 0a20 2020 2020 2020 2074 7279 3a0a  on.        try:.
-000109c0: 2020 2020 2020 2020 2020 2020 6966 2068              if h
-000109d0: 6f73 745f 696e 6465 7820 6973 204e 6f6e  ost_index is Non
-000109e0: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
-000109f0: 2020 2069 6e64 6578 203d 2063 6f6e 6669     index = confi
-00010a00: 6775 7261 7469 6f6e 2e73 6572 7665 725f  guration.server_
-00010a10: 6f70 6572 6174 696f 6e5f 696e 6465 782e  operation_index.
-00010a20: 6765 7428 0a20 2020 2020 2020 2020 2020  get(.           
-00010a30: 2020 2020 2020 2020 206f 7065 7261 7469           operati
-00010a40: 6f6e 5f69 642c 2063 6f6e 6669 6775 7261  on_id, configura
-00010a50: 7469 6f6e 2e73 6572 7665 725f 696e 6465  tion.server_inde
-00010a60: 780a 2020 2020 2020 2020 2020 2020 2020  x.              
-00010a70: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
-00010a80: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00010a90: 2020 2020 2020 696e 6465 7820 3d20 686f        index = ho
-00010aa0: 7374 5f69 6e64 6578 0a20 2020 2020 2020  st_index.       
-00010ab0: 2020 2020 2073 6572 7665 725f 7661 7269       server_vari
-00010ac0: 6162 6c65 7320 3d20 636f 6e66 6967 7572  ables = configur
-00010ad0: 6174 696f 6e2e 7365 7276 6572 5f6f 7065  ation.server_ope
-00010ae0: 7261 7469 6f6e 5f76 6172 6961 626c 6573  ration_variables
-00010af0: 2e67 6574 280a 2020 2020 2020 2020 2020  .get(.          
-00010b00: 2020 2020 2020 6f70 6572 6174 696f 6e5f        operation_
-00010b10: 6964 2c20 636f 6e66 6967 7572 6174 696f  id, configuratio
-00010b20: 6e2e 7365 7276 6572 5f76 6172 6961 626c  n.server_variabl
-00010b30: 6573 0a20 2020 2020 2020 2020 2020 2029  es.            )
-00010b40: 0a20 2020 2020 2020 2020 2020 2068 6f73  .            hos
-00010b50: 7420 3d20 636f 6e66 6967 7572 6174 696f  t = configuratio
-00010b60: 6e2e 6765 745f 686f 7374 5f66 726f 6d5f  n.get_host_from_
-00010b70: 7365 7474 696e 6773 280a 2020 2020 2020  settings(.      
-00010b80: 2020 2020 2020 2020 2020 696e 6465 782c            index,
-00010b90: 2076 6172 6961 626c 6573 3d73 6572 7665   variables=serve
-00010ba0: 725f 7661 7269 6162 6c65 732c 2073 6572  r_variables, ser
-00010bb0: 7665 7273 3d73 6572 7665 7273 0a20 2020  vers=servers.   
-00010bc0: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
-00010bd0: 2020 2065 7863 6570 7420 496e 6465 7845     except IndexE
-00010be0: 7272 6f72 3a0a 2020 2020 2020 2020 2020  rror:.          
-00010bf0: 2020 6966 2073 6572 7665 7273 3a0a 2020    if servers:.  
-00010c00: 2020 2020 2020 2020 2020 2020 2020 7261                ra
-00010c10: 6973 6520 4170 6956 616c 7565 4572 726f  ise ApiValueErro
-00010c20: 7228 0a20 2020 2020 2020 2020 2020 2020  r(.             
-00010c30: 2020 2020 2020 2022 496e 7661 6c69 6420         "Invalid 
-00010c40: 686f 7374 2069 6e64 6578 2e20 4d75 7374  host index. Must
-00010c50: 2062 6520 3020 3c3d 2069 6e64 6578 203c   be 0 <= index <
-00010c60: 2025 7322 2025 0a20 2020 2020 2020 2020   %s" %.         
-00010c70: 2020 2020 2020 2020 2020 206c 656e 2873             len(s
-00010c80: 6572 7665 7273 290a 2020 2020 2020 2020  ervers).        
-00010c90: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
-00010ca0: 2020 2020 2020 686f 7374 203d 204e 6f6e        host = Non
-00010cb0: 650a 2020 2020 2020 2020 7265 7475 726e  e.        return
-00010cc0: 2068 6f73 740a 0a0a 636c 6173 7320 5365   host...class Se
-00010cd0: 7269 616c 697a 6564 5265 7175 6573 7442  rializedRequestB
-00010ce0: 6f64 7928 7479 7069 6e67 5f65 7874 656e  ody(typing_exten
-00010cf0: 7369 6f6e 732e 5479 7065 6444 6963 742c  sions.TypedDict,
-00010d00: 2074 6f74 616c 3d46 616c 7365 293a 0a20   total=False):. 
-00010d10: 2020 2062 6f64 793a 2074 7970 696e 672e     body: typing.
-00010d20: 556e 696f 6e5b 7374 722c 2062 7974 6573  Union[str, bytes
-00010d30: 5d0a 2020 2020 6669 656c 6473 3a20 7479  ].    fields: ty
-00010d40: 7069 6e67 2e54 7570 6c65 5b74 7970 696e  ping.Tuple[typin
-00010d50: 672e 556e 696f 6e5b 5265 7175 6573 7446  g.Union[RequestF
-00010d60: 6965 6c64 2c20 7479 7069 6e67 2e54 7570  ield, typing.Tup
-00010d70: 6c65 5b73 7472 2c20 7374 725d 5d2c 202e  le[str, str]], .
-00010d80: 2e2e 5d0a 0a0a 636c 6173 7320 5265 7175  ..]...class Requ
-00010d90: 6573 7442 6f64 7928 5374 796c 6546 6f72  estBody(StyleFor
-00010da0: 6d53 6572 6961 6c69 7a65 722c 204a 534f  mSerializer, JSO
-00010db0: 4e44 6574 6563 746f 7229 3a0a 2020 2020  NDetector):.    
-00010dc0: 2222 220a 2020 2020 4120 7265 7175 6573  """.    A reques
-00010dd0: 7420 626f 6479 2070 6172 616d 6574 6572  t body parameter
-00010de0: 0a20 2020 2063 6f6e 7465 6e74 3a20 636f  .    content: co
-00010df0: 6e74 656e 745f 7479 7065 2074 6f20 4d65  ntent_type to Me
-00010e00: 6469 6154 7970 6520 5363 6865 6d61 2069  diaType Schema i
-00010e10: 6e66 6f0a 2020 2020 2222 220a 2020 2020  nfo.    """.    
-00010e20: 5f5f 6a73 6f6e 5f65 6e63 6f64 6572 203d  __json_encoder =
-00010e30: 204a 534f 4e45 6e63 6f64 6572 2829 0a0a   JSONEncoder()..
-00010e40: 2020 2020 6465 6620 5f5f 696e 6974 5f5f      def __init__
-00010e50: 280a 2020 2020 2020 2020 7365 6c66 2c0a  (.        self,.
-00010e60: 2020 2020 2020 2020 636f 6e74 656e 743a          content:
-00010e70: 2074 7970 696e 672e 4469 6374 5b73 7472   typing.Dict[str
-00010e80: 2c20 4d65 6469 6154 7970 655d 2c0a 2020  , MediaType],.  
-00010e90: 2020 2020 2020 7265 7175 6972 6564 3a20        required: 
-00010ea0: 626f 6f6c 203d 2046 616c 7365 2c0a 2020  bool = False,.  
-00010eb0: 2020 293a 0a20 2020 2020 2020 2073 656c    ):.        sel
-00010ec0: 662e 7265 7175 6972 6564 203d 2072 6571  f.required = req
-00010ed0: 7569 7265 640a 2020 2020 2020 2020 6966  uired.        if
-00010ee0: 206c 656e 2863 6f6e 7465 6e74 2920 3d3d   len(content) ==
-00010ef0: 2030 3a0a 2020 2020 2020 2020 2020 2020   0:.            
-00010f00: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
-00010f10: 2827 496e 7661 6c69 6420 7661 6c75 6520  ('Invalid value 
-00010f20: 666f 7220 636f 6e74 656e 742c 2074 6865  for content, the
-00010f30: 2063 6f6e 7465 6e74 2064 6963 7420 6d75   content dict mu
-00010f40: 7374 2068 6176 6520 3e3d 2031 2065 6e74  st have >= 1 ent
-00010f50: 7279 2729 0a20 2020 2020 2020 2073 656c  ry').        sel
-00010f60: 662e 636f 6e74 656e 7420 3d20 636f 6e74  f.content = cont
-00010f70: 656e 740a 0a20 2020 2064 6566 205f 5f73  ent..    def __s
-00010f80: 6572 6961 6c69 7a65 5f6a 736f 6e28 0a20  erialize_json(. 
-00010f90: 2020 2020 2020 2073 656c 662c 0a20 2020         self,.   
-00010fa0: 2020 2020 2069 6e5f 6461 7461 3a20 7479       in_data: ty
-00010fb0: 7069 6e67 2e41 6e79 0a20 2020 2029 202d  ping.Any.    ) -
-00010fc0: 3e20 7479 7069 6e67 2e44 6963 745b 7374  > typing.Dict[st
-00010fd0: 722c 2062 7974 6573 5d3a 0a20 2020 2020  r, bytes]:.     
-00010fe0: 2020 2069 6e5f 6461 7461 203d 2073 656c     in_data = sel
-00010ff0: 662e 5f5f 6a73 6f6e 5f65 6e63 6f64 6572  f.__json_encoder
-00011000: 2e64 6566 6175 6c74 2869 6e5f 6461 7461  .default(in_data
-00011010: 290a 2020 2020 2020 2020 6a73 6f6e 5f73  ).        json_s
-00011020: 7472 203d 206a 736f 6e2e 6475 6d70 7328  tr = json.dumps(
-00011030: 696e 5f64 6174 612c 2073 6570 6172 6174  in_data, separat
-00011040: 6f72 733d 2822 2c22 2c20 223a 2229 2c20  ors=(",", ":"), 
-00011050: 656e 7375 7265 5f61 7363 6969 3d46 616c  ensure_ascii=Fal
-00011060: 7365 292e 656e 636f 6465 280a 2020 2020  se).encode(.    
-00011070: 2020 2020 2020 2020 2275 7466 2d38 220a          "utf-8".
-00011080: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
-00011090: 2020 7265 7475 726e 2064 6963 7428 626f    return dict(bo
-000110a0: 6479 3d6a 736f 6e5f 7374 7229 0a0a 2020  dy=json_str)..  
-000110b0: 2020 4073 7461 7469 636d 6574 686f 640a    @staticmethod.
-000110c0: 2020 2020 6465 6620 5f5f 7365 7269 616c      def __serial
-000110d0: 697a 655f 7465 7874 5f70 6c61 696e 2869  ize_text_plain(i
-000110e0: 6e5f 6461 7461 3a20 7479 7069 6e67 2e41  n_data: typing.A
-000110f0: 6e79 2920 2d3e 2074 7970 696e 672e 4469  ny) -> typing.Di
-00011100: 6374 5b73 7472 2c20 7374 725d 3a0a 2020  ct[str, str]:.  
-00011110: 2020 2020 2020 6966 2069 7369 6e73 7461        if isinsta
-00011120: 6e63 6528 696e 5f64 6174 612c 2066 726f  nce(in_data, fro
-00011130: 7a65 6e64 6963 742e 6672 6f7a 656e 6469  zendict.frozendi
-00011140: 6374 293a 0a20 2020 2020 2020 2020 2020  ct):.           
-00011150: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
-00011160: 7228 2755 6e61 626c 6520 746f 2073 6572  r('Unable to ser
-00011170: 6961 6c69 7a65 2074 7970 6520 6672 6f7a  ialize type froz
-00011180: 656e 6469 6374 2e66 726f 7a65 6e64 6963  endict.frozendic
-00011190: 7420 746f 2074 6578 742f 706c 6169 6e27  t to text/plain'
-000111a0: 290a 2020 2020 2020 2020 656c 6966 2069  ).        elif i
-000111b0: 7369 6e73 7461 6e63 6528 696e 5f64 6174  sinstance(in_dat
-000111c0: 612c 2074 7570 6c65 293a 0a20 2020 2020  a, tuple):.     
-000111d0: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
-000111e0: 7565 4572 726f 7228 2755 6e61 626c 6520  ueError('Unable 
-000111f0: 746f 2073 6572 6961 6c69 7a65 2074 7970  to serialize typ
-00011200: 6520 7475 706c 6520 746f 2074 6578 742f  e tuple to text/
-00011210: 706c 6169 6e27 290a 2020 2020 2020 2020  plain').        
-00011220: 656c 6966 2069 7369 6e73 7461 6e63 6528  elif isinstance(
-00011230: 696e 5f64 6174 612c 204e 6f6e 6543 6c61  in_data, NoneCla
-00011240: 7373 293a 0a20 2020 2020 2020 2020 2020  ss):.           
-00011250: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
-00011260: 7228 2755 6e61 626c 6520 746f 2073 6572  r('Unable to ser
-00011270: 6961 6c69 7a65 2074 7970 6520 4e6f 6e65  ialize type None
-00011280: 436c 6173 7320 746f 2074 6578 742f 706c  Class to text/pl
-00011290: 6169 6e27 290a 2020 2020 2020 2020 656c  ain').        el
-000112a0: 6966 2069 7369 6e73 7461 6e63 6528 696e  if isinstance(in
-000112b0: 5f64 6174 612c 2042 6f6f 6c43 6c61 7373  _data, BoolClass
-000112c0: 293a 0a20 2020 2020 2020 2020 2020 2072  ):.            r
-000112d0: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
-000112e0: 2755 6e61 626c 6520 746f 2073 6572 6961  'Unable to seria
-000112f0: 6c69 7a65 2074 7970 6520 426f 6f6c 436c  lize type BoolCl
-00011300: 6173 7320 746f 2074 6578 742f 706c 6169  ass to text/plai
-00011310: 6e27 290a 2020 2020 2020 2020 7265 7475  n').        retu
-00011320: 726e 2064 6963 7428 626f 6479 3d73 7472  rn dict(body=str
-00011330: 2869 6e5f 6461 7461 2929 0a0a 2020 2020  (in_data))..    
-00011340: 6465 6620 5f5f 6d75 6c74 6970 6172 745f  def __multipart_
-00011350: 6a73 6f6e 5f69 7465 6d28 7365 6c66 2c20  json_item(self, 
-00011360: 6b65 793a 2073 7472 2c20 7661 6c75 653a  key: str, value:
-00011370: 2053 6368 656d 6129 202d 3e20 5265 7175   Schema) -> Requ
-00011380: 6573 7446 6965 6c64 3a0a 2020 2020 2020  estField:.      
-00011390: 2020 6a73 6f6e 5f76 616c 7565 203d 2073    json_value = s
-000113a0: 656c 662e 5f5f 6a73 6f6e 5f65 6e63 6f64  elf.__json_encod
-000113b0: 6572 2e64 6566 6175 6c74 2876 616c 7565  er.default(value
-000113c0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-000113d0: 2052 6571 7565 7374 4669 656c 6428 6e61   RequestField(na
-000113e0: 6d65 3d6b 6579 2c20 6461 7461 3d6a 736f  me=key, data=jso
-000113f0: 6e2e 6475 6d70 7328 6a73 6f6e 5f76 616c  n.dumps(json_val
-00011400: 7565 292c 2068 6561 6465 7273 3d7b 2743  ue), headers={'C
-00011410: 6f6e 7465 6e74 2d54 7970 6527 3a20 2761  ontent-Type': 'a
-00011420: 7070 6c69 6361 7469 6f6e 2f6a 736f 6e27  pplication/json'
-00011430: 7d29 0a0a 2020 2020 6465 6620 5f5f 6d75  })..    def __mu
-00011440: 6c74 6970 6172 745f 666f 726d 5f69 7465  ltipart_form_ite
-00011450: 6d28 7365 6c66 2c20 6b65 793a 2073 7472  m(self, key: str
-00011460: 2c20 7661 6c75 653a 2053 6368 656d 6129  , value: Schema)
-00011470: 202d 3e20 5265 7175 6573 7446 6965 6c64   -> RequestField
-00011480: 3a0a 2020 2020 2020 2020 6966 2069 7369  :.        if isi
-00011490: 6e73 7461 6e63 6528 7661 6c75 652c 2073  nstance(value, s
-000114a0: 7472 293a 0a20 2020 2020 2020 2020 2020  tr):.           
-000114b0: 2072 6574 7572 6e20 5265 7175 6573 7446   return RequestF
-000114c0: 6965 6c64 286e 616d 653d 6b65 792c 2064  ield(name=key, d
-000114d0: 6174 613d 7374 7228 7661 6c75 6529 2c20  ata=str(value), 
-000114e0: 6865 6164 6572 733d 7b27 436f 6e74 656e  headers={'Conten
-000114f0: 742d 5479 7065 273a 2027 7465 7874 2f70  t-Type': 'text/p
-00011500: 6c61 696e 277d 290a 2020 2020 2020 2020  lain'}).        
-00011510: 656c 6966 2069 7369 6e73 7461 6e63 6528  elif isinstance(
-00011520: 7661 6c75 652c 2062 7974 6573 293a 0a20  value, bytes):. 
-00011530: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00011540: 6e20 5265 7175 6573 7446 6965 6c64 286e  n RequestField(n
-00011550: 616d 653d 6b65 792c 2064 6174 613d 7661  ame=key, data=va
-00011560: 6c75 652c 2068 6561 6465 7273 3d7b 2743  lue, headers={'C
-00011570: 6f6e 7465 6e74 2d54 7970 6527 3a20 2761  ontent-Type': 'a
-00011580: 7070 6c69 6361 7469 6f6e 2f6f 6374 6574  pplication/octet
-00011590: 2d73 7472 6561 6d27 7d29 0a20 2020 2020  -stream'}).     
-000115a0: 2020 2065 6c69 6620 6973 696e 7374 616e     elif isinstan
-000115b0: 6365 2876 616c 7565 2c20 4669 6c65 494f  ce(value, FileIO
-000115c0: 293a 0a20 2020 2020 2020 2020 2020 2066  ):.            f
-000115d0: 696c 656e 616d 6520 3d20 6f73 2e70 6174  ilename = os.pat
-000115e0: 682e 6261 7365 6e61 6d65 2876 616c 7565  h.basename(value
-000115f0: 2e6e 616d 6529 0a20 2020 2020 2020 2020  .name).         
-00011600: 2020 2072 6571 7565 7374 5f66 6965 6c64     request_field
-00011610: 203d 2052 6571 7565 7374 4669 656c 6428   = RequestField(
-00011620: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00011630: 206e 616d 653d 6b65 792c 0a20 2020 2020   name=key,.     
-00011640: 2020 2020 2020 2020 2020 2064 6174 613d             data=
-00011650: 7661 6c75 652e 7265 6164 2829 2c0a 2020  value.read(),.  
-00011660: 2020 2020 2020 2020 2020 2020 2020 6669                fi
-00011670: 6c65 6e61 6d65 3d66 696c 656e 616d 652c  lename=filename,
-00011680: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00011690: 2068 6561 6465 7273 3d7b 2743 6f6e 7465   headers={'Conte
-000116a0: 6e74 2d54 7970 6527 3a20 6775 6573 735f  nt-Type': guess_
-000116b0: 636f 6e74 656e 745f 7479 7065 2866 696c  content_type(fil
-000116c0: 656e 616d 6529 7d0a 2020 2020 2020 2020  ename)}.        
-000116d0: 2020 2020 290a 2020 2020 2020 2020 2020      ).          
-000116e0: 2020 7661 6c75 652e 636c 6f73 6528 290a    value.close().
-000116f0: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00011700: 726e 2072 6571 7565 7374 5f66 6965 6c64  rn request_field
-00011710: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
-00011720: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00011730: 6e20 7365 6c66 2e5f 5f6d 756c 7469 7061  n self.__multipa
-00011740: 7274 5f6a 736f 6e5f 6974 656d 286b 6579  rt_json_item(key
-00011750: 3d6b 6579 2c20 7661 6c75 653d 7661 6c75  =key, value=valu
-00011760: 6529 0a0a 2020 2020 6465 6620 5f5f 7365  e)..    def __se
-00011770: 7269 616c 697a 655f 6d75 6c74 6970 6172  rialize_multipar
-00011780: 745f 666f 726d 5f64 6174 6128 0a20 2020  t_form_data(.   
-00011790: 2020 2020 2073 656c 662c 2069 6e5f 6461       self, in_da
-000117a0: 7461 3a20 5363 6865 6d61 0a20 2020 2029  ta: Schema.    )
-000117b0: 202d 3e20 7479 7069 6e67 2e44 6963 745b   -> typing.Dict[
-000117c0: 7374 722c 2074 7970 696e 672e 5475 706c  str, typing.Tupl
-000117d0: 655b 5265 7175 6573 7446 6965 6c64 2c20  e[RequestField, 
-000117e0: 2e2e 2e5d 5d3a 0a20 2020 2020 2020 2069  ...]]:.        i
-000117f0: 6620 6e6f 7420 6973 696e 7374 616e 6365  f not isinstance
-00011800: 2869 6e5f 6461 7461 2c20 6672 6f7a 656e  (in_data, frozen
-00011810: 6469 6374 2e66 726f 7a65 6e64 6963 7429  dict.frozendict)
-00011820: 2061 6e64 206e 6f74 2069 7369 6e73 7461   and not isinsta
-00011830: 6e63 6528 696e 5f64 6174 612c 206c 6973  nce(in_data, lis
-00011840: 7429 2061 6e64 206e 6f74 2069 7369 6e73  t) and not isins
-00011850: 7461 6e63 6528 696e 5f64 6174 612c 2074  tance(in_data, t
-00011860: 7570 6c65 293a 0a20 2020 2020 2020 2020  uple):.         
-00011870: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
-00011880: 726f 7228 6627 556e 6162 6c65 2074 6f20  ror(f'Unable to 
-00011890: 7365 7269 616c 697a 6520 7b69 6e5f 6461  serialize {in_da
-000118a0: 7461 7d20 746f 206d 756c 7469 7061 7274  ta} to multipart
-000118b0: 2f66 6f72 6d2d 6461 7461 2062 6563 6175  /form-data becau
-000118c0: 7365 2069 7420 6973 206e 6f74 2061 2064  se it is not a d
-000118d0: 6963 7420 6f66 2064 6174 6120 6f72 2061  ict of data or a
-000118e0: 206c 6973 7420 6f66 2064 6174 6127 290a   list of data').
-000118f0: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-00011900: 2020 2020 496e 2061 206d 756c 7469 7061      In a multipa
-00011910: 7274 2f66 6f72 6d2d 6461 7461 2072 6571  rt/form-data req
-00011920: 7565 7374 2062 6f64 792c 2065 6163 6820  uest body, each 
-00011930: 7363 6865 6d61 2070 726f 7065 7274 792c  schema property,
-00011940: 206f 7220 6561 6368 2065 6c65 6d65 6e74   or each element
-00011950: 206f 6620 6120 7363 6865 6d61 2061 7272   of a schema arr
-00011960: 6179 2070 726f 7065 7274 792c 0a20 2020  ay property,.   
-00011970: 2020 2020 2074 616b 6573 2061 2073 6563       takes a sec
-00011980: 7469 6f6e 2069 6e20 7468 6520 7061 796c  tion in the payl
-00011990: 6f61 6420 7769 7468 2061 6e20 696e 7465  oad with an inte
-000119a0: 726e 616c 2068 6561 6465 7220 6173 2064  rnal header as d
-000119b0: 6566 696e 6564 2062 7920 5246 4337 3537  efined by RFC757
-000119c0: 382e 2054 6865 2073 6572 6961 6c69 7a61  8. The serializa
-000119d0: 7469 6f6e 2073 7472 6174 6567 790a 2020  tion strategy.  
-000119e0: 2020 2020 2020 666f 7220 6561 6368 2070        for each p
-000119f0: 726f 7065 7274 7920 6f66 2061 206d 756c  roperty of a mul
-00011a00: 7469 7061 7274 2f66 6f72 6d2d 6461 7461  tipart/form-data
-00011a10: 2072 6571 7565 7374 2062 6f64 7920 6361   request body ca
-00011a20: 6e20 6265 2073 7065 6369 6669 6564 2069  n be specified i
-00011a30: 6e20 616e 2061 7373 6f63 6961 7465 6420  n an associated 
-00011a40: 456e 636f 6469 6e67 204f 626a 6563 742e  Encoding Object.
-00011a50: 0a0a 2020 2020 2020 2020 5768 656e 2070  ..        When p
-00011a60: 6173 7369 6e67 2069 6e20 6d75 6c74 6970  assing in multip
-00011a70: 6172 7420 7479 7065 732c 2062 6f75 6e64  art types, bound
-00011a80: 6172 6965 7320 4d41 5920 6265 2075 7365  aries MAY be use
-00011a90: 6420 746f 2073 6570 6172 6174 6520 7365  d to separate se
-00011aa0: 6374 696f 6e73 206f 6620 7468 6520 636f  ctions of the co
-00011ab0: 6e74 656e 7420 6265 696e 670a 2020 2020  ntent being.    
-00011ac0: 2020 2020 7472 616e 7366 6572 7265 6420      transferred 
-00011ad0: e280 9320 7468 7573 2c20 7468 6520 666f  ... thus, the fo
-00011ae0: 6c6c 6f77 696e 6720 6465 6661 756c 7420  llowing default 
-00011af0: 436f 6e74 656e 742d 5479 7065 7320 6172  Content-Types ar
-00011b00: 6520 6465 6669 6e65 6420 666f 7220 6d75  e defined for mu
-00011b10: 6c74 6970 6172 743a 0a0a 2020 2020 2020  ltipart:..      
-00011b20: 2020 4966 2074 6865 2028 6f62 6a65 6374    If the (object
-00011b30: 2920 7072 6f70 6572 7479 2069 7320 6120  ) property is a 
-00011b40: 7072 696d 6974 6976 652c 206f 7220 616e  primitive, or an
-00011b50: 2061 7272 6179 206f 6620 7072 696d 6974   array of primit
-00011b60: 6976 6520 7661 6c75 6573 2c20 7468 6520  ive values, the 
-00011b70: 6465 6661 756c 7420 436f 6e74 656e 742d  default Content-
-00011b80: 5479 7065 2069 7320 7465 7874 2f70 6c61  Type is text/pla
-00011b90: 696e 0a20 2020 2020 2020 2049 6620 7468  in.        If th
-00011ba0: 6520 7072 6f70 6572 7479 2069 7320 636f  e property is co
-00011bb0: 6d70 6c65 782c 206f 7220 616e 2061 7272  mplex, or an arr
-00011bc0: 6179 206f 6620 636f 6d70 6c65 7820 7661  ay of complex va
-00011bd0: 6c75 6573 2c20 7468 6520 6465 6661 756c  lues, the defaul
-00011be0: 7420 436f 6e74 656e 742d 5479 7065 2069  t Content-Type i
-00011bf0: 7320 6170 706c 6963 6174 696f 6e2f 6a73  s application/js
-00011c00: 6f6e 0a20 2020 2020 2020 2020 2020 2051  on.            Q
-00011c10: 7565 7374 696f 6e3a 2068 6f77 2069 7320  uestion: how is 
-00011c20: 7468 6520 6172 7261 7920 6f66 2070 7269  the array of pri
-00011c30: 6d69 7469 7665 7320 656e 636f 6465 643f  mitives encoded?
-00011c40: 0a20 2020 2020 2020 2049 6620 7468 6520  .        If the 
-00011c50: 7072 6f70 6572 7479 2069 7320 6120 7479  property is a ty
-00011c60: 7065 3a20 7374 7269 6e67 2077 6974 6820  pe: string with 
-00011c70: 6120 636f 6e74 656e 7445 6e63 6f64 696e  a contentEncodin
-00011c80: 672c 2074 6865 2064 6566 6175 6c74 2043  g, the default C
-00011c90: 6f6e 7465 6e74 2d54 7970 6520 6973 2061  ontent-Type is a
-00011ca0: 7070 6c69 6361 7469 6f6e 2f6f 6374 6574  pplication/octet
-00011cb0: 2d73 7472 6561 6d0a 2020 2020 2020 2020  -stream.        
-00011cc0: 2222 220a 2020 2020 2020 2020 6669 656c  """.        fiel
-00011cd0: 6473 3a20 7479 7069 6e67 2e4c 6973 745b  ds: typing.List[
-00011ce0: 5265 7175 6573 7446 6965 6c64 5d20 3d20  RequestField] = 
-00011cf0: 5b5d 0a0a 2020 2020 2020 2020 6465 6620  []..        def 
-00011d00: 6164 645f 6669 656c 6428 6461 7461 293a  add_field(data):
-00011d10: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
-00011d20: 206b 6579 2c20 7661 6c75 6520 696e 2064   key, value in d
-00011d30: 6174 612e 6974 656d 7328 293a 0a20 2020  ata.items():.   
-00011d40: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-00011d50: 6973 696e 7374 616e 6365 2876 616c 7565  isinstance(value
-00011d60: 2c20 7475 706c 6529 3a0a 2020 2020 2020  , tuple):.      
-00011d70: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00011d80: 2076 616c 7565 3a0a 2020 2020 2020 2020   value:.        
-00011d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011da0: 2320 7661 6c75 6573 2075 7365 2065 7870  # values use exp
-00011db0: 6c6f 6465 203d 2054 7275 652c 2073 6f20  lode = True, so 
-00011dc0: 7468 6520 636f 6465 206d 616b 6573 2061  the code makes a
-00011dd0: 2052 6571 7565 7374 4669 656c 6420 666f   RequestField fo
-00011de0: 7220 6561 6368 2069 7465 6d20 7769 7468  r each item with
-00011df0: 206e 616d 653d 6b65 790a 2020 2020 2020   name=key.      
-00011e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011e10: 2020 666f 7220 6974 656d 2069 6e20 7661    for item in va
-00011e20: 6c75 653a 0a20 2020 2020 2020 2020 2020  lue:.           
-00011e30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011e40: 2072 6571 7565 7374 5f66 6965 6c64 203d   request_field =
-00011e50: 2073 656c 662e 5f5f 6d75 6c74 6970 6172   self.__multipar
-00011e60: 745f 666f 726d 5f69 7465 6d28 6b65 793d  t_form_item(key=
-00011e70: 6b65 792c 2076 616c 7565 3d69 7465 6d29  key, value=item)
-00011e80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00011e90: 2020 2020 2020 2020 2020 2020 2066 6965               fie
-00011ea0: 6c64 732e 6170 7065 6e64 2872 6571 7565  lds.append(reque
-00011eb0: 7374 5f66 6965 6c64 290a 2020 2020 2020  st_field).      
-00011ec0: 2020 2020 2020 2020 2020 2020 2020 656c                el
-00011ed0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00011ee0: 2020 2020 2020 2020 2020 2020 2320 7365              # se
-00011ef0: 6e64 2061 6e20 656d 7074 7920 6172 7261  nd an empty arra
-00011f00: 7920 6173 206a 736f 6e20 6265 6361 7573  y as json becaus
-00011f10: 6520 6578 706c 6f64 696e 6720 7769 6c6c  e exploding will
-00011f20: 206e 6f74 2073 656e 6420 6974 0a20 2020   not send it.   
-00011f30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011f40: 2020 2020 2072 6571 7565 7374 5f66 6965       request_fie
-00011f50: 6c64 203d 2073 656c 662e 5f5f 6d75 6c74  ld = self.__mult
-00011f60: 6970 6172 745f 6a73 6f6e 5f69 7465 6d28  ipart_json_item(
-00011f70: 6b65 793d 6b65 792c 2076 616c 7565 3d76  key=key, value=v
-00011f80: 616c 7565 290a 2020 2020 2020 2020 2020  alue).          
-00011f90: 2020 2020 2020 2020 2020 2020 2020 6669                fi
-00011fa0: 656c 6473 2e61 7070 656e 6428 7265 7175  elds.append(requ
-00011fb0: 6573 745f 6669 656c 6429 0a20 2020 2020  est_field).     
-00011fc0: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
-00011fd0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00011fe0: 2020 2020 2072 6571 7565 7374 5f66 6965       request_fie
-00011ff0: 6c64 203d 2073 656c 662e 5f5f 6d75 6c74  ld = self.__mult
-00012000: 6970 6172 745f 666f 726d 5f69 7465 6d28  ipart_form_item(
-00012010: 6b65 793d 6b65 792c 2076 616c 7565 3d76  key=key, value=v
-00012020: 616c 7565 290a 2020 2020 2020 2020 2020  alue).          
-00012030: 2020 2020 2020 2020 2020 6669 656c 6473            fields
-00012040: 2e61 7070 656e 6428 7265 7175 6573 745f  .append(request_
-00012050: 6669 656c 6429 0a0a 2020 2020 2020 2020  field)..        
-00012060: 6966 2069 7369 6e73 7461 6e63 6528 696e  if isinstance(in
-00012070: 5f64 6174 612c 206c 6973 7429 206f 7220  _data, list) or 
+00010880: 6c5f 6b65 7973 292c 2064 6973 616c 6c6f  l_keys), disallo
+00010890: 7765 645f 6164 6469 7469 6f6e 616c 5f6b  wed_additional_k
+000108a0: 6579 730a 2020 2020 2020 2020 2020 2020  eys.            
+000108b0: 2020 2020 290a 2020 2020 2020 2020 2020      ).          
+000108c0: 2020 290a 0a20 2020 2064 6566 205f 6765    )..    def _ge
+000108d0: 745f 686f 7374 5f6f 6170 6728 0a20 2020  t_host_oapg(.   
+000108e0: 2020 2020 2073 656c 662c 0a20 2020 2020       self,.     
+000108f0: 2020 206f 7065 7261 7469 6f6e 5f69 643a     operation_id:
+00010900: 2073 7472 2c0a 2020 2020 2020 2020 7365   str,.        se
+00010910: 7276 6572 733a 2074 7970 696e 672e 5475  rvers: typing.Tu
+00010920: 706c 655b 7479 7069 6e67 2e44 6963 745b  ple[typing.Dict[
+00010930: 7374 722c 2073 7472 5d2c 202e 2e2e 5d20  str, str], ...] 
+00010940: 3d20 7475 706c 6528 292c 0a20 2020 2020  = tuple(),.     
+00010950: 2020 2068 6f73 745f 696e 6465 783a 2074     host_index: t
+00010960: 7970 696e 672e 4f70 7469 6f6e 616c 5b69  yping.Optional[i
+00010970: 6e74 5d20 3d20 4e6f 6e65 0a20 2020 2029  nt] = None.    )
+00010980: 202d 3e20 7479 7069 6e67 2e4f 7074 696f   -> typing.Optio
+00010990: 6e61 6c5b 7374 725d 3a0a 2020 2020 2020  nal[str]:.      
+000109a0: 2020 636f 6e66 6967 7572 6174 696f 6e20    configuration 
+000109b0: 3d20 7365 6c66 2e61 7069 5f63 6c69 656e  = self.api_clien
+000109c0: 742e 636f 6e66 6967 7572 6174 696f 6e0a  t.configuration.
+000109d0: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
+000109e0: 2020 2020 2020 2020 2069 6620 686f 7374           if host
+000109f0: 5f69 6e64 6578 2069 7320 4e6f 6e65 3a0a  _index is None:.
+00010a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010a10: 696e 6465 7820 3d20 636f 6e66 6967 7572  index = configur
+00010a20: 6174 696f 6e2e 7365 7276 6572 5f6f 7065  ation.server_ope
+00010a30: 7261 7469 6f6e 5f69 6e64 6578 2e67 6574  ration_index.get
+00010a40: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+00010a50: 2020 2020 2020 6f70 6572 6174 696f 6e5f        operation_
+00010a60: 6964 2c20 636f 6e66 6967 7572 6174 696f  id, configuratio
+00010a70: 6e2e 7365 7276 6572 5f69 6e64 6578 0a20  n.server_index. 
+00010a80: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+00010a90: 0a20 2020 2020 2020 2020 2020 2065 6c73  .            els
+00010aa0: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+00010ab0: 2020 2069 6e64 6578 203d 2068 6f73 745f     index = host_
+00010ac0: 696e 6465 780a 2020 2020 2020 2020 2020  index.          
+00010ad0: 2020 7365 7276 6572 5f76 6172 6961 626c    server_variabl
+00010ae0: 6573 203d 2063 6f6e 6669 6775 7261 7469  es = configurati
+00010af0: 6f6e 2e73 6572 7665 725f 6f70 6572 6174  on.server_operat
+00010b00: 696f 6e5f 7661 7269 6162 6c65 732e 6765  ion_variables.ge
+00010b10: 7428 0a20 2020 2020 2020 2020 2020 2020  t(.             
+00010b20: 2020 206f 7065 7261 7469 6f6e 5f69 642c     operation_id,
+00010b30: 2063 6f6e 6669 6775 7261 7469 6f6e 2e73   configuration.s
+00010b40: 6572 7665 725f 7661 7269 6162 6c65 730a  erver_variables.
+00010b50: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+00010b60: 2020 2020 2020 2020 2020 686f 7374 203d            host =
+00010b70: 2063 6f6e 6669 6775 7261 7469 6f6e 2e67   configuration.g
+00010b80: 6574 5f68 6f73 745f 6672 6f6d 5f73 6574  et_host_from_set
+00010b90: 7469 6e67 7328 0a20 2020 2020 2020 2020  tings(.         
+00010ba0: 2020 2020 2020 2069 6e64 6578 2c20 7661         index, va
+00010bb0: 7269 6162 6c65 733d 7365 7276 6572 5f76  riables=server_v
+00010bc0: 6172 6961 626c 6573 2c20 7365 7276 6572  ariables, server
+00010bd0: 733d 7365 7276 6572 730a 2020 2020 2020  s=servers.      
+00010be0: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+00010bf0: 6578 6365 7074 2049 6e64 6578 4572 726f  except IndexErro
+00010c00: 723a 0a20 2020 2020 2020 2020 2020 2069  r:.            i
+00010c10: 6620 7365 7276 6572 733a 0a20 2020 2020  f servers:.     
+00010c20: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00010c30: 2041 7069 5661 6c75 6545 7272 6f72 280a   ApiValueError(.
+00010c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010c50: 2020 2020 2249 6e76 616c 6964 2068 6f73      "Invalid hos
+00010c60: 7420 696e 6465 782e 204d 7573 7420 6265  t index. Must be
+00010c70: 2030 203c 3d20 696e 6465 7820 3c20 2573   0 <= index < %s
+00010c80: 2220 250a 2020 2020 2020 2020 2020 2020  " %.            
+00010c90: 2020 2020 2020 2020 6c65 6e28 7365 7276          len(serv
+00010ca0: 6572 7329 0a20 2020 2020 2020 2020 2020  ers).           
+00010cb0: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
+00010cc0: 2020 2068 6f73 7420 3d20 4e6f 6e65 0a20     host = None. 
+00010cd0: 2020 2020 2020 2072 6574 7572 6e20 686f         return ho
+00010ce0: 7374 0a0a 0a63 6c61 7373 2053 6572 6961  st...class Seria
+00010cf0: 6c69 7a65 6452 6571 7565 7374 426f 6479  lizedRequestBody
+00010d00: 2874 7970 696e 675f 6578 7465 6e73 696f  (typing_extensio
+00010d10: 6e73 2e54 7970 6564 4469 6374 2c20 746f  ns.TypedDict, to
+00010d20: 7461 6c3d 4661 6c73 6529 3a0a 2020 2020  tal=False):.    
+00010d30: 626f 6479 3a20 7479 7069 6e67 2e55 6e69  body: typing.Uni
+00010d40: 6f6e 5b73 7472 2c20 6279 7465 735d 0a20  on[str, bytes]. 
+00010d50: 2020 2066 6965 6c64 733a 2074 7970 696e     fields: typin
+00010d60: 672e 5475 706c 655b 7479 7069 6e67 2e55  g.Tuple[typing.U
+00010d70: 6e69 6f6e 5b52 6571 7565 7374 4669 656c  nion[RequestFiel
+00010d80: 642c 2074 7970 696e 672e 5475 706c 655b  d, typing.Tuple[
+00010d90: 7374 722c 2073 7472 5d5d 2c20 2e2e 2e5d  str, str]], ...]
+00010da0: 0a0a 0a63 6c61 7373 2052 6571 7565 7374  ...class Request
+00010db0: 426f 6479 2853 7479 6c65 466f 726d 5365  Body(StyleFormSe
+00010dc0: 7269 616c 697a 6572 2c20 4a53 4f4e 4465  rializer, JSONDe
+00010dd0: 7465 6374 6f72 293a 0a20 2020 2022 2222  tector):.    """
+00010de0: 0a20 2020 2041 2072 6571 7565 7374 2062  .    A request b
+00010df0: 6f64 7920 7061 7261 6d65 7465 720a 2020  ody parameter.  
+00010e00: 2020 636f 6e74 656e 743a 2063 6f6e 7465    content: conte
+00010e10: 6e74 5f74 7970 6520 746f 204d 6564 6961  nt_type to Media
+00010e20: 5479 7065 2053 6368 656d 6120 696e 666f  Type Schema info
+00010e30: 0a20 2020 2022 2222 0a20 2020 205f 5f6a  .    """.    __j
+00010e40: 736f 6e5f 656e 636f 6465 7220 3d20 4a53  son_encoder = JS
+00010e50: 4f4e 456e 636f 6465 7228 290a 0a20 2020  ONEncoder()..   
+00010e60: 2064 6566 205f 5f69 6e69 745f 5f28 0a20   def __init__(. 
+00010e70: 2020 2020 2020 2073 656c 662c 0a20 2020         self,.   
+00010e80: 2020 2020 2063 6f6e 7465 6e74 3a20 7479       content: ty
+00010e90: 7069 6e67 2e44 6963 745b 7374 722c 204d  ping.Dict[str, M
+00010ea0: 6564 6961 5479 7065 5d2c 0a20 2020 2020  ediaType],.     
+00010eb0: 2020 2072 6571 7569 7265 643a 2062 6f6f     required: boo
+00010ec0: 6c20 3d20 4661 6c73 652c 0a20 2020 2029  l = False,.    )
+00010ed0: 3a0a 2020 2020 2020 2020 7365 6c66 2e72  :.        self.r
+00010ee0: 6571 7569 7265 6420 3d20 7265 7175 6972  equired = requir
+00010ef0: 6564 0a20 2020 2020 2020 2069 6620 6c65  ed.        if le
+00010f00: 6e28 636f 6e74 656e 7429 203d 3d20 303a  n(content) == 0:
+00010f10: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
+00010f20: 7365 2056 616c 7565 4572 726f 7228 2749  se ValueError('I
+00010f30: 6e76 616c 6964 2076 616c 7565 2066 6f72  nvalid value for
+00010f40: 2063 6f6e 7465 6e74 2c20 7468 6520 636f   content, the co
+00010f50: 6e74 656e 7420 6469 6374 206d 7573 7420  ntent dict must 
+00010f60: 6861 7665 203e 3d20 3120 656e 7472 7927  have >= 1 entry'
+00010f70: 290a 2020 2020 2020 2020 7365 6c66 2e63  ).        self.c
+00010f80: 6f6e 7465 6e74 203d 2063 6f6e 7465 6e74  ontent = content
+00010f90: 0a0a 2020 2020 6465 6620 5f5f 7365 7269  ..    def __seri
+00010fa0: 616c 697a 655f 6a73 6f6e 280a 2020 2020  alize_json(.    
+00010fb0: 2020 2020 7365 6c66 2c0a 2020 2020 2020      self,.      
+00010fc0: 2020 696e 5f64 6174 613a 2074 7970 696e    in_data: typin
+00010fd0: 672e 416e 790a 2020 2020 2920 2d3e 2074  g.Any.    ) -> t
+00010fe0: 7970 696e 672e 4469 6374 5b73 7472 2c20  yping.Dict[str, 
+00010ff0: 6279 7465 735d 3a0a 2020 2020 2020 2020  bytes]:.        
+00011000: 696e 5f64 6174 6120 3d20 7365 6c66 2e5f  in_data = self._
+00011010: 5f6a 736f 6e5f 656e 636f 6465 722e 6465  _json_encoder.de
+00011020: 6661 756c 7428 696e 5f64 6174 6129 0a20  fault(in_data). 
+00011030: 2020 2020 2020 206a 736f 6e5f 7374 7220         json_str 
+00011040: 3d20 6a73 6f6e 2e64 756d 7073 2869 6e5f  = json.dumps(in_
+00011050: 6461 7461 2c20 7365 7061 7261 746f 7273  data, separators
+00011060: 3d28 222c 222c 2022 3a22 292c 2065 6e73  =(",", ":"), ens
+00011070: 7572 655f 6173 6369 693d 4661 6c73 6529  ure_ascii=False)
+00011080: 2e65 6e63 6f64 6528 0a20 2020 2020 2020  .encode(.       
+00011090: 2020 2020 2022 7574 662d 3822 0a20 2020       "utf-8".   
+000110a0: 2020 2020 2029 0a20 2020 2020 2020 2072       ).        r
+000110b0: 6574 7572 6e20 6469 6374 2862 6f64 793d  eturn dict(body=
+000110c0: 6a73 6f6e 5f73 7472 290a 0a20 2020 2040  json_str)..    @
+000110d0: 7374 6174 6963 6d65 7468 6f64 0a20 2020  staticmethod.   
+000110e0: 2064 6566 205f 5f73 6572 6961 6c69 7a65   def __serialize
+000110f0: 5f74 6578 745f 706c 6169 6e28 696e 5f64  _text_plain(in_d
+00011100: 6174 613a 2074 7970 696e 672e 416e 7929  ata: typing.Any)
+00011110: 202d 3e20 7479 7069 6e67 2e44 6963 745b   -> typing.Dict[
+00011120: 7374 722c 2073 7472 5d3a 0a20 2020 2020  str, str]:.     
+00011130: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
+00011140: 2869 6e5f 6461 7461 2c20 6672 6f7a 656e  (in_data, frozen
+00011150: 6469 6374 2e66 726f 7a65 6e64 6963 7429  dict.frozendict)
+00011160: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
+00011170: 6973 6520 5661 6c75 6545 7272 6f72 2827  ise ValueError('
+00011180: 556e 6162 6c65 2074 6f20 7365 7269 616c  Unable to serial
+00011190: 697a 6520 7479 7065 2066 726f 7a65 6e64  ize type frozend
+000111a0: 6963 742e 6672 6f7a 656e 6469 6374 2074  ict.frozendict t
+000111b0: 6f20 7465 7874 2f70 6c61 696e 2729 0a20  o text/plain'). 
+000111c0: 2020 2020 2020 2065 6c69 6620 6973 696e         elif isin
+000111d0: 7374 616e 6365 2869 6e5f 6461 7461 2c20  stance(in_data, 
+000111e0: 7475 706c 6529 3a0a 2020 2020 2020 2020  tuple):.        
+000111f0: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
+00011200: 7272 6f72 2827 556e 6162 6c65 2074 6f20  rror('Unable to 
+00011210: 7365 7269 616c 697a 6520 7479 7065 2074  serialize type t
+00011220: 7570 6c65 2074 6f20 7465 7874 2f70 6c61  uple to text/pla
+00011230: 696e 2729 0a20 2020 2020 2020 2065 6c69  in').        eli
+00011240: 6620 6973 696e 7374 616e 6365 2869 6e5f  f isinstance(in_
+00011250: 6461 7461 2c20 4e6f 6e65 436c 6173 7329  data, NoneClass)
+00011260: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
+00011270: 6973 6520 5661 6c75 6545 7272 6f72 2827  ise ValueError('
+00011280: 556e 6162 6c65 2074 6f20 7365 7269 616c  Unable to serial
+00011290: 697a 6520 7479 7065 204e 6f6e 6543 6c61  ize type NoneCla
+000112a0: 7373 2074 6f20 7465 7874 2f70 6c61 696e  ss to text/plain
+000112b0: 2729 0a20 2020 2020 2020 2065 6c69 6620  ').        elif 
+000112c0: 6973 696e 7374 616e 6365 2869 6e5f 6461  isinstance(in_da
+000112d0: 7461 2c20 426f 6f6c 436c 6173 7329 3a0a  ta, BoolClass):.
+000112e0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+000112f0: 6520 5661 6c75 6545 7272 6f72 2827 556e  e ValueError('Un
+00011300: 6162 6c65 2074 6f20 7365 7269 616c 697a  able to serializ
+00011310: 6520 7479 7065 2042 6f6f 6c43 6c61 7373  e type BoolClass
+00011320: 2074 6f20 7465 7874 2f70 6c61 696e 2729   to text/plain')
+00011330: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00011340: 6469 6374 2862 6f64 793d 7374 7228 696e  dict(body=str(in
+00011350: 5f64 6174 6129 290a 0a20 2020 2064 6566  _data))..    def
+00011360: 205f 5f6d 756c 7469 7061 7274 5f6a 736f   __multipart_jso
+00011370: 6e5f 6974 656d 2873 656c 662c 206b 6579  n_item(self, key
+00011380: 3a20 7374 722c 2076 616c 7565 3a20 5363  : str, value: Sc
+00011390: 6865 6d61 2920 2d3e 2052 6571 7565 7374  hema) -> Request
+000113a0: 4669 656c 643a 0a20 2020 2020 2020 206a  Field:.        j
+000113b0: 736f 6e5f 7661 6c75 6520 3d20 7365 6c66  son_value = self
+000113c0: 2e5f 5f6a 736f 6e5f 656e 636f 6465 722e  .__json_encoder.
+000113d0: 6465 6661 756c 7428 7661 6c75 6529 0a20  default(value). 
+000113e0: 2020 2020 2020 2072 6574 7572 6e20 5265         return Re
+000113f0: 7175 6573 7446 6965 6c64 286e 616d 653d  questField(name=
+00011400: 6b65 792c 2064 6174 613d 6a73 6f6e 2e64  key, data=json.d
+00011410: 756d 7073 286a 736f 6e5f 7661 6c75 6529  umps(json_value)
+00011420: 2c20 6865 6164 6572 733d 7b27 436f 6e74  , headers={'Cont
+00011430: 656e 742d 5479 7065 273a 2027 6170 706c  ent-Type': 'appl
+00011440: 6963 6174 696f 6e2f 6a73 6f6e 277d 290a  ication/json'}).
+00011450: 0a20 2020 2064 6566 205f 5f6d 756c 7469  .    def __multi
+00011460: 7061 7274 5f66 6f72 6d5f 6974 656d 2873  part_form_item(s
+00011470: 656c 662c 206b 6579 3a20 7374 722c 2076  elf, key: str, v
+00011480: 616c 7565 3a20 5363 6865 6d61 2920 2d3e  alue: Schema) ->
+00011490: 2052 6571 7565 7374 4669 656c 643a 0a20   RequestField:. 
+000114a0: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
+000114b0: 616e 6365 2876 616c 7565 2c20 7374 7229  ance(value, str)
+000114c0: 3a0a 2020 2020 2020 2020 2020 2020 7265  :.            re
+000114d0: 7475 726e 2052 6571 7565 7374 4669 656c  turn RequestFiel
+000114e0: 6428 6e61 6d65 3d6b 6579 2c20 6461 7461  d(name=key, data
+000114f0: 3d73 7472 2876 616c 7565 292c 2068 6561  =str(value), hea
+00011500: 6465 7273 3d7b 2743 6f6e 7465 6e74 2d54  ders={'Content-T
+00011510: 7970 6527 3a20 2774 6578 742f 706c 6169  ype': 'text/plai
+00011520: 6e27 7d29 0a20 2020 2020 2020 2065 6c69  n'}).        eli
+00011530: 6620 6973 696e 7374 616e 6365 2876 616c  f isinstance(val
+00011540: 7565 2c20 6279 7465 7329 3a0a 2020 2020  ue, bytes):.    
+00011550: 2020 2020 2020 2020 7265 7475 726e 2052          return R
+00011560: 6571 7565 7374 4669 656c 6428 6e61 6d65  equestField(name
+00011570: 3d6b 6579 2c20 6461 7461 3d76 616c 7565  =key, data=value
+00011580: 2c20 6865 6164 6572 733d 7b27 436f 6e74  , headers={'Cont
+00011590: 656e 742d 5479 7065 273a 2027 6170 706c  ent-Type': 'appl
+000115a0: 6963 6174 696f 6e2f 6f63 7465 742d 7374  ication/octet-st
+000115b0: 7265 616d 277d 290a 2020 2020 2020 2020  ream'}).        
+000115c0: 656c 6966 2069 7369 6e73 7461 6e63 6528  elif isinstance(
+000115d0: 7661 6c75 652c 2046 696c 6549 4f29 3a0a  value, FileIO):.
+000115e0: 2020 2020 2020 2020 2020 2020 6669 6c65              file
+000115f0: 6e61 6d65 203d 206f 732e 7061 7468 2e62  name = os.path.b
+00011600: 6173 656e 616d 6528 7661 6c75 652e 6e61  asename(value.na
+00011610: 6d65 290a 2020 2020 2020 2020 2020 2020  me).            
+00011620: 7265 7175 6573 745f 6669 656c 6420 3d20  request_field = 
+00011630: 5265 7175 6573 7446 6965 6c64 280a 2020  RequestField(.  
+00011640: 2020 2020 2020 2020 2020 2020 2020 6e61                na
+00011650: 6d65 3d6b 6579 2c0a 2020 2020 2020 2020  me=key,.        
+00011660: 2020 2020 2020 2020 6461 7461 3d76 616c          data=val
+00011670: 7565 2e72 6561 6428 292c 0a20 2020 2020  ue.read(),.     
+00011680: 2020 2020 2020 2020 2020 2066 696c 656e             filen
+00011690: 616d 653d 6669 6c65 6e61 6d65 2c0a 2020  ame=filename,.  
+000116a0: 2020 2020 2020 2020 2020 2020 2020 6865                he
+000116b0: 6164 6572 733d 7b27 436f 6e74 656e 742d  aders={'Content-
+000116c0: 5479 7065 273a 2067 7565 7373 5f63 6f6e  Type': guess_con
+000116d0: 7465 6e74 5f74 7970 6528 6669 6c65 6e61  tent_type(filena
+000116e0: 6d65 297d 0a20 2020 2020 2020 2020 2020  me)}.           
+000116f0: 2029 0a20 2020 2020 2020 2020 2020 2076   ).            v
+00011700: 616c 7565 2e63 6c6f 7365 2829 0a20 2020  alue.close().   
+00011710: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00011720: 7265 7175 6573 745f 6669 656c 640a 2020  request_field.  
+00011730: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+00011740: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+00011750: 656c 662e 5f5f 6d75 6c74 6970 6172 745f  elf.__multipart_
+00011760: 6a73 6f6e 5f69 7465 6d28 6b65 793d 6b65  json_item(key=ke
+00011770: 792c 2076 616c 7565 3d76 616c 7565 290a  y, value=value).
+00011780: 0a20 2020 2064 6566 205f 5f73 6572 6961  .    def __seria
+00011790: 6c69 7a65 5f6d 756c 7469 7061 7274 5f66  lize_multipart_f
+000117a0: 6f72 6d5f 6461 7461 280a 2020 2020 2020  orm_data(.      
+000117b0: 2020 7365 6c66 2c20 696e 5f64 6174 613a    self, in_data:
+000117c0: 2053 6368 656d 610a 2020 2020 2920 2d3e   Schema.    ) ->
+000117d0: 2074 7970 696e 672e 4469 6374 5b73 7472   typing.Dict[str
+000117e0: 2c20 7479 7069 6e67 2e54 7570 6c65 5b52  , typing.Tuple[R
+000117f0: 6571 7565 7374 4669 656c 642c 202e 2e2e  equestField, ...
+00011800: 5d5d 3a0a 2020 2020 2020 2020 6966 206e  ]]:.        if n
+00011810: 6f74 2069 7369 6e73 7461 6e63 6528 696e  ot isinstance(in
+00011820: 5f64 6174 612c 2066 726f 7a65 6e64 6963  _data, frozendic
+00011830: 742e 6672 6f7a 656e 6469 6374 2920 616e  t.frozendict) an
+00011840: 6420 6e6f 7420 6973 696e 7374 616e 6365  d not isinstance
+00011850: 2869 6e5f 6461 7461 2c20 6c69 7374 2920  (in_data, list) 
+00011860: 616e 6420 6e6f 7420 6973 696e 7374 616e  and not isinstan
+00011870: 6365 2869 6e5f 6461 7461 2c20 7475 706c  ce(in_data, tupl
+00011880: 6529 3a0a 2020 2020 2020 2020 2020 2020  e):.            
+00011890: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
+000118a0: 2866 2755 6e61 626c 6520 746f 2073 6572  (f'Unable to ser
+000118b0: 6961 6c69 7a65 207b 696e 5f64 6174 617d  ialize {in_data}
+000118c0: 2074 6f20 6d75 6c74 6970 6172 742f 666f   to multipart/fo
+000118d0: 726d 2d64 6174 6120 6265 6361 7573 6520  rm-data because 
+000118e0: 6974 2069 7320 6e6f 7420 6120 6469 6374  it is not a dict
+000118f0: 206f 6620 6461 7461 206f 7220 6120 6c69   of data or a li
+00011900: 7374 206f 6620 6461 7461 2729 0a20 2020  st of data').   
+00011910: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
+00011920: 2049 6e20 6120 6d75 6c74 6970 6172 742f   In a multipart/
+00011930: 666f 726d 2d64 6174 6120 7265 7175 6573  form-data reques
+00011940: 7420 626f 6479 2c20 6561 6368 2073 6368  t body, each sch
+00011950: 656d 6120 7072 6f70 6572 7479 2c20 6f72  ema property, or
+00011960: 2065 6163 6820 656c 656d 656e 7420 6f66   each element of
+00011970: 2061 2073 6368 656d 6120 6172 7261 7920   a schema array 
+00011980: 7072 6f70 6572 7479 2c0a 2020 2020 2020  property,.      
+00011990: 2020 7461 6b65 7320 6120 7365 6374 696f    takes a sectio
+000119a0: 6e20 696e 2074 6865 2070 6179 6c6f 6164  n in the payload
+000119b0: 2077 6974 6820 616e 2069 6e74 6572 6e61   with an interna
+000119c0: 6c20 6865 6164 6572 2061 7320 6465 6669  l header as defi
+000119d0: 6e65 6420 6279 2052 4643 3735 3738 2e20  ned by RFC7578. 
+000119e0: 5468 6520 7365 7269 616c 697a 6174 696f  The serializatio
+000119f0: 6e20 7374 7261 7465 6779 0a20 2020 2020  n strategy.     
+00011a00: 2020 2066 6f72 2065 6163 6820 7072 6f70     for each prop
+00011a10: 6572 7479 206f 6620 6120 6d75 6c74 6970  erty of a multip
+00011a20: 6172 742f 666f 726d 2d64 6174 6120 7265  art/form-data re
+00011a30: 7175 6573 7420 626f 6479 2063 616e 2062  quest body can b
+00011a40: 6520 7370 6563 6966 6965 6420 696e 2061  e specified in a
+00011a50: 6e20 6173 736f 6369 6174 6564 2045 6e63  n associated Enc
+00011a60: 6f64 696e 6720 4f62 6a65 6374 2e0a 0a20  oding Object... 
+00011a70: 2020 2020 2020 2057 6865 6e20 7061 7373         When pass
+00011a80: 696e 6720 696e 206d 756c 7469 7061 7274  ing in multipart
+00011a90: 2074 7970 6573 2c20 626f 756e 6461 7269   types, boundari
+00011aa0: 6573 204d 4159 2062 6520 7573 6564 2074  es MAY be used t
+00011ab0: 6f20 7365 7061 7261 7465 2073 6563 7469  o separate secti
+00011ac0: 6f6e 7320 6f66 2074 6865 2063 6f6e 7465  ons of the conte
+00011ad0: 6e74 2062 6569 6e67 0a20 2020 2020 2020  nt being.       
+00011ae0: 2074 7261 6e73 6665 7272 6564 20e2 8093   transferred ...
+00011af0: 2074 6875 732c 2074 6865 2066 6f6c 6c6f   thus, the follo
+00011b00: 7769 6e67 2064 6566 6175 6c74 2043 6f6e  wing default Con
+00011b10: 7465 6e74 2d54 7970 6573 2061 7265 2064  tent-Types are d
+00011b20: 6566 696e 6564 2066 6f72 206d 756c 7469  efined for multi
+00011b30: 7061 7274 3a0a 0a20 2020 2020 2020 2049  part:..        I
+00011b40: 6620 7468 6520 286f 626a 6563 7429 2070  f the (object) p
+00011b50: 726f 7065 7274 7920 6973 2061 2070 7269  roperty is a pri
+00011b60: 6d69 7469 7665 2c20 6f72 2061 6e20 6172  mitive, or an ar
+00011b70: 7261 7920 6f66 2070 7269 6d69 7469 7665  ray of primitive
+00011b80: 2076 616c 7565 732c 2074 6865 2064 6566   values, the def
+00011b90: 6175 6c74 2043 6f6e 7465 6e74 2d54 7970  ault Content-Typ
+00011ba0: 6520 6973 2074 6578 742f 706c 6169 6e0a  e is text/plain.
+00011bb0: 2020 2020 2020 2020 4966 2074 6865 2070          If the p
+00011bc0: 726f 7065 7274 7920 6973 2063 6f6d 706c  roperty is compl
+00011bd0: 6578 2c20 6f72 2061 6e20 6172 7261 7920  ex, or an array 
+00011be0: 6f66 2063 6f6d 706c 6578 2076 616c 7565  of complex value
+00011bf0: 732c 2074 6865 2064 6566 6175 6c74 2043  s, the default C
+00011c00: 6f6e 7465 6e74 2d54 7970 6520 6973 2061  ontent-Type is a
+00011c10: 7070 6c69 6361 7469 6f6e 2f6a 736f 6e0a  pplication/json.
+00011c20: 2020 2020 2020 2020 2020 2020 5175 6573              Ques
+00011c30: 7469 6f6e 3a20 686f 7720 6973 2074 6865  tion: how is the
+00011c40: 2061 7272 6179 206f 6620 7072 696d 6974   array of primit
+00011c50: 6976 6573 2065 6e63 6f64 6564 3f0a 2020  ives encoded?.  
+00011c60: 2020 2020 2020 4966 2074 6865 2070 726f        If the pro
+00011c70: 7065 7274 7920 6973 2061 2074 7970 653a  perty is a type:
+00011c80: 2073 7472 696e 6720 7769 7468 2061 2063   string with a c
+00011c90: 6f6e 7465 6e74 456e 636f 6469 6e67 2c20  ontentEncoding, 
+00011ca0: 7468 6520 6465 6661 756c 7420 436f 6e74  the default Cont
+00011cb0: 656e 742d 5479 7065 2069 7320 6170 706c  ent-Type is appl
+00011cc0: 6963 6174 696f 6e2f 6f63 7465 742d 7374  ication/octet-st
+00011cd0: 7265 616d 0a20 2020 2020 2020 2022 2222  ream.        """
+00011ce0: 0a20 2020 2020 2020 2066 6965 6c64 733a  .        fields:
+00011cf0: 2074 7970 696e 672e 4c69 7374 5b52 6571   typing.List[Req
+00011d00: 7565 7374 4669 656c 645d 203d 205b 5d0a  uestField] = [].
+00011d10: 0a20 2020 2020 2020 2064 6566 2061 6464  .        def add
+00011d20: 5f66 6965 6c64 2864 6174 6129 3a0a 2020  _field(data):.  
+00011d30: 2020 2020 2020 2020 2020 666f 7220 6b65            for ke
+00011d40: 792c 2076 616c 7565 2069 6e20 6461 7461  y, value in data
+00011d50: 2e69 7465 6d73 2829 3a0a 2020 2020 2020  .items():.      
+00011d60: 2020 2020 2020 2020 2020 6966 2069 7369            if isi
+00011d70: 6e73 7461 6e63 6528 7661 6c75 652c 2074  nstance(value, t
+00011d80: 7570 6c65 293a 0a20 2020 2020 2020 2020  uple):.         
+00011d90: 2020 2020 2020 2020 2020 2069 6620 7661             if va
+00011da0: 6c75 653a 0a20 2020 2020 2020 2020 2020  lue:.           
+00011db0: 2020 2020 2020 2020 2020 2020 2023 2076               # v
+00011dc0: 616c 7565 7320 7573 6520 6578 706c 6f64  alues use explod
+00011dd0: 6520 3d20 5472 7565 2c20 736f 2074 6865  e = True, so the
+00011de0: 2063 6f64 6520 6d61 6b65 7320 6120 5265   code makes a Re
+00011df0: 7175 6573 7446 6965 6c64 2066 6f72 2065  questField for e
+00011e00: 6163 6820 6974 656d 2077 6974 6820 6e61  ach item with na
+00011e10: 6d65 3d6b 6579 0a20 2020 2020 2020 2020  me=key.         
+00011e20: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+00011e30: 6f72 2069 7465 6d20 696e 2076 616c 7565  or item in value
+00011e40: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00011e50: 2020 2020 2020 2020 2020 2020 2020 7265                re
+00011e60: 7175 6573 745f 6669 656c 6420 3d20 7365  quest_field = se
+00011e70: 6c66 2e5f 5f6d 756c 7469 7061 7274 5f66  lf.__multipart_f
+00011e80: 6f72 6d5f 6974 656d 286b 6579 3d6b 6579  orm_item(key=key
+00011e90: 2c20 7661 6c75 653d 6974 656d 290a 2020  , value=item).  
+00011ea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011eb0: 2020 2020 2020 2020 2020 6669 656c 6473            fields
+00011ec0: 2e61 7070 656e 6428 7265 7175 6573 745f  .append(request_
+00011ed0: 6669 656c 6429 0a20 2020 2020 2020 2020  field).         
+00011ee0: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
+00011ef0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011f00: 2020 2020 2020 2020 2023 2073 656e 6420           # send 
+00011f10: 616e 2065 6d70 7479 2061 7272 6179 2061  an empty array a
+00011f20: 7320 6a73 6f6e 2062 6563 6175 7365 2065  s json because e
+00011f30: 7870 6c6f 6469 6e67 2077 696c 6c20 6e6f  xploding will no
+00011f40: 7420 7365 6e64 2069 740a 2020 2020 2020  t send it.      
+00011f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011f60: 2020 7265 7175 6573 745f 6669 656c 6420    request_field 
+00011f70: 3d20 7365 6c66 2e5f 5f6d 756c 7469 7061  = self.__multipa
+00011f80: 7274 5f6a 736f 6e5f 6974 656d 286b 6579  rt_json_item(key
+00011f90: 3d6b 6579 2c20 7661 6c75 653d 7661 6c75  =key, value=valu
+00011fa0: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
+00011fb0: 2020 2020 2020 2020 2020 2066 6965 6c64             field
+00011fc0: 732e 6170 7065 6e64 2872 6571 7565 7374  s.append(request
+00011fd0: 5f66 6965 6c64 290a 2020 2020 2020 2020  _field).        
+00011fe0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00011ff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012000: 2020 7265 7175 6573 745f 6669 656c 6420    request_field 
+00012010: 3d20 7365 6c66 2e5f 5f6d 756c 7469 7061  = self.__multipa
+00012020: 7274 5f66 6f72 6d5f 6974 656d 286b 6579  rt_form_item(key
+00012030: 3d6b 6579 2c20 7661 6c75 653d 7661 6c75  =key, value=valu
+00012040: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
+00012050: 2020 2020 2020 2066 6965 6c64 732e 6170         fields.ap
+00012060: 7065 6e64 2872 6571 7565 7374 5f66 6965  pend(request_fie
+00012070: 6c64 290a 0a20 2020 2020 2020 2069 6620  ld)..        if 
 00012080: 6973 696e 7374 616e 6365 2869 6e5f 6461  isinstance(in_da
-00012090: 7461 2c20 7475 706c 6529 3a0a 2020 2020  ta, tuple):.    
-000120a0: 2020 2020 2020 2020 666f 7220 6974 656d          for item
-000120b0: 2069 6e20 696e 5f64 6174 613a 0a20 2020   in in_data:.   
-000120c0: 2020 2020 2020 2020 2020 2020 2061 6464               add
-000120d0: 5f66 6965 6c64 2869 7465 6d29 0a20 2020  _field(item).   
-000120e0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-000120f0: 2020 2020 2020 2061 6464 5f66 6965 6c64         add_field
-00012100: 2869 6e5f 6461 7461 290a 0a20 2020 2020  (in_data)..     
-00012110: 2020 2023 2054 6869 7320 6973 206e 6563     # This is nec
-00012120: 6573 7361 7279 2074 6f20 6669 6c6c 2074  essary to fill t
-00012130: 6865 2022 436f 6e74 656e 742d 4469 7370  he "Content-Disp
-00012140: 6f73 6974 696f 6e22 2068 6561 6465 7220  osition" header 
-00012150: 6e65 6564 6564 2066 6f72 206e 616d 696e  needed for namin
-00012160: 6720 6669 656c 6473 2069 6e20 6d75 6c74  g fields in mult
-00012170: 6970 6172 740a 2020 2020 2020 2020 666f  ipart.        fo
-00012180: 7220 6669 656c 6420 696e 2066 6965 6c64  r field in field
-00012190: 733a 0a20 2020 2020 2020 2020 2020 2066  s:.            f
-000121a0: 6965 6c64 2e6d 616b 655f 6d75 6c74 6970  ield.make_multip
-000121b0: 6172 7428 636f 6e74 656e 745f 7479 7065  art(content_type
-000121c0: 3d66 6965 6c64 2e68 6561 6465 7273 5b22  =field.headers["
-000121d0: 436f 6e74 656e 742d 5479 7065 225d 290a  Content-Type"]).
-000121e0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-000121f0: 6469 6374 2866 6965 6c64 733d 7475 706c  dict(fields=tupl
-00012200: 6528 6669 656c 6473 2929 0a0a 2020 2020  e(fields))..    
-00012210: 6465 6620 5f5f 7365 7269 616c 697a 655f  def __serialize_
-00012220: 6170 706c 6963 6174 696f 6e5f 6f63 7465  application_octe
-00012230: 745f 7374 7265 616d 2873 656c 662c 2069  t_stream(self, i
-00012240: 6e5f 6461 7461 3a20 4269 6e61 7279 5363  n_data: BinarySc
-00012250: 6865 6d61 2920 2d3e 2074 7970 696e 672e  hema) -> typing.
-00012260: 4469 6374 5b73 7472 2c20 6279 7465 735d  Dict[str, bytes]
-00012270: 3a0a 2020 2020 2020 2020 6966 2069 7369  :.        if isi
-00012280: 6e73 7461 6e63 6528 696e 5f64 6174 612c  nstance(in_data,
-00012290: 2062 7974 6573 293a 0a20 2020 2020 2020   bytes):.       
-000122a0: 2020 2020 2072 6574 7572 6e20 6469 6374       return dict
-000122b0: 2862 6f64 793d 696e 5f64 6174 6129 0a20  (body=in_data). 
-000122c0: 2020 2020 2020 2023 2046 696c 6549 4f20         # FileIO 
-000122d0: 7479 7065 0a20 2020 2020 2020 2072 6573  type.        res
-000122e0: 756c 7420 3d20 6469 6374 2862 6f64 793d  ult = dict(body=
-000122f0: 696e 5f64 6174 612e 7265 6164 2829 290a  in_data.read()).
-00012300: 2020 2020 2020 2020 696e 5f64 6174 612e          in_data.
-00012310: 636c 6f73 6528 290a 2020 2020 2020 2020  close().        
-00012320: 7265 7475 726e 2072 6573 756c 740a 0a20  return result.. 
-00012330: 2020 2064 6566 205f 5f73 6572 6961 6c69     def __seriali
-00012340: 7a65 5f61 7070 6c69 6361 7469 6f6e 5f78  ze_application_x
-00012350: 5f77 7777 5f66 6f72 6d5f 6461 7461 280a  _www_form_data(.
-00012360: 2020 2020 2020 2020 7365 6c66 2c20 696e          self, in
-00012370: 5f64 6174 613a 2074 7970 696e 672e 416e  _data: typing.An
-00012380: 790a 2020 2020 2920 2d3e 2053 6572 6961  y.    ) -> Seria
-00012390: 6c69 7a65 6452 6571 7565 7374 426f 6479  lizedRequestBody
-000123a0: 3a0a 2020 2020 2020 2020 2222 220a 2020  :.        """.  
-000123b0: 2020 2020 2020 504f 5354 2073 7562 6d69        POST submi
-000123c0: 7373 696f 6e20 6f66 2066 6f72 6d20 6461  ssion of form da
-000123d0: 7461 2069 6e20 626f 6479 0a20 2020 2020  ta in body.     
-000123e0: 2020 2022 2222 0a20 2020 2020 2020 2069     """.        i
-000123f0: 6620 6e6f 7420 6973 696e 7374 616e 6365  f not isinstance
-00012400: 2869 6e5f 6461 7461 2c20 6672 6f7a 656e  (in_data, frozen
-00012410: 6469 6374 2e66 726f 7a65 6e64 6963 7429  dict.frozendict)
-00012420: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
-00012430: 6973 6520 5661 6c75 6545 7272 6f72 280a  ise ValueError(.
-00012440: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012450: 6627 556e 6162 6c65 2074 6f20 7365 7269  f'Unable to seri
-00012460: 616c 697a 6520 7b69 6e5f 6461 7461 7d20  alize {in_data} 
-00012470: 746f 2061 7070 6c69 6361 7469 6f6e 2f78  to application/x
-00012480: 2d77 7777 2d66 6f72 6d2d 7572 6c65 6e63  -www-form-urlenc
-00012490: 6f64 6564 2062 6563 6175 7365 2069 7420  oded because it 
-000124a0: 6973 206e 6f74 2061 2064 6963 7420 6f66  is not a dict of
-000124b0: 2064 6174 6127 290a 2020 2020 2020 2020   data').        
-000124c0: 6361 7374 5f69 6e5f 6461 7461 203d 2073  cast_in_data = s
-000124d0: 656c 662e 5f5f 6a73 6f6e 5f65 6e63 6f64  elf.__json_encod
-000124e0: 6572 2e64 6566 6175 6c74 2869 6e5f 6461  er.default(in_da
-000124f0: 7461 290a 2020 2020 2020 2020 7661 6c75  ta).        valu
-00012500: 6520 3d20 7365 6c66 2e5f 7365 7269 616c  e = self._serial
-00012510: 697a 655f 666f 726d 2863 6173 745f 696e  ize_form(cast_in
-00012520: 5f64 6174 612c 206e 616d 653d 2727 2c20  _data, name='', 
-00012530: 6578 706c 6f64 653d 5472 7565 2c20 7065  explode=True, pe
-00012540: 7263 656e 745f 656e 636f 6465 3d54 7275  rcent_encode=Tru
-00012550: 6529 0a20 2020 2020 2020 2072 6574 7572  e).        retur
-00012560: 6e20 6469 6374 2862 6f64 793d 7661 6c75  n dict(body=valu
-00012570: 6529 0a0a 2020 2020 6465 6620 7365 7269  e)..    def seri
-00012580: 616c 697a 6528 0a20 2020 2020 2020 2073  alize(.        s
-00012590: 656c 662c 2069 6e5f 6461 7461 3a20 7479  elf, in_data: ty
-000125a0: 7069 6e67 2e41 6e79 2c20 636f 6e74 656e  ping.Any, conten
-000125b0: 745f 7479 7065 3a20 7374 720a 2020 2020  t_type: str.    
-000125c0: 2920 2d3e 2053 6572 6961 6c69 7a65 6452  ) -> SerializedR
-000125d0: 6571 7565 7374 426f 6479 3a0a 2020 2020  equestBody:.    
-000125e0: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
-000125f0: 4966 2061 2073 7472 2069 7320 7265 7475  If a str is retu
-00012600: 726e 6564 2074 6865 6e20 7468 6520 7265  rned then the re
-00012610: 7375 6c74 2077 696c 6c20 6265 2061 7373  sult will be ass
-00012620: 6967 6e65 6420 746f 2064 6174 6120 7768  igned to data wh
-00012630: 656e 206d 616b 696e 6720 7468 6520 7265  en making the re
-00012640: 7175 6573 740a 2020 2020 2020 2020 4966  quest.        If
-00012650: 2061 2074 7570 6c65 2069 7320 7265 7475   a tuple is retu
-00012660: 726e 6564 2074 6865 6e20 7468 6520 7265  rned then the re
-00012670: 7375 6c74 2077 696c 6c20 6265 2075 7365  sult will be use
-00012680: 6420 6173 2066 6965 6c64 7320 696e 7075  d as fields inpu
-00012690: 7420 696e 2065 6e63 6f64 655f 6d75 6c74  t in encode_mult
-000126a0: 6970 6172 745f 666f 726d 6461 7461 0a20  ipart_formdata. 
-000126b0: 2020 2020 2020 2052 6574 7572 6e20 6120         Return a 
-000126c0: 7475 706c 6520 6f66 0a0a 2020 2020 2020  tuple of..      
-000126d0: 2020 5468 6520 6b65 7920 6f66 2074 6865    The key of the
-000126e0: 2072 6574 7572 6e20 6469 6374 2069 730a   return dict is.
-000126f0: 2020 2020 2020 2020 2d20 626f 6479 2066          - body f
-00012700: 6f72 2061 7070 6c69 6361 7469 6f6e 2f6a  or application/j
-00012710: 736f 6e0a 2020 2020 2020 2020 2d20 656e  son.        - en
-00012720: 636f 6465 5f6d 756c 7469 7061 7274 2061  code_multipart a
-00012730: 6e64 2066 6965 6c64 7320 666f 7220 6d75  nd fields for mu
-00012740: 6c74 6970 6172 742f 666f 726d 2d64 6174  ltipart/form-dat
-00012750: 610a 2020 2020 2020 2020 2222 220a 2020  a.        """.  
-00012760: 2020 2020 2020 6d65 6469 615f 7479 7065        media_type
-00012770: 203d 2073 656c 662e 636f 6e74 656e 745b   = self.content[
-00012780: 636f 6e74 656e 745f 7479 7065 5d0a 2020  content_type].  
-00012790: 2020 2020 2020 6966 2069 7369 6e73 7461        if isinsta
-000127a0: 6e63 6528 696e 5f64 6174 612c 206d 6564  nce(in_data, med
-000127b0: 6961 5f74 7970 652e 7363 6865 6d61 293a  ia_type.schema):
-000127c0: 0a20 2020 2020 2020 2020 2020 2063 6173  .            cas
-000127d0: 745f 696e 5f64 6174 6120 3d20 696e 5f64  t_in_data = in_d
-000127e0: 6174 610a 2020 2020 2020 2020 656c 6966  ata.        elif
-000127f0: 2069 7369 6e73 7461 6e63 6528 696e 5f64   isinstance(in_d
-00012800: 6174 612c 2028 6469 6374 2c20 6672 6f7a  ata, (dict, froz
-00012810: 656e 6469 6374 2e66 726f 7a65 6e64 6963  endict.frozendic
-00012820: 7429 2920 616e 6420 696e 5f64 6174 613a  t)) and in_data:
-00012830: 0a20 2020 2020 2020 2020 2020 2074 7279  .            try
-00012840: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00012850: 2020 6361 7374 5f69 6e5f 6461 7461 203d    cast_in_data =
-00012860: 206d 6564 6961 5f74 7970 652e 7363 6865   media_type.sche
-00012870: 6d61 282a 2a69 6e5f 6461 7461 290a 2020  ma(**in_data).  
-00012880: 2020 2020 2020 2020 2020 6578 6365 7074            except
-00012890: 2054 7970 6545 7272 6f72 2061 7320 653a   TypeError as e:
-000128a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000128b0: 2072 6169 7365 204d 6973 7369 6e67 5265   raise MissingRe
-000128c0: 7175 6972 6564 5061 7261 6d65 7465 7273  quiredParameters
-000128d0: 4572 726f 7228 6529 0a20 2020 2020 2020  Error(e).       
-000128e0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-000128f0: 2020 2063 6173 745f 696e 5f64 6174 6120     cast_in_data 
-00012900: 3d20 6d65 6469 615f 7479 7065 2e73 6368  = media_type.sch
-00012910: 656d 6128 696e 5f64 6174 6129 0a20 2020  ema(in_data).   
-00012920: 2020 2020 2023 2054 4f44 4f20 6368 6563       # TODO chec
-00012930: 6b20 666f 7220 616e 6420 7573 6520 656e  k for and use en
-00012940: 636f 6469 6e67 2069 6620 6974 2065 7869  coding if it exi
-00012950: 7374 730a 2020 2020 2020 2020 2320 616e  sts.        # an
-00012960: 6420 636f 6e74 656e 745f 7479 7065 2069  d content_type i
-00012970: 7320 6d75 6c74 6970 6172 7420 6f72 2061  s multipart or a
-00012980: 7070 6c69 6361 7469 6f6e 2f78 2d77 7777  pplication/x-www
-00012990: 2d66 6f72 6d2d 7572 6c65 6e63 6f64 6564  -form-urlencoded
-000129a0: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
-000129b0: 2e5f 636f 6e74 656e 745f 7479 7065 5f69  ._content_type_i
-000129c0: 735f 6a73 6f6e 2863 6f6e 7465 6e74 5f74  s_json(content_t
-000129d0: 7970 6529 3a0a 2020 2020 2020 2020 2020  ype):.          
-000129e0: 2020 7265 7475 726e 2073 656c 662e 5f5f    return self.__
-000129f0: 7365 7269 616c 697a 655f 6a73 6f6e 2863  serialize_json(c
-00012a00: 6173 745f 696e 5f64 6174 6129 0a20 2020  ast_in_data).   
-00012a10: 2020 2020 2065 6c69 6620 636f 6e74 656e       elif conten
-00012a20: 745f 7479 7065 203d 3d20 2774 6578 742f  t_type == 'text/
-00012a30: 706c 6169 6e27 3a0a 2020 2020 2020 2020  plain':.        
-00012a40: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
-00012a50: 5f5f 7365 7269 616c 697a 655f 7465 7874  __serialize_text
-00012a60: 5f70 6c61 696e 2863 6173 745f 696e 5f64  _plain(cast_in_d
-00012a70: 6174 6129 0a20 2020 2020 2020 2065 6c69  ata).        eli
-00012a80: 6620 636f 6e74 656e 745f 7479 7065 203d  f content_type =
-00012a90: 3d20 276d 756c 7469 7061 7274 2f66 6f72  = 'multipart/for
-00012aa0: 6d2d 6461 7461 273a 0a20 2020 2020 2020  m-data':.       
-00012ab0: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
-00012ac0: 2e5f 5f73 6572 6961 6c69 7a65 5f6d 756c  .__serialize_mul
-00012ad0: 7469 7061 7274 5f66 6f72 6d5f 6461 7461  tipart_form_data
-00012ae0: 2863 6173 745f 696e 5f64 6174 6129 0a20  (cast_in_data). 
-00012af0: 2020 2020 2020 2065 6c69 6620 636f 6e74         elif cont
-00012b00: 656e 745f 7479 7065 203d 3d20 2761 7070  ent_type == 'app
-00012b10: 6c69 6361 7469 6f6e 2f78 2d77 7777 2d66  lication/x-www-f
-00012b20: 6f72 6d2d 7572 6c65 6e63 6f64 6564 273a  orm-urlencoded':
-00012b30: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-00012b40: 7572 6e20 7365 6c66 2e5f 5f73 6572 6961  urn self.__seria
-00012b50: 6c69 7a65 5f61 7070 6c69 6361 7469 6f6e  lize_application
-00012b60: 5f78 5f77 7777 5f66 6f72 6d5f 6461 7461  _x_www_form_data
-00012b70: 2863 6173 745f 696e 5f64 6174 6129 0a20  (cast_in_data). 
-00012b80: 2020 2020 2020 2065 6c69 6620 636f 6e74         elif cont
-00012b90: 656e 745f 7479 7065 203d 3d20 2761 7070  ent_type == 'app
-00012ba0: 6c69 6361 7469 6f6e 2f6f 6374 6574 2d73  lication/octet-s
-00012bb0: 7472 6561 6d27 3a0a 2020 2020 2020 2020  tream':.        
-00012bc0: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
-00012bd0: 5f5f 7365 7269 616c 697a 655f 6170 706c  __serialize_appl
-00012be0: 6963 6174 696f 6e5f 6f63 7465 745f 7374  ication_octet_st
-00012bf0: 7265 616d 2863 6173 745f 696e 5f64 6174  ream(cast_in_dat
-00012c00: 6129 0a20 2020 2020 2020 2072 6169 7365  a).        raise
-00012c10: 204e 6f74 496d 706c 656d 656e 7465 6445   NotImplementedE
-00012c20: 7272 6f72 2827 5365 7269 616c 697a 6174  rror('Serializat
-00012c30: 696f 6e20 6861 7320 6e6f 7420 7965 7420  ion has not yet 
-00012c40: 6265 656e 2069 6d70 6c65 6d65 6e74 6564  been implemented
-00012c50: 2066 6f72 207b 7d27 2e66 6f72 6d61 7428   for {}'.format(
-00012c60: 636f 6e74 656e 745f 7479 7065 2929 0a    content_type)).
+00012090: 7461 2c20 6c69 7374 2920 6f72 2069 7369  ta, list) or isi
+000120a0: 6e73 7461 6e63 6528 696e 5f64 6174 612c  nstance(in_data,
+000120b0: 2074 7570 6c65 293a 0a20 2020 2020 2020   tuple):.       
+000120c0: 2020 2020 2066 6f72 2069 7465 6d20 696e       for item in
+000120d0: 2069 6e5f 6461 7461 3a0a 2020 2020 2020   in_data:.      
+000120e0: 2020 2020 2020 2020 2020 6164 645f 6669            add_fi
+000120f0: 656c 6428 6974 656d 290a 2020 2020 2020  eld(item).      
+00012100: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00012110: 2020 2020 6164 645f 6669 656c 6428 696e      add_field(in
+00012120: 5f64 6174 6129 0a0a 2020 2020 2020 2020  _data)..        
+00012130: 2320 5468 6973 2069 7320 6e65 6365 7373  # This is necess
+00012140: 6172 7920 746f 2066 696c 6c20 7468 6520  ary to fill the 
+00012150: 2243 6f6e 7465 6e74 2d44 6973 706f 7369  "Content-Disposi
+00012160: 7469 6f6e 2220 6865 6164 6572 206e 6565  tion" header nee
+00012170: 6465 6420 666f 7220 6e61 6d69 6e67 2066  ded for naming f
+00012180: 6965 6c64 7320 696e 206d 756c 7469 7061  ields in multipa
+00012190: 7274 0a20 2020 2020 2020 2066 6f72 2066  rt.        for f
+000121a0: 6965 6c64 2069 6e20 6669 656c 6473 3a0a  ield in fields:.
+000121b0: 2020 2020 2020 2020 2020 2020 6669 656c              fiel
+000121c0: 642e 6d61 6b65 5f6d 756c 7469 7061 7274  d.make_multipart
+000121d0: 2863 6f6e 7465 6e74 5f74 7970 653d 6669  (content_type=fi
+000121e0: 656c 642e 6865 6164 6572 735b 2243 6f6e  eld.headers["Con
+000121f0: 7465 6e74 2d54 7970 6522 5d29 0a0a 2020  tent-Type"])..  
+00012200: 2020 2020 2020 7265 7475 726e 2064 6963        return dic
+00012210: 7428 6669 656c 6473 3d74 7570 6c65 2866  t(fields=tuple(f
+00012220: 6965 6c64 7329 290a 0a20 2020 2064 6566  ields))..    def
+00012230: 205f 5f73 6572 6961 6c69 7a65 5f61 7070   __serialize_app
+00012240: 6c69 6361 7469 6f6e 5f6f 6374 6574 5f73  lication_octet_s
+00012250: 7472 6561 6d28 7365 6c66 2c20 696e 5f64  tream(self, in_d
+00012260: 6174 613a 2042 696e 6172 7953 6368 656d  ata: BinarySchem
+00012270: 6129 202d 3e20 7479 7069 6e67 2e44 6963  a) -> typing.Dic
+00012280: 745b 7374 722c 2062 7974 6573 5d3a 0a20  t[str, bytes]:. 
+00012290: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
+000122a0: 616e 6365 2869 6e5f 6461 7461 2c20 6279  ance(in_data, by
+000122b0: 7465 7329 3a0a 2020 2020 2020 2020 2020  tes):.          
+000122c0: 2020 7265 7475 726e 2064 6963 7428 626f    return dict(bo
+000122d0: 6479 3d69 6e5f 6461 7461 290a 2020 2020  dy=in_data).    
+000122e0: 2020 2020 2320 4669 6c65 494f 2074 7970      # FileIO typ
+000122f0: 650a 2020 2020 2020 2020 7265 7375 6c74  e.        result
+00012300: 203d 2064 6963 7428 626f 6479 3d69 6e5f   = dict(body=in_
+00012310: 6461 7461 2e72 6561 6428 2929 0a20 2020  data.read()).   
+00012320: 2020 2020 2069 6e5f 6461 7461 2e63 6c6f       in_data.clo
+00012330: 7365 2829 0a20 2020 2020 2020 2072 6574  se().        ret
+00012340: 7572 6e20 7265 7375 6c74 0a0a 2020 2020  urn result..    
+00012350: 6465 6620 5f5f 7365 7269 616c 697a 655f  def __serialize_
+00012360: 6170 706c 6963 6174 696f 6e5f 785f 7777  application_x_ww
+00012370: 775f 666f 726d 5f64 6174 6128 0a20 2020  w_form_data(.   
+00012380: 2020 2020 2073 656c 662c 2069 6e5f 6461       self, in_da
+00012390: 7461 3a20 7479 7069 6e67 2e41 6e79 0a20  ta: typing.Any. 
+000123a0: 2020 2029 202d 3e20 5365 7269 616c 697a     ) -> Serializ
+000123b0: 6564 5265 7175 6573 7442 6f64 793a 0a20  edRequestBody:. 
+000123c0: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+000123d0: 2020 2050 4f53 5420 7375 626d 6973 7369     POST submissi
+000123e0: 6f6e 206f 6620 666f 726d 2064 6174 6120  on of form data 
+000123f0: 696e 2062 6f64 790a 2020 2020 2020 2020  in body.        
+00012400: 2222 220a 2020 2020 2020 2020 6966 206e  """.        if n
+00012410: 6f74 2069 7369 6e73 7461 6e63 6528 696e  ot isinstance(in
+00012420: 5f64 6174 612c 2066 726f 7a65 6e64 6963  _data, frozendic
+00012430: 742e 6672 6f7a 656e 6469 6374 293a 0a20  t.frozendict):. 
+00012440: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00012450: 2056 616c 7565 4572 726f 7228 0a20 2020   ValueError(.   
+00012460: 2020 2020 2020 2020 2020 2020 2066 2755               f'U
+00012470: 6e61 626c 6520 746f 2073 6572 6961 6c69  nable to seriali
+00012480: 7a65 207b 696e 5f64 6174 617d 2074 6f20  ze {in_data} to 
+00012490: 6170 706c 6963 6174 696f 6e2f 782d 7777  application/x-ww
+000124a0: 772d 666f 726d 2d75 726c 656e 636f 6465  w-form-urlencode
+000124b0: 6420 6265 6361 7573 6520 6974 2069 7320  d because it is 
+000124c0: 6e6f 7420 6120 6469 6374 206f 6620 6461  not a dict of da
+000124d0: 7461 2729 0a20 2020 2020 2020 2063 6173  ta').        cas
+000124e0: 745f 696e 5f64 6174 6120 3d20 7365 6c66  t_in_data = self
+000124f0: 2e5f 5f6a 736f 6e5f 656e 636f 6465 722e  .__json_encoder.
+00012500: 6465 6661 756c 7428 696e 5f64 6174 6129  default(in_data)
+00012510: 0a20 2020 2020 2020 2076 616c 7565 203d  .        value =
+00012520: 2073 656c 662e 5f73 6572 6961 6c69 7a65   self._serialize
+00012530: 5f66 6f72 6d28 6361 7374 5f69 6e5f 6461  _form(cast_in_da
+00012540: 7461 2c20 6e61 6d65 3d27 272c 2065 7870  ta, name='', exp
+00012550: 6c6f 6465 3d54 7275 652c 2070 6572 6365  lode=True, perce
+00012560: 6e74 5f65 6e63 6f64 653d 5472 7565 290a  nt_encode=True).
+00012570: 2020 2020 2020 2020 7265 7475 726e 2064          return d
+00012580: 6963 7428 626f 6479 3d76 616c 7565 290a  ict(body=value).
+00012590: 0a20 2020 2064 6566 2073 6572 6961 6c69  .    def seriali
+000125a0: 7a65 280a 2020 2020 2020 2020 7365 6c66  ze(.        self
+000125b0: 2c20 696e 5f64 6174 613a 2074 7970 696e  , in_data: typin
+000125c0: 672e 416e 792c 2063 6f6e 7465 6e74 5f74  g.Any, content_t
+000125d0: 7970 653a 2073 7472 0a20 2020 2029 202d  ype: str.    ) -
+000125e0: 3e20 5365 7269 616c 697a 6564 5265 7175  > SerializedRequ
+000125f0: 6573 7442 6f64 793a 0a20 2020 2020 2020  estBody:.       
+00012600: 2022 2222 0a20 2020 2020 2020 2049 6620   """.        If 
+00012610: 6120 7374 7220 6973 2072 6574 7572 6e65  a str is returne
+00012620: 6420 7468 656e 2074 6865 2072 6573 756c  d then the resul
+00012630: 7420 7769 6c6c 2062 6520 6173 7369 676e  t will be assign
+00012640: 6564 2074 6f20 6461 7461 2077 6865 6e20  ed to data when 
+00012650: 6d61 6b69 6e67 2074 6865 2072 6571 7565  making the reque
+00012660: 7374 0a20 2020 2020 2020 2049 6620 6120  st.        If a 
+00012670: 7475 706c 6520 6973 2072 6574 7572 6e65  tuple is returne
+00012680: 6420 7468 656e 2074 6865 2072 6573 756c  d then the resul
+00012690: 7420 7769 6c6c 2062 6520 7573 6564 2061  t will be used a
+000126a0: 7320 6669 656c 6473 2069 6e70 7574 2069  s fields input i
+000126b0: 6e20 656e 636f 6465 5f6d 756c 7469 7061  n encode_multipa
+000126c0: 7274 5f66 6f72 6d64 6174 610a 2020 2020  rt_formdata.    
+000126d0: 2020 2020 5265 7475 726e 2061 2074 7570      Return a tup
+000126e0: 6c65 206f 660a 0a20 2020 2020 2020 2054  le of..        T
+000126f0: 6865 206b 6579 206f 6620 7468 6520 7265  he key of the re
+00012700: 7475 726e 2064 6963 7420 6973 0a20 2020  turn dict is.   
+00012710: 2020 2020 202d 2062 6f64 7920 666f 7220       - body for 
+00012720: 6170 706c 6963 6174 696f 6e2f 6a73 6f6e  application/json
+00012730: 0a20 2020 2020 2020 202d 2065 6e63 6f64  .        - encod
+00012740: 655f 6d75 6c74 6970 6172 7420 616e 6420  e_multipart and 
+00012750: 6669 656c 6473 2066 6f72 206d 756c 7469  fields for multi
+00012760: 7061 7274 2f66 6f72 6d2d 6461 7461 0a20  part/form-data. 
+00012770: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+00012780: 2020 206d 6564 6961 5f74 7970 6520 3d20     media_type = 
+00012790: 7365 6c66 2e63 6f6e 7465 6e74 5b63 6f6e  self.content[con
+000127a0: 7465 6e74 5f74 7970 655d 0a20 2020 2020  tent_type].     
+000127b0: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
+000127c0: 2869 6e5f 6461 7461 2c20 6d65 6469 615f  (in_data, media_
+000127d0: 7479 7065 2e73 6368 656d 6129 3a0a 2020  type.schema):.  
+000127e0: 2020 2020 2020 2020 2020 6361 7374 5f69            cast_i
+000127f0: 6e5f 6461 7461 203d 2069 6e5f 6461 7461  n_data = in_data
+00012800: 0a20 2020 2020 2020 2065 6c69 6620 6973  .        elif is
+00012810: 696e 7374 616e 6365 2869 6e5f 6461 7461  instance(in_data
+00012820: 2c20 2864 6963 742c 2066 726f 7a65 6e64  , (dict, frozend
+00012830: 6963 742e 6672 6f7a 656e 6469 6374 2929  ict.frozendict))
+00012840: 2061 6e64 2069 6e5f 6461 7461 3a0a 2020   and in_data:.  
+00012850: 2020 2020 2020 2020 2020 7472 793a 0a20            try:. 
+00012860: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+00012870: 6173 745f 696e 5f64 6174 6120 3d20 6d65  ast_in_data = me
+00012880: 6469 615f 7479 7065 2e73 6368 656d 6128  dia_type.schema(
+00012890: 2a2a 696e 5f64 6174 6129 0a20 2020 2020  **in_data).     
+000128a0: 2020 2020 2020 2065 7863 6570 7420 5479         except Ty
+000128b0: 7065 4572 726f 7220 6173 2065 3a0a 2020  peError as e:.  
+000128c0: 2020 2020 2020 2020 2020 2020 2020 7261                ra
+000128d0: 6973 6520 4d69 7373 696e 6752 6571 7569  ise MissingRequi
+000128e0: 7265 6450 6172 616d 6574 6572 7345 7272  redParametersErr
+000128f0: 6f72 2865 290a 2020 2020 2020 2020 656c  or(e).        el
+00012900: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+00012910: 6361 7374 5f69 6e5f 6461 7461 203d 206d  cast_in_data = m
+00012920: 6564 6961 5f74 7970 652e 7363 6865 6d61  edia_type.schema
+00012930: 2869 6e5f 6461 7461 290a 2020 2020 2020  (in_data).      
+00012940: 2020 2320 544f 444f 2063 6865 636b 2066    # TODO check f
+00012950: 6f72 2061 6e64 2075 7365 2065 6e63 6f64  or and use encod
+00012960: 696e 6720 6966 2069 7420 6578 6973 7473  ing if it exists
+00012970: 0a20 2020 2020 2020 2023 2061 6e64 2063  .        # and c
+00012980: 6f6e 7465 6e74 5f74 7970 6520 6973 206d  ontent_type is m
+00012990: 756c 7469 7061 7274 206f 7220 6170 706c  ultipart or appl
+000129a0: 6963 6174 696f 6e2f 782d 7777 772d 666f  ication/x-www-fo
+000129b0: 726d 2d75 726c 656e 636f 6465 640a 2020  rm-urlencoded.  
+000129c0: 2020 2020 2020 6966 2073 656c 662e 5f63        if self._c
+000129d0: 6f6e 7465 6e74 5f74 7970 655f 6973 5f6a  ontent_type_is_j
+000129e0: 736f 6e28 636f 6e74 656e 745f 7479 7065  son(content_type
+000129f0: 293a 0a20 2020 2020 2020 2020 2020 2072  ):.            r
+00012a00: 6574 7572 6e20 7365 6c66 2e5f 5f73 6572  eturn self.__ser
+00012a10: 6961 6c69 7a65 5f6a 736f 6e28 6361 7374  ialize_json(cast
+00012a20: 5f69 6e5f 6461 7461 290a 2020 2020 2020  _in_data).      
+00012a30: 2020 656c 6966 2063 6f6e 7465 6e74 5f74    elif content_t
+00012a40: 7970 6520 3d3d 2027 7465 7874 2f70 6c61  ype == 'text/pla
+00012a50: 696e 273a 0a20 2020 2020 2020 2020 2020  in':.           
+00012a60: 2072 6574 7572 6e20 7365 6c66 2e5f 5f73   return self.__s
+00012a70: 6572 6961 6c69 7a65 5f74 6578 745f 706c  erialize_text_pl
+00012a80: 6169 6e28 6361 7374 5f69 6e5f 6461 7461  ain(cast_in_data
+00012a90: 290a 2020 2020 2020 2020 656c 6966 2063  ).        elif c
+00012aa0: 6f6e 7465 6e74 5f74 7970 6520 3d3d 2027  ontent_type == '
+00012ab0: 6d75 6c74 6970 6172 742f 666f 726d 2d64  multipart/form-d
+00012ac0: 6174 6127 3a0a 2020 2020 2020 2020 2020  ata':.          
+00012ad0: 2020 7265 7475 726e 2073 656c 662e 5f5f    return self.__
+00012ae0: 7365 7269 616c 697a 655f 6d75 6c74 6970  serialize_multip
+00012af0: 6172 745f 666f 726d 5f64 6174 6128 6361  art_form_data(ca
+00012b00: 7374 5f69 6e5f 6461 7461 290a 2020 2020  st_in_data).    
+00012b10: 2020 2020 656c 6966 2063 6f6e 7465 6e74      elif content
+00012b20: 5f74 7970 6520 3d3d 2027 6170 706c 6963  _type == 'applic
+00012b30: 6174 696f 6e2f 782d 7777 772d 666f 726d  ation/x-www-form
+00012b40: 2d75 726c 656e 636f 6465 6427 3a0a 2020  -urlencoded':.  
+00012b50: 2020 2020 2020 2020 2020 7265 7475 726e            return
+00012b60: 2073 656c 662e 5f5f 7365 7269 616c 697a   self.__serializ
+00012b70: 655f 6170 706c 6963 6174 696f 6e5f 785f  e_application_x_
+00012b80: 7777 775f 666f 726d 5f64 6174 6128 6361  www_form_data(ca
+00012b90: 7374 5f69 6e5f 6461 7461 290a 2020 2020  st_in_data).    
+00012ba0: 2020 2020 656c 6966 2063 6f6e 7465 6e74      elif content
+00012bb0: 5f74 7970 6520 3d3d 2027 6170 706c 6963  _type == 'applic
+00012bc0: 6174 696f 6e2f 6f63 7465 742d 7374 7265  ation/octet-stre
+00012bd0: 616d 273a 0a20 2020 2020 2020 2020 2020  am':.           
+00012be0: 2072 6574 7572 6e20 7365 6c66 2e5f 5f73   return self.__s
+00012bf0: 6572 6961 6c69 7a65 5f61 7070 6c69 6361  erialize_applica
+00012c00: 7469 6f6e 5f6f 6374 6574 5f73 7472 6561  tion_octet_strea
+00012c10: 6d28 6361 7374 5f69 6e5f 6461 7461 290a  m(cast_in_data).
+00012c20: 2020 2020 2020 2020 7261 6973 6520 4e6f          raise No
+00012c30: 7449 6d70 6c65 6d65 6e74 6564 4572 726f  tImplementedErro
+00012c40: 7228 2753 6572 6961 6c69 7a61 7469 6f6e  r('Serialization
+00012c50: 2068 6173 206e 6f74 2079 6574 2062 6565   has not yet bee
+00012c60: 6e20 696d 706c 656d 656e 7465 6420 666f  n implemented fo
+00012c70: 7220 7b7d 272e 666f 726d 6174 2863 6f6e  r {}'.format(con
+00012c80: 7465 6e74 5f74 7970 6529 290a            tent_type)).
```

### Comparing `carbon_python_sdk-0.1.9/carbon/api_response.py` & `carbon_python_sdk-0.2.0/carbon/api_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/apis/path_to_api.py` & `carbon_python_sdk-0.2.0/carbon/apis/path_to_api.py`

 * *Files 14% similar despite different names*

```diff
@@ -16,35 +16,42 @@
 from carbon.apis.paths.integrations_freshdesk import IntegrationsFreshdesk
 from carbon.apis.paths.integrations_outlook_user_folders import IntegrationsOutlookUserFolders
 from carbon.apis.paths.integrations_outlook_user_categories import IntegrationsOutlookUserCategories
 from carbon.apis.paths.integrations_gmail_user_labels import IntegrationsGmailUserLabels
 from carbon.apis.paths.integrations_gitbook import IntegrationsGitbook
 from carbon.apis.paths.integrations_gitbook_spaces import IntegrationsGitbookSpaces
 from carbon.apis.paths.integrations_gitbook_sync import IntegrationsGitbookSync
+from carbon.apis.paths.integrations_github import IntegrationsGithub
+from carbon.apis.paths.integrations_github_repos import IntegrationsGithubRepos
+from carbon.apis.paths.integrations_github_sync_repos import IntegrationsGithubSyncRepos
 from carbon.apis.paths.auth_v1_access_token import AuthV1AccessToken
 from carbon.apis.paths.auth_v1_white_labeling import AuthV1WhiteLabeling
 from carbon.apis.paths.embeddings import Embeddings
 from carbon.apis.paths.text_chunks import TextChunks
 from carbon.apis.paths.upload_chunks_and_embeddings import UploadChunksAndEmbeddings
 from carbon.apis.paths.organization import Organization
+from carbon.apis.paths.organization_update import OrganizationUpdate
+from carbon.apis.paths.organization_statistics import OrganizationStatistics
 from carbon.apis.paths.user import User
 from carbon.apis.paths.modify_user_configuration import ModifyUserConfiguration
 from carbon.apis.paths.delete_users import DeleteUsers
+from carbon.apis.paths.update_users import UpdateUsers
 from carbon.apis.paths.uploadfile import Uploadfile
 from carbon.apis.paths.upload_file_from_url import UploadFileFromUrl
 from carbon.apis.paths.upload_text import UploadText
-from carbon.apis.paths.deletefile_file_id import DeletefileFileId
-from carbon.apis.paths.delete_files import DeleteFiles
+from carbon.apis.paths.delete_files_v2 import DeleteFilesV2
 from carbon.apis.paths.user_files_v2 import UserFilesV2
 from carbon.apis.paths.create_user_file_tags import CreateUserFileTags
 from carbon.apis.paths.delete_user_file_tags import DeleteUserFileTags
 from carbon.apis.paths.resync_file import ResyncFile
 from carbon.apis.paths.raw_file_file_id import RawFileFileId
 from carbon.apis.paths.parsed_file_file_id import ParsedFileFileId
 from carbon.apis.paths.user_files import UserFiles
+from carbon.apis.paths.deletefile_file_id import DeletefileFileId
+from carbon.apis.paths.delete_files import DeleteFiles
 from carbon.apis.paths.webhooks import Webhooks
 from carbon.apis.paths.add_webhook import AddWebhook
 from carbon.apis.paths.delete_webhook_webhook_id import DeleteWebhookWebhookId
 from carbon.apis.paths.user_data_sources import UserDataSources
 from carbon.apis.paths.revoke_access_token import RevokeAccessToken
 from carbon.apis.paths.web_scrape import WebScrape
 from carbon.apis.paths.process_sitemap import ProcessSitemap
@@ -72,35 +79,42 @@
         PathValues.INTEGRATIONS_FRESHDESK: IntegrationsFreshdesk,
         PathValues.INTEGRATIONS_OUTLOOK_USER_FOLDERS: IntegrationsOutlookUserFolders,
         PathValues.INTEGRATIONS_OUTLOOK_USER_CATEGORIES: IntegrationsOutlookUserCategories,
         PathValues.INTEGRATIONS_GMAIL_USER_LABELS: IntegrationsGmailUserLabels,
         PathValues.INTEGRATIONS_GITBOOK: IntegrationsGitbook,
         PathValues.INTEGRATIONS_GITBOOK_SPACES: IntegrationsGitbookSpaces,
         PathValues.INTEGRATIONS_GITBOOK_SYNC: IntegrationsGitbookSync,
+        PathValues.INTEGRATIONS_GITHUB: IntegrationsGithub,
+        PathValues.INTEGRATIONS_GITHUB_REPOS: IntegrationsGithubRepos,
+        PathValues.INTEGRATIONS_GITHUB_SYNC_REPOS: IntegrationsGithubSyncRepos,
         PathValues.AUTH_V1_ACCESS_TOKEN: AuthV1AccessToken,
         PathValues.AUTH_V1_WHITE_LABELING: AuthV1WhiteLabeling,
         PathValues.EMBEDDINGS: Embeddings,
         PathValues.TEXT_CHUNKS: TextChunks,
         PathValues.UPLOAD_CHUNKS_AND_EMBEDDINGS: UploadChunksAndEmbeddings,
         PathValues.ORGANIZATION: Organization,
+        PathValues.ORGANIZATION_UPDATE: OrganizationUpdate,
+        PathValues.ORGANIZATION_STATISTICS: OrganizationStatistics,
         PathValues.USER: User,
         PathValues.MODIFY_USER_CONFIGURATION: ModifyUserConfiguration,
         PathValues.DELETE_USERS: DeleteUsers,
+        PathValues.UPDATE_USERS: UpdateUsers,
         PathValues.UPLOADFILE: Uploadfile,
         PathValues.UPLOAD_FILE_FROM_URL: UploadFileFromUrl,
         PathValues.UPLOAD_TEXT: UploadText,
-        PathValues.DELETEFILE_FILE_ID: DeletefileFileId,
-        PathValues.DELETE_FILES: DeleteFiles,
+        PathValues.DELETE_FILES_V2: DeleteFilesV2,
         PathValues.USER_FILES_V2: UserFilesV2,
         PathValues.CREATE_USER_FILE_TAGS: CreateUserFileTags,
         PathValues.DELETE_USER_FILE_TAGS: DeleteUserFileTags,
         PathValues.RESYNC_FILE: ResyncFile,
         PathValues.RAW_FILE_FILE_ID: RawFileFileId,
         PathValues.PARSED_FILE_FILE_ID: ParsedFileFileId,
         PathValues.USER_FILES: UserFiles,
+        PathValues.DELETEFILE_FILE_ID: DeletefileFileId,
+        PathValues.DELETE_FILES: DeleteFiles,
         PathValues.WEBHOOKS: Webhooks,
         PathValues.ADD_WEBHOOK: AddWebhook,
         PathValues.DELETE_WEBHOOK_WEBHOOK_ID: DeleteWebhookWebhookId,
         PathValues.USER_DATA_SOURCES: UserDataSources,
         PathValues.REVOKE_ACCESS_TOKEN: RevokeAccessToken,
         PathValues.WEB_SCRAPE: WebScrape,
         PathValues.PROCESS_SITEMAP: ProcessSitemap,
@@ -129,35 +143,42 @@
         PathValues.INTEGRATIONS_FRESHDESK: IntegrationsFreshdesk,
         PathValues.INTEGRATIONS_OUTLOOK_USER_FOLDERS: IntegrationsOutlookUserFolders,
         PathValues.INTEGRATIONS_OUTLOOK_USER_CATEGORIES: IntegrationsOutlookUserCategories,
         PathValues.INTEGRATIONS_GMAIL_USER_LABELS: IntegrationsGmailUserLabels,
         PathValues.INTEGRATIONS_GITBOOK: IntegrationsGitbook,
         PathValues.INTEGRATIONS_GITBOOK_SPACES: IntegrationsGitbookSpaces,
         PathValues.INTEGRATIONS_GITBOOK_SYNC: IntegrationsGitbookSync,
+        PathValues.INTEGRATIONS_GITHUB: IntegrationsGithub,
+        PathValues.INTEGRATIONS_GITHUB_REPOS: IntegrationsGithubRepos,
+        PathValues.INTEGRATIONS_GITHUB_SYNC_REPOS: IntegrationsGithubSyncRepos,
         PathValues.AUTH_V1_ACCESS_TOKEN: AuthV1AccessToken,
         PathValues.AUTH_V1_WHITE_LABELING: AuthV1WhiteLabeling,
         PathValues.EMBEDDINGS: Embeddings,
         PathValues.TEXT_CHUNKS: TextChunks,
         PathValues.UPLOAD_CHUNKS_AND_EMBEDDINGS: UploadChunksAndEmbeddings,
         PathValues.ORGANIZATION: Organization,
+        PathValues.ORGANIZATION_UPDATE: OrganizationUpdate,
+        PathValues.ORGANIZATION_STATISTICS: OrganizationStatistics,
         PathValues.USER: User,
         PathValues.MODIFY_USER_CONFIGURATION: ModifyUserConfiguration,
         PathValues.DELETE_USERS: DeleteUsers,
+        PathValues.UPDATE_USERS: UpdateUsers,
         PathValues.UPLOADFILE: Uploadfile,
         PathValues.UPLOAD_FILE_FROM_URL: UploadFileFromUrl,
         PathValues.UPLOAD_TEXT: UploadText,
-        PathValues.DELETEFILE_FILE_ID: DeletefileFileId,
-        PathValues.DELETE_FILES: DeleteFiles,
+        PathValues.DELETE_FILES_V2: DeleteFilesV2,
         PathValues.USER_FILES_V2: UserFilesV2,
         PathValues.CREATE_USER_FILE_TAGS: CreateUserFileTags,
         PathValues.DELETE_USER_FILE_TAGS: DeleteUserFileTags,
         PathValues.RESYNC_FILE: ResyncFile,
         PathValues.RAW_FILE_FILE_ID: RawFileFileId,
         PathValues.PARSED_FILE_FILE_ID: ParsedFileFileId,
         PathValues.USER_FILES: UserFiles,
+        PathValues.DELETEFILE_FILE_ID: DeletefileFileId,
+        PathValues.DELETE_FILES: DeleteFiles,
         PathValues.WEBHOOKS: Webhooks,
         PathValues.ADD_WEBHOOK: AddWebhook,
         PathValues.DELETE_WEBHOOK_WEBHOOK_ID: DeleteWebhookWebhookId,
         PathValues.USER_DATA_SOURCES: UserDataSources,
         PathValues.REVOKE_ACCESS_TOKEN: RevokeAccessToken,
         PathValues.WEB_SCRAPE: WebScrape,
         PathValues.PROCESS_SITEMAP: ProcessSitemap,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/apis/tag_to_api.py` & `carbon_python_sdk-0.2.0/carbon/apis/tag_to_api.py`

 * *Ordering differences only*

 * *Files 0% similar despite different names*

```diff
@@ -3,51 +3,51 @@
 from carbon.apis.tags import TagValues
 from carbon.apis.tags.integrations_api import IntegrationsApi
 from carbon.apis.tags.files_api import FilesApi
 from carbon.apis.tags.utilities_api import UtilitiesApi
 from carbon.apis.tags.users_api import UsersApi
 from carbon.apis.tags.embeddings_api import EmbeddingsApi
 from carbon.apis.tags.webhooks_api import WebhooksApi
+from carbon.apis.tags.organizations_api import OrganizationsApi
 from carbon.apis.tags.auth_api import AuthApi
 from carbon.apis.tags.data_sources_api import DataSourcesApi
 from carbon.apis.tags.health_api import HealthApi
-from carbon.apis.tags.organizations_api import OrganizationsApi
 from carbon.apis.tags.getting_started_api import GettingStartedApi
 from carbon.apis.tags.carbon_connect_api import CarbonConnectApi
 from carbon.apis.tags.contact_us_api import ContactUsApi
 
 TagToApi = typing_extensions.TypedDict(
     'TagToApi',
     {
         TagValues.INTEGRATIONS: IntegrationsApi,
         TagValues.FILES: FilesApi,
         TagValues.UTILITIES: UtilitiesApi,
         TagValues.USERS: UsersApi,
         TagValues.EMBEDDINGS: EmbeddingsApi,
         TagValues.WEBHOOKS: WebhooksApi,
+        TagValues.ORGANIZATIONS: OrganizationsApi,
         TagValues.AUTH: AuthApi,
         TagValues.DATA_SOURCES: DataSourcesApi,
         TagValues.HEALTH: HealthApi,
-        TagValues.ORGANIZATIONS: OrganizationsApi,
         TagValues.GETTING_STARTED: GettingStartedApi,
         TagValues.CARBON_CONNECT: CarbonConnectApi,
         TagValues.CONTACT_US: ContactUsApi,
     }
 )
 
 tag_to_api = TagToApi(
     {
         TagValues.INTEGRATIONS: IntegrationsApi,
         TagValues.FILES: FilesApi,
         TagValues.UTILITIES: UtilitiesApi,
         TagValues.USERS: UsersApi,
         TagValues.EMBEDDINGS: EmbeddingsApi,
         TagValues.WEBHOOKS: WebhooksApi,
+        TagValues.ORGANIZATIONS: OrganizationsApi,
         TagValues.AUTH: AuthApi,
         TagValues.DATA_SOURCES: DataSourcesApi,
         TagValues.HEALTH: HealthApi,
-        TagValues.ORGANIZATIONS: OrganizationsApi,
         TagValues.GETTING_STARTED: GettingStartedApi,
         TagValues.CARBON_CONNECT: CarbonConnectApi,
         TagValues.CONTACT_US: ContactUsApi,
     }
 )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/apis/tags/__init__.py` & `carbon_python_sdk-0.2.0/carbon/apis/tags/__init__.py`

 * *Ordering differences only*

 * *Files 0% similar despite different names*

```diff
@@ -8,14 +8,14 @@
 class TagValues(str, enum.Enum):
     INTEGRATIONS = "Integrations"
     FILES = "Files"
     UTILITIES = "Utilities"
     USERS = "Users"
     EMBEDDINGS = "Embeddings"
     WEBHOOKS = "Webhooks"
+    ORGANIZATIONS = "Organizations"
     AUTH = "Auth"
     DATA_SOURCES = "Data Sources"
     HEALTH = "Health"
-    ORGANIZATIONS = "Organizations"
     GETTING_STARTED = "Getting Started"
     CARBON_CONNECT = "Carbon Connect"
     CONTACT_US = "Contact Us"
```

### Comparing `carbon_python_sdk-0.1.9/carbon/apis/tags/auth_api.py` & `carbon_python_sdk-0.2.0/carbon/apis/tags/auth_api_generated.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,24 +1,23 @@
 # coding: utf-8
-
 """
     Carbon
 
     Connect external data to LLMs, no matter the source.
 
     The version of the OpenAPI document: 1.0.0
     Generated by: https://konfigthis.com
 """
 
 from carbon.paths.auth_v1_access_token.get import GetAccessToken
 from carbon.paths.auth_v1_white_labeling.get import GetWhiteLabeling
 from carbon.apis.tags.auth_api_raw import AuthApiRaw
 
 
-class AuthApi(
+class AuthApiGenerated(
     GetAccessToken,
     GetWhiteLabeling,
 ):
     """NOTE:
     This class is auto generated by Konfig (https://konfigthis.com)
     """
     raw: AuthApiRaw
```

### Comparing `carbon_python_sdk-0.1.9/carbon/apis/tags/data_sources_api.py` & `carbon_python_sdk-0.2.0/carbon/apis/tags/data_sources_api_generated.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,24 +1,23 @@
 # coding: utf-8
-
 """
     Carbon
 
     Connect external data to LLMs, no matter the source.
 
     The version of the OpenAPI document: 1.0.0
     Generated by: https://konfigthis.com
 """
 
 from carbon.paths.user_data_sources.post import QueryUserDataSources
 from carbon.paths.revoke_access_token.post import RevokeAccessToken
 from carbon.apis.tags.data_sources_api_raw import DataSourcesApiRaw
 
 
-class DataSourcesApi(
+class DataSourcesApiGenerated(
     QueryUserDataSources,
     RevokeAccessToken,
 ):
     """NOTE:
     This class is auto generated by Konfig (https://konfigthis.com)
     """
     raw: DataSourcesApiRaw
```

### Comparing `carbon_python_sdk-0.1.9/carbon/apis/tags/embeddings_api.py` & `carbon_python_sdk-0.2.0/carbon/apis/tags/embeddings_api_generated.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # coding: utf-8
-
 """
     Carbon
 
     Connect external data to LLMs, no matter the source.
 
     The version of the OpenAPI document: 1.0.0
     Generated by: https://konfigthis.com
@@ -11,15 +10,15 @@
 
 from carbon.paths.embeddings.post import GetDocuments
 from carbon.paths.text_chunks.post import GetEmbeddingsAndChunks
 from carbon.paths.upload_chunks_and_embeddings.post import UploadChunksAndEmbeddings
 from carbon.apis.tags.embeddings_api_raw import EmbeddingsApiRaw
 
 
-class EmbeddingsApi(
+class EmbeddingsApiGenerated(
     GetDocuments,
     GetEmbeddingsAndChunks,
     UploadChunksAndEmbeddings,
 ):
     """NOTE:
     This class is auto generated by Konfig (https://konfigthis.com)
     """
```

### Comparing `carbon_python_sdk-0.1.9/carbon/apis/tags/embeddings_api_raw.py` & `carbon_python_sdk-0.2.0/carbon/apis/tags/embeddings_api_raw.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/apis/tags/files_api.py` & `carbon_python_sdk-0.2.0/carbon/apis/tags/files_api_generated.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,38 +1,39 @@
 # coding: utf-8
-
 """
     Carbon
 
     Connect external data to LLMs, no matter the source.
 
     The version of the OpenAPI document: 1.0.0
     Generated by: https://konfigthis.com
 """
 
 from carbon.paths.create_user_file_tags.post import CreateUserFileTags
 from carbon.paths.deletefile_file_id.delete import Delete
 from carbon.paths.delete_user_file_tags.post import DeleteFileTags
 from carbon.paths.delete_files.post import DeleteMany
+from carbon.paths.delete_files_v2.post import DeleteV2
 from carbon.paths.parsed_file_file_id.get import GetParsedFile
 from carbon.paths.raw_file_file_id.get import GetRawFile
 from carbon.paths.user_files_v2.post import QueryUserFiles
 from carbon.paths.user_files.post import QueryUserFilesDeprecated
 from carbon.paths.resync_file.post import Resync
 from carbon.paths.uploadfile.post import Upload
 from carbon.paths.upload_file_from_url.post import UploadFromUrl
 from carbon.paths.upload_text.post import UploadText
 from carbon.apis.tags.files_api_raw import FilesApiRaw
 
 
-class FilesApi(
+class FilesApiGenerated(
     CreateUserFileTags,
     Delete,
     DeleteFileTags,
     DeleteMany,
+    DeleteV2,
     GetParsedFile,
     GetRawFile,
     QueryUserFiles,
     QueryUserFilesDeprecated,
     Resync,
     Upload,
     UploadFromUrl,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/apis/tags/files_api_raw.py` & `carbon_python_sdk-0.2.0/carbon/apis/tags/files_api_raw.py`

 * *Files 3% similar despite different names*

```diff
@@ -9,14 +9,15 @@
     Generated by: https://konfigthis.com
 """
 
 from carbon.paths.create_user_file_tags.post import CreateUserFileTagsRaw
 from carbon.paths.deletefile_file_id.delete import DeleteRaw
 from carbon.paths.delete_user_file_tags.post import DeleteFileTagsRaw
 from carbon.paths.delete_files.post import DeleteManyRaw
+from carbon.paths.delete_files_v2.post import DeleteV2Raw
 from carbon.paths.parsed_file_file_id.get import GetParsedFileRaw
 from carbon.paths.raw_file_file_id.get import GetRawFileRaw
 from carbon.paths.user_files_v2.post import QueryUserFilesRaw
 from carbon.paths.user_files.post import QueryUserFilesDeprecatedRaw
 from carbon.paths.resync_file.post import ResyncRaw
 from carbon.paths.uploadfile.post import UploadRaw
 from carbon.paths.upload_file_from_url.post import UploadFromUrlRaw
@@ -24,14 +25,15 @@
 
 
 class FilesApiRaw(
     CreateUserFileTagsRaw,
     DeleteRaw,
     DeleteFileTagsRaw,
     DeleteManyRaw,
+    DeleteV2Raw,
     GetParsedFileRaw,
     GetRawFileRaw,
     QueryUserFilesRaw,
     QueryUserFilesDeprecatedRaw,
     ResyncRaw,
     UploadRaw,
     UploadFromUrlRaw,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/apis/tags/health_api.py` & `carbon_python_sdk-0.2.0/carbon/apis/tags/health_api_generated.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,22 @@
 # coding: utf-8
-
 """
     Carbon
 
     Connect external data to LLMs, no matter the source.
 
     The version of the OpenAPI document: 1.0.0
     Generated by: https://konfigthis.com
 """
 
 from carbon.paths.health.get import Check
 from carbon.apis.tags.health_api_raw import HealthApiRaw
 
 
-class HealthApi(
+class HealthApiGenerated(
     Check,
 ):
     """NOTE:
     This class is auto generated by Konfig (https://konfigthis.com)
     """
     raw: HealthApiRaw
```

### Comparing `carbon_python_sdk-0.1.9/carbon/apis/tags/integrations_api.py` & `carbon_python_sdk-0.2.0/carbon/apis/tags/integrations_api_generated.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # coding: utf-8
-
 """
     Carbon
 
     Connect external data to LLMs, no matter the source.
 
     The version of the OpenAPI document: 1.0.0
     Generated by: https://konfigthis.com
@@ -16,43 +15,49 @@
 from carbon.paths.integrations_oauth_url.post import GetOauthUrl
 from carbon.paths.integrations_confluence_list.post import ListConfluencePages
 from carbon.paths.integrations_items_list.post import ListDataSourceItems
 from carbon.paths.integrations_outlook_user_folders.get import ListFolders
 from carbon.paths.integrations_gitbook_spaces.get import ListGitbookSpaces
 from carbon.paths.integrations_gmail_user_labels.get import ListLabels
 from carbon.paths.integrations_outlook_user_categories.get import ListOutlookCategories
+from carbon.paths.integrations_github_repos.get import ListRepos
 from carbon.paths.integrations_confluence_sync.post import SyncConfluence
 from carbon.paths.integrations_items_sync.post import SyncDataSourceItems
 from carbon.paths.integrations_files_sync.post import SyncFiles
+from carbon.paths.integrations_github.post import SyncGitHub
 from carbon.paths.integrations_gitbook_sync.post import SyncGitbook
 from carbon.paths.integrations_gmail_sync.post import SyncGmail
 from carbon.paths.integrations_outlook_sync.post import SyncOutlook
+from carbon.paths.integrations_github_sync_repos.post import SyncRepos
 from carbon.paths.integrations_rss_feed.post import SyncRssFeed
 from carbon.paths.integrations_s3_files.post import SyncS3Files
 from carbon.apis.tags.integrations_api_raw import IntegrationsApiRaw
 
 
-class IntegrationsApi(
+class IntegrationsApiGenerated(
     ConnectDataSource,
     ConnectFreshdesk,
     ConnectGitbook,
     CreateAwsIamUser,
     GetOauthUrl,
     ListConfluencePages,
     ListDataSourceItems,
     ListFolders,
     ListGitbookSpaces,
     ListLabels,
     ListOutlookCategories,
+    ListRepos,
     SyncConfluence,
     SyncDataSourceItems,
     SyncFiles,
+    SyncGitHub,
     SyncGitbook,
     SyncGmail,
     SyncOutlook,
+    SyncRepos,
     SyncRssFeed,
     SyncS3Files,
 ):
     """NOTE:
     This class is auto generated by Konfig (https://konfigthis.com)
     """
     raw: IntegrationsApiRaw
```

### Comparing `carbon_python_sdk-0.1.9/carbon/apis/tags/integrations_api_raw.py` & `carbon_python_sdk-0.2.0/carbon/apis/tags/integrations_api_raw.py`

 * *Files 4% similar despite different names*

```diff
@@ -16,20 +16,23 @@
 from carbon.paths.integrations_oauth_url.post import GetOauthUrlRaw
 from carbon.paths.integrations_confluence_list.post import ListConfluencePagesRaw
 from carbon.paths.integrations_items_list.post import ListDataSourceItemsRaw
 from carbon.paths.integrations_outlook_user_folders.get import ListFoldersRaw
 from carbon.paths.integrations_gitbook_spaces.get import ListGitbookSpacesRaw
 from carbon.paths.integrations_gmail_user_labels.get import ListLabelsRaw
 from carbon.paths.integrations_outlook_user_categories.get import ListOutlookCategoriesRaw
+from carbon.paths.integrations_github_repos.get import ListReposRaw
 from carbon.paths.integrations_confluence_sync.post import SyncConfluenceRaw
 from carbon.paths.integrations_items_sync.post import SyncDataSourceItemsRaw
 from carbon.paths.integrations_files_sync.post import SyncFilesRaw
+from carbon.paths.integrations_github.post import SyncGitHubRaw
 from carbon.paths.integrations_gitbook_sync.post import SyncGitbookRaw
 from carbon.paths.integrations_gmail_sync.post import SyncGmailRaw
 from carbon.paths.integrations_outlook_sync.post import SyncOutlookRaw
+from carbon.paths.integrations_github_sync_repos.post import SyncReposRaw
 from carbon.paths.integrations_rss_feed.post import SyncRssFeedRaw
 from carbon.paths.integrations_s3_files.post import SyncS3FilesRaw
 
 
 class IntegrationsApiRaw(
     ConnectDataSourceRaw,
     ConnectFreshdeskRaw,
@@ -38,20 +41,23 @@
     GetOauthUrlRaw,
     ListConfluencePagesRaw,
     ListDataSourceItemsRaw,
     ListFoldersRaw,
     ListGitbookSpacesRaw,
     ListLabelsRaw,
     ListOutlookCategoriesRaw,
+    ListReposRaw,
     SyncConfluenceRaw,
     SyncDataSourceItemsRaw,
     SyncFilesRaw,
+    SyncGitHubRaw,
     SyncGitbookRaw,
     SyncGmailRaw,
     SyncOutlookRaw,
+    SyncReposRaw,
     SyncRssFeedRaw,
     SyncS3FilesRaw,
 ):
     """NOTE:
     This class is auto generated by Konfig (https://konfigthis.com)
     """
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/apis/tags/users_api.py` & `carbon_python_sdk-0.2.0/carbon/apis/tags/users_api_generated.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,28 +1,29 @@
 # coding: utf-8
-
 """
     Carbon
 
     Connect external data to LLMs, no matter the source.
 
     The version of the OpenAPI document: 1.0.0
     Generated by: https://konfigthis.com
 """
 
 from carbon.paths.delete_users.post import Delete
 from carbon.paths.user.post import Get
 from carbon.paths.modify_user_configuration.post import ToggleUserFeatures
+from carbon.paths.update_users.post import UpdateUsers
 from carbon.apis.tags.users_api_raw import UsersApiRaw
 
 
-class UsersApi(
+class UsersApiGenerated(
     Delete,
     Get,
     ToggleUserFeatures,
+    UpdateUsers,
 ):
     """NOTE:
     This class is auto generated by Konfig (https://konfigthis.com)
     """
     raw: UsersApiRaw
 
     def __init__(self, api_client=None):
```

### Comparing `carbon_python_sdk-0.1.9/carbon/apis/tags/users_api_raw.py` & `carbon_python_sdk-0.2.0/carbon/apis/tags/users_api_raw.py`

 * *Files 10% similar despite different names*

```diff
@@ -8,18 +8,20 @@
     The version of the OpenAPI document: 1.0.0
     Generated by: https://konfigthis.com
 """
 
 from carbon.paths.delete_users.post import DeleteRaw
 from carbon.paths.user.post import GetRaw
 from carbon.paths.modify_user_configuration.post import ToggleUserFeaturesRaw
+from carbon.paths.update_users.post import UpdateUsersRaw
 
 
 class UsersApiRaw(
     DeleteRaw,
     GetRaw,
     ToggleUserFeaturesRaw,
+    UpdateUsersRaw,
 ):
     """NOTE:
     This class is auto generated by Konfig (https://konfigthis.com)
     """
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/apis/tags/utilities_api.py` & `carbon_python_sdk-0.2.0/carbon/apis/tags/utilities_api_generated.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # coding: utf-8
-
 """
     Carbon
 
     Connect external data to LLMs, no matter the source.
 
     The version of the OpenAPI document: 1.0.0
     Generated by: https://konfigthis.com
@@ -14,15 +13,15 @@
 from carbon.paths.process_sitemap.get import ProcessSitemap
 from carbon.paths.scrape_sitemap.post import ScrapeSitemap
 from carbon.paths.web_scrape.post import ScrapeWeb
 from carbon.paths.search_urls.get import SearchUrls
 from carbon.apis.tags.utilities_api_raw import UtilitiesApiRaw
 
 
-class UtilitiesApi(
+class UtilitiesApiGenerated(
     FetchUrls,
     FetchYoutubeTranscripts,
     ProcessSitemap,
     ScrapeSitemap,
     ScrapeWeb,
     SearchUrls,
 ):
```

### Comparing `carbon_python_sdk-0.1.9/carbon/apis/tags/utilities_api_raw.py` & `carbon_python_sdk-0.2.0/carbon/apis/tags/utilities_api_raw.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/apis/tags/webhooks_api.py` & `carbon_python_sdk-0.2.0/carbon/apis/tags/webhooks_api_generated.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # coding: utf-8
-
 """
     Carbon
 
     Connect external data to LLMs, no matter the source.
 
     The version of the OpenAPI document: 1.0.0
     Generated by: https://konfigthis.com
@@ -11,15 +10,15 @@
 
 from carbon.paths.add_webhook.post import AddUrl
 from carbon.paths.delete_webhook_webhook_id.delete import DeleteUrl
 from carbon.paths.webhooks.post import Urls
 from carbon.apis.tags.webhooks_api_raw import WebhooksApiRaw
 
 
-class WebhooksApi(
+class WebhooksApiGenerated(
     AddUrl,
     DeleteUrl,
     Urls,
 ):
     """NOTE:
     This class is auto generated by Konfig (https://konfigthis.com)
     """
```

### Comparing `carbon_python_sdk-0.1.9/carbon/apis/tags/webhooks_api_raw.py` & `carbon_python_sdk-0.2.0/carbon/apis/tags/webhooks_api_raw.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/client.py` & `carbon_python_sdk-0.2.0/carbon/client.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/client.pyi` & `carbon_python_sdk-0.2.0/carbon/client.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/client_custom.py` & `carbon_python_sdk-0.2.0/carbon/client_custom.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/configuration.py` & `carbon_python_sdk-0.2.0/carbon/configuration.py`

 * *Files 1% similar despite different names*

```diff
@@ -398,15 +398,15 @@
 
         :return: The report for debugging.
         """
         return "Python SDK Debug Report:\n"\
                "OS: {env}\n"\
                "Python Version: {pyversion}\n"\
                "Version of the API: 1.0.0\n"\
-               "SDK Package Version: 0.1.9".\
+               "SDK Package Version: 0.2.0".\
                format(env=sys.platform, pyversion=sys.version)
 
     def get_host_settings(self):
         """Gets an array of host settings
 
         :return: An array of host settings
         """
```

### Comparing `carbon_python_sdk-0.1.9/carbon/exceptions.py` & `carbon_python_sdk-0.2.0/carbon/exceptions.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/exceptions_base.py` & `carbon_python_sdk-0.2.0/carbon/exceptions_base.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/add_webhook_props.py` & `carbon_python_sdk-0.2.0/carbon/model/add_webhook_props.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/add_webhook_props.pyi` & `carbon_python_sdk-0.2.0/carbon/model/add_webhook_props.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/body_create_upload_file_uploadfile_post.py` & `carbon_python_sdk-0.2.0/carbon/model/body_create_upload_file_uploadfile_post.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/body_create_upload_file_uploadfile_post.pyi` & `carbon_python_sdk-0.2.0/carbon/model/body_create_upload_file_uploadfile_post.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/chunk_properties.py` & `carbon_python_sdk-0.2.0/carbon/model/chunk_properties.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/chunk_properties.pyi` & `carbon_python_sdk-0.2.0/carbon/model/chunk_properties.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/chunk_properties_nullable.py` & `carbon_python_sdk-0.2.0/carbon/model/chunk_properties_nullable.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/chunk_properties_nullable.pyi` & `carbon_python_sdk-0.2.0/carbon/model/chunk_properties_nullable.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/chunks_and_embeddings.py` & `carbon_python_sdk-0.2.0/carbon/model/chunks_and_embeddings.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/chunks_and_embeddings.pyi` & `carbon_python_sdk-0.2.0/carbon/model/chunks_and_embeddings.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/chunks_and_embeddings_embedding.py` & `carbon_python_sdk-0.2.0/carbon/model/chunks_and_embeddings_embedding.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/chunks_and_embeddings_embedding.pyi` & `carbon_python_sdk-0.2.0/carbon/model/chunks_and_embeddings_embedding.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/chunks_and_embeddings_upload_input.py` & `carbon_python_sdk-0.2.0/carbon/model/chunks_and_embeddings_upload_input.py`

 * *Files 8% similar despite different names*

```diff
@@ -66,15 +66,18 @@
                         _configuration=_configuration,
                     )
             
                 def __getitem__(self, i: int) -> 'SingleChunksAndEmbeddingsUploadInput':
                     return super().__getitem__(i)
             overwrite_existing = schemas.BoolSchema
             chunks_only = schemas.BoolSchema
-            custom_credentials = schemas.DictSchema
+        
+            @staticmethod
+            def custom_credentials() -> typing.Type['ChunksAndEmbeddingsUploadInputCustomCredentials']:
+                return ChunksAndEmbeddingsUploadInputCustomCredentials
             __annotations__ = {
                 "embedding_model": embedding_model,
                 "chunks_and_embeddings": chunks_and_embeddings,
                 "overwrite_existing": overwrite_existing,
                 "chunks_only": chunks_only,
                 "custom_credentials": custom_credentials,
             }
@@ -91,15 +94,15 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["overwrite_existing"]) -> MetaOapg.properties.overwrite_existing: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunks_only"]) -> MetaOapg.properties.chunks_only: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["custom_credentials"]) -> MetaOapg.properties.custom_credentials: ...
+    def __getitem__(self, name: typing_extensions.Literal["custom_credentials"]) -> 'ChunksAndEmbeddingsUploadInputCustomCredentials': ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
     def __getitem__(self, name: typing.Union[typing_extensions.Literal["embedding_model", "chunks_and_embeddings", "overwrite_existing", "chunks_only", "custom_credentials", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
@@ -114,15 +117,15 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["overwrite_existing"]) -> typing.Union[MetaOapg.properties.overwrite_existing, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunks_only"]) -> typing.Union[MetaOapg.properties.chunks_only, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["custom_credentials"]) -> typing.Union[MetaOapg.properties.custom_credentials, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["custom_credentials"]) -> typing.Union['ChunksAndEmbeddingsUploadInputCustomCredentials', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
     def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["embedding_model", "chunks_and_embeddings", "overwrite_existing", "chunks_only", "custom_credentials", ], str]):
         return super().get_item_oapg(name)
     
@@ -130,15 +133,15 @@
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         chunks_and_embeddings: typing.Union[MetaOapg.properties.chunks_and_embeddings, list, tuple, ],
         embedding_model: 'EmbeddingGenerators',
         overwrite_existing: typing.Union[MetaOapg.properties.overwrite_existing, bool, schemas.Unset] = schemas.unset,
         chunks_only: typing.Union[MetaOapg.properties.chunks_only, bool, schemas.Unset] = schemas.unset,
-        custom_credentials: typing.Union[MetaOapg.properties.custom_credentials, dict, frozendict.frozendict, schemas.Unset] = schemas.unset,
+        custom_credentials: typing.Union['ChunksAndEmbeddingsUploadInputCustomCredentials', schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
     ) -> 'ChunksAndEmbeddingsUploadInput':
         return super().__new__(
             cls,
             *args,
             chunks_and_embeddings=chunks_and_embeddings,
@@ -146,9 +149,10 @@
             overwrite_existing=overwrite_existing,
             chunks_only=chunks_only,
             custom_credentials=custom_credentials,
             _configuration=_configuration,
             **kwargs,
         )
 
+from carbon.model.chunks_and_embeddings_upload_input_custom_credentials import ChunksAndEmbeddingsUploadInputCustomCredentials
 from carbon.model.embedding_generators import EmbeddingGenerators
 from carbon.model.single_chunks_and_embeddings_upload_input import SingleChunksAndEmbeddingsUploadInput
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/chunks_and_embeddings_upload_input.pyi` & `carbon_python_sdk-0.2.0/carbon/model/chunks_and_embeddings_upload_input.pyi`

 * *Files 8% similar despite different names*

```diff
@@ -66,15 +66,18 @@
                         _configuration=_configuration,
                     )
             
                 def __getitem__(self, i: int) -> 'SingleChunksAndEmbeddingsUploadInput':
                     return super().__getitem__(i)
             overwrite_existing = schemas.BoolSchema
             chunks_only = schemas.BoolSchema
-            custom_credentials = schemas.DictSchema
+        
+            @staticmethod
+            def custom_credentials() -> typing.Type['ChunksAndEmbeddingsUploadInputCustomCredentials']:
+                return ChunksAndEmbeddingsUploadInputCustomCredentials
             __annotations__ = {
                 "embedding_model": embedding_model,
                 "chunks_and_embeddings": chunks_and_embeddings,
                 "overwrite_existing": overwrite_existing,
                 "chunks_only": chunks_only,
                 "custom_credentials": custom_credentials,
             }
@@ -91,15 +94,15 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["overwrite_existing"]) -> MetaOapg.properties.overwrite_existing: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunks_only"]) -> MetaOapg.properties.chunks_only: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["custom_credentials"]) -> MetaOapg.properties.custom_credentials: ...
+    def __getitem__(self, name: typing_extensions.Literal["custom_credentials"]) -> 'ChunksAndEmbeddingsUploadInputCustomCredentials': ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
     def __getitem__(self, name: typing.Union[typing_extensions.Literal["embedding_model", "chunks_and_embeddings", "overwrite_existing", "chunks_only", "custom_credentials", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
@@ -114,15 +117,15 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["overwrite_existing"]) -> typing.Union[MetaOapg.properties.overwrite_existing, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunks_only"]) -> typing.Union[MetaOapg.properties.chunks_only, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["custom_credentials"]) -> typing.Union[MetaOapg.properties.custom_credentials, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["custom_credentials"]) -> typing.Union['ChunksAndEmbeddingsUploadInputCustomCredentials', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
     def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["embedding_model", "chunks_and_embeddings", "overwrite_existing", "chunks_only", "custom_credentials", ], str]):
         return super().get_item_oapg(name)
     
@@ -130,15 +133,15 @@
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         chunks_and_embeddings: typing.Union[MetaOapg.properties.chunks_and_embeddings, list, tuple, ],
         embedding_model: 'EmbeddingGenerators',
         overwrite_existing: typing.Union[MetaOapg.properties.overwrite_existing, bool, schemas.Unset] = schemas.unset,
         chunks_only: typing.Union[MetaOapg.properties.chunks_only, bool, schemas.Unset] = schemas.unset,
-        custom_credentials: typing.Union[MetaOapg.properties.custom_credentials, dict, frozendict.frozendict, schemas.Unset] = schemas.unset,
+        custom_credentials: typing.Union['ChunksAndEmbeddingsUploadInputCustomCredentials', schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
     ) -> 'ChunksAndEmbeddingsUploadInput':
         return super().__new__(
             cls,
             *args,
             chunks_and_embeddings=chunks_and_embeddings,
@@ -146,9 +149,10 @@
             overwrite_existing=overwrite_existing,
             chunks_only=chunks_only,
             custom_credentials=custom_credentials,
             _configuration=_configuration,
             **kwargs,
         )
 
+from carbon.model.chunks_and_embeddings_upload_input_custom_credentials import ChunksAndEmbeddingsUploadInputCustomCredentials
 from carbon.model.embedding_generators import EmbeddingGenerators
 from carbon.model.single_chunks_and_embeddings_upload_input import SingleChunksAndEmbeddingsUploadInput
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/configuration_keys.py` & `carbon_python_sdk-0.2.0/carbon/model/configuration_keys.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/configuration_keys.pyi` & `carbon_python_sdk-0.2.0/carbon/model/configuration_keys.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/confluence_authentication.py` & `carbon_python_sdk-0.2.0/carbon/model/confluence_authentication.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/confluence_authentication.pyi` & `carbon_python_sdk-0.2.0/carbon/model/confluence_authentication.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/connect_data_source_input.py` & `carbon_python_sdk-0.2.0/carbon/model/connect_data_source_input.py`

 * *Files 2% similar despite different names*

```diff
@@ -63,14 +63,15 @@
                             ConfluenceAuthentication,
                             ZendeskAuthentication,
                             ZoteroAuthentication,
                             GitbookAuthetication,
                             SalesforceAuthentication,
                             FreskdeskAuthentication,
                             S3Authentication,
+                            GithubAuthentication,
                         ]
             
             
                 def __new__(
                     cls,
                     *args: typing.Union[dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
@@ -136,14 +137,15 @@
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.confluence_authentication import ConfluenceAuthentication
 from carbon.model.freskdesk_authentication import FreskdeskAuthentication
 from carbon.model.gitbook_authetication import GitbookAuthetication
+from carbon.model.github_authentication import GithubAuthentication
 from carbon.model.notion_authentication import NotionAuthentication
 from carbon.model.o_auth_authentication import OAuthAuthentication
 from carbon.model.s3_authentication import S3Authentication
 from carbon.model.salesforce_authentication import SalesforceAuthentication
 from carbon.model.sharepoint_authentication import SharepointAuthentication
 from carbon.model.sync_options import SyncOptions
 from carbon.model.zendesk_authentication import ZendeskAuthentication
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/connect_data_source_input.pyi` & `carbon_python_sdk-0.2.0/carbon/model/connect_data_source_input.pyi`

 * *Files 2% similar despite different names*

```diff
@@ -63,14 +63,15 @@
                             ConfluenceAuthentication,
                             ZendeskAuthentication,
                             ZoteroAuthentication,
                             GitbookAuthetication,
                             SalesforceAuthentication,
                             FreskdeskAuthentication,
                             S3Authentication,
+                            GithubAuthentication,
                         ]
             
             
                 def __new__(
                     cls,
                     *args: typing.Union[dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
@@ -136,14 +137,15 @@
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.confluence_authentication import ConfluenceAuthentication
 from carbon.model.freskdesk_authentication import FreskdeskAuthentication
 from carbon.model.gitbook_authetication import GitbookAuthetication
+from carbon.model.github_authentication import GithubAuthentication
 from carbon.model.notion_authentication import NotionAuthentication
 from carbon.model.o_auth_authentication import OAuthAuthentication
 from carbon.model.s3_authentication import S3Authentication
 from carbon.model.salesforce_authentication import SalesforceAuthentication
 from carbon.model.sharepoint_authentication import SharepointAuthentication
 from carbon.model.sync_options import SyncOptions
 from carbon.model.zendesk_authentication import ZendeskAuthentication
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/connect_data_source_response.py` & `carbon_python_sdk-0.2.0/carbon/model/connect_data_source_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/connect_data_source_response.pyi` & `carbon_python_sdk-0.2.0/carbon/model/connect_data_source_response.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/data_source_last_sync_actions.py` & `carbon_python_sdk-0.2.0/carbon/model/data_source_last_sync_actions.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/data_source_last_sync_actions.pyi` & `carbon_python_sdk-0.2.0/carbon/model/data_source_last_sync_actions.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/data_source_sync_statuses.py` & `carbon_python_sdk-0.2.0/carbon/model/data_source_sync_statuses.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/data_source_sync_statuses.pyi` & `carbon_python_sdk-0.2.0/carbon/model/data_source_sync_statuses.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/data_source_type.py` & `carbon_python_sdk-0.2.0/carbon/model/file_formats.py`

 * *Files 12% similar despite different names*

```diff
@@ -19,129 +19,76 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class DataSourceType(
+class FileFormats(
     schemas.EnumBase,
     schemas.StrSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         enum_value_to_name = {
-            "GOOGLE_DRIVE": "GOOGLE_DRIVE",
-            "NOTION": "NOTION",
-            "NOTION_DATABASE": "NOTION_DATABASE",
-            "INTERCOM": "INTERCOM",
-            "DROPBOX": "DROPBOX",
-            "ONEDRIVE": "ONEDRIVE",
-            "SHAREPOINT": "SHAREPOINT",
-            "CONFLUENCE": "CONFLUENCE",
-            "BOX": "BOX",
-            "ZENDESK": "ZENDESK",
-            "ZOTERO": "ZOTERO",
-            "S3": "S3",
-            "GMAIL": "GMAIL",
-            "OUTLOOK": "OUTLOOK",
-            "TEXT": "TEXT",
+            "TXT": "TXT",
             "CSV": "CSV",
             "TSV": "TSV",
             "PDF": "PDF",
             "DOCX": "DOCX",
             "PPTX": "PPTX",
             "XLSX": "XLSX",
             "MD": "MD",
             "RTF": "RTF",
             "JSON": "JSON",
-            "RAW_TEXT": "RAW_TEXT",
-            "WEB_SCRAPE": "WEB_SCRAPE",
+            "HTML": "HTML",
+            "NOTION": "NOTION",
+            "GOOGLE_DOCS": "GOOGLE_DOCS",
+            "GOOGLE_SHEETS": "GOOGLE_SHEETS",
+            "GOOGLE_SLIDES": "GOOGLE_SLIDES",
+            "INTERCOM": "INTERCOM",
+            "CONFLUENCE": "CONFLUENCE",
             "RSS_FEED": "RSS_FEED",
+            "GMAIL": "GMAIL",
+            "OUTLOOK": "OUTLOOK",
+            "ZENDESK": "ZENDESK",
             "FRESHDESK": "FRESHDESK",
+            "WEB_SCRAPE": "WEB_SCRAPE",
             "GITBOOK": "GITBOOK",
             "SALESFORCE": "SALESFORCE",
+            "GITHUB": "GITHUB",
             "JPG": "JPG",
             "PNG": "PNG",
             "MP3": "MP3",
-            "MP4": "MP4",
             "MP2": "MP2",
             "AAC": "AAC",
             "WAV": "WAV",
             "FLAC": "FLAC",
             "PCM": "PCM",
             "M4A": "M4A",
             "OGG": "OGG",
             "OPUS": "OPUS",
+            "MPEG": "MPEG",
+            "MPG": "MPG",
+            "MP4": "MP4",
+            "WMV": "WMV",
+            "AVI": "AVI",
+            "MOV": "MOV",
+            "MKV": "MKV",
+            "FLV": "FLV",
             "WEBM": "WEBM",
         }
     
     @schemas.classproperty
-    def GOOGLE_DRIVE(cls):
-        return cls("GOOGLE_DRIVE")
-    
-    @schemas.classproperty
-    def NOTION(cls):
-        return cls("NOTION")
-    
-    @schemas.classproperty
-    def NOTION_DATABASE(cls):
-        return cls("NOTION_DATABASE")
-    
-    @schemas.classproperty
-    def INTERCOM(cls):
-        return cls("INTERCOM")
-    
-    @schemas.classproperty
-    def DROPBOX(cls):
-        return cls("DROPBOX")
-    
-    @schemas.classproperty
-    def ONEDRIVE(cls):
-        return cls("ONEDRIVE")
-    
-    @schemas.classproperty
-    def SHAREPOINT(cls):
-        return cls("SHAREPOINT")
-    
-    @schemas.classproperty
-    def CONFLUENCE(cls):
-        return cls("CONFLUENCE")
-    
-    @schemas.classproperty
-    def BOX(cls):
-        return cls("BOX")
-    
-    @schemas.classproperty
-    def ZENDESK(cls):
-        return cls("ZENDESK")
-    
-    @schemas.classproperty
-    def ZOTERO(cls):
-        return cls("ZOTERO")
-    
-    @schemas.classproperty
-    def S3(cls):
-        return cls("S3")
-    
-    @schemas.classproperty
-    def GMAIL(cls):
-        return cls("GMAIL")
-    
-    @schemas.classproperty
-    def OUTLOOK(cls):
-        return cls("OUTLOOK")
-    
-    @schemas.classproperty
-    def TEXT(cls):
-        return cls("TEXT")
+    def TXT(cls):
+        return cls("TXT")
     
     @schemas.classproperty
     def CSV(cls):
         return cls("CSV")
     
     @schemas.classproperty
     def TSV(cls):
@@ -172,54 +119,90 @@
         return cls("RTF")
     
     @schemas.classproperty
     def JSON(cls):
         return cls("JSON")
     
     @schemas.classproperty
-    def RAW_TEXT(cls):
-        return cls("RAW_TEXT")
+    def HTML(cls):
+        return cls("HTML")
     
     @schemas.classproperty
-    def WEB_SCRAPE(cls):
-        return cls("WEB_SCRAPE")
+    def NOTION(cls):
+        return cls("NOTION")
+    
+    @schemas.classproperty
+    def GOOGLE_DOCS(cls):
+        return cls("GOOGLE_DOCS")
+    
+    @schemas.classproperty
+    def GOOGLE_SHEETS(cls):
+        return cls("GOOGLE_SHEETS")
+    
+    @schemas.classproperty
+    def GOOGLE_SLIDES(cls):
+        return cls("GOOGLE_SLIDES")
+    
+    @schemas.classproperty
+    def INTERCOM(cls):
+        return cls("INTERCOM")
+    
+    @schemas.classproperty
+    def CONFLUENCE(cls):
+        return cls("CONFLUENCE")
     
     @schemas.classproperty
     def RSS_FEED(cls):
         return cls("RSS_FEED")
     
     @schemas.classproperty
+    def GMAIL(cls):
+        return cls("GMAIL")
+    
+    @schemas.classproperty
+    def OUTLOOK(cls):
+        return cls("OUTLOOK")
+    
+    @schemas.classproperty
+    def ZENDESK(cls):
+        return cls("ZENDESK")
+    
+    @schemas.classproperty
     def FRESHDESK(cls):
         return cls("FRESHDESK")
     
     @schemas.classproperty
+    def WEB_SCRAPE(cls):
+        return cls("WEB_SCRAPE")
+    
+    @schemas.classproperty
     def GITBOOK(cls):
         return cls("GITBOOK")
     
     @schemas.classproperty
     def SALESFORCE(cls):
         return cls("SALESFORCE")
     
     @schemas.classproperty
+    def GITHUB(cls):
+        return cls("GITHUB")
+    
+    @schemas.classproperty
     def JPG(cls):
         return cls("JPG")
     
     @schemas.classproperty
     def PNG(cls):
         return cls("PNG")
     
     @schemas.classproperty
     def MP3(cls):
         return cls("MP3")
     
     @schemas.classproperty
-    def MP4(cls):
-        return cls("MP4")
-    
-    @schemas.classproperty
     def MP2(cls):
         return cls("MP2")
     
     @schemas.classproperty
     def AAC(cls):
         return cls("AAC")
     
@@ -244,9 +227,41 @@
         return cls("OGG")
     
     @schemas.classproperty
     def OPUS(cls):
         return cls("OPUS")
     
     @schemas.classproperty
+    def MPEG(cls):
+        return cls("MPEG")
+    
+    @schemas.classproperty
+    def MPG(cls):
+        return cls("MPG")
+    
+    @schemas.classproperty
+    def MP4(cls):
+        return cls("MP4")
+    
+    @schemas.classproperty
+    def WMV(cls):
+        return cls("WMV")
+    
+    @schemas.classproperty
+    def AVI(cls):
+        return cls("AVI")
+    
+    @schemas.classproperty
+    def MOV(cls):
+        return cls("MOV")
+    
+    @schemas.classproperty
+    def MKV(cls):
+        return cls("MKV")
+    
+    @schemas.classproperty
+    def FLV(cls):
+        return cls("FLV")
+    
+    @schemas.classproperty
     def WEBM(cls):
         return cls("WEBM")
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/data_source_type.pyi` & `carbon_python_sdk-0.2.0/carbon/model/file_formats.pyi`

 * *Files 5% similar despite different names*

```diff
@@ -19,81 +19,25 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class DataSourceType(
+class FileFormats(
     schemas.EnumBase,
     schemas.StrSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
     
     @schemas.classproperty
-    def GOOGLE_DRIVE(cls):
-        return cls("GOOGLE_DRIVE")
-    
-    @schemas.classproperty
-    def NOTION(cls):
-        return cls("NOTION")
-    
-    @schemas.classproperty
-    def NOTION_DATABASE(cls):
-        return cls("NOTION_DATABASE")
-    
-    @schemas.classproperty
-    def INTERCOM(cls):
-        return cls("INTERCOM")
-    
-    @schemas.classproperty
-    def DROPBOX(cls):
-        return cls("DROPBOX")
-    
-    @schemas.classproperty
-    def ONEDRIVE(cls):
-        return cls("ONEDRIVE")
-    
-    @schemas.classproperty
-    def SHAREPOINT(cls):
-        return cls("SHAREPOINT")
-    
-    @schemas.classproperty
-    def CONFLUENCE(cls):
-        return cls("CONFLUENCE")
-    
-    @schemas.classproperty
-    def BOX(cls):
-        return cls("BOX")
-    
-    @schemas.classproperty
-    def ZENDESK(cls):
-        return cls("ZENDESK")
-    
-    @schemas.classproperty
-    def ZOTERO(cls):
-        return cls("ZOTERO")
-    
-    @schemas.classproperty
-    def S3(cls):
-        return cls("S3")
-    
-    @schemas.classproperty
-    def GMAIL(cls):
-        return cls("GMAIL")
-    
-    @schemas.classproperty
-    def OUTLOOK(cls):
-        return cls("OUTLOOK")
-    
-    @schemas.classproperty
-    def TEXT(cls):
-        return cls("TEXT")
+    def TXT(cls):
+        return cls("TXT")
     
     @schemas.classproperty
     def CSV(cls):
         return cls("CSV")
     
     @schemas.classproperty
     def TSV(cls):
@@ -124,54 +68,90 @@
         return cls("RTF")
     
     @schemas.classproperty
     def JSON(cls):
         return cls("JSON")
     
     @schemas.classproperty
-    def RAW_TEXT(cls):
-        return cls("RAW_TEXT")
+    def HTML(cls):
+        return cls("HTML")
     
     @schemas.classproperty
-    def WEB_SCRAPE(cls):
-        return cls("WEB_SCRAPE")
+    def NOTION(cls):
+        return cls("NOTION")
+    
+    @schemas.classproperty
+    def GOOGLE_DOCS(cls):
+        return cls("GOOGLE_DOCS")
+    
+    @schemas.classproperty
+    def GOOGLE_SHEETS(cls):
+        return cls("GOOGLE_SHEETS")
+    
+    @schemas.classproperty
+    def GOOGLE_SLIDES(cls):
+        return cls("GOOGLE_SLIDES")
+    
+    @schemas.classproperty
+    def INTERCOM(cls):
+        return cls("INTERCOM")
+    
+    @schemas.classproperty
+    def CONFLUENCE(cls):
+        return cls("CONFLUENCE")
     
     @schemas.classproperty
     def RSS_FEED(cls):
         return cls("RSS_FEED")
     
     @schemas.classproperty
+    def GMAIL(cls):
+        return cls("GMAIL")
+    
+    @schemas.classproperty
+    def OUTLOOK(cls):
+        return cls("OUTLOOK")
+    
+    @schemas.classproperty
+    def ZENDESK(cls):
+        return cls("ZENDESK")
+    
+    @schemas.classproperty
     def FRESHDESK(cls):
         return cls("FRESHDESK")
     
     @schemas.classproperty
+    def WEB_SCRAPE(cls):
+        return cls("WEB_SCRAPE")
+    
+    @schemas.classproperty
     def GITBOOK(cls):
         return cls("GITBOOK")
     
     @schemas.classproperty
     def SALESFORCE(cls):
         return cls("SALESFORCE")
     
     @schemas.classproperty
+    def GITHUB(cls):
+        return cls("GITHUB")
+    
+    @schemas.classproperty
     def JPG(cls):
         return cls("JPG")
     
     @schemas.classproperty
     def PNG(cls):
         return cls("PNG")
     
     @schemas.classproperty
     def MP3(cls):
         return cls("MP3")
     
     @schemas.classproperty
-    def MP4(cls):
-        return cls("MP4")
-    
-    @schemas.classproperty
     def MP2(cls):
         return cls("MP2")
     
     @schemas.classproperty
     def AAC(cls):
         return cls("AAC")
     
@@ -196,9 +176,41 @@
         return cls("OGG")
     
     @schemas.classproperty
     def OPUS(cls):
         return cls("OPUS")
     
     @schemas.classproperty
+    def MPEG(cls):
+        return cls("MPEG")
+    
+    @schemas.classproperty
+    def MPG(cls):
+        return cls("MPG")
+    
+    @schemas.classproperty
+    def MP4(cls):
+        return cls("MP4")
+    
+    @schemas.classproperty
+    def WMV(cls):
+        return cls("WMV")
+    
+    @schemas.classproperty
+    def AVI(cls):
+        return cls("AVI")
+    
+    @schemas.classproperty
+    def MOV(cls):
+        return cls("MOV")
+    
+    @schemas.classproperty
+    def MKV(cls):
+        return cls("MKV")
+    
+    @schemas.classproperty
+    def FLV(cls):
+        return cls("FLV")
+    
+    @schemas.classproperty
     def WEBM(cls):
         return cls("WEBM")
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/data_source_type_nullable.py` & `carbon_python_sdk-0.2.0/carbon/model/data_source_type_nullable.py`

 * *Files 14% similar despite different names*

```diff
@@ -57,32 +57,42 @@
             "PDF": "PDF",
             "DOCX": "DOCX",
             "PPTX": "PPTX",
             "XLSX": "XLSX",
             "MD": "MD",
             "RTF": "RTF",
             "JSON": "JSON",
+            "HTML": "HTML",
             "RAW_TEXT": "RAW_TEXT",
             "WEB_SCRAPE": "WEB_SCRAPE",
             "RSS_FEED": "RSS_FEED",
             "FRESHDESK": "FRESHDESK",
             "GITBOOK": "GITBOOK",
             "SALESFORCE": "SALESFORCE",
+            "GITHUB": "GITHUB",
             "JPG": "JPG",
             "PNG": "PNG",
+            "JPEG": "JPEG",
             "MP3": "MP3",
-            "MP4": "MP4",
             "MP2": "MP2",
             "AAC": "AAC",
             "WAV": "WAV",
             "FLAC": "FLAC",
             "PCM": "PCM",
             "M4A": "M4A",
             "OGG": "OGG",
             "OPUS": "OPUS",
+            "MPEG": "MPEG",
+            "MPG": "MPG",
+            "MP4": "MP4",
+            "WMV": "WMV",
+            "AVI": "AVI",
+            "MOV": "MOV",
+            "MKV": "MKV",
+            "FLV": "FLV",
             "WEBM": "WEBM",
         }
     
     @schemas.classproperty
     def GOOGLE_DRIVE(cls):
         return cls("GOOGLE_DRIVE")
     
@@ -175,14 +185,18 @@
         return cls("RTF")
     
     @schemas.classproperty
     def JSON(cls):
         return cls("JSON")
     
     @schemas.classproperty
+    def HTML(cls):
+        return cls("HTML")
+    
+    @schemas.classproperty
     def RAW_TEXT(cls):
         return cls("RAW_TEXT")
     
     @schemas.classproperty
     def WEB_SCRAPE(cls):
         return cls("WEB_SCRAPE")
     
@@ -199,28 +213,32 @@
         return cls("GITBOOK")
     
     @schemas.classproperty
     def SALESFORCE(cls):
         return cls("SALESFORCE")
     
     @schemas.classproperty
+    def GITHUB(cls):
+        return cls("GITHUB")
+    
+    @schemas.classproperty
     def JPG(cls):
         return cls("JPG")
     
     @schemas.classproperty
     def PNG(cls):
         return cls("PNG")
     
     @schemas.classproperty
-    def MP3(cls):
-        return cls("MP3")
+    def JPEG(cls):
+        return cls("JPEG")
     
     @schemas.classproperty
-    def MP4(cls):
-        return cls("MP4")
+    def MP3(cls):
+        return cls("MP3")
     
     @schemas.classproperty
     def MP2(cls):
         return cls("MP2")
     
     @schemas.classproperty
     def AAC(cls):
@@ -247,14 +265,46 @@
         return cls("OGG")
     
     @schemas.classproperty
     def OPUS(cls):
         return cls("OPUS")
     
     @schemas.classproperty
+    def MPEG(cls):
+        return cls("MPEG")
+    
+    @schemas.classproperty
+    def MPG(cls):
+        return cls("MPG")
+    
+    @schemas.classproperty
+    def MP4(cls):
+        return cls("MP4")
+    
+    @schemas.classproperty
+    def WMV(cls):
+        return cls("WMV")
+    
+    @schemas.classproperty
+    def AVI(cls):
+        return cls("AVI")
+    
+    @schemas.classproperty
+    def MOV(cls):
+        return cls("MOV")
+    
+    @schemas.classproperty
+    def MKV(cls):
+        return cls("MKV")
+    
+    @schemas.classproperty
+    def FLV(cls):
+        return cls("FLV")
+    
+    @schemas.classproperty
     def WEBM(cls):
         return cls("WEBM")
 
 
     def __new__(
         cls,
         *args: typing.Union[None, str, ],
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/data_source_type_nullable.pyi` & `carbon_python_sdk-0.2.0/carbon/model/data_source_type_nullable.pyi`

 * *Files 14% similar despite different names*

```diff
@@ -57,32 +57,42 @@
             "PDF": "PDF",
             "DOCX": "DOCX",
             "PPTX": "PPTX",
             "XLSX": "XLSX",
             "MD": "MD",
             "RTF": "RTF",
             "JSON": "JSON",
+            "HTML": "HTML",
             "RAW_TEXT": "RAW_TEXT",
             "WEB_SCRAPE": "WEB_SCRAPE",
             "RSS_FEED": "RSS_FEED",
             "FRESHDESK": "FRESHDESK",
             "GITBOOK": "GITBOOK",
             "SALESFORCE": "SALESFORCE",
+            "GITHUB": "GITHUB",
             "JPG": "JPG",
             "PNG": "PNG",
+            "JPEG": "JPEG",
             "MP3": "MP3",
-            "MP4": "MP4",
             "MP2": "MP2",
             "AAC": "AAC",
             "WAV": "WAV",
             "FLAC": "FLAC",
             "PCM": "PCM",
             "M4A": "M4A",
             "OGG": "OGG",
             "OPUS": "OPUS",
+            "MPEG": "MPEG",
+            "MPG": "MPG",
+            "MP4": "MP4",
+            "WMV": "WMV",
+            "AVI": "AVI",
+            "MOV": "MOV",
+            "MKV": "MKV",
+            "FLV": "FLV",
             "WEBM": "WEBM",
         }
     
     @schemas.classproperty
     def GOOGLE_DRIVE(cls):
         return cls("GOOGLE_DRIVE")
     
@@ -175,14 +185,18 @@
         return cls("RTF")
     
     @schemas.classproperty
     def JSON(cls):
         return cls("JSON")
     
     @schemas.classproperty
+    def HTML(cls):
+        return cls("HTML")
+    
+    @schemas.classproperty
     def RAW_TEXT(cls):
         return cls("RAW_TEXT")
     
     @schemas.classproperty
     def WEB_SCRAPE(cls):
         return cls("WEB_SCRAPE")
     
@@ -199,28 +213,32 @@
         return cls("GITBOOK")
     
     @schemas.classproperty
     def SALESFORCE(cls):
         return cls("SALESFORCE")
     
     @schemas.classproperty
+    def GITHUB(cls):
+        return cls("GITHUB")
+    
+    @schemas.classproperty
     def JPG(cls):
         return cls("JPG")
     
     @schemas.classproperty
     def PNG(cls):
         return cls("PNG")
     
     @schemas.classproperty
-    def MP3(cls):
-        return cls("MP3")
+    def JPEG(cls):
+        return cls("JPEG")
     
     @schemas.classproperty
-    def MP4(cls):
-        return cls("MP4")
+    def MP3(cls):
+        return cls("MP3")
     
     @schemas.classproperty
     def MP2(cls):
         return cls("MP2")
     
     @schemas.classproperty
     def AAC(cls):
@@ -247,14 +265,46 @@
         return cls("OGG")
     
     @schemas.classproperty
     def OPUS(cls):
         return cls("OPUS")
     
     @schemas.classproperty
+    def MPEG(cls):
+        return cls("MPEG")
+    
+    @schemas.classproperty
+    def MPG(cls):
+        return cls("MPG")
+    
+    @schemas.classproperty
+    def MP4(cls):
+        return cls("MP4")
+    
+    @schemas.classproperty
+    def WMV(cls):
+        return cls("WMV")
+    
+    @schemas.classproperty
+    def AVI(cls):
+        return cls("AVI")
+    
+    @schemas.classproperty
+    def MOV(cls):
+        return cls("MOV")
+    
+    @schemas.classproperty
+    def MKV(cls):
+        return cls("MKV")
+    
+    @schemas.classproperty
+    def FLV(cls):
+        return cls("FLV")
+    
+    @schemas.classproperty
     def WEBM(cls):
         return cls("WEBM")
 
 
     def __new__(
         cls,
         *args: typing.Union[None, str, ],
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/delete_files_query_input.py` & `carbon_python_sdk-0.2.0/carbon/model/delete_files_query_input.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/delete_files_query_input.pyi` & `carbon_python_sdk-0.2.0/carbon/model/delete_files_query_input.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/delete_files_query_input_file_ids.py` & `carbon_python_sdk-0.2.0/carbon/model/delete_files_query_input_file_ids.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/delete_files_query_input_file_ids.pyi` & `carbon_python_sdk-0.2.0/carbon/model/delete_files_query_input_file_ids.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/delete_users_input.py` & `carbon_python_sdk-0.2.0/carbon/model/delete_users_input.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/delete_users_input.pyi` & `carbon_python_sdk-0.2.0/carbon/model/delete_users_input.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/delete_users_input_customer_ids.py` & `carbon_python_sdk-0.2.0/carbon/model/delete_users_input_customer_ids.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/delete_users_input_customer_ids.pyi` & `carbon_python_sdk-0.2.0/carbon/model/delete_users_input_customer_ids.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/directory_item.py` & `carbon_python_sdk-0.2.0/carbon/model/directory_item.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/directory_item.pyi` & `carbon_python_sdk-0.2.0/carbon/model/directory_item.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/document_response.py` & `carbon_python_sdk-0.2.0/carbon/model/document_response.py`

 * *Files 12% similar despite different names*

```diff
@@ -29,36 +29,58 @@
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
-            "score",
-            "file_id",
-            "content_metadata",
+            "chunk_index",
+            "parent_file_id",
             "presigned_url",
-            "rank",
             "source_type",
-            "vector",
             "source",
             "content",
             "source_url",
             "tags",
+            "score",
+            "file_id",
+            "content_metadata",
+            "rank",
+            "vector",
         }
         
         class properties:
         
             @staticmethod
             def tags() -> typing.Type['DocumentResponseTags']:
                 return DocumentResponseTags
             content = schemas.StrSchema
             file_id = schemas.IntSchema
             
             
+            class parent_file_id(
+                schemas.IntBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneDecimalMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, decimal.Decimal, int, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'parent_file_id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
             class source(
                 schemas.StrBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneStrMixin
             ):
             
@@ -198,50 +220,77 @@
                 ) -> 'content_metadata':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                         **kwargs,
                     )
+            
+            
+            class chunk_index(
+                schemas.IntBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneDecimalMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, decimal.Decimal, int, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'chunk_index':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             __annotations__ = {
                 "tags": tags,
                 "content": content,
                 "file_id": file_id,
+                "parent_file_id": parent_file_id,
                 "source": source,
                 "source_url": source_url,
                 "source_type": source_type,
                 "presigned_url": presigned_url,
                 "vector": vector,
                 "score": score,
                 "rank": rank,
                 "content_metadata": content_metadata,
+                "chunk_index": chunk_index,
             }
     
-    score: MetaOapg.properties.score
-    file_id: MetaOapg.properties.file_id
-    content_metadata: MetaOapg.properties.content_metadata
+    chunk_index: MetaOapg.properties.chunk_index
+    parent_file_id: MetaOapg.properties.parent_file_id
     presigned_url: MetaOapg.properties.presigned_url
-    rank: MetaOapg.properties.rank
     source_type: 'DataSourceTypeNullable'
-    vector: 'DocumentResponseVector'
     source: MetaOapg.properties.source
     content: MetaOapg.properties.content
     source_url: MetaOapg.properties.source_url
     tags: 'DocumentResponseTags'
+    score: MetaOapg.properties.score
+    file_id: MetaOapg.properties.file_id
+    content_metadata: MetaOapg.properties.content_metadata
+    rank: MetaOapg.properties.rank
+    vector: 'DocumentResponseVector'
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["tags"]) -> 'DocumentResponseTags': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["content"]) -> MetaOapg.properties.content: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["file_id"]) -> MetaOapg.properties.file_id: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["parent_file_id"]) -> MetaOapg.properties.parent_file_id: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["source_url"]) -> MetaOapg.properties.source_url: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["source_type"]) -> 'DataSourceTypeNullable': ...
@@ -258,31 +307,37 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["rank"]) -> MetaOapg.properties.rank: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["content_metadata"]) -> MetaOapg.properties.content_metadata: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["chunk_index"]) -> MetaOapg.properties.chunk_index: ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["tags", "content", "file_id", "source", "source_url", "source_type", "presigned_url", "vector", "score", "rank", "content_metadata", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["tags", "content", "file_id", "parent_file_id", "source", "source_url", "source_type", "presigned_url", "vector", "score", "rank", "content_metadata", "chunk_index", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> 'DocumentResponseTags': ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["content"]) -> MetaOapg.properties.content: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["file_id"]) -> MetaOapg.properties.file_id: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["parent_file_id"]) -> MetaOapg.properties.parent_file_id: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["source_url"]) -> MetaOapg.properties.source_url: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["source_type"]) -> 'DataSourceTypeNullable': ...
@@ -299,51 +354,58 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["rank"]) -> MetaOapg.properties.rank: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["content_metadata"]) -> MetaOapg.properties.content_metadata: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["chunk_index"]) -> MetaOapg.properties.chunk_index: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["tags", "content", "file_id", "source", "source_url", "source_type", "presigned_url", "vector", "score", "rank", "content_metadata", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["tags", "content", "file_id", "parent_file_id", "source", "source_url", "source_type", "presigned_url", "vector", "score", "rank", "content_metadata", "chunk_index", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        score: typing.Union[MetaOapg.properties.score, None, decimal.Decimal, int, float, ],
-        file_id: typing.Union[MetaOapg.properties.file_id, decimal.Decimal, int, ],
-        content_metadata: typing.Union[MetaOapg.properties.content_metadata, dict, frozendict.frozendict, None, ],
+        chunk_index: typing.Union[MetaOapg.properties.chunk_index, None, decimal.Decimal, int, ],
+        parent_file_id: typing.Union[MetaOapg.properties.parent_file_id, None, decimal.Decimal, int, ],
         presigned_url: typing.Union[MetaOapg.properties.presigned_url, None, str, ],
-        rank: typing.Union[MetaOapg.properties.rank, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
         source_type: 'DataSourceTypeNullable',
-        vector: 'DocumentResponseVector',
         source: typing.Union[MetaOapg.properties.source, None, str, ],
         content: typing.Union[MetaOapg.properties.content, str, ],
         source_url: typing.Union[MetaOapg.properties.source_url, None, str, ],
         tags: 'DocumentResponseTags',
+        score: typing.Union[MetaOapg.properties.score, None, decimal.Decimal, int, float, ],
+        file_id: typing.Union[MetaOapg.properties.file_id, decimal.Decimal, int, ],
+        content_metadata: typing.Union[MetaOapg.properties.content_metadata, dict, frozendict.frozendict, None, ],
+        rank: typing.Union[MetaOapg.properties.rank, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
+        vector: 'DocumentResponseVector',
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
     ) -> 'DocumentResponse':
         return super().__new__(
             cls,
             *args,
-            score=score,
-            file_id=file_id,
-            content_metadata=content_metadata,
+            chunk_index=chunk_index,
+            parent_file_id=parent_file_id,
             presigned_url=presigned_url,
-            rank=rank,
             source_type=source_type,
-            vector=vector,
             source=source,
             content=content,
             source_url=source_url,
             tags=tags,
+            score=score,
+            file_id=file_id,
+            content_metadata=content_metadata,
+            rank=rank,
+            vector=vector,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.data_source_type_nullable import DataSourceTypeNullable
 from carbon.model.document_response_tags import DocumentResponseTags
 from carbon.model.document_response_vector import DocumentResponseVector
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/document_response.pyi` & `carbon_python_sdk-0.2.0/carbon/model/document_response.pyi`

 * *Files 12% similar despite different names*

```diff
@@ -29,36 +29,58 @@
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
-            "score",
-            "file_id",
-            "content_metadata",
+            "chunk_index",
+            "parent_file_id",
             "presigned_url",
-            "rank",
             "source_type",
-            "vector",
             "source",
             "content",
             "source_url",
             "tags",
+            "score",
+            "file_id",
+            "content_metadata",
+            "rank",
+            "vector",
         }
         
         class properties:
         
             @staticmethod
             def tags() -> typing.Type['DocumentResponseTags']:
                 return DocumentResponseTags
             content = schemas.StrSchema
             file_id = schemas.IntSchema
             
             
+            class parent_file_id(
+                schemas.IntBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneDecimalMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, decimal.Decimal, int, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'parent_file_id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
             class source(
                 schemas.StrBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneStrMixin
             ):
             
@@ -198,50 +220,77 @@
                 ) -> 'content_metadata':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                         **kwargs,
                     )
+            
+            
+            class chunk_index(
+                schemas.IntBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneDecimalMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, decimal.Decimal, int, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'chunk_index':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             __annotations__ = {
                 "tags": tags,
                 "content": content,
                 "file_id": file_id,
+                "parent_file_id": parent_file_id,
                 "source": source,
                 "source_url": source_url,
                 "source_type": source_type,
                 "presigned_url": presigned_url,
                 "vector": vector,
                 "score": score,
                 "rank": rank,
                 "content_metadata": content_metadata,
+                "chunk_index": chunk_index,
             }
     
-    score: MetaOapg.properties.score
-    file_id: MetaOapg.properties.file_id
-    content_metadata: MetaOapg.properties.content_metadata
+    chunk_index: MetaOapg.properties.chunk_index
+    parent_file_id: MetaOapg.properties.parent_file_id
     presigned_url: MetaOapg.properties.presigned_url
-    rank: MetaOapg.properties.rank
     source_type: 'DataSourceTypeNullable'
-    vector: 'DocumentResponseVector'
     source: MetaOapg.properties.source
     content: MetaOapg.properties.content
     source_url: MetaOapg.properties.source_url
     tags: 'DocumentResponseTags'
+    score: MetaOapg.properties.score
+    file_id: MetaOapg.properties.file_id
+    content_metadata: MetaOapg.properties.content_metadata
+    rank: MetaOapg.properties.rank
+    vector: 'DocumentResponseVector'
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["tags"]) -> 'DocumentResponseTags': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["content"]) -> MetaOapg.properties.content: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["file_id"]) -> MetaOapg.properties.file_id: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["parent_file_id"]) -> MetaOapg.properties.parent_file_id: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["source_url"]) -> MetaOapg.properties.source_url: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["source_type"]) -> 'DataSourceTypeNullable': ...
@@ -258,31 +307,37 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["rank"]) -> MetaOapg.properties.rank: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["content_metadata"]) -> MetaOapg.properties.content_metadata: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["chunk_index"]) -> MetaOapg.properties.chunk_index: ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["tags", "content", "file_id", "source", "source_url", "source_type", "presigned_url", "vector", "score", "rank", "content_metadata", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["tags", "content", "file_id", "parent_file_id", "source", "source_url", "source_type", "presigned_url", "vector", "score", "rank", "content_metadata", "chunk_index", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> 'DocumentResponseTags': ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["content"]) -> MetaOapg.properties.content: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["file_id"]) -> MetaOapg.properties.file_id: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["parent_file_id"]) -> MetaOapg.properties.parent_file_id: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["source_url"]) -> MetaOapg.properties.source_url: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["source_type"]) -> 'DataSourceTypeNullable': ...
@@ -299,51 +354,58 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["rank"]) -> MetaOapg.properties.rank: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["content_metadata"]) -> MetaOapg.properties.content_metadata: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["chunk_index"]) -> MetaOapg.properties.chunk_index: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["tags", "content", "file_id", "source", "source_url", "source_type", "presigned_url", "vector", "score", "rank", "content_metadata", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["tags", "content", "file_id", "parent_file_id", "source", "source_url", "source_type", "presigned_url", "vector", "score", "rank", "content_metadata", "chunk_index", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        score: typing.Union[MetaOapg.properties.score, None, decimal.Decimal, int, float, ],
-        file_id: typing.Union[MetaOapg.properties.file_id, decimal.Decimal, int, ],
-        content_metadata: typing.Union[MetaOapg.properties.content_metadata, dict, frozendict.frozendict, None, ],
+        chunk_index: typing.Union[MetaOapg.properties.chunk_index, None, decimal.Decimal, int, ],
+        parent_file_id: typing.Union[MetaOapg.properties.parent_file_id, None, decimal.Decimal, int, ],
         presigned_url: typing.Union[MetaOapg.properties.presigned_url, None, str, ],
-        rank: typing.Union[MetaOapg.properties.rank, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
         source_type: 'DataSourceTypeNullable',
-        vector: 'DocumentResponseVector',
         source: typing.Union[MetaOapg.properties.source, None, str, ],
         content: typing.Union[MetaOapg.properties.content, str, ],
         source_url: typing.Union[MetaOapg.properties.source_url, None, str, ],
         tags: 'DocumentResponseTags',
+        score: typing.Union[MetaOapg.properties.score, None, decimal.Decimal, int, float, ],
+        file_id: typing.Union[MetaOapg.properties.file_id, decimal.Decimal, int, ],
+        content_metadata: typing.Union[MetaOapg.properties.content_metadata, dict, frozendict.frozendict, None, ],
+        rank: typing.Union[MetaOapg.properties.rank, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
+        vector: 'DocumentResponseVector',
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
     ) -> 'DocumentResponse':
         return super().__new__(
             cls,
             *args,
-            score=score,
-            file_id=file_id,
-            content_metadata=content_metadata,
+            chunk_index=chunk_index,
+            parent_file_id=parent_file_id,
             presigned_url=presigned_url,
-            rank=rank,
             source_type=source_type,
-            vector=vector,
             source=source,
             content=content,
             source_url=source_url,
             tags=tags,
+            score=score,
+            file_id=file_id,
+            content_metadata=content_metadata,
+            rank=rank,
+            vector=vector,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.data_source_type_nullable import DataSourceTypeNullable
 from carbon.model.document_response_tags import DocumentResponseTags
 from carbon.model.document_response_vector import DocumentResponseVector
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/document_response_list.py` & `carbon_python_sdk-0.2.0/carbon/model/document_response_list.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/document_response_list.pyi` & `carbon_python_sdk-0.2.0/carbon/model/document_response_list.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/document_response_tags.py` & `carbon_python_sdk-0.2.0/carbon/model/document_response_tags.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/document_response_tags.pyi` & `carbon_python_sdk-0.2.0/carbon/model/document_response_tags.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/document_response_vector.py` & `carbon_python_sdk-0.2.0/carbon/model/document_response_vector.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/document_response_vector.pyi` & `carbon_python_sdk-0.2.0/carbon/model/document_response_vector.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/embedding_and_chunk.py` & `carbon_python_sdk-0.2.0/carbon/model/file_sync_config.py`

 * *Files 18% similar despite different names*

```diff
@@ -19,123 +19,105 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class EmbeddingAndChunk(
+class FileSyncConfig(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
-        required = {
-            "chunk_index",
-            "source_content",
-            "user_file_id",
-            "embedding",
-        }
         
         class properties:
-            user_file_id = schemas.IntSchema
             
             
-            class chunk_index(
-                schemas.IntBase,
-                schemas.NoneBase,
-                schemas.Schema,
-                schemas.NoneDecimalMixin
+            class auto_synced_source_types(
+                schemas.ListSchema
             ):
             
             
+                class MetaOapg:
+                    
+                    @staticmethod
+                    def items() -> typing.Type['HelpdeskFileTypes']:
+                        return HelpdeskFileTypes
+            
                 def __new__(
                     cls,
-                    *args: typing.Union[None, decimal.Decimal, int, ],
+                    arg: typing.Union[typing.Tuple['HelpdeskFileTypes'], typing.List['HelpdeskFileTypes']],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'chunk_index':
+                ) -> 'auto_synced_source_types':
                     return super().__new__(
                         cls,
-                        *args,
+                        arg,
                         _configuration=_configuration,
                     )
-            source_content = schemas.StrSchema
-        
-            @staticmethod
-            def embedding() -> typing.Type['EmbeddingAndChunkEmbedding']:
-                return EmbeddingAndChunkEmbedding
+            
+                def __getitem__(self, i: int) -> 'HelpdeskFileTypes':
+                    return super().__getitem__(i)
+            sync_attachments = schemas.BoolSchema
+            detect_audio_language = schemas.BoolSchema
             __annotations__ = {
-                "user_file_id": user_file_id,
-                "chunk_index": chunk_index,
-                "source_content": source_content,
-                "embedding": embedding,
+                "auto_synced_source_types": auto_synced_source_types,
+                "sync_attachments": sync_attachments,
+                "detect_audio_language": detect_audio_language,
             }
     
-    chunk_index: MetaOapg.properties.chunk_index
-    source_content: MetaOapg.properties.source_content
-    user_file_id: MetaOapg.properties.user_file_id
-    embedding: 'EmbeddingAndChunkEmbedding'
-    
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["user_file_id"]) -> MetaOapg.properties.user_file_id: ...
+    def __getitem__(self, name: typing_extensions.Literal["auto_synced_source_types"]) -> MetaOapg.properties.auto_synced_source_types: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["chunk_index"]) -> MetaOapg.properties.chunk_index: ...
+    def __getitem__(self, name: typing_extensions.Literal["sync_attachments"]) -> MetaOapg.properties.sync_attachments: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["source_content"]) -> MetaOapg.properties.source_content: ...
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["embedding"]) -> 'EmbeddingAndChunkEmbedding': ...
+    def __getitem__(self, name: typing_extensions.Literal["detect_audio_language"]) -> MetaOapg.properties.detect_audio_language: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["user_file_id", "chunk_index", "source_content", "embedding", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["auto_synced_source_types", "sync_attachments", "detect_audio_language", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["user_file_id"]) -> MetaOapg.properties.user_file_id: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["chunk_index"]) -> MetaOapg.properties.chunk_index: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["auto_synced_source_types"]) -> typing.Union[MetaOapg.properties.auto_synced_source_types, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["source_content"]) -> MetaOapg.properties.source_content: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_attachments"]) -> typing.Union[MetaOapg.properties.sync_attachments, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["embedding"]) -> 'EmbeddingAndChunkEmbedding': ...
+    def get_item_oapg(self, name: typing_extensions.Literal["detect_audio_language"]) -> typing.Union[MetaOapg.properties.detect_audio_language, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["user_file_id", "chunk_index", "source_content", "embedding", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["auto_synced_source_types", "sync_attachments", "detect_audio_language", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        chunk_index: typing.Union[MetaOapg.properties.chunk_index, None, decimal.Decimal, int, ],
-        source_content: typing.Union[MetaOapg.properties.source_content, str, ],
-        user_file_id: typing.Union[MetaOapg.properties.user_file_id, decimal.Decimal, int, ],
-        embedding: 'EmbeddingAndChunkEmbedding',
+        auto_synced_source_types: typing.Union[MetaOapg.properties.auto_synced_source_types, list, tuple, schemas.Unset] = schemas.unset,
+        sync_attachments: typing.Union[MetaOapg.properties.sync_attachments, bool, schemas.Unset] = schemas.unset,
+        detect_audio_language: typing.Union[MetaOapg.properties.detect_audio_language, bool, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'EmbeddingAndChunk':
+    ) -> 'FileSyncConfig':
         return super().__new__(
             cls,
             *args,
-            chunk_index=chunk_index,
-            source_content=source_content,
-            user_file_id=user_file_id,
-            embedding=embedding,
+            auto_synced_source_types=auto_synced_source_types,
+            sync_attachments=sync_attachments,
+            detect_audio_language=detect_audio_language,
             _configuration=_configuration,
             **kwargs,
         )
 
-from carbon.model.embedding_and_chunk_embedding import EmbeddingAndChunkEmbedding
+from carbon.model.helpdesk_file_types import HelpdeskFileTypes
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/embedding_and_chunk.pyi` & `carbon_python_sdk-0.2.0/carbon/model/file_sync_config.pyi`

 * *Files 18% similar despite different names*

```diff
@@ -19,123 +19,105 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class EmbeddingAndChunk(
+class FileSyncConfig(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
-        required = {
-            "chunk_index",
-            "source_content",
-            "user_file_id",
-            "embedding",
-        }
         
         class properties:
-            user_file_id = schemas.IntSchema
             
             
-            class chunk_index(
-                schemas.IntBase,
-                schemas.NoneBase,
-                schemas.Schema,
-                schemas.NoneDecimalMixin
+            class auto_synced_source_types(
+                schemas.ListSchema
             ):
             
             
+                class MetaOapg:
+                    
+                    @staticmethod
+                    def items() -> typing.Type['HelpdeskFileTypes']:
+                        return HelpdeskFileTypes
+            
                 def __new__(
                     cls,
-                    *args: typing.Union[None, decimal.Decimal, int, ],
+                    arg: typing.Union[typing.Tuple['HelpdeskFileTypes'], typing.List['HelpdeskFileTypes']],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'chunk_index':
+                ) -> 'auto_synced_source_types':
                     return super().__new__(
                         cls,
-                        *args,
+                        arg,
                         _configuration=_configuration,
                     )
-            source_content = schemas.StrSchema
-        
-            @staticmethod
-            def embedding() -> typing.Type['EmbeddingAndChunkEmbedding']:
-                return EmbeddingAndChunkEmbedding
+            
+                def __getitem__(self, i: int) -> 'HelpdeskFileTypes':
+                    return super().__getitem__(i)
+            sync_attachments = schemas.BoolSchema
+            detect_audio_language = schemas.BoolSchema
             __annotations__ = {
-                "user_file_id": user_file_id,
-                "chunk_index": chunk_index,
-                "source_content": source_content,
-                "embedding": embedding,
+                "auto_synced_source_types": auto_synced_source_types,
+                "sync_attachments": sync_attachments,
+                "detect_audio_language": detect_audio_language,
             }
     
-    chunk_index: MetaOapg.properties.chunk_index
-    source_content: MetaOapg.properties.source_content
-    user_file_id: MetaOapg.properties.user_file_id
-    embedding: 'EmbeddingAndChunkEmbedding'
-    
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["user_file_id"]) -> MetaOapg.properties.user_file_id: ...
+    def __getitem__(self, name: typing_extensions.Literal["auto_synced_source_types"]) -> MetaOapg.properties.auto_synced_source_types: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["chunk_index"]) -> MetaOapg.properties.chunk_index: ...
+    def __getitem__(self, name: typing_extensions.Literal["sync_attachments"]) -> MetaOapg.properties.sync_attachments: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["source_content"]) -> MetaOapg.properties.source_content: ...
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["embedding"]) -> 'EmbeddingAndChunkEmbedding': ...
+    def __getitem__(self, name: typing_extensions.Literal["detect_audio_language"]) -> MetaOapg.properties.detect_audio_language: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["user_file_id", "chunk_index", "source_content", "embedding", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["auto_synced_source_types", "sync_attachments", "detect_audio_language", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["user_file_id"]) -> MetaOapg.properties.user_file_id: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["chunk_index"]) -> MetaOapg.properties.chunk_index: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["auto_synced_source_types"]) -> typing.Union[MetaOapg.properties.auto_synced_source_types, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["source_content"]) -> MetaOapg.properties.source_content: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_attachments"]) -> typing.Union[MetaOapg.properties.sync_attachments, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["embedding"]) -> 'EmbeddingAndChunkEmbedding': ...
+    def get_item_oapg(self, name: typing_extensions.Literal["detect_audio_language"]) -> typing.Union[MetaOapg.properties.detect_audio_language, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["user_file_id", "chunk_index", "source_content", "embedding", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["auto_synced_source_types", "sync_attachments", "detect_audio_language", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        chunk_index: typing.Union[MetaOapg.properties.chunk_index, None, decimal.Decimal, int, ],
-        source_content: typing.Union[MetaOapg.properties.source_content, str, ],
-        user_file_id: typing.Union[MetaOapg.properties.user_file_id, decimal.Decimal, int, ],
-        embedding: 'EmbeddingAndChunkEmbedding',
+        auto_synced_source_types: typing.Union[MetaOapg.properties.auto_synced_source_types, list, tuple, schemas.Unset] = schemas.unset,
+        sync_attachments: typing.Union[MetaOapg.properties.sync_attachments, bool, schemas.Unset] = schemas.unset,
+        detect_audio_language: typing.Union[MetaOapg.properties.detect_audio_language, bool, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'EmbeddingAndChunk':
+    ) -> 'FileSyncConfig':
         return super().__new__(
             cls,
             *args,
-            chunk_index=chunk_index,
-            source_content=source_content,
-            user_file_id=user_file_id,
-            embedding=embedding,
+            auto_synced_source_types=auto_synced_source_types,
+            sync_attachments=sync_attachments,
+            detect_audio_language=detect_audio_language,
             _configuration=_configuration,
             **kwargs,
         )
 
-from carbon.model.embedding_and_chunk_embedding import EmbeddingAndChunkEmbedding
+from carbon.model.helpdesk_file_types import HelpdeskFileTypes
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/embedding_and_chunk_embedding.py` & `carbon_python_sdk-0.2.0/carbon/model/embedding_and_chunk_embedding.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/embedding_and_chunk_embedding.pyi` & `carbon_python_sdk-0.2.0/carbon/model/embedding_and_chunk_embedding.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/embedding_generators.py` & `carbon_python_sdk-0.2.0/carbon/model/text_embedding_generators.py`

 * *Files 5% similar despite different names*

```diff
@@ -19,78 +19,54 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class EmbeddingGenerators(
+class TextEmbeddingGenerators(
     schemas.EnumBase,
     schemas.StrSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         enum_value_to_name = {
             "OPENAI": "OPENAI",
             "AZURE_OPENAI": "AZURE_OPENAI",
-            "AZURE_ADA_LARGE_256": "AZURE_ADA_LARGE_256",
-            "AZURE_ADA_LARGE_1024": "AZURE_ADA_LARGE_1024",
-            "AZURE_ADA_LARGE_3072": "AZURE_ADA_LARGE_3072",
-            "AZURE_ADA_SMALL_512": "AZURE_ADA_SMALL_512",
-            "AZURE_ADA_SMALL_1536": "AZURE_ADA_SMALL_1536",
             "COHERE_MULTILINGUAL_V3": "COHERE_MULTILINGUAL_V3",
-            "VERTEX_MULTIMODAL": "VERTEX_MULTIMODAL",
             "OPENAI_ADA_LARGE_256": "OPENAI_ADA_LARGE_256",
             "OPENAI_ADA_LARGE_1024": "OPENAI_ADA_LARGE_1024",
             "OPENAI_ADA_LARGE_3072": "OPENAI_ADA_LARGE_3072",
             "OPENAI_ADA_SMALL_512": "OPENAI_ADA_SMALL_512",
             "OPENAI_ADA_SMALL_1536": "OPENAI_ADA_SMALL_1536",
+            "AZURE_ADA_LARGE_256": "AZURE_ADA_LARGE_256",
+            "AZURE_ADA_LARGE_1024": "AZURE_ADA_LARGE_1024",
+            "AZURE_ADA_LARGE_3072": "AZURE_ADA_LARGE_3072",
+            "AZURE_ADA_SMALL_512": "AZURE_ADA_SMALL_512",
+            "AZURE_ADA_SMALL_1536": "AZURE_ADA_SMALL_1536",
+            "SOLAR_1_MINI": "SOLAR_1_MINI",
         }
     
     @schemas.classproperty
     def OPENAI(cls):
         return cls("OPENAI")
     
     @schemas.classproperty
     def AZURE_OPENAI(cls):
         return cls("AZURE_OPENAI")
     
     @schemas.classproperty
-    def AZURE_ADA_LARGE_256(cls):
-        return cls("AZURE_ADA_LARGE_256")
-    
-    @schemas.classproperty
-    def AZURE_ADA_LARGE_1024(cls):
-        return cls("AZURE_ADA_LARGE_1024")
-    
-    @schemas.classproperty
-    def AZURE_ADA_LARGE_3072(cls):
-        return cls("AZURE_ADA_LARGE_3072")
-    
-    @schemas.classproperty
-    def AZURE_ADA_SMALL_512(cls):
-        return cls("AZURE_ADA_SMALL_512")
-    
-    @schemas.classproperty
-    def AZURE_ADA_SMALL_1536(cls):
-        return cls("AZURE_ADA_SMALL_1536")
-    
-    @schemas.classproperty
     def COHERE_MULTILINGUAL_V3(cls):
         return cls("COHERE_MULTILINGUAL_V3")
     
     @schemas.classproperty
-    def VERTEX_MULTIMODAL(cls):
-        return cls("VERTEX_MULTIMODAL")
-    
-    @schemas.classproperty
     def OPENAI_ADA_LARGE_256(cls):
         return cls("OPENAI_ADA_LARGE_256")
     
     @schemas.classproperty
     def OPENAI_ADA_LARGE_1024(cls):
         return cls("OPENAI_ADA_LARGE_1024")
     
@@ -101,7 +77,31 @@
     @schemas.classproperty
     def OPENAI_ADA_SMALL_512(cls):
         return cls("OPENAI_ADA_SMALL_512")
     
     @schemas.classproperty
     def OPENAI_ADA_SMALL_1536(cls):
         return cls("OPENAI_ADA_SMALL_1536")
+    
+    @schemas.classproperty
+    def AZURE_ADA_LARGE_256(cls):
+        return cls("AZURE_ADA_LARGE_256")
+    
+    @schemas.classproperty
+    def AZURE_ADA_LARGE_1024(cls):
+        return cls("AZURE_ADA_LARGE_1024")
+    
+    @schemas.classproperty
+    def AZURE_ADA_LARGE_3072(cls):
+        return cls("AZURE_ADA_LARGE_3072")
+    
+    @schemas.classproperty
+    def AZURE_ADA_SMALL_512(cls):
+        return cls("AZURE_ADA_SMALL_512")
+    
+    @schemas.classproperty
+    def AZURE_ADA_SMALL_1536(cls):
+        return cls("AZURE_ADA_SMALL_1536")
+    
+    @schemas.classproperty
+    def SOLAR_1_MINI(cls):
+        return cls("SOLAR_1_MINI")
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/embedding_generators.pyi` & `carbon_python_sdk-0.2.0/carbon/model/embedding_generators.pyi`

 * *Files 6% similar despite different names*

```diff
@@ -82,7 +82,11 @@
     @schemas.classproperty
     def OPENAI_ADA_SMALL_512(cls):
         return cls("OPENAI_ADA_SMALL_512")
     
     @schemas.classproperty
     def OPENAI_ADA_SMALL_1536(cls):
         return cls("OPENAI_ADA_SMALL_1536")
+    
+    @schemas.classproperty
+    def SOLAR_1_MINI(cls):
+        return cls("SOLAR_1_MINI")
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/embedding_generators_nullable.py` & `carbon_python_sdk-0.2.0/carbon/model/embedding_generators_nullable.py`

 * *Files 3% similar despite different names*

```diff
@@ -47,14 +47,15 @@
             "COHERE_MULTILINGUAL_V3": "COHERE_MULTILINGUAL_V3",
             "VERTEX_MULTIMODAL": "VERTEX_MULTIMODAL",
             "OPENAI_ADA_LARGE_256": "OPENAI_ADA_LARGE_256",
             "OPENAI_ADA_LARGE_1024": "OPENAI_ADA_LARGE_1024",
             "OPENAI_ADA_LARGE_3072": "OPENAI_ADA_LARGE_3072",
             "OPENAI_ADA_SMALL_512": "OPENAI_ADA_SMALL_512",
             "OPENAI_ADA_SMALL_1536": "OPENAI_ADA_SMALL_1536",
+            "SOLAR_1_MINI": "SOLAR_1_MINI",
         }
     
     @schemas.classproperty
     def OPENAI(cls):
         return cls("OPENAI")
     
     @schemas.classproperty
@@ -104,14 +105,18 @@
     @schemas.classproperty
     def OPENAI_ADA_SMALL_512(cls):
         return cls("OPENAI_ADA_SMALL_512")
     
     @schemas.classproperty
     def OPENAI_ADA_SMALL_1536(cls):
         return cls("OPENAI_ADA_SMALL_1536")
+    
+    @schemas.classproperty
+    def SOLAR_1_MINI(cls):
+        return cls("SOLAR_1_MINI")
 
 
     def __new__(
         cls,
         *args: typing.Union[None, str, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
     ) -> 'EmbeddingGeneratorsNullable':
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/embedding_generators_nullable.pyi` & `carbon_python_sdk-0.2.0/carbon/model/embedding_generators_nullable.pyi`

 * *Files 3% similar despite different names*

```diff
@@ -47,14 +47,15 @@
             "COHERE_MULTILINGUAL_V3": "COHERE_MULTILINGUAL_V3",
             "VERTEX_MULTIMODAL": "VERTEX_MULTIMODAL",
             "OPENAI_ADA_LARGE_256": "OPENAI_ADA_LARGE_256",
             "OPENAI_ADA_LARGE_1024": "OPENAI_ADA_LARGE_1024",
             "OPENAI_ADA_LARGE_3072": "OPENAI_ADA_LARGE_3072",
             "OPENAI_ADA_SMALL_512": "OPENAI_ADA_SMALL_512",
             "OPENAI_ADA_SMALL_1536": "OPENAI_ADA_SMALL_1536",
+            "SOLAR_1_MINI": "SOLAR_1_MINI",
         }
     
     @schemas.classproperty
     def OPENAI(cls):
         return cls("OPENAI")
     
     @schemas.classproperty
@@ -104,14 +105,18 @@
     @schemas.classproperty
     def OPENAI_ADA_SMALL_512(cls):
         return cls("OPENAI_ADA_SMALL_512")
     
     @schemas.classproperty
     def OPENAI_ADA_SMALL_1536(cls):
         return cls("OPENAI_ADA_SMALL_1536")
+    
+    @schemas.classproperty
+    def SOLAR_1_MINI(cls):
+        return cls("SOLAR_1_MINI")
 
 
     def __new__(
         cls,
         *args: typing.Union[None, str, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
     ) -> 'EmbeddingGeneratorsNullable':
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/embedding_properties.py` & `carbon_python_sdk-0.2.0/carbon/model/embedding_properties.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/embedding_properties.pyi` & `carbon_python_sdk-0.2.0/carbon/model/embedding_properties.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/embeddings_and_chunks_filters.py` & `carbon_python_sdk-0.2.0/carbon/model/embeddings_and_chunks_filters.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/embeddings_and_chunks_filters.pyi` & `carbon_python_sdk-0.2.0/carbon/model/embeddings_and_chunks_filters.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/embeddings_and_chunks_order_by_columns.py` & `carbon_python_sdk-0.2.0/carbon/model/embeddings_and_chunks_order_by_columns.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/embeddings_and_chunks_order_by_columns.pyi` & `carbon_python_sdk-0.2.0/carbon/model/embeddings_and_chunks_order_by_columns.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/embeddings_and_chunks_query_input.py` & `carbon_python_sdk-0.2.0/carbon/model/embeddings_and_chunks_query_input.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/embeddings_and_chunks_query_input.pyi` & `carbon_python_sdk-0.2.0/carbon/model/embeddings_and_chunks_query_input.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/embeddings_and_chunks_response.py` & `carbon_python_sdk-0.2.0/carbon/model/embeddings_and_chunks_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/embeddings_and_chunks_response.pyi` & `carbon_python_sdk-0.2.0/carbon/model/embeddings_and_chunks_response.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/external_file_sync_statuses.py` & `carbon_python_sdk-0.2.0/carbon/model/external_file_sync_statuses.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/external_file_sync_statuses.pyi` & `carbon_python_sdk-0.2.0/carbon/model/external_file_sync_statuses.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/external_source_item.py` & `carbon_python_sdk-0.2.0/carbon/model/external_source_item.py`

 * *Files 3% similar despite different names*

```diff
@@ -38,14 +38,15 @@
             "organization_user_data_source_id",
             "created_at",
             "parent_external_id",
             "external_id",
             "source",
             "organization_supplied_user_id",
             "is_selectable",
+            "external_url",
             "is_expandable",
             "updated_at",
             "organization_user_file_to_sync_id",
             "organization_id",
             "organization_user_id",
             "name",
             "id",
@@ -181,14 +182,34 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'root_external_id':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            
+            
+            class external_url(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'external_url':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             created_at = schemas.DateTimeSchema
             updated_at = schemas.DateTimeSchema
             __annotations__ = {
                 "id": id,
                 "external_id": external_id,
                 "source": source,
                 "name": name,
@@ -199,27 +220,29 @@
                 "organization_supplied_user_id": organization_supplied_user_id,
                 "organization_user_id": organization_user_id,
                 "organization_user_data_source_id": organization_user_data_source_id,
                 "organization_user_file_to_sync_id": organization_user_file_to_sync_id,
                 "parent_external_id": parent_external_id,
                 "item_type": item_type,
                 "root_external_id": root_external_id,
+                "external_url": external_url,
                 "created_at": created_at,
                 "updated_at": updated_at,
             }
     
     root_external_id: MetaOapg.properties.root_external_id
     item_type: MetaOapg.properties.item_type
     organization_user_data_source_id: MetaOapg.properties.organization_user_data_source_id
     created_at: MetaOapg.properties.created_at
     parent_external_id: MetaOapg.properties.parent_external_id
     external_id: MetaOapg.properties.external_id
     source: 'DataSourceType'
     organization_supplied_user_id: MetaOapg.properties.organization_supplied_user_id
     is_selectable: MetaOapg.properties.is_selectable
+    external_url: MetaOapg.properties.external_url
     is_expandable: MetaOapg.properties.is_expandable
     updated_at: MetaOapg.properties.updated_at
     organization_user_file_to_sync_id: MetaOapg.properties.organization_user_file_to_sync_id
     organization_id: MetaOapg.properties.organization_id
     organization_user_id: MetaOapg.properties.organization_user_id
     name: MetaOapg.properties.name
     id: MetaOapg.properties.id
@@ -267,23 +290,26 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["item_type"]) -> MetaOapg.properties.item_type: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["root_external_id"]) -> MetaOapg.properties.root_external_id: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["external_url"]) -> MetaOapg.properties.external_url: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "external_id", "source", "name", "synced_at", "is_selectable", "is_expandable", "organization_id", "organization_supplied_user_id", "organization_user_id", "organization_user_data_source_id", "organization_user_file_to_sync_id", "parent_external_id", "item_type", "root_external_id", "created_at", "updated_at", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "external_id", "source", "name", "synced_at", "is_selectable", "is_expandable", "organization_id", "organization_supplied_user_id", "organization_user_id", "organization_user_data_source_id", "organization_user_file_to_sync_id", "parent_external_id", "item_type", "root_external_id", "external_url", "created_at", "updated_at", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
     
@@ -326,23 +352,26 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["item_type"]) -> MetaOapg.properties.item_type: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["root_external_id"]) -> MetaOapg.properties.root_external_id: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["external_url"]) -> MetaOapg.properties.external_url: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "external_id", "source", "name", "synced_at", "is_selectable", "is_expandable", "organization_id", "organization_supplied_user_id", "organization_user_id", "organization_user_data_source_id", "organization_user_file_to_sync_id", "parent_external_id", "item_type", "root_external_id", "created_at", "updated_at", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "external_id", "source", "name", "synced_at", "is_selectable", "is_expandable", "organization_id", "organization_supplied_user_id", "organization_user_id", "organization_user_data_source_id", "organization_user_file_to_sync_id", "parent_external_id", "item_type", "root_external_id", "external_url", "created_at", "updated_at", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         root_external_id: typing.Union[MetaOapg.properties.root_external_id, None, str, ],
@@ -350,14 +379,15 @@
         organization_user_data_source_id: typing.Union[MetaOapg.properties.organization_user_data_source_id, decimal.Decimal, int, ],
         created_at: typing.Union[MetaOapg.properties.created_at, str, datetime, ],
         parent_external_id: typing.Union[MetaOapg.properties.parent_external_id, None, str, ],
         external_id: typing.Union[MetaOapg.properties.external_id, str, ],
         source: 'DataSourceType',
         organization_supplied_user_id: typing.Union[MetaOapg.properties.organization_supplied_user_id, str, ],
         is_selectable: typing.Union[MetaOapg.properties.is_selectable, None, bool, ],
+        external_url: typing.Union[MetaOapg.properties.external_url, None, str, ],
         is_expandable: typing.Union[MetaOapg.properties.is_expandable, None, bool, ],
         updated_at: typing.Union[MetaOapg.properties.updated_at, str, datetime, ],
         organization_user_file_to_sync_id: typing.Union[MetaOapg.properties.organization_user_file_to_sync_id, None, decimal.Decimal, int, ],
         organization_id: typing.Union[MetaOapg.properties.organization_id, decimal.Decimal, int, ],
         organization_user_id: typing.Union[MetaOapg.properties.organization_user_id, decimal.Decimal, int, ],
         name: typing.Union[MetaOapg.properties.name, str, ],
         id: typing.Union[MetaOapg.properties.id, decimal.Decimal, int, ],
@@ -373,14 +403,15 @@
             organization_user_data_source_id=organization_user_data_source_id,
             created_at=created_at,
             parent_external_id=parent_external_id,
             external_id=external_id,
             source=source,
             organization_supplied_user_id=organization_supplied_user_id,
             is_selectable=is_selectable,
+            external_url=external_url,
             is_expandable=is_expandable,
             updated_at=updated_at,
             organization_user_file_to_sync_id=organization_user_file_to_sync_id,
             organization_id=organization_id,
             organization_user_id=organization_user_id,
             name=name,
             id=id,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/external_source_item.pyi` & `carbon_python_sdk-0.2.0/carbon/model/external_source_item.pyi`

 * *Files 3% similar despite different names*

```diff
@@ -38,14 +38,15 @@
             "organization_user_data_source_id",
             "created_at",
             "parent_external_id",
             "external_id",
             "source",
             "organization_supplied_user_id",
             "is_selectable",
+            "external_url",
             "is_expandable",
             "updated_at",
             "organization_user_file_to_sync_id",
             "organization_id",
             "organization_user_id",
             "name",
             "id",
@@ -181,14 +182,34 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'root_external_id':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            
+            
+            class external_url(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'external_url':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             created_at = schemas.DateTimeSchema
             updated_at = schemas.DateTimeSchema
             __annotations__ = {
                 "id": id,
                 "external_id": external_id,
                 "source": source,
                 "name": name,
@@ -199,27 +220,29 @@
                 "organization_supplied_user_id": organization_supplied_user_id,
                 "organization_user_id": organization_user_id,
                 "organization_user_data_source_id": organization_user_data_source_id,
                 "organization_user_file_to_sync_id": organization_user_file_to_sync_id,
                 "parent_external_id": parent_external_id,
                 "item_type": item_type,
                 "root_external_id": root_external_id,
+                "external_url": external_url,
                 "created_at": created_at,
                 "updated_at": updated_at,
             }
     
     root_external_id: MetaOapg.properties.root_external_id
     item_type: MetaOapg.properties.item_type
     organization_user_data_source_id: MetaOapg.properties.organization_user_data_source_id
     created_at: MetaOapg.properties.created_at
     parent_external_id: MetaOapg.properties.parent_external_id
     external_id: MetaOapg.properties.external_id
     source: 'DataSourceType'
     organization_supplied_user_id: MetaOapg.properties.organization_supplied_user_id
     is_selectable: MetaOapg.properties.is_selectable
+    external_url: MetaOapg.properties.external_url
     is_expandable: MetaOapg.properties.is_expandable
     updated_at: MetaOapg.properties.updated_at
     organization_user_file_to_sync_id: MetaOapg.properties.organization_user_file_to_sync_id
     organization_id: MetaOapg.properties.organization_id
     organization_user_id: MetaOapg.properties.organization_user_id
     name: MetaOapg.properties.name
     id: MetaOapg.properties.id
@@ -267,23 +290,26 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["item_type"]) -> MetaOapg.properties.item_type: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["root_external_id"]) -> MetaOapg.properties.root_external_id: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["external_url"]) -> MetaOapg.properties.external_url: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "external_id", "source", "name", "synced_at", "is_selectable", "is_expandable", "organization_id", "organization_supplied_user_id", "organization_user_id", "organization_user_data_source_id", "organization_user_file_to_sync_id", "parent_external_id", "item_type", "root_external_id", "created_at", "updated_at", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "external_id", "source", "name", "synced_at", "is_selectable", "is_expandable", "organization_id", "organization_supplied_user_id", "organization_user_id", "organization_user_data_source_id", "organization_user_file_to_sync_id", "parent_external_id", "item_type", "root_external_id", "external_url", "created_at", "updated_at", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
     
@@ -326,23 +352,26 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["item_type"]) -> MetaOapg.properties.item_type: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["root_external_id"]) -> MetaOapg.properties.root_external_id: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["external_url"]) -> MetaOapg.properties.external_url: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "external_id", "source", "name", "synced_at", "is_selectable", "is_expandable", "organization_id", "organization_supplied_user_id", "organization_user_id", "organization_user_data_source_id", "organization_user_file_to_sync_id", "parent_external_id", "item_type", "root_external_id", "created_at", "updated_at", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "external_id", "source", "name", "synced_at", "is_selectable", "is_expandable", "organization_id", "organization_supplied_user_id", "organization_user_id", "organization_user_data_source_id", "organization_user_file_to_sync_id", "parent_external_id", "item_type", "root_external_id", "external_url", "created_at", "updated_at", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         root_external_id: typing.Union[MetaOapg.properties.root_external_id, None, str, ],
@@ -350,14 +379,15 @@
         organization_user_data_source_id: typing.Union[MetaOapg.properties.organization_user_data_source_id, decimal.Decimal, int, ],
         created_at: typing.Union[MetaOapg.properties.created_at, str, datetime, ],
         parent_external_id: typing.Union[MetaOapg.properties.parent_external_id, None, str, ],
         external_id: typing.Union[MetaOapg.properties.external_id, str, ],
         source: 'DataSourceType',
         organization_supplied_user_id: typing.Union[MetaOapg.properties.organization_supplied_user_id, str, ],
         is_selectable: typing.Union[MetaOapg.properties.is_selectable, None, bool, ],
+        external_url: typing.Union[MetaOapg.properties.external_url, None, str, ],
         is_expandable: typing.Union[MetaOapg.properties.is_expandable, None, bool, ],
         updated_at: typing.Union[MetaOapg.properties.updated_at, str, datetime, ],
         organization_user_file_to_sync_id: typing.Union[MetaOapg.properties.organization_user_file_to_sync_id, None, decimal.Decimal, int, ],
         organization_id: typing.Union[MetaOapg.properties.organization_id, decimal.Decimal, int, ],
         organization_user_id: typing.Union[MetaOapg.properties.organization_user_id, decimal.Decimal, int, ],
         name: typing.Union[MetaOapg.properties.name, str, ],
         id: typing.Union[MetaOapg.properties.id, decimal.Decimal, int, ],
@@ -373,14 +403,15 @@
             organization_user_data_source_id=organization_user_data_source_id,
             created_at=created_at,
             parent_external_id=parent_external_id,
             external_id=external_id,
             source=source,
             organization_supplied_user_id=organization_supplied_user_id,
             is_selectable=is_selectable,
+            external_url=external_url,
             is_expandable=is_expandable,
             updated_at=updated_at,
             organization_user_file_to_sync_id=organization_user_file_to_sync_id,
             organization_id=organization_id,
             organization_user_id=organization_user_id,
             name=name,
             id=id,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/fetch_urls_response.py` & `carbon_python_sdk-0.2.0/carbon/model/pagination.py`

 * *Files 20% similar despite different names*

```diff
@@ -19,80 +19,68 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class FetchURLsResponse(
+class Pagination(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
-        required = {
-            "html_content",
-            "urls",
-        }
         
         class properties:
-        
-            @staticmethod
-            def urls() -> typing.Type['FetchURLsResponseUrls']:
-                return FetchURLsResponseUrls
-            html_content = schemas.StrSchema
+            limit = schemas.IntSchema
+            offset = schemas.IntSchema
             __annotations__ = {
-                "urls": urls,
-                "html_content": html_content,
+                "limit": limit,
+                "offset": offset,
             }
     
-    html_content: MetaOapg.properties.html_content
-    urls: 'FetchURLsResponseUrls'
-    
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["urls"]) -> 'FetchURLsResponseUrls': ...
+    def __getitem__(self, name: typing_extensions.Literal["limit"]) -> MetaOapg.properties.limit: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["html_content"]) -> MetaOapg.properties.html_content: ...
+    def __getitem__(self, name: typing_extensions.Literal["offset"]) -> MetaOapg.properties.offset: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["urls", "html_content", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["limit", "offset", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["urls"]) -> 'FetchURLsResponseUrls': ...
+    def get_item_oapg(self, name: typing_extensions.Literal["limit"]) -> typing.Union[MetaOapg.properties.limit, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["html_content"]) -> MetaOapg.properties.html_content: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["offset"]) -> typing.Union[MetaOapg.properties.offset, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["urls", "html_content", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["limit", "offset", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        html_content: typing.Union[MetaOapg.properties.html_content, str, ],
-        urls: 'FetchURLsResponseUrls',
+        limit: typing.Union[MetaOapg.properties.limit, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        offset: typing.Union[MetaOapg.properties.offset, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'FetchURLsResponse':
+    ) -> 'Pagination':
         return super().__new__(
             cls,
             *args,
-            html_content=html_content,
-            urls=urls,
+            limit=limit,
+            offset=offset,
             _configuration=_configuration,
             **kwargs,
         )
-
-from carbon.model.fetch_urls_response_urls import FetchURLsResponseUrls
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/fetch_urls_response.pyi` & `carbon_python_sdk-0.2.0/carbon/model/pagination.pyi`

 * *Files 20% similar despite different names*

```diff
@@ -19,80 +19,68 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class FetchURLsResponse(
+class Pagination(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
-        required = {
-            "html_content",
-            "urls",
-        }
         
         class properties:
-        
-            @staticmethod
-            def urls() -> typing.Type['FetchURLsResponseUrls']:
-                return FetchURLsResponseUrls
-            html_content = schemas.StrSchema
+            limit = schemas.IntSchema
+            offset = schemas.IntSchema
             __annotations__ = {
-                "urls": urls,
-                "html_content": html_content,
+                "limit": limit,
+                "offset": offset,
             }
     
-    html_content: MetaOapg.properties.html_content
-    urls: 'FetchURLsResponseUrls'
-    
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["urls"]) -> 'FetchURLsResponseUrls': ...
+    def __getitem__(self, name: typing_extensions.Literal["limit"]) -> MetaOapg.properties.limit: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["html_content"]) -> MetaOapg.properties.html_content: ...
+    def __getitem__(self, name: typing_extensions.Literal["offset"]) -> MetaOapg.properties.offset: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["urls", "html_content", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["limit", "offset", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["urls"]) -> 'FetchURLsResponseUrls': ...
+    def get_item_oapg(self, name: typing_extensions.Literal["limit"]) -> typing.Union[MetaOapg.properties.limit, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["html_content"]) -> MetaOapg.properties.html_content: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["offset"]) -> typing.Union[MetaOapg.properties.offset, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["urls", "html_content", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["limit", "offset", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        html_content: typing.Union[MetaOapg.properties.html_content, str, ],
-        urls: 'FetchURLsResponseUrls',
+        limit: typing.Union[MetaOapg.properties.limit, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        offset: typing.Union[MetaOapg.properties.offset, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'FetchURLsResponse':
+    ) -> 'Pagination':
         return super().__new__(
             cls,
             *args,
-            html_content=html_content,
-            urls=urls,
+            limit=limit,
+            offset=offset,
             _configuration=_configuration,
             **kwargs,
         )
-
-from carbon.model.fetch_urls_response_urls import FetchURLsResponseUrls
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/fetch_urls_response_urls.py` & `carbon_python_sdk-0.2.0/carbon/model/fetch_urls_response_urls.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/fetch_urls_response_urls.pyi` & `carbon_python_sdk-0.2.0/carbon/model/fetch_urls_response_urls.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/file_content_types.py` & `carbon_python_sdk-0.2.0/carbon/model/file_content_types.pyi`

 * *Files 9% similar despite different names*

```diff
@@ -26,22 +26,23 @@
 class FileContentTypes(
     schemas.EnumBase,
     schemas.StrSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
-
-
-    class MetaOapg:
-        enum_value_to_name = {
-            "TEXT": "TEXT",
-            "IMAGE": "IMAGE",
-        }
     
     @schemas.classproperty
     def TEXT(cls):
         return cls("TEXT")
     
     @schemas.classproperty
     def IMAGE(cls):
         return cls("IMAGE")
+    
+    @schemas.classproperty
+    def AUDIO(cls):
+        return cls("AUDIO")
+    
+    @schemas.classproperty
+    def VIDEO(cls):
+        return cls("VIDEO")
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/file_content_types.pyi` & `carbon_python_sdk-0.2.0/carbon/model/order_dir_v2.py`

 * *Files 11% similar despite different names*

```diff
@@ -19,22 +19,29 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class FileContentTypes(
+class OrderDirV2(
     schemas.EnumBase,
     schemas.StrSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
+
+
+    class MetaOapg:
+        enum_value_to_name = {
+            "asc": "ASC",
+            "desc": "DESC",
+        }
     
     @schemas.classproperty
-    def TEXT(cls):
-        return cls("TEXT")
+    def ASC(cls):
+        return cls("asc")
     
     @schemas.classproperty
-    def IMAGE(cls):
-        return cls("IMAGE")
+    def DESC(cls):
+        return cls("desc")
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/file_content_types_nullable.py` & `carbon_python_sdk-0.2.0/carbon/model/file_content_types_nullable.py`

 * *Files 9% similar despite different names*

```diff
@@ -40,23 +40,33 @@
     """
 
 
     class MetaOapg:
         enum_value_to_name = {
             "TEXT": "TEXT",
             "IMAGE": "IMAGE",
+            "AUDIO": "AUDIO",
+            "VIDEO": "VIDEO",
         }
     
     @schemas.classproperty
     def TEXT(cls):
         return cls("TEXT")
     
     @schemas.classproperty
     def IMAGE(cls):
         return cls("IMAGE")
+    
+    @schemas.classproperty
+    def AUDIO(cls):
+        return cls("AUDIO")
+    
+    @schemas.classproperty
+    def VIDEO(cls):
+        return cls("VIDEO")
 
 
     def __new__(
         cls,
         *args: typing.Union[None, str, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
     ) -> 'FileContentTypesNullable':
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/file_content_types_nullable.pyi` & `carbon_python_sdk-0.2.0/carbon/model/file_content_types_nullable.pyi`

 * *Files 9% similar despite different names*

```diff
@@ -40,23 +40,33 @@
     """
 
 
     class MetaOapg:
         enum_value_to_name = {
             "TEXT": "TEXT",
             "IMAGE": "IMAGE",
+            "AUDIO": "AUDIO",
+            "VIDEO": "VIDEO",
         }
     
     @schemas.classproperty
     def TEXT(cls):
         return cls("TEXT")
     
     @schemas.classproperty
     def IMAGE(cls):
         return cls("IMAGE")
+    
+    @schemas.classproperty
+    def AUDIO(cls):
+        return cls("AUDIO")
+    
+    @schemas.classproperty
+    def VIDEO(cls):
+        return cls("VIDEO")
 
 
     def __new__(
         cls,
         *args: typing.Union[None, str, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
     ) -> 'FileContentTypesNullable':
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/file_formats.py` & `carbon_python_sdk-0.2.0/carbon/model/data_source_type.pyi`

 * *Files 26% similar despite different names*

```diff
@@ -19,67 +19,81 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class FileFormats(
+class DataSourceType(
     schemas.EnumBase,
     schemas.StrSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
-
-
-    class MetaOapg:
-        enum_value_to_name = {
-            "TXT": "TXT",
-            "CSV": "CSV",
-            "TSV": "TSV",
-            "PDF": "PDF",
-            "DOCX": "DOCX",
-            "PPTX": "PPTX",
-            "XLSX": "XLSX",
-            "MD": "MD",
-            "RTF": "RTF",
-            "JSON": "JSON",
-            "NOTION": "NOTION",
-            "GOOGLE_DOCS": "GOOGLE_DOCS",
-            "GOOGLE_SHEETS": "GOOGLE_SHEETS",
-            "GOOGLE_SLIDES": "GOOGLE_SLIDES",
-            "INTERCOM": "INTERCOM",
-            "CONFLUENCE": "CONFLUENCE",
-            "RSS_FEED": "RSS_FEED",
-            "GMAIL": "GMAIL",
-            "OUTLOOK": "OUTLOOK",
-            "ZENDESK": "ZENDESK",
-            "FRESHDESK": "FRESHDESK",
-            "WEB_SCRAPE": "WEB_SCRAPE",
-            "GITBOOK": "GITBOOK",
-            "SALESFORCE": "SALESFORCE",
-            "JPG": "JPG",
-            "PNG": "PNG",
-            "MP3": "MP3",
-            "MP4": "MP4",
-            "MP2": "MP2",
-            "AAC": "AAC",
-            "WAV": "WAV",
-            "FLAC": "FLAC",
-            "PCM": "PCM",
-            "M4A": "M4A",
-            "OGG": "OGG",
-            "OPUS": "OPUS",
-            "WEBM": "WEBM",
-        }
     
     @schemas.classproperty
-    def TXT(cls):
-        return cls("TXT")
+    def GOOGLE_DRIVE(cls):
+        return cls("GOOGLE_DRIVE")
+    
+    @schemas.classproperty
+    def NOTION(cls):
+        return cls("NOTION")
+    
+    @schemas.classproperty
+    def NOTION_DATABASE(cls):
+        return cls("NOTION_DATABASE")
+    
+    @schemas.classproperty
+    def INTERCOM(cls):
+        return cls("INTERCOM")
+    
+    @schemas.classproperty
+    def DROPBOX(cls):
+        return cls("DROPBOX")
+    
+    @schemas.classproperty
+    def ONEDRIVE(cls):
+        return cls("ONEDRIVE")
+    
+    @schemas.classproperty
+    def SHAREPOINT(cls):
+        return cls("SHAREPOINT")
+    
+    @schemas.classproperty
+    def CONFLUENCE(cls):
+        return cls("CONFLUENCE")
+    
+    @schemas.classproperty
+    def BOX(cls):
+        return cls("BOX")
+    
+    @schemas.classproperty
+    def ZENDESK(cls):
+        return cls("ZENDESK")
+    
+    @schemas.classproperty
+    def ZOTERO(cls):
+        return cls("ZOTERO")
+    
+    @schemas.classproperty
+    def S3(cls):
+        return cls("S3")
+    
+    @schemas.classproperty
+    def GMAIL(cls):
+        return cls("GMAIL")
+    
+    @schemas.classproperty
+    def OUTLOOK(cls):
+        return cls("OUTLOOK")
+    
+    @schemas.classproperty
+    def TEXT(cls):
+        return cls("TEXT")
     
     @schemas.classproperty
     def CSV(cls):
         return cls("CSV")
     
     @schemas.classproperty
     def TSV(cls):
@@ -110,84 +124,60 @@
         return cls("RTF")
     
     @schemas.classproperty
     def JSON(cls):
         return cls("JSON")
     
     @schemas.classproperty
-    def NOTION(cls):
-        return cls("NOTION")
-    
-    @schemas.classproperty
-    def GOOGLE_DOCS(cls):
-        return cls("GOOGLE_DOCS")
-    
-    @schemas.classproperty
-    def GOOGLE_SHEETS(cls):
-        return cls("GOOGLE_SHEETS")
-    
-    @schemas.classproperty
-    def GOOGLE_SLIDES(cls):
-        return cls("GOOGLE_SLIDES")
+    def HTML(cls):
+        return cls("HTML")
     
     @schemas.classproperty
-    def INTERCOM(cls):
-        return cls("INTERCOM")
+    def RAW_TEXT(cls):
+        return cls("RAW_TEXT")
     
     @schemas.classproperty
-    def CONFLUENCE(cls):
-        return cls("CONFLUENCE")
+    def WEB_SCRAPE(cls):
+        return cls("WEB_SCRAPE")
     
     @schemas.classproperty
     def RSS_FEED(cls):
         return cls("RSS_FEED")
     
     @schemas.classproperty
-    def GMAIL(cls):
-        return cls("GMAIL")
-    
-    @schemas.classproperty
-    def OUTLOOK(cls):
-        return cls("OUTLOOK")
-    
-    @schemas.classproperty
-    def ZENDESK(cls):
-        return cls("ZENDESK")
-    
-    @schemas.classproperty
     def FRESHDESK(cls):
         return cls("FRESHDESK")
     
     @schemas.classproperty
-    def WEB_SCRAPE(cls):
-        return cls("WEB_SCRAPE")
-    
-    @schemas.classproperty
     def GITBOOK(cls):
         return cls("GITBOOK")
     
     @schemas.classproperty
     def SALESFORCE(cls):
         return cls("SALESFORCE")
     
     @schemas.classproperty
+    def GITHUB(cls):
+        return cls("GITHUB")
+    
+    @schemas.classproperty
     def JPG(cls):
         return cls("JPG")
     
     @schemas.classproperty
     def PNG(cls):
         return cls("PNG")
     
     @schemas.classproperty
-    def MP3(cls):
-        return cls("MP3")
+    def JPEG(cls):
+        return cls("JPEG")
     
     @schemas.classproperty
-    def MP4(cls):
-        return cls("MP4")
+    def MP3(cls):
+        return cls("MP3")
     
     @schemas.classproperty
     def MP2(cls):
         return cls("MP2")
     
     @schemas.classproperty
     def AAC(cls):
@@ -214,9 +204,41 @@
         return cls("OGG")
     
     @schemas.classproperty
     def OPUS(cls):
         return cls("OPUS")
     
     @schemas.classproperty
+    def MPEG(cls):
+        return cls("MPEG")
+    
+    @schemas.classproperty
+    def MPG(cls):
+        return cls("MPG")
+    
+    @schemas.classproperty
+    def MP4(cls):
+        return cls("MP4")
+    
+    @schemas.classproperty
+    def WMV(cls):
+        return cls("WMV")
+    
+    @schemas.classproperty
+    def AVI(cls):
+        return cls("AVI")
+    
+    @schemas.classproperty
+    def MOV(cls):
+        return cls("MOV")
+    
+    @schemas.classproperty
+    def MKV(cls):
+        return cls("MKV")
+    
+    @schemas.classproperty
+    def FLV(cls):
+        return cls("FLV")
+    
+    @schemas.classproperty
     def WEBM(cls):
         return cls("WEBM")
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/file_formats_nullable.py` & `carbon_python_sdk-0.2.0/carbon/model/file_formats_nullable.py`

 * *Files 20% similar despite different names*

```diff
@@ -43,40 +43,49 @@
             "PDF": "PDF",
             "DOCX": "DOCX",
             "PPTX": "PPTX",
             "XLSX": "XLSX",
             "MD": "MD",
             "RTF": "RTF",
             "JSON": "JSON",
+            "HTML": "HTML",
             "NOTION": "NOTION",
             "GOOGLE_DOCS": "GOOGLE_DOCS",
             "GOOGLE_SHEETS": "GOOGLE_SHEETS",
             "GOOGLE_SLIDES": "GOOGLE_SLIDES",
             "INTERCOM": "INTERCOM",
             "CONFLUENCE": "CONFLUENCE",
             "RSS_FEED": "RSS_FEED",
             "GMAIL": "GMAIL",
             "OUTLOOK": "OUTLOOK",
             "ZENDESK": "ZENDESK",
             "FRESHDESK": "FRESHDESK",
             "WEB_SCRAPE": "WEB_SCRAPE",
             "GITBOOK": "GITBOOK",
             "SALESFORCE": "SALESFORCE",
+            "GITHUB": "GITHUB",
             "JPG": "JPG",
             "PNG": "PNG",
             "MP3": "MP3",
-            "MP4": "MP4",
             "MP2": "MP2",
             "AAC": "AAC",
             "WAV": "WAV",
             "FLAC": "FLAC",
             "PCM": "PCM",
             "M4A": "M4A",
             "OGG": "OGG",
             "OPUS": "OPUS",
+            "MPEG": "MPEG",
+            "MPG": "MPG",
+            "MP4": "MP4",
+            "WMV": "WMV",
+            "AVI": "AVI",
+            "MOV": "MOV",
+            "MKV": "MKV",
+            "FLV": "FLV",
             "WEBM": "WEBM",
         }
     
     @schemas.classproperty
     def TXT(cls):
         return cls("TXT")
     
@@ -113,14 +122,18 @@
         return cls("RTF")
     
     @schemas.classproperty
     def JSON(cls):
         return cls("JSON")
     
     @schemas.classproperty
+    def HTML(cls):
+        return cls("HTML")
+    
+    @schemas.classproperty
     def NOTION(cls):
         return cls("NOTION")
     
     @schemas.classproperty
     def GOOGLE_DOCS(cls):
         return cls("GOOGLE_DOCS")
     
@@ -169,30 +182,30 @@
         return cls("GITBOOK")
     
     @schemas.classproperty
     def SALESFORCE(cls):
         return cls("SALESFORCE")
     
     @schemas.classproperty
+    def GITHUB(cls):
+        return cls("GITHUB")
+    
+    @schemas.classproperty
     def JPG(cls):
         return cls("JPG")
     
     @schemas.classproperty
     def PNG(cls):
         return cls("PNG")
     
     @schemas.classproperty
     def MP3(cls):
         return cls("MP3")
     
     @schemas.classproperty
-    def MP4(cls):
-        return cls("MP4")
-    
-    @schemas.classproperty
     def MP2(cls):
         return cls("MP2")
     
     @schemas.classproperty
     def AAC(cls):
         return cls("AAC")
     
@@ -217,14 +230,46 @@
         return cls("OGG")
     
     @schemas.classproperty
     def OPUS(cls):
         return cls("OPUS")
     
     @schemas.classproperty
+    def MPEG(cls):
+        return cls("MPEG")
+    
+    @schemas.classproperty
+    def MPG(cls):
+        return cls("MPG")
+    
+    @schemas.classproperty
+    def MP4(cls):
+        return cls("MP4")
+    
+    @schemas.classproperty
+    def WMV(cls):
+        return cls("WMV")
+    
+    @schemas.classproperty
+    def AVI(cls):
+        return cls("AVI")
+    
+    @schemas.classproperty
+    def MOV(cls):
+        return cls("MOV")
+    
+    @schemas.classproperty
+    def MKV(cls):
+        return cls("MKV")
+    
+    @schemas.classproperty
+    def FLV(cls):
+        return cls("FLV")
+    
+    @schemas.classproperty
     def WEBM(cls):
         return cls("WEBM")
 
 
     def __new__(
         cls,
         *args: typing.Union[None, str, ],
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/file_formats_nullable.pyi` & `carbon_python_sdk-0.2.0/carbon/model/file_formats_nullable.pyi`

 * *Files 20% similar despite different names*

```diff
@@ -43,40 +43,49 @@
             "PDF": "PDF",
             "DOCX": "DOCX",
             "PPTX": "PPTX",
             "XLSX": "XLSX",
             "MD": "MD",
             "RTF": "RTF",
             "JSON": "JSON",
+            "HTML": "HTML",
             "NOTION": "NOTION",
             "GOOGLE_DOCS": "GOOGLE_DOCS",
             "GOOGLE_SHEETS": "GOOGLE_SHEETS",
             "GOOGLE_SLIDES": "GOOGLE_SLIDES",
             "INTERCOM": "INTERCOM",
             "CONFLUENCE": "CONFLUENCE",
             "RSS_FEED": "RSS_FEED",
             "GMAIL": "GMAIL",
             "OUTLOOK": "OUTLOOK",
             "ZENDESK": "ZENDESK",
             "FRESHDESK": "FRESHDESK",
             "WEB_SCRAPE": "WEB_SCRAPE",
             "GITBOOK": "GITBOOK",
             "SALESFORCE": "SALESFORCE",
+            "GITHUB": "GITHUB",
             "JPG": "JPG",
             "PNG": "PNG",
             "MP3": "MP3",
-            "MP4": "MP4",
             "MP2": "MP2",
             "AAC": "AAC",
             "WAV": "WAV",
             "FLAC": "FLAC",
             "PCM": "PCM",
             "M4A": "M4A",
             "OGG": "OGG",
             "OPUS": "OPUS",
+            "MPEG": "MPEG",
+            "MPG": "MPG",
+            "MP4": "MP4",
+            "WMV": "WMV",
+            "AVI": "AVI",
+            "MOV": "MOV",
+            "MKV": "MKV",
+            "FLV": "FLV",
             "WEBM": "WEBM",
         }
     
     @schemas.classproperty
     def TXT(cls):
         return cls("TXT")
     
@@ -113,14 +122,18 @@
         return cls("RTF")
     
     @schemas.classproperty
     def JSON(cls):
         return cls("JSON")
     
     @schemas.classproperty
+    def HTML(cls):
+        return cls("HTML")
+    
+    @schemas.classproperty
     def NOTION(cls):
         return cls("NOTION")
     
     @schemas.classproperty
     def GOOGLE_DOCS(cls):
         return cls("GOOGLE_DOCS")
     
@@ -169,30 +182,30 @@
         return cls("GITBOOK")
     
     @schemas.classproperty
     def SALESFORCE(cls):
         return cls("SALESFORCE")
     
     @schemas.classproperty
+    def GITHUB(cls):
+        return cls("GITHUB")
+    
+    @schemas.classproperty
     def JPG(cls):
         return cls("JPG")
     
     @schemas.classproperty
     def PNG(cls):
         return cls("PNG")
     
     @schemas.classproperty
     def MP3(cls):
         return cls("MP3")
     
     @schemas.classproperty
-    def MP4(cls):
-        return cls("MP4")
-    
-    @schemas.classproperty
     def MP2(cls):
         return cls("MP2")
     
     @schemas.classproperty
     def AAC(cls):
         return cls("AAC")
     
@@ -217,14 +230,46 @@
         return cls("OGG")
     
     @schemas.classproperty
     def OPUS(cls):
         return cls("OPUS")
     
     @schemas.classproperty
+    def MPEG(cls):
+        return cls("MPEG")
+    
+    @schemas.classproperty
+    def MPG(cls):
+        return cls("MPG")
+    
+    @schemas.classproperty
+    def MP4(cls):
+        return cls("MP4")
+    
+    @schemas.classproperty
+    def WMV(cls):
+        return cls("WMV")
+    
+    @schemas.classproperty
+    def AVI(cls):
+        return cls("AVI")
+    
+    @schemas.classproperty
+    def MOV(cls):
+        return cls("MOV")
+    
+    @schemas.classproperty
+    def MKV(cls):
+        return cls("MKV")
+    
+    @schemas.classproperty
+    def FLV(cls):
+        return cls("FLV")
+    
+    @schemas.classproperty
     def WEBM(cls):
         return cls("WEBM")
 
 
     def __new__(
         cls,
         *args: typing.Union[None, str, ],
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/file_statistics.py` & `carbon_python_sdk-0.2.0/carbon/model/file_statistics.py`

 * *Files 4% similar despite different names*

```diff
@@ -29,14 +29,15 @@
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
+            "mime_type",
             "num_tokens",
             "num_embeddings",
             "file_format",
             "file_size",
             "num_characters",
         }
         
@@ -121,22 +122,44 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'num_embeddings':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            
+            
+            class mime_type(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'mime_type':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             __annotations__ = {
                 "file_format": file_format,
                 "file_size": file_size,
                 "num_characters": num_characters,
                 "num_tokens": num_tokens,
                 "num_embeddings": num_embeddings,
+                "mime_type": mime_type,
             }
     
+    mime_type: MetaOapg.properties.mime_type
     num_tokens: MetaOapg.properties.num_tokens
     num_embeddings: MetaOapg.properties.num_embeddings
     file_format: 'FileFormatsNullable'
     file_size: MetaOapg.properties.file_size
     num_characters: MetaOapg.properties.num_characters
     
     @typing.overload
@@ -151,17 +174,20 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["num_tokens"]) -> MetaOapg.properties.num_tokens: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["num_embeddings"]) -> MetaOapg.properties.num_embeddings: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["mime_type"]) -> MetaOapg.properties.mime_type: ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["file_format", "file_size", "num_characters", "num_tokens", "num_embeddings", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["file_format", "file_size", "num_characters", "num_tokens", "num_embeddings", "mime_type", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["file_format"]) -> 'FileFormatsNullable': ...
     
@@ -174,34 +200,39 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["num_tokens"]) -> MetaOapg.properties.num_tokens: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["num_embeddings"]) -> MetaOapg.properties.num_embeddings: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["mime_type"]) -> MetaOapg.properties.mime_type: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["file_format", "file_size", "num_characters", "num_tokens", "num_embeddings", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["file_format", "file_size", "num_characters", "num_tokens", "num_embeddings", "mime_type", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
+        mime_type: typing.Union[MetaOapg.properties.mime_type, None, str, ],
         num_tokens: typing.Union[MetaOapg.properties.num_tokens, None, decimal.Decimal, int, ],
         num_embeddings: typing.Union[MetaOapg.properties.num_embeddings, None, decimal.Decimal, int, ],
         file_format: 'FileFormatsNullable',
         file_size: typing.Union[MetaOapg.properties.file_size, None, decimal.Decimal, int, ],
         num_characters: typing.Union[MetaOapg.properties.num_characters, None, decimal.Decimal, int, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
     ) -> 'FileStatistics':
         return super().__new__(
             cls,
             *args,
+            mime_type=mime_type,
             num_tokens=num_tokens,
             num_embeddings=num_embeddings,
             file_format=file_format,
             file_size=file_size,
             num_characters=num_characters,
             _configuration=_configuration,
             **kwargs,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/file_statistics.pyi` & `carbon_python_sdk-0.2.0/carbon/model/file_statistics.pyi`

 * *Files 4% similar despite different names*

```diff
@@ -29,14 +29,15 @@
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
+            "mime_type",
             "num_tokens",
             "num_embeddings",
             "file_format",
             "file_size",
             "num_characters",
         }
         
@@ -121,22 +122,44 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'num_embeddings':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            
+            
+            class mime_type(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'mime_type':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             __annotations__ = {
                 "file_format": file_format,
                 "file_size": file_size,
                 "num_characters": num_characters,
                 "num_tokens": num_tokens,
                 "num_embeddings": num_embeddings,
+                "mime_type": mime_type,
             }
     
+    mime_type: MetaOapg.properties.mime_type
     num_tokens: MetaOapg.properties.num_tokens
     num_embeddings: MetaOapg.properties.num_embeddings
     file_format: 'FileFormatsNullable'
     file_size: MetaOapg.properties.file_size
     num_characters: MetaOapg.properties.num_characters
     
     @typing.overload
@@ -151,17 +174,20 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["num_tokens"]) -> MetaOapg.properties.num_tokens: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["num_embeddings"]) -> MetaOapg.properties.num_embeddings: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["mime_type"]) -> MetaOapg.properties.mime_type: ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["file_format", "file_size", "num_characters", "num_tokens", "num_embeddings", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["file_format", "file_size", "num_characters", "num_tokens", "num_embeddings", "mime_type", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["file_format"]) -> 'FileFormatsNullable': ...
     
@@ -174,34 +200,39 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["num_tokens"]) -> MetaOapg.properties.num_tokens: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["num_embeddings"]) -> MetaOapg.properties.num_embeddings: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["mime_type"]) -> MetaOapg.properties.mime_type: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["file_format", "file_size", "num_characters", "num_tokens", "num_embeddings", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["file_format", "file_size", "num_characters", "num_tokens", "num_embeddings", "mime_type", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
+        mime_type: typing.Union[MetaOapg.properties.mime_type, None, str, ],
         num_tokens: typing.Union[MetaOapg.properties.num_tokens, None, decimal.Decimal, int, ],
         num_embeddings: typing.Union[MetaOapg.properties.num_embeddings, None, decimal.Decimal, int, ],
         file_format: 'FileFormatsNullable',
         file_size: typing.Union[MetaOapg.properties.file_size, None, decimal.Decimal, int, ],
         num_characters: typing.Union[MetaOapg.properties.num_characters, None, decimal.Decimal, int, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
     ) -> 'FileStatistics':
         return super().__new__(
             cls,
             *args,
+            mime_type=mime_type,
             num_tokens=num_tokens,
             num_embeddings=num_embeddings,
             file_format=file_format,
             file_size=file_size,
             num_characters=num_characters,
             _configuration=_configuration,
             **kwargs,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/file_statistics_nullable.py` & `carbon_python_sdk-0.2.0/carbon/model/file_statistics_nullable.py`

 * *Files 6% similar despite different names*

```diff
@@ -32,14 +32,15 @@
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
+            "mime_type",
             "num_tokens",
             "num_embeddings",
             "file_format",
             "file_size",
             "num_characters",
         }
         
@@ -124,23 +125,45 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'num_embeddings':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            
+            
+            class mime_type(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'mime_type':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             __annotations__ = {
                 "file_format": file_format,
                 "file_size": file_size,
                 "num_characters": num_characters,
                 "num_tokens": num_tokens,
                 "num_embeddings": num_embeddings,
+                "mime_type": mime_type,
             }
 
     
+    mime_type: MetaOapg.properties.mime_type
     num_tokens: MetaOapg.properties.num_tokens
     num_embeddings: MetaOapg.properties.num_embeddings
     file_format: 'FileFormatsNullable'
     file_size: MetaOapg.properties.file_size
     num_characters: MetaOapg.properties.num_characters
     
     @typing.overload
@@ -155,17 +178,20 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["num_tokens"]) -> MetaOapg.properties.num_tokens: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["num_embeddings"]) -> MetaOapg.properties.num_embeddings: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["mime_type"]) -> MetaOapg.properties.mime_type: ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["file_format", "file_size", "num_characters", "num_tokens", "num_embeddings", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["file_format", "file_size", "num_characters", "num_tokens", "num_embeddings", "mime_type", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["file_format"]) -> 'FileFormatsNullable': ...
     
@@ -178,17 +204,20 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["num_tokens"]) -> MetaOapg.properties.num_tokens: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["num_embeddings"]) -> MetaOapg.properties.num_embeddings: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["mime_type"]) -> MetaOapg.properties.mime_type: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["file_format", "file_size", "num_characters", "num_tokens", "num_embeddings", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["file_format", "file_size", "num_characters", "num_tokens", "num_embeddings", "mime_type", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, None, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/file_statistics_nullable.pyi` & `carbon_python_sdk-0.2.0/carbon/model/file_statistics_nullable.pyi`

 * *Files 6% similar despite different names*

```diff
@@ -32,14 +32,15 @@
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
+            "mime_type",
             "num_tokens",
             "num_embeddings",
             "file_format",
             "file_size",
             "num_characters",
         }
         
@@ -124,23 +125,45 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'num_embeddings':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            
+            
+            class mime_type(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'mime_type':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             __annotations__ = {
                 "file_format": file_format,
                 "file_size": file_size,
                 "num_characters": num_characters,
                 "num_tokens": num_tokens,
                 "num_embeddings": num_embeddings,
+                "mime_type": mime_type,
             }
 
     
+    mime_type: MetaOapg.properties.mime_type
     num_tokens: MetaOapg.properties.num_tokens
     num_embeddings: MetaOapg.properties.num_embeddings
     file_format: 'FileFormatsNullable'
     file_size: MetaOapg.properties.file_size
     num_characters: MetaOapg.properties.num_characters
     
     @typing.overload
@@ -155,17 +178,20 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["num_tokens"]) -> MetaOapg.properties.num_tokens: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["num_embeddings"]) -> MetaOapg.properties.num_embeddings: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["mime_type"]) -> MetaOapg.properties.mime_type: ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["file_format", "file_size", "num_characters", "num_tokens", "num_embeddings", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["file_format", "file_size", "num_characters", "num_tokens", "num_embeddings", "mime_type", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["file_format"]) -> 'FileFormatsNullable': ...
     
@@ -178,17 +204,20 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["num_tokens"]) -> MetaOapg.properties.num_tokens: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["num_embeddings"]) -> MetaOapg.properties.num_embeddings: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["mime_type"]) -> MetaOapg.properties.mime_type: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["file_format", "file_size", "num_characters", "num_tokens", "num_embeddings", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["file_format", "file_size", "num_characters", "num_tokens", "num_embeddings", "mime_type", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, None, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/files_query_user_files_deprecated_response.py` & `carbon_python_sdk-0.2.0/carbon/model/files_query_user_files_deprecated_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/files_query_user_files_deprecated_response.pyi` & `carbon_python_sdk-0.2.0/carbon/model/files_query_user_files_deprecated_response.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/fresh_desk_connect_request.py` & `carbon_python_sdk-0.2.0/carbon/model/rss_feed_input.py`

 * *Files 6% similar despite different names*

```diff
@@ -19,31 +19,29 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class FreshDeskConnectRequest(
+class RSSFeedInput(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
-            "api_key",
-            "domain",
+            "url",
         }
         
         class properties:
-            domain = schemas.StrSchema
-            api_key = schemas.StrSchema
+            url = schemas.StrSchema
             
             
             class tags(
                 schemas.DictBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneFrozenDictMixin
@@ -120,16 +118,16 @@
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
         
             @staticmethod
-            def embedding_model() -> typing.Type['EmbeddingGeneratorsNullable']:
-                return EmbeddingGeneratorsNullable
+            def embedding_model() -> typing.Type['EmbeddingGenerators']:
+                return EmbeddingGenerators
             
             
             class generate_sparse_vectors(
                 schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneBoolMixin
@@ -164,150 +162,140 @@
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
             
             
-            class sync_files_on_connection(
-                schemas.BoolBase,
+            class request_id(
+                schemas.StrBase,
                 schemas.NoneBase,
                 schemas.Schema,
-                schemas.NoneBoolMixin
+                schemas.NoneStrMixin
             ):
             
             
                 def __new__(
                     cls,
-                    *args: typing.Union[None, bool, ],
+                    *args: typing.Union[None, str, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'sync_files_on_connection':
+                ) -> 'request_id':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
             __annotations__ = {
-                "domain": domain,
-                "api_key": api_key,
+                "url": url,
                 "tags": tags,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
                 "embedding_model": embedding_model,
                 "generate_sparse_vectors": generate_sparse_vectors,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
-                "sync_files_on_connection": sync_files_on_connection,
+                "request_id": request_id,
             }
     
-    api_key: MetaOapg.properties.api_key
-    domain: MetaOapg.properties.domain
+    url: MetaOapg.properties.url
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["domain"]) -> MetaOapg.properties.domain: ...
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["api_key"]) -> MetaOapg.properties.api_key: ...
+    def __getitem__(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_size"]) -> MetaOapg.properties.chunk_size: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> MetaOapg.properties.skip_embedding_generation: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGeneratorsNullable': ...
+    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["sync_files_on_connection"]) -> MetaOapg.properties.sync_files_on_connection: ...
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["domain", "api_key", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "sync_files_on_connection", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["url", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "request_id", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["domain"]) -> MetaOapg.properties.domain: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["api_key"]) -> MetaOapg.properties.api_key: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union[MetaOapg.properties.tags, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_size"]) -> typing.Union[MetaOapg.properties.chunk_size, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_overlap"]) -> typing.Union[MetaOapg.properties.chunk_overlap, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> typing.Union[MetaOapg.properties.skip_embedding_generation, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGeneratorsNullable', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> typing.Union[MetaOapg.properties.generate_sparse_vectors, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["sync_files_on_connection"]) -> typing.Union[MetaOapg.properties.sync_files_on_connection, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> typing.Union[MetaOapg.properties.request_id, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["domain", "api_key", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "sync_files_on_connection", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["url", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "request_id", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        api_key: typing.Union[MetaOapg.properties.api_key, str, ],
-        domain: typing.Union[MetaOapg.properties.domain, str, ],
+        url: typing.Union[MetaOapg.properties.url, str, ],
         tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
-        embedding_model: typing.Union['EmbeddingGeneratorsNullable', schemas.Unset] = schemas.unset,
+        embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
-        sync_files_on_connection: typing.Union[MetaOapg.properties.sync_files_on_connection, None, bool, schemas.Unset] = schemas.unset,
+        request_id: typing.Union[MetaOapg.properties.request_id, None, str, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'FreshDeskConnectRequest':
+    ) -> 'RSSFeedInput':
         return super().__new__(
             cls,
             *args,
-            api_key=api_key,
-            domain=domain,
+            url=url,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
             _configuration=_configuration,
             **kwargs,
         )
 
-from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.model.embedding_generators import EmbeddingGenerators
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/fresh_desk_connect_request.pyi` & `carbon_python_sdk-0.2.0/carbon/model/rss_feed_input.pyi`

 * *Files 6% similar despite different names*

```diff
@@ -19,31 +19,29 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class FreshDeskConnectRequest(
+class RSSFeedInput(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
-            "api_key",
-            "domain",
+            "url",
         }
         
         class properties:
-            domain = schemas.StrSchema
-            api_key = schemas.StrSchema
+            url = schemas.StrSchema
             
             
             class tags(
                 schemas.DictBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneFrozenDictMixin
@@ -120,16 +118,16 @@
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
         
             @staticmethod
-            def embedding_model() -> typing.Type['EmbeddingGeneratorsNullable']:
-                return EmbeddingGeneratorsNullable
+            def embedding_model() -> typing.Type['EmbeddingGenerators']:
+                return EmbeddingGenerators
             
             
             class generate_sparse_vectors(
                 schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneBoolMixin
@@ -164,150 +162,140 @@
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
             
             
-            class sync_files_on_connection(
-                schemas.BoolBase,
+            class request_id(
+                schemas.StrBase,
                 schemas.NoneBase,
                 schemas.Schema,
-                schemas.NoneBoolMixin
+                schemas.NoneStrMixin
             ):
             
             
                 def __new__(
                     cls,
-                    *args: typing.Union[None, bool, ],
+                    *args: typing.Union[None, str, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'sync_files_on_connection':
+                ) -> 'request_id':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
             __annotations__ = {
-                "domain": domain,
-                "api_key": api_key,
+                "url": url,
                 "tags": tags,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
                 "embedding_model": embedding_model,
                 "generate_sparse_vectors": generate_sparse_vectors,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
-                "sync_files_on_connection": sync_files_on_connection,
+                "request_id": request_id,
             }
     
-    api_key: MetaOapg.properties.api_key
-    domain: MetaOapg.properties.domain
+    url: MetaOapg.properties.url
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["domain"]) -> MetaOapg.properties.domain: ...
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["api_key"]) -> MetaOapg.properties.api_key: ...
+    def __getitem__(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_size"]) -> MetaOapg.properties.chunk_size: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> MetaOapg.properties.skip_embedding_generation: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGeneratorsNullable': ...
+    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["sync_files_on_connection"]) -> MetaOapg.properties.sync_files_on_connection: ...
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["domain", "api_key", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "sync_files_on_connection", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["url", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "request_id", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["domain"]) -> MetaOapg.properties.domain: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["api_key"]) -> MetaOapg.properties.api_key: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union[MetaOapg.properties.tags, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_size"]) -> typing.Union[MetaOapg.properties.chunk_size, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_overlap"]) -> typing.Union[MetaOapg.properties.chunk_overlap, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> typing.Union[MetaOapg.properties.skip_embedding_generation, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGeneratorsNullable', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> typing.Union[MetaOapg.properties.generate_sparse_vectors, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["sync_files_on_connection"]) -> typing.Union[MetaOapg.properties.sync_files_on_connection, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> typing.Union[MetaOapg.properties.request_id, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["domain", "api_key", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "sync_files_on_connection", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["url", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "request_id", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        api_key: typing.Union[MetaOapg.properties.api_key, str, ],
-        domain: typing.Union[MetaOapg.properties.domain, str, ],
+        url: typing.Union[MetaOapg.properties.url, str, ],
         tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
-        embedding_model: typing.Union['EmbeddingGeneratorsNullable', schemas.Unset] = schemas.unset,
+        embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
-        sync_files_on_connection: typing.Union[MetaOapg.properties.sync_files_on_connection, None, bool, schemas.Unset] = schemas.unset,
+        request_id: typing.Union[MetaOapg.properties.request_id, None, str, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'FreshDeskConnectRequest':
+    ) -> 'RSSFeedInput':
         return super().__new__(
             cls,
             *args,
-            api_key=api_key,
-            domain=domain,
+            url=url,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
             _configuration=_configuration,
             **kwargs,
         )
 
-from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.model.embedding_generators import EmbeddingGenerators
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/freskdesk_authentication.py` & `carbon_python_sdk-0.2.0/carbon/model/freskdesk_authentication.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/freskdesk_authentication.pyi` & `carbon_python_sdk-0.2.0/carbon/model/freskdesk_authentication.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/generic_success_response.py` & `carbon_python_sdk-0.2.0/carbon/model/generic_success_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/generic_success_response.pyi` & `carbon_python_sdk-0.2.0/carbon/model/generic_success_response.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body.py` & `carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body.py`

 * *Files 4% similar despite different names*

```diff
@@ -68,14 +68,15 @@
             @staticmethod
             def file_ids() -> typing.Type['GetEmbeddingDocumentsBodyFileIds']:
                 return GetEmbeddingDocumentsBodyFileIds
         
             @staticmethod
             def parent_file_ids() -> typing.Type['GetEmbeddingDocumentsBodyParentFileIds']:
                 return GetEmbeddingDocumentsBodyParentFileIds
+            include_all_children = schemas.BoolSchema
             
             
             class tags_v2(
                 schemas.DictBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneFrozenDictMixin
@@ -189,14 +190,15 @@
             __annotations__ = {
                 "query": query,
                 "k": k,
                 "tags": tags,
                 "query_vector": query_vector,
                 "file_ids": file_ids,
                 "parent_file_ids": parent_file_ids,
+                "include_all_children": include_all_children,
                 "tags_v2": tags_v2,
                 "include_tags": include_tags,
                 "include_vectors": include_vectors,
                 "include_raw_file": include_raw_file,
                 "hybrid_search": hybrid_search,
                 "hybrid_search_tuning_parameters": hybrid_search_tuning_parameters,
                 "media_type": media_type,
@@ -221,14 +223,17 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["file_ids"]) -> 'GetEmbeddingDocumentsBodyFileIds': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["parent_file_ids"]) -> 'GetEmbeddingDocumentsBodyParentFileIds': ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["include_all_children"]) -> MetaOapg.properties.include_all_children: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["tags_v2"]) -> MetaOapg.properties.tags_v2: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["include_tags"]) -> MetaOapg.properties.include_tags: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["include_vectors"]) -> MetaOapg.properties.include_vectors: ...
@@ -247,15 +252,15 @@
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGeneratorsNullable': ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["query", "k", "tags", "query_vector", "file_ids", "parent_file_ids", "tags_v2", "include_tags", "include_vectors", "include_raw_file", "hybrid_search", "hybrid_search_tuning_parameters", "media_type", "embedding_model", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["query", "k", "tags", "query_vector", "file_ids", "parent_file_ids", "include_all_children", "tags_v2", "include_tags", "include_vectors", "include_raw_file", "hybrid_search", "hybrid_search_tuning_parameters", "media_type", "embedding_model", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["query"]) -> MetaOapg.properties.query: ...
     
@@ -271,14 +276,17 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["file_ids"]) -> typing.Union['GetEmbeddingDocumentsBodyFileIds', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["parent_file_ids"]) -> typing.Union['GetEmbeddingDocumentsBodyParentFileIds', schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["include_all_children"]) -> typing.Union[MetaOapg.properties.include_all_children, schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["tags_v2"]) -> typing.Union[MetaOapg.properties.tags_v2, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["include_tags"]) -> typing.Union[MetaOapg.properties.include_tags, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["include_vectors"]) -> typing.Union[MetaOapg.properties.include_vectors, schemas.Unset]: ...
@@ -297,27 +305,28 @@
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGeneratorsNullable', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["query", "k", "tags", "query_vector", "file_ids", "parent_file_ids", "tags_v2", "include_tags", "include_vectors", "include_raw_file", "hybrid_search", "hybrid_search_tuning_parameters", "media_type", "embedding_model", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["query", "k", "tags", "query_vector", "file_ids", "parent_file_ids", "include_all_children", "tags_v2", "include_tags", "include_vectors", "include_raw_file", "hybrid_search", "hybrid_search_tuning_parameters", "media_type", "embedding_model", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         query: typing.Union[MetaOapg.properties.query, str, ],
         k: typing.Union[MetaOapg.properties.k, decimal.Decimal, int, ],
         tags: typing.Union['GetEmbeddingDocumentsBodyTags', schemas.Unset] = schemas.unset,
         query_vector: typing.Union['GetEmbeddingDocumentsBodyQueryVector', schemas.Unset] = schemas.unset,
         file_ids: typing.Union['GetEmbeddingDocumentsBodyFileIds', schemas.Unset] = schemas.unset,
         parent_file_ids: typing.Union['GetEmbeddingDocumentsBodyParentFileIds', schemas.Unset] = schemas.unset,
+        include_all_children: typing.Union[MetaOapg.properties.include_all_children, bool, schemas.Unset] = schemas.unset,
         tags_v2: typing.Union[MetaOapg.properties.tags_v2, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
         include_tags: typing.Union[MetaOapg.properties.include_tags, None, bool, schemas.Unset] = schemas.unset,
         include_vectors: typing.Union[MetaOapg.properties.include_vectors, None, bool, schemas.Unset] = schemas.unset,
         include_raw_file: typing.Union[MetaOapg.properties.include_raw_file, None, bool, schemas.Unset] = schemas.unset,
         hybrid_search: typing.Union[MetaOapg.properties.hybrid_search, None, bool, schemas.Unset] = schemas.unset,
         hybrid_search_tuning_parameters: typing.Union['HybridSearchTuningParamsNullable', schemas.Unset] = schemas.unset,
         media_type: typing.Union['FileContentTypesNullable', schemas.Unset] = schemas.unset,
@@ -330,14 +339,15 @@
             *args,
             query=query,
             k=k,
             tags=tags,
             query_vector=query_vector,
             file_ids=file_ids,
             parent_file_ids=parent_file_ids,
+            include_all_children=include_all_children,
             tags_v2=tags_v2,
             include_tags=include_tags,
             include_vectors=include_vectors,
             include_raw_file=include_raw_file,
             hybrid_search=hybrid_search,
             hybrid_search_tuning_parameters=hybrid_search_tuning_parameters,
             media_type=media_type,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body.pyi` & `carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body.pyi`

 * *Files 6% similar despite different names*

```diff
@@ -62,14 +62,15 @@
             @staticmethod
             def file_ids() -> typing.Type['GetEmbeddingDocumentsBodyFileIds']:
                 return GetEmbeddingDocumentsBodyFileIds
         
             @staticmethod
             def parent_file_ids() -> typing.Type['GetEmbeddingDocumentsBodyParentFileIds']:
                 return GetEmbeddingDocumentsBodyParentFileIds
+            include_all_children = schemas.BoolSchema
             
             
             class tags_v2(
                 schemas.DictBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneFrozenDictMixin
@@ -183,14 +184,15 @@
             __annotations__ = {
                 "query": query,
                 "k": k,
                 "tags": tags,
                 "query_vector": query_vector,
                 "file_ids": file_ids,
                 "parent_file_ids": parent_file_ids,
+                "include_all_children": include_all_children,
                 "tags_v2": tags_v2,
                 "include_tags": include_tags,
                 "include_vectors": include_vectors,
                 "include_raw_file": include_raw_file,
                 "hybrid_search": hybrid_search,
                 "hybrid_search_tuning_parameters": hybrid_search_tuning_parameters,
                 "media_type": media_type,
@@ -215,14 +217,17 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["file_ids"]) -> 'GetEmbeddingDocumentsBodyFileIds': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["parent_file_ids"]) -> 'GetEmbeddingDocumentsBodyParentFileIds': ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["include_all_children"]) -> MetaOapg.properties.include_all_children: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["tags_v2"]) -> MetaOapg.properties.tags_v2: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["include_tags"]) -> MetaOapg.properties.include_tags: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["include_vectors"]) -> MetaOapg.properties.include_vectors: ...
@@ -241,15 +246,15 @@
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGeneratorsNullable': ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["query", "k", "tags", "query_vector", "file_ids", "parent_file_ids", "tags_v2", "include_tags", "include_vectors", "include_raw_file", "hybrid_search", "hybrid_search_tuning_parameters", "media_type", "embedding_model", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["query", "k", "tags", "query_vector", "file_ids", "parent_file_ids", "include_all_children", "tags_v2", "include_tags", "include_vectors", "include_raw_file", "hybrid_search", "hybrid_search_tuning_parameters", "media_type", "embedding_model", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["query"]) -> MetaOapg.properties.query: ...
     
@@ -265,14 +270,17 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["file_ids"]) -> typing.Union['GetEmbeddingDocumentsBodyFileIds', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["parent_file_ids"]) -> typing.Union['GetEmbeddingDocumentsBodyParentFileIds', schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["include_all_children"]) -> typing.Union[MetaOapg.properties.include_all_children, schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["tags_v2"]) -> typing.Union[MetaOapg.properties.tags_v2, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["include_tags"]) -> typing.Union[MetaOapg.properties.include_tags, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["include_vectors"]) -> typing.Union[MetaOapg.properties.include_vectors, schemas.Unset]: ...
@@ -291,27 +299,28 @@
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGeneratorsNullable', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["query", "k", "tags", "query_vector", "file_ids", "parent_file_ids", "tags_v2", "include_tags", "include_vectors", "include_raw_file", "hybrid_search", "hybrid_search_tuning_parameters", "media_type", "embedding_model", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["query", "k", "tags", "query_vector", "file_ids", "parent_file_ids", "include_all_children", "tags_v2", "include_tags", "include_vectors", "include_raw_file", "hybrid_search", "hybrid_search_tuning_parameters", "media_type", "embedding_model", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         query: typing.Union[MetaOapg.properties.query, str, ],
         k: typing.Union[MetaOapg.properties.k, decimal.Decimal, int, ],
         tags: typing.Union['GetEmbeddingDocumentsBodyTags', schemas.Unset] = schemas.unset,
         query_vector: typing.Union['GetEmbeddingDocumentsBodyQueryVector', schemas.Unset] = schemas.unset,
         file_ids: typing.Union['GetEmbeddingDocumentsBodyFileIds', schemas.Unset] = schemas.unset,
         parent_file_ids: typing.Union['GetEmbeddingDocumentsBodyParentFileIds', schemas.Unset] = schemas.unset,
+        include_all_children: typing.Union[MetaOapg.properties.include_all_children, bool, schemas.Unset] = schemas.unset,
         tags_v2: typing.Union[MetaOapg.properties.tags_v2, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
         include_tags: typing.Union[MetaOapg.properties.include_tags, None, bool, schemas.Unset] = schemas.unset,
         include_vectors: typing.Union[MetaOapg.properties.include_vectors, None, bool, schemas.Unset] = schemas.unset,
         include_raw_file: typing.Union[MetaOapg.properties.include_raw_file, None, bool, schemas.Unset] = schemas.unset,
         hybrid_search: typing.Union[MetaOapg.properties.hybrid_search, None, bool, schemas.Unset] = schemas.unset,
         hybrid_search_tuning_parameters: typing.Union['HybridSearchTuningParamsNullable', schemas.Unset] = schemas.unset,
         media_type: typing.Union['FileContentTypesNullable', schemas.Unset] = schemas.unset,
@@ -324,14 +333,15 @@
             *args,
             query=query,
             k=k,
             tags=tags,
             query_vector=query_vector,
             file_ids=file_ids,
             parent_file_ids=parent_file_ids,
+            include_all_children=include_all_children,
             tags_v2=tags_v2,
             include_tags=include_tags,
             include_vectors=include_vectors,
             include_raw_file=include_raw_file,
             hybrid_search=hybrid_search,
             hybrid_search_tuning_parameters=hybrid_search_tuning_parameters,
             media_type=media_type,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body_file_ids.py` & `carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body_file_ids.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body_file_ids.pyi` & `carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body_file_ids.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body_parent_file_ids.py` & `carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body_parent_file_ids.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body_parent_file_ids.pyi` & `carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body_parent_file_ids.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body_query_vector.py` & `carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body_query_vector.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body_query_vector.pyi` & `carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body_query_vector.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body_tags.py` & `carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body_tags.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/get_embedding_documents_body_tags.pyi` & `carbon_python_sdk-0.2.0/carbon/model/get_embedding_documents_body_tags.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/gitbook_authetication.py` & `carbon_python_sdk-0.2.0/carbon/model/gitbook_authetication.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/gitbook_authetication.pyi` & `carbon_python_sdk-0.2.0/carbon/model/gitbook_authetication.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/gitbook_connect_request.py` & `carbon_python_sdk-0.2.0/carbon/model/gitbook_connect_request.py`

 * *Files 10% similar despite different names*

```diff
@@ -182,25 +182,48 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'sync_files_on_connection':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            
+            
+            class request_id(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'request_id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            sync_source_items = schemas.BoolSchema
             __annotations__ = {
                 "organization": organization,
                 "access_token": access_token,
                 "tags": tags,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
                 "embedding_model": embedding_model,
                 "generate_sparse_vectors": generate_sparse_vectors,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
                 "sync_files_on_connection": sync_files_on_connection,
+                "request_id": request_id,
+                "sync_source_items": sync_source_items,
             }
     
     access_token: MetaOapg.properties.access_token
     organization: MetaOapg.properties.organization
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["organization"]) -> MetaOapg.properties.organization: ...
@@ -229,17 +252,23 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["sync_files_on_connection"]) -> MetaOapg.properties.sync_files_on_connection: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["sync_source_items"]) -> MetaOapg.properties.sync_source_items: ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["organization", "access_token", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "sync_files_on_connection", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["organization", "access_token", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "sync_files_on_connection", "request_id", "sync_source_items", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["organization"]) -> MetaOapg.properties.organization: ...
     
@@ -267,17 +296,23 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["sync_files_on_connection"]) -> typing.Union[MetaOapg.properties.sync_files_on_connection, schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> typing.Union[MetaOapg.properties.request_id, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_source_items"]) -> typing.Union[MetaOapg.properties.sync_source_items, schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["organization", "access_token", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "sync_files_on_connection", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["organization", "access_token", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "sync_files_on_connection", "request_id", "sync_source_items", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         access_token: typing.Union[MetaOapg.properties.access_token, str, ],
@@ -286,14 +321,16 @@
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
         embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
         sync_files_on_connection: typing.Union[MetaOapg.properties.sync_files_on_connection, None, bool, schemas.Unset] = schemas.unset,
+        request_id: typing.Union[MetaOapg.properties.request_id, None, str, schemas.Unset] = schemas.unset,
+        sync_source_items: typing.Union[MetaOapg.properties.sync_source_items, bool, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
     ) -> 'GitbookConnectRequest':
         return super().__new__(
             cls,
             *args,
             access_token=access_token,
@@ -302,12 +339,14 @@
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.embedding_generators import EmbeddingGenerators
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/gitbook_connect_request.pyi` & `carbon_python_sdk-0.2.0/carbon/model/gitbook_connect_request.pyi`

 * *Files 10% similar despite different names*

```diff
@@ -182,25 +182,48 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'sync_files_on_connection':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            
+            
+            class request_id(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'request_id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            sync_source_items = schemas.BoolSchema
             __annotations__ = {
                 "organization": organization,
                 "access_token": access_token,
                 "tags": tags,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
                 "embedding_model": embedding_model,
                 "generate_sparse_vectors": generate_sparse_vectors,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
                 "sync_files_on_connection": sync_files_on_connection,
+                "request_id": request_id,
+                "sync_source_items": sync_source_items,
             }
     
     access_token: MetaOapg.properties.access_token
     organization: MetaOapg.properties.organization
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["organization"]) -> MetaOapg.properties.organization: ...
@@ -229,17 +252,23 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["sync_files_on_connection"]) -> MetaOapg.properties.sync_files_on_connection: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["sync_source_items"]) -> MetaOapg.properties.sync_source_items: ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["organization", "access_token", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "sync_files_on_connection", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["organization", "access_token", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "sync_files_on_connection", "request_id", "sync_source_items", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["organization"]) -> MetaOapg.properties.organization: ...
     
@@ -267,17 +296,23 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["sync_files_on_connection"]) -> typing.Union[MetaOapg.properties.sync_files_on_connection, schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> typing.Union[MetaOapg.properties.request_id, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_source_items"]) -> typing.Union[MetaOapg.properties.sync_source_items, schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["organization", "access_token", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "sync_files_on_connection", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["organization", "access_token", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "sync_files_on_connection", "request_id", "sync_source_items", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         access_token: typing.Union[MetaOapg.properties.access_token, str, ],
@@ -286,14 +321,16 @@
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
         embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
         sync_files_on_connection: typing.Union[MetaOapg.properties.sync_files_on_connection, None, bool, schemas.Unset] = schemas.unset,
+        request_id: typing.Union[MetaOapg.properties.request_id, None, str, schemas.Unset] = schemas.unset,
+        sync_source_items: typing.Union[MetaOapg.properties.sync_source_items, bool, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
     ) -> 'GitbookConnectRequest':
         return super().__new__(
             cls,
             *args,
             access_token=access_token,
@@ -302,12 +339,14 @@
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.embedding_generators import EmbeddingGenerators
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/gitbook_sync_request.py` & `carbon_python_sdk-0.2.0/carbon/model/gitbook_sync_request.py`

 * *Files 4% similar despite different names*

```diff
@@ -165,24 +165,45 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'prepend_filename_to_chunks':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            
+            
+            class request_id(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'request_id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             __annotations__ = {
                 "space_ids": space_ids,
                 "data_source_id": data_source_id,
                 "tags": tags,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
                 "embedding_model": embedding_model,
                 "generate_sparse_vectors": generate_sparse_vectors,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
+                "request_id": request_id,
             }
     
     space_ids: 'GitbookSyncRequestSpaceIds'
     data_source_id: MetaOapg.properties.data_source_id
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["space_ids"]) -> 'GitbookSyncRequestSpaceIds': ...
@@ -208,17 +229,20 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["space_ids", "data_source_id", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["space_ids", "data_source_id", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "request_id", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["space_ids"]) -> 'GitbookSyncRequestSpaceIds': ...
     
@@ -243,17 +267,20 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> typing.Union[MetaOapg.properties.generate_sparse_vectors, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> typing.Union[MetaOapg.properties.request_id, schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["space_ids", "data_source_id", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["space_ids", "data_source_id", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "request_id", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         space_ids: 'GitbookSyncRequestSpaceIds',
@@ -261,14 +288,15 @@
         tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
         embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
+        request_id: typing.Union[MetaOapg.properties.request_id, None, str, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
     ) -> 'GitbookSyncRequest':
         return super().__new__(
             cls,
             *args,
             space_ids=space_ids,
@@ -276,13 +304,14 @@
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            request_id=request_id,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.embedding_generators import EmbeddingGenerators
 from carbon.model.gitbook_sync_request_space_ids import GitbookSyncRequestSpaceIds
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/gitbook_sync_request.pyi` & `carbon_python_sdk-0.2.0/carbon/model/gitbook_sync_request.pyi`

 * *Files 4% similar despite different names*

```diff
@@ -165,24 +165,45 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'prepend_filename_to_chunks':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            
+            
+            class request_id(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'request_id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             __annotations__ = {
                 "space_ids": space_ids,
                 "data_source_id": data_source_id,
                 "tags": tags,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
                 "embedding_model": embedding_model,
                 "generate_sparse_vectors": generate_sparse_vectors,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
+                "request_id": request_id,
             }
     
     space_ids: 'GitbookSyncRequestSpaceIds'
     data_source_id: MetaOapg.properties.data_source_id
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["space_ids"]) -> 'GitbookSyncRequestSpaceIds': ...
@@ -208,17 +229,20 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["space_ids", "data_source_id", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["space_ids", "data_source_id", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "request_id", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["space_ids"]) -> 'GitbookSyncRequestSpaceIds': ...
     
@@ -243,17 +267,20 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> typing.Union[MetaOapg.properties.generate_sparse_vectors, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> typing.Union[MetaOapg.properties.request_id, schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["space_ids", "data_source_id", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["space_ids", "data_source_id", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "request_id", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         space_ids: 'GitbookSyncRequestSpaceIds',
@@ -261,14 +288,15 @@
         tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
         embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
+        request_id: typing.Union[MetaOapg.properties.request_id, None, str, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
     ) -> 'GitbookSyncRequest':
         return super().__new__(
             cls,
             *args,
             space_ids=space_ids,
@@ -276,13 +304,14 @@
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            request_id=request_id,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.embedding_generators import EmbeddingGenerators
 from carbon.model.gitbook_sync_request_space_ids import GitbookSyncRequestSpaceIds
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/gitbook_sync_request_space_ids.py` & `carbon_python_sdk-0.2.0/carbon/model/gitbook_sync_request_space_ids.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/gitbook_sync_request_space_ids.pyi` & `carbon_python_sdk-0.2.0/carbon/model/gitbook_sync_request_space_ids.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/gmail_sync_input.py` & `carbon_python_sdk-0.2.0/carbon/model/upload_file_from_url_input.py`

 * *Files 13% similar despite different names*

```diff
@@ -19,50 +19,48 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class GmailSyncInput(
+class UploadFileFromUrlInput(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
-            "filters",
+            "url",
         }
         
         class properties:
-            filters = schemas.DictSchema
+            url = schemas.StrSchema
             
             
-            class tags(
-                schemas.DictBase,
+            class file_name(
+                schemas.StrBase,
                 schemas.NoneBase,
                 schemas.Schema,
-                schemas.NoneFrozenDictMixin
+                schemas.NoneStrMixin
             ):
             
             
                 def __new__(
                     cls,
-                    *args: typing.Union[dict, frozendict.frozendict, None, ],
+                    *args: typing.Union[None, str, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                    **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-                ) -> 'tags':
+                ) -> 'file_name':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
-                        **kwargs,
                     )
             
             
             class chunk_size(
                 schemas.IntBase,
                 schemas.NoneBase,
                 schemas.Schema,
@@ -96,206 +94,189 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'chunk_overlap':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
-            
-            
-            class skip_embedding_generation(
-                schemas.BoolBase,
-                schemas.NoneBase,
-                schemas.Schema,
-                schemas.NoneBoolMixin
-            ):
-            
-            
-                def __new__(
-                    cls,
-                    *args: typing.Union[None, bool, ],
-                    _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'skip_embedding_generation':
-                    return super().__new__(
-                        cls,
-                        *args,
-                        _configuration=_configuration,
-                    )
+            skip_embedding_generation = schemas.BoolSchema
+            set_page_as_boundary = schemas.BoolSchema
         
             @staticmethod
             def embedding_model() -> typing.Type['EmbeddingGenerators']:
                 return EmbeddingGenerators
+            generate_sparse_vectors = schemas.BoolSchema
+            use_textract = schemas.BoolSchema
+            prepend_filename_to_chunks = schemas.BoolSchema
             
             
-            class generate_sparse_vectors(
-                schemas.BoolBase,
-                schemas.NoneBase,
-                schemas.Schema,
-                schemas.NoneBoolMixin
-            ):
-            
-            
-                def __new__(
-                    cls,
-                    *args: typing.Union[None, bool, ],
-                    _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'generate_sparse_vectors':
-                    return super().__new__(
-                        cls,
-                        *args,
-                        _configuration=_configuration,
-                    )
-            
-            
-            class prepend_filename_to_chunks(
-                schemas.BoolBase,
-                schemas.NoneBase,
-                schemas.Schema,
-                schemas.NoneBoolMixin
-            ):
-            
-            
-                def __new__(
-                    cls,
-                    *args: typing.Union[None, bool, ],
-                    _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'prepend_filename_to_chunks':
-                    return super().__new__(
-                        cls,
-                        *args,
-                        _configuration=_configuration,
-                    )
-            
-            
-            class data_source_id(
+            class max_items_per_chunk(
                 schemas.IntBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneDecimalMixin
             ):
             
             
                 def __new__(
                     cls,
                     *args: typing.Union[None, decimal.Decimal, int, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'data_source_id':
+                ) -> 'max_items_per_chunk':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            parse_pdf_tables_with_ocr = schemas.BoolSchema
+            detect_audio_language = schemas.BoolSchema
             __annotations__ = {
-                "filters": filters,
-                "tags": tags,
+                "url": url,
+                "file_name": file_name,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
+                "set_page_as_boundary": set_page_as_boundary,
                 "embedding_model": embedding_model,
                 "generate_sparse_vectors": generate_sparse_vectors,
+                "use_textract": use_textract,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
-                "data_source_id": data_source_id,
+                "max_items_per_chunk": max_items_per_chunk,
+                "parse_pdf_tables_with_ocr": parse_pdf_tables_with_ocr,
+                "detect_audio_language": detect_audio_language,
             }
     
-    filters: MetaOapg.properties.filters
+    url: MetaOapg.properties.url
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["filters"]) -> MetaOapg.properties.filters: ...
+    def __getitem__(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
+    def __getitem__(self, name: typing_extensions.Literal["file_name"]) -> MetaOapg.properties.file_name: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_size"]) -> MetaOapg.properties.chunk_size: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> MetaOapg.properties.skip_embedding_generation: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["set_page_as_boundary"]) -> MetaOapg.properties.set_page_as_boundary: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["use_textract"]) -> MetaOapg.properties.use_textract: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
+    def __getitem__(self, name: typing_extensions.Literal["max_items_per_chunk"]) -> MetaOapg.properties.max_items_per_chunk: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["parse_pdf_tables_with_ocr"]) -> MetaOapg.properties.parse_pdf_tables_with_ocr: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["detect_audio_language"]) -> MetaOapg.properties.detect_audio_language: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["filters", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "data_source_id", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["url", "file_name", "chunk_size", "chunk_overlap", "skip_embedding_generation", "set_page_as_boundary", "embedding_model", "generate_sparse_vectors", "use_textract", "prepend_filename_to_chunks", "max_items_per_chunk", "parse_pdf_tables_with_ocr", "detect_audio_language", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["filters"]) -> MetaOapg.properties.filters: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union[MetaOapg.properties.tags, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["file_name"]) -> typing.Union[MetaOapg.properties.file_name, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_size"]) -> typing.Union[MetaOapg.properties.chunk_size, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_overlap"]) -> typing.Union[MetaOapg.properties.chunk_overlap, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> typing.Union[MetaOapg.properties.skip_embedding_generation, schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["set_page_as_boundary"]) -> typing.Union[MetaOapg.properties.set_page_as_boundary, schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> typing.Union[MetaOapg.properties.generate_sparse_vectors, schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["use_textract"]) -> typing.Union[MetaOapg.properties.use_textract, schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> typing.Union[MetaOapg.properties.data_source_id, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["max_items_per_chunk"]) -> typing.Union[MetaOapg.properties.max_items_per_chunk, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["parse_pdf_tables_with_ocr"]) -> typing.Union[MetaOapg.properties.parse_pdf_tables_with_ocr, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["detect_audio_language"]) -> typing.Union[MetaOapg.properties.detect_audio_language, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["filters", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "data_source_id", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["url", "file_name", "chunk_size", "chunk_overlap", "skip_embedding_generation", "set_page_as_boundary", "embedding_model", "generate_sparse_vectors", "use_textract", "prepend_filename_to_chunks", "max_items_per_chunk", "parse_pdf_tables_with_ocr", "detect_audio_language", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        filters: typing.Union[MetaOapg.properties.filters, dict, frozendict.frozendict, ],
-        tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
+        url: typing.Union[MetaOapg.properties.url, str, ],
+        file_name: typing.Union[MetaOapg.properties.file_name, None, str, schemas.Unset] = schemas.unset,
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
-        skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
+        skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, bool, schemas.Unset] = schemas.unset,
+        set_page_as_boundary: typing.Union[MetaOapg.properties.set_page_as_boundary, bool, schemas.Unset] = schemas.unset,
         embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
-        generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
-        prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
-        data_source_id: typing.Union[MetaOapg.properties.data_source_id, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, bool, schemas.Unset] = schemas.unset,
+        use_textract: typing.Union[MetaOapg.properties.use_textract, bool, schemas.Unset] = schemas.unset,
+        prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, bool, schemas.Unset] = schemas.unset,
+        max_items_per_chunk: typing.Union[MetaOapg.properties.max_items_per_chunk, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        parse_pdf_tables_with_ocr: typing.Union[MetaOapg.properties.parse_pdf_tables_with_ocr, bool, schemas.Unset] = schemas.unset,
+        detect_audio_language: typing.Union[MetaOapg.properties.detect_audio_language, bool, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'GmailSyncInput':
+    ) -> 'UploadFileFromUrlInput':
         return super().__new__(
             cls,
             *args,
-            filters=filters,
-            tags=tags,
+            url=url,
+            file_name=file_name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
+            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            data_source_id=data_source_id,
+            max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.embedding_generators import EmbeddingGenerators
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/gmail_sync_input.pyi` & `carbon_python_sdk-0.2.0/carbon/model/upload_file_from_url_input.pyi`

 * *Files 13% similar despite different names*

```diff
@@ -19,50 +19,48 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class GmailSyncInput(
+class UploadFileFromUrlInput(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
-            "filters",
+            "url",
         }
         
         class properties:
-            filters = schemas.DictSchema
+            url = schemas.StrSchema
             
             
-            class tags(
-                schemas.DictBase,
+            class file_name(
+                schemas.StrBase,
                 schemas.NoneBase,
                 schemas.Schema,
-                schemas.NoneFrozenDictMixin
+                schemas.NoneStrMixin
             ):
             
             
                 def __new__(
                     cls,
-                    *args: typing.Union[dict, frozendict.frozendict, None, ],
+                    *args: typing.Union[None, str, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                    **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-                ) -> 'tags':
+                ) -> 'file_name':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
-                        **kwargs,
                     )
             
             
             class chunk_size(
                 schemas.IntBase,
                 schemas.NoneBase,
                 schemas.Schema,
@@ -96,206 +94,189 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'chunk_overlap':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
-            
-            
-            class skip_embedding_generation(
-                schemas.BoolBase,
-                schemas.NoneBase,
-                schemas.Schema,
-                schemas.NoneBoolMixin
-            ):
-            
-            
-                def __new__(
-                    cls,
-                    *args: typing.Union[None, bool, ],
-                    _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'skip_embedding_generation':
-                    return super().__new__(
-                        cls,
-                        *args,
-                        _configuration=_configuration,
-                    )
+            skip_embedding_generation = schemas.BoolSchema
+            set_page_as_boundary = schemas.BoolSchema
         
             @staticmethod
             def embedding_model() -> typing.Type['EmbeddingGenerators']:
                 return EmbeddingGenerators
+            generate_sparse_vectors = schemas.BoolSchema
+            use_textract = schemas.BoolSchema
+            prepend_filename_to_chunks = schemas.BoolSchema
             
             
-            class generate_sparse_vectors(
-                schemas.BoolBase,
-                schemas.NoneBase,
-                schemas.Schema,
-                schemas.NoneBoolMixin
-            ):
-            
-            
-                def __new__(
-                    cls,
-                    *args: typing.Union[None, bool, ],
-                    _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'generate_sparse_vectors':
-                    return super().__new__(
-                        cls,
-                        *args,
-                        _configuration=_configuration,
-                    )
-            
-            
-            class prepend_filename_to_chunks(
-                schemas.BoolBase,
-                schemas.NoneBase,
-                schemas.Schema,
-                schemas.NoneBoolMixin
-            ):
-            
-            
-                def __new__(
-                    cls,
-                    *args: typing.Union[None, bool, ],
-                    _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'prepend_filename_to_chunks':
-                    return super().__new__(
-                        cls,
-                        *args,
-                        _configuration=_configuration,
-                    )
-            
-            
-            class data_source_id(
+            class max_items_per_chunk(
                 schemas.IntBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneDecimalMixin
             ):
             
             
                 def __new__(
                     cls,
                     *args: typing.Union[None, decimal.Decimal, int, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'data_source_id':
+                ) -> 'max_items_per_chunk':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            parse_pdf_tables_with_ocr = schemas.BoolSchema
+            detect_audio_language = schemas.BoolSchema
             __annotations__ = {
-                "filters": filters,
-                "tags": tags,
+                "url": url,
+                "file_name": file_name,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
+                "set_page_as_boundary": set_page_as_boundary,
                 "embedding_model": embedding_model,
                 "generate_sparse_vectors": generate_sparse_vectors,
+                "use_textract": use_textract,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
-                "data_source_id": data_source_id,
+                "max_items_per_chunk": max_items_per_chunk,
+                "parse_pdf_tables_with_ocr": parse_pdf_tables_with_ocr,
+                "detect_audio_language": detect_audio_language,
             }
     
-    filters: MetaOapg.properties.filters
+    url: MetaOapg.properties.url
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["filters"]) -> MetaOapg.properties.filters: ...
+    def __getitem__(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
+    def __getitem__(self, name: typing_extensions.Literal["file_name"]) -> MetaOapg.properties.file_name: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_size"]) -> MetaOapg.properties.chunk_size: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> MetaOapg.properties.skip_embedding_generation: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["set_page_as_boundary"]) -> MetaOapg.properties.set_page_as_boundary: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["use_textract"]) -> MetaOapg.properties.use_textract: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
+    def __getitem__(self, name: typing_extensions.Literal["max_items_per_chunk"]) -> MetaOapg.properties.max_items_per_chunk: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["parse_pdf_tables_with_ocr"]) -> MetaOapg.properties.parse_pdf_tables_with_ocr: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["detect_audio_language"]) -> MetaOapg.properties.detect_audio_language: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["filters", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "data_source_id", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["url", "file_name", "chunk_size", "chunk_overlap", "skip_embedding_generation", "set_page_as_boundary", "embedding_model", "generate_sparse_vectors", "use_textract", "prepend_filename_to_chunks", "max_items_per_chunk", "parse_pdf_tables_with_ocr", "detect_audio_language", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["filters"]) -> MetaOapg.properties.filters: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union[MetaOapg.properties.tags, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["file_name"]) -> typing.Union[MetaOapg.properties.file_name, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_size"]) -> typing.Union[MetaOapg.properties.chunk_size, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_overlap"]) -> typing.Union[MetaOapg.properties.chunk_overlap, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> typing.Union[MetaOapg.properties.skip_embedding_generation, schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["set_page_as_boundary"]) -> typing.Union[MetaOapg.properties.set_page_as_boundary, schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> typing.Union[MetaOapg.properties.generate_sparse_vectors, schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["use_textract"]) -> typing.Union[MetaOapg.properties.use_textract, schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> typing.Union[MetaOapg.properties.data_source_id, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["max_items_per_chunk"]) -> typing.Union[MetaOapg.properties.max_items_per_chunk, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["parse_pdf_tables_with_ocr"]) -> typing.Union[MetaOapg.properties.parse_pdf_tables_with_ocr, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["detect_audio_language"]) -> typing.Union[MetaOapg.properties.detect_audio_language, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["filters", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "data_source_id", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["url", "file_name", "chunk_size", "chunk_overlap", "skip_embedding_generation", "set_page_as_boundary", "embedding_model", "generate_sparse_vectors", "use_textract", "prepend_filename_to_chunks", "max_items_per_chunk", "parse_pdf_tables_with_ocr", "detect_audio_language", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        filters: typing.Union[MetaOapg.properties.filters, dict, frozendict.frozendict, ],
-        tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
+        url: typing.Union[MetaOapg.properties.url, str, ],
+        file_name: typing.Union[MetaOapg.properties.file_name, None, str, schemas.Unset] = schemas.unset,
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
-        skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
+        skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, bool, schemas.Unset] = schemas.unset,
+        set_page_as_boundary: typing.Union[MetaOapg.properties.set_page_as_boundary, bool, schemas.Unset] = schemas.unset,
         embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
-        generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
-        prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
-        data_source_id: typing.Union[MetaOapg.properties.data_source_id, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, bool, schemas.Unset] = schemas.unset,
+        use_textract: typing.Union[MetaOapg.properties.use_textract, bool, schemas.Unset] = schemas.unset,
+        prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, bool, schemas.Unset] = schemas.unset,
+        max_items_per_chunk: typing.Union[MetaOapg.properties.max_items_per_chunk, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        parse_pdf_tables_with_ocr: typing.Union[MetaOapg.properties.parse_pdf_tables_with_ocr, bool, schemas.Unset] = schemas.unset,
+        detect_audio_language: typing.Union[MetaOapg.properties.detect_audio_language, bool, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'GmailSyncInput':
+    ) -> 'UploadFileFromUrlInput':
         return super().__new__(
             cls,
             *args,
-            filters=filters,
-            tags=tags,
+            url=url,
+            file_name=file_name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
+            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            data_source_id=data_source_id,
+            max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.embedding_generators import EmbeddingGenerators
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/http_validation_error.py` & `carbon_python_sdk-0.2.0/carbon/model/http_validation_error.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/http_validation_error.pyi` & `carbon_python_sdk-0.2.0/carbon/model/http_validation_error.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/hybrid_search_tuning_params.py` & `carbon_python_sdk-0.2.0/carbon/model/hybrid_search_tuning_params.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/hybrid_search_tuning_params.pyi` & `carbon_python_sdk-0.2.0/carbon/model/hybrid_search_tuning_params.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/hybrid_search_tuning_params_nullable.py` & `carbon_python_sdk-0.2.0/carbon/model/hybrid_search_tuning_params_nullable.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/hybrid_search_tuning_params_nullable.pyi` & `carbon_python_sdk-0.2.0/carbon/model/hybrid_search_tuning_params_nullable.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/list_data_source_items_request.py` & `carbon_python_sdk-0.2.0/carbon/model/s3_get_file_input.py`

 * *Files 14% similar despite different names*

```diff
@@ -19,107 +19,106 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class ListDataSourceItemsRequest(
+class S3GetFileInput(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
-        required = {
-            "data_source_id",
-        }
         
         class properties:
-            data_source_id = schemas.IntSchema
             
             
-            class parent_id(
+            class id(
                 schemas.StrBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneStrMixin
             ):
             
             
                 def __new__(
                     cls,
                     *args: typing.Union[None, str, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'parent_id':
+                ) -> 'id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class bucket(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'bucket':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
-        
-            @staticmethod
-            def pagination() -> typing.Type['Pagination']:
-                return Pagination
             __annotations__ = {
-                "data_source_id": data_source_id,
-                "parent_id": parent_id,
-                "pagination": pagination,
+                "id": id,
+                "bucket": bucket,
             }
     
-    data_source_id: MetaOapg.properties.data_source_id
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
-    
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["parent_id"]) -> MetaOapg.properties.parent_id: ...
+    def __getitem__(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["pagination"]) -> 'Pagination': ...
+    def __getitem__(self, name: typing_extensions.Literal["bucket"]) -> MetaOapg.properties.bucket: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["data_source_id", "parent_id", "pagination", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "bucket", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> typing.Union[MetaOapg.properties.id, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["parent_id"]) -> typing.Union[MetaOapg.properties.parent_id, schemas.Unset]: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["pagination"]) -> typing.Union['Pagination', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["bucket"]) -> typing.Union[MetaOapg.properties.bucket, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["data_source_id", "parent_id", "pagination", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "bucket", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        data_source_id: typing.Union[MetaOapg.properties.data_source_id, decimal.Decimal, int, ],
-        parent_id: typing.Union[MetaOapg.properties.parent_id, None, str, schemas.Unset] = schemas.unset,
-        pagination: typing.Union['Pagination', schemas.Unset] = schemas.unset,
+        id: typing.Union[MetaOapg.properties.id, None, str, schemas.Unset] = schemas.unset,
+        bucket: typing.Union[MetaOapg.properties.bucket, None, str, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'ListDataSourceItemsRequest':
+    ) -> 'S3GetFileInput':
         return super().__new__(
             cls,
             *args,
-            data_source_id=data_source_id,
-            parent_id=parent_id,
-            pagination=pagination,
+            id=id,
+            bucket=bucket,
             _configuration=_configuration,
             **kwargs,
         )
-
-from carbon.model.pagination import Pagination
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/list_data_source_items_request.pyi` & `carbon_python_sdk-0.2.0/carbon/model/s3_get_file_input.pyi`

 * *Files 14% similar despite different names*

```diff
@@ -19,107 +19,106 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class ListDataSourceItemsRequest(
+class S3GetFileInput(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
-        required = {
-            "data_source_id",
-        }
         
         class properties:
-            data_source_id = schemas.IntSchema
             
             
-            class parent_id(
+            class id(
                 schemas.StrBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneStrMixin
             ):
             
             
                 def __new__(
                     cls,
                     *args: typing.Union[None, str, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'parent_id':
+                ) -> 'id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class bucket(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'bucket':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
-        
-            @staticmethod
-            def pagination() -> typing.Type['Pagination']:
-                return Pagination
             __annotations__ = {
-                "data_source_id": data_source_id,
-                "parent_id": parent_id,
-                "pagination": pagination,
+                "id": id,
+                "bucket": bucket,
             }
     
-    data_source_id: MetaOapg.properties.data_source_id
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
-    
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["parent_id"]) -> MetaOapg.properties.parent_id: ...
+    def __getitem__(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["pagination"]) -> 'Pagination': ...
+    def __getitem__(self, name: typing_extensions.Literal["bucket"]) -> MetaOapg.properties.bucket: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["data_source_id", "parent_id", "pagination", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "bucket", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> typing.Union[MetaOapg.properties.id, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["parent_id"]) -> typing.Union[MetaOapg.properties.parent_id, schemas.Unset]: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["pagination"]) -> typing.Union['Pagination', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["bucket"]) -> typing.Union[MetaOapg.properties.bucket, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["data_source_id", "parent_id", "pagination", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "bucket", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        data_source_id: typing.Union[MetaOapg.properties.data_source_id, decimal.Decimal, int, ],
-        parent_id: typing.Union[MetaOapg.properties.parent_id, None, str, schemas.Unset] = schemas.unset,
-        pagination: typing.Union['Pagination', schemas.Unset] = schemas.unset,
+        id: typing.Union[MetaOapg.properties.id, None, str, schemas.Unset] = schemas.unset,
+        bucket: typing.Union[MetaOapg.properties.bucket, None, str, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'ListDataSourceItemsRequest':
+    ) -> 'S3GetFileInput':
         return super().__new__(
             cls,
             *args,
-            data_source_id=data_source_id,
-            parent_id=parent_id,
-            pagination=pagination,
+            id=id,
+            bucket=bucket,
             _configuration=_configuration,
             **kwargs,
         )
-
-from carbon.model.pagination import Pagination
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/list_data_source_items_response.py` & `carbon_python_sdk-0.2.0/carbon/model/list_data_source_items_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/list_data_source_items_response.pyi` & `carbon_python_sdk-0.2.0/carbon/model/list_data_source_items_response.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/list_request.py` & `carbon_python_sdk-0.2.0/carbon/model/list_request.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/list_request.pyi` & `carbon_python_sdk-0.2.0/carbon/model/list_request.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/list_response.py` & `carbon_python_sdk-0.2.0/carbon/model/list_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/list_response.pyi` & `carbon_python_sdk-0.2.0/carbon/model/list_response.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/modify_user_configuration_input.py` & `carbon_python_sdk-0.2.0/carbon/model/modify_user_configuration_input.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/modify_user_configuration_input.pyi` & `carbon_python_sdk-0.2.0/carbon/model/modify_user_configuration_input.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/notion_authentication.py` & `carbon_python_sdk-0.2.0/carbon/model/notion_authentication.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/notion_authentication.pyi` & `carbon_python_sdk-0.2.0/carbon/model/notion_authentication.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/o_auth_authentication.py` & `carbon_python_sdk-0.2.0/carbon/model/o_auth_authentication.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/o_auth_authentication.pyi` & `carbon_python_sdk-0.2.0/carbon/model/o_auth_authentication.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/o_auth_url_request.py` & `carbon_python_sdk-0.2.0/carbon/model/o_auth_url_request.py`

 * *Files 12% similar despite different names*

```diff
@@ -343,14 +343,62 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'connecting_new_account':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            request_id = schemas.StrSchema
+            
+            
+            class use_ocr(
+                schemas.BoolBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneBoolMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, bool, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'use_ocr':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class parse_pdf_tables_with_ocr(
+                schemas.BoolBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneBoolMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, bool, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'parse_pdf_tables_with_ocr':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            enable_file_picker = schemas.BoolSchema
+            sync_source_items = schemas.BoolSchema
+            incremental_sync = schemas.BoolSchema
+        
+            @staticmethod
+            def file_sync_config() -> typing.Type['FileSyncConfigNullable']:
+                return FileSyncConfigNullable
             __annotations__ = {
                 "service": service,
                 "tags": tags,
                 "scope": scope,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
@@ -363,14 +411,21 @@
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
                 "max_items_per_chunk": max_items_per_chunk,
                 "salesforce_domain": salesforce_domain,
                 "sync_files_on_connection": sync_files_on_connection,
                 "set_page_as_boundary": set_page_as_boundary,
                 "data_source_id": data_source_id,
                 "connecting_new_account": connecting_new_account,
+                "request_id": request_id,
+                "use_ocr": use_ocr,
+                "parse_pdf_tables_with_ocr": parse_pdf_tables_with_ocr,
+                "enable_file_picker": enable_file_picker,
+                "sync_source_items": sync_source_items,
+                "incremental_sync": incremental_sync,
+                "file_sync_config": file_sync_config,
             }
     
     service: 'DataSourceType'
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["service"]) -> 'DataSourceType': ...
     
@@ -425,17 +480,38 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["connecting_new_account"]) -> MetaOapg.properties.connecting_new_account: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["use_ocr"]) -> MetaOapg.properties.use_ocr: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["parse_pdf_tables_with_ocr"]) -> MetaOapg.properties.parse_pdf_tables_with_ocr: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["enable_file_picker"]) -> MetaOapg.properties.enable_file_picker: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["sync_source_items"]) -> MetaOapg.properties.sync_source_items: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["incremental_sync"]) -> MetaOapg.properties.incremental_sync: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["file_sync_config"]) -> 'FileSyncConfigNullable': ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["service", "tags", "scope", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "zendesk_subdomain", "microsoft_tenant", "sharepoint_site_name", "confluence_subdomain", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "salesforce_domain", "sync_files_on_connection", "set_page_as_boundary", "data_source_id", "connecting_new_account", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["service", "tags", "scope", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "zendesk_subdomain", "microsoft_tenant", "sharepoint_site_name", "confluence_subdomain", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "salesforce_domain", "sync_files_on_connection", "set_page_as_boundary", "data_source_id", "connecting_new_account", "request_id", "use_ocr", "parse_pdf_tables_with_ocr", "enable_file_picker", "sync_source_items", "incremental_sync", "file_sync_config", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["service"]) -> 'DataSourceType': ...
     
@@ -490,17 +566,38 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> typing.Union[MetaOapg.properties.data_source_id, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["connecting_new_account"]) -> typing.Union[MetaOapg.properties.connecting_new_account, schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> typing.Union[MetaOapg.properties.request_id, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["use_ocr"]) -> typing.Union[MetaOapg.properties.use_ocr, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["parse_pdf_tables_with_ocr"]) -> typing.Union[MetaOapg.properties.parse_pdf_tables_with_ocr, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["enable_file_picker"]) -> typing.Union[MetaOapg.properties.enable_file_picker, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_source_items"]) -> typing.Union[MetaOapg.properties.sync_source_items, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["incremental_sync"]) -> typing.Union[MetaOapg.properties.incremental_sync, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["file_sync_config"]) -> typing.Union['FileSyncConfigNullable', schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["service", "tags", "scope", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "zendesk_subdomain", "microsoft_tenant", "sharepoint_site_name", "confluence_subdomain", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "salesforce_domain", "sync_files_on_connection", "set_page_as_boundary", "data_source_id", "connecting_new_account", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["service", "tags", "scope", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "zendesk_subdomain", "microsoft_tenant", "sharepoint_site_name", "confluence_subdomain", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "salesforce_domain", "sync_files_on_connection", "set_page_as_boundary", "data_source_id", "connecting_new_account", "request_id", "use_ocr", "parse_pdf_tables_with_ocr", "enable_file_picker", "sync_source_items", "incremental_sync", "file_sync_config", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         service: 'DataSourceType',
@@ -518,14 +615,21 @@
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
         max_items_per_chunk: typing.Union[MetaOapg.properties.max_items_per_chunk, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         salesforce_domain: typing.Union[MetaOapg.properties.salesforce_domain, None, str, schemas.Unset] = schemas.unset,
         sync_files_on_connection: typing.Union[MetaOapg.properties.sync_files_on_connection, None, bool, schemas.Unset] = schemas.unset,
         set_page_as_boundary: typing.Union[MetaOapg.properties.set_page_as_boundary, bool, schemas.Unset] = schemas.unset,
         data_source_id: typing.Union[MetaOapg.properties.data_source_id, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         connecting_new_account: typing.Union[MetaOapg.properties.connecting_new_account, None, bool, schemas.Unset] = schemas.unset,
+        request_id: typing.Union[MetaOapg.properties.request_id, str, schemas.Unset] = schemas.unset,
+        use_ocr: typing.Union[MetaOapg.properties.use_ocr, None, bool, schemas.Unset] = schemas.unset,
+        parse_pdf_tables_with_ocr: typing.Union[MetaOapg.properties.parse_pdf_tables_with_ocr, None, bool, schemas.Unset] = schemas.unset,
+        enable_file_picker: typing.Union[MetaOapg.properties.enable_file_picker, bool, schemas.Unset] = schemas.unset,
+        sync_source_items: typing.Union[MetaOapg.properties.sync_source_items, bool, schemas.Unset] = schemas.unset,
+        incremental_sync: typing.Union[MetaOapg.properties.incremental_sync, bool, schemas.Unset] = schemas.unset,
+        file_sync_config: typing.Union['FileSyncConfigNullable', schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
     ) -> 'OAuthURLRequest':
         return super().__new__(
             cls,
             *args,
             service=service,
@@ -543,13 +647,21 @@
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
             salesforce_domain=salesforce_domain,
             sync_files_on_connection=sync_files_on_connection,
             set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
             connecting_new_account=connecting_new_account,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            enable_file_picker=enable_file_picker,
+            sync_source_items=sync_source_items,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.data_source_type import DataSourceType
 from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/o_auth_url_request.pyi` & `carbon_python_sdk-0.2.0/carbon/model/o_auth_url_request.pyi`

 * *Files 12% similar despite different names*

```diff
@@ -343,14 +343,62 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'connecting_new_account':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            request_id = schemas.StrSchema
+            
+            
+            class use_ocr(
+                schemas.BoolBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneBoolMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, bool, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'use_ocr':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class parse_pdf_tables_with_ocr(
+                schemas.BoolBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneBoolMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, bool, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'parse_pdf_tables_with_ocr':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            enable_file_picker = schemas.BoolSchema
+            sync_source_items = schemas.BoolSchema
+            incremental_sync = schemas.BoolSchema
+        
+            @staticmethod
+            def file_sync_config() -> typing.Type['FileSyncConfigNullable']:
+                return FileSyncConfigNullable
             __annotations__ = {
                 "service": service,
                 "tags": tags,
                 "scope": scope,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
@@ -363,14 +411,21 @@
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
                 "max_items_per_chunk": max_items_per_chunk,
                 "salesforce_domain": salesforce_domain,
                 "sync_files_on_connection": sync_files_on_connection,
                 "set_page_as_boundary": set_page_as_boundary,
                 "data_source_id": data_source_id,
                 "connecting_new_account": connecting_new_account,
+                "request_id": request_id,
+                "use_ocr": use_ocr,
+                "parse_pdf_tables_with_ocr": parse_pdf_tables_with_ocr,
+                "enable_file_picker": enable_file_picker,
+                "sync_source_items": sync_source_items,
+                "incremental_sync": incremental_sync,
+                "file_sync_config": file_sync_config,
             }
     
     service: 'DataSourceType'
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["service"]) -> 'DataSourceType': ...
     
@@ -425,17 +480,38 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["connecting_new_account"]) -> MetaOapg.properties.connecting_new_account: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["use_ocr"]) -> MetaOapg.properties.use_ocr: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["parse_pdf_tables_with_ocr"]) -> MetaOapg.properties.parse_pdf_tables_with_ocr: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["enable_file_picker"]) -> MetaOapg.properties.enable_file_picker: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["sync_source_items"]) -> MetaOapg.properties.sync_source_items: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["incremental_sync"]) -> MetaOapg.properties.incremental_sync: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["file_sync_config"]) -> 'FileSyncConfigNullable': ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["service", "tags", "scope", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "zendesk_subdomain", "microsoft_tenant", "sharepoint_site_name", "confluence_subdomain", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "salesforce_domain", "sync_files_on_connection", "set_page_as_boundary", "data_source_id", "connecting_new_account", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["service", "tags", "scope", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "zendesk_subdomain", "microsoft_tenant", "sharepoint_site_name", "confluence_subdomain", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "salesforce_domain", "sync_files_on_connection", "set_page_as_boundary", "data_source_id", "connecting_new_account", "request_id", "use_ocr", "parse_pdf_tables_with_ocr", "enable_file_picker", "sync_source_items", "incremental_sync", "file_sync_config", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["service"]) -> 'DataSourceType': ...
     
@@ -490,17 +566,38 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> typing.Union[MetaOapg.properties.data_source_id, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["connecting_new_account"]) -> typing.Union[MetaOapg.properties.connecting_new_account, schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> typing.Union[MetaOapg.properties.request_id, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["use_ocr"]) -> typing.Union[MetaOapg.properties.use_ocr, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["parse_pdf_tables_with_ocr"]) -> typing.Union[MetaOapg.properties.parse_pdf_tables_with_ocr, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["enable_file_picker"]) -> typing.Union[MetaOapg.properties.enable_file_picker, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_source_items"]) -> typing.Union[MetaOapg.properties.sync_source_items, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["incremental_sync"]) -> typing.Union[MetaOapg.properties.incremental_sync, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["file_sync_config"]) -> typing.Union['FileSyncConfigNullable', schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["service", "tags", "scope", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "zendesk_subdomain", "microsoft_tenant", "sharepoint_site_name", "confluence_subdomain", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "salesforce_domain", "sync_files_on_connection", "set_page_as_boundary", "data_source_id", "connecting_new_account", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["service", "tags", "scope", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "zendesk_subdomain", "microsoft_tenant", "sharepoint_site_name", "confluence_subdomain", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "salesforce_domain", "sync_files_on_connection", "set_page_as_boundary", "data_source_id", "connecting_new_account", "request_id", "use_ocr", "parse_pdf_tables_with_ocr", "enable_file_picker", "sync_source_items", "incremental_sync", "file_sync_config", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         service: 'DataSourceType',
@@ -518,14 +615,21 @@
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
         max_items_per_chunk: typing.Union[MetaOapg.properties.max_items_per_chunk, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         salesforce_domain: typing.Union[MetaOapg.properties.salesforce_domain, None, str, schemas.Unset] = schemas.unset,
         sync_files_on_connection: typing.Union[MetaOapg.properties.sync_files_on_connection, None, bool, schemas.Unset] = schemas.unset,
         set_page_as_boundary: typing.Union[MetaOapg.properties.set_page_as_boundary, bool, schemas.Unset] = schemas.unset,
         data_source_id: typing.Union[MetaOapg.properties.data_source_id, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         connecting_new_account: typing.Union[MetaOapg.properties.connecting_new_account, None, bool, schemas.Unset] = schemas.unset,
+        request_id: typing.Union[MetaOapg.properties.request_id, str, schemas.Unset] = schemas.unset,
+        use_ocr: typing.Union[MetaOapg.properties.use_ocr, None, bool, schemas.Unset] = schemas.unset,
+        parse_pdf_tables_with_ocr: typing.Union[MetaOapg.properties.parse_pdf_tables_with_ocr, None, bool, schemas.Unset] = schemas.unset,
+        enable_file_picker: typing.Union[MetaOapg.properties.enable_file_picker, bool, schemas.Unset] = schemas.unset,
+        sync_source_items: typing.Union[MetaOapg.properties.sync_source_items, bool, schemas.Unset] = schemas.unset,
+        incremental_sync: typing.Union[MetaOapg.properties.incremental_sync, bool, schemas.Unset] = schemas.unset,
+        file_sync_config: typing.Union['FileSyncConfigNullable', schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
     ) -> 'OAuthURLRequest':
         return super().__new__(
             cls,
             *args,
             service=service,
@@ -543,13 +647,21 @@
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
             salesforce_domain=salesforce_domain,
             sync_files_on_connection=sync_files_on_connection,
             set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
             connecting_new_account=connecting_new_account,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            enable_file_picker=enable_file_picker,
+            sync_source_items=sync_source_items,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.data_source_type import DataSourceType
 from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/order_dir.py` & `carbon_python_sdk-0.2.0/carbon/model/order_dir.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/order_dir.pyi` & `carbon_python_sdk-0.2.0/carbon/model/order_dir.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_response.py` & `carbon_python_sdk-0.2.0/carbon/model/organization_response.py`

 * *Files 15% similar despite different names*

```diff
@@ -31,26 +31,30 @@
     """
 
 
     class MetaOapg:
         required = {
             "aggregate_file_size",
             "aggregate_num_characters",
+            "aggregate_num_files_by_file_format",
             "cancel_at_period_end",
             "custom_limits",
             "created_at",
             "custom_branding",
+            "global_user_config",
             "updated_at",
             "aggregate_num_embeddings",
+            "aggregate_num_files_by_source",
             "name",
             "nickname",
             "remove_branding",
             "id",
             "period_ends_at",
             "aggregate_num_tokens",
+            "file_statistics_aggregated_at",
         }
         
         class properties:
             id = schemas.IntSchema
             name = schemas.StrSchema
             
             
@@ -117,14 +121,41 @@
                         _configuration=_configuration,
                         **kwargs,
                     )
             aggregate_file_size = schemas.DictSchema
             aggregate_num_characters = schemas.DictSchema
             aggregate_num_tokens = schemas.DictSchema
             aggregate_num_embeddings = schemas.DictSchema
+            aggregate_num_files_by_source = schemas.DictSchema
+            aggregate_num_files_by_file_format = schemas.DictSchema
+            
+            
+            class file_statistics_aggregated_at(
+                schemas.DateTimeBase,
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                class MetaOapg:
+                    format = 'date-time'
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, datetime, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'file_statistics_aggregated_at':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             
             
             class period_ends_at(
                 schemas.DateTimeBase,
                 schemas.StrBase,
                 schemas.NoneBase,
                 schemas.Schema,
@@ -162,47 +193,56 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'cancel_at_period_end':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            global_user_config = schemas.DictSchema
             created_at = schemas.DateTimeSchema
             updated_at = schemas.DateTimeSchema
             __annotations__ = {
                 "id": id,
                 "name": name,
                 "nickname": nickname,
                 "remove_branding": remove_branding,
                 "custom_branding": custom_branding,
                 "custom_limits": custom_limits,
                 "aggregate_file_size": aggregate_file_size,
                 "aggregate_num_characters": aggregate_num_characters,
                 "aggregate_num_tokens": aggregate_num_tokens,
                 "aggregate_num_embeddings": aggregate_num_embeddings,
+                "aggregate_num_files_by_source": aggregate_num_files_by_source,
+                "aggregate_num_files_by_file_format": aggregate_num_files_by_file_format,
+                "file_statistics_aggregated_at": file_statistics_aggregated_at,
                 "period_ends_at": period_ends_at,
                 "cancel_at_period_end": cancel_at_period_end,
+                "global_user_config": global_user_config,
                 "created_at": created_at,
                 "updated_at": updated_at,
             }
     
     aggregate_file_size: MetaOapg.properties.aggregate_file_size
     aggregate_num_characters: MetaOapg.properties.aggregate_num_characters
+    aggregate_num_files_by_file_format: MetaOapg.properties.aggregate_num_files_by_file_format
     cancel_at_period_end: MetaOapg.properties.cancel_at_period_end
     custom_limits: MetaOapg.properties.custom_limits
     created_at: MetaOapg.properties.created_at
     custom_branding: MetaOapg.properties.custom_branding
+    global_user_config: MetaOapg.properties.global_user_config
     updated_at: MetaOapg.properties.updated_at
     aggregate_num_embeddings: MetaOapg.properties.aggregate_num_embeddings
+    aggregate_num_files_by_source: MetaOapg.properties.aggregate_num_files_by_source
     name: MetaOapg.properties.name
     nickname: MetaOapg.properties.nickname
     remove_branding: MetaOapg.properties.remove_branding
     id: MetaOapg.properties.id
     period_ends_at: MetaOapg.properties.period_ends_at
     aggregate_num_tokens: MetaOapg.properties.aggregate_num_tokens
+    file_statistics_aggregated_at: MetaOapg.properties.file_statistics_aggregated_at
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["name"]) -> MetaOapg.properties.name: ...
     
@@ -227,29 +267,41 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["aggregate_num_tokens"]) -> MetaOapg.properties.aggregate_num_tokens: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["aggregate_num_embeddings"]) -> MetaOapg.properties.aggregate_num_embeddings: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["aggregate_num_files_by_source"]) -> MetaOapg.properties.aggregate_num_files_by_source: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["aggregate_num_files_by_file_format"]) -> MetaOapg.properties.aggregate_num_files_by_file_format: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["file_statistics_aggregated_at"]) -> MetaOapg.properties.file_statistics_aggregated_at: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["period_ends_at"]) -> MetaOapg.properties.period_ends_at: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["cancel_at_period_end"]) -> MetaOapg.properties.cancel_at_period_end: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["global_user_config"]) -> MetaOapg.properties.global_user_config: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "name", "nickname", "remove_branding", "custom_branding", "custom_limits", "aggregate_file_size", "aggregate_num_characters", "aggregate_num_tokens", "aggregate_num_embeddings", "period_ends_at", "cancel_at_period_end", "created_at", "updated_at", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "name", "nickname", "remove_branding", "custom_branding", "custom_limits", "aggregate_file_size", "aggregate_num_characters", "aggregate_num_tokens", "aggregate_num_embeddings", "aggregate_num_files_by_source", "aggregate_num_files_by_file_format", "file_statistics_aggregated_at", "period_ends_at", "cancel_at_period_end", "global_user_config", "created_at", "updated_at", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
     
@@ -277,65 +329,85 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["aggregate_num_tokens"]) -> MetaOapg.properties.aggregate_num_tokens: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["aggregate_num_embeddings"]) -> MetaOapg.properties.aggregate_num_embeddings: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["aggregate_num_files_by_source"]) -> MetaOapg.properties.aggregate_num_files_by_source: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["aggregate_num_files_by_file_format"]) -> MetaOapg.properties.aggregate_num_files_by_file_format: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["file_statistics_aggregated_at"]) -> MetaOapg.properties.file_statistics_aggregated_at: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["period_ends_at"]) -> MetaOapg.properties.period_ends_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["cancel_at_period_end"]) -> MetaOapg.properties.cancel_at_period_end: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["global_user_config"]) -> MetaOapg.properties.global_user_config: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "name", "nickname", "remove_branding", "custom_branding", "custom_limits", "aggregate_file_size", "aggregate_num_characters", "aggregate_num_tokens", "aggregate_num_embeddings", "period_ends_at", "cancel_at_period_end", "created_at", "updated_at", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "name", "nickname", "remove_branding", "custom_branding", "custom_limits", "aggregate_file_size", "aggregate_num_characters", "aggregate_num_tokens", "aggregate_num_embeddings", "aggregate_num_files_by_source", "aggregate_num_files_by_file_format", "file_statistics_aggregated_at", "period_ends_at", "cancel_at_period_end", "global_user_config", "created_at", "updated_at", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         aggregate_file_size: typing.Union[MetaOapg.properties.aggregate_file_size, dict, frozendict.frozendict, ],
         aggregate_num_characters: typing.Union[MetaOapg.properties.aggregate_num_characters, dict, frozendict.frozendict, ],
+        aggregate_num_files_by_file_format: typing.Union[MetaOapg.properties.aggregate_num_files_by_file_format, dict, frozendict.frozendict, ],
         cancel_at_period_end: typing.Union[MetaOapg.properties.cancel_at_period_end, None, bool, ],
         custom_limits: typing.Union[MetaOapg.properties.custom_limits, dict, frozendict.frozendict, None, ],
         created_at: typing.Union[MetaOapg.properties.created_at, str, datetime, ],
         custom_branding: typing.Union[MetaOapg.properties.custom_branding, dict, frozendict.frozendict, None, ],
+        global_user_config: typing.Union[MetaOapg.properties.global_user_config, dict, frozendict.frozendict, ],
         updated_at: typing.Union[MetaOapg.properties.updated_at, str, datetime, ],
         aggregate_num_embeddings: typing.Union[MetaOapg.properties.aggregate_num_embeddings, dict, frozendict.frozendict, ],
+        aggregate_num_files_by_source: typing.Union[MetaOapg.properties.aggregate_num_files_by_source, dict, frozendict.frozendict, ],
         name: typing.Union[MetaOapg.properties.name, str, ],
         nickname: typing.Union[MetaOapg.properties.nickname, None, str, ],
         remove_branding: typing.Union[MetaOapg.properties.remove_branding, bool, ],
         id: typing.Union[MetaOapg.properties.id, decimal.Decimal, int, ],
         period_ends_at: typing.Union[MetaOapg.properties.period_ends_at, None, str, datetime, ],
         aggregate_num_tokens: typing.Union[MetaOapg.properties.aggregate_num_tokens, dict, frozendict.frozendict, ],
+        file_statistics_aggregated_at: typing.Union[MetaOapg.properties.file_statistics_aggregated_at, None, str, datetime, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
     ) -> 'OrganizationResponse':
         return super().__new__(
             cls,
             *args,
             aggregate_file_size=aggregate_file_size,
             aggregate_num_characters=aggregate_num_characters,
+            aggregate_num_files_by_file_format=aggregate_num_files_by_file_format,
             cancel_at_period_end=cancel_at_period_end,
             custom_limits=custom_limits,
             created_at=created_at,
             custom_branding=custom_branding,
+            global_user_config=global_user_config,
             updated_at=updated_at,
             aggregate_num_embeddings=aggregate_num_embeddings,
+            aggregate_num_files_by_source=aggregate_num_files_by_source,
             name=name,
             nickname=nickname,
             remove_branding=remove_branding,
             id=id,
             period_ends_at=period_ends_at,
             aggregate_num_tokens=aggregate_num_tokens,
+            file_statistics_aggregated_at=file_statistics_aggregated_at,
             _configuration=_configuration,
             **kwargs,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_response.pyi` & `carbon_python_sdk-0.2.0/carbon/model/organization_response.pyi`

 * *Files 15% similar despite different names*

```diff
@@ -31,26 +31,30 @@
     """
 
 
     class MetaOapg:
         required = {
             "aggregate_file_size",
             "aggregate_num_characters",
+            "aggregate_num_files_by_file_format",
             "cancel_at_period_end",
             "custom_limits",
             "created_at",
             "custom_branding",
+            "global_user_config",
             "updated_at",
             "aggregate_num_embeddings",
+            "aggregate_num_files_by_source",
             "name",
             "nickname",
             "remove_branding",
             "id",
             "period_ends_at",
             "aggregate_num_tokens",
+            "file_statistics_aggregated_at",
         }
         
         class properties:
             id = schemas.IntSchema
             name = schemas.StrSchema
             
             
@@ -117,14 +121,41 @@
                         _configuration=_configuration,
                         **kwargs,
                     )
             aggregate_file_size = schemas.DictSchema
             aggregate_num_characters = schemas.DictSchema
             aggregate_num_tokens = schemas.DictSchema
             aggregate_num_embeddings = schemas.DictSchema
+            aggregate_num_files_by_source = schemas.DictSchema
+            aggregate_num_files_by_file_format = schemas.DictSchema
+            
+            
+            class file_statistics_aggregated_at(
+                schemas.DateTimeBase,
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                class MetaOapg:
+                    format = 'date-time'
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, datetime, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'file_statistics_aggregated_at':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             
             
             class period_ends_at(
                 schemas.DateTimeBase,
                 schemas.StrBase,
                 schemas.NoneBase,
                 schemas.Schema,
@@ -162,47 +193,56 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'cancel_at_period_end':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            global_user_config = schemas.DictSchema
             created_at = schemas.DateTimeSchema
             updated_at = schemas.DateTimeSchema
             __annotations__ = {
                 "id": id,
                 "name": name,
                 "nickname": nickname,
                 "remove_branding": remove_branding,
                 "custom_branding": custom_branding,
                 "custom_limits": custom_limits,
                 "aggregate_file_size": aggregate_file_size,
                 "aggregate_num_characters": aggregate_num_characters,
                 "aggregate_num_tokens": aggregate_num_tokens,
                 "aggregate_num_embeddings": aggregate_num_embeddings,
+                "aggregate_num_files_by_source": aggregate_num_files_by_source,
+                "aggregate_num_files_by_file_format": aggregate_num_files_by_file_format,
+                "file_statistics_aggregated_at": file_statistics_aggregated_at,
                 "period_ends_at": period_ends_at,
                 "cancel_at_period_end": cancel_at_period_end,
+                "global_user_config": global_user_config,
                 "created_at": created_at,
                 "updated_at": updated_at,
             }
     
     aggregate_file_size: MetaOapg.properties.aggregate_file_size
     aggregate_num_characters: MetaOapg.properties.aggregate_num_characters
+    aggregate_num_files_by_file_format: MetaOapg.properties.aggregate_num_files_by_file_format
     cancel_at_period_end: MetaOapg.properties.cancel_at_period_end
     custom_limits: MetaOapg.properties.custom_limits
     created_at: MetaOapg.properties.created_at
     custom_branding: MetaOapg.properties.custom_branding
+    global_user_config: MetaOapg.properties.global_user_config
     updated_at: MetaOapg.properties.updated_at
     aggregate_num_embeddings: MetaOapg.properties.aggregate_num_embeddings
+    aggregate_num_files_by_source: MetaOapg.properties.aggregate_num_files_by_source
     name: MetaOapg.properties.name
     nickname: MetaOapg.properties.nickname
     remove_branding: MetaOapg.properties.remove_branding
     id: MetaOapg.properties.id
     period_ends_at: MetaOapg.properties.period_ends_at
     aggregate_num_tokens: MetaOapg.properties.aggregate_num_tokens
+    file_statistics_aggregated_at: MetaOapg.properties.file_statistics_aggregated_at
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["name"]) -> MetaOapg.properties.name: ...
     
@@ -227,29 +267,41 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["aggregate_num_tokens"]) -> MetaOapg.properties.aggregate_num_tokens: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["aggregate_num_embeddings"]) -> MetaOapg.properties.aggregate_num_embeddings: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["aggregate_num_files_by_source"]) -> MetaOapg.properties.aggregate_num_files_by_source: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["aggregate_num_files_by_file_format"]) -> MetaOapg.properties.aggregate_num_files_by_file_format: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["file_statistics_aggregated_at"]) -> MetaOapg.properties.file_statistics_aggregated_at: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["period_ends_at"]) -> MetaOapg.properties.period_ends_at: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["cancel_at_period_end"]) -> MetaOapg.properties.cancel_at_period_end: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["global_user_config"]) -> MetaOapg.properties.global_user_config: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "name", "nickname", "remove_branding", "custom_branding", "custom_limits", "aggregate_file_size", "aggregate_num_characters", "aggregate_num_tokens", "aggregate_num_embeddings", "period_ends_at", "cancel_at_period_end", "created_at", "updated_at", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "name", "nickname", "remove_branding", "custom_branding", "custom_limits", "aggregate_file_size", "aggregate_num_characters", "aggregate_num_tokens", "aggregate_num_embeddings", "aggregate_num_files_by_source", "aggregate_num_files_by_file_format", "file_statistics_aggregated_at", "period_ends_at", "cancel_at_period_end", "global_user_config", "created_at", "updated_at", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
     
@@ -277,65 +329,85 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["aggregate_num_tokens"]) -> MetaOapg.properties.aggregate_num_tokens: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["aggregate_num_embeddings"]) -> MetaOapg.properties.aggregate_num_embeddings: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["aggregate_num_files_by_source"]) -> MetaOapg.properties.aggregate_num_files_by_source: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["aggregate_num_files_by_file_format"]) -> MetaOapg.properties.aggregate_num_files_by_file_format: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["file_statistics_aggregated_at"]) -> MetaOapg.properties.file_statistics_aggregated_at: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["period_ends_at"]) -> MetaOapg.properties.period_ends_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["cancel_at_period_end"]) -> MetaOapg.properties.cancel_at_period_end: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["global_user_config"]) -> MetaOapg.properties.global_user_config: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "name", "nickname", "remove_branding", "custom_branding", "custom_limits", "aggregate_file_size", "aggregate_num_characters", "aggregate_num_tokens", "aggregate_num_embeddings", "period_ends_at", "cancel_at_period_end", "created_at", "updated_at", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "name", "nickname", "remove_branding", "custom_branding", "custom_limits", "aggregate_file_size", "aggregate_num_characters", "aggregate_num_tokens", "aggregate_num_embeddings", "aggregate_num_files_by_source", "aggregate_num_files_by_file_format", "file_statistics_aggregated_at", "period_ends_at", "cancel_at_period_end", "global_user_config", "created_at", "updated_at", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         aggregate_file_size: typing.Union[MetaOapg.properties.aggregate_file_size, dict, frozendict.frozendict, ],
         aggregate_num_characters: typing.Union[MetaOapg.properties.aggregate_num_characters, dict, frozendict.frozendict, ],
+        aggregate_num_files_by_file_format: typing.Union[MetaOapg.properties.aggregate_num_files_by_file_format, dict, frozendict.frozendict, ],
         cancel_at_period_end: typing.Union[MetaOapg.properties.cancel_at_period_end, None, bool, ],
         custom_limits: typing.Union[MetaOapg.properties.custom_limits, dict, frozendict.frozendict, None, ],
         created_at: typing.Union[MetaOapg.properties.created_at, str, datetime, ],
         custom_branding: typing.Union[MetaOapg.properties.custom_branding, dict, frozendict.frozendict, None, ],
+        global_user_config: typing.Union[MetaOapg.properties.global_user_config, dict, frozendict.frozendict, ],
         updated_at: typing.Union[MetaOapg.properties.updated_at, str, datetime, ],
         aggregate_num_embeddings: typing.Union[MetaOapg.properties.aggregate_num_embeddings, dict, frozendict.frozendict, ],
+        aggregate_num_files_by_source: typing.Union[MetaOapg.properties.aggregate_num_files_by_source, dict, frozendict.frozendict, ],
         name: typing.Union[MetaOapg.properties.name, str, ],
         nickname: typing.Union[MetaOapg.properties.nickname, None, str, ],
         remove_branding: typing.Union[MetaOapg.properties.remove_branding, bool, ],
         id: typing.Union[MetaOapg.properties.id, decimal.Decimal, int, ],
         period_ends_at: typing.Union[MetaOapg.properties.period_ends_at, None, str, datetime, ],
         aggregate_num_tokens: typing.Union[MetaOapg.properties.aggregate_num_tokens, dict, frozendict.frozendict, ],
+        file_statistics_aggregated_at: typing.Union[MetaOapg.properties.file_statistics_aggregated_at, None, str, datetime, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
     ) -> 'OrganizationResponse':
         return super().__new__(
             cls,
             *args,
             aggregate_file_size=aggregate_file_size,
             aggregate_num_characters=aggregate_num_characters,
+            aggregate_num_files_by_file_format=aggregate_num_files_by_file_format,
             cancel_at_period_end=cancel_at_period_end,
             custom_limits=custom_limits,
             created_at=created_at,
             custom_branding=custom_branding,
+            global_user_config=global_user_config,
             updated_at=updated_at,
             aggregate_num_embeddings=aggregate_num_embeddings,
+            aggregate_num_files_by_source=aggregate_num_files_by_source,
             name=name,
             nickname=nickname,
             remove_branding=remove_branding,
             id=id,
             period_ends_at=period_ends_at,
             aggregate_num_tokens=aggregate_num_tokens,
+            file_statistics_aggregated_at=file_statistics_aggregated_at,
             _configuration=_configuration,
             **kwargs,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_api.py` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_api.py`

 * *Files 14% similar despite different names*

```diff
@@ -33,18 +33,21 @@
 
     class MetaOapg:
         required = {
             "last_synced_at",
             "revoked_access",
             "created_at",
             "data_source_type",
+            "data_source_metadata",
             "organization_supplied_user_id",
             "token",
             "updated_at",
+            "files_synced_at",
             "source_items_synced_at",
+            "enable_auto_sync",
             "organization_id",
             "organization_user_id",
             "last_sync_action",
             "sync_status",
             "id",
             "data_source_external_id",
         }
@@ -131,41 +134,93 @@
             organization_supplied_user_id = schemas.StrSchema
             revoked_access = schemas.BoolSchema
             last_synced_at = schemas.DateTimeSchema
         
             @staticmethod
             def last_sync_action() -> typing.Type['DataSourceLastSyncActions']:
                 return DataSourceLastSyncActions
+            
+            
+            class enable_auto_sync(
+                schemas.BoolBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneBoolMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, bool, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'enable_auto_sync':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             created_at = schemas.DateTimeSchema
             updated_at = schemas.DateTimeSchema
+            
+            
+            class files_synced_at(
+                schemas.DateTimeBase,
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                class MetaOapg:
+                    format = 'date-time'
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, datetime, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'files_synced_at':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            data_source_metadata = schemas.DictSchema
             __annotations__ = {
                 "id": id,
                 "data_source_external_id": data_source_external_id,
                 "data_source_type": data_source_type,
                 "token": token,
                 "sync_status": sync_status,
                 "source_items_synced_at": source_items_synced_at,
                 "organization_user_id": organization_user_id,
                 "organization_id": organization_id,
                 "organization_supplied_user_id": organization_supplied_user_id,
                 "revoked_access": revoked_access,
                 "last_synced_at": last_synced_at,
                 "last_sync_action": last_sync_action,
+                "enable_auto_sync": enable_auto_sync,
                 "created_at": created_at,
                 "updated_at": updated_at,
+                "files_synced_at": files_synced_at,
+                "data_source_metadata": data_source_metadata,
             }
     
     last_synced_at: MetaOapg.properties.last_synced_at
     revoked_access: MetaOapg.properties.revoked_access
     created_at: MetaOapg.properties.created_at
     data_source_type: 'DataSourceType'
+    data_source_metadata: MetaOapg.properties.data_source_metadata
     organization_supplied_user_id: MetaOapg.properties.organization_supplied_user_id
     token: MetaOapg.properties.token
     updated_at: MetaOapg.properties.updated_at
+    files_synced_at: MetaOapg.properties.files_synced_at
     source_items_synced_at: MetaOapg.properties.source_items_synced_at
+    enable_auto_sync: MetaOapg.properties.enable_auto_sync
     organization_id: MetaOapg.properties.organization_id
     organization_user_id: MetaOapg.properties.organization_user_id
     last_sync_action: 'DataSourceLastSyncActions'
     sync_status: 'DataSourceSyncStatuses'
     id: MetaOapg.properties.id
     data_source_external_id: MetaOapg.properties.data_source_external_id
     
@@ -202,23 +257,32 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["last_synced_at"]) -> MetaOapg.properties.last_synced_at: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["last_sync_action"]) -> 'DataSourceLastSyncActions': ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["enable_auto_sync"]) -> MetaOapg.properties.enable_auto_sync: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["files_synced_at"]) -> MetaOapg.properties.files_synced_at: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["data_source_metadata"]) -> MetaOapg.properties.data_source_metadata: ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "data_source_external_id", "data_source_type", "token", "sync_status", "source_items_synced_at", "organization_user_id", "organization_id", "organization_supplied_user_id", "revoked_access", "last_synced_at", "last_sync_action", "created_at", "updated_at", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "data_source_external_id", "data_source_type", "token", "sync_status", "source_items_synced_at", "organization_user_id", "organization_id", "organization_supplied_user_id", "revoked_access", "last_synced_at", "last_sync_action", "enable_auto_sync", "created_at", "updated_at", "files_synced_at", "data_source_metadata", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
     
@@ -252,37 +316,49 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["last_synced_at"]) -> MetaOapg.properties.last_synced_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["last_sync_action"]) -> 'DataSourceLastSyncActions': ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["enable_auto_sync"]) -> MetaOapg.properties.enable_auto_sync: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["files_synced_at"]) -> MetaOapg.properties.files_synced_at: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["data_source_metadata"]) -> MetaOapg.properties.data_source_metadata: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "data_source_external_id", "data_source_type", "token", "sync_status", "source_items_synced_at", "organization_user_id", "organization_id", "organization_supplied_user_id", "revoked_access", "last_synced_at", "last_sync_action", "created_at", "updated_at", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "data_source_external_id", "data_source_type", "token", "sync_status", "source_items_synced_at", "organization_user_id", "organization_id", "organization_supplied_user_id", "revoked_access", "last_synced_at", "last_sync_action", "enable_auto_sync", "created_at", "updated_at", "files_synced_at", "data_source_metadata", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         last_synced_at: typing.Union[MetaOapg.properties.last_synced_at, str, datetime, ],
         revoked_access: typing.Union[MetaOapg.properties.revoked_access, bool, ],
         created_at: typing.Union[MetaOapg.properties.created_at, str, datetime, ],
         data_source_type: 'DataSourceType',
+        data_source_metadata: typing.Union[MetaOapg.properties.data_source_metadata, dict, frozendict.frozendict, ],
         organization_supplied_user_id: typing.Union[MetaOapg.properties.organization_supplied_user_id, str, ],
         token: typing.Union[MetaOapg.properties.token, dict, frozendict.frozendict, None, ],
         updated_at: typing.Union[MetaOapg.properties.updated_at, str, datetime, ],
+        files_synced_at: typing.Union[MetaOapg.properties.files_synced_at, None, str, datetime, ],
         source_items_synced_at: typing.Union[MetaOapg.properties.source_items_synced_at, None, str, datetime, ],
+        enable_auto_sync: typing.Union[MetaOapg.properties.enable_auto_sync, None, bool, ],
         organization_id: typing.Union[MetaOapg.properties.organization_id, decimal.Decimal, int, ],
         organization_user_id: typing.Union[MetaOapg.properties.organization_user_id, decimal.Decimal, int, ],
         last_sync_action: 'DataSourceLastSyncActions',
         sync_status: 'DataSourceSyncStatuses',
         id: typing.Union[MetaOapg.properties.id, decimal.Decimal, int, ],
         data_source_external_id: typing.Union[MetaOapg.properties.data_source_external_id, None, str, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
@@ -291,18 +367,21 @@
         return super().__new__(
             cls,
             *args,
             last_synced_at=last_synced_at,
             revoked_access=revoked_access,
             created_at=created_at,
             data_source_type=data_source_type,
+            data_source_metadata=data_source_metadata,
             organization_supplied_user_id=organization_supplied_user_id,
             token=token,
             updated_at=updated_at,
+            files_synced_at=files_synced_at,
             source_items_synced_at=source_items_synced_at,
+            enable_auto_sync=enable_auto_sync,
             organization_id=organization_id,
             organization_user_id=organization_user_id,
             last_sync_action=last_sync_action,
             sync_status=sync_status,
             id=id,
             data_source_external_id=data_source_external_id,
             _configuration=_configuration,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_api.pyi` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_api.pyi`

 * *Files 14% similar despite different names*

```diff
@@ -33,18 +33,21 @@
 
     class MetaOapg:
         required = {
             "last_synced_at",
             "revoked_access",
             "created_at",
             "data_source_type",
+            "data_source_metadata",
             "organization_supplied_user_id",
             "token",
             "updated_at",
+            "files_synced_at",
             "source_items_synced_at",
+            "enable_auto_sync",
             "organization_id",
             "organization_user_id",
             "last_sync_action",
             "sync_status",
             "id",
             "data_source_external_id",
         }
@@ -131,41 +134,93 @@
             organization_supplied_user_id = schemas.StrSchema
             revoked_access = schemas.BoolSchema
             last_synced_at = schemas.DateTimeSchema
         
             @staticmethod
             def last_sync_action() -> typing.Type['DataSourceLastSyncActions']:
                 return DataSourceLastSyncActions
+            
+            
+            class enable_auto_sync(
+                schemas.BoolBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneBoolMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, bool, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'enable_auto_sync':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             created_at = schemas.DateTimeSchema
             updated_at = schemas.DateTimeSchema
+            
+            
+            class files_synced_at(
+                schemas.DateTimeBase,
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                class MetaOapg:
+                    format = 'date-time'
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, datetime, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'files_synced_at':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            data_source_metadata = schemas.DictSchema
             __annotations__ = {
                 "id": id,
                 "data_source_external_id": data_source_external_id,
                 "data_source_type": data_source_type,
                 "token": token,
                 "sync_status": sync_status,
                 "source_items_synced_at": source_items_synced_at,
                 "organization_user_id": organization_user_id,
                 "organization_id": organization_id,
                 "organization_supplied_user_id": organization_supplied_user_id,
                 "revoked_access": revoked_access,
                 "last_synced_at": last_synced_at,
                 "last_sync_action": last_sync_action,
+                "enable_auto_sync": enable_auto_sync,
                 "created_at": created_at,
                 "updated_at": updated_at,
+                "files_synced_at": files_synced_at,
+                "data_source_metadata": data_source_metadata,
             }
     
     last_synced_at: MetaOapg.properties.last_synced_at
     revoked_access: MetaOapg.properties.revoked_access
     created_at: MetaOapg.properties.created_at
     data_source_type: 'DataSourceType'
+    data_source_metadata: MetaOapg.properties.data_source_metadata
     organization_supplied_user_id: MetaOapg.properties.organization_supplied_user_id
     token: MetaOapg.properties.token
     updated_at: MetaOapg.properties.updated_at
+    files_synced_at: MetaOapg.properties.files_synced_at
     source_items_synced_at: MetaOapg.properties.source_items_synced_at
+    enable_auto_sync: MetaOapg.properties.enable_auto_sync
     organization_id: MetaOapg.properties.organization_id
     organization_user_id: MetaOapg.properties.organization_user_id
     last_sync_action: 'DataSourceLastSyncActions'
     sync_status: 'DataSourceSyncStatuses'
     id: MetaOapg.properties.id
     data_source_external_id: MetaOapg.properties.data_source_external_id
     
@@ -202,23 +257,32 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["last_synced_at"]) -> MetaOapg.properties.last_synced_at: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["last_sync_action"]) -> 'DataSourceLastSyncActions': ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["enable_auto_sync"]) -> MetaOapg.properties.enable_auto_sync: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["files_synced_at"]) -> MetaOapg.properties.files_synced_at: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["data_source_metadata"]) -> MetaOapg.properties.data_source_metadata: ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "data_source_external_id", "data_source_type", "token", "sync_status", "source_items_synced_at", "organization_user_id", "organization_id", "organization_supplied_user_id", "revoked_access", "last_synced_at", "last_sync_action", "created_at", "updated_at", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "data_source_external_id", "data_source_type", "token", "sync_status", "source_items_synced_at", "organization_user_id", "organization_id", "organization_supplied_user_id", "revoked_access", "last_synced_at", "last_sync_action", "enable_auto_sync", "created_at", "updated_at", "files_synced_at", "data_source_metadata", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
     
@@ -252,37 +316,49 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["last_synced_at"]) -> MetaOapg.properties.last_synced_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["last_sync_action"]) -> 'DataSourceLastSyncActions': ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["enable_auto_sync"]) -> MetaOapg.properties.enable_auto_sync: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["files_synced_at"]) -> MetaOapg.properties.files_synced_at: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["data_source_metadata"]) -> MetaOapg.properties.data_source_metadata: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "data_source_external_id", "data_source_type", "token", "sync_status", "source_items_synced_at", "organization_user_id", "organization_id", "organization_supplied_user_id", "revoked_access", "last_synced_at", "last_sync_action", "created_at", "updated_at", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "data_source_external_id", "data_source_type", "token", "sync_status", "source_items_synced_at", "organization_user_id", "organization_id", "organization_supplied_user_id", "revoked_access", "last_synced_at", "last_sync_action", "enable_auto_sync", "created_at", "updated_at", "files_synced_at", "data_source_metadata", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         last_synced_at: typing.Union[MetaOapg.properties.last_synced_at, str, datetime, ],
         revoked_access: typing.Union[MetaOapg.properties.revoked_access, bool, ],
         created_at: typing.Union[MetaOapg.properties.created_at, str, datetime, ],
         data_source_type: 'DataSourceType',
+        data_source_metadata: typing.Union[MetaOapg.properties.data_source_metadata, dict, frozendict.frozendict, ],
         organization_supplied_user_id: typing.Union[MetaOapg.properties.organization_supplied_user_id, str, ],
         token: typing.Union[MetaOapg.properties.token, dict, frozendict.frozendict, None, ],
         updated_at: typing.Union[MetaOapg.properties.updated_at, str, datetime, ],
+        files_synced_at: typing.Union[MetaOapg.properties.files_synced_at, None, str, datetime, ],
         source_items_synced_at: typing.Union[MetaOapg.properties.source_items_synced_at, None, str, datetime, ],
+        enable_auto_sync: typing.Union[MetaOapg.properties.enable_auto_sync, None, bool, ],
         organization_id: typing.Union[MetaOapg.properties.organization_id, decimal.Decimal, int, ],
         organization_user_id: typing.Union[MetaOapg.properties.organization_user_id, decimal.Decimal, int, ],
         last_sync_action: 'DataSourceLastSyncActions',
         sync_status: 'DataSourceSyncStatuses',
         id: typing.Union[MetaOapg.properties.id, decimal.Decimal, int, ],
         data_source_external_id: typing.Union[MetaOapg.properties.data_source_external_id, None, str, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
@@ -291,18 +367,21 @@
         return super().__new__(
             cls,
             *args,
             last_synced_at=last_synced_at,
             revoked_access=revoked_access,
             created_at=created_at,
             data_source_type=data_source_type,
+            data_source_metadata=data_source_metadata,
             organization_supplied_user_id=organization_supplied_user_id,
             token=token,
             updated_at=updated_at,
+            files_synced_at=files_synced_at,
             source_items_synced_at=source_items_synced_at,
+            enable_auto_sync=enable_auto_sync,
             organization_id=organization_id,
             organization_user_id=organization_user_id,
             last_sync_action=last_sync_action,
             sync_status=sync_status,
             id=id,
             data_source_external_id=data_source_external_id,
             _configuration=_configuration,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_filters.py` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_filters.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_filters.pyi` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_filters.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_filters_ids.py` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_filters_ids.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_filters_ids.pyi` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_filters_ids.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_order_by_columns.py` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_order_by_columns.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_order_by_columns.pyi` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_order_by_columns.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_query_input.py` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_query_input.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_query_input.pyi` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_query_input.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_response.py` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_data_source_response.pyi` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_data_source_response.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_file_tag_create.py` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_file_tag_create.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_file_tag_create.pyi` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_file_tag_create.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_file_tag_create_tags.py` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_file_tag_create_tags.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_file_tag_create_tags.pyi` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_file_tag_create_tags.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_file_tags_remove.py` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_file_tags_remove.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_file_tags_remove.pyi` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_file_tags_remove.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_file_tags_remove_tags.py` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_file_tags_remove_tags.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_file_tags_remove_tags.pyi` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_file_tags_remove_tags.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters.py` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters.py`

 * *Files 14% similar despite different names*

```diff
@@ -229,26 +229,77 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'root_files_only':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            include_all_children = schemas.BoolSchema
+            non_synced_only = schemas.BoolSchema
+        
+            @staticmethod
+            def request_ids() -> typing.Type['OrganizationUserFilesToSyncFiltersRequestIds']:
+                return OrganizationUserFilesToSyncFiltersRequestIds
+            
+            
+            class sync_error_message(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'sync_error_message':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class include_containers(
+                schemas.BoolBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneBoolMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, bool, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'include_containers':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             __annotations__ = {
                 "tags": tags,
                 "source": source,
                 "name": name,
                 "tags_v2": tags_v2,
                 "ids": ids,
                 "external_file_ids": external_file_ids,
                 "sync_statuses": sync_statuses,
                 "parent_file_ids": parent_file_ids,
                 "organization_user_data_source_id": organization_user_data_source_id,
                 "embedding_generators": embedding_generators,
                 "root_files_only": root_files_only,
+                "include_all_children": include_all_children,
+                "non_synced_only": non_synced_only,
+                "request_ids": request_ids,
+                "sync_error_message": sync_error_message,
+                "include_containers": include_containers,
             }
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["tags"]) -> 'OrganizationUserFilesToSyncFiltersTags': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
@@ -277,17 +328,32 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["embedding_generators"]) -> MetaOapg.properties.embedding_generators: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["root_files_only"]) -> MetaOapg.properties.root_files_only: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["include_all_children"]) -> MetaOapg.properties.include_all_children: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["non_synced_only"]) -> MetaOapg.properties.non_synced_only: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["request_ids"]) -> 'OrganizationUserFilesToSyncFiltersRequestIds': ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["sync_error_message"]) -> MetaOapg.properties.sync_error_message: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["include_containers"]) -> MetaOapg.properties.include_containers: ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["tags", "source", "name", "tags_v2", "ids", "external_file_ids", "sync_statuses", "parent_file_ids", "organization_user_data_source_id", "embedding_generators", "root_files_only", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["tags", "source", "name", "tags_v2", "ids", "external_file_ids", "sync_statuses", "parent_file_ids", "organization_user_data_source_id", "embedding_generators", "root_files_only", "include_all_children", "non_synced_only", "request_ids", "sync_error_message", "include_containers", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union['OrganizationUserFilesToSyncFiltersTags', schemas.Unset]: ...
     
@@ -318,17 +384,32 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["embedding_generators"]) -> typing.Union[MetaOapg.properties.embedding_generators, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["root_files_only"]) -> typing.Union[MetaOapg.properties.root_files_only, schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["include_all_children"]) -> typing.Union[MetaOapg.properties.include_all_children, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["non_synced_only"]) -> typing.Union[MetaOapg.properties.non_synced_only, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["request_ids"]) -> typing.Union['OrganizationUserFilesToSyncFiltersRequestIds', schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_error_message"]) -> typing.Union[MetaOapg.properties.sync_error_message, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["include_containers"]) -> typing.Union[MetaOapg.properties.include_containers, schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["tags", "source", "name", "tags_v2", "ids", "external_file_ids", "sync_statuses", "parent_file_ids", "organization_user_data_source_id", "embedding_generators", "root_files_only", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["tags", "source", "name", "tags_v2", "ids", "external_file_ids", "sync_statuses", "parent_file_ids", "organization_user_data_source_id", "embedding_generators", "root_files_only", "include_all_children", "non_synced_only", "request_ids", "sync_error_message", "include_containers", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         tags: typing.Union['OrganizationUserFilesToSyncFiltersTags', schemas.Unset] = schemas.unset,
@@ -338,14 +419,19 @@
         ids: typing.Union['OrganizationUserFilesToSyncFiltersIds', schemas.Unset] = schemas.unset,
         external_file_ids: typing.Union['OrganizationUserFilesToSyncFiltersExternalFileIds', schemas.Unset] = schemas.unset,
         sync_statuses: typing.Union[MetaOapg.properties.sync_statuses, list, tuple, None, schemas.Unset] = schemas.unset,
         parent_file_ids: typing.Union['OrganizationUserFilesToSyncFiltersParentFileIds', schemas.Unset] = schemas.unset,
         organization_user_data_source_id: typing.Union['OrganizationUserFilesToSyncFiltersOrganizationUserDataSourceId', schemas.Unset] = schemas.unset,
         embedding_generators: typing.Union[MetaOapg.properties.embedding_generators, list, tuple, None, schemas.Unset] = schemas.unset,
         root_files_only: typing.Union[MetaOapg.properties.root_files_only, None, bool, schemas.Unset] = schemas.unset,
+        include_all_children: typing.Union[MetaOapg.properties.include_all_children, bool, schemas.Unset] = schemas.unset,
+        non_synced_only: typing.Union[MetaOapg.properties.non_synced_only, bool, schemas.Unset] = schemas.unset,
+        request_ids: typing.Union['OrganizationUserFilesToSyncFiltersRequestIds', schemas.Unset] = schemas.unset,
+        sync_error_message: typing.Union[MetaOapg.properties.sync_error_message, None, str, schemas.Unset] = schemas.unset,
+        include_containers: typing.Union[MetaOapg.properties.include_containers, None, bool, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
     ) -> 'OrganizationUserFilesToSyncFilters':
         return super().__new__(
             cls,
             *args,
             tags=tags,
@@ -355,19 +441,25 @@
             ids=ids,
             external_file_ids=external_file_ids,
             sync_statuses=sync_statuses,
             parent_file_ids=parent_file_ids,
             organization_user_data_source_id=organization_user_data_source_id,
             embedding_generators=embedding_generators,
             root_files_only=root_files_only,
+            include_all_children=include_all_children,
+            non_synced_only=non_synced_only,
+            request_ids=request_ids,
+            sync_error_message=sync_error_message,
+            include_containers=include_containers,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.data_source_type import DataSourceType
 from carbon.model.embedding_generators import EmbeddingGenerators
 from carbon.model.external_file_sync_statuses import ExternalFileSyncStatuses
 from carbon.model.organization_user_files_to_sync_filters_external_file_ids import OrganizationUserFilesToSyncFiltersExternalFileIds
 from carbon.model.organization_user_files_to_sync_filters_ids import OrganizationUserFilesToSyncFiltersIds
 from carbon.model.organization_user_files_to_sync_filters_organization_user_data_source_id import OrganizationUserFilesToSyncFiltersOrganizationUserDataSourceId
 from carbon.model.organization_user_files_to_sync_filters_parent_file_ids import OrganizationUserFilesToSyncFiltersParentFileIds
+from carbon.model.organization_user_files_to_sync_filters_request_ids import OrganizationUserFilesToSyncFiltersRequestIds
 from carbon.model.organization_user_files_to_sync_filters_tags import OrganizationUserFilesToSyncFiltersTags
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters.pyi` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters.pyi`

 * *Files 14% similar despite different names*

```diff
@@ -229,26 +229,77 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'root_files_only':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            include_all_children = schemas.BoolSchema
+            non_synced_only = schemas.BoolSchema
+        
+            @staticmethod
+            def request_ids() -> typing.Type['OrganizationUserFilesToSyncFiltersRequestIds']:
+                return OrganizationUserFilesToSyncFiltersRequestIds
+            
+            
+            class sync_error_message(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'sync_error_message':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class include_containers(
+                schemas.BoolBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneBoolMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, bool, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'include_containers':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             __annotations__ = {
                 "tags": tags,
                 "source": source,
                 "name": name,
                 "tags_v2": tags_v2,
                 "ids": ids,
                 "external_file_ids": external_file_ids,
                 "sync_statuses": sync_statuses,
                 "parent_file_ids": parent_file_ids,
                 "organization_user_data_source_id": organization_user_data_source_id,
                 "embedding_generators": embedding_generators,
                 "root_files_only": root_files_only,
+                "include_all_children": include_all_children,
+                "non_synced_only": non_synced_only,
+                "request_ids": request_ids,
+                "sync_error_message": sync_error_message,
+                "include_containers": include_containers,
             }
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["tags"]) -> 'OrganizationUserFilesToSyncFiltersTags': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
@@ -277,17 +328,32 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["embedding_generators"]) -> MetaOapg.properties.embedding_generators: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["root_files_only"]) -> MetaOapg.properties.root_files_only: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["include_all_children"]) -> MetaOapg.properties.include_all_children: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["non_synced_only"]) -> MetaOapg.properties.non_synced_only: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["request_ids"]) -> 'OrganizationUserFilesToSyncFiltersRequestIds': ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["sync_error_message"]) -> MetaOapg.properties.sync_error_message: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["include_containers"]) -> MetaOapg.properties.include_containers: ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["tags", "source", "name", "tags_v2", "ids", "external_file_ids", "sync_statuses", "parent_file_ids", "organization_user_data_source_id", "embedding_generators", "root_files_only", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["tags", "source", "name", "tags_v2", "ids", "external_file_ids", "sync_statuses", "parent_file_ids", "organization_user_data_source_id", "embedding_generators", "root_files_only", "include_all_children", "non_synced_only", "request_ids", "sync_error_message", "include_containers", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union['OrganizationUserFilesToSyncFiltersTags', schemas.Unset]: ...
     
@@ -318,17 +384,32 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["embedding_generators"]) -> typing.Union[MetaOapg.properties.embedding_generators, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["root_files_only"]) -> typing.Union[MetaOapg.properties.root_files_only, schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["include_all_children"]) -> typing.Union[MetaOapg.properties.include_all_children, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["non_synced_only"]) -> typing.Union[MetaOapg.properties.non_synced_only, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["request_ids"]) -> typing.Union['OrganizationUserFilesToSyncFiltersRequestIds', schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_error_message"]) -> typing.Union[MetaOapg.properties.sync_error_message, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["include_containers"]) -> typing.Union[MetaOapg.properties.include_containers, schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["tags", "source", "name", "tags_v2", "ids", "external_file_ids", "sync_statuses", "parent_file_ids", "organization_user_data_source_id", "embedding_generators", "root_files_only", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["tags", "source", "name", "tags_v2", "ids", "external_file_ids", "sync_statuses", "parent_file_ids", "organization_user_data_source_id", "embedding_generators", "root_files_only", "include_all_children", "non_synced_only", "request_ids", "sync_error_message", "include_containers", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         tags: typing.Union['OrganizationUserFilesToSyncFiltersTags', schemas.Unset] = schemas.unset,
@@ -338,14 +419,19 @@
         ids: typing.Union['OrganizationUserFilesToSyncFiltersIds', schemas.Unset] = schemas.unset,
         external_file_ids: typing.Union['OrganizationUserFilesToSyncFiltersExternalFileIds', schemas.Unset] = schemas.unset,
         sync_statuses: typing.Union[MetaOapg.properties.sync_statuses, list, tuple, None, schemas.Unset] = schemas.unset,
         parent_file_ids: typing.Union['OrganizationUserFilesToSyncFiltersParentFileIds', schemas.Unset] = schemas.unset,
         organization_user_data_source_id: typing.Union['OrganizationUserFilesToSyncFiltersOrganizationUserDataSourceId', schemas.Unset] = schemas.unset,
         embedding_generators: typing.Union[MetaOapg.properties.embedding_generators, list, tuple, None, schemas.Unset] = schemas.unset,
         root_files_only: typing.Union[MetaOapg.properties.root_files_only, None, bool, schemas.Unset] = schemas.unset,
+        include_all_children: typing.Union[MetaOapg.properties.include_all_children, bool, schemas.Unset] = schemas.unset,
+        non_synced_only: typing.Union[MetaOapg.properties.non_synced_only, bool, schemas.Unset] = schemas.unset,
+        request_ids: typing.Union['OrganizationUserFilesToSyncFiltersRequestIds', schemas.Unset] = schemas.unset,
+        sync_error_message: typing.Union[MetaOapg.properties.sync_error_message, None, str, schemas.Unset] = schemas.unset,
+        include_containers: typing.Union[MetaOapg.properties.include_containers, None, bool, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
     ) -> 'OrganizationUserFilesToSyncFilters':
         return super().__new__(
             cls,
             *args,
             tags=tags,
@@ -355,19 +441,25 @@
             ids=ids,
             external_file_ids=external_file_ids,
             sync_statuses=sync_statuses,
             parent_file_ids=parent_file_ids,
             organization_user_data_source_id=organization_user_data_source_id,
             embedding_generators=embedding_generators,
             root_files_only=root_files_only,
+            include_all_children=include_all_children,
+            non_synced_only=non_synced_only,
+            request_ids=request_ids,
+            sync_error_message=sync_error_message,
+            include_containers=include_containers,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.data_source_type import DataSourceType
 from carbon.model.embedding_generators import EmbeddingGenerators
 from carbon.model.external_file_sync_statuses import ExternalFileSyncStatuses
 from carbon.model.organization_user_files_to_sync_filters_external_file_ids import OrganizationUserFilesToSyncFiltersExternalFileIds
 from carbon.model.organization_user_files_to_sync_filters_ids import OrganizationUserFilesToSyncFiltersIds
 from carbon.model.organization_user_files_to_sync_filters_organization_user_data_source_id import OrganizationUserFilesToSyncFiltersOrganizationUserDataSourceId
 from carbon.model.organization_user_files_to_sync_filters_parent_file_ids import OrganizationUserFilesToSyncFiltersParentFileIds
+from carbon.model.organization_user_files_to_sync_filters_request_ids import OrganizationUserFilesToSyncFiltersRequestIds
 from carbon.model.organization_user_files_to_sync_filters_tags import OrganizationUserFilesToSyncFiltersTags
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_external_file_ids.py` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_request_ids.pyi`

 * *Files 4% similar despite different names*

```diff
@@ -19,32 +19,34 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class OrganizationUserFilesToSyncFiltersExternalFileIds(
+class OrganizationUserFilesToSyncFiltersRequestIds(
     schemas.ListBase,
     schemas.NoneBase,
     schemas.Schema,
     schemas.NoneTupleMixin
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
+
+    Filter by request ID(s) which were used to sync the files
     """
 
 
     class MetaOapg:
         items = schemas.StrSchema
 
 
     def __new__(
         cls,
         *args: typing.Union[list, tuple, None, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
-    ) -> 'OrganizationUserFilesToSyncFiltersExternalFileIds':
+    ) -> 'OrganizationUserFilesToSyncFiltersRequestIds':
         return super().__new__(
             cls,
             *args,
             _configuration=_configuration,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_external_file_ids.pyi` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_external_file_ids.py`

 * *Files 7% similar despite different names*

```diff
@@ -27,14 +27,16 @@
     schemas.ListBase,
     schemas.NoneBase,
     schemas.Schema,
     schemas.NoneTupleMixin
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
+
+    The external file IDs of the files. The query will return files with these external file IDs.
     """
 
 
     class MetaOapg:
         items = schemas.StrSchema
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_ids.py` & `carbon_python_sdk-0.2.0/carbon/model/webscrape_request_html_tags_to_skip.py`

 * *Files 7% similar despite different names*

```diff
@@ -19,32 +19,32 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class OrganizationUserFilesToSyncFiltersIds(
+class WebscrapeRequestHtmlTagsToSkip(
     schemas.ListBase,
     schemas.NoneBase,
     schemas.Schema,
     schemas.NoneTupleMixin
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
-        items = schemas.IntSchema
+        items = schemas.StrSchema
 
 
     def __new__(
         cls,
         *args: typing.Union[list, tuple, None, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
-    ) -> 'OrganizationUserFilesToSyncFiltersIds':
+    ) -> 'WebscrapeRequestHtmlTagsToSkip':
         return super().__new__(
             cls,
             *args,
             _configuration=_configuration,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_ids.pyi` & `carbon_python_sdk-0.2.0/carbon/model/webscrape_request_html_tags_to_skip.pyi`

 * *Files 7% similar despite different names*

```diff
@@ -19,32 +19,32 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class OrganizationUserFilesToSyncFiltersIds(
+class WebscrapeRequestHtmlTagsToSkip(
     schemas.ListBase,
     schemas.NoneBase,
     schemas.Schema,
     schemas.NoneTupleMixin
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
-        items = schemas.IntSchema
+        items = schemas.StrSchema
 
 
     def __new__(
         cls,
         *args: typing.Union[list, tuple, None, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
-    ) -> 'OrganizationUserFilesToSyncFiltersIds':
+    ) -> 'WebscrapeRequestHtmlTagsToSkip':
         return super().__new__(
             cls,
             *args,
             _configuration=_configuration,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_organization_user_data_source_id.py` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_request_ids.py`

 * *Files 6% similar despite different names*

```diff
@@ -19,32 +19,35 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class OrganizationUserFilesToSyncFiltersOrganizationUserDataSourceId(
+class OrganizationUserFilesToSyncFiltersRequestIds(
     schemas.ListBase,
     schemas.NoneBase,
     schemas.Schema,
     schemas.NoneTupleMixin
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
+
+    Filter by request ID(s) which were used to sync the files
     """
 
 
     class MetaOapg:
-        items = schemas.IntSchema
+        items = schemas.StrSchema
+        max_items = 100
 
 
     def __new__(
         cls,
         *args: typing.Union[list, tuple, None, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
-    ) -> 'OrganizationUserFilesToSyncFiltersOrganizationUserDataSourceId':
+    ) -> 'OrganizationUserFilesToSyncFiltersRequestIds':
         return super().__new__(
             cls,
             *args,
             _configuration=_configuration,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_organization_user_data_source_id.pyi` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_parent_file_ids.py`

 * *Files 8% similar despite different names*

```diff
@@ -19,15 +19,15 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class OrganizationUserFilesToSyncFiltersOrganizationUserDataSourceId(
+class OrganizationUserFilesToSyncFiltersParentFileIds(
     schemas.ListBase,
     schemas.NoneBase,
     schemas.Schema,
     schemas.NoneTupleMixin
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
@@ -38,13 +38,13 @@
         items = schemas.IntSchema
 
 
     def __new__(
         cls,
         *args: typing.Union[list, tuple, None, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
-    ) -> 'OrganizationUserFilesToSyncFiltersOrganizationUserDataSourceId':
+    ) -> 'OrganizationUserFilesToSyncFiltersParentFileIds':
         return super().__new__(
             cls,
             *args,
             _configuration=_configuration,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_parent_file_ids.py` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_parent_file_ids.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_parent_file_ids.pyi` & `carbon_python_sdk-0.2.0/carbon/model/list_items_filters_nullable_external_ids.py`

 * *Files 12% similar despite different names*

```diff
@@ -19,32 +19,32 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class OrganizationUserFilesToSyncFiltersParentFileIds(
+class ListItemsFiltersNullableExternalIds(
     schemas.ListBase,
     schemas.NoneBase,
     schemas.Schema,
     schemas.NoneTupleMixin
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
-        items = schemas.IntSchema
+        items = schemas.StrSchema
 
 
     def __new__(
         cls,
         *args: typing.Union[list, tuple, None, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
-    ) -> 'OrganizationUserFilesToSyncFiltersParentFileIds':
+    ) -> 'ListItemsFiltersNullableExternalIds':
         return super().__new__(
             cls,
             *args,
             _configuration=_configuration,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_tags.py` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_tags.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_filters_tags.pyi` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_filters_tags.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_order_by_types.py` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_order_by_types.py`

 * *Files 8% similar despite different names*

```diff
@@ -35,14 +35,15 @@
     class MetaOapg:
         enum_value_to_name = {
             "created_at": "CREATED_AT",
             "updated_at": "UPDATED_AT",
             "name": "NAME",
             "last_sync": "LAST_SYNC",
             "file_size": "FILE_SIZE",
+            "id": "ID",
         }
     
     @schemas.classproperty
     def CREATED_AT(cls):
         return cls("created_at")
     
     @schemas.classproperty
@@ -56,7 +57,11 @@
     @schemas.classproperty
     def LAST_SYNC(cls):
         return cls("last_sync")
     
     @schemas.classproperty
     def FILE_SIZE(cls):
         return cls("file_size")
+    
+    @schemas.classproperty
+    def ID(cls):
+        return cls("id")
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_order_by_types.pyi` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_order_by_types.pyi`

 * *Files 5% similar despite different names*

```diff
@@ -46,7 +46,11 @@
     @schemas.classproperty
     def LAST_SYNC(cls):
         return cls("last_sync")
     
     @schemas.classproperty
     def FILE_SIZE(cls):
         return cls("file_size")
+    
+    @schemas.classproperty
+    def ID(cls):
+        return cls("id")
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_query_input.py` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_query_input.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/organization_user_files_to_sync_query_input.pyi` & `carbon_python_sdk-0.2.0/carbon/model/organization_user_files_to_sync_query_input.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/outh_url_response.py` & `carbon_python_sdk-0.2.0/carbon/model/outh_url_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/outh_url_response.pyi` & `carbon_python_sdk-0.2.0/carbon/model/outh_url_response.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/outlook_sync_input.py` & `carbon_python_sdk-0.2.0/carbon/model/fresh_desk_connect_request.py`

 * *Files 9% similar despite different names*

```diff
@@ -19,29 +19,31 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class OutlookSyncInput(
+class FreshDeskConnectRequest(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
-            "filters",
+            "api_key",
+            "domain",
         }
         
         class properties:
-            filters = schemas.DictSchema
+            domain = schemas.StrSchema
+            api_key = schemas.StrSchema
             
             
             class tags(
                 schemas.DictBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneFrozenDictMixin
@@ -58,34 +60,14 @@
                         cls,
                         *args,
                         _configuration=_configuration,
                         **kwargs,
                     )
             
             
-            class folder(
-                schemas.StrBase,
-                schemas.NoneBase,
-                schemas.Schema,
-                schemas.NoneStrMixin
-            ):
-            
-            
-                def __new__(
-                    cls,
-                    *args: typing.Union[None, str, ],
-                    _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'folder':
-                    return super().__new__(
-                        cls,
-                        *args,
-                        _configuration=_configuration,
-                    )
-            
-            
             class chunk_size(
                 schemas.IntBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneDecimalMixin
             ):
             
@@ -138,16 +120,16 @@
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
         
             @staticmethod
-            def embedding_model() -> typing.Type['EmbeddingGenerators']:
-                return EmbeddingGenerators
+            def embedding_model() -> typing.Type['EmbeddingGeneratorsNullable']:
+                return EmbeddingGeneratorsNullable
             
             
             class generate_sparse_vectors(
                 schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneBoolMixin
@@ -182,149 +164,203 @@
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
             
             
-            class data_source_id(
-                schemas.IntBase,
+            class sync_files_on_connection(
+                schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
-                schemas.NoneDecimalMixin
+                schemas.NoneBoolMixin
             ):
             
             
                 def __new__(
                     cls,
-                    *args: typing.Union[None, decimal.Decimal, int, ],
+                    *args: typing.Union[None, bool, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'sync_files_on_connection':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class request_id(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'data_source_id':
+                ) -> 'request_id':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            sync_source_items = schemas.BoolSchema
+        
+            @staticmethod
+            def file_sync_config() -> typing.Type['FileSyncConfigNullable']:
+                return FileSyncConfigNullable
             __annotations__ = {
-                "filters": filters,
+                "domain": domain,
+                "api_key": api_key,
                 "tags": tags,
-                "folder": folder,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
                 "embedding_model": embedding_model,
                 "generate_sparse_vectors": generate_sparse_vectors,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
-                "data_source_id": data_source_id,
+                "sync_files_on_connection": sync_files_on_connection,
+                "request_id": request_id,
+                "sync_source_items": sync_source_items,
+                "file_sync_config": file_sync_config,
             }
     
-    filters: MetaOapg.properties.filters
+    api_key: MetaOapg.properties.api_key
+    domain: MetaOapg.properties.domain
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["filters"]) -> MetaOapg.properties.filters: ...
+    def __getitem__(self, name: typing_extensions.Literal["domain"]) -> MetaOapg.properties.domain: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
+    def __getitem__(self, name: typing_extensions.Literal["api_key"]) -> MetaOapg.properties.api_key: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["folder"]) -> MetaOapg.properties.folder: ...
+    def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_size"]) -> MetaOapg.properties.chunk_size: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> MetaOapg.properties.skip_embedding_generation: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
+    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGeneratorsNullable': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
+    def __getitem__(self, name: typing_extensions.Literal["sync_files_on_connection"]) -> MetaOapg.properties.sync_files_on_connection: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["sync_source_items"]) -> MetaOapg.properties.sync_source_items: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["file_sync_config"]) -> 'FileSyncConfigNullable': ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["filters", "tags", "folder", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "data_source_id", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["domain", "api_key", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "sync_files_on_connection", "request_id", "sync_source_items", "file_sync_config", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["filters"]) -> MetaOapg.properties.filters: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["domain"]) -> MetaOapg.properties.domain: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union[MetaOapg.properties.tags, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["api_key"]) -> MetaOapg.properties.api_key: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["folder"]) -> typing.Union[MetaOapg.properties.folder, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union[MetaOapg.properties.tags, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_size"]) -> typing.Union[MetaOapg.properties.chunk_size, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_overlap"]) -> typing.Union[MetaOapg.properties.chunk_overlap, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> typing.Union[MetaOapg.properties.skip_embedding_generation, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGeneratorsNullable', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> typing.Union[MetaOapg.properties.generate_sparse_vectors, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> typing.Union[MetaOapg.properties.data_source_id, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_files_on_connection"]) -> typing.Union[MetaOapg.properties.sync_files_on_connection, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> typing.Union[MetaOapg.properties.request_id, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_source_items"]) -> typing.Union[MetaOapg.properties.sync_source_items, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["file_sync_config"]) -> typing.Union['FileSyncConfigNullable', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["filters", "tags", "folder", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "data_source_id", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["domain", "api_key", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "sync_files_on_connection", "request_id", "sync_source_items", "file_sync_config", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        filters: typing.Union[MetaOapg.properties.filters, dict, frozendict.frozendict, ],
+        api_key: typing.Union[MetaOapg.properties.api_key, str, ],
+        domain: typing.Union[MetaOapg.properties.domain, str, ],
         tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
-        folder: typing.Union[MetaOapg.properties.folder, None, str, schemas.Unset] = schemas.unset,
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
-        embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
+        embedding_model: typing.Union['EmbeddingGeneratorsNullable', schemas.Unset] = schemas.unset,
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
-        data_source_id: typing.Union[MetaOapg.properties.data_source_id, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        sync_files_on_connection: typing.Union[MetaOapg.properties.sync_files_on_connection, None, bool, schemas.Unset] = schemas.unset,
+        request_id: typing.Union[MetaOapg.properties.request_id, None, str, schemas.Unset] = schemas.unset,
+        sync_source_items: typing.Union[MetaOapg.properties.sync_source_items, bool, schemas.Unset] = schemas.unset,
+        file_sync_config: typing.Union['FileSyncConfigNullable', schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'OutlookSyncInput':
+    ) -> 'FreshDeskConnectRequest':
         return super().__new__(
             cls,
             *args,
-            filters=filters,
+            api_key=api_key,
+            domain=domain,
             tags=tags,
-            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            data_source_id=data_source_id,
+            sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
+            file_sync_config=file_sync_config,
             _configuration=_configuration,
             **kwargs,
         )
 
-from carbon.model.embedding_generators import EmbeddingGenerators
+from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/outlook_sync_input.pyi` & `carbon_python_sdk-0.2.0/carbon/model/fresh_desk_connect_request.pyi`

 * *Files 9% similar despite different names*

```diff
@@ -19,29 +19,31 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class OutlookSyncInput(
+class FreshDeskConnectRequest(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
-            "filters",
+            "api_key",
+            "domain",
         }
         
         class properties:
-            filters = schemas.DictSchema
+            domain = schemas.StrSchema
+            api_key = schemas.StrSchema
             
             
             class tags(
                 schemas.DictBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneFrozenDictMixin
@@ -58,34 +60,14 @@
                         cls,
                         *args,
                         _configuration=_configuration,
                         **kwargs,
                     )
             
             
-            class folder(
-                schemas.StrBase,
-                schemas.NoneBase,
-                schemas.Schema,
-                schemas.NoneStrMixin
-            ):
-            
-            
-                def __new__(
-                    cls,
-                    *args: typing.Union[None, str, ],
-                    _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'folder':
-                    return super().__new__(
-                        cls,
-                        *args,
-                        _configuration=_configuration,
-                    )
-            
-            
             class chunk_size(
                 schemas.IntBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneDecimalMixin
             ):
             
@@ -138,16 +120,16 @@
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
         
             @staticmethod
-            def embedding_model() -> typing.Type['EmbeddingGenerators']:
-                return EmbeddingGenerators
+            def embedding_model() -> typing.Type['EmbeddingGeneratorsNullable']:
+                return EmbeddingGeneratorsNullable
             
             
             class generate_sparse_vectors(
                 schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneBoolMixin
@@ -182,149 +164,203 @@
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
             
             
-            class data_source_id(
-                schemas.IntBase,
+            class sync_files_on_connection(
+                schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
-                schemas.NoneDecimalMixin
+                schemas.NoneBoolMixin
             ):
             
             
                 def __new__(
                     cls,
-                    *args: typing.Union[None, decimal.Decimal, int, ],
+                    *args: typing.Union[None, bool, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'sync_files_on_connection':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class request_id(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'data_source_id':
+                ) -> 'request_id':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            sync_source_items = schemas.BoolSchema
+        
+            @staticmethod
+            def file_sync_config() -> typing.Type['FileSyncConfigNullable']:
+                return FileSyncConfigNullable
             __annotations__ = {
-                "filters": filters,
+                "domain": domain,
+                "api_key": api_key,
                 "tags": tags,
-                "folder": folder,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
                 "embedding_model": embedding_model,
                 "generate_sparse_vectors": generate_sparse_vectors,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
-                "data_source_id": data_source_id,
+                "sync_files_on_connection": sync_files_on_connection,
+                "request_id": request_id,
+                "sync_source_items": sync_source_items,
+                "file_sync_config": file_sync_config,
             }
     
-    filters: MetaOapg.properties.filters
+    api_key: MetaOapg.properties.api_key
+    domain: MetaOapg.properties.domain
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["filters"]) -> MetaOapg.properties.filters: ...
+    def __getitem__(self, name: typing_extensions.Literal["domain"]) -> MetaOapg.properties.domain: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
+    def __getitem__(self, name: typing_extensions.Literal["api_key"]) -> MetaOapg.properties.api_key: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["folder"]) -> MetaOapg.properties.folder: ...
+    def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_size"]) -> MetaOapg.properties.chunk_size: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> MetaOapg.properties.skip_embedding_generation: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
+    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGeneratorsNullable': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
+    def __getitem__(self, name: typing_extensions.Literal["sync_files_on_connection"]) -> MetaOapg.properties.sync_files_on_connection: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["sync_source_items"]) -> MetaOapg.properties.sync_source_items: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["file_sync_config"]) -> 'FileSyncConfigNullable': ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["filters", "tags", "folder", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "data_source_id", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["domain", "api_key", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "sync_files_on_connection", "request_id", "sync_source_items", "file_sync_config", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["filters"]) -> MetaOapg.properties.filters: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["domain"]) -> MetaOapg.properties.domain: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union[MetaOapg.properties.tags, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["api_key"]) -> MetaOapg.properties.api_key: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["folder"]) -> typing.Union[MetaOapg.properties.folder, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union[MetaOapg.properties.tags, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_size"]) -> typing.Union[MetaOapg.properties.chunk_size, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_overlap"]) -> typing.Union[MetaOapg.properties.chunk_overlap, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> typing.Union[MetaOapg.properties.skip_embedding_generation, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGeneratorsNullable', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> typing.Union[MetaOapg.properties.generate_sparse_vectors, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> typing.Union[MetaOapg.properties.data_source_id, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_files_on_connection"]) -> typing.Union[MetaOapg.properties.sync_files_on_connection, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> typing.Union[MetaOapg.properties.request_id, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_source_items"]) -> typing.Union[MetaOapg.properties.sync_source_items, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["file_sync_config"]) -> typing.Union['FileSyncConfigNullable', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["filters", "tags", "folder", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "data_source_id", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["domain", "api_key", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "sync_files_on_connection", "request_id", "sync_source_items", "file_sync_config", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        filters: typing.Union[MetaOapg.properties.filters, dict, frozendict.frozendict, ],
+        api_key: typing.Union[MetaOapg.properties.api_key, str, ],
+        domain: typing.Union[MetaOapg.properties.domain, str, ],
         tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
-        folder: typing.Union[MetaOapg.properties.folder, None, str, schemas.Unset] = schemas.unset,
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
-        embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
+        embedding_model: typing.Union['EmbeddingGeneratorsNullable', schemas.Unset] = schemas.unset,
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
-        data_source_id: typing.Union[MetaOapg.properties.data_source_id, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        sync_files_on_connection: typing.Union[MetaOapg.properties.sync_files_on_connection, None, bool, schemas.Unset] = schemas.unset,
+        request_id: typing.Union[MetaOapg.properties.request_id, None, str, schemas.Unset] = schemas.unset,
+        sync_source_items: typing.Union[MetaOapg.properties.sync_source_items, bool, schemas.Unset] = schemas.unset,
+        file_sync_config: typing.Union['FileSyncConfigNullable', schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'OutlookSyncInput':
+    ) -> 'FreshDeskConnectRequest':
         return super().__new__(
             cls,
             *args,
-            filters=filters,
+            api_key=api_key,
+            domain=domain,
             tags=tags,
-            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            data_source_id=data_source_id,
+            sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
+            file_sync_config=file_sync_config,
             _configuration=_configuration,
             **kwargs,
         )
 
-from carbon.model.embedding_generators import EmbeddingGenerators
+from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/pagination.py` & `carbon_python_sdk-0.2.0/carbon/model/sync_files_ids.py`

 * *Files 15% similar despite different names*

```diff
@@ -19,68 +19,75 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class Pagination(
+class SyncFilesIds(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
+        required = {
+            "root_id",
+            "id",
+        }
         
         class properties:
-            limit = schemas.IntSchema
-            offset = schemas.IntSchema
+            id = schemas.StrSchema
+            root_id = schemas.StrSchema
             __annotations__ = {
-                "limit": limit,
-                "offset": offset,
+                "id": id,
+                "root_id": root_id,
             }
     
+    root_id: MetaOapg.properties.root_id
+    id: MetaOapg.properties.id
+    
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["limit"]) -> MetaOapg.properties.limit: ...
+    def __getitem__(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["offset"]) -> MetaOapg.properties.offset: ...
+    def __getitem__(self, name: typing_extensions.Literal["root_id"]) -> MetaOapg.properties.root_id: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["limit", "offset", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "root_id", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["limit"]) -> typing.Union[MetaOapg.properties.limit, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["offset"]) -> typing.Union[MetaOapg.properties.offset, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["root_id"]) -> MetaOapg.properties.root_id: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["limit", "offset", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "root_id", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        limit: typing.Union[MetaOapg.properties.limit, decimal.Decimal, int, schemas.Unset] = schemas.unset,
-        offset: typing.Union[MetaOapg.properties.offset, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        root_id: typing.Union[MetaOapg.properties.root_id, str, ],
+        id: typing.Union[MetaOapg.properties.id, str, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'Pagination':
+    ) -> 'SyncFilesIds':
         return super().__new__(
             cls,
             *args,
-            limit=limit,
-            offset=offset,
+            root_id=root_id,
+            id=id,
             _configuration=_configuration,
             **kwargs,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/pagination.pyi` & `carbon_python_sdk-0.2.0/carbon/model/sync_files_ids.pyi`

 * *Files 15% similar despite different names*

```diff
@@ -19,68 +19,75 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class Pagination(
+class SyncFilesIds(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
+        required = {
+            "root_id",
+            "id",
+        }
         
         class properties:
-            limit = schemas.IntSchema
-            offset = schemas.IntSchema
+            id = schemas.StrSchema
+            root_id = schemas.StrSchema
             __annotations__ = {
-                "limit": limit,
-                "offset": offset,
+                "id": id,
+                "root_id": root_id,
             }
     
+    root_id: MetaOapg.properties.root_id
+    id: MetaOapg.properties.id
+    
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["limit"]) -> MetaOapg.properties.limit: ...
+    def __getitem__(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["offset"]) -> MetaOapg.properties.offset: ...
+    def __getitem__(self, name: typing_extensions.Literal["root_id"]) -> MetaOapg.properties.root_id: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["limit", "offset", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "root_id", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["limit"]) -> typing.Union[MetaOapg.properties.limit, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["offset"]) -> typing.Union[MetaOapg.properties.offset, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["root_id"]) -> MetaOapg.properties.root_id: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["limit", "offset", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "root_id", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        limit: typing.Union[MetaOapg.properties.limit, decimal.Decimal, int, schemas.Unset] = schemas.unset,
-        offset: typing.Union[MetaOapg.properties.offset, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        root_id: typing.Union[MetaOapg.properties.root_id, str, ],
+        id: typing.Union[MetaOapg.properties.id, str, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'Pagination':
+    ) -> 'SyncFilesIds':
         return super().__new__(
             cls,
             *args,
-            limit=limit,
-            offset=offset,
+            root_id=root_id,
+            id=id,
             _configuration=_configuration,
             **kwargs,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/presigned_url_response.py` & `carbon_python_sdk-0.2.0/carbon/model/presigned_url_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/presigned_url_response.pyi` & `carbon_python_sdk-0.2.0/carbon/model/presigned_url_response.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/raw_text_input.py` & `carbon_python_sdk-0.2.0/carbon/model/raw_text_input.pyi`

 * *Files 1% similar despite different names*

```diff
@@ -33,15 +33,20 @@
 
     class MetaOapg:
         required = {
             "contents",
         }
         
         class properties:
-            contents = schemas.StrSchema
+            
+            
+            class contents(
+                schemas.StrSchema
+            ):
+                pass
             
             
             class name(
                 schemas.StrBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneStrMixin
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/raw_text_input.pyi` & `carbon_python_sdk-0.2.0/carbon/model/raw_text_input.py`

 * *Files 2% similar despite different names*

```diff
@@ -33,15 +33,23 @@
 
     class MetaOapg:
         required = {
             "contents",
         }
         
         class properties:
-            contents = schemas.StrSchema
+            
+            
+            class contents(
+                schemas.StrSchema
+            ):
+            
+            
+                class MetaOapg:
+                    min_length = 5
             
             
             class name(
                 schemas.StrBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneStrMixin
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/resync_file_query_input.py` & `carbon_python_sdk-0.2.0/carbon/model/resync_file_query_input.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/resync_file_query_input.pyi` & `carbon_python_sdk-0.2.0/carbon/model/resync_file_query_input.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/revoke_access_token_input.py` & `carbon_python_sdk-0.2.0/carbon/model/revoke_access_token_input.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/revoke_access_token_input.pyi` & `carbon_python_sdk-0.2.0/carbon/model/revoke_access_token_input.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/rss_feed_input.py` & `carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request.pyi`

 * *Files 20% similar despite different names*

```diff
@@ -19,50 +19,55 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class RSSFeedInput(
+class SitemapScrapeRequest(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
             "url",
         }
         
         class properties:
             url = schemas.StrSchema
+        
+            @staticmethod
+            def tags() -> typing.Type['SitemapScrapeRequestTags']:
+                return SitemapScrapeRequestTags
             
             
-            class tags(
-                schemas.DictBase,
+            class max_pages_to_scrape(
+                schemas.IntBase,
                 schemas.NoneBase,
                 schemas.Schema,
-                schemas.NoneFrozenDictMixin
+                schemas.NoneDecimalMixin
             ):
             
             
+                class MetaOapg:
+            
+            
                 def __new__(
                     cls,
-                    *args: typing.Union[dict, frozendict.frozendict, None, ],
+                    *args: typing.Union[None, decimal.Decimal, int, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                    **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-                ) -> 'tags':
+                ) -> 'max_pages_to_scrape':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
-                        **kwargs,
                     )
             
             
             class chunk_size(
                 schemas.IntBase,
                 schemas.NoneBase,
                 schemas.Schema,
@@ -116,18 +121,34 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'skip_embedding_generation':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
-        
-            @staticmethod
-            def embedding_model() -> typing.Type['EmbeddingGenerators']:
-                return EmbeddingGenerators
+            
+            
+            class enable_auto_sync(
+                schemas.BoolBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneBoolMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, bool, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'enable_auto_sync':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             
             
             class generate_sparse_vectors(
                 schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneBoolMixin
@@ -160,113 +181,178 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'prepend_filename_to_chunks':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+        
+            @staticmethod
+            def html_tags_to_skip() -> typing.Type['SitemapScrapeRequestHtmlTagsToSkip']:
+                return SitemapScrapeRequestHtmlTagsToSkip
+        
+            @staticmethod
+            def css_classes_to_skip() -> typing.Type['SitemapScrapeRequestCssClassesToSkip']:
+                return SitemapScrapeRequestCssClassesToSkip
+        
+            @staticmethod
+            def css_selectors_to_skip() -> typing.Type['SitemapScrapeRequestCssSelectorsToSkip']:
+                return SitemapScrapeRequestCssSelectorsToSkip
+        
+            @staticmethod
+            def embedding_model() -> typing.Type['EmbeddingGenerators']:
+                return EmbeddingGenerators
             __annotations__ = {
                 "url": url,
                 "tags": tags,
+                "max_pages_to_scrape": max_pages_to_scrape,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
-                "embedding_model": embedding_model,
+                "enable_auto_sync": enable_auto_sync,
                 "generate_sparse_vectors": generate_sparse_vectors,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
+                "html_tags_to_skip": html_tags_to_skip,
+                "css_classes_to_skip": css_classes_to_skip,
+                "css_selectors_to_skip": css_selectors_to_skip,
+                "embedding_model": embedding_model,
             }
     
     url: MetaOapg.properties.url
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
+    def __getitem__(self, name: typing_extensions.Literal["tags"]) -> 'SitemapScrapeRequestTags': ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["max_pages_to_scrape"]) -> MetaOapg.properties.max_pages_to_scrape: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_size"]) -> MetaOapg.properties.chunk_size: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> MetaOapg.properties.skip_embedding_generation: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
+    def __getitem__(self, name: typing_extensions.Literal["enable_auto_sync"]) -> MetaOapg.properties.enable_auto_sync: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["html_tags_to_skip"]) -> 'SitemapScrapeRequestHtmlTagsToSkip': ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["css_classes_to_skip"]) -> 'SitemapScrapeRequestCssClassesToSkip': ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["css_selectors_to_skip"]) -> 'SitemapScrapeRequestCssSelectorsToSkip': ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["url", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["url", "tags", "max_pages_to_scrape", "chunk_size", "chunk_overlap", "skip_embedding_generation", "enable_auto_sync", "generate_sparse_vectors", "prepend_filename_to_chunks", "html_tags_to_skip", "css_classes_to_skip", "css_selectors_to_skip", "embedding_model", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union[MetaOapg.properties.tags, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union['SitemapScrapeRequestTags', schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["max_pages_to_scrape"]) -> typing.Union[MetaOapg.properties.max_pages_to_scrape, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_size"]) -> typing.Union[MetaOapg.properties.chunk_size, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_overlap"]) -> typing.Union[MetaOapg.properties.chunk_overlap, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> typing.Union[MetaOapg.properties.skip_embedding_generation, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["enable_auto_sync"]) -> typing.Union[MetaOapg.properties.enable_auto_sync, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> typing.Union[MetaOapg.properties.generate_sparse_vectors, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["html_tags_to_skip"]) -> typing.Union['SitemapScrapeRequestHtmlTagsToSkip', schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["css_classes_to_skip"]) -> typing.Union['SitemapScrapeRequestCssClassesToSkip', schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["css_selectors_to_skip"]) -> typing.Union['SitemapScrapeRequestCssSelectorsToSkip', schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["url", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["url", "tags", "max_pages_to_scrape", "chunk_size", "chunk_overlap", "skip_embedding_generation", "enable_auto_sync", "generate_sparse_vectors", "prepend_filename_to_chunks", "html_tags_to_skip", "css_classes_to_skip", "css_selectors_to_skip", "embedding_model", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         url: typing.Union[MetaOapg.properties.url, str, ],
-        tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
+        tags: typing.Union['SitemapScrapeRequestTags', schemas.Unset] = schemas.unset,
+        max_pages_to_scrape: typing.Union[MetaOapg.properties.max_pages_to_scrape, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
-        embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
+        enable_auto_sync: typing.Union[MetaOapg.properties.enable_auto_sync, None, bool, schemas.Unset] = schemas.unset,
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
+        html_tags_to_skip: typing.Union['SitemapScrapeRequestHtmlTagsToSkip', schemas.Unset] = schemas.unset,
+        css_classes_to_skip: typing.Union['SitemapScrapeRequestCssClassesToSkip', schemas.Unset] = schemas.unset,
+        css_selectors_to_skip: typing.Union['SitemapScrapeRequestCssSelectorsToSkip', schemas.Unset] = schemas.unset,
+        embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'RSSFeedInput':
+    ) -> 'SitemapScrapeRequest':
         return super().__new__(
             cls,
             *args,
             url=url,
             tags=tags,
+            max_pages_to_scrape=max_pages_to_scrape,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
-            embedding_model=embedding_model,
+            enable_auto_sync=enable_auto_sync,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            html_tags_to_skip=html_tags_to_skip,
+            css_classes_to_skip=css_classes_to_skip,
+            css_selectors_to_skip=css_selectors_to_skip,
+            embedding_model=embedding_model,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.embedding_generators import EmbeddingGenerators
+from carbon.model.sitemap_scrape_request_css_classes_to_skip import SitemapScrapeRequestCssClassesToSkip
+from carbon.model.sitemap_scrape_request_css_selectors_to_skip import SitemapScrapeRequestCssSelectorsToSkip
+from carbon.model.sitemap_scrape_request_html_tags_to_skip import SitemapScrapeRequestHtmlTagsToSkip
+from carbon.model.sitemap_scrape_request_tags import SitemapScrapeRequestTags
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/rss_feed_input.pyi` & `carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request.py`

 * *Files 21% similar despite different names*

```diff
@@ -19,50 +19,56 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class RSSFeedInput(
+class SitemapScrapeRequest(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
             "url",
         }
         
         class properties:
             url = schemas.StrSchema
+        
+            @staticmethod
+            def tags() -> typing.Type['SitemapScrapeRequestTags']:
+                return SitemapScrapeRequestTags
             
             
-            class tags(
-                schemas.DictBase,
+            class max_pages_to_scrape(
+                schemas.IntBase,
                 schemas.NoneBase,
                 schemas.Schema,
-                schemas.NoneFrozenDictMixin
+                schemas.NoneDecimalMixin
             ):
             
             
+                class MetaOapg:
+                    inclusive_minimum = 1
+            
+            
                 def __new__(
                     cls,
-                    *args: typing.Union[dict, frozendict.frozendict, None, ],
+                    *args: typing.Union[None, decimal.Decimal, int, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                    **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-                ) -> 'tags':
+                ) -> 'max_pages_to_scrape':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
-                        **kwargs,
                     )
             
             
             class chunk_size(
                 schemas.IntBase,
                 schemas.NoneBase,
                 schemas.Schema,
@@ -116,18 +122,34 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'skip_embedding_generation':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
-        
-            @staticmethod
-            def embedding_model() -> typing.Type['EmbeddingGenerators']:
-                return EmbeddingGenerators
+            
+            
+            class enable_auto_sync(
+                schemas.BoolBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneBoolMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, bool, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'enable_auto_sync':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             
             
             class generate_sparse_vectors(
                 schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneBoolMixin
@@ -160,113 +182,178 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'prepend_filename_to_chunks':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+        
+            @staticmethod
+            def html_tags_to_skip() -> typing.Type['SitemapScrapeRequestHtmlTagsToSkip']:
+                return SitemapScrapeRequestHtmlTagsToSkip
+        
+            @staticmethod
+            def css_classes_to_skip() -> typing.Type['SitemapScrapeRequestCssClassesToSkip']:
+                return SitemapScrapeRequestCssClassesToSkip
+        
+            @staticmethod
+            def css_selectors_to_skip() -> typing.Type['SitemapScrapeRequestCssSelectorsToSkip']:
+                return SitemapScrapeRequestCssSelectorsToSkip
+        
+            @staticmethod
+            def embedding_model() -> typing.Type['EmbeddingGenerators']:
+                return EmbeddingGenerators
             __annotations__ = {
                 "url": url,
                 "tags": tags,
+                "max_pages_to_scrape": max_pages_to_scrape,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
-                "embedding_model": embedding_model,
+                "enable_auto_sync": enable_auto_sync,
                 "generate_sparse_vectors": generate_sparse_vectors,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
+                "html_tags_to_skip": html_tags_to_skip,
+                "css_classes_to_skip": css_classes_to_skip,
+                "css_selectors_to_skip": css_selectors_to_skip,
+                "embedding_model": embedding_model,
             }
     
     url: MetaOapg.properties.url
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
+    def __getitem__(self, name: typing_extensions.Literal["tags"]) -> 'SitemapScrapeRequestTags': ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["max_pages_to_scrape"]) -> MetaOapg.properties.max_pages_to_scrape: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_size"]) -> MetaOapg.properties.chunk_size: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> MetaOapg.properties.skip_embedding_generation: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
+    def __getitem__(self, name: typing_extensions.Literal["enable_auto_sync"]) -> MetaOapg.properties.enable_auto_sync: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["html_tags_to_skip"]) -> 'SitemapScrapeRequestHtmlTagsToSkip': ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["css_classes_to_skip"]) -> 'SitemapScrapeRequestCssClassesToSkip': ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["css_selectors_to_skip"]) -> 'SitemapScrapeRequestCssSelectorsToSkip': ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["url", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["url", "tags", "max_pages_to_scrape", "chunk_size", "chunk_overlap", "skip_embedding_generation", "enable_auto_sync", "generate_sparse_vectors", "prepend_filename_to_chunks", "html_tags_to_skip", "css_classes_to_skip", "css_selectors_to_skip", "embedding_model", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union[MetaOapg.properties.tags, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union['SitemapScrapeRequestTags', schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["max_pages_to_scrape"]) -> typing.Union[MetaOapg.properties.max_pages_to_scrape, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_size"]) -> typing.Union[MetaOapg.properties.chunk_size, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_overlap"]) -> typing.Union[MetaOapg.properties.chunk_overlap, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> typing.Union[MetaOapg.properties.skip_embedding_generation, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["enable_auto_sync"]) -> typing.Union[MetaOapg.properties.enable_auto_sync, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> typing.Union[MetaOapg.properties.generate_sparse_vectors, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["html_tags_to_skip"]) -> typing.Union['SitemapScrapeRequestHtmlTagsToSkip', schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["css_classes_to_skip"]) -> typing.Union['SitemapScrapeRequestCssClassesToSkip', schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["css_selectors_to_skip"]) -> typing.Union['SitemapScrapeRequestCssSelectorsToSkip', schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["url", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["url", "tags", "max_pages_to_scrape", "chunk_size", "chunk_overlap", "skip_embedding_generation", "enable_auto_sync", "generate_sparse_vectors", "prepend_filename_to_chunks", "html_tags_to_skip", "css_classes_to_skip", "css_selectors_to_skip", "embedding_model", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         url: typing.Union[MetaOapg.properties.url, str, ],
-        tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
+        tags: typing.Union['SitemapScrapeRequestTags', schemas.Unset] = schemas.unset,
+        max_pages_to_scrape: typing.Union[MetaOapg.properties.max_pages_to_scrape, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
-        embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
+        enable_auto_sync: typing.Union[MetaOapg.properties.enable_auto_sync, None, bool, schemas.Unset] = schemas.unset,
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
+        html_tags_to_skip: typing.Union['SitemapScrapeRequestHtmlTagsToSkip', schemas.Unset] = schemas.unset,
+        css_classes_to_skip: typing.Union['SitemapScrapeRequestCssClassesToSkip', schemas.Unset] = schemas.unset,
+        css_selectors_to_skip: typing.Union['SitemapScrapeRequestCssSelectorsToSkip', schemas.Unset] = schemas.unset,
+        embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'RSSFeedInput':
+    ) -> 'SitemapScrapeRequest':
         return super().__new__(
             cls,
             *args,
             url=url,
             tags=tags,
+            max_pages_to_scrape=max_pages_to_scrape,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
-            embedding_model=embedding_model,
+            enable_auto_sync=enable_auto_sync,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            html_tags_to_skip=html_tags_to_skip,
+            css_classes_to_skip=css_classes_to_skip,
+            css_selectors_to_skip=css_selectors_to_skip,
+            embedding_model=embedding_model,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.embedding_generators import EmbeddingGenerators
+from carbon.model.sitemap_scrape_request_css_classes_to_skip import SitemapScrapeRequestCssClassesToSkip
+from carbon.model.sitemap_scrape_request_css_selectors_to_skip import SitemapScrapeRequestCssSelectorsToSkip
+from carbon.model.sitemap_scrape_request_html_tags_to_skip import SitemapScrapeRequestHtmlTagsToSkip
+from carbon.model.sitemap_scrape_request_tags import SitemapScrapeRequestTags
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/s3_auth_request.py` & `carbon_python_sdk-0.2.0/carbon/model/s3_authentication.py`

 * *Files 14% similar despite different names*

```diff
@@ -19,75 +19,87 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class S3AuthRequest(
+class S3Authentication(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
             "access_key",
             "access_key_secret",
+            "source",
         }
         
         class properties:
+            source = schemas.AnyTypeSchema
             access_key = schemas.StrSchema
             access_key_secret = schemas.StrSchema
             __annotations__ = {
+                "source": source,
                 "access_key": access_key,
                 "access_key_secret": access_key_secret,
             }
     
     access_key: MetaOapg.properties.access_key
     access_key_secret: MetaOapg.properties.access_key_secret
+    source: MetaOapg.properties.source
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["access_key"]) -> MetaOapg.properties.access_key: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["access_key_secret"]) -> MetaOapg.properties.access_key_secret: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["access_key", "access_key_secret", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["source", "access_key", "access_key_secret", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["access_key"]) -> MetaOapg.properties.access_key: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["access_key_secret"]) -> MetaOapg.properties.access_key_secret: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["access_key", "access_key_secret", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["source", "access_key", "access_key_secret", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         access_key: typing.Union[MetaOapg.properties.access_key, str, ],
         access_key_secret: typing.Union[MetaOapg.properties.access_key_secret, str, ],
+        source: typing.Union[MetaOapg.properties.source, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'S3AuthRequest':
+    ) -> 'S3Authentication':
         return super().__new__(
             cls,
             *args,
             access_key=access_key,
             access_key_secret=access_key_secret,
+            source=source,
             _configuration=_configuration,
             **kwargs,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/s3_auth_request.pyi` & `carbon_python_sdk-0.2.0/carbon/model/s3_authentication.pyi`

 * *Files 14% similar despite different names*

```diff
@@ -19,75 +19,87 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class S3AuthRequest(
+class S3Authentication(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
             "access_key",
             "access_key_secret",
+            "source",
         }
         
         class properties:
+            source = schemas.AnyTypeSchema
             access_key = schemas.StrSchema
             access_key_secret = schemas.StrSchema
             __annotations__ = {
+                "source": source,
                 "access_key": access_key,
                 "access_key_secret": access_key_secret,
             }
     
     access_key: MetaOapg.properties.access_key
     access_key_secret: MetaOapg.properties.access_key_secret
+    source: MetaOapg.properties.source
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["access_key"]) -> MetaOapg.properties.access_key: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["access_key_secret"]) -> MetaOapg.properties.access_key_secret: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["access_key", "access_key_secret", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["source", "access_key", "access_key_secret", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["access_key"]) -> MetaOapg.properties.access_key: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["access_key_secret"]) -> MetaOapg.properties.access_key_secret: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["access_key", "access_key_secret", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["source", "access_key", "access_key_secret", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         access_key: typing.Union[MetaOapg.properties.access_key, str, ],
         access_key_secret: typing.Union[MetaOapg.properties.access_key_secret, str, ],
+        source: typing.Union[MetaOapg.properties.source, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'S3AuthRequest':
+    ) -> 'S3Authentication':
         return super().__new__(
             cls,
             *args,
             access_key=access_key,
             access_key_secret=access_key_secret,
+            source=source,
             _configuration=_configuration,
             **kwargs,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/s3_authentication.py` & `carbon_python_sdk-0.2.0/carbon/model/s3_auth_request.py`

 * *Files 13% similar despite different names*

```diff
@@ -19,87 +19,85 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class S3Authentication(
+class S3AuthRequest(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
             "access_key",
             "access_key_secret",
-            "source",
         }
         
         class properties:
-            source = schemas.AnyTypeSchema
             access_key = schemas.StrSchema
             access_key_secret = schemas.StrSchema
+            sync_source_items = schemas.BoolSchema
             __annotations__ = {
-                "source": source,
                 "access_key": access_key,
                 "access_key_secret": access_key_secret,
+                "sync_source_items": sync_source_items,
             }
     
     access_key: MetaOapg.properties.access_key
     access_key_secret: MetaOapg.properties.access_key_secret
-    source: MetaOapg.properties.source
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["access_key"]) -> MetaOapg.properties.access_key: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["access_key_secret"]) -> MetaOapg.properties.access_key_secret: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["sync_source_items"]) -> MetaOapg.properties.sync_source_items: ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["source", "access_key", "access_key_secret", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["access_key", "access_key_secret", "sync_source_items", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
-    
-    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["access_key"]) -> MetaOapg.properties.access_key: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["access_key_secret"]) -> MetaOapg.properties.access_key_secret: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_source_items"]) -> typing.Union[MetaOapg.properties.sync_source_items, schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["source", "access_key", "access_key_secret", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["access_key", "access_key_secret", "sync_source_items", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         access_key: typing.Union[MetaOapg.properties.access_key, str, ],
         access_key_secret: typing.Union[MetaOapg.properties.access_key_secret, str, ],
-        source: typing.Union[MetaOapg.properties.source, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
+        sync_source_items: typing.Union[MetaOapg.properties.sync_source_items, bool, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'S3Authentication':
+    ) -> 'S3AuthRequest':
         return super().__new__(
             cls,
             *args,
             access_key=access_key,
             access_key_secret=access_key_secret,
-            source=source,
+            sync_source_items=sync_source_items,
             _configuration=_configuration,
             **kwargs,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/s3_authentication.pyi` & `carbon_python_sdk-0.2.0/carbon/model/s3_auth_request.pyi`

 * *Files 13% similar despite different names*

```diff
@@ -19,87 +19,85 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class S3Authentication(
+class S3AuthRequest(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
             "access_key",
             "access_key_secret",
-            "source",
         }
         
         class properties:
-            source = schemas.AnyTypeSchema
             access_key = schemas.StrSchema
             access_key_secret = schemas.StrSchema
+            sync_source_items = schemas.BoolSchema
             __annotations__ = {
-                "source": source,
                 "access_key": access_key,
                 "access_key_secret": access_key_secret,
+                "sync_source_items": sync_source_items,
             }
     
     access_key: MetaOapg.properties.access_key
     access_key_secret: MetaOapg.properties.access_key_secret
-    source: MetaOapg.properties.source
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["access_key"]) -> MetaOapg.properties.access_key: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["access_key_secret"]) -> MetaOapg.properties.access_key_secret: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["sync_source_items"]) -> MetaOapg.properties.sync_source_items: ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["source", "access_key", "access_key_secret", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["access_key", "access_key_secret", "sync_source_items", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
-    
-    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["access_key"]) -> MetaOapg.properties.access_key: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["access_key_secret"]) -> MetaOapg.properties.access_key_secret: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_source_items"]) -> typing.Union[MetaOapg.properties.sync_source_items, schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["source", "access_key", "access_key_secret", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["access_key", "access_key_secret", "sync_source_items", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         access_key: typing.Union[MetaOapg.properties.access_key, str, ],
         access_key_secret: typing.Union[MetaOapg.properties.access_key_secret, str, ],
-        source: typing.Union[MetaOapg.properties.source, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
+        sync_source_items: typing.Union[MetaOapg.properties.sync_source_items, bool, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'S3Authentication':
+    ) -> 'S3AuthRequest':
         return super().__new__(
             cls,
             *args,
             access_key=access_key,
             access_key_secret=access_key_secret,
-            source=source,
+            sync_source_items=sync_source_items,
             _configuration=_configuration,
             **kwargs,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/s3_file_sync_input.py` & `carbon_python_sdk-0.2.0/carbon/model/sync_options.py`

 * *Files 7% similar despite different names*

```diff
@@ -19,76 +19,26 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class S3FileSyncInput(
+class SyncOptions(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
-        required = {
-            "ids",
-        }
         
         class properties:
-            
-            
-            class ids(
-                schemas.ListSchema
-            ):
-            
-            
-                class MetaOapg:
-                    
-                    @staticmethod
-                    def items() -> typing.Type['S3GetFileInput']:
-                        return S3GetFileInput
-            
-                def __new__(
-                    cls,
-                    arg: typing.Union[typing.Tuple['S3GetFileInput'], typing.List['S3GetFileInput']],
-                    _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'ids':
-                    return super().__new__(
-                        cls,
-                        arg,
-                        _configuration=_configuration,
-                    )
-            
-                def __getitem__(self, i: int) -> 'S3GetFileInput':
-                    return super().__getitem__(i)
-            
-            
-            class tags(
-                schemas.DictBase,
-                schemas.NoneBase,
-                schemas.Schema,
-                schemas.NoneFrozenDictMixin
-            ):
-            
-            
-                def __new__(
-                    cls,
-                    *args: typing.Union[dict, frozendict.frozendict, None, ],
-                    _configuration: typing.Optional[schemas.Configuration] = None,
-                    **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-                ) -> 'tags':
-                    return super().__new__(
-                        cls,
-                        *args,
-                        _configuration=_configuration,
-                        **kwargs,
-                    )
+            tags = schemas.AnyTypeSchema
             
             
             class chunk_size(
                 schemas.IntBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneDecimalMixin
@@ -143,16 +93,16 @@
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
         
             @staticmethod
-            def embedding_model() -> typing.Type['EmbeddingGenerators']:
-                return EmbeddingGenerators
+            def embedding_model() -> typing.Type['EmbeddingGeneratorsNullable']:
+                return EmbeddingGeneratorsNullable
             
             
             class generate_sparse_vectors(
                 schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneBoolMixin
@@ -205,162 +155,204 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'max_items_per_chunk':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
-            set_page_as_boundary = schemas.BoolSchema
             
             
-            class data_source_id(
-                schemas.IntBase,
+            class sync_files_on_connection(
+                schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
-                schemas.NoneDecimalMixin
+                schemas.NoneBoolMixin
             ):
             
             
                 def __new__(
                     cls,
-                    *args: typing.Union[None, decimal.Decimal, int, ],
+                    *args: typing.Union[None, bool, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'data_source_id':
+                ) -> 'sync_files_on_connection':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            set_page_as_boundary = schemas.BoolSchema
+            request_id = schemas.StrSchema
+            enable_file_picker = schemas.BoolSchema
+            sync_source_items = schemas.BoolSchema
+            incremental_sync = schemas.BoolSchema
+        
+            @staticmethod
+            def file_sync_config() -> typing.Type['FileSyncConfigNullable']:
+                return FileSyncConfigNullable
             __annotations__ = {
-                "ids": ids,
                 "tags": tags,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
                 "embedding_model": embedding_model,
                 "generate_sparse_vectors": generate_sparse_vectors,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
                 "max_items_per_chunk": max_items_per_chunk,
+                "sync_files_on_connection": sync_files_on_connection,
                 "set_page_as_boundary": set_page_as_boundary,
-                "data_source_id": data_source_id,
+                "request_id": request_id,
+                "enable_file_picker": enable_file_picker,
+                "sync_source_items": sync_source_items,
+                "incremental_sync": incremental_sync,
+                "file_sync_config": file_sync_config,
             }
     
-    ids: MetaOapg.properties.ids
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["ids"]) -> MetaOapg.properties.ids: ...
-    
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_size"]) -> MetaOapg.properties.chunk_size: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> MetaOapg.properties.skip_embedding_generation: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
+    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGeneratorsNullable': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["max_items_per_chunk"]) -> MetaOapg.properties.max_items_per_chunk: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["sync_files_on_connection"]) -> MetaOapg.properties.sync_files_on_connection: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["set_page_as_boundary"]) -> MetaOapg.properties.set_page_as_boundary: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["enable_file_picker"]) -> MetaOapg.properties.enable_file_picker: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["sync_source_items"]) -> MetaOapg.properties.sync_source_items: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["incremental_sync"]) -> MetaOapg.properties.incremental_sync: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["file_sync_config"]) -> 'FileSyncConfigNullable': ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["ids", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "set_page_as_boundary", "data_source_id", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "sync_files_on_connection", "set_page_as_boundary", "request_id", "enable_file_picker", "sync_source_items", "incremental_sync", "file_sync_config", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["ids"]) -> MetaOapg.properties.ids: ...
-    
-    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union[MetaOapg.properties.tags, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_size"]) -> typing.Union[MetaOapg.properties.chunk_size, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_overlap"]) -> typing.Union[MetaOapg.properties.chunk_overlap, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> typing.Union[MetaOapg.properties.skip_embedding_generation, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGeneratorsNullable', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> typing.Union[MetaOapg.properties.generate_sparse_vectors, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["max_items_per_chunk"]) -> typing.Union[MetaOapg.properties.max_items_per_chunk, schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_files_on_connection"]) -> typing.Union[MetaOapg.properties.sync_files_on_connection, schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["set_page_as_boundary"]) -> typing.Union[MetaOapg.properties.set_page_as_boundary, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> typing.Union[MetaOapg.properties.data_source_id, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> typing.Union[MetaOapg.properties.request_id, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["enable_file_picker"]) -> typing.Union[MetaOapg.properties.enable_file_picker, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_source_items"]) -> typing.Union[MetaOapg.properties.sync_source_items, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["incremental_sync"]) -> typing.Union[MetaOapg.properties.incremental_sync, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["file_sync_config"]) -> typing.Union['FileSyncConfigNullable', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["ids", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "set_page_as_boundary", "data_source_id", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "sync_files_on_connection", "set_page_as_boundary", "request_id", "enable_file_picker", "sync_source_items", "incremental_sync", "file_sync_config", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        ids: typing.Union[MetaOapg.properties.ids, list, tuple, ],
-        tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
+        tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, schemas.Unset] = schemas.unset,
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
-        embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
+        embedding_model: typing.Union['EmbeddingGeneratorsNullable', schemas.Unset] = schemas.unset,
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
         max_items_per_chunk: typing.Union[MetaOapg.properties.max_items_per_chunk, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        sync_files_on_connection: typing.Union[MetaOapg.properties.sync_files_on_connection, None, bool, schemas.Unset] = schemas.unset,
         set_page_as_boundary: typing.Union[MetaOapg.properties.set_page_as_boundary, bool, schemas.Unset] = schemas.unset,
-        data_source_id: typing.Union[MetaOapg.properties.data_source_id, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        request_id: typing.Union[MetaOapg.properties.request_id, str, schemas.Unset] = schemas.unset,
+        enable_file_picker: typing.Union[MetaOapg.properties.enable_file_picker, bool, schemas.Unset] = schemas.unset,
+        sync_source_items: typing.Union[MetaOapg.properties.sync_source_items, bool, schemas.Unset] = schemas.unset,
+        incremental_sync: typing.Union[MetaOapg.properties.incremental_sync, bool, schemas.Unset] = schemas.unset,
+        file_sync_config: typing.Union['FileSyncConfigNullable', schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'S3FileSyncInput':
+    ) -> 'SyncOptions':
         return super().__new__(
             cls,
             *args,
-            ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            sync_files_on_connection=sync_files_on_connection,
             set_page_as_boundary=set_page_as_boundary,
-            data_source_id=data_source_id,
+            request_id=request_id,
+            enable_file_picker=enable_file_picker,
+            sync_source_items=sync_source_items,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
             _configuration=_configuration,
             **kwargs,
         )
 
-from carbon.model.embedding_generators import EmbeddingGenerators
-from carbon.model.s3_get_file_input import S3GetFileInput
+from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/s3_file_sync_input.pyi` & `carbon_python_sdk-0.2.0/carbon/model/sync_options.pyi`

 * *Files 7% similar despite different names*

```diff
@@ -19,76 +19,26 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class S3FileSyncInput(
+class SyncOptions(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
-        required = {
-            "ids",
-        }
         
         class properties:
-            
-            
-            class ids(
-                schemas.ListSchema
-            ):
-            
-            
-                class MetaOapg:
-                    
-                    @staticmethod
-                    def items() -> typing.Type['S3GetFileInput']:
-                        return S3GetFileInput
-            
-                def __new__(
-                    cls,
-                    arg: typing.Union[typing.Tuple['S3GetFileInput'], typing.List['S3GetFileInput']],
-                    _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'ids':
-                    return super().__new__(
-                        cls,
-                        arg,
-                        _configuration=_configuration,
-                    )
-            
-                def __getitem__(self, i: int) -> 'S3GetFileInput':
-                    return super().__getitem__(i)
-            
-            
-            class tags(
-                schemas.DictBase,
-                schemas.NoneBase,
-                schemas.Schema,
-                schemas.NoneFrozenDictMixin
-            ):
-            
-            
-                def __new__(
-                    cls,
-                    *args: typing.Union[dict, frozendict.frozendict, None, ],
-                    _configuration: typing.Optional[schemas.Configuration] = None,
-                    **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-                ) -> 'tags':
-                    return super().__new__(
-                        cls,
-                        *args,
-                        _configuration=_configuration,
-                        **kwargs,
-                    )
+            tags = schemas.AnyTypeSchema
             
             
             class chunk_size(
                 schemas.IntBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneDecimalMixin
@@ -143,16 +93,16 @@
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
         
             @staticmethod
-            def embedding_model() -> typing.Type['EmbeddingGenerators']:
-                return EmbeddingGenerators
+            def embedding_model() -> typing.Type['EmbeddingGeneratorsNullable']:
+                return EmbeddingGeneratorsNullable
             
             
             class generate_sparse_vectors(
                 schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneBoolMixin
@@ -205,162 +155,204 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'max_items_per_chunk':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
-            set_page_as_boundary = schemas.BoolSchema
             
             
-            class data_source_id(
-                schemas.IntBase,
+            class sync_files_on_connection(
+                schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
-                schemas.NoneDecimalMixin
+                schemas.NoneBoolMixin
             ):
             
             
                 def __new__(
                     cls,
-                    *args: typing.Union[None, decimal.Decimal, int, ],
+                    *args: typing.Union[None, bool, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'data_source_id':
+                ) -> 'sync_files_on_connection':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            set_page_as_boundary = schemas.BoolSchema
+            request_id = schemas.StrSchema
+            enable_file_picker = schemas.BoolSchema
+            sync_source_items = schemas.BoolSchema
+            incremental_sync = schemas.BoolSchema
+        
+            @staticmethod
+            def file_sync_config() -> typing.Type['FileSyncConfigNullable']:
+                return FileSyncConfigNullable
             __annotations__ = {
-                "ids": ids,
                 "tags": tags,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
                 "embedding_model": embedding_model,
                 "generate_sparse_vectors": generate_sparse_vectors,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
                 "max_items_per_chunk": max_items_per_chunk,
+                "sync_files_on_connection": sync_files_on_connection,
                 "set_page_as_boundary": set_page_as_boundary,
-                "data_source_id": data_source_id,
+                "request_id": request_id,
+                "enable_file_picker": enable_file_picker,
+                "sync_source_items": sync_source_items,
+                "incremental_sync": incremental_sync,
+                "file_sync_config": file_sync_config,
             }
     
-    ids: MetaOapg.properties.ids
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["ids"]) -> MetaOapg.properties.ids: ...
-    
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_size"]) -> MetaOapg.properties.chunk_size: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> MetaOapg.properties.skip_embedding_generation: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
+    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGeneratorsNullable': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["max_items_per_chunk"]) -> MetaOapg.properties.max_items_per_chunk: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["sync_files_on_connection"]) -> MetaOapg.properties.sync_files_on_connection: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["set_page_as_boundary"]) -> MetaOapg.properties.set_page_as_boundary: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["enable_file_picker"]) -> MetaOapg.properties.enable_file_picker: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["sync_source_items"]) -> MetaOapg.properties.sync_source_items: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["incremental_sync"]) -> MetaOapg.properties.incremental_sync: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["file_sync_config"]) -> 'FileSyncConfigNullable': ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["ids", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "set_page_as_boundary", "data_source_id", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "sync_files_on_connection", "set_page_as_boundary", "request_id", "enable_file_picker", "sync_source_items", "incremental_sync", "file_sync_config", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["ids"]) -> MetaOapg.properties.ids: ...
-    
-    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union[MetaOapg.properties.tags, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_size"]) -> typing.Union[MetaOapg.properties.chunk_size, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_overlap"]) -> typing.Union[MetaOapg.properties.chunk_overlap, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> typing.Union[MetaOapg.properties.skip_embedding_generation, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGeneratorsNullable', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> typing.Union[MetaOapg.properties.generate_sparse_vectors, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["max_items_per_chunk"]) -> typing.Union[MetaOapg.properties.max_items_per_chunk, schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_files_on_connection"]) -> typing.Union[MetaOapg.properties.sync_files_on_connection, schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["set_page_as_boundary"]) -> typing.Union[MetaOapg.properties.set_page_as_boundary, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> typing.Union[MetaOapg.properties.data_source_id, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> typing.Union[MetaOapg.properties.request_id, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["enable_file_picker"]) -> typing.Union[MetaOapg.properties.enable_file_picker, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_source_items"]) -> typing.Union[MetaOapg.properties.sync_source_items, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["incremental_sync"]) -> typing.Union[MetaOapg.properties.incremental_sync, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["file_sync_config"]) -> typing.Union['FileSyncConfigNullable', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["ids", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "set_page_as_boundary", "data_source_id", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "sync_files_on_connection", "set_page_as_boundary", "request_id", "enable_file_picker", "sync_source_items", "incremental_sync", "file_sync_config", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        ids: typing.Union[MetaOapg.properties.ids, list, tuple, ],
-        tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
+        tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, schemas.Unset] = schemas.unset,
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
-        embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
+        embedding_model: typing.Union['EmbeddingGeneratorsNullable', schemas.Unset] = schemas.unset,
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
         max_items_per_chunk: typing.Union[MetaOapg.properties.max_items_per_chunk, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        sync_files_on_connection: typing.Union[MetaOapg.properties.sync_files_on_connection, None, bool, schemas.Unset] = schemas.unset,
         set_page_as_boundary: typing.Union[MetaOapg.properties.set_page_as_boundary, bool, schemas.Unset] = schemas.unset,
-        data_source_id: typing.Union[MetaOapg.properties.data_source_id, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        request_id: typing.Union[MetaOapg.properties.request_id, str, schemas.Unset] = schemas.unset,
+        enable_file_picker: typing.Union[MetaOapg.properties.enable_file_picker, bool, schemas.Unset] = schemas.unset,
+        sync_source_items: typing.Union[MetaOapg.properties.sync_source_items, bool, schemas.Unset] = schemas.unset,
+        incremental_sync: typing.Union[MetaOapg.properties.incremental_sync, bool, schemas.Unset] = schemas.unset,
+        file_sync_config: typing.Union['FileSyncConfigNullable', schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'S3FileSyncInput':
+    ) -> 'SyncOptions':
         return super().__new__(
             cls,
             *args,
-            ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            sync_files_on_connection=sync_files_on_connection,
             set_page_as_boundary=set_page_as_boundary,
-            data_source_id=data_source_id,
+            request_id=request_id,
+            enable_file_picker=enable_file_picker,
+            sync_source_items=sync_source_items,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
             _configuration=_configuration,
             **kwargs,
         )
 
-from carbon.model.embedding_generators import EmbeddingGenerators
-from carbon.model.s3_get_file_input import S3GetFileInput
+from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/s3_get_file_input.py` & `carbon_python_sdk-0.2.0/carbon/model/github_fetch_repos_request.py`

 * *Files 14% similar despite different names*

```diff
@@ -19,106 +19,97 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class S3GetFileInput(
+class GithubFetchReposRequest(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
+        required = {
+            "repos",
+        }
         
         class properties:
+        
+            @staticmethod
+            def repos() -> typing.Type['GithubFetchReposRequestRepos']:
+                return GithubFetchReposRequestRepos
             
             
-            class id(
-                schemas.StrBase,
-                schemas.NoneBase,
-                schemas.Schema,
-                schemas.NoneStrMixin
-            ):
-            
-            
-                def __new__(
-                    cls,
-                    *args: typing.Union[None, str, ],
-                    _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'id':
-                    return super().__new__(
-                        cls,
-                        *args,
-                        _configuration=_configuration,
-                    )
-            
-            
-            class bucket(
-                schemas.StrBase,
+            class data_source_id(
+                schemas.IntBase,
                 schemas.NoneBase,
                 schemas.Schema,
-                schemas.NoneStrMixin
+                schemas.NoneDecimalMixin
             ):
             
             
                 def __new__(
                     cls,
-                    *args: typing.Union[None, str, ],
+                    *args: typing.Union[None, decimal.Decimal, int, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'bucket':
+                ) -> 'data_source_id':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
             __annotations__ = {
-                "id": id,
-                "bucket": bucket,
+                "repos": repos,
+                "data_source_id": data_source_id,
             }
     
+    repos: 'GithubFetchReposRequestRepos'
+    
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
+    def __getitem__(self, name: typing_extensions.Literal["repos"]) -> 'GithubFetchReposRequestRepos': ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["bucket"]) -> MetaOapg.properties.bucket: ...
+    def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "bucket", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["repos", "data_source_id", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> typing.Union[MetaOapg.properties.id, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["repos"]) -> 'GithubFetchReposRequestRepos': ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["bucket"]) -> typing.Union[MetaOapg.properties.bucket, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> typing.Union[MetaOapg.properties.data_source_id, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "bucket", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["repos", "data_source_id", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        id: typing.Union[MetaOapg.properties.id, None, str, schemas.Unset] = schemas.unset,
-        bucket: typing.Union[MetaOapg.properties.bucket, None, str, schemas.Unset] = schemas.unset,
+        repos: 'GithubFetchReposRequestRepos',
+        data_source_id: typing.Union[MetaOapg.properties.data_source_id, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'S3GetFileInput':
+    ) -> 'GithubFetchReposRequest':
         return super().__new__(
             cls,
             *args,
-            id=id,
-            bucket=bucket,
+            repos=repos,
+            data_source_id=data_source_id,
             _configuration=_configuration,
             **kwargs,
         )
+
+from carbon.model.github_fetch_repos_request_repos import GithubFetchReposRequestRepos
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/s3_get_file_input.pyi` & `carbon_python_sdk-0.2.0/carbon/model/github_fetch_repos_request.pyi`

 * *Files 14% similar despite different names*

```diff
@@ -19,106 +19,97 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class S3GetFileInput(
+class GithubFetchReposRequest(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
+        required = {
+            "repos",
+        }
         
         class properties:
+        
+            @staticmethod
+            def repos() -> typing.Type['GithubFetchReposRequestRepos']:
+                return GithubFetchReposRequestRepos
             
             
-            class id(
-                schemas.StrBase,
-                schemas.NoneBase,
-                schemas.Schema,
-                schemas.NoneStrMixin
-            ):
-            
-            
-                def __new__(
-                    cls,
-                    *args: typing.Union[None, str, ],
-                    _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'id':
-                    return super().__new__(
-                        cls,
-                        *args,
-                        _configuration=_configuration,
-                    )
-            
-            
-            class bucket(
-                schemas.StrBase,
+            class data_source_id(
+                schemas.IntBase,
                 schemas.NoneBase,
                 schemas.Schema,
-                schemas.NoneStrMixin
+                schemas.NoneDecimalMixin
             ):
             
             
                 def __new__(
                     cls,
-                    *args: typing.Union[None, str, ],
+                    *args: typing.Union[None, decimal.Decimal, int, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'bucket':
+                ) -> 'data_source_id':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
             __annotations__ = {
-                "id": id,
-                "bucket": bucket,
+                "repos": repos,
+                "data_source_id": data_source_id,
             }
     
+    repos: 'GithubFetchReposRequestRepos'
+    
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
+    def __getitem__(self, name: typing_extensions.Literal["repos"]) -> 'GithubFetchReposRequestRepos': ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["bucket"]) -> MetaOapg.properties.bucket: ...
+    def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "bucket", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["repos", "data_source_id", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> typing.Union[MetaOapg.properties.id, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["repos"]) -> 'GithubFetchReposRequestRepos': ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["bucket"]) -> typing.Union[MetaOapg.properties.bucket, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> typing.Union[MetaOapg.properties.data_source_id, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "bucket", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["repos", "data_source_id", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        id: typing.Union[MetaOapg.properties.id, None, str, schemas.Unset] = schemas.unset,
-        bucket: typing.Union[MetaOapg.properties.bucket, None, str, schemas.Unset] = schemas.unset,
+        repos: 'GithubFetchReposRequestRepos',
+        data_source_id: typing.Union[MetaOapg.properties.data_source_id, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'S3GetFileInput':
+    ) -> 'GithubFetchReposRequest':
         return super().__new__(
             cls,
             *args,
-            id=id,
-            bucket=bucket,
+            repos=repos,
+            data_source_id=data_source_id,
             _configuration=_configuration,
             **kwargs,
         )
+
+from carbon.model.github_fetch_repos_request_repos import GithubFetchReposRequestRepos
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/salesforce_authentication.py` & `carbon_python_sdk-0.2.0/carbon/model/salesforce_authentication.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/salesforce_authentication.pyi` & `carbon_python_sdk-0.2.0/carbon/model/salesforce_authentication.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sharepoint_authentication.py` & `carbon_python_sdk-0.2.0/carbon/model/sharepoint_authentication.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sharepoint_authentication.pyi` & `carbon_python_sdk-0.2.0/carbon/model/sharepoint_authentication.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/simple_o_auth_data_sources.py` & `carbon_python_sdk-0.2.0/carbon/model/simple_o_auth_data_sources.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/simple_o_auth_data_sources.pyi` & `carbon_python_sdk-0.2.0/carbon/model/simple_o_auth_data_sources.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/single_chunks_and_embeddings_upload_input.py` & `carbon_python_sdk-0.2.0/carbon/model/single_chunks_and_embeddings_upload_input.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/single_chunks_and_embeddings_upload_input.pyi` & `carbon_python_sdk-0.2.0/carbon/model/single_chunks_and_embeddings_upload_input.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request.py` & `carbon_python_sdk-0.2.0/carbon/model/webscrape_request.py`

 * *Files 5% similar despite different names*

```diff
@@ -19,15 +19,15 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class SitemapScrapeRequest(
+class WebscrapeRequest(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
@@ -36,16 +36,40 @@
             "url",
         }
         
         class properties:
             url = schemas.StrSchema
         
             @staticmethod
-            def tags() -> typing.Type['SitemapScrapeRequestTags']:
-                return SitemapScrapeRequestTags
+            def tags() -> typing.Type['WebscrapeRequestTags']:
+                return WebscrapeRequestTags
+            
+            
+            class recursion_depth(
+                schemas.IntBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneDecimalMixin
+            ):
+            
+            
+                class MetaOapg:
+                    inclusive_minimum = 0
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, decimal.Decimal, int, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'recursion_depth':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             
             
             class max_pages_to_scrape(
                 schemas.IntBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneDecimalMixin
@@ -184,31 +208,32 @@
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
         
             @staticmethod
-            def html_tags_to_skip() -> typing.Type['SitemapScrapeRequestHtmlTagsToSkip']:
-                return SitemapScrapeRequestHtmlTagsToSkip
+            def html_tags_to_skip() -> typing.Type['WebscrapeRequestHtmlTagsToSkip']:
+                return WebscrapeRequestHtmlTagsToSkip
         
             @staticmethod
-            def css_classes_to_skip() -> typing.Type['SitemapScrapeRequestCssClassesToSkip']:
-                return SitemapScrapeRequestCssClassesToSkip
+            def css_classes_to_skip() -> typing.Type['WebscrapeRequestCssClassesToSkip']:
+                return WebscrapeRequestCssClassesToSkip
         
             @staticmethod
-            def css_selectors_to_skip() -> typing.Type['SitemapScrapeRequestCssSelectorsToSkip']:
-                return SitemapScrapeRequestCssSelectorsToSkip
+            def css_selectors_to_skip() -> typing.Type['WebscrapeRequestCssSelectorsToSkip']:
+                return WebscrapeRequestCssSelectorsToSkip
         
             @staticmethod
             def embedding_model() -> typing.Type['EmbeddingGenerators']:
                 return EmbeddingGenerators
             __annotations__ = {
                 "url": url,
                 "tags": tags,
+                "recursion_depth": recursion_depth,
                 "max_pages_to_scrape": max_pages_to_scrape,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
                 "enable_auto_sync": enable_auto_sync,
                 "generate_sparse_vectors": generate_sparse_vectors,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
@@ -220,15 +245,18 @@
     
     url: MetaOapg.properties.url
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["tags"]) -> 'SitemapScrapeRequestTags': ...
+    def __getitem__(self, name: typing_extensions.Literal["tags"]) -> 'WebscrapeRequestTags': ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["recursion_depth"]) -> MetaOapg.properties.recursion_depth: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["max_pages_to_scrape"]) -> MetaOapg.properties.max_pages_to_scrape: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_size"]) -> MetaOapg.properties.chunk_size: ...
     
@@ -244,38 +272,41 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["html_tags_to_skip"]) -> 'SitemapScrapeRequestHtmlTagsToSkip': ...
+    def __getitem__(self, name: typing_extensions.Literal["html_tags_to_skip"]) -> 'WebscrapeRequestHtmlTagsToSkip': ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["css_classes_to_skip"]) -> 'SitemapScrapeRequestCssClassesToSkip': ...
+    def __getitem__(self, name: typing_extensions.Literal["css_classes_to_skip"]) -> 'WebscrapeRequestCssClassesToSkip': ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["css_selectors_to_skip"]) -> 'SitemapScrapeRequestCssSelectorsToSkip': ...
+    def __getitem__(self, name: typing_extensions.Literal["css_selectors_to_skip"]) -> 'WebscrapeRequestCssSelectorsToSkip': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["url", "tags", "max_pages_to_scrape", "chunk_size", "chunk_overlap", "skip_embedding_generation", "enable_auto_sync", "generate_sparse_vectors", "prepend_filename_to_chunks", "html_tags_to_skip", "css_classes_to_skip", "css_selectors_to_skip", "embedding_model", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["url", "tags", "recursion_depth", "max_pages_to_scrape", "chunk_size", "chunk_overlap", "skip_embedding_generation", "enable_auto_sync", "generate_sparse_vectors", "prepend_filename_to_chunks", "html_tags_to_skip", "css_classes_to_skip", "css_selectors_to_skip", "embedding_model", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union['SitemapScrapeRequestTags', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union['WebscrapeRequestTags', schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["recursion_depth"]) -> typing.Union[MetaOapg.properties.recursion_depth, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["max_pages_to_scrape"]) -> typing.Union[MetaOapg.properties.max_pages_to_scrape, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_size"]) -> typing.Union[MetaOapg.properties.chunk_size, schemas.Unset]: ...
     
@@ -291,56 +322,58 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> typing.Union[MetaOapg.properties.generate_sparse_vectors, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["html_tags_to_skip"]) -> typing.Union['SitemapScrapeRequestHtmlTagsToSkip', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["html_tags_to_skip"]) -> typing.Union['WebscrapeRequestHtmlTagsToSkip', schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["css_classes_to_skip"]) -> typing.Union['SitemapScrapeRequestCssClassesToSkip', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["css_classes_to_skip"]) -> typing.Union['WebscrapeRequestCssClassesToSkip', schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["css_selectors_to_skip"]) -> typing.Union['SitemapScrapeRequestCssSelectorsToSkip', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["css_selectors_to_skip"]) -> typing.Union['WebscrapeRequestCssSelectorsToSkip', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["url", "tags", "max_pages_to_scrape", "chunk_size", "chunk_overlap", "skip_embedding_generation", "enable_auto_sync", "generate_sparse_vectors", "prepend_filename_to_chunks", "html_tags_to_skip", "css_classes_to_skip", "css_selectors_to_skip", "embedding_model", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["url", "tags", "recursion_depth", "max_pages_to_scrape", "chunk_size", "chunk_overlap", "skip_embedding_generation", "enable_auto_sync", "generate_sparse_vectors", "prepend_filename_to_chunks", "html_tags_to_skip", "css_classes_to_skip", "css_selectors_to_skip", "embedding_model", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         url: typing.Union[MetaOapg.properties.url, str, ],
-        tags: typing.Union['SitemapScrapeRequestTags', schemas.Unset] = schemas.unset,
+        tags: typing.Union['WebscrapeRequestTags', schemas.Unset] = schemas.unset,
+        recursion_depth: typing.Union[MetaOapg.properties.recursion_depth, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         max_pages_to_scrape: typing.Union[MetaOapg.properties.max_pages_to_scrape, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
         enable_auto_sync: typing.Union[MetaOapg.properties.enable_auto_sync, None, bool, schemas.Unset] = schemas.unset,
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
-        html_tags_to_skip: typing.Union['SitemapScrapeRequestHtmlTagsToSkip', schemas.Unset] = schemas.unset,
-        css_classes_to_skip: typing.Union['SitemapScrapeRequestCssClassesToSkip', schemas.Unset] = schemas.unset,
-        css_selectors_to_skip: typing.Union['SitemapScrapeRequestCssSelectorsToSkip', schemas.Unset] = schemas.unset,
+        html_tags_to_skip: typing.Union['WebscrapeRequestHtmlTagsToSkip', schemas.Unset] = schemas.unset,
+        css_classes_to_skip: typing.Union['WebscrapeRequestCssClassesToSkip', schemas.Unset] = schemas.unset,
+        css_selectors_to_skip: typing.Union['WebscrapeRequestCssSelectorsToSkip', schemas.Unset] = schemas.unset,
         embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'SitemapScrapeRequest':
+    ) -> 'WebscrapeRequest':
         return super().__new__(
             cls,
             *args,
             url=url,
             tags=tags,
+            recursion_depth=recursion_depth,
             max_pages_to_scrape=max_pages_to_scrape,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             enable_auto_sync=enable_auto_sync,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
@@ -349,11 +382,11 @@
             css_selectors_to_skip=css_selectors_to_skip,
             embedding_model=embedding_model,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.embedding_generators import EmbeddingGenerators
-from carbon.model.sitemap_scrape_request_css_classes_to_skip import SitemapScrapeRequestCssClassesToSkip
-from carbon.model.sitemap_scrape_request_css_selectors_to_skip import SitemapScrapeRequestCssSelectorsToSkip
-from carbon.model.sitemap_scrape_request_html_tags_to_skip import SitemapScrapeRequestHtmlTagsToSkip
-from carbon.model.sitemap_scrape_request_tags import SitemapScrapeRequestTags
+from carbon.model.webscrape_request_css_classes_to_skip import WebscrapeRequestCssClassesToSkip
+from carbon.model.webscrape_request_css_selectors_to_skip import WebscrapeRequestCssSelectorsToSkip
+from carbon.model.webscrape_request_html_tags_to_skip import WebscrapeRequestHtmlTagsToSkip
+from carbon.model.webscrape_request_tags import WebscrapeRequestTags
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request.pyi` & `carbon_python_sdk-0.2.0/carbon/model/gmail_sync_input.py`

 * *Files 8% similar despite different names*

```diff
@@ -19,55 +19,50 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class SitemapScrapeRequest(
+class GmailSyncInput(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
-            "url",
+            "filters",
         }
         
         class properties:
-            url = schemas.StrSchema
-        
-            @staticmethod
-            def tags() -> typing.Type['SitemapScrapeRequestTags']:
-                return SitemapScrapeRequestTags
+            filters = schemas.DictSchema
             
             
-            class max_pages_to_scrape(
-                schemas.IntBase,
+            class tags(
+                schemas.DictBase,
                 schemas.NoneBase,
                 schemas.Schema,
-                schemas.NoneDecimalMixin
+                schemas.NoneFrozenDictMixin
             ):
             
             
-                class MetaOapg:
-            
-            
                 def __new__(
                     cls,
-                    *args: typing.Union[None, decimal.Decimal, int, ],
+                    *args: typing.Union[dict, frozendict.frozendict, None, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'max_pages_to_scrape':
+                    **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
+                ) -> 'tags':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
+                        **kwargs,
                     )
             
             
             class chunk_size(
                 schemas.IntBase,
                 schemas.NoneBase,
                 schemas.Schema,
@@ -121,238 +116,268 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'skip_embedding_generation':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+        
+            @staticmethod
+            def embedding_model() -> typing.Type['EmbeddingGenerators']:
+                return EmbeddingGenerators
             
             
-            class enable_auto_sync(
+            class generate_sparse_vectors(
                 schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneBoolMixin
             ):
             
             
                 def __new__(
                     cls,
                     *args: typing.Union[None, bool, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'enable_auto_sync':
+                ) -> 'generate_sparse_vectors':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
             
             
-            class generate_sparse_vectors(
+            class prepend_filename_to_chunks(
                 schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneBoolMixin
             ):
             
             
                 def __new__(
                     cls,
                     *args: typing.Union[None, bool, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'generate_sparse_vectors':
+                ) -> 'prepend_filename_to_chunks':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
             
             
-            class prepend_filename_to_chunks(
+            class data_source_id(
+                schemas.IntBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneDecimalMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, decimal.Decimal, int, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'data_source_id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class request_id(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'request_id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class sync_attachments(
                 schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneBoolMixin
             ):
             
             
                 def __new__(
                     cls,
                     *args: typing.Union[None, bool, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'prepend_filename_to_chunks':
+                ) -> 'sync_attachments':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
         
             @staticmethod
-            def html_tags_to_skip() -> typing.Type['SitemapScrapeRequestHtmlTagsToSkip']:
-                return SitemapScrapeRequestHtmlTagsToSkip
-        
-            @staticmethod
-            def css_classes_to_skip() -> typing.Type['SitemapScrapeRequestCssClassesToSkip']:
-                return SitemapScrapeRequestCssClassesToSkip
-        
-            @staticmethod
-            def css_selectors_to_skip() -> typing.Type['SitemapScrapeRequestCssSelectorsToSkip']:
-                return SitemapScrapeRequestCssSelectorsToSkip
-        
-            @staticmethod
-            def embedding_model() -> typing.Type['EmbeddingGenerators']:
-                return EmbeddingGenerators
+            def file_sync_config() -> typing.Type['FileSyncConfigNullable']:
+                return FileSyncConfigNullable
+            incremental_sync = schemas.BoolSchema
             __annotations__ = {
-                "url": url,
+                "filters": filters,
                 "tags": tags,
-                "max_pages_to_scrape": max_pages_to_scrape,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
-                "enable_auto_sync": enable_auto_sync,
+                "embedding_model": embedding_model,
                 "generate_sparse_vectors": generate_sparse_vectors,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
-                "html_tags_to_skip": html_tags_to_skip,
-                "css_classes_to_skip": css_classes_to_skip,
-                "css_selectors_to_skip": css_selectors_to_skip,
-                "embedding_model": embedding_model,
+                "data_source_id": data_source_id,
+                "request_id": request_id,
+                "sync_attachments": sync_attachments,
+                "file_sync_config": file_sync_config,
+                "incremental_sync": incremental_sync,
             }
     
-    url: MetaOapg.properties.url
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
+    filters: MetaOapg.properties.filters
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["tags"]) -> 'SitemapScrapeRequestTags': ...
+    def __getitem__(self, name: typing_extensions.Literal["filters"]) -> MetaOapg.properties.filters: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["max_pages_to_scrape"]) -> MetaOapg.properties.max_pages_to_scrape: ...
+    def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_size"]) -> MetaOapg.properties.chunk_size: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> MetaOapg.properties.skip_embedding_generation: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["enable_auto_sync"]) -> MetaOapg.properties.enable_auto_sync: ...
+    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["html_tags_to_skip"]) -> 'SitemapScrapeRequestHtmlTagsToSkip': ...
+    def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["css_classes_to_skip"]) -> 'SitemapScrapeRequestCssClassesToSkip': ...
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["css_selectors_to_skip"]) -> 'SitemapScrapeRequestCssSelectorsToSkip': ...
+    def __getitem__(self, name: typing_extensions.Literal["sync_attachments"]) -> MetaOapg.properties.sync_attachments: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
+    def __getitem__(self, name: typing_extensions.Literal["file_sync_config"]) -> 'FileSyncConfigNullable': ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["incremental_sync"]) -> MetaOapg.properties.incremental_sync: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["url", "tags", "max_pages_to_scrape", "chunk_size", "chunk_overlap", "skip_embedding_generation", "enable_auto_sync", "generate_sparse_vectors", "prepend_filename_to_chunks", "html_tags_to_skip", "css_classes_to_skip", "css_selectors_to_skip", "embedding_model", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["filters", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "data_source_id", "request_id", "sync_attachments", "file_sync_config", "incremental_sync", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["filters"]) -> MetaOapg.properties.filters: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union['SitemapScrapeRequestTags', schemas.Unset]: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["max_pages_to_scrape"]) -> typing.Union[MetaOapg.properties.max_pages_to_scrape, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union[MetaOapg.properties.tags, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_size"]) -> typing.Union[MetaOapg.properties.chunk_size, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_overlap"]) -> typing.Union[MetaOapg.properties.chunk_overlap, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> typing.Union[MetaOapg.properties.skip_embedding_generation, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["enable_auto_sync"]) -> typing.Union[MetaOapg.properties.enable_auto_sync, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> typing.Union[MetaOapg.properties.generate_sparse_vectors, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["html_tags_to_skip"]) -> typing.Union['SitemapScrapeRequestHtmlTagsToSkip', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> typing.Union[MetaOapg.properties.data_source_id, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["css_classes_to_skip"]) -> typing.Union['SitemapScrapeRequestCssClassesToSkip', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> typing.Union[MetaOapg.properties.request_id, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["css_selectors_to_skip"]) -> typing.Union['SitemapScrapeRequestCssSelectorsToSkip', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_attachments"]) -> typing.Union[MetaOapg.properties.sync_attachments, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["file_sync_config"]) -> typing.Union['FileSyncConfigNullable', schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["incremental_sync"]) -> typing.Union[MetaOapg.properties.incremental_sync, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["url", "tags", "max_pages_to_scrape", "chunk_size", "chunk_overlap", "skip_embedding_generation", "enable_auto_sync", "generate_sparse_vectors", "prepend_filename_to_chunks", "html_tags_to_skip", "css_classes_to_skip", "css_selectors_to_skip", "embedding_model", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["filters", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "data_source_id", "request_id", "sync_attachments", "file_sync_config", "incremental_sync", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        url: typing.Union[MetaOapg.properties.url, str, ],
-        tags: typing.Union['SitemapScrapeRequestTags', schemas.Unset] = schemas.unset,
-        max_pages_to_scrape: typing.Union[MetaOapg.properties.max_pages_to_scrape, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        filters: typing.Union[MetaOapg.properties.filters, dict, frozendict.frozendict, ],
+        tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
-        enable_auto_sync: typing.Union[MetaOapg.properties.enable_auto_sync, None, bool, schemas.Unset] = schemas.unset,
+        embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
-        html_tags_to_skip: typing.Union['SitemapScrapeRequestHtmlTagsToSkip', schemas.Unset] = schemas.unset,
-        css_classes_to_skip: typing.Union['SitemapScrapeRequestCssClassesToSkip', schemas.Unset] = schemas.unset,
-        css_selectors_to_skip: typing.Union['SitemapScrapeRequestCssSelectorsToSkip', schemas.Unset] = schemas.unset,
-        embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
+        data_source_id: typing.Union[MetaOapg.properties.data_source_id, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        request_id: typing.Union[MetaOapg.properties.request_id, None, str, schemas.Unset] = schemas.unset,
+        sync_attachments: typing.Union[MetaOapg.properties.sync_attachments, None, bool, schemas.Unset] = schemas.unset,
+        file_sync_config: typing.Union['FileSyncConfigNullable', schemas.Unset] = schemas.unset,
+        incremental_sync: typing.Union[MetaOapg.properties.incremental_sync, bool, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'SitemapScrapeRequest':
+    ) -> 'GmailSyncInput':
         return super().__new__(
             cls,
             *args,
-            url=url,
+            filters=filters,
             tags=tags,
-            max_pages_to_scrape=max_pages_to_scrape,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
-            enable_auto_sync=enable_auto_sync,
+            embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            html_tags_to_skip=html_tags_to_skip,
-            css_classes_to_skip=css_classes_to_skip,
-            css_selectors_to_skip=css_selectors_to_skip,
-            embedding_model=embedding_model,
+            data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.embedding_generators import EmbeddingGenerators
-from carbon.model.sitemap_scrape_request_css_classes_to_skip import SitemapScrapeRequestCssClassesToSkip
-from carbon.model.sitemap_scrape_request_css_selectors_to_skip import SitemapScrapeRequestCssSelectorsToSkip
-from carbon.model.sitemap_scrape_request_html_tags_to_skip import SitemapScrapeRequestHtmlTagsToSkip
-from carbon.model.sitemap_scrape_request_tags import SitemapScrapeRequestTags
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request_css_classes_to_skip.py` & `carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request_css_classes_to_skip.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request_css_classes_to_skip.pyi` & `carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request_css_classes_to_skip.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request_css_selectors_to_skip.py` & `carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request_css_selectors_to_skip.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request_css_selectors_to_skip.pyi` & `carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request_css_selectors_to_skip.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request_html_tags_to_skip.py` & `carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request_html_tags_to_skip.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request_html_tags_to_skip.pyi` & `carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request_html_tags_to_skip.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request_tags.py` & `carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request_tags.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sitemap_scrape_request_tags.pyi` & `carbon_python_sdk-0.2.0/carbon/model/sitemap_scrape_request_tags.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sync_directory_request.py` & `carbon_python_sdk-0.2.0/carbon/model/sync_directory_request.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sync_directory_request.pyi` & `carbon_python_sdk-0.2.0/carbon/model/sync_directory_request.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sync_files_ids.py` & `carbon_python_sdk-0.2.0/carbon/model/validation_error.py`

 * *Files 14% similar despite different names*

```diff
@@ -19,75 +19,92 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class SyncFilesIds(
+class ValidationError(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
-            "root_id",
-            "id",
+            "msg",
+            "loc",
+            "type",
         }
         
         class properties:
-            id = schemas.StrSchema
-            root_id = schemas.StrSchema
+        
+            @staticmethod
+            def loc() -> typing.Type['ValidationErrorLoc']:
+                return ValidationErrorLoc
+            msg = schemas.StrSchema
+            type = schemas.StrSchema
             __annotations__ = {
-                "id": id,
-                "root_id": root_id,
+                "loc": loc,
+                "msg": msg,
+                "type": type,
             }
     
-    root_id: MetaOapg.properties.root_id
-    id: MetaOapg.properties.id
+    msg: MetaOapg.properties.msg
+    loc: 'ValidationErrorLoc'
+    type: MetaOapg.properties.type
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["loc"]) -> 'ValidationErrorLoc': ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
+    def __getitem__(self, name: typing_extensions.Literal["msg"]) -> MetaOapg.properties.msg: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["root_id"]) -> MetaOapg.properties.root_id: ...
+    def __getitem__(self, name: typing_extensions.Literal["type"]) -> MetaOapg.properties.type: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "root_id", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["loc", "msg", "type", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["loc"]) -> 'ValidationErrorLoc': ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["root_id"]) -> MetaOapg.properties.root_id: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["msg"]) -> MetaOapg.properties.msg: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["type"]) -> MetaOapg.properties.type: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "root_id", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["loc", "msg", "type", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        root_id: typing.Union[MetaOapg.properties.root_id, str, ],
-        id: typing.Union[MetaOapg.properties.id, str, ],
+        msg: typing.Union[MetaOapg.properties.msg, str, ],
+        loc: 'ValidationErrorLoc',
+        type: typing.Union[MetaOapg.properties.type, str, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'SyncFilesIds':
+    ) -> 'ValidationError':
         return super().__new__(
             cls,
             *args,
-            root_id=root_id,
-            id=id,
+            msg=msg,
+            loc=loc,
+            type=type,
             _configuration=_configuration,
             **kwargs,
         )
+
+from carbon.model.validation_error_loc import ValidationErrorLoc
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sync_files_ids.pyi` & `carbon_python_sdk-0.2.0/carbon/model/validation_error.pyi`

 * *Files 14% similar despite different names*

```diff
@@ -19,75 +19,92 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class SyncFilesIds(
+class ValidationError(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
-            "root_id",
-            "id",
+            "msg",
+            "loc",
+            "type",
         }
         
         class properties:
-            id = schemas.StrSchema
-            root_id = schemas.StrSchema
+        
+            @staticmethod
+            def loc() -> typing.Type['ValidationErrorLoc']:
+                return ValidationErrorLoc
+            msg = schemas.StrSchema
+            type = schemas.StrSchema
             __annotations__ = {
-                "id": id,
-                "root_id": root_id,
+                "loc": loc,
+                "msg": msg,
+                "type": type,
             }
     
-    root_id: MetaOapg.properties.root_id
-    id: MetaOapg.properties.id
+    msg: MetaOapg.properties.msg
+    loc: 'ValidationErrorLoc'
+    type: MetaOapg.properties.type
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["loc"]) -> 'ValidationErrorLoc': ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
+    def __getitem__(self, name: typing_extensions.Literal["msg"]) -> MetaOapg.properties.msg: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["root_id"]) -> MetaOapg.properties.root_id: ...
+    def __getitem__(self, name: typing_extensions.Literal["type"]) -> MetaOapg.properties.type: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "root_id", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["loc", "msg", "type", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["loc"]) -> 'ValidationErrorLoc': ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["root_id"]) -> MetaOapg.properties.root_id: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["msg"]) -> MetaOapg.properties.msg: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["type"]) -> MetaOapg.properties.type: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "root_id", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["loc", "msg", "type", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        root_id: typing.Union[MetaOapg.properties.root_id, str, ],
-        id: typing.Union[MetaOapg.properties.id, str, ],
+        msg: typing.Union[MetaOapg.properties.msg, str, ],
+        loc: 'ValidationErrorLoc',
+        type: typing.Union[MetaOapg.properties.type, str, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'SyncFilesIds':
+    ) -> 'ValidationError':
         return super().__new__(
             cls,
             *args,
-            root_id=root_id,
-            id=id,
+            msg=msg,
+            loc=loc,
+            type=type,
             _configuration=_configuration,
             **kwargs,
         )
+
+from carbon.model.validation_error_loc import ValidationErrorLoc
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sync_files_request.py` & `carbon_python_sdk-0.2.0/carbon/model/s3_file_sync_input.py`

 * *Files 11% similar despite different names*

```diff
@@ -19,117 +19,55 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class SyncFilesRequest(
+class S3FileSyncInput(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
             "ids",
-            "data_source_id",
         }
         
         class properties:
-            data_source_id = schemas.IntSchema
             
             
             class ids(
-                schemas.ComposedSchema,
+                schemas.ListSchema
             ):
             
             
                 class MetaOapg:
                     
-                    
-                    class any_of_0(
-                        schemas.ListSchema
-                    ):
-                    
-                    
-                        class MetaOapg:
-                            items = schemas.StrSchema
-                    
-                        def __new__(
-                            cls,
-                            arg: typing.Union[typing.Tuple[typing.Union[MetaOapg.items, str, ]], typing.List[typing.Union[MetaOapg.items, str, ]]],
-                            _configuration: typing.Optional[schemas.Configuration] = None,
-                        ) -> 'any_of_0':
-                            return super().__new__(
-                                cls,
-                                arg,
-                                _configuration=_configuration,
-                            )
-                    
-                        def __getitem__(self, i: int) -> MetaOapg.items:
-                            return super().__getitem__(i)
-                    
-                    
-                    class any_of_1(
-                        schemas.ListSchema
-                    ):
-                    
-                    
-                        class MetaOapg:
-                            
-                            @staticmethod
-                            def items() -> typing.Type['SyncFilesIds']:
-                                return SyncFilesIds
-                    
-                        def __new__(
-                            cls,
-                            arg: typing.Union[typing.Tuple['SyncFilesIds'], typing.List['SyncFilesIds']],
-                            _configuration: typing.Optional[schemas.Configuration] = None,
-                        ) -> 'any_of_1':
-                            return super().__new__(
-                                cls,
-                                arg,
-                                _configuration=_configuration,
-                            )
-                    
-                        def __getitem__(self, i: int) -> 'SyncFilesIds':
-                            return super().__getitem__(i)
-                    
-                    @classmethod
-                    @functools.lru_cache()
-                    def any_of(cls):
-                        # we need this here to make our import statements work
-                        # we must store _composed_schemas in here so the code is only run
-                        # when we invoke this method. If we kept this at the class
-                        # level we would get an error because the class level
-                        # code would be run when this module is imported, and these composed
-                        # classes don't exist yet because their module has not finished
-                        # loading
-                        return [
-                            cls.any_of_0,
-                            cls.any_of_1,
-                        ]
-            
+                    @staticmethod
+                    def items() -> typing.Type['S3GetFileInput']:
+                        return S3GetFileInput
             
                 def __new__(
                     cls,
-                    *args: typing.Union[dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
+                    arg: typing.Union[typing.Tuple['S3GetFileInput'], typing.List['S3GetFileInput']],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                    **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
                 ) -> 'ids':
                     return super().__new__(
                         cls,
-                        *args,
+                        arg,
                         _configuration=_configuration,
-                        **kwargs,
                     )
             
+                def __getitem__(self, i: int) -> 'S3GetFileInput':
+                    return super().__getitem__(i)
+            
             
             class tags(
                 schemas.DictBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneFrozenDictMixin
             ):
@@ -205,16 +143,16 @@
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
         
             @staticmethod
-            def embedding_model() -> typing.Type['EmbeddingGeneratorsNullable']:
-                return EmbeddingGeneratorsNullable
+            def embedding_model() -> typing.Type['EmbeddingGenerators']:
+                return EmbeddingGenerators
             
             
             class generate_sparse_vectors(
                 schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneBoolMixin
@@ -268,33 +206,117 @@
                 ) -> 'max_items_per_chunk':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
             set_page_as_boundary = schemas.BoolSchema
+            
+            
+            class data_source_id(
+                schemas.IntBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneDecimalMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, decimal.Decimal, int, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'data_source_id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class request_id(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'request_id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class use_ocr(
+                schemas.BoolBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneBoolMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, bool, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'use_ocr':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class parse_pdf_tables_with_ocr(
+                schemas.BoolBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneBoolMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, bool, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'parse_pdf_tables_with_ocr':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+        
+            @staticmethod
+            def file_sync_config() -> typing.Type['FileSyncConfigNullable']:
+                return FileSyncConfigNullable
             __annotations__ = {
-                "data_source_id": data_source_id,
                 "ids": ids,
                 "tags": tags,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
                 "embedding_model": embedding_model,
                 "generate_sparse_vectors": generate_sparse_vectors,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
                 "max_items_per_chunk": max_items_per_chunk,
                 "set_page_as_boundary": set_page_as_boundary,
+                "data_source_id": data_source_id,
+                "request_id": request_id,
+                "use_ocr": use_ocr,
+                "parse_pdf_tables_with_ocr": parse_pdf_tables_with_ocr,
+                "file_sync_config": file_sync_config,
             }
     
     ids: MetaOapg.properties.ids
-    data_source_id: MetaOapg.properties.data_source_id
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["ids"]) -> MetaOapg.properties.ids: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
     
@@ -304,40 +326,52 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> MetaOapg.properties.skip_embedding_generation: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGeneratorsNullable': ...
+    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["max_items_per_chunk"]) -> MetaOapg.properties.max_items_per_chunk: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["set_page_as_boundary"]) -> MetaOapg.properties.set_page_as_boundary: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["use_ocr"]) -> MetaOapg.properties.use_ocr: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["parse_pdf_tables_with_ocr"]) -> MetaOapg.properties.parse_pdf_tables_with_ocr: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["file_sync_config"]) -> 'FileSyncConfigNullable': ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["data_source_id", "ids", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "set_page_as_boundary", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["ids", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "set_page_as_boundary", "data_source_id", "request_id", "use_ocr", "parse_pdf_tables_with_ocr", "file_sync_config", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
-    
-    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["ids"]) -> MetaOapg.properties.ids: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union[MetaOapg.properties.tags, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_size"]) -> typing.Union[MetaOapg.properties.chunk_size, schemas.Unset]: ...
@@ -345,65 +379,89 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_overlap"]) -> typing.Union[MetaOapg.properties.chunk_overlap, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> typing.Union[MetaOapg.properties.skip_embedding_generation, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGeneratorsNullable', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> typing.Union[MetaOapg.properties.generate_sparse_vectors, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["max_items_per_chunk"]) -> typing.Union[MetaOapg.properties.max_items_per_chunk, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["set_page_as_boundary"]) -> typing.Union[MetaOapg.properties.set_page_as_boundary, schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> typing.Union[MetaOapg.properties.data_source_id, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> typing.Union[MetaOapg.properties.request_id, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["use_ocr"]) -> typing.Union[MetaOapg.properties.use_ocr, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["parse_pdf_tables_with_ocr"]) -> typing.Union[MetaOapg.properties.parse_pdf_tables_with_ocr, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["file_sync_config"]) -> typing.Union['FileSyncConfigNullable', schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["data_source_id", "ids", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "set_page_as_boundary", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["ids", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "set_page_as_boundary", "data_source_id", "request_id", "use_ocr", "parse_pdf_tables_with_ocr", "file_sync_config", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        ids: typing.Union[MetaOapg.properties.ids, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
-        data_source_id: typing.Union[MetaOapg.properties.data_source_id, decimal.Decimal, int, ],
+        ids: typing.Union[MetaOapg.properties.ids, list, tuple, ],
         tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
-        embedding_model: typing.Union['EmbeddingGeneratorsNullable', schemas.Unset] = schemas.unset,
+        embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
         max_items_per_chunk: typing.Union[MetaOapg.properties.max_items_per_chunk, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         set_page_as_boundary: typing.Union[MetaOapg.properties.set_page_as_boundary, bool, schemas.Unset] = schemas.unset,
+        data_source_id: typing.Union[MetaOapg.properties.data_source_id, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        request_id: typing.Union[MetaOapg.properties.request_id, None, str, schemas.Unset] = schemas.unset,
+        use_ocr: typing.Union[MetaOapg.properties.use_ocr, None, bool, schemas.Unset] = schemas.unset,
+        parse_pdf_tables_with_ocr: typing.Union[MetaOapg.properties.parse_pdf_tables_with_ocr, None, bool, schemas.Unset] = schemas.unset,
+        file_sync_config: typing.Union['FileSyncConfigNullable', schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'SyncFilesRequest':
+    ) -> 'S3FileSyncInput':
         return super().__new__(
             cls,
             *args,
             ids=ids,
-            data_source_id=data_source_id,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
             set_page_as_boundary=set_page_as_boundary,
+            data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            file_sync_config=file_sync_config,
             _configuration=_configuration,
             **kwargs,
         )
 
-from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable
-from carbon.model.sync_files_ids import SyncFilesIds
+from carbon.model.embedding_generators import EmbeddingGenerators
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable
+from carbon.model.s3_get_file_input import S3GetFileInput
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sync_files_request.pyi` & `carbon_python_sdk-0.2.0/carbon/model/s3_file_sync_input.pyi`

 * *Files 11% similar despite different names*

```diff
@@ -19,117 +19,55 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class SyncFilesRequest(
+class S3FileSyncInput(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
             "ids",
-            "data_source_id",
         }
         
         class properties:
-            data_source_id = schemas.IntSchema
             
             
             class ids(
-                schemas.ComposedSchema,
+                schemas.ListSchema
             ):
             
             
                 class MetaOapg:
                     
-                    
-                    class any_of_0(
-                        schemas.ListSchema
-                    ):
-                    
-                    
-                        class MetaOapg:
-                            items = schemas.StrSchema
-                    
-                        def __new__(
-                            cls,
-                            arg: typing.Union[typing.Tuple[typing.Union[MetaOapg.items, str, ]], typing.List[typing.Union[MetaOapg.items, str, ]]],
-                            _configuration: typing.Optional[schemas.Configuration] = None,
-                        ) -> 'any_of_0':
-                            return super().__new__(
-                                cls,
-                                arg,
-                                _configuration=_configuration,
-                            )
-                    
-                        def __getitem__(self, i: int) -> MetaOapg.items:
-                            return super().__getitem__(i)
-                    
-                    
-                    class any_of_1(
-                        schemas.ListSchema
-                    ):
-                    
-                    
-                        class MetaOapg:
-                            
-                            @staticmethod
-                            def items() -> typing.Type['SyncFilesIds']:
-                                return SyncFilesIds
-                    
-                        def __new__(
-                            cls,
-                            arg: typing.Union[typing.Tuple['SyncFilesIds'], typing.List['SyncFilesIds']],
-                            _configuration: typing.Optional[schemas.Configuration] = None,
-                        ) -> 'any_of_1':
-                            return super().__new__(
-                                cls,
-                                arg,
-                                _configuration=_configuration,
-                            )
-                    
-                        def __getitem__(self, i: int) -> 'SyncFilesIds':
-                            return super().__getitem__(i)
-                    
-                    @classmethod
-                    @functools.lru_cache()
-                    def any_of(cls):
-                        # we need this here to make our import statements work
-                        # we must store _composed_schemas in here so the code is only run
-                        # when we invoke this method. If we kept this at the class
-                        # level we would get an error because the class level
-                        # code would be run when this module is imported, and these composed
-                        # classes don't exist yet because their module has not finished
-                        # loading
-                        return [
-                            cls.any_of_0,
-                            cls.any_of_1,
-                        ]
-            
+                    @staticmethod
+                    def items() -> typing.Type['S3GetFileInput']:
+                        return S3GetFileInput
             
                 def __new__(
                     cls,
-                    *args: typing.Union[dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
+                    arg: typing.Union[typing.Tuple['S3GetFileInput'], typing.List['S3GetFileInput']],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                    **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
                 ) -> 'ids':
                     return super().__new__(
                         cls,
-                        *args,
+                        arg,
                         _configuration=_configuration,
-                        **kwargs,
                     )
             
+                def __getitem__(self, i: int) -> 'S3GetFileInput':
+                    return super().__getitem__(i)
+            
             
             class tags(
                 schemas.DictBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneFrozenDictMixin
             ):
@@ -205,16 +143,16 @@
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
         
             @staticmethod
-            def embedding_model() -> typing.Type['EmbeddingGeneratorsNullable']:
-                return EmbeddingGeneratorsNullable
+            def embedding_model() -> typing.Type['EmbeddingGenerators']:
+                return EmbeddingGenerators
             
             
             class generate_sparse_vectors(
                 schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneBoolMixin
@@ -268,33 +206,117 @@
                 ) -> 'max_items_per_chunk':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
             set_page_as_boundary = schemas.BoolSchema
+            
+            
+            class data_source_id(
+                schemas.IntBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneDecimalMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, decimal.Decimal, int, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'data_source_id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class request_id(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'request_id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class use_ocr(
+                schemas.BoolBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneBoolMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, bool, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'use_ocr':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class parse_pdf_tables_with_ocr(
+                schemas.BoolBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneBoolMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, bool, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'parse_pdf_tables_with_ocr':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+        
+            @staticmethod
+            def file_sync_config() -> typing.Type['FileSyncConfigNullable']:
+                return FileSyncConfigNullable
             __annotations__ = {
-                "data_source_id": data_source_id,
                 "ids": ids,
                 "tags": tags,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
                 "embedding_model": embedding_model,
                 "generate_sparse_vectors": generate_sparse_vectors,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
                 "max_items_per_chunk": max_items_per_chunk,
                 "set_page_as_boundary": set_page_as_boundary,
+                "data_source_id": data_source_id,
+                "request_id": request_id,
+                "use_ocr": use_ocr,
+                "parse_pdf_tables_with_ocr": parse_pdf_tables_with_ocr,
+                "file_sync_config": file_sync_config,
             }
     
     ids: MetaOapg.properties.ids
-    data_source_id: MetaOapg.properties.data_source_id
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["ids"]) -> MetaOapg.properties.ids: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
     
@@ -304,40 +326,52 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> MetaOapg.properties.skip_embedding_generation: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGeneratorsNullable': ...
+    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["max_items_per_chunk"]) -> MetaOapg.properties.max_items_per_chunk: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["set_page_as_boundary"]) -> MetaOapg.properties.set_page_as_boundary: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["use_ocr"]) -> MetaOapg.properties.use_ocr: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["parse_pdf_tables_with_ocr"]) -> MetaOapg.properties.parse_pdf_tables_with_ocr: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["file_sync_config"]) -> 'FileSyncConfigNullable': ...
+    
+    @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["data_source_id", "ids", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "set_page_as_boundary", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["ids", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "set_page_as_boundary", "data_source_id", "request_id", "use_ocr", "parse_pdf_tables_with_ocr", "file_sync_config", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
-    
-    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["ids"]) -> MetaOapg.properties.ids: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union[MetaOapg.properties.tags, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_size"]) -> typing.Union[MetaOapg.properties.chunk_size, schemas.Unset]: ...
@@ -345,65 +379,89 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_overlap"]) -> typing.Union[MetaOapg.properties.chunk_overlap, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> typing.Union[MetaOapg.properties.skip_embedding_generation, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGeneratorsNullable', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> typing.Union[MetaOapg.properties.generate_sparse_vectors, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["max_items_per_chunk"]) -> typing.Union[MetaOapg.properties.max_items_per_chunk, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["set_page_as_boundary"]) -> typing.Union[MetaOapg.properties.set_page_as_boundary, schemas.Unset]: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> typing.Union[MetaOapg.properties.data_source_id, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> typing.Union[MetaOapg.properties.request_id, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["use_ocr"]) -> typing.Union[MetaOapg.properties.use_ocr, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["parse_pdf_tables_with_ocr"]) -> typing.Union[MetaOapg.properties.parse_pdf_tables_with_ocr, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["file_sync_config"]) -> typing.Union['FileSyncConfigNullable', schemas.Unset]: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["data_source_id", "ids", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "set_page_as_boundary", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["ids", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "set_page_as_boundary", "data_source_id", "request_id", "use_ocr", "parse_pdf_tables_with_ocr", "file_sync_config", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        ids: typing.Union[MetaOapg.properties.ids, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
-        data_source_id: typing.Union[MetaOapg.properties.data_source_id, decimal.Decimal, int, ],
+        ids: typing.Union[MetaOapg.properties.ids, list, tuple, ],
         tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
-        embedding_model: typing.Union['EmbeddingGeneratorsNullable', schemas.Unset] = schemas.unset,
+        embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
         max_items_per_chunk: typing.Union[MetaOapg.properties.max_items_per_chunk, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         set_page_as_boundary: typing.Union[MetaOapg.properties.set_page_as_boundary, bool, schemas.Unset] = schemas.unset,
+        data_source_id: typing.Union[MetaOapg.properties.data_source_id, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        request_id: typing.Union[MetaOapg.properties.request_id, None, str, schemas.Unset] = schemas.unset,
+        use_ocr: typing.Union[MetaOapg.properties.use_ocr, None, bool, schemas.Unset] = schemas.unset,
+        parse_pdf_tables_with_ocr: typing.Union[MetaOapg.properties.parse_pdf_tables_with_ocr, None, bool, schemas.Unset] = schemas.unset,
+        file_sync_config: typing.Union['FileSyncConfigNullable', schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'SyncFilesRequest':
+    ) -> 'S3FileSyncInput':
         return super().__new__(
             cls,
             *args,
             ids=ids,
-            data_source_id=data_source_id,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
             set_page_as_boundary=set_page_as_boundary,
+            data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            file_sync_config=file_sync_config,
             _configuration=_configuration,
             **kwargs,
         )
 
-from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable
-from carbon.model.sync_files_ids import SyncFilesIds
+from carbon.model.embedding_generators import EmbeddingGenerators
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable
+from carbon.model.s3_get_file_input import S3GetFileInput
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/sync_options.py` & `carbon_python_sdk-0.2.0/carbon/model/gmail_sync_input.pyi`

 * *Files 25% similar despite different names*

```diff
@@ -19,26 +19,51 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class SyncOptions(
+class GmailSyncInput(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
+        required = {
+            "filters",
+        }
         
         class properties:
-            tags = schemas.AnyTypeSchema
+            filters = schemas.DictSchema
+            
+            
+            class tags(
+                schemas.DictBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneFrozenDictMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[dict, frozendict.frozendict, None, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                    **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
+                ) -> 'tags':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                        **kwargs,
+                    )
             
             
             class chunk_size(
                 schemas.IntBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneDecimalMixin
@@ -93,16 +118,16 @@
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
         
             @staticmethod
-            def embedding_model() -> typing.Type['EmbeddingGeneratorsNullable']:
-                return EmbeddingGeneratorsNullable
+            def embedding_model() -> typing.Type['EmbeddingGenerators']:
+                return EmbeddingGenerators
             
             
             class generate_sparse_vectors(
                 schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneBoolMixin
@@ -137,168 +162,222 @@
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
             
             
-            class max_items_per_chunk(
+            class data_source_id(
                 schemas.IntBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneDecimalMixin
             ):
             
             
                 def __new__(
                     cls,
                     *args: typing.Union[None, decimal.Decimal, int, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'max_items_per_chunk':
+                ) -> 'data_source_id':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
             
             
-            class sync_files_on_connection(
+            class request_id(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'request_id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class sync_attachments(
                 schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneBoolMixin
             ):
             
             
                 def __new__(
                     cls,
                     *args: typing.Union[None, bool, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'sync_files_on_connection':
+                ) -> 'sync_attachments':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
-            set_page_as_boundary = schemas.BoolSchema
+        
+            @staticmethod
+            def file_sync_config() -> typing.Type['FileSyncConfigNullable']:
+                return FileSyncConfigNullable
+            incremental_sync = schemas.BoolSchema
             __annotations__ = {
+                "filters": filters,
                 "tags": tags,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
                 "embedding_model": embedding_model,
                 "generate_sparse_vectors": generate_sparse_vectors,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
-                "max_items_per_chunk": max_items_per_chunk,
-                "sync_files_on_connection": sync_files_on_connection,
-                "set_page_as_boundary": set_page_as_boundary,
+                "data_source_id": data_source_id,
+                "request_id": request_id,
+                "sync_attachments": sync_attachments,
+                "file_sync_config": file_sync_config,
+                "incremental_sync": incremental_sync,
             }
     
+    filters: MetaOapg.properties.filters
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["filters"]) -> MetaOapg.properties.filters: ...
+    
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_size"]) -> MetaOapg.properties.chunk_size: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> MetaOapg.properties.skip_embedding_generation: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGeneratorsNullable': ...
+    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["max_items_per_chunk"]) -> MetaOapg.properties.max_items_per_chunk: ...
+    def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["sync_files_on_connection"]) -> MetaOapg.properties.sync_files_on_connection: ...
+    def __getitem__(self, name: typing_extensions.Literal["sync_attachments"]) -> MetaOapg.properties.sync_attachments: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["set_page_as_boundary"]) -> MetaOapg.properties.set_page_as_boundary: ...
+    def __getitem__(self, name: typing_extensions.Literal["file_sync_config"]) -> 'FileSyncConfigNullable': ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["incremental_sync"]) -> MetaOapg.properties.incremental_sync: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "sync_files_on_connection", "set_page_as_boundary", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["filters", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "data_source_id", "request_id", "sync_attachments", "file_sync_config", "incremental_sync", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["filters"]) -> MetaOapg.properties.filters: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union[MetaOapg.properties.tags, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_size"]) -> typing.Union[MetaOapg.properties.chunk_size, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_overlap"]) -> typing.Union[MetaOapg.properties.chunk_overlap, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> typing.Union[MetaOapg.properties.skip_embedding_generation, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGeneratorsNullable', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> typing.Union[MetaOapg.properties.generate_sparse_vectors, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["max_items_per_chunk"]) -> typing.Union[MetaOapg.properties.max_items_per_chunk, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> typing.Union[MetaOapg.properties.data_source_id, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> typing.Union[MetaOapg.properties.request_id, schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_attachments"]) -> typing.Union[MetaOapg.properties.sync_attachments, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["sync_files_on_connection"]) -> typing.Union[MetaOapg.properties.sync_files_on_connection, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["file_sync_config"]) -> typing.Union['FileSyncConfigNullable', schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["set_page_as_boundary"]) -> typing.Union[MetaOapg.properties.set_page_as_boundary, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["incremental_sync"]) -> typing.Union[MetaOapg.properties.incremental_sync, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "max_items_per_chunk", "sync_files_on_connection", "set_page_as_boundary", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["filters", "tags", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "data_source_id", "request_id", "sync_attachments", "file_sync_config", "incremental_sync", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, schemas.Unset] = schemas.unset,
+        filters: typing.Union[MetaOapg.properties.filters, dict, frozendict.frozendict, ],
+        tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
-        embedding_model: typing.Union['EmbeddingGeneratorsNullable', schemas.Unset] = schemas.unset,
+        embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
-        max_items_per_chunk: typing.Union[MetaOapg.properties.max_items_per_chunk, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
-        sync_files_on_connection: typing.Union[MetaOapg.properties.sync_files_on_connection, None, bool, schemas.Unset] = schemas.unset,
-        set_page_as_boundary: typing.Union[MetaOapg.properties.set_page_as_boundary, bool, schemas.Unset] = schemas.unset,
+        data_source_id: typing.Union[MetaOapg.properties.data_source_id, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        request_id: typing.Union[MetaOapg.properties.request_id, None, str, schemas.Unset] = schemas.unset,
+        sync_attachments: typing.Union[MetaOapg.properties.sync_attachments, None, bool, schemas.Unset] = schemas.unset,
+        file_sync_config: typing.Union['FileSyncConfigNullable', schemas.Unset] = schemas.unset,
+        incremental_sync: typing.Union[MetaOapg.properties.incremental_sync, bool, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'SyncOptions':
+    ) -> 'GmailSyncInput':
         return super().__new__(
             cls,
             *args,
+            filters=filters,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            sync_files_on_connection=sync_files_on_connection,
-            set_page_as_boundary=set_page_as_boundary,
+            data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
             _configuration=_configuration,
             **kwargs,
         )
 
-from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.model.embedding_generators import EmbeddingGenerators
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/text_embedding_generators.py` & `carbon_python_sdk-0.2.0/carbon/model/embedding_generators.py`

 * *Files 19% similar despite different names*

```diff
@@ -19,48 +19,79 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class TextEmbeddingGenerators(
+class EmbeddingGenerators(
     schemas.EnumBase,
     schemas.StrSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         enum_value_to_name = {
             "OPENAI": "OPENAI",
             "AZURE_OPENAI": "AZURE_OPENAI",
+            "AZURE_ADA_LARGE_256": "AZURE_ADA_LARGE_256",
+            "AZURE_ADA_LARGE_1024": "AZURE_ADA_LARGE_1024",
+            "AZURE_ADA_LARGE_3072": "AZURE_ADA_LARGE_3072",
+            "AZURE_ADA_SMALL_512": "AZURE_ADA_SMALL_512",
+            "AZURE_ADA_SMALL_1536": "AZURE_ADA_SMALL_1536",
             "COHERE_MULTILINGUAL_V3": "COHERE_MULTILINGUAL_V3",
+            "VERTEX_MULTIMODAL": "VERTEX_MULTIMODAL",
             "OPENAI_ADA_LARGE_256": "OPENAI_ADA_LARGE_256",
             "OPENAI_ADA_LARGE_1024": "OPENAI_ADA_LARGE_1024",
             "OPENAI_ADA_LARGE_3072": "OPENAI_ADA_LARGE_3072",
             "OPENAI_ADA_SMALL_512": "OPENAI_ADA_SMALL_512",
             "OPENAI_ADA_SMALL_1536": "OPENAI_ADA_SMALL_1536",
+            "SOLAR_1_MINI": "SOLAR_1_MINI",
         }
     
     @schemas.classproperty
     def OPENAI(cls):
         return cls("OPENAI")
     
     @schemas.classproperty
     def AZURE_OPENAI(cls):
         return cls("AZURE_OPENAI")
     
     @schemas.classproperty
+    def AZURE_ADA_LARGE_256(cls):
+        return cls("AZURE_ADA_LARGE_256")
+    
+    @schemas.classproperty
+    def AZURE_ADA_LARGE_1024(cls):
+        return cls("AZURE_ADA_LARGE_1024")
+    
+    @schemas.classproperty
+    def AZURE_ADA_LARGE_3072(cls):
+        return cls("AZURE_ADA_LARGE_3072")
+    
+    @schemas.classproperty
+    def AZURE_ADA_SMALL_512(cls):
+        return cls("AZURE_ADA_SMALL_512")
+    
+    @schemas.classproperty
+    def AZURE_ADA_SMALL_1536(cls):
+        return cls("AZURE_ADA_SMALL_1536")
+    
+    @schemas.classproperty
     def COHERE_MULTILINGUAL_V3(cls):
         return cls("COHERE_MULTILINGUAL_V3")
     
     @schemas.classproperty
+    def VERTEX_MULTIMODAL(cls):
+        return cls("VERTEX_MULTIMODAL")
+    
+    @schemas.classproperty
     def OPENAI_ADA_LARGE_256(cls):
         return cls("OPENAI_ADA_LARGE_256")
     
     @schemas.classproperty
     def OPENAI_ADA_LARGE_1024(cls):
         return cls("OPENAI_ADA_LARGE_1024")
     
@@ -71,7 +102,11 @@
     @schemas.classproperty
     def OPENAI_ADA_SMALL_512(cls):
         return cls("OPENAI_ADA_SMALL_512")
     
     @schemas.classproperty
     def OPENAI_ADA_SMALL_1536(cls):
         return cls("OPENAI_ADA_SMALL_1536")
+    
+    @schemas.classproperty
+    def SOLAR_1_MINI(cls):
+        return cls("SOLAR_1_MINI")
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/text_embedding_generators.pyi` & `carbon_python_sdk-0.2.0/carbon/model/custom_credentials_type.pyi`

 * *Files 18% similar despite different names*

```diff
@@ -19,46 +19,34 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class TextEmbeddingGenerators(
+class CustomCredentialsType(
     schemas.EnumBase,
     schemas.StrSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
     
     @schemas.classproperty
     def OPENAI(cls):
         return cls("OPENAI")
     
     @schemas.classproperty
-    def AZURE_OPENAI(cls):
-        return cls("AZURE_OPENAI")
-    
-    @schemas.classproperty
-    def COHERE_MULTILINGUAL_V3(cls):
-        return cls("COHERE_MULTILINGUAL_V3")
-    
-    @schemas.classproperty
-    def OPENAI_ADA_LARGE_256(cls):
-        return cls("OPENAI_ADA_LARGE_256")
-    
-    @schemas.classproperty
-    def OPENAI_ADA_LARGE_1024(cls):
-        return cls("OPENAI_ADA_LARGE_1024")
+    def COHERE(cls):
+        return cls("COHERE")
     
     @schemas.classproperty
-    def OPENAI_ADA_LARGE_3072(cls):
-        return cls("OPENAI_ADA_LARGE_3072")
+    def AZURE_OPENAI(cls):
+        return cls("AZURE_OPENAI")
     
     @schemas.classproperty
-    def OPENAI_ADA_SMALL_512(cls):
-        return cls("OPENAI_ADA_SMALL_512")
+    def AZURE_OPENAI_V3(cls):
+        return cls("AZURE_OPENAI_V3")
     
     @schemas.classproperty
-    def OPENAI_ADA_SMALL_1536(cls):
-        return cls("OPENAI_ADA_SMALL_1536")
+    def UPSTAGE(cls):
+        return cls("UPSTAGE")
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/token_response.py` & `carbon_python_sdk-0.2.0/carbon/model/token_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/token_response.pyi` & `carbon_python_sdk-0.2.0/carbon/model/token_response.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/user_file.py` & `carbon_python_sdk-0.2.0/carbon/model/user_file.py`

 * *Files 2% similar despite different names*

```diff
@@ -33,37 +33,41 @@
 
     class MetaOapg:
         required = {
             "additional_presigned_urls",
             "chunk_size",
             "embedding_properties",
             "organization_user_data_source_id",
+            "sync_properties",
             "created_at",
             "external_file_id",
             "file_metadata",
             "source",
             "organization_supplied_user_id",
             "external_url",
             "source_created_at",
+            "ocr_job_started_at",
             "updated_at",
             "generate_sparse_vectors",
             "enable_auto_sync",
             "id",
             "chunk_properties",
             "last_sync",
+            "ocr_properties",
             "presigned_url",
             "tags",
             "sync_error_message",
             "parent_id",
             "organization_id",
             "name",
             "file_statistics",
             "sync_status",
             "parsed_text_url",
             "chunk_overlap",
+            "request_id",
             "skip_embedding_generation",
         }
         
         class properties:
             
             
             class tags(
@@ -253,14 +257,40 @@
                         *args,
                         _configuration=_configuration,
                     )
         
             @staticmethod
             def chunk_properties() -> typing.Type['ChunkPropertiesNullable']:
                 return ChunkPropertiesNullable
+            ocr_properties = schemas.DictSchema
+            
+            
+            class ocr_job_started_at(
+                schemas.DateTimeBase,
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                class MetaOapg:
+                    format = 'date-time'
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, datetime, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'ocr_job_started_at':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             
             
             class name(
                 schemas.StrBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneStrMixin
@@ -421,14 +451,35 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'generate_sparse_vectors':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            
+            
+            class request_id(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'request_id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            sync_properties = schemas.DictSchema
             created_at = schemas.DateTimeSchema
             updated_at = schemas.DateTimeSchema
             __annotations__ = {
                 "tags": tags,
                 "id": id,
                 "source": source,
                 "organization_id": organization_id,
@@ -441,54 +492,62 @@
                 "last_sync": last_sync,
                 "file_statistics": file_statistics,
                 "file_metadata": file_metadata,
                 "embedding_properties": embedding_properties,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "chunk_properties": chunk_properties,
+                "ocr_properties": ocr_properties,
+                "ocr_job_started_at": ocr_job_started_at,
                 "name": name,
                 "parent_id": parent_id,
                 "enable_auto_sync": enable_auto_sync,
                 "presigned_url": presigned_url,
                 "parsed_text_url": parsed_text_url,
                 "additional_presigned_urls": additional_presigned_urls,
                 "skip_embedding_generation": skip_embedding_generation,
                 "source_created_at": source_created_at,
                 "generate_sparse_vectors": generate_sparse_vectors,
+                "request_id": request_id,
+                "sync_properties": sync_properties,
                 "created_at": created_at,
                 "updated_at": updated_at,
             }
     
     additional_presigned_urls: MetaOapg.properties.additional_presigned_urls
     chunk_size: MetaOapg.properties.chunk_size
     embedding_properties: 'UserFileEmbeddingProperties'
     organization_user_data_source_id: MetaOapg.properties.organization_user_data_source_id
+    sync_properties: MetaOapg.properties.sync_properties
     created_at: MetaOapg.properties.created_at
     external_file_id: MetaOapg.properties.external_file_id
     file_metadata: MetaOapg.properties.file_metadata
     source: 'DataSourceType'
     organization_supplied_user_id: MetaOapg.properties.organization_supplied_user_id
     external_url: MetaOapg.properties.external_url
     source_created_at: MetaOapg.properties.source_created_at
+    ocr_job_started_at: MetaOapg.properties.ocr_job_started_at
     updated_at: MetaOapg.properties.updated_at
     generate_sparse_vectors: MetaOapg.properties.generate_sparse_vectors
     enable_auto_sync: MetaOapg.properties.enable_auto_sync
     id: MetaOapg.properties.id
     chunk_properties: 'ChunkPropertiesNullable'
     last_sync: MetaOapg.properties.last_sync
+    ocr_properties: MetaOapg.properties.ocr_properties
     presigned_url: MetaOapg.properties.presigned_url
     tags: MetaOapg.properties.tags
     sync_error_message: MetaOapg.properties.sync_error_message
     parent_id: MetaOapg.properties.parent_id
     organization_id: MetaOapg.properties.organization_id
     name: MetaOapg.properties.name
     file_statistics: 'FileStatisticsNullable'
     sync_status: 'ExternalFileSyncStatuses'
     parsed_text_url: MetaOapg.properties.parsed_text_url
     chunk_overlap: MetaOapg.properties.chunk_overlap
+    request_id: MetaOapg.properties.request_id
     skip_embedding_generation: MetaOapg.properties.skip_embedding_generation
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
@@ -535,14 +594,20 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_properties"]) -> 'ChunkPropertiesNullable': ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["ocr_properties"]) -> MetaOapg.properties.ocr_properties: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["ocr_job_started_at"]) -> MetaOapg.properties.ocr_job_started_at: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["name"]) -> MetaOapg.properties.name: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["parent_id"]) -> MetaOapg.properties.parent_id: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["enable_auto_sync"]) -> MetaOapg.properties.enable_auto_sync: ...
@@ -562,23 +627,29 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["source_created_at"]) -> MetaOapg.properties.source_created_at: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["sync_properties"]) -> MetaOapg.properties.sync_properties: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["tags", "id", "source", "organization_id", "organization_supplied_user_id", "organization_user_data_source_id", "external_file_id", "external_url", "sync_status", "sync_error_message", "last_sync", "file_statistics", "file_metadata", "embedding_properties", "chunk_size", "chunk_overlap", "chunk_properties", "name", "parent_id", "enable_auto_sync", "presigned_url", "parsed_text_url", "additional_presigned_urls", "skip_embedding_generation", "source_created_at", "generate_sparse_vectors", "created_at", "updated_at", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["tags", "id", "source", "organization_id", "organization_supplied_user_id", "organization_user_data_source_id", "external_file_id", "external_url", "sync_status", "sync_error_message", "last_sync", "file_statistics", "file_metadata", "embedding_properties", "chunk_size", "chunk_overlap", "chunk_properties", "ocr_properties", "ocr_job_started_at", "name", "parent_id", "enable_auto_sync", "presigned_url", "parsed_text_url", "additional_presigned_urls", "skip_embedding_generation", "source_created_at", "generate_sparse_vectors", "request_id", "sync_properties", "created_at", "updated_at", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
     
@@ -627,14 +698,20 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_properties"]) -> 'ChunkPropertiesNullable': ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["ocr_properties"]) -> MetaOapg.properties.ocr_properties: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["ocr_job_started_at"]) -> MetaOapg.properties.ocr_job_started_at: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["name"]) -> MetaOapg.properties.name: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["parent_id"]) -> MetaOapg.properties.parent_id: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["enable_auto_sync"]) -> MetaOapg.properties.enable_auto_sync: ...
@@ -654,90 +731,104 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["source_created_at"]) -> MetaOapg.properties.source_created_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_properties"]) -> MetaOapg.properties.sync_properties: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["tags", "id", "source", "organization_id", "organization_supplied_user_id", "organization_user_data_source_id", "external_file_id", "external_url", "sync_status", "sync_error_message", "last_sync", "file_statistics", "file_metadata", "embedding_properties", "chunk_size", "chunk_overlap", "chunk_properties", "name", "parent_id", "enable_auto_sync", "presigned_url", "parsed_text_url", "additional_presigned_urls", "skip_embedding_generation", "source_created_at", "generate_sparse_vectors", "created_at", "updated_at", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["tags", "id", "source", "organization_id", "organization_supplied_user_id", "organization_user_data_source_id", "external_file_id", "external_url", "sync_status", "sync_error_message", "last_sync", "file_statistics", "file_metadata", "embedding_properties", "chunk_size", "chunk_overlap", "chunk_properties", "ocr_properties", "ocr_job_started_at", "name", "parent_id", "enable_auto_sync", "presigned_url", "parsed_text_url", "additional_presigned_urls", "skip_embedding_generation", "source_created_at", "generate_sparse_vectors", "request_id", "sync_properties", "created_at", "updated_at", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         additional_presigned_urls: typing.Union[MetaOapg.properties.additional_presigned_urls, dict, frozendict.frozendict, None, ],
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, ],
         embedding_properties: 'UserFileEmbeddingProperties',
         organization_user_data_source_id: typing.Union[MetaOapg.properties.organization_user_data_source_id, None, decimal.Decimal, int, ],
+        sync_properties: typing.Union[MetaOapg.properties.sync_properties, dict, frozendict.frozendict, ],
         created_at: typing.Union[MetaOapg.properties.created_at, str, datetime, ],
         external_file_id: typing.Union[MetaOapg.properties.external_file_id, str, ],
         file_metadata: typing.Union[MetaOapg.properties.file_metadata, dict, frozendict.frozendict, None, ],
         source: 'DataSourceType',
         organization_supplied_user_id: typing.Union[MetaOapg.properties.organization_supplied_user_id, str, ],
         external_url: typing.Union[MetaOapg.properties.external_url, None, str, ],
         source_created_at: typing.Union[MetaOapg.properties.source_created_at, None, str, datetime, ],
+        ocr_job_started_at: typing.Union[MetaOapg.properties.ocr_job_started_at, None, str, datetime, ],
         updated_at: typing.Union[MetaOapg.properties.updated_at, str, datetime, ],
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, ],
         enable_auto_sync: typing.Union[MetaOapg.properties.enable_auto_sync, None, bool, ],
         id: typing.Union[MetaOapg.properties.id, decimal.Decimal, int, ],
         chunk_properties: 'ChunkPropertiesNullable',
         last_sync: typing.Union[MetaOapg.properties.last_sync, None, str, datetime, ],
+        ocr_properties: typing.Union[MetaOapg.properties.ocr_properties, dict, frozendict.frozendict, ],
         presigned_url: typing.Union[MetaOapg.properties.presigned_url, None, str, ],
         tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, ],
         sync_error_message: typing.Union[MetaOapg.properties.sync_error_message, None, str, ],
         parent_id: typing.Union[MetaOapg.properties.parent_id, None, decimal.Decimal, int, ],
         organization_id: typing.Union[MetaOapg.properties.organization_id, decimal.Decimal, int, ],
         name: typing.Union[MetaOapg.properties.name, None, str, ],
         file_statistics: 'FileStatisticsNullable',
         sync_status: 'ExternalFileSyncStatuses',
         parsed_text_url: typing.Union[MetaOapg.properties.parsed_text_url, None, str, ],
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, ],
+        request_id: typing.Union[MetaOapg.properties.request_id, None, str, ],
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, bool, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
     ) -> 'UserFile':
         return super().__new__(
             cls,
             *args,
             additional_presigned_urls=additional_presigned_urls,
             chunk_size=chunk_size,
             embedding_properties=embedding_properties,
             organization_user_data_source_id=organization_user_data_source_id,
+            sync_properties=sync_properties,
             created_at=created_at,
             external_file_id=external_file_id,
             file_metadata=file_metadata,
             source=source,
             organization_supplied_user_id=organization_supplied_user_id,
             external_url=external_url,
             source_created_at=source_created_at,
+            ocr_job_started_at=ocr_job_started_at,
             updated_at=updated_at,
             generate_sparse_vectors=generate_sparse_vectors,
             enable_auto_sync=enable_auto_sync,
             id=id,
             chunk_properties=chunk_properties,
             last_sync=last_sync,
+            ocr_properties=ocr_properties,
             presigned_url=presigned_url,
             tags=tags,
             sync_error_message=sync_error_message,
             parent_id=parent_id,
             organization_id=organization_id,
             name=name,
             file_statistics=file_statistics,
             sync_status=sync_status,
             parsed_text_url=parsed_text_url,
             chunk_overlap=chunk_overlap,
+            request_id=request_id,
             skip_embedding_generation=skip_embedding_generation,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.chunk_properties_nullable import ChunkPropertiesNullable
 from carbon.model.data_source_type import DataSourceType
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/user_file.pyi` & `carbon_python_sdk-0.2.0/carbon/model/user_file.pyi`

 * *Files 2% similar despite different names*

```diff
@@ -33,37 +33,41 @@
 
     class MetaOapg:
         required = {
             "additional_presigned_urls",
             "chunk_size",
             "embedding_properties",
             "organization_user_data_source_id",
+            "sync_properties",
             "created_at",
             "external_file_id",
             "file_metadata",
             "source",
             "organization_supplied_user_id",
             "external_url",
             "source_created_at",
+            "ocr_job_started_at",
             "updated_at",
             "generate_sparse_vectors",
             "enable_auto_sync",
             "id",
             "chunk_properties",
             "last_sync",
+            "ocr_properties",
             "presigned_url",
             "tags",
             "sync_error_message",
             "parent_id",
             "organization_id",
             "name",
             "file_statistics",
             "sync_status",
             "parsed_text_url",
             "chunk_overlap",
+            "request_id",
             "skip_embedding_generation",
         }
         
         class properties:
             
             
             class tags(
@@ -253,14 +257,40 @@
                         *args,
                         _configuration=_configuration,
                     )
         
             @staticmethod
             def chunk_properties() -> typing.Type['ChunkPropertiesNullable']:
                 return ChunkPropertiesNullable
+            ocr_properties = schemas.DictSchema
+            
+            
+            class ocr_job_started_at(
+                schemas.DateTimeBase,
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                class MetaOapg:
+                    format = 'date-time'
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, datetime, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'ocr_job_started_at':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
             
             
             class name(
                 schemas.StrBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneStrMixin
@@ -421,14 +451,35 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'generate_sparse_vectors':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+            
+            
+            class request_id(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'request_id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            sync_properties = schemas.DictSchema
             created_at = schemas.DateTimeSchema
             updated_at = schemas.DateTimeSchema
             __annotations__ = {
                 "tags": tags,
                 "id": id,
                 "source": source,
                 "organization_id": organization_id,
@@ -441,54 +492,62 @@
                 "last_sync": last_sync,
                 "file_statistics": file_statistics,
                 "file_metadata": file_metadata,
                 "embedding_properties": embedding_properties,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "chunk_properties": chunk_properties,
+                "ocr_properties": ocr_properties,
+                "ocr_job_started_at": ocr_job_started_at,
                 "name": name,
                 "parent_id": parent_id,
                 "enable_auto_sync": enable_auto_sync,
                 "presigned_url": presigned_url,
                 "parsed_text_url": parsed_text_url,
                 "additional_presigned_urls": additional_presigned_urls,
                 "skip_embedding_generation": skip_embedding_generation,
                 "source_created_at": source_created_at,
                 "generate_sparse_vectors": generate_sparse_vectors,
+                "request_id": request_id,
+                "sync_properties": sync_properties,
                 "created_at": created_at,
                 "updated_at": updated_at,
             }
     
     additional_presigned_urls: MetaOapg.properties.additional_presigned_urls
     chunk_size: MetaOapg.properties.chunk_size
     embedding_properties: 'UserFileEmbeddingProperties'
     organization_user_data_source_id: MetaOapg.properties.organization_user_data_source_id
+    sync_properties: MetaOapg.properties.sync_properties
     created_at: MetaOapg.properties.created_at
     external_file_id: MetaOapg.properties.external_file_id
     file_metadata: MetaOapg.properties.file_metadata
     source: 'DataSourceType'
     organization_supplied_user_id: MetaOapg.properties.organization_supplied_user_id
     external_url: MetaOapg.properties.external_url
     source_created_at: MetaOapg.properties.source_created_at
+    ocr_job_started_at: MetaOapg.properties.ocr_job_started_at
     updated_at: MetaOapg.properties.updated_at
     generate_sparse_vectors: MetaOapg.properties.generate_sparse_vectors
     enable_auto_sync: MetaOapg.properties.enable_auto_sync
     id: MetaOapg.properties.id
     chunk_properties: 'ChunkPropertiesNullable'
     last_sync: MetaOapg.properties.last_sync
+    ocr_properties: MetaOapg.properties.ocr_properties
     presigned_url: MetaOapg.properties.presigned_url
     tags: MetaOapg.properties.tags
     sync_error_message: MetaOapg.properties.sync_error_message
     parent_id: MetaOapg.properties.parent_id
     organization_id: MetaOapg.properties.organization_id
     name: MetaOapg.properties.name
     file_statistics: 'FileStatisticsNullable'
     sync_status: 'ExternalFileSyncStatuses'
     parsed_text_url: MetaOapg.properties.parsed_text_url
     chunk_overlap: MetaOapg.properties.chunk_overlap
+    request_id: MetaOapg.properties.request_id
     skip_embedding_generation: MetaOapg.properties.skip_embedding_generation
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
@@ -535,14 +594,20 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_properties"]) -> 'ChunkPropertiesNullable': ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["ocr_properties"]) -> MetaOapg.properties.ocr_properties: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["ocr_job_started_at"]) -> MetaOapg.properties.ocr_job_started_at: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["name"]) -> MetaOapg.properties.name: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["parent_id"]) -> MetaOapg.properties.parent_id: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["enable_auto_sync"]) -> MetaOapg.properties.enable_auto_sync: ...
@@ -562,23 +627,29 @@
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["source_created_at"]) -> MetaOapg.properties.source_created_at: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["sync_properties"]) -> MetaOapg.properties.sync_properties: ...
+    
+    @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["tags", "id", "source", "organization_id", "organization_supplied_user_id", "organization_user_data_source_id", "external_file_id", "external_url", "sync_status", "sync_error_message", "last_sync", "file_statistics", "file_metadata", "embedding_properties", "chunk_size", "chunk_overlap", "chunk_properties", "name", "parent_id", "enable_auto_sync", "presigned_url", "parsed_text_url", "additional_presigned_urls", "skip_embedding_generation", "source_created_at", "generate_sparse_vectors", "created_at", "updated_at", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["tags", "id", "source", "organization_id", "organization_supplied_user_id", "organization_user_data_source_id", "external_file_id", "external_url", "sync_status", "sync_error_message", "last_sync", "file_statistics", "file_metadata", "embedding_properties", "chunk_size", "chunk_overlap", "chunk_properties", "ocr_properties", "ocr_job_started_at", "name", "parent_id", "enable_auto_sync", "presigned_url", "parsed_text_url", "additional_presigned_urls", "skip_embedding_generation", "source_created_at", "generate_sparse_vectors", "request_id", "sync_properties", "created_at", "updated_at", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
     
@@ -627,14 +698,20 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_properties"]) -> 'ChunkPropertiesNullable': ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["ocr_properties"]) -> MetaOapg.properties.ocr_properties: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["ocr_job_started_at"]) -> MetaOapg.properties.ocr_job_started_at: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["name"]) -> MetaOapg.properties.name: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["parent_id"]) -> MetaOapg.properties.parent_id: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["enable_auto_sync"]) -> MetaOapg.properties.enable_auto_sync: ...
@@ -654,90 +731,104 @@
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["source_created_at"]) -> MetaOapg.properties.source_created_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_properties"]) -> MetaOapg.properties.sync_properties: ...
+    
+    @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["tags", "id", "source", "organization_id", "organization_supplied_user_id", "organization_user_data_source_id", "external_file_id", "external_url", "sync_status", "sync_error_message", "last_sync", "file_statistics", "file_metadata", "embedding_properties", "chunk_size", "chunk_overlap", "chunk_properties", "name", "parent_id", "enable_auto_sync", "presigned_url", "parsed_text_url", "additional_presigned_urls", "skip_embedding_generation", "source_created_at", "generate_sparse_vectors", "created_at", "updated_at", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["tags", "id", "source", "organization_id", "organization_supplied_user_id", "organization_user_data_source_id", "external_file_id", "external_url", "sync_status", "sync_error_message", "last_sync", "file_statistics", "file_metadata", "embedding_properties", "chunk_size", "chunk_overlap", "chunk_properties", "ocr_properties", "ocr_job_started_at", "name", "parent_id", "enable_auto_sync", "presigned_url", "parsed_text_url", "additional_presigned_urls", "skip_embedding_generation", "source_created_at", "generate_sparse_vectors", "request_id", "sync_properties", "created_at", "updated_at", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         additional_presigned_urls: typing.Union[MetaOapg.properties.additional_presigned_urls, dict, frozendict.frozendict, None, ],
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, ],
         embedding_properties: 'UserFileEmbeddingProperties',
         organization_user_data_source_id: typing.Union[MetaOapg.properties.organization_user_data_source_id, None, decimal.Decimal, int, ],
+        sync_properties: typing.Union[MetaOapg.properties.sync_properties, dict, frozendict.frozendict, ],
         created_at: typing.Union[MetaOapg.properties.created_at, str, datetime, ],
         external_file_id: typing.Union[MetaOapg.properties.external_file_id, str, ],
         file_metadata: typing.Union[MetaOapg.properties.file_metadata, dict, frozendict.frozendict, None, ],
         source: 'DataSourceType',
         organization_supplied_user_id: typing.Union[MetaOapg.properties.organization_supplied_user_id, str, ],
         external_url: typing.Union[MetaOapg.properties.external_url, None, str, ],
         source_created_at: typing.Union[MetaOapg.properties.source_created_at, None, str, datetime, ],
+        ocr_job_started_at: typing.Union[MetaOapg.properties.ocr_job_started_at, None, str, datetime, ],
         updated_at: typing.Union[MetaOapg.properties.updated_at, str, datetime, ],
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, ],
         enable_auto_sync: typing.Union[MetaOapg.properties.enable_auto_sync, None, bool, ],
         id: typing.Union[MetaOapg.properties.id, decimal.Decimal, int, ],
         chunk_properties: 'ChunkPropertiesNullable',
         last_sync: typing.Union[MetaOapg.properties.last_sync, None, str, datetime, ],
+        ocr_properties: typing.Union[MetaOapg.properties.ocr_properties, dict, frozendict.frozendict, ],
         presigned_url: typing.Union[MetaOapg.properties.presigned_url, None, str, ],
         tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, ],
         sync_error_message: typing.Union[MetaOapg.properties.sync_error_message, None, str, ],
         parent_id: typing.Union[MetaOapg.properties.parent_id, None, decimal.Decimal, int, ],
         organization_id: typing.Union[MetaOapg.properties.organization_id, decimal.Decimal, int, ],
         name: typing.Union[MetaOapg.properties.name, None, str, ],
         file_statistics: 'FileStatisticsNullable',
         sync_status: 'ExternalFileSyncStatuses',
         parsed_text_url: typing.Union[MetaOapg.properties.parsed_text_url, None, str, ],
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, ],
+        request_id: typing.Union[MetaOapg.properties.request_id, None, str, ],
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, bool, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
     ) -> 'UserFile':
         return super().__new__(
             cls,
             *args,
             additional_presigned_urls=additional_presigned_urls,
             chunk_size=chunk_size,
             embedding_properties=embedding_properties,
             organization_user_data_source_id=organization_user_data_source_id,
+            sync_properties=sync_properties,
             created_at=created_at,
             external_file_id=external_file_id,
             file_metadata=file_metadata,
             source=source,
             organization_supplied_user_id=organization_supplied_user_id,
             external_url=external_url,
             source_created_at=source_created_at,
+            ocr_job_started_at=ocr_job_started_at,
             updated_at=updated_at,
             generate_sparse_vectors=generate_sparse_vectors,
             enable_auto_sync=enable_auto_sync,
             id=id,
             chunk_properties=chunk_properties,
             last_sync=last_sync,
+            ocr_properties=ocr_properties,
             presigned_url=presigned_url,
             tags=tags,
             sync_error_message=sync_error_message,
             parent_id=parent_id,
             organization_id=organization_id,
             name=name,
             file_statistics=file_statistics,
             sync_status=sync_status,
             parsed_text_url=parsed_text_url,
             chunk_overlap=chunk_overlap,
+            request_id=request_id,
             skip_embedding_generation=skip_embedding_generation,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.chunk_properties_nullable import ChunkPropertiesNullable
 from carbon.model.data_source_type import DataSourceType
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/user_file_embedding_properties.py` & `carbon_python_sdk-0.2.0/carbon/model/user_file_embedding_properties.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/user_file_embedding_properties.pyi` & `carbon_python_sdk-0.2.0/carbon/model/user_file_embedding_properties.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/user_files_v2.py` & `carbon_python_sdk-0.2.0/carbon/model/user_files_v2.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/user_files_v2.pyi` & `carbon_python_sdk-0.2.0/carbon/model/user_files_v2.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/user_request_content.py` & `carbon_python_sdk-0.2.0/carbon/model/user_request_content.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/user_request_content.pyi` & `carbon_python_sdk-0.2.0/carbon/model/user_request_content.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/user_response_unique_file_tags.py` & `carbon_python_sdk-0.2.0/carbon/model/user_response_unique_file_tags.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/user_response_unique_file_tags.pyi` & `carbon_python_sdk-0.2.0/carbon/model/user_response_unique_file_tags.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/utilities_scrape_web_request.py` & `carbon_python_sdk-0.2.0/carbon/model/utilities_scrape_web_request.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/utilities_scrape_web_request.pyi` & `carbon_python_sdk-0.2.0/carbon/model/utilities_scrape_web_request.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/validation_error.py` & `carbon_python_sdk-0.2.0/carbon/model/update_organization_input.py`

 * *Files 18% similar despite different names*

```diff
@@ -19,92 +19,63 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class ValidationError(
+class UpdateOrganizationInput(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
-        required = {
-            "msg",
-            "loc",
-            "type",
-        }
         
         class properties:
         
             @staticmethod
-            def loc() -> typing.Type['ValidationErrorLoc']:
-                return ValidationErrorLoc
-            msg = schemas.StrSchema
-            type = schemas.StrSchema
+            def global_user_config() -> typing.Type['UserConfigurationNullable']:
+                return UserConfigurationNullable
             __annotations__ = {
-                "loc": loc,
-                "msg": msg,
-                "type": type,
+                "global_user_config": global_user_config,
             }
     
-    msg: MetaOapg.properties.msg
-    loc: 'ValidationErrorLoc'
-    type: MetaOapg.properties.type
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["loc"]) -> 'ValidationErrorLoc': ...
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["msg"]) -> MetaOapg.properties.msg: ...
-    
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["type"]) -> MetaOapg.properties.type: ...
+    def __getitem__(self, name: typing_extensions.Literal["global_user_config"]) -> 'UserConfigurationNullable': ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["loc", "msg", "type", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["global_user_config", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["loc"]) -> 'ValidationErrorLoc': ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["msg"]) -> MetaOapg.properties.msg: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["type"]) -> MetaOapg.properties.type: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["global_user_config"]) -> typing.Union['UserConfigurationNullable', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["loc", "msg", "type", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["global_user_config", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        msg: typing.Union[MetaOapg.properties.msg, str, ],
-        loc: 'ValidationErrorLoc',
-        type: typing.Union[MetaOapg.properties.type, str, ],
+        global_user_config: typing.Union['UserConfigurationNullable', schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'ValidationError':
+    ) -> 'UpdateOrganizationInput':
         return super().__new__(
             cls,
             *args,
-            msg=msg,
-            loc=loc,
-            type=type,
+            global_user_config=global_user_config,
             _configuration=_configuration,
             **kwargs,
         )
 
-from carbon.model.validation_error_loc import ValidationErrorLoc
+from carbon.model.user_configuration_nullable import UserConfigurationNullable
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/validation_error.pyi` & `carbon_python_sdk-0.2.0/carbon/model/update_organization_input.pyi`

 * *Files 18% similar despite different names*

```diff
@@ -19,92 +19,63 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class ValidationError(
+class UpdateOrganizationInput(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
-        required = {
-            "msg",
-            "loc",
-            "type",
-        }
         
         class properties:
         
             @staticmethod
-            def loc() -> typing.Type['ValidationErrorLoc']:
-                return ValidationErrorLoc
-            msg = schemas.StrSchema
-            type = schemas.StrSchema
+            def global_user_config() -> typing.Type['UserConfigurationNullable']:
+                return UserConfigurationNullable
             __annotations__ = {
-                "loc": loc,
-                "msg": msg,
-                "type": type,
+                "global_user_config": global_user_config,
             }
     
-    msg: MetaOapg.properties.msg
-    loc: 'ValidationErrorLoc'
-    type: MetaOapg.properties.type
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["loc"]) -> 'ValidationErrorLoc': ...
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["msg"]) -> MetaOapg.properties.msg: ...
-    
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["type"]) -> MetaOapg.properties.type: ...
+    def __getitem__(self, name: typing_extensions.Literal["global_user_config"]) -> 'UserConfigurationNullable': ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["loc", "msg", "type", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["global_user_config", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["loc"]) -> 'ValidationErrorLoc': ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["msg"]) -> MetaOapg.properties.msg: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["type"]) -> MetaOapg.properties.type: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["global_user_config"]) -> typing.Union['UserConfigurationNullable', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["loc", "msg", "type", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["global_user_config", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        msg: typing.Union[MetaOapg.properties.msg, str, ],
-        loc: 'ValidationErrorLoc',
-        type: typing.Union[MetaOapg.properties.type, str, ],
+        global_user_config: typing.Union['UserConfigurationNullable', schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'ValidationError':
+    ) -> 'UpdateOrganizationInput':
         return super().__new__(
             cls,
             *args,
-            msg=msg,
-            loc=loc,
-            type=type,
+            global_user_config=global_user_config,
             _configuration=_configuration,
             **kwargs,
         )
 
-from carbon.model.validation_error_loc import ValidationErrorLoc
+from carbon.model.user_configuration_nullable import UserConfigurationNullable
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/validation_error_loc.py` & `carbon_python_sdk-0.2.0/carbon/model/validation_error_loc.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/validation_error_loc.pyi` & `carbon_python_sdk-0.2.0/carbon/model/validation_error_loc.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webhook.py` & `carbon_python_sdk-0.2.0/carbon/model/zotero_authentication.py`

 * *Files 22% similar despite different names*

```diff
@@ -19,123 +19,111 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class Webhook(
+class ZoteroAuthentication(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
-            "signing_key",
-            "updated_at",
-            "organization_id",
-            "created_at",
-            "id",
-            "url",
+            "access_token",
+            "zotero_id",
+            "source",
+            "access_token_secret",
+            "username",
         }
         
         class properties:
-            id = schemas.IntSchema
-            organization_id = schemas.IntSchema
-            url = schemas.StrSchema
-            signing_key = schemas.StrSchema
-            created_at = schemas.DateTimeSchema
-            updated_at = schemas.DateTimeSchema
+            source = schemas.AnyTypeSchema
+            access_token = schemas.StrSchema
+            access_token_secret = schemas.StrSchema
+            username = schemas.StrSchema
+            zotero_id = schemas.StrSchema
             __annotations__ = {
-                "id": id,
-                "organization_id": organization_id,
-                "url": url,
-                "signing_key": signing_key,
-                "created_at": created_at,
-                "updated_at": updated_at,
+                "source": source,
+                "access_token": access_token,
+                "access_token_secret": access_token_secret,
+                "username": username,
+                "zotero_id": zotero_id,
             }
     
-    signing_key: MetaOapg.properties.signing_key
-    updated_at: MetaOapg.properties.updated_at
-    organization_id: MetaOapg.properties.organization_id
-    created_at: MetaOapg.properties.created_at
-    id: MetaOapg.properties.id
-    url: MetaOapg.properties.url
+    access_token: MetaOapg.properties.access_token
+    zotero_id: MetaOapg.properties.zotero_id
+    source: MetaOapg.properties.source
+    access_token_secret: MetaOapg.properties.access_token_secret
+    username: MetaOapg.properties.username
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
+    def __getitem__(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["organization_id"]) -> MetaOapg.properties.organization_id: ...
+    def __getitem__(self, name: typing_extensions.Literal["access_token"]) -> MetaOapg.properties.access_token: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
+    def __getitem__(self, name: typing_extensions.Literal["access_token_secret"]) -> MetaOapg.properties.access_token_secret: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["signing_key"]) -> MetaOapg.properties.signing_key: ...
+    def __getitem__(self, name: typing_extensions.Literal["username"]) -> MetaOapg.properties.username: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
+    def __getitem__(self, name: typing_extensions.Literal["zotero_id"]) -> MetaOapg.properties.zotero_id: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "organization_id", "url", "signing_key", "created_at", "updated_at", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["source", "access_token", "access_token_secret", "username", "zotero_id", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["organization_id"]) -> MetaOapg.properties.organization_id: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["access_token"]) -> MetaOapg.properties.access_token: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["signing_key"]) -> MetaOapg.properties.signing_key: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["access_token_secret"]) -> MetaOapg.properties.access_token_secret: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["username"]) -> MetaOapg.properties.username: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["zotero_id"]) -> MetaOapg.properties.zotero_id: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "organization_id", "url", "signing_key", "created_at", "updated_at", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["source", "access_token", "access_token_secret", "username", "zotero_id", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        signing_key: typing.Union[MetaOapg.properties.signing_key, str, ],
-        updated_at: typing.Union[MetaOapg.properties.updated_at, str, datetime, ],
-        organization_id: typing.Union[MetaOapg.properties.organization_id, decimal.Decimal, int, ],
-        created_at: typing.Union[MetaOapg.properties.created_at, str, datetime, ],
-        id: typing.Union[MetaOapg.properties.id, decimal.Decimal, int, ],
-        url: typing.Union[MetaOapg.properties.url, str, ],
+        access_token: typing.Union[MetaOapg.properties.access_token, str, ],
+        zotero_id: typing.Union[MetaOapg.properties.zotero_id, str, ],
+        source: typing.Union[MetaOapg.properties.source, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
+        access_token_secret: typing.Union[MetaOapg.properties.access_token_secret, str, ],
+        username: typing.Union[MetaOapg.properties.username, str, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'Webhook':
+    ) -> 'ZoteroAuthentication':
         return super().__new__(
             cls,
             *args,
-            signing_key=signing_key,
-            updated_at=updated_at,
-            organization_id=organization_id,
-            created_at=created_at,
-            id=id,
-            url=url,
+            access_token=access_token,
+            zotero_id=zotero_id,
+            source=source,
+            access_token_secret=access_token_secret,
+            username=username,
             _configuration=_configuration,
             **kwargs,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webhook.pyi` & `carbon_python_sdk-0.2.0/carbon/model/zotero_authentication.pyi`

 * *Files 22% similar despite different names*

```diff
@@ -19,123 +19,111 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class Webhook(
+class ZoteroAuthentication(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
-            "signing_key",
-            "updated_at",
-            "organization_id",
-            "created_at",
-            "id",
-            "url",
+            "access_token",
+            "zotero_id",
+            "source",
+            "access_token_secret",
+            "username",
         }
         
         class properties:
-            id = schemas.IntSchema
-            organization_id = schemas.IntSchema
-            url = schemas.StrSchema
-            signing_key = schemas.StrSchema
-            created_at = schemas.DateTimeSchema
-            updated_at = schemas.DateTimeSchema
+            source = schemas.AnyTypeSchema
+            access_token = schemas.StrSchema
+            access_token_secret = schemas.StrSchema
+            username = schemas.StrSchema
+            zotero_id = schemas.StrSchema
             __annotations__ = {
-                "id": id,
-                "organization_id": organization_id,
-                "url": url,
-                "signing_key": signing_key,
-                "created_at": created_at,
-                "updated_at": updated_at,
+                "source": source,
+                "access_token": access_token,
+                "access_token_secret": access_token_secret,
+                "username": username,
+                "zotero_id": zotero_id,
             }
     
-    signing_key: MetaOapg.properties.signing_key
-    updated_at: MetaOapg.properties.updated_at
-    organization_id: MetaOapg.properties.organization_id
-    created_at: MetaOapg.properties.created_at
-    id: MetaOapg.properties.id
-    url: MetaOapg.properties.url
+    access_token: MetaOapg.properties.access_token
+    zotero_id: MetaOapg.properties.zotero_id
+    source: MetaOapg.properties.source
+    access_token_secret: MetaOapg.properties.access_token_secret
+    username: MetaOapg.properties.username
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
+    def __getitem__(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["organization_id"]) -> MetaOapg.properties.organization_id: ...
+    def __getitem__(self, name: typing_extensions.Literal["access_token"]) -> MetaOapg.properties.access_token: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
+    def __getitem__(self, name: typing_extensions.Literal["access_token_secret"]) -> MetaOapg.properties.access_token_secret: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["signing_key"]) -> MetaOapg.properties.signing_key: ...
+    def __getitem__(self, name: typing_extensions.Literal["username"]) -> MetaOapg.properties.username: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
+    def __getitem__(self, name: typing_extensions.Literal["zotero_id"]) -> MetaOapg.properties.zotero_id: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "organization_id", "url", "signing_key", "created_at", "updated_at", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["source", "access_token", "access_token_secret", "username", "zotero_id", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["organization_id"]) -> MetaOapg.properties.organization_id: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["access_token"]) -> MetaOapg.properties.access_token: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["signing_key"]) -> MetaOapg.properties.signing_key: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["access_token_secret"]) -> MetaOapg.properties.access_token_secret: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["username"]) -> MetaOapg.properties.username: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["zotero_id"]) -> MetaOapg.properties.zotero_id: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "organization_id", "url", "signing_key", "created_at", "updated_at", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["source", "access_token", "access_token_secret", "username", "zotero_id", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        signing_key: typing.Union[MetaOapg.properties.signing_key, str, ],
-        updated_at: typing.Union[MetaOapg.properties.updated_at, str, datetime, ],
-        organization_id: typing.Union[MetaOapg.properties.organization_id, decimal.Decimal, int, ],
-        created_at: typing.Union[MetaOapg.properties.created_at, str, datetime, ],
-        id: typing.Union[MetaOapg.properties.id, decimal.Decimal, int, ],
-        url: typing.Union[MetaOapg.properties.url, str, ],
+        access_token: typing.Union[MetaOapg.properties.access_token, str, ],
+        zotero_id: typing.Union[MetaOapg.properties.zotero_id, str, ],
+        source: typing.Union[MetaOapg.properties.source, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
+        access_token_secret: typing.Union[MetaOapg.properties.access_token_secret, str, ],
+        username: typing.Union[MetaOapg.properties.username, str, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'Webhook':
+    ) -> 'ZoteroAuthentication':
         return super().__new__(
             cls,
             *args,
-            signing_key=signing_key,
-            updated_at=updated_at,
-            organization_id=organization_id,
-            created_at=created_at,
-            id=id,
-            url=url,
+            access_token=access_token,
+            zotero_id=zotero_id,
+            source=source,
+            access_token_secret=access_token_secret,
+            username=username,
             _configuration=_configuration,
             **kwargs,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webhook_filters.py` & `carbon_python_sdk-0.2.0/carbon/model/webhook_filters.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webhook_filters.pyi` & `carbon_python_sdk-0.2.0/carbon/model/webhook_filters.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webhook_filters_ids.py` & `carbon_python_sdk-0.2.0/carbon/model/webhook_filters_ids.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webhook_filters_ids.pyi` & `carbon_python_sdk-0.2.0/carbon/model/webhook_filters_ids.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webhook_no_key.py` & `carbon_python_sdk-0.2.0/carbon/model/file_sync_config_nullable.py`

 * *Files 27% similar despite different names*

```diff
@@ -19,111 +19,111 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class WebhookNoKey(
-    schemas.DictSchema
+class FileSyncConfigNullable(
+    schemas.DictBase,
+    schemas.NoneBase,
+    schemas.Schema,
+    schemas.NoneFrozenDictMixin
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
+
+    Used to configure file syncing for certain connectors when sync_files_on_connection is set to true
     """
 
 
     class MetaOapg:
-        required = {
-            "updated_at",
-            "organization_id",
-            "created_at",
-            "id",
-            "url",
-        }
         
         class properties:
-            id = schemas.IntSchema
-            organization_id = schemas.IntSchema
-            url = schemas.StrSchema
-            created_at = schemas.DateTimeSchema
-            updated_at = schemas.DateTimeSchema
+            
+            
+            class auto_synced_source_types(
+                schemas.ListSchema
+            ):
+            
+            
+                class MetaOapg:
+                    
+                    @staticmethod
+                    def items() -> typing.Type['HelpdeskFileTypes']:
+                        return HelpdeskFileTypes
+            
+                def __new__(
+                    cls,
+                    arg: typing.Union[typing.Tuple['HelpdeskFileTypes'], typing.List['HelpdeskFileTypes']],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'auto_synced_source_types':
+                    return super().__new__(
+                        cls,
+                        arg,
+                        _configuration=_configuration,
+                    )
+            
+                def __getitem__(self, i: int) -> 'HelpdeskFileTypes':
+                    return super().__getitem__(i)
+            sync_attachments = schemas.BoolSchema
+            detect_audio_language = schemas.BoolSchema
             __annotations__ = {
-                "id": id,
-                "organization_id": organization_id,
-                "url": url,
-                "created_at": created_at,
-                "updated_at": updated_at,
+                "auto_synced_source_types": auto_synced_source_types,
+                "sync_attachments": sync_attachments,
+                "detect_audio_language": detect_audio_language,
             }
-    
-    updated_at: MetaOapg.properties.updated_at
-    organization_id: MetaOapg.properties.organization_id
-    created_at: MetaOapg.properties.created_at
-    id: MetaOapg.properties.id
-    url: MetaOapg.properties.url
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["organization_id"]) -> MetaOapg.properties.organization_id: ...
+
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
+    def __getitem__(self, name: typing_extensions.Literal["auto_synced_source_types"]) -> MetaOapg.properties.auto_synced_source_types: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
+    def __getitem__(self, name: typing_extensions.Literal["sync_attachments"]) -> MetaOapg.properties.sync_attachments: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
+    def __getitem__(self, name: typing_extensions.Literal["detect_audio_language"]) -> MetaOapg.properties.detect_audio_language: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "organization_id", "url", "created_at", "updated_at", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["auto_synced_source_types", "sync_attachments", "detect_audio_language", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["organization_id"]) -> MetaOapg.properties.organization_id: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["auto_synced_source_types"]) -> typing.Union[MetaOapg.properties.auto_synced_source_types, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_attachments"]) -> typing.Union[MetaOapg.properties.sync_attachments, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["detect_audio_language"]) -> typing.Union[MetaOapg.properties.detect_audio_language, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "organization_id", "url", "created_at", "updated_at", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["auto_synced_source_types", "sync_attachments", "detect_audio_language", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
-        *args: typing.Union[dict, frozendict.frozendict, ],
-        updated_at: typing.Union[MetaOapg.properties.updated_at, str, datetime, ],
-        organization_id: typing.Union[MetaOapg.properties.organization_id, decimal.Decimal, int, ],
-        created_at: typing.Union[MetaOapg.properties.created_at, str, datetime, ],
-        id: typing.Union[MetaOapg.properties.id, decimal.Decimal, int, ],
-        url: typing.Union[MetaOapg.properties.url, str, ],
+        *args: typing.Union[dict, frozendict.frozendict, None, ],
+        auto_synced_source_types: typing.Union[MetaOapg.properties.auto_synced_source_types, list, tuple, schemas.Unset] = schemas.unset,
+        sync_attachments: typing.Union[MetaOapg.properties.sync_attachments, bool, schemas.Unset] = schemas.unset,
+        detect_audio_language: typing.Union[MetaOapg.properties.detect_audio_language, bool, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'WebhookNoKey':
+    ) -> 'FileSyncConfigNullable':
         return super().__new__(
             cls,
             *args,
-            updated_at=updated_at,
-            organization_id=organization_id,
-            created_at=created_at,
-            id=id,
-            url=url,
+            auto_synced_source_types=auto_synced_source_types,
+            sync_attachments=sync_attachments,
+            detect_audio_language=detect_audio_language,
             _configuration=_configuration,
             **kwargs,
         )
+
+from carbon.model.helpdesk_file_types import HelpdeskFileTypes
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webhook_no_key.pyi` & `carbon_python_sdk-0.2.0/carbon/model/file_sync_config_nullable.pyi`

 * *Files 27% similar despite different names*

```diff
@@ -19,111 +19,111 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class WebhookNoKey(
-    schemas.DictSchema
+class FileSyncConfigNullable(
+    schemas.DictBase,
+    schemas.NoneBase,
+    schemas.Schema,
+    schemas.NoneFrozenDictMixin
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
+
+    Used to configure file syncing for certain connectors when sync_files_on_connection is set to true
     """
 
 
     class MetaOapg:
-        required = {
-            "updated_at",
-            "organization_id",
-            "created_at",
-            "id",
-            "url",
-        }
         
         class properties:
-            id = schemas.IntSchema
-            organization_id = schemas.IntSchema
-            url = schemas.StrSchema
-            created_at = schemas.DateTimeSchema
-            updated_at = schemas.DateTimeSchema
+            
+            
+            class auto_synced_source_types(
+                schemas.ListSchema
+            ):
+            
+            
+                class MetaOapg:
+                    
+                    @staticmethod
+                    def items() -> typing.Type['HelpdeskFileTypes']:
+                        return HelpdeskFileTypes
+            
+                def __new__(
+                    cls,
+                    arg: typing.Union[typing.Tuple['HelpdeskFileTypes'], typing.List['HelpdeskFileTypes']],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'auto_synced_source_types':
+                    return super().__new__(
+                        cls,
+                        arg,
+                        _configuration=_configuration,
+                    )
+            
+                def __getitem__(self, i: int) -> 'HelpdeskFileTypes':
+                    return super().__getitem__(i)
+            sync_attachments = schemas.BoolSchema
+            detect_audio_language = schemas.BoolSchema
             __annotations__ = {
-                "id": id,
-                "organization_id": organization_id,
-                "url": url,
-                "created_at": created_at,
-                "updated_at": updated_at,
+                "auto_synced_source_types": auto_synced_source_types,
+                "sync_attachments": sync_attachments,
+                "detect_audio_language": detect_audio_language,
             }
-    
-    updated_at: MetaOapg.properties.updated_at
-    organization_id: MetaOapg.properties.organization_id
-    created_at: MetaOapg.properties.created_at
-    id: MetaOapg.properties.id
-    url: MetaOapg.properties.url
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["organization_id"]) -> MetaOapg.properties.organization_id: ...
+
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
+    def __getitem__(self, name: typing_extensions.Literal["auto_synced_source_types"]) -> MetaOapg.properties.auto_synced_source_types: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
+    def __getitem__(self, name: typing_extensions.Literal["sync_attachments"]) -> MetaOapg.properties.sync_attachments: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
+    def __getitem__(self, name: typing_extensions.Literal["detect_audio_language"]) -> MetaOapg.properties.detect_audio_language: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["id", "organization_id", "url", "created_at", "updated_at", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["auto_synced_source_types", "sync_attachments", "detect_audio_language", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["organization_id"]) -> MetaOapg.properties.organization_id: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["auto_synced_source_types"]) -> typing.Union[MetaOapg.properties.auto_synced_source_types, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["created_at"]) -> MetaOapg.properties.created_at: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_attachments"]) -> typing.Union[MetaOapg.properties.sync_attachments, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["updated_at"]) -> MetaOapg.properties.updated_at: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["detect_audio_language"]) -> typing.Union[MetaOapg.properties.detect_audio_language, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["id", "organization_id", "url", "created_at", "updated_at", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["auto_synced_source_types", "sync_attachments", "detect_audio_language", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
-        *args: typing.Union[dict, frozendict.frozendict, ],
-        updated_at: typing.Union[MetaOapg.properties.updated_at, str, datetime, ],
-        organization_id: typing.Union[MetaOapg.properties.organization_id, decimal.Decimal, int, ],
-        created_at: typing.Union[MetaOapg.properties.created_at, str, datetime, ],
-        id: typing.Union[MetaOapg.properties.id, decimal.Decimal, int, ],
-        url: typing.Union[MetaOapg.properties.url, str, ],
+        *args: typing.Union[dict, frozendict.frozendict, None, ],
+        auto_synced_source_types: typing.Union[MetaOapg.properties.auto_synced_source_types, list, tuple, schemas.Unset] = schemas.unset,
+        sync_attachments: typing.Union[MetaOapg.properties.sync_attachments, bool, schemas.Unset] = schemas.unset,
+        detect_audio_language: typing.Union[MetaOapg.properties.detect_audio_language, bool, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'WebhookNoKey':
+    ) -> 'FileSyncConfigNullable':
         return super().__new__(
             cls,
             *args,
-            updated_at=updated_at,
-            organization_id=organization_id,
-            created_at=created_at,
-            id=id,
-            url=url,
+            auto_synced_source_types=auto_synced_source_types,
+            sync_attachments=sync_attachments,
+            detect_audio_language=detect_audio_language,
             _configuration=_configuration,
             **kwargs,
         )
+
+from carbon.model.helpdesk_file_types import HelpdeskFileTypes
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webhook_order_by_columns.py` & `carbon_python_sdk-0.2.0/carbon/model/webhook_order_by_columns.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webhook_order_by_columns.pyi` & `carbon_python_sdk-0.2.0/carbon/model/webhook_order_by_columns.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webhook_query_input.py` & `carbon_python_sdk-0.2.0/carbon/model/webhook_query_input.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webhook_query_input.pyi` & `carbon_python_sdk-0.2.0/carbon/model/webhook_query_input.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webhook_query_response.py` & `carbon_python_sdk-0.2.0/carbon/model/webhook_query_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webhook_query_response.pyi` & `carbon_python_sdk-0.2.0/carbon/model/webhook_query_response.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webscrape_request.py` & `carbon_python_sdk-0.2.0/carbon/model/webscrape_request.pyi`

 * *Files 0% similar despite different names*

```diff
@@ -49,15 +49,14 @@
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneDecimalMixin
             ):
             
             
                 class MetaOapg:
-                    inclusive_minimum = 0
             
             
                 def __new__(
                     cls,
                     *args: typing.Union[None, decimal.Decimal, int, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'recursion_depth':
@@ -73,15 +72,14 @@
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneDecimalMixin
             ):
             
             
                 class MetaOapg:
-                    inclusive_minimum = 1
             
             
                 def __new__(
                     cls,
                     *args: typing.Union[None, decimal.Decimal, int, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'max_pages_to_scrape':
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webscrape_request.pyi` & `carbon_python_sdk-0.2.0/carbon/model/outlook_sync_input.py`

 * *Files 10% similar despite different names*

```diff
@@ -19,74 +19,66 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class WebscrapeRequest(
+class OutlookSyncInput(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
-            "url",
+            "filters",
         }
         
         class properties:
-            url = schemas.StrSchema
-        
-            @staticmethod
-            def tags() -> typing.Type['WebscrapeRequestTags']:
-                return WebscrapeRequestTags
+            filters = schemas.DictSchema
             
             
-            class recursion_depth(
-                schemas.IntBase,
+            class tags(
+                schemas.DictBase,
                 schemas.NoneBase,
                 schemas.Schema,
-                schemas.NoneDecimalMixin
+                schemas.NoneFrozenDictMixin
             ):
             
             
-                class MetaOapg:
-            
-            
                 def __new__(
                     cls,
-                    *args: typing.Union[None, decimal.Decimal, int, ],
+                    *args: typing.Union[dict, frozendict.frozendict, None, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'recursion_depth':
+                    **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
+                ) -> 'tags':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
+                        **kwargs,
                     )
             
             
-            class max_pages_to_scrape(
-                schemas.IntBase,
+            class folder(
+                schemas.StrBase,
                 schemas.NoneBase,
                 schemas.Schema,
-                schemas.NoneDecimalMixin
+                schemas.NoneStrMixin
             ):
             
             
-                class MetaOapg:
-            
-            
                 def __new__(
                     cls,
-                    *args: typing.Union[None, decimal.Decimal, int, ],
+                    *args: typing.Union[None, str, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'max_pages_to_scrape':
+                ) -> 'folder':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
             
             
@@ -144,247 +136,277 @@
                     _configuration: typing.Optional[schemas.Configuration] = None,
                 ) -> 'skip_embedding_generation':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
+        
+            @staticmethod
+            def embedding_model() -> typing.Type['EmbeddingGenerators']:
+                return EmbeddingGenerators
             
             
-            class enable_auto_sync(
+            class generate_sparse_vectors(
                 schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneBoolMixin
             ):
             
             
                 def __new__(
                     cls,
                     *args: typing.Union[None, bool, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'enable_auto_sync':
+                ) -> 'generate_sparse_vectors':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
             
             
-            class generate_sparse_vectors(
+            class prepend_filename_to_chunks(
                 schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneBoolMixin
             ):
             
             
                 def __new__(
                     cls,
                     *args: typing.Union[None, bool, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'generate_sparse_vectors':
+                ) -> 'prepend_filename_to_chunks':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
             
             
-            class prepend_filename_to_chunks(
+            class data_source_id(
+                schemas.IntBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneDecimalMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, decimal.Decimal, int, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'data_source_id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class request_id(
+                schemas.StrBase,
+                schemas.NoneBase,
+                schemas.Schema,
+                schemas.NoneStrMixin
+            ):
+            
+            
+                def __new__(
+                    cls,
+                    *args: typing.Union[None, str, ],
+                    _configuration: typing.Optional[schemas.Configuration] = None,
+                ) -> 'request_id':
+                    return super().__new__(
+                        cls,
+                        *args,
+                        _configuration=_configuration,
+                    )
+            
+            
+            class sync_attachments(
                 schemas.BoolBase,
                 schemas.NoneBase,
                 schemas.Schema,
                 schemas.NoneBoolMixin
             ):
             
             
                 def __new__(
                     cls,
                     *args: typing.Union[None, bool, ],
                     _configuration: typing.Optional[schemas.Configuration] = None,
-                ) -> 'prepend_filename_to_chunks':
+                ) -> 'sync_attachments':
                     return super().__new__(
                         cls,
                         *args,
                         _configuration=_configuration,
                     )
         
             @staticmethod
-            def html_tags_to_skip() -> typing.Type['WebscrapeRequestHtmlTagsToSkip']:
-                return WebscrapeRequestHtmlTagsToSkip
-        
-            @staticmethod
-            def css_classes_to_skip() -> typing.Type['WebscrapeRequestCssClassesToSkip']:
-                return WebscrapeRequestCssClassesToSkip
-        
-            @staticmethod
-            def css_selectors_to_skip() -> typing.Type['WebscrapeRequestCssSelectorsToSkip']:
-                return WebscrapeRequestCssSelectorsToSkip
-        
-            @staticmethod
-            def embedding_model() -> typing.Type['EmbeddingGenerators']:
-                return EmbeddingGenerators
+            def file_sync_config() -> typing.Type['FileSyncConfigNullable']:
+                return FileSyncConfigNullable
+            incremental_sync = schemas.BoolSchema
             __annotations__ = {
-                "url": url,
+                "filters": filters,
                 "tags": tags,
-                "recursion_depth": recursion_depth,
-                "max_pages_to_scrape": max_pages_to_scrape,
+                "folder": folder,
                 "chunk_size": chunk_size,
                 "chunk_overlap": chunk_overlap,
                 "skip_embedding_generation": skip_embedding_generation,
-                "enable_auto_sync": enable_auto_sync,
+                "embedding_model": embedding_model,
                 "generate_sparse_vectors": generate_sparse_vectors,
                 "prepend_filename_to_chunks": prepend_filename_to_chunks,
-                "html_tags_to_skip": html_tags_to_skip,
-                "css_classes_to_skip": css_classes_to_skip,
-                "css_selectors_to_skip": css_selectors_to_skip,
-                "embedding_model": embedding_model,
+                "data_source_id": data_source_id,
+                "request_id": request_id,
+                "sync_attachments": sync_attachments,
+                "file_sync_config": file_sync_config,
+                "incremental_sync": incremental_sync,
             }
     
-    url: MetaOapg.properties.url
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
+    filters: MetaOapg.properties.filters
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["tags"]) -> 'WebscrapeRequestTags': ...
+    def __getitem__(self, name: typing_extensions.Literal["filters"]) -> MetaOapg.properties.filters: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["recursion_depth"]) -> MetaOapg.properties.recursion_depth: ...
+    def __getitem__(self, name: typing_extensions.Literal["tags"]) -> MetaOapg.properties.tags: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["max_pages_to_scrape"]) -> MetaOapg.properties.max_pages_to_scrape: ...
+    def __getitem__(self, name: typing_extensions.Literal["folder"]) -> MetaOapg.properties.folder: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_size"]) -> MetaOapg.properties.chunk_size: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["chunk_overlap"]) -> MetaOapg.properties.chunk_overlap: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> MetaOapg.properties.skip_embedding_generation: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["enable_auto_sync"]) -> MetaOapg.properties.enable_auto_sync: ...
+    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> MetaOapg.properties.generate_sparse_vectors: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> MetaOapg.properties.prepend_filename_to_chunks: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["html_tags_to_skip"]) -> 'WebscrapeRequestHtmlTagsToSkip': ...
+    def __getitem__(self, name: typing_extensions.Literal["data_source_id"]) -> MetaOapg.properties.data_source_id: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["css_classes_to_skip"]) -> 'WebscrapeRequestCssClassesToSkip': ...
+    def __getitem__(self, name: typing_extensions.Literal["request_id"]) -> MetaOapg.properties.request_id: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["css_selectors_to_skip"]) -> 'WebscrapeRequestCssSelectorsToSkip': ...
+    def __getitem__(self, name: typing_extensions.Literal["sync_attachments"]) -> MetaOapg.properties.sync_attachments: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["embedding_model"]) -> 'EmbeddingGenerators': ...
+    def __getitem__(self, name: typing_extensions.Literal["file_sync_config"]) -> 'FileSyncConfigNullable': ...
+    
+    @typing.overload
+    def __getitem__(self, name: typing_extensions.Literal["incremental_sync"]) -> MetaOapg.properties.incremental_sync: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["url", "tags", "recursion_depth", "max_pages_to_scrape", "chunk_size", "chunk_overlap", "skip_embedding_generation", "enable_auto_sync", "generate_sparse_vectors", "prepend_filename_to_chunks", "html_tags_to_skip", "css_classes_to_skip", "css_selectors_to_skip", "embedding_model", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["filters", "tags", "folder", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "data_source_id", "request_id", "sync_attachments", "file_sync_config", "incremental_sync", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["url"]) -> MetaOapg.properties.url: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["filters"]) -> MetaOapg.properties.filters: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union['WebscrapeRequestTags', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["tags"]) -> typing.Union[MetaOapg.properties.tags, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["recursion_depth"]) -> typing.Union[MetaOapg.properties.recursion_depth, schemas.Unset]: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["max_pages_to_scrape"]) -> typing.Union[MetaOapg.properties.max_pages_to_scrape, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["folder"]) -> typing.Union[MetaOapg.properties.folder, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_size"]) -> typing.Union[MetaOapg.properties.chunk_size, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["chunk_overlap"]) -> typing.Union[MetaOapg.properties.chunk_overlap, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["skip_embedding_generation"]) -> typing.Union[MetaOapg.properties.skip_embedding_generation, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["enable_auto_sync"]) -> typing.Union[MetaOapg.properties.enable_auto_sync, schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["generate_sparse_vectors"]) -> typing.Union[MetaOapg.properties.generate_sparse_vectors, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["prepend_filename_to_chunks"]) -> typing.Union[MetaOapg.properties.prepend_filename_to_chunks, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["html_tags_to_skip"]) -> typing.Union['WebscrapeRequestHtmlTagsToSkip', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["data_source_id"]) -> typing.Union[MetaOapg.properties.data_source_id, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["css_classes_to_skip"]) -> typing.Union['WebscrapeRequestCssClassesToSkip', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["request_id"]) -> typing.Union[MetaOapg.properties.request_id, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["css_selectors_to_skip"]) -> typing.Union['WebscrapeRequestCssSelectorsToSkip', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_attachments"]) -> typing.Union[MetaOapg.properties.sync_attachments, schemas.Unset]: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["embedding_model"]) -> typing.Union['EmbeddingGenerators', schemas.Unset]: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["file_sync_config"]) -> typing.Union['FileSyncConfigNullable', schemas.Unset]: ...
+    
+    @typing.overload
+    def get_item_oapg(self, name: typing_extensions.Literal["incremental_sync"]) -> typing.Union[MetaOapg.properties.incremental_sync, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["url", "tags", "recursion_depth", "max_pages_to_scrape", "chunk_size", "chunk_overlap", "skip_embedding_generation", "enable_auto_sync", "generate_sparse_vectors", "prepend_filename_to_chunks", "html_tags_to_skip", "css_classes_to_skip", "css_selectors_to_skip", "embedding_model", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["filters", "tags", "folder", "chunk_size", "chunk_overlap", "skip_embedding_generation", "embedding_model", "generate_sparse_vectors", "prepend_filename_to_chunks", "data_source_id", "request_id", "sync_attachments", "file_sync_config", "incremental_sync", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
-        url: typing.Union[MetaOapg.properties.url, str, ],
-        tags: typing.Union['WebscrapeRequestTags', schemas.Unset] = schemas.unset,
-        recursion_depth: typing.Union[MetaOapg.properties.recursion_depth, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
-        max_pages_to_scrape: typing.Union[MetaOapg.properties.max_pages_to_scrape, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        filters: typing.Union[MetaOapg.properties.filters, dict, frozendict.frozendict, ],
+        tags: typing.Union[MetaOapg.properties.tags, dict, frozendict.frozendict, None, schemas.Unset] = schemas.unset,
+        folder: typing.Union[MetaOapg.properties.folder, None, str, schemas.Unset] = schemas.unset,
         chunk_size: typing.Union[MetaOapg.properties.chunk_size, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         chunk_overlap: typing.Union[MetaOapg.properties.chunk_overlap, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
         skip_embedding_generation: typing.Union[MetaOapg.properties.skip_embedding_generation, None, bool, schemas.Unset] = schemas.unset,
-        enable_auto_sync: typing.Union[MetaOapg.properties.enable_auto_sync, None, bool, schemas.Unset] = schemas.unset,
+        embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
         generate_sparse_vectors: typing.Union[MetaOapg.properties.generate_sparse_vectors, None, bool, schemas.Unset] = schemas.unset,
         prepend_filename_to_chunks: typing.Union[MetaOapg.properties.prepend_filename_to_chunks, None, bool, schemas.Unset] = schemas.unset,
-        html_tags_to_skip: typing.Union['WebscrapeRequestHtmlTagsToSkip', schemas.Unset] = schemas.unset,
-        css_classes_to_skip: typing.Union['WebscrapeRequestCssClassesToSkip', schemas.Unset] = schemas.unset,
-        css_selectors_to_skip: typing.Union['WebscrapeRequestCssSelectorsToSkip', schemas.Unset] = schemas.unset,
-        embedding_model: typing.Union['EmbeddingGenerators', schemas.Unset] = schemas.unset,
+        data_source_id: typing.Union[MetaOapg.properties.data_source_id, None, decimal.Decimal, int, schemas.Unset] = schemas.unset,
+        request_id: typing.Union[MetaOapg.properties.request_id, None, str, schemas.Unset] = schemas.unset,
+        sync_attachments: typing.Union[MetaOapg.properties.sync_attachments, None, bool, schemas.Unset] = schemas.unset,
+        file_sync_config: typing.Union['FileSyncConfigNullable', schemas.Unset] = schemas.unset,
+        incremental_sync: typing.Union[MetaOapg.properties.incremental_sync, bool, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'WebscrapeRequest':
+    ) -> 'OutlookSyncInput':
         return super().__new__(
             cls,
             *args,
-            url=url,
+            filters=filters,
             tags=tags,
-            recursion_depth=recursion_depth,
-            max_pages_to_scrape=max_pages_to_scrape,
+            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
-            enable_auto_sync=enable_auto_sync,
+            embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            html_tags_to_skip=html_tags_to_skip,
-            css_classes_to_skip=css_classes_to_skip,
-            css_selectors_to_skip=css_selectors_to_skip,
-            embedding_model=embedding_model,
+            data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
             _configuration=_configuration,
             **kwargs,
         )
 
 from carbon.model.embedding_generators import EmbeddingGenerators
-from carbon.model.webscrape_request_css_classes_to_skip import WebscrapeRequestCssClassesToSkip
-from carbon.model.webscrape_request_css_selectors_to_skip import WebscrapeRequestCssSelectorsToSkip
-from carbon.model.webscrape_request_html_tags_to_skip import WebscrapeRequestHtmlTagsToSkip
-from carbon.model.webscrape_request_tags import WebscrapeRequestTags
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webscrape_request_css_classes_to_skip.py` & `carbon_python_sdk-0.2.0/carbon/model/webscrape_request_css_classes_to_skip.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webscrape_request_css_classes_to_skip.pyi` & `carbon_python_sdk-0.2.0/carbon/model/webscrape_request_css_classes_to_skip.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webscrape_request_css_selectors_to_skip.py` & `carbon_python_sdk-0.2.0/carbon/model/webscrape_request_css_selectors_to_skip.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webscrape_request_css_selectors_to_skip.pyi` & `carbon_python_sdk-0.2.0/carbon/model/webscrape_request_css_selectors_to_skip.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webscrape_request_html_tags_to_skip.py` & `carbon_python_sdk-0.2.0/carbon/model/list_items_filters_ids.py`

 * *Files 14% similar despite different names*

```diff
@@ -19,32 +19,32 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class WebscrapeRequestHtmlTagsToSkip(
+class ListItemsFiltersIds(
     schemas.ListBase,
     schemas.NoneBase,
     schemas.Schema,
     schemas.NoneTupleMixin
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
-        items = schemas.StrSchema
+        items = schemas.IntSchema
 
 
     def __new__(
         cls,
         *args: typing.Union[list, tuple, None, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
-    ) -> 'WebscrapeRequestHtmlTagsToSkip':
+    ) -> 'ListItemsFiltersIds':
         return super().__new__(
             cls,
             *args,
             _configuration=_configuration,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webscrape_request_html_tags_to_skip.pyi` & `carbon_python_sdk-0.2.0/carbon/model/list_items_filters_ids.pyi`

 * *Files 14% similar despite different names*

```diff
@@ -19,32 +19,32 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class WebscrapeRequestHtmlTagsToSkip(
+class ListItemsFiltersIds(
     schemas.ListBase,
     schemas.NoneBase,
     schemas.Schema,
     schemas.NoneTupleMixin
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
-        items = schemas.StrSchema
+        items = schemas.IntSchema
 
 
     def __new__(
         cls,
         *args: typing.Union[list, tuple, None, ],
         _configuration: typing.Optional[schemas.Configuration] = None,
-    ) -> 'WebscrapeRequestHtmlTagsToSkip':
+    ) -> 'ListItemsFiltersIds':
         return super().__new__(
             cls,
             *args,
             _configuration=_configuration,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webscrape_request_tags.py` & `carbon_python_sdk-0.2.0/carbon/model/webscrape_request_tags.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/webscrape_request_tags.pyi` & `carbon_python_sdk-0.2.0/carbon/model/webscrape_request_tags.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/white_labeling_response.py` & `carbon_python_sdk-0.2.0/carbon/model/white_labeling_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/white_labeling_response.pyi` & `carbon_python_sdk-0.2.0/carbon/model/white_labeling_response.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/youtube_transcript_response.py` & `carbon_python_sdk-0.2.0/carbon/model/youtube_transcript_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/youtube_transcript_response.pyi` & `carbon_python_sdk-0.2.0/carbon/model/youtube_transcript_response.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/youtube_transcript_response_raw_transcript.py` & `carbon_python_sdk-0.2.0/carbon/model/youtube_transcript_response_raw_transcript.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/youtube_transcript_response_raw_transcript.pyi` & `carbon_python_sdk-0.2.0/carbon/model/youtube_transcript_response_raw_transcript.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/youtube_transcript_response_raw_transcript_item.py` & `carbon_python_sdk-0.2.0/carbon/model/youtube_transcript_response_raw_transcript_item.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/youtube_transcript_response_raw_transcript_item.pyi` & `carbon_python_sdk-0.2.0/carbon/model/youtube_transcript_response_raw_transcript_item.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/zendesk_authentication.py` & `carbon_python_sdk-0.2.0/carbon/model/zendesk_authentication.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/zendesk_authentication.pyi` & `carbon_python_sdk-0.2.0/carbon/model/zendesk_authentication.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/model/zotero_authentication.py` & `carbon_python_sdk-0.2.0/carbon/model/github_connect_request.py`

 * *Files 20% similar despite different names*

```diff
@@ -19,111 +19,85 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class ZoteroAuthentication(
+class GithubConnectRequest(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
             "access_token",
-            "zotero_id",
-            "source",
-            "access_token_secret",
             "username",
         }
         
         class properties:
-            source = schemas.AnyTypeSchema
-            access_token = schemas.StrSchema
-            access_token_secret = schemas.StrSchema
             username = schemas.StrSchema
-            zotero_id = schemas.StrSchema
+            access_token = schemas.StrSchema
+            sync_source_items = schemas.BoolSchema
             __annotations__ = {
-                "source": source,
-                "access_token": access_token,
-                "access_token_secret": access_token_secret,
                 "username": username,
-                "zotero_id": zotero_id,
+                "access_token": access_token,
+                "sync_source_items": sync_source_items,
             }
     
     access_token: MetaOapg.properties.access_token
-    zotero_id: MetaOapg.properties.zotero_id
-    source: MetaOapg.properties.source
-    access_token_secret: MetaOapg.properties.access_token_secret
     username: MetaOapg.properties.username
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
+    def __getitem__(self, name: typing_extensions.Literal["username"]) -> MetaOapg.properties.username: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["access_token"]) -> MetaOapg.properties.access_token: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["access_token_secret"]) -> MetaOapg.properties.access_token_secret: ...
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["username"]) -> MetaOapg.properties.username: ...
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["zotero_id"]) -> MetaOapg.properties.zotero_id: ...
+    def __getitem__(self, name: typing_extensions.Literal["sync_source_items"]) -> MetaOapg.properties.sync_source_items: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["source", "access_token", "access_token_secret", "username", "zotero_id", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["username", "access_token", "sync_source_items", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["username"]) -> MetaOapg.properties.username: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["access_token"]) -> MetaOapg.properties.access_token: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["access_token_secret"]) -> MetaOapg.properties.access_token_secret: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["username"]) -> MetaOapg.properties.username: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["zotero_id"]) -> MetaOapg.properties.zotero_id: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_source_items"]) -> typing.Union[MetaOapg.properties.sync_source_items, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["source", "access_token", "access_token_secret", "username", "zotero_id", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["username", "access_token", "sync_source_items", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         access_token: typing.Union[MetaOapg.properties.access_token, str, ],
-        zotero_id: typing.Union[MetaOapg.properties.zotero_id, str, ],
-        source: typing.Union[MetaOapg.properties.source, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
-        access_token_secret: typing.Union[MetaOapg.properties.access_token_secret, str, ],
         username: typing.Union[MetaOapg.properties.username, str, ],
+        sync_source_items: typing.Union[MetaOapg.properties.sync_source_items, bool, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'ZoteroAuthentication':
+    ) -> 'GithubConnectRequest':
         return super().__new__(
             cls,
             *args,
             access_token=access_token,
-            zotero_id=zotero_id,
-            source=source,
-            access_token_secret=access_token_secret,
             username=username,
+            sync_source_items=sync_source_items,
             _configuration=_configuration,
             **kwargs,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/model/zotero_authentication.pyi` & `carbon_python_sdk-0.2.0/carbon/model/github_connect_request.pyi`

 * *Files 20% similar despite different names*

```diff
@@ -19,111 +19,85 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 
-class ZoteroAuthentication(
+class GithubConnectRequest(
     schemas.DictSchema
 ):
     """
     This class is auto generated by Konfig (https://konfigthis.com)
     """
 
 
     class MetaOapg:
         required = {
             "access_token",
-            "zotero_id",
-            "source",
-            "access_token_secret",
             "username",
         }
         
         class properties:
-            source = schemas.AnyTypeSchema
-            access_token = schemas.StrSchema
-            access_token_secret = schemas.StrSchema
             username = schemas.StrSchema
-            zotero_id = schemas.StrSchema
+            access_token = schemas.StrSchema
+            sync_source_items = schemas.BoolSchema
             __annotations__ = {
-                "source": source,
-                "access_token": access_token,
-                "access_token_secret": access_token_secret,
                 "username": username,
-                "zotero_id": zotero_id,
+                "access_token": access_token,
+                "sync_source_items": sync_source_items,
             }
     
     access_token: MetaOapg.properties.access_token
-    zotero_id: MetaOapg.properties.zotero_id
-    source: MetaOapg.properties.source
-    access_token_secret: MetaOapg.properties.access_token_secret
     username: MetaOapg.properties.username
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
+    def __getitem__(self, name: typing_extensions.Literal["username"]) -> MetaOapg.properties.username: ...
     
     @typing.overload
     def __getitem__(self, name: typing_extensions.Literal["access_token"]) -> MetaOapg.properties.access_token: ...
     
     @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["access_token_secret"]) -> MetaOapg.properties.access_token_secret: ...
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["username"]) -> MetaOapg.properties.username: ...
-    
-    @typing.overload
-    def __getitem__(self, name: typing_extensions.Literal["zotero_id"]) -> MetaOapg.properties.zotero_id: ...
+    def __getitem__(self, name: typing_extensions.Literal["sync_source_items"]) -> MetaOapg.properties.sync_source_items: ...
     
     @typing.overload
     def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema: ...
     
-    def __getitem__(self, name: typing.Union[typing_extensions.Literal["source", "access_token", "access_token_secret", "username", "zotero_id", ], str]):
+    def __getitem__(self, name: typing.Union[typing_extensions.Literal["username", "access_token", "sync_source_items", ], str]):
         # dict_instance[name] accessor
         return super().__getitem__(name)
     
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["source"]) -> MetaOapg.properties.source: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["username"]) -> MetaOapg.properties.username: ...
     
     @typing.overload
     def get_item_oapg(self, name: typing_extensions.Literal["access_token"]) -> MetaOapg.properties.access_token: ...
     
     @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["access_token_secret"]) -> MetaOapg.properties.access_token_secret: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["username"]) -> MetaOapg.properties.username: ...
-    
-    @typing.overload
-    def get_item_oapg(self, name: typing_extensions.Literal["zotero_id"]) -> MetaOapg.properties.zotero_id: ...
+    def get_item_oapg(self, name: typing_extensions.Literal["sync_source_items"]) -> typing.Union[MetaOapg.properties.sync_source_items, schemas.Unset]: ...
     
     @typing.overload
     def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]: ...
     
-    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["source", "access_token", "access_token_secret", "username", "zotero_id", ], str]):
+    def get_item_oapg(self, name: typing.Union[typing_extensions.Literal["username", "access_token", "sync_source_items", ], str]):
         return super().get_item_oapg(name)
     
 
     def __new__(
         cls,
         *args: typing.Union[dict, frozendict.frozendict, ],
         access_token: typing.Union[MetaOapg.properties.access_token, str, ],
-        zotero_id: typing.Union[MetaOapg.properties.zotero_id, str, ],
-        source: typing.Union[MetaOapg.properties.source, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, bool, None, list, tuple, bytes, io.FileIO, io.BufferedReader, ],
-        access_token_secret: typing.Union[MetaOapg.properties.access_token_secret, str, ],
         username: typing.Union[MetaOapg.properties.username, str, ],
+        sync_source_items: typing.Union[MetaOapg.properties.sync_source_items, bool, schemas.Unset] = schemas.unset,
         _configuration: typing.Optional[schemas.Configuration] = None,
         **kwargs: typing.Union[schemas.AnyTypeSchema, dict, frozendict.frozendict, str, date, datetime, uuid.UUID, int, float, decimal.Decimal, None, list, tuple, bytes],
-    ) -> 'ZoteroAuthentication':
+    ) -> 'GithubConnectRequest':
         return super().__new__(
             cls,
             *args,
             access_token=access_token,
-            zotero_id=zotero_id,
-            source=source,
-            access_token_secret=access_token_secret,
             username=username,
+            sync_source_items=sync_source_items,
             _configuration=_configuration,
             **kwargs,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/models/__init__.py` & `carbon_python_sdk-0.2.0/carbon/models/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -14,24 +14,28 @@
 from carbon.model.add_webhook_props import AddWebhookProps
 from carbon.model.body_create_upload_file_uploadfile_post import BodyCreateUploadFileUploadfilePost
 from carbon.model.chunk_properties import ChunkProperties
 from carbon.model.chunk_properties_nullable import ChunkPropertiesNullable
 from carbon.model.chunks_and_embeddings import ChunksAndEmbeddings
 from carbon.model.chunks_and_embeddings_embedding import ChunksAndEmbeddingsEmbedding
 from carbon.model.chunks_and_embeddings_upload_input import ChunksAndEmbeddingsUploadInput
+from carbon.model.chunks_and_embeddings_upload_input_custom_credentials import ChunksAndEmbeddingsUploadInputCustomCredentials
 from carbon.model.configuration_keys import ConfigurationKeys
 from carbon.model.confluence_authentication import ConfluenceAuthentication
 from carbon.model.connect_data_source_input import ConnectDataSourceInput
 from carbon.model.connect_data_source_response import ConnectDataSourceResponse
+from carbon.model.custom_credentials_type import CustomCredentialsType
+from carbon.model.data_source_extended_input import DataSourceExtendedInput
 from carbon.model.data_source_last_sync_actions import DataSourceLastSyncActions
 from carbon.model.data_source_sync_statuses import DataSourceSyncStatuses
 from carbon.model.data_source_type import DataSourceType
 from carbon.model.data_source_type_nullable import DataSourceTypeNullable
 from carbon.model.delete_files_query_input import DeleteFilesQueryInput
 from carbon.model.delete_files_query_input_file_ids import DeleteFilesQueryInputFileIds
+from carbon.model.delete_files_v2_query_input import DeleteFilesV2QueryInput
 from carbon.model.delete_users_input import DeleteUsersInput
 from carbon.model.delete_users_input_customer_ids import DeleteUsersInputCustomerIds
 from carbon.model.directory_item import DirectoryItem
 from carbon.model.document_response import DocumentResponse
 from carbon.model.document_response_list import DocumentResponseList
 from carbon.model.document_response_tags import DocumentResponseTags
 from carbon.model.document_response_vector import DocumentResponseVector
@@ -42,48 +46,63 @@
 from carbon.model.embedding_properties import EmbeddingProperties
 from carbon.model.embeddings_and_chunks_filters import EmbeddingsAndChunksFilters
 from carbon.model.embeddings_and_chunks_order_by_columns import EmbeddingsAndChunksOrderByColumns
 from carbon.model.embeddings_and_chunks_query_input import EmbeddingsAndChunksQueryInput
 from carbon.model.embeddings_and_chunks_response import EmbeddingsAndChunksResponse
 from carbon.model.external_file_sync_statuses import ExternalFileSyncStatuses
 from carbon.model.external_source_item import ExternalSourceItem
+from carbon.model.external_source_items_order_by import ExternalSourceItemsOrderBy
 from carbon.model.fetch_urls_response import FetchURLsResponse
 from carbon.model.fetch_urls_response_urls import FetchURLsResponseUrls
 from carbon.model.file_content_types import FileContentTypes
 from carbon.model.file_content_types_nullable import FileContentTypesNullable
 from carbon.model.file_formats import FileFormats
 from carbon.model.file_formats_nullable import FileFormatsNullable
 from carbon.model.file_statistics import FileStatistics
 from carbon.model.file_statistics_nullable import FileStatisticsNullable
+from carbon.model.file_sync_config import FileSyncConfig
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable
 from carbon.model.files_query_user_files_deprecated_response import FilesQueryUserFilesDeprecatedResponse
 from carbon.model.fresh_desk_connect_request import FreshDeskConnectRequest
 from carbon.model.freskdesk_authentication import FreskdeskAuthentication
 from carbon.model.generic_success_response import GenericSuccessResponse
 from carbon.model.get_embedding_documents_body import GetEmbeddingDocumentsBody
 from carbon.model.get_embedding_documents_body_file_ids import GetEmbeddingDocumentsBodyFileIds
 from carbon.model.get_embedding_documents_body_parent_file_ids import GetEmbeddingDocumentsBodyParentFileIds
 from carbon.model.get_embedding_documents_body_query_vector import GetEmbeddingDocumentsBodyQueryVector
 from carbon.model.get_embedding_documents_body_tags import GetEmbeddingDocumentsBodyTags
 from carbon.model.gitbook_authetication import GitbookAuthetication
 from carbon.model.gitbook_connect_request import GitbookConnectRequest
 from carbon.model.gitbook_sync_request import GitbookSyncRequest
 from carbon.model.gitbook_sync_request_space_ids import GitbookSyncRequestSpaceIds
+from carbon.model.github_authentication import GithubAuthentication
+from carbon.model.github_connect_request import GithubConnectRequest
+from carbon.model.github_fetch_repos_request import GithubFetchReposRequest
+from carbon.model.github_fetch_repos_request_repos import GithubFetchReposRequestRepos
 from carbon.model.gmail_sync_input import GmailSyncInput
 from carbon.model.http_validation_error import HTTPValidationError
+from carbon.model.helpdesk_file_types import HelpdeskFileTypes
 from carbon.model.hybrid_search_tuning_params import HybridSearchTuningParams
 from carbon.model.hybrid_search_tuning_params_nullable import HybridSearchTuningParamsNullable
 from carbon.model.list_data_source_items_request import ListDataSourceItemsRequest
 from carbon.model.list_data_source_items_response import ListDataSourceItemsResponse
+from carbon.model.list_items_filters import ListItemsFilters
+from carbon.model.list_items_filters_external_ids import ListItemsFiltersExternalIds
+from carbon.model.list_items_filters_ids import ListItemsFiltersIds
+from carbon.model.list_items_filters_nullable import ListItemsFiltersNullable
+from carbon.model.list_items_filters_nullable_external_ids import ListItemsFiltersNullableExternalIds
+from carbon.model.list_items_filters_nullable_ids import ListItemsFiltersNullableIds
 from carbon.model.list_request import ListRequest
 from carbon.model.list_response import ListResponse
 from carbon.model.modify_user_configuration_input import ModifyUserConfigurationInput
 from carbon.model.notion_authentication import NotionAuthentication
 from carbon.model.o_auth_authentication import OAuthAuthentication
 from carbon.model.o_auth_url_request import OAuthURLRequest
 from carbon.model.order_dir import OrderDir
+from carbon.model.order_dir_v2 import OrderDirV2
 from carbon.model.organization_response import OrganizationResponse
 from carbon.model.organization_user_data_source_api import OrganizationUserDataSourceAPI
 from carbon.model.organization_user_data_source_filters import OrganizationUserDataSourceFilters
 from carbon.model.organization_user_data_source_filters_ids import OrganizationUserDataSourceFiltersIds
 from carbon.model.organization_user_data_source_order_by_columns import OrganizationUserDataSourceOrderByColumns
 from carbon.model.organization_user_data_source_query_input import OrganizationUserDataSourceQueryInput
 from carbon.model.organization_user_data_source_response import OrganizationUserDataSourceResponse
@@ -92,14 +111,15 @@
 from carbon.model.organization_user_file_tags_remove import OrganizationUserFileTagsRemove
 from carbon.model.organization_user_file_tags_remove_tags import OrganizationUserFileTagsRemoveTags
 from carbon.model.organization_user_files_to_sync_filters import OrganizationUserFilesToSyncFilters
 from carbon.model.organization_user_files_to_sync_filters_external_file_ids import OrganizationUserFilesToSyncFiltersExternalFileIds
 from carbon.model.organization_user_files_to_sync_filters_ids import OrganizationUserFilesToSyncFiltersIds
 from carbon.model.organization_user_files_to_sync_filters_organization_user_data_source_id import OrganizationUserFilesToSyncFiltersOrganizationUserDataSourceId
 from carbon.model.organization_user_files_to_sync_filters_parent_file_ids import OrganizationUserFilesToSyncFiltersParentFileIds
+from carbon.model.organization_user_files_to_sync_filters_request_ids import OrganizationUserFilesToSyncFiltersRequestIds
 from carbon.model.organization_user_files_to_sync_filters_tags import OrganizationUserFilesToSyncFiltersTags
 from carbon.model.organization_user_files_to_sync_order_by_types import OrganizationUserFilesToSyncOrderByTypes
 from carbon.model.organization_user_files_to_sync_query_input import OrganizationUserFilesToSyncQueryInput
 from carbon.model.outh_url_response import OuthURLResponse
 from carbon.model.outlook_sync_input import OutlookSyncInput
 from carbon.model.pagination import Pagination
 from carbon.model.presigned_url_response import PresignedURLResponse
@@ -122,31 +142,38 @@
 from carbon.model.sitemap_scrape_request_tags import SitemapScrapeRequestTags
 from carbon.model.sync_directory_request import SyncDirectoryRequest
 from carbon.model.sync_files_ids import SyncFilesIds
 from carbon.model.sync_files_request import SyncFilesRequest
 from carbon.model.sync_options import SyncOptions
 from carbon.model.text_embedding_generators import TextEmbeddingGenerators
 from carbon.model.token_response import TokenResponse
+from carbon.model.update_organization_input import UpdateOrganizationInput
+from carbon.model.update_users_input import UpdateUsersInput
+from carbon.model.update_users_input_customer_ids import UpdateUsersInputCustomerIds
 from carbon.model.upload_file_from_url_input import UploadFileFromUrlInput
+from carbon.model.user_configuration import UserConfiguration
+from carbon.model.user_configuration_nullable import UserConfigurationNullable
 from carbon.model.user_file import UserFile
 from carbon.model.user_file_embedding_properties import UserFileEmbeddingProperties
 from carbon.model.user_files_v2 import UserFilesV2
 from carbon.model.user_request_content import UserRequestContent
 from carbon.model.user_response import UserResponse
+from carbon.model.user_response_auto_sync_enabled_sources import UserResponseAutoSyncEnabledSources
 from carbon.model.user_response_unique_file_tags import UserResponseUniqueFileTags
 from carbon.model.utilities_scrape_web_request import UtilitiesScrapeWebRequest
 from carbon.model.validation_error import ValidationError
 from carbon.model.validation_error_loc import ValidationErrorLoc
 from carbon.model.webhook import Webhook
 from carbon.model.webhook_filters import WebhookFilters
 from carbon.model.webhook_filters_ids import WebhookFiltersIds
 from carbon.model.webhook_no_key import WebhookNoKey
 from carbon.model.webhook_order_by_columns import WebhookOrderByColumns
 from carbon.model.webhook_query_input import WebhookQueryInput
 from carbon.model.webhook_query_response import WebhookQueryResponse
+from carbon.model.webhook_status import WebhookStatus
 from carbon.model.webscrape_request import WebscrapeRequest
 from carbon.model.webscrape_request_css_classes_to_skip import WebscrapeRequestCssClassesToSkip
 from carbon.model.webscrape_request_css_selectors_to_skip import WebscrapeRequestCssSelectorsToSkip
 from carbon.model.webscrape_request_html_tags_to_skip import WebscrapeRequestHtmlTagsToSkip
 from carbon.model.webscrape_request_tags import WebscrapeRequestTags
 from carbon.model.white_labeling_response import WhiteLabelingResponse
 from carbon.model.youtube_transcript_response import YoutubeTranscriptResponse
```

### Comparing `carbon_python_sdk-0.1.9/carbon/operation_parameter_map.py` & `carbon_python_sdk-0.2.0/carbon/operation_parameter_map.py`

 * *Files 8% similar despite different names*

```diff
@@ -47,14 +47,17 @@
             {
                 'name': 'file_ids'
             },
             {
                 'name': 'parent_file_ids'
             },
             {
+                'name': 'include_all_children'
+            },
+            {
                 'name': 'tags_v2'
             },
             {
                 'name': 'include_tags'
             },
             {
                 'name': 'include_vectors'
@@ -156,14 +159,24 @@
                 'name': 'send_webhook'
             },
             {
                 'name': 'delete_child_files'
             },
         ]
     },
+    '/delete_files_v2-POST': {
+        'parameters': [
+            {
+                'name': 'filters'
+            },
+            {
+                'name': 'send_webhook'
+            },
+        ]
+    },
     '/parsed_file/{file_id}-GET': {
         'parameters': [
             {
                 'name': 'file_id'
             },
         ]
     },
@@ -268,14 +281,23 @@
             },
             {
                 'name': 'prepend_filename_to_chunks'
             },
             {
                 'name': 'max_items_per_chunk'
             },
+            {
+                'name': 'parse_pdf_tables_with_ocr'
+            },
+            {
+                'name': 'detect_audio_language'
+            },
+            {
+                'name': 'media_type'
+            },
         ]
     },
     '/upload_file_from_url-POST': {
         'parameters': [
             {
                 'name': 'url'
             },
@@ -305,14 +327,20 @@
             },
             {
                 'name': 'prepend_filename_to_chunks'
             },
             {
                 'name': 'max_items_per_chunk'
             },
+            {
+                'name': 'parse_pdf_tables_with_ocr'
+            },
+            {
+                'name': 'detect_audio_language'
+            },
         ]
     },
     '/upload_text-POST': {
         'parameters': [
             {
                 'name': 'contents'
             },
@@ -381,14 +409,23 @@
             },
             {
                 'name': 'prepend_filename_to_chunks'
             },
             {
                 'name': 'sync_files_on_connection'
             },
+            {
+                'name': 'request_id'
+            },
+            {
+                'name': 'sync_source_items'
+            },
+            {
+                'name': 'file_sync_config'
+            },
         ]
     },
     '/integrations/gitbook-POST': {
         'parameters': [
             {
                 'name': 'organization'
             },
@@ -415,24 +452,33 @@
             },
             {
                 'name': 'prepend_filename_to_chunks'
             },
             {
                 'name': 'sync_files_on_connection'
             },
+            {
+                'name': 'request_id'
+            },
+            {
+                'name': 'sync_source_items'
+            },
         ]
     },
     '/integrations/s3-POST': {
         'parameters': [
             {
                 'name': 'access_key'
             },
             {
                 'name': 'access_key_secret'
             },
+            {
+                'name': 'sync_source_items'
+            },
         ]
     },
     '/integrations/oauth_url-POST': {
         'parameters': [
             {
                 'name': 'service'
             },
@@ -486,14 +532,35 @@
             },
             {
                 'name': 'data_source_id'
             },
             {
                 'name': 'connecting_new_account'
             },
+            {
+                'name': 'request_id'
+            },
+            {
+                'name': 'use_ocr'
+            },
+            {
+                'name': 'parse_pdf_tables_with_ocr'
+            },
+            {
+                'name': 'enable_file_picker'
+            },
+            {
+                'name': 'sync_source_items'
+            },
+            {
+                'name': 'incremental_sync'
+            },
+            {
+                'name': 'file_sync_config'
+            },
         ]
     },
     '/integrations/confluence/list-POST': {
         'parameters': [
             {
                 'name': 'data_source_id'
             },
@@ -507,16 +574,25 @@
             {
                 'name': 'data_source_id'
             },
             {
                 'name': 'parent_id'
             },
             {
+                'name': 'filters'
+            },
+            {
                 'name': 'pagination'
             },
+            {
+                'name': 'order_by'
+            },
+            {
+                'name': 'order_dir'
+            },
         ]
     },
     '/integrations/outlook/user_folders-GET': {
         'parameters': [
             {
                 'name': 'data_source_id'
             },
@@ -539,14 +615,27 @@
     '/integrations/outlook/user_categories-GET': {
         'parameters': [
             {
                 'name': 'data_source_id'
             },
         ]
     },
+    '/integrations/github/repos-GET': {
+        'parameters': [
+            {
+                'name': 'per_page'
+            },
+            {
+                'name': 'page'
+            },
+            {
+                'name': 'data_source_id'
+            },
+        ]
+    },
     '/integrations/confluence/sync-POST': {
         'parameters': [
             {
                 'name': 'data_source_id'
             },
             {
                 'name': 'ids'
@@ -574,14 +663,29 @@
             },
             {
                 'name': 'max_items_per_chunk'
             },
             {
                 'name': 'set_page_as_boundary'
             },
+            {
+                'name': 'request_id'
+            },
+            {
+                'name': 'use_ocr'
+            },
+            {
+                'name': 'parse_pdf_tables_with_ocr'
+            },
+            {
+                'name': 'incremental_sync'
+            },
+            {
+                'name': 'file_sync_config'
+            },
         ]
     },
     '/integrations/items/sync-POST': {
         'parameters': [
             {
                 'name': 'data_source_id'
             },
@@ -618,14 +722,42 @@
             },
             {
                 'name': 'max_items_per_chunk'
             },
             {
                 'name': 'set_page_as_boundary'
             },
+            {
+                'name': 'request_id'
+            },
+            {
+                'name': 'use_ocr'
+            },
+            {
+                'name': 'parse_pdf_tables_with_ocr'
+            },
+            {
+                'name': 'incremental_sync'
+            },
+            {
+                'name': 'file_sync_config'
+            },
+        ]
+    },
+    '/integrations/github-POST': {
+        'parameters': [
+            {
+                'name': 'username'
+            },
+            {
+                'name': 'access_token'
+            },
+            {
+                'name': 'sync_source_items'
+            },
         ]
     },
     '/integrations/gitbook/sync-POST': {
         'parameters': [
             {
                 'name': 'space_ids'
             },
@@ -649,14 +781,17 @@
             },
             {
                 'name': 'generate_sparse_vectors'
             },
             {
                 'name': 'prepend_filename_to_chunks'
             },
+            {
+                'name': 'request_id'
+            },
         ]
     },
     '/integrations/gmail/sync-POST': {
         'parameters': [
             {
                 'name': 'filters'
             },
@@ -680,14 +815,26 @@
             },
             {
                 'name': 'prepend_filename_to_chunks'
             },
             {
                 'name': 'data_source_id'
             },
+            {
+                'name': 'request_id'
+            },
+            {
+                'name': 'sync_attachments'
+            },
+            {
+                'name': 'file_sync_config'
+            },
+            {
+                'name': 'incremental_sync'
+            },
         ]
     },
     '/integrations/outlook/sync-POST': {
         'parameters': [
             {
                 'name': 'filters'
             },
@@ -714,14 +861,36 @@
             },
             {
                 'name': 'prepend_filename_to_chunks'
             },
             {
                 'name': 'data_source_id'
             },
+            {
+                'name': 'request_id'
+            },
+            {
+                'name': 'sync_attachments'
+            },
+            {
+                'name': 'file_sync_config'
+            },
+            {
+                'name': 'incremental_sync'
+            },
+        ]
+    },
+    '/integrations/github/sync_repos-POST': {
+        'parameters': [
+            {
+                'name': 'repos'
+            },
+            {
+                'name': 'data_source_id'
+            },
         ]
     },
     '/integrations/rss_feed-POST': {
         'parameters': [
             {
                 'name': 'url'
             },
@@ -742,14 +911,17 @@
             },
             {
                 'name': 'generate_sparse_vectors'
             },
             {
                 'name': 'prepend_filename_to_chunks'
             },
+            {
+                'name': 'request_id'
+            },
         ]
     },
     '/integrations/s3/files-POST': {
         'parameters': [
             {
                 'name': 'ids'
             },
@@ -779,20 +951,43 @@
             },
             {
                 'name': 'set_page_as_boundary'
             },
             {
                 'name': 'data_source_id'
             },
+            {
+                'name': 'request_id'
+            },
+            {
+                'name': 'use_ocr'
+            },
+            {
+                'name': 'parse_pdf_tables_with_ocr'
+            },
+            {
+                'name': 'file_sync_config'
+            },
         ]
     },
     '/organization-GET': {
         'parameters': [
         ]
     },
+    '/organization/update-POST': {
+        'parameters': [
+            {
+                'name': 'global_user_config'
+            },
+        ]
+    },
+    '/organization/statistics-POST': {
+        'parameters': [
+        ]
+    },
     '/delete_users-POST': {
         'parameters': [
             {
                 'name': 'customer_ids'
             },
         ]
     },
@@ -809,14 +1004,30 @@
                 'name': 'configuration_key_name'
             },
             {
                 'name': 'value'
             },
         ]
     },
+    '/update_users-POST': {
+        'parameters': [
+            {
+                'name': 'customer_ids'
+            },
+            {
+                'name': 'auto_sync_enabled_sources'
+            },
+            {
+                'name': 'max_files'
+            },
+            {
+                'name': 'max_files_per_upload'
+            },
+        ]
+    },
     '/fetch_urls-GET': {
         'parameters': [
             {
                 'name': 'url'
             },
         ]
     },
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/__init__.py` & `carbon_python_sdk-0.2.0/carbon/paths/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -21,35 +21,42 @@
     INTEGRATIONS_FRESHDESK = "/integrations/freshdesk"
     INTEGRATIONS_OUTLOOK_USER_FOLDERS = "/integrations/outlook/user_folders"
     INTEGRATIONS_OUTLOOK_USER_CATEGORIES = "/integrations/outlook/user_categories"
     INTEGRATIONS_GMAIL_USER_LABELS = "/integrations/gmail/user_labels"
     INTEGRATIONS_GITBOOK = "/integrations/gitbook"
     INTEGRATIONS_GITBOOK_SPACES = "/integrations/gitbook/spaces"
     INTEGRATIONS_GITBOOK_SYNC = "/integrations/gitbook/sync"
+    INTEGRATIONS_GITHUB = "/integrations/github"
+    INTEGRATIONS_GITHUB_REPOS = "/integrations/github/repos"
+    INTEGRATIONS_GITHUB_SYNC_REPOS = "/integrations/github/sync_repos"
     AUTH_V1_ACCESS_TOKEN = "/auth/v1/access_token"
     AUTH_V1_WHITE_LABELING = "/auth/v1/white_labeling"
     EMBEDDINGS = "/embeddings"
     TEXT_CHUNKS = "/text_chunks"
     UPLOAD_CHUNKS_AND_EMBEDDINGS = "/upload_chunks_and_embeddings"
     ORGANIZATION = "/organization"
+    ORGANIZATION_UPDATE = "/organization/update"
+    ORGANIZATION_STATISTICS = "/organization/statistics"
     USER = "/user"
     MODIFY_USER_CONFIGURATION = "/modify_user_configuration"
     DELETE_USERS = "/delete_users"
+    UPDATE_USERS = "/update_users"
     UPLOADFILE = "/uploadfile"
     UPLOAD_FILE_FROM_URL = "/upload_file_from_url"
     UPLOAD_TEXT = "/upload_text"
-    DELETEFILE_FILE_ID = "/deletefile/{file_id}"
-    DELETE_FILES = "/delete_files"
+    DELETE_FILES_V2 = "/delete_files_v2"
     USER_FILES_V2 = "/user_files_v2"
     CREATE_USER_FILE_TAGS = "/create_user_file_tags"
     DELETE_USER_FILE_TAGS = "/delete_user_file_tags"
     RESYNC_FILE = "/resync_file"
     RAW_FILE_FILE_ID = "/raw_file/{file_id}"
     PARSED_FILE_FILE_ID = "/parsed_file/{file_id}"
     USER_FILES = "/user_files"
+    DELETEFILE_FILE_ID = "/deletefile/{file_id}"
+    DELETE_FILES = "/delete_files"
     WEBHOOKS = "/webhooks"
     ADD_WEBHOOK = "/add_webhook"
     DELETE_WEBHOOK_WEBHOOK_ID = "/delete_webhook/{webhook_id}"
     USER_DATA_SOURCES = "/user_data_sources"
     REVOKE_ACCESS_TOKEN = "/revoke_access_token"
     WEB_SCRAPE = "/web_scrape"
     PROCESS_SITEMAP = "/process_sitemap"
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/add_webhook/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/add_webhook/post.py`

 * *Files 0% similar despite different names*

```diff
@@ -55,15 +55,15 @@
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
 _auth = [
-    'accessToken',
+    'apiKey',
 ]
 SchemaFor200ResponseBodyApplicationJson = WebhookSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
     body: Webhook
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/add_webhook/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/add_webhook/post.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/auth_v1_access_token/get.py` & `carbon_python_sdk-0.2.0/carbon/paths/auth_v1_access_token/get.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/auth_v1_access_token/get.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/auth_v1_access_token/get.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/auth_v1_white_labeling/get.py` & `carbon_python_sdk-0.2.0/carbon/paths/auth_v1_white_labeling/get.pyi`

 * *Files 6% similar despite different names*

```diff
@@ -28,29 +28,21 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
-from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
 from carbon.model.white_labeling_response import WhiteLabelingResponse as WhiteLabelingResponseSchema
 
-from carbon.type.http_validation_error import HTTPValidationError
 from carbon.type.white_labeling_response import WhiteLabelingResponse
 
 from ...api_client import Dictionary
-from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.white_labeling_response import WhiteLabelingResponse as WhiteLabelingResponsePydantic
 
-from . import path
-
-_auth = [
-    'accessToken',
-]
 SchemaFor200ResponseBodyApplicationJson = WhiteLabelingResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
     body: WhiteLabelingResponse
 
@@ -64,39 +56,14 @@
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor200ResponseBodyApplicationJson),
     },
 )
-SchemaFor422ResponseBodyApplicationJson = HTTPValidationErrorSchema
-
-
-@dataclass
-class ApiResponseFor422(api_client.ApiResponse):
-    body: HTTPValidationError
-
-
-@dataclass
-class ApiResponseFor422Async(api_client.AsyncApiResponse):
-    body: HTTPValidationError
-
-
-_response_for_422 = api_client.OpenApiResponse(
-    response_cls=ApiResponseFor422,
-    response_cls_async=ApiResponseFor422Async,
-    content={
-        'application/json': api_client.MediaType(
-            schema=SchemaFor422ResponseBodyApplicationJson),
-    },
-)
-_status_code_to_response = {
-    '200': _response_for_200,
-    '422': _response_for_422,
-}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/auth_v1_white_labeling/get.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/auth_v1_white_labeling/get.py`

 * *Files 5% similar despite different names*

```diff
@@ -28,24 +28,28 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
-from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
 from carbon.model.white_labeling_response import WhiteLabelingResponse as WhiteLabelingResponseSchema
 
-from carbon.type.http_validation_error import HTTPValidationError
 from carbon.type.white_labeling_response import WhiteLabelingResponse
 
 from ...api_client import Dictionary
-from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.white_labeling_response import WhiteLabelingResponse as WhiteLabelingResponsePydantic
 
+from . import path
+
+_auth = [
+    'accessToken',
+    'apiKey',
+    'customerId',
+]
 SchemaFor200ResponseBodyApplicationJson = WhiteLabelingResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
     body: WhiteLabelingResponse
 
@@ -59,35 +63,17 @@
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor200ResponseBodyApplicationJson),
     },
 )
-SchemaFor422ResponseBodyApplicationJson = HTTPValidationErrorSchema
-
-
-@dataclass
-class ApiResponseFor422(api_client.ApiResponse):
-    body: HTTPValidationError
-
-
-@dataclass
-class ApiResponseFor422Async(api_client.AsyncApiResponse):
-    body: HTTPValidationError
-
-
-_response_for_422 = api_client.OpenApiResponse(
-    response_cls=ApiResponseFor422,
-    response_cls_async=ApiResponseFor422Async,
-    content={
-        'application/json': api_client.MediaType(
-            schema=SchemaFor422ResponseBodyApplicationJson),
-    },
-)
+_status_code_to_response = {
+    '200': _response_for_200,
+}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/create_user_file_tags/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/create_user_file_tags/post.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/create_user_file_tags/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/create_user_file_tags/post.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/delete_files/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/delete_files/post.py`

 * *Files 2% similar despite different names*

```diff
@@ -343,14 +343,15 @@
     
         return api_response
 
 
 class DeleteManyRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
+    @api_client.DeprecationWarningOnce(prefix="files")
     async def adelete_many(
         self,
         file_ids: typing.Optional[DeleteFilesQueryInputFileIds] = None,
         sync_statuses: typing.Optional[typing.Optional[typing.List[ExternalFileSyncStatuses]]] = None,
         delete_non_synced_only: typing.Optional[bool] = None,
         send_webhook: typing.Optional[bool] = None,
         delete_child_files: typing.Optional[bool] = None,
@@ -368,14 +369,15 @@
             delete_child_files=delete_child_files,
         )
         return await self._adelete_many_oapg(
             body=args.body,
             **kwargs,
         )
     
+    @api_client.DeprecationWarningOnce(prefix="files")
     def delete_many(
         self,
         file_ids: typing.Optional[DeleteFilesQueryInputFileIds] = None,
         sync_statuses: typing.Optional[typing.Optional[typing.List[ExternalFileSyncStatuses]]] = None,
         delete_non_synced_only: typing.Optional[bool] = None,
         send_webhook: typing.Optional[bool] = None,
         delete_child_files: typing.Optional[bool] = None,
@@ -392,14 +394,15 @@
         )
         return self._delete_many_oapg(
             body=args.body,
         )
 
 class DeleteMany(BaseApi):
 
+    @api_client.DeprecationWarningOnce(prefix="files")
     async def adelete_many(
         self,
         file_ids: typing.Optional[DeleteFilesQueryInputFileIds] = None,
         sync_statuses: typing.Optional[typing.Optional[typing.List[ExternalFileSyncStatuses]]] = None,
         delete_non_synced_only: typing.Optional[bool] = None,
         send_webhook: typing.Optional[bool] = None,
         delete_child_files: typing.Optional[bool] = None,
@@ -415,14 +418,15 @@
             **kwargs,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
+    @api_client.DeprecationWarningOnce(prefix="files")
     def delete_many(
         self,
         file_ids: typing.Optional[DeleteFilesQueryInputFileIds] = None,
         sync_statuses: typing.Optional[typing.Optional[typing.List[ExternalFileSyncStatuses]]] = None,
         delete_non_synced_only: typing.Optional[bool] = None,
         send_webhook: typing.Optional[bool] = None,
         delete_child_files: typing.Optional[bool] = None,
@@ -439,14 +443,15 @@
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
+    @api_client.DeprecationWarningOnce(prefix="files")
     async def apost(
         self,
         file_ids: typing.Optional[DeleteFilesQueryInputFileIds] = None,
         sync_statuses: typing.Optional[typing.Optional[typing.List[ExternalFileSyncStatuses]]] = None,
         delete_non_synced_only: typing.Optional[bool] = None,
         send_webhook: typing.Optional[bool] = None,
         delete_child_files: typing.Optional[bool] = None,
@@ -464,14 +469,15 @@
             delete_child_files=delete_child_files,
         )
         return await self._adelete_many_oapg(
             body=args.body,
             **kwargs,
         )
     
+    @api_client.DeprecationWarningOnce(prefix="files")
     def post(
         self,
         file_ids: typing.Optional[DeleteFilesQueryInputFileIds] = None,
         sync_statuses: typing.Optional[typing.Optional[typing.List[ExternalFileSyncStatuses]]] = None,
         delete_non_synced_only: typing.Optional[bool] = None,
         send_webhook: typing.Optional[bool] = None,
         delete_child_files: typing.Optional[bool] = None,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/delete_files/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/delete_files/post.pyi`

 * *Files 5% similar despite different names*

```diff
@@ -332,14 +332,15 @@
     
         return api_response
 
 
 class DeleteManyRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
+    @api_client.DeprecationWarningOnce(prefix="files")
     async def adelete_many(
         self,
         file_ids: typing.Optional[DeleteFilesQueryInputFileIds] = None,
         sync_statuses: typing.Optional[typing.Optional[typing.List[ExternalFileSyncStatuses]]] = None,
         delete_non_synced_only: typing.Optional[bool] = None,
         send_webhook: typing.Optional[bool] = None,
         delete_child_files: typing.Optional[bool] = None,
@@ -357,14 +358,15 @@
             delete_child_files=delete_child_files,
         )
         return await self._adelete_many_oapg(
             body=args.body,
             **kwargs,
         )
     
+    @api_client.DeprecationWarningOnce(prefix="files")
     def delete_many(
         self,
         file_ids: typing.Optional[DeleteFilesQueryInputFileIds] = None,
         sync_statuses: typing.Optional[typing.Optional[typing.List[ExternalFileSyncStatuses]]] = None,
         delete_non_synced_only: typing.Optional[bool] = None,
         send_webhook: typing.Optional[bool] = None,
         delete_child_files: typing.Optional[bool] = None,
@@ -381,14 +383,15 @@
         )
         return self._delete_many_oapg(
             body=args.body,
         )
 
 class DeleteMany(BaseApi):
 
+    @api_client.DeprecationWarningOnce(prefix="files")
     async def adelete_many(
         self,
         file_ids: typing.Optional[DeleteFilesQueryInputFileIds] = None,
         sync_statuses: typing.Optional[typing.Optional[typing.List[ExternalFileSyncStatuses]]] = None,
         delete_non_synced_only: typing.Optional[bool] = None,
         send_webhook: typing.Optional[bool] = None,
         delete_child_files: typing.Optional[bool] = None,
@@ -404,14 +407,15 @@
             **kwargs,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
+    @api_client.DeprecationWarningOnce(prefix="files")
     def delete_many(
         self,
         file_ids: typing.Optional[DeleteFilesQueryInputFileIds] = None,
         sync_statuses: typing.Optional[typing.Optional[typing.List[ExternalFileSyncStatuses]]] = None,
         delete_non_synced_only: typing.Optional[bool] = None,
         send_webhook: typing.Optional[bool] = None,
         delete_child_files: typing.Optional[bool] = None,
@@ -428,14 +432,15 @@
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
+    @api_client.DeprecationWarningOnce(prefix="files")
     async def apost(
         self,
         file_ids: typing.Optional[DeleteFilesQueryInputFileIds] = None,
         sync_statuses: typing.Optional[typing.Optional[typing.List[ExternalFileSyncStatuses]]] = None,
         delete_non_synced_only: typing.Optional[bool] = None,
         send_webhook: typing.Optional[bool] = None,
         delete_child_files: typing.Optional[bool] = None,
@@ -453,14 +458,15 @@
             delete_child_files=delete_child_files,
         )
         return await self._adelete_many_oapg(
             body=args.body,
             **kwargs,
         )
     
+    @api_client.DeprecationWarningOnce(prefix="files")
     def post(
         self,
         file_ids: typing.Optional[DeleteFilesQueryInputFileIds] = None,
         sync_statuses: typing.Optional[typing.Optional[typing.List[ExternalFileSyncStatuses]]] = None,
         delete_non_synced_only: typing.Optional[bool] = None,
         send_webhook: typing.Optional[bool] = None,
         delete_child_files: typing.Optional[bool] = None,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/delete_user_file_tags/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/delete_user_file_tags/post.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/delete_user_file_tags/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/delete_user_file_tags/post.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/delete_users/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/delete_users/post.py`

 * *Files 0% similar despite different names*

```diff
@@ -58,15 +58,15 @@
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
 _auth = [
-    'accessToken',
+    'apiKey',
 ]
 SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
     body: GenericSuccessResponse
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/delete_users/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/delete_users/post.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/delete_webhook_webhook_id/delete.py` & `carbon_python_sdk-0.2.0/carbon/paths/delete_webhook_webhook_id/delete.py`

 * *Files 0% similar despite different names*

```diff
@@ -67,15 +67,15 @@
 request_path_webhook_id = api_client.PathParameter(
     name="webhook_id",
     style=api_client.ParameterStyle.SIMPLE,
     schema=WebhookIdSchema,
     required=True,
 )
 _auth = [
-    'accessToken',
+    'apiKey',
 ]
 SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
     body: GenericSuccessResponse
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/delete_webhook_webhook_id/delete.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/delete_webhook_webhook_id/delete.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/deletefile_file_id/delete.py` & `carbon_python_sdk-0.2.0/carbon/paths/deletefile_file_id/delete.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/deletefile_file_id/delete.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/deletefile_file_id/delete.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/embeddings/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/embeddings/post.py`

 * *Files 7% similar despite different names*

```diff
@@ -141,14 +141,15 @@
         self,
         query: str,
         k: int,
         tags: typing.Optional[GetEmbeddingDocumentsBodyTags] = None,
         query_vector: typing.Optional[GetEmbeddingDocumentsBodyQueryVector] = None,
         file_ids: typing.Optional[GetEmbeddingDocumentsBodyFileIds] = None,
         parent_file_ids: typing.Optional[GetEmbeddingDocumentsBodyParentFileIds] = None,
+        include_all_children: typing.Optional[bool] = None,
         tags_v2: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         include_tags: typing.Optional[typing.Optional[bool]] = None,
         include_vectors: typing.Optional[typing.Optional[bool]] = None,
         include_raw_file: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search_tuning_parameters: typing.Optional[HybridSearchTuningParamsNullable] = None,
         media_type: typing.Optional[FileContentTypesNullable] = None,
@@ -164,14 +165,16 @@
             _body["query_vector"] = query_vector
         if k is not None:
             _body["k"] = k
         if file_ids is not None:
             _body["file_ids"] = file_ids
         if parent_file_ids is not None:
             _body["parent_file_ids"] = parent_file_ids
+        if include_all_children is not None:
+            _body["include_all_children"] = include_all_children
         if tags_v2 is not None:
             _body["tags_v2"] = tags_v2
         if include_tags is not None:
             _body["include_tags"] = include_tags
         if include_vectors is not None:
             _body["include_vectors"] = include_vectors
         if include_raw_file is not None:
@@ -393,14 +396,15 @@
         self,
         query: str,
         k: int,
         tags: typing.Optional[GetEmbeddingDocumentsBodyTags] = None,
         query_vector: typing.Optional[GetEmbeddingDocumentsBodyQueryVector] = None,
         file_ids: typing.Optional[GetEmbeddingDocumentsBodyFileIds] = None,
         parent_file_ids: typing.Optional[GetEmbeddingDocumentsBodyParentFileIds] = None,
+        include_all_children: typing.Optional[bool] = None,
         tags_v2: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         include_tags: typing.Optional[typing.Optional[bool]] = None,
         include_vectors: typing.Optional[typing.Optional[bool]] = None,
         include_raw_file: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search_tuning_parameters: typing.Optional[HybridSearchTuningParamsNullable] = None,
         media_type: typing.Optional[FileContentTypesNullable] = None,
@@ -414,14 +418,15 @@
         args = self._get_documents_mapped_args(
             query=query,
             k=k,
             tags=tags,
             query_vector=query_vector,
             file_ids=file_ids,
             parent_file_ids=parent_file_ids,
+            include_all_children=include_all_children,
             tags_v2=tags_v2,
             include_tags=include_tags,
             include_vectors=include_vectors,
             include_raw_file=include_raw_file,
             hybrid_search=hybrid_search,
             hybrid_search_tuning_parameters=hybrid_search_tuning_parameters,
             media_type=media_type,
@@ -436,14 +441,15 @@
         self,
         query: str,
         k: int,
         tags: typing.Optional[GetEmbeddingDocumentsBodyTags] = None,
         query_vector: typing.Optional[GetEmbeddingDocumentsBodyQueryVector] = None,
         file_ids: typing.Optional[GetEmbeddingDocumentsBodyFileIds] = None,
         parent_file_ids: typing.Optional[GetEmbeddingDocumentsBodyParentFileIds] = None,
+        include_all_children: typing.Optional[bool] = None,
         tags_v2: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         include_tags: typing.Optional[typing.Optional[bool]] = None,
         include_vectors: typing.Optional[typing.Optional[bool]] = None,
         include_raw_file: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search_tuning_parameters: typing.Optional[HybridSearchTuningParamsNullable] = None,
         media_type: typing.Optional[FileContentTypesNullable] = None,
@@ -455,14 +461,15 @@
         args = self._get_documents_mapped_args(
             query=query,
             k=k,
             tags=tags,
             query_vector=query_vector,
             file_ids=file_ids,
             parent_file_ids=parent_file_ids,
+            include_all_children=include_all_children,
             tags_v2=tags_v2,
             include_tags=include_tags,
             include_vectors=include_vectors,
             include_raw_file=include_raw_file,
             hybrid_search=hybrid_search,
             hybrid_search_tuning_parameters=hybrid_search_tuning_parameters,
             media_type=media_type,
@@ -478,14 +485,15 @@
         self,
         query: str,
         k: int,
         tags: typing.Optional[GetEmbeddingDocumentsBodyTags] = None,
         query_vector: typing.Optional[GetEmbeddingDocumentsBodyQueryVector] = None,
         file_ids: typing.Optional[GetEmbeddingDocumentsBodyFileIds] = None,
         parent_file_ids: typing.Optional[GetEmbeddingDocumentsBodyParentFileIds] = None,
+        include_all_children: typing.Optional[bool] = None,
         tags_v2: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         include_tags: typing.Optional[typing.Optional[bool]] = None,
         include_vectors: typing.Optional[typing.Optional[bool]] = None,
         include_raw_file: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search_tuning_parameters: typing.Optional[HybridSearchTuningParamsNullable] = None,
         media_type: typing.Optional[FileContentTypesNullable] = None,
@@ -496,14 +504,15 @@
         raw_response = await self.raw.aget_documents(
             query=query,
             k=k,
             tags=tags,
             query_vector=query_vector,
             file_ids=file_ids,
             parent_file_ids=parent_file_ids,
+            include_all_children=include_all_children,
             tags_v2=tags_v2,
             include_tags=include_tags,
             include_vectors=include_vectors,
             include_raw_file=include_raw_file,
             hybrid_search=hybrid_search,
             hybrid_search_tuning_parameters=hybrid_search_tuning_parameters,
             media_type=media_type,
@@ -519,14 +528,15 @@
         self,
         query: str,
         k: int,
         tags: typing.Optional[GetEmbeddingDocumentsBodyTags] = None,
         query_vector: typing.Optional[GetEmbeddingDocumentsBodyQueryVector] = None,
         file_ids: typing.Optional[GetEmbeddingDocumentsBodyFileIds] = None,
         parent_file_ids: typing.Optional[GetEmbeddingDocumentsBodyParentFileIds] = None,
+        include_all_children: typing.Optional[bool] = None,
         tags_v2: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         include_tags: typing.Optional[typing.Optional[bool]] = None,
         include_vectors: typing.Optional[typing.Optional[bool]] = None,
         include_raw_file: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search_tuning_parameters: typing.Optional[HybridSearchTuningParamsNullable] = None,
         media_type: typing.Optional[FileContentTypesNullable] = None,
@@ -536,14 +546,15 @@
         raw_response = self.raw.get_documents(
             query=query,
             k=k,
             tags=tags,
             query_vector=query_vector,
             file_ids=file_ids,
             parent_file_ids=parent_file_ids,
+            include_all_children=include_all_children,
             tags_v2=tags_v2,
             include_tags=include_tags,
             include_vectors=include_vectors,
             include_raw_file=include_raw_file,
             hybrid_search=hybrid_search,
             hybrid_search_tuning_parameters=hybrid_search_tuning_parameters,
             media_type=media_type,
@@ -561,14 +572,15 @@
         self,
         query: str,
         k: int,
         tags: typing.Optional[GetEmbeddingDocumentsBodyTags] = None,
         query_vector: typing.Optional[GetEmbeddingDocumentsBodyQueryVector] = None,
         file_ids: typing.Optional[GetEmbeddingDocumentsBodyFileIds] = None,
         parent_file_ids: typing.Optional[GetEmbeddingDocumentsBodyParentFileIds] = None,
+        include_all_children: typing.Optional[bool] = None,
         tags_v2: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         include_tags: typing.Optional[typing.Optional[bool]] = None,
         include_vectors: typing.Optional[typing.Optional[bool]] = None,
         include_raw_file: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search_tuning_parameters: typing.Optional[HybridSearchTuningParamsNullable] = None,
         media_type: typing.Optional[FileContentTypesNullable] = None,
@@ -582,14 +594,15 @@
         args = self._get_documents_mapped_args(
             query=query,
             k=k,
             tags=tags,
             query_vector=query_vector,
             file_ids=file_ids,
             parent_file_ids=parent_file_ids,
+            include_all_children=include_all_children,
             tags_v2=tags_v2,
             include_tags=include_tags,
             include_vectors=include_vectors,
             include_raw_file=include_raw_file,
             hybrid_search=hybrid_search,
             hybrid_search_tuning_parameters=hybrid_search_tuning_parameters,
             media_type=media_type,
@@ -604,14 +617,15 @@
         self,
         query: str,
         k: int,
         tags: typing.Optional[GetEmbeddingDocumentsBodyTags] = None,
         query_vector: typing.Optional[GetEmbeddingDocumentsBodyQueryVector] = None,
         file_ids: typing.Optional[GetEmbeddingDocumentsBodyFileIds] = None,
         parent_file_ids: typing.Optional[GetEmbeddingDocumentsBodyParentFileIds] = None,
+        include_all_children: typing.Optional[bool] = None,
         tags_v2: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         include_tags: typing.Optional[typing.Optional[bool]] = None,
         include_vectors: typing.Optional[typing.Optional[bool]] = None,
         include_raw_file: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search_tuning_parameters: typing.Optional[HybridSearchTuningParamsNullable] = None,
         media_type: typing.Optional[FileContentTypesNullable] = None,
@@ -623,14 +637,15 @@
         args = self._get_documents_mapped_args(
             query=query,
             k=k,
             tags=tags,
             query_vector=query_vector,
             file_ids=file_ids,
             parent_file_ids=parent_file_ids,
+            include_all_children=include_all_children,
             tags_v2=tags_v2,
             include_tags=include_tags,
             include_vectors=include_vectors,
             include_raw_file=include_raw_file,
             hybrid_search=hybrid_search,
             hybrid_search_tuning_parameters=hybrid_search_tuning_parameters,
             media_type=media_type,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/embeddings/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/embeddings/post.pyi`

 * *Files 7% similar despite different names*

```diff
@@ -130,14 +130,15 @@
         self,
         query: str,
         k: int,
         tags: typing.Optional[GetEmbeddingDocumentsBodyTags] = None,
         query_vector: typing.Optional[GetEmbeddingDocumentsBodyQueryVector] = None,
         file_ids: typing.Optional[GetEmbeddingDocumentsBodyFileIds] = None,
         parent_file_ids: typing.Optional[GetEmbeddingDocumentsBodyParentFileIds] = None,
+        include_all_children: typing.Optional[bool] = None,
         tags_v2: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         include_tags: typing.Optional[typing.Optional[bool]] = None,
         include_vectors: typing.Optional[typing.Optional[bool]] = None,
         include_raw_file: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search_tuning_parameters: typing.Optional[HybridSearchTuningParamsNullable] = None,
         media_type: typing.Optional[FileContentTypesNullable] = None,
@@ -153,14 +154,16 @@
             _body["query_vector"] = query_vector
         if k is not None:
             _body["k"] = k
         if file_ids is not None:
             _body["file_ids"] = file_ids
         if parent_file_ids is not None:
             _body["parent_file_ids"] = parent_file_ids
+        if include_all_children is not None:
+            _body["include_all_children"] = include_all_children
         if tags_v2 is not None:
             _body["tags_v2"] = tags_v2
         if include_tags is not None:
             _body["include_tags"] = include_tags
         if include_vectors is not None:
             _body["include_vectors"] = include_vectors
         if include_raw_file is not None:
@@ -382,14 +385,15 @@
         self,
         query: str,
         k: int,
         tags: typing.Optional[GetEmbeddingDocumentsBodyTags] = None,
         query_vector: typing.Optional[GetEmbeddingDocumentsBodyQueryVector] = None,
         file_ids: typing.Optional[GetEmbeddingDocumentsBodyFileIds] = None,
         parent_file_ids: typing.Optional[GetEmbeddingDocumentsBodyParentFileIds] = None,
+        include_all_children: typing.Optional[bool] = None,
         tags_v2: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         include_tags: typing.Optional[typing.Optional[bool]] = None,
         include_vectors: typing.Optional[typing.Optional[bool]] = None,
         include_raw_file: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search_tuning_parameters: typing.Optional[HybridSearchTuningParamsNullable] = None,
         media_type: typing.Optional[FileContentTypesNullable] = None,
@@ -403,14 +407,15 @@
         args = self._get_documents_mapped_args(
             query=query,
             k=k,
             tags=tags,
             query_vector=query_vector,
             file_ids=file_ids,
             parent_file_ids=parent_file_ids,
+            include_all_children=include_all_children,
             tags_v2=tags_v2,
             include_tags=include_tags,
             include_vectors=include_vectors,
             include_raw_file=include_raw_file,
             hybrid_search=hybrid_search,
             hybrid_search_tuning_parameters=hybrid_search_tuning_parameters,
             media_type=media_type,
@@ -425,14 +430,15 @@
         self,
         query: str,
         k: int,
         tags: typing.Optional[GetEmbeddingDocumentsBodyTags] = None,
         query_vector: typing.Optional[GetEmbeddingDocumentsBodyQueryVector] = None,
         file_ids: typing.Optional[GetEmbeddingDocumentsBodyFileIds] = None,
         parent_file_ids: typing.Optional[GetEmbeddingDocumentsBodyParentFileIds] = None,
+        include_all_children: typing.Optional[bool] = None,
         tags_v2: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         include_tags: typing.Optional[typing.Optional[bool]] = None,
         include_vectors: typing.Optional[typing.Optional[bool]] = None,
         include_raw_file: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search_tuning_parameters: typing.Optional[HybridSearchTuningParamsNullable] = None,
         media_type: typing.Optional[FileContentTypesNullable] = None,
@@ -444,14 +450,15 @@
         args = self._get_documents_mapped_args(
             query=query,
             k=k,
             tags=tags,
             query_vector=query_vector,
             file_ids=file_ids,
             parent_file_ids=parent_file_ids,
+            include_all_children=include_all_children,
             tags_v2=tags_v2,
             include_tags=include_tags,
             include_vectors=include_vectors,
             include_raw_file=include_raw_file,
             hybrid_search=hybrid_search,
             hybrid_search_tuning_parameters=hybrid_search_tuning_parameters,
             media_type=media_type,
@@ -467,14 +474,15 @@
         self,
         query: str,
         k: int,
         tags: typing.Optional[GetEmbeddingDocumentsBodyTags] = None,
         query_vector: typing.Optional[GetEmbeddingDocumentsBodyQueryVector] = None,
         file_ids: typing.Optional[GetEmbeddingDocumentsBodyFileIds] = None,
         parent_file_ids: typing.Optional[GetEmbeddingDocumentsBodyParentFileIds] = None,
+        include_all_children: typing.Optional[bool] = None,
         tags_v2: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         include_tags: typing.Optional[typing.Optional[bool]] = None,
         include_vectors: typing.Optional[typing.Optional[bool]] = None,
         include_raw_file: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search_tuning_parameters: typing.Optional[HybridSearchTuningParamsNullable] = None,
         media_type: typing.Optional[FileContentTypesNullable] = None,
@@ -485,14 +493,15 @@
         raw_response = await self.raw.aget_documents(
             query=query,
             k=k,
             tags=tags,
             query_vector=query_vector,
             file_ids=file_ids,
             parent_file_ids=parent_file_ids,
+            include_all_children=include_all_children,
             tags_v2=tags_v2,
             include_tags=include_tags,
             include_vectors=include_vectors,
             include_raw_file=include_raw_file,
             hybrid_search=hybrid_search,
             hybrid_search_tuning_parameters=hybrid_search_tuning_parameters,
             media_type=media_type,
@@ -508,14 +517,15 @@
         self,
         query: str,
         k: int,
         tags: typing.Optional[GetEmbeddingDocumentsBodyTags] = None,
         query_vector: typing.Optional[GetEmbeddingDocumentsBodyQueryVector] = None,
         file_ids: typing.Optional[GetEmbeddingDocumentsBodyFileIds] = None,
         parent_file_ids: typing.Optional[GetEmbeddingDocumentsBodyParentFileIds] = None,
+        include_all_children: typing.Optional[bool] = None,
         tags_v2: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         include_tags: typing.Optional[typing.Optional[bool]] = None,
         include_vectors: typing.Optional[typing.Optional[bool]] = None,
         include_raw_file: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search_tuning_parameters: typing.Optional[HybridSearchTuningParamsNullable] = None,
         media_type: typing.Optional[FileContentTypesNullable] = None,
@@ -525,14 +535,15 @@
         raw_response = self.raw.get_documents(
             query=query,
             k=k,
             tags=tags,
             query_vector=query_vector,
             file_ids=file_ids,
             parent_file_ids=parent_file_ids,
+            include_all_children=include_all_children,
             tags_v2=tags_v2,
             include_tags=include_tags,
             include_vectors=include_vectors,
             include_raw_file=include_raw_file,
             hybrid_search=hybrid_search,
             hybrid_search_tuning_parameters=hybrid_search_tuning_parameters,
             media_type=media_type,
@@ -550,14 +561,15 @@
         self,
         query: str,
         k: int,
         tags: typing.Optional[GetEmbeddingDocumentsBodyTags] = None,
         query_vector: typing.Optional[GetEmbeddingDocumentsBodyQueryVector] = None,
         file_ids: typing.Optional[GetEmbeddingDocumentsBodyFileIds] = None,
         parent_file_ids: typing.Optional[GetEmbeddingDocumentsBodyParentFileIds] = None,
+        include_all_children: typing.Optional[bool] = None,
         tags_v2: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         include_tags: typing.Optional[typing.Optional[bool]] = None,
         include_vectors: typing.Optional[typing.Optional[bool]] = None,
         include_raw_file: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search_tuning_parameters: typing.Optional[HybridSearchTuningParamsNullable] = None,
         media_type: typing.Optional[FileContentTypesNullable] = None,
@@ -571,14 +583,15 @@
         args = self._get_documents_mapped_args(
             query=query,
             k=k,
             tags=tags,
             query_vector=query_vector,
             file_ids=file_ids,
             parent_file_ids=parent_file_ids,
+            include_all_children=include_all_children,
             tags_v2=tags_v2,
             include_tags=include_tags,
             include_vectors=include_vectors,
             include_raw_file=include_raw_file,
             hybrid_search=hybrid_search,
             hybrid_search_tuning_parameters=hybrid_search_tuning_parameters,
             media_type=media_type,
@@ -593,14 +606,15 @@
         self,
         query: str,
         k: int,
         tags: typing.Optional[GetEmbeddingDocumentsBodyTags] = None,
         query_vector: typing.Optional[GetEmbeddingDocumentsBodyQueryVector] = None,
         file_ids: typing.Optional[GetEmbeddingDocumentsBodyFileIds] = None,
         parent_file_ids: typing.Optional[GetEmbeddingDocumentsBodyParentFileIds] = None,
+        include_all_children: typing.Optional[bool] = None,
         tags_v2: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         include_tags: typing.Optional[typing.Optional[bool]] = None,
         include_vectors: typing.Optional[typing.Optional[bool]] = None,
         include_raw_file: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search: typing.Optional[typing.Optional[bool]] = None,
         hybrid_search_tuning_parameters: typing.Optional[HybridSearchTuningParamsNullable] = None,
         media_type: typing.Optional[FileContentTypesNullable] = None,
@@ -612,14 +626,15 @@
         args = self._get_documents_mapped_args(
             query=query,
             k=k,
             tags=tags,
             query_vector=query_vector,
             file_ids=file_ids,
             parent_file_ids=parent_file_ids,
+            include_all_children=include_all_children,
             tags_v2=tags_v2,
             include_tags=include_tags,
             include_vectors=include_vectors,
             include_raw_file=include_raw_file,
             hybrid_search=hybrid_search,
             hybrid_search_tuning_parameters=hybrid_search_tuning_parameters,
             media_type=media_type,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/fetch_urls/get.py` & `carbon_python_sdk-0.2.0/carbon/paths/fetch_urls/get.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/fetch_urls/get.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/fetch_urls/get.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/fetch_youtube_transcript/get.py` & `carbon_python_sdk-0.2.0/carbon/paths/fetch_youtube_transcript/get.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/fetch_youtube_transcript/get.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/fetch_youtube_transcript/get.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/health/get.py` & `carbon_python_sdk-0.2.0/carbon/paths/health/get.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/health/get.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/health/get.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_confluence_list/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_confluence_list/post.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_confluence_list/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_confluence_list/post.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_confluence_sync/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_rss_feed/post.py`

 * *Files 8% similar despite different names*

```diff
@@ -29,39 +29,36 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullableSchema
-from carbon.model.sync_files_request import SyncFilesRequest as SyncFilesRequestSchema
-from carbon.model.sync_files_ids import SyncFilesIds as SyncFilesIdsSchema
+from carbon.model.rss_feed_input import RSSFeedInput as RSSFeedInputSchema
+from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
 from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
 
-from carbon.type.sync_files_request import SyncFilesRequest
+from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
 from carbon.type.generic_success_response import GenericSuccessResponse
-from carbon.type.sync_files_ids import SyncFilesIds
-from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.type.rss_feed_input import RSSFeedInput
 
 from ...api_client import Dictionary
-from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullablePydantic
-from carbon.pydantic.sync_files_request import SyncFilesRequest as SyncFilesRequestPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
-from carbon.pydantic.sync_files_ids import SyncFilesIds as SyncFilesIdsPydantic
+from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
+from carbon.pydantic.rss_feed_input import RSSFeedInput as RSSFeedInputPydantic
 
 from . import path
 
 # body param
-SchemaForRequestBodyApplicationJson = SyncFilesRequestSchema
+SchemaForRequestBodyApplicationJson = RSSFeedInputSchema
 
 
-request_body_sync_files_request = api_client.RequestBody(
+request_body_rss_feed_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
 _auth = [
@@ -118,71 +115,65 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _sync_confluence_mapped_args(
+    def _sync_rss_feed_mapped_args(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        url: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if tags is not None:
             _body["tags"] = tags
-        if data_source_id is not None:
-            _body["data_source_id"] = data_source_id
-        if ids is not None:
-            _body["ids"] = ids
+        if url is not None:
+            _body["url"] = url
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
             _body["skip_embedding_generation"] = skip_embedding_generation
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
-        if max_items_per_chunk is not None:
-            _body["max_items_per_chunk"] = max_items_per_chunk
-        if set_page_as_boundary is not None:
-            _body["set_page_as_boundary"] = set_page_as_boundary
+        if request_id is not None:
+            _body["request_id"] = request_id
         args.body = _body
         return args
 
-    async def _async_confluence_oapg(
+    async def _async_rss_feed_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Confluence Sync
+        Rss Feed
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -198,20 +189,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/confluence/sync',
+            path_template='/integrations/rss_feed',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_sync_files_request.serialize(body, content_type)
+        serialized_data = request_body_rss_feed_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -275,28 +266,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _sync_confluence_oapg(
+    def _sync_rss_feed_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Confluence Sync
+        Rss Feed
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -312,20 +303,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/confluence/sync',
+            path_template='/integrations/rss_feed',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_sync_files_request.serialize(body, content_type)
+        serialized_data = request_body_rss_feed_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -358,225 +349,201 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class SyncConfluenceRaw(BaseApi):
+class SyncRssFeedRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def async_confluence(
+    async def async_rss_feed(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        url: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_confluence_mapped_args(
-            data_source_id=data_source_id,
-            ids=ids,
+        args = self._sync_rss_feed_mapped_args(
+            url=url,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
         )
-        return await self._async_confluence_oapg(
+        return await self._async_rss_feed_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def sync_confluence(
+    def sync_rss_feed(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        url: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_confluence_mapped_args(
-            data_source_id=data_source_id,
-            ids=ids,
+        args = self._sync_rss_feed_mapped_args(
+            url=url,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
         )
-        return self._sync_confluence_oapg(
+        return self._sync_rss_feed_oapg(
             body=args.body,
         )
 
-class SyncConfluence(BaseApi):
+class SyncRssFeed(BaseApi):
 
-    async def async_confluence(
+    async def async_rss_feed(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        url: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
         validate: bool = False,
         **kwargs,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = await self.raw.async_confluence(
-            data_source_id=data_source_id,
-            ids=ids,
+        raw_response = await self.raw.async_rss_feed(
+            url=url,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
             **kwargs,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
-    def sync_confluence(
+    def sync_rss_feed(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        url: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
         validate: bool = False,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = self.raw.sync_confluence(
-            data_source_id=data_source_id,
-            ids=ids,
+        raw_response = self.raw.sync_rss_feed(
+            url=url,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        url: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_confluence_mapped_args(
-            data_source_id=data_source_id,
-            ids=ids,
+        args = self._sync_rss_feed_mapped_args(
+            url=url,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
         )
-        return await self._async_confluence_oapg(
+        return await self._async_rss_feed_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        url: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_confluence_mapped_args(
-            data_source_id=data_source_id,
-            ids=ids,
+        args = self._sync_rss_feed_mapped_args(
+            url=url,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
         )
-        return self._sync_confluence_oapg(
+        return self._sync_rss_feed_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_confluence_sync/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_rss_feed/post.pyi`

 * *Files 8% similar despite different names*

```diff
@@ -29,37 +29,34 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullableSchema
-from carbon.model.sync_files_request import SyncFilesRequest as SyncFilesRequestSchema
-from carbon.model.sync_files_ids import SyncFilesIds as SyncFilesIdsSchema
+from carbon.model.rss_feed_input import RSSFeedInput as RSSFeedInputSchema
+from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
 from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
 
-from carbon.type.sync_files_request import SyncFilesRequest
+from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
 from carbon.type.generic_success_response import GenericSuccessResponse
-from carbon.type.sync_files_ids import SyncFilesIds
-from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.type.rss_feed_input import RSSFeedInput
 
 from ...api_client import Dictionary
-from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullablePydantic
-from carbon.pydantic.sync_files_request import SyncFilesRequest as SyncFilesRequestPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
-from carbon.pydantic.sync_files_ids import SyncFilesIds as SyncFilesIdsPydantic
+from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
+from carbon.pydantic.rss_feed_input import RSSFeedInput as RSSFeedInputPydantic
 
 # body param
-SchemaForRequestBodyApplicationJson = SyncFilesRequestSchema
+SchemaForRequestBodyApplicationJson = RSSFeedInputSchema
 
 
-request_body_sync_files_request = api_client.RequestBody(
+request_body_rss_feed_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
 SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
@@ -107,71 +104,65 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _sync_confluence_mapped_args(
+    def _sync_rss_feed_mapped_args(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        url: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if tags is not None:
             _body["tags"] = tags
-        if data_source_id is not None:
-            _body["data_source_id"] = data_source_id
-        if ids is not None:
-            _body["ids"] = ids
+        if url is not None:
+            _body["url"] = url
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
             _body["skip_embedding_generation"] = skip_embedding_generation
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
-        if max_items_per_chunk is not None:
-            _body["max_items_per_chunk"] = max_items_per_chunk
-        if set_page_as_boundary is not None:
-            _body["set_page_as_boundary"] = set_page_as_boundary
+        if request_id is not None:
+            _body["request_id"] = request_id
         args.body = _body
         return args
 
-    async def _async_confluence_oapg(
+    async def _async_rss_feed_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Confluence Sync
+        Rss Feed
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -187,20 +178,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/confluence/sync',
+            path_template='/integrations/rss_feed',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_sync_files_request.serialize(body, content_type)
+        serialized_data = request_body_rss_feed_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -264,28 +255,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _sync_confluence_oapg(
+    def _sync_rss_feed_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Confluence Sync
+        Rss Feed
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -301,20 +292,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/confluence/sync',
+            path_template='/integrations/rss_feed',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_sync_files_request.serialize(body, content_type)
+        serialized_data = request_body_rss_feed_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -347,225 +338,201 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class SyncConfluenceRaw(BaseApi):
+class SyncRssFeedRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def async_confluence(
+    async def async_rss_feed(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        url: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_confluence_mapped_args(
-            data_source_id=data_source_id,
-            ids=ids,
+        args = self._sync_rss_feed_mapped_args(
+            url=url,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
         )
-        return await self._async_confluence_oapg(
+        return await self._async_rss_feed_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def sync_confluence(
+    def sync_rss_feed(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        url: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_confluence_mapped_args(
-            data_source_id=data_source_id,
-            ids=ids,
+        args = self._sync_rss_feed_mapped_args(
+            url=url,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
         )
-        return self._sync_confluence_oapg(
+        return self._sync_rss_feed_oapg(
             body=args.body,
         )
 
-class SyncConfluence(BaseApi):
+class SyncRssFeed(BaseApi):
 
-    async def async_confluence(
+    async def async_rss_feed(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        url: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
         validate: bool = False,
         **kwargs,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = await self.raw.async_confluence(
-            data_source_id=data_source_id,
-            ids=ids,
+        raw_response = await self.raw.async_rss_feed(
+            url=url,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
             **kwargs,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
-    def sync_confluence(
+    def sync_rss_feed(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        url: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
         validate: bool = False,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = self.raw.sync_confluence(
-            data_source_id=data_source_id,
-            ids=ids,
+        raw_response = self.raw.sync_rss_feed(
+            url=url,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        url: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_confluence_mapped_args(
-            data_source_id=data_source_id,
-            ids=ids,
+        args = self._sync_rss_feed_mapped_args(
+            url=url,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
         )
-        return await self._async_confluence_oapg(
+        return await self._async_rss_feed_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        url: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_confluence_mapped_args(
-            data_source_id=data_source_id,
-            ids=ids,
+        args = self._sync_rss_feed_mapped_args(
+            url=url,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
         )
-        return self._sync_confluence_oapg(
+        return self._sync_rss_feed_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_connect/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_connect/post.py`

 * *Files 8% similar despite different names*

```diff
@@ -42,22 +42,24 @@
 from carbon.model.gitbook_authetication import GitbookAuthetication as GitbookAutheticationSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
 from carbon.model.s3_authentication import S3Authentication as S3AuthenticationSchema
 from carbon.model.salesforce_authentication import SalesforceAuthentication as SalesforceAuthenticationSchema
 from carbon.model.notion_authentication import NotionAuthentication as NotionAuthenticationSchema
 from carbon.model.sharepoint_authentication import SharepointAuthentication as SharepointAuthenticationSchema
 from carbon.model.zotero_authentication import ZoteroAuthentication as ZoteroAuthenticationSchema
+from carbon.model.github_authentication import GithubAuthentication as GithubAuthenticationSchema
 
 from carbon.type.salesforce_authentication import SalesforceAuthentication
 from carbon.type.freskdesk_authentication import FreskdeskAuthentication
 from carbon.type.connect_data_source_response import ConnectDataSourceResponse
 from carbon.type.gitbook_authetication import GitbookAuthetication
 from carbon.type.notion_authentication import NotionAuthentication
 from carbon.type.zotero_authentication import ZoteroAuthentication
 from carbon.type.sharepoint_authentication import SharepointAuthentication
+from carbon.type.github_authentication import GithubAuthentication
 from carbon.type.zendesk_authentication import ZendeskAuthentication
 from carbon.type.http_validation_error import HTTPValidationError
 from carbon.type.o_auth_authentication import OAuthAuthentication
 from carbon.type.confluence_authentication import ConfluenceAuthentication
 from carbon.type.s3_authentication import S3Authentication
 from carbon.type.connect_data_source_input import ConnectDataSourceInput
 from carbon.type.sync_options import SyncOptions
@@ -69,14 +71,15 @@
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.confluence_authentication import ConfluenceAuthentication as ConfluenceAuthenticationPydantic
 from carbon.pydantic.salesforce_authentication import SalesforceAuthentication as SalesforceAuthenticationPydantic
 from carbon.pydantic.zendesk_authentication import ZendeskAuthentication as ZendeskAuthenticationPydantic
 from carbon.pydantic.sync_options import SyncOptions as SyncOptionsPydantic
 from carbon.pydantic.sharepoint_authentication import SharepointAuthentication as SharepointAuthenticationPydantic
 from carbon.pydantic.notion_authentication import NotionAuthentication as NotionAuthenticationPydantic
+from carbon.pydantic.github_authentication import GithubAuthentication as GithubAuthenticationPydantic
 from carbon.pydantic.freskdesk_authentication import FreskdeskAuthentication as FreskdeskAuthenticationPydantic
 from carbon.pydantic.zotero_authentication import ZoteroAuthentication as ZoteroAuthenticationPydantic
 from carbon.pydantic.gitbook_authetication import GitbookAuthetication as GitbookAutheticationPydantic
 from carbon.pydantic.connect_data_source_input import ConnectDataSourceInput as ConnectDataSourceInputPydantic
 
 from . import path
 
@@ -147,15 +150,15 @@
 )
 
 
 class BaseApi(api_client.Api):
 
     def _connect_data_source_mapped_args(
         self,
-        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication],
+        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication, GithubAuthentication],
         sync_options: typing.Optional[SyncOptions] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if authentication is not None:
             _body["authentication"] = authentication
         if sync_options is not None:
@@ -363,15 +366,15 @@
 
 
 class ConnectDataSourceRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
     async def aconnect_data_source(
         self,
-        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication],
+        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication, GithubAuthentication],
         sync_options: typing.Optional[SyncOptions] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
@@ -382,15 +385,15 @@
         return await self._aconnect_data_source_oapg(
             body=args.body,
             **kwargs,
         )
     
     def connect_data_source(
         self,
-        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication],
+        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication, GithubAuthentication],
         sync_options: typing.Optional[SyncOptions] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._connect_data_source_mapped_args(
             authentication=authentication,
@@ -400,15 +403,15 @@
             body=args.body,
         )
 
 class ConnectDataSource(BaseApi):
 
     async def aconnect_data_source(
         self,
-        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication],
+        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication, GithubAuthentication],
         sync_options: typing.Optional[SyncOptions] = None,
         validate: bool = False,
         **kwargs,
     ) -> ConnectDataSourceResponsePydantic:
         raw_response = await self.raw.aconnect_data_source(
             authentication=authentication,
             sync_options=sync_options,
@@ -417,15 +420,15 @@
         if validate:
             return ConnectDataSourceResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(ConnectDataSourceResponsePydantic, raw_response.body)
     
     
     def connect_data_source(
         self,
-        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication],
+        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication, GithubAuthentication],
         sync_options: typing.Optional[SyncOptions] = None,
         validate: bool = False,
     ) -> ConnectDataSourceResponsePydantic:
         raw_response = self.raw.connect_data_source(
             authentication=authentication,
             sync_options=sync_options,
         )
@@ -435,15 +438,15 @@
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication],
+        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication, GithubAuthentication],
         sync_options: typing.Optional[SyncOptions] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
@@ -454,15 +457,15 @@
         return await self._aconnect_data_source_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication],
+        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication, GithubAuthentication],
         sync_options: typing.Optional[SyncOptions] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._connect_data_source_mapped_args(
             authentication=authentication,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_connect/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_connect/post.pyi`

 * *Files 2% similar despite different names*

```diff
@@ -42,22 +42,24 @@
 from carbon.model.gitbook_authetication import GitbookAuthetication as GitbookAutheticationSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
 from carbon.model.s3_authentication import S3Authentication as S3AuthenticationSchema
 from carbon.model.salesforce_authentication import SalesforceAuthentication as SalesforceAuthenticationSchema
 from carbon.model.notion_authentication import NotionAuthentication as NotionAuthenticationSchema
 from carbon.model.sharepoint_authentication import SharepointAuthentication as SharepointAuthenticationSchema
 from carbon.model.zotero_authentication import ZoteroAuthentication as ZoteroAuthenticationSchema
+from carbon.model.github_authentication import GithubAuthentication as GithubAuthenticationSchema
 
 from carbon.type.salesforce_authentication import SalesforceAuthentication
 from carbon.type.freskdesk_authentication import FreskdeskAuthentication
 from carbon.type.connect_data_source_response import ConnectDataSourceResponse
 from carbon.type.gitbook_authetication import GitbookAuthetication
 from carbon.type.notion_authentication import NotionAuthentication
 from carbon.type.zotero_authentication import ZoteroAuthentication
 from carbon.type.sharepoint_authentication import SharepointAuthentication
+from carbon.type.github_authentication import GithubAuthentication
 from carbon.type.zendesk_authentication import ZendeskAuthentication
 from carbon.type.http_validation_error import HTTPValidationError
 from carbon.type.o_auth_authentication import OAuthAuthentication
 from carbon.type.confluence_authentication import ConfluenceAuthentication
 from carbon.type.s3_authentication import S3Authentication
 from carbon.type.connect_data_source_input import ConnectDataSourceInput
 from carbon.type.sync_options import SyncOptions
@@ -69,14 +71,15 @@
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.confluence_authentication import ConfluenceAuthentication as ConfluenceAuthenticationPydantic
 from carbon.pydantic.salesforce_authentication import SalesforceAuthentication as SalesforceAuthenticationPydantic
 from carbon.pydantic.zendesk_authentication import ZendeskAuthentication as ZendeskAuthenticationPydantic
 from carbon.pydantic.sync_options import SyncOptions as SyncOptionsPydantic
 from carbon.pydantic.sharepoint_authentication import SharepointAuthentication as SharepointAuthenticationPydantic
 from carbon.pydantic.notion_authentication import NotionAuthentication as NotionAuthenticationPydantic
+from carbon.pydantic.github_authentication import GithubAuthentication as GithubAuthenticationPydantic
 from carbon.pydantic.freskdesk_authentication import FreskdeskAuthentication as FreskdeskAuthenticationPydantic
 from carbon.pydantic.zotero_authentication import ZoteroAuthentication as ZoteroAuthenticationPydantic
 from carbon.pydantic.gitbook_authetication import GitbookAuthetication as GitbookAutheticationPydantic
 from carbon.pydantic.connect_data_source_input import ConnectDataSourceInput as ConnectDataSourceInputPydantic
 
 # body param
 SchemaForRequestBodyApplicationJson = ConnectDataSourceInputSchema
@@ -136,15 +139,15 @@
 )
 
 
 class BaseApi(api_client.Api):
 
     def _connect_data_source_mapped_args(
         self,
-        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication],
+        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication, GithubAuthentication],
         sync_options: typing.Optional[SyncOptions] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if authentication is not None:
             _body["authentication"] = authentication
         if sync_options is not None:
@@ -352,15 +355,15 @@
 
 
 class ConnectDataSourceRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
     async def aconnect_data_source(
         self,
-        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication],
+        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication, GithubAuthentication],
         sync_options: typing.Optional[SyncOptions] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
@@ -371,15 +374,15 @@
         return await self._aconnect_data_source_oapg(
             body=args.body,
             **kwargs,
         )
     
     def connect_data_source(
         self,
-        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication],
+        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication, GithubAuthentication],
         sync_options: typing.Optional[SyncOptions] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._connect_data_source_mapped_args(
             authentication=authentication,
@@ -389,15 +392,15 @@
             body=args.body,
         )
 
 class ConnectDataSource(BaseApi):
 
     async def aconnect_data_source(
         self,
-        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication],
+        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication, GithubAuthentication],
         sync_options: typing.Optional[SyncOptions] = None,
         validate: bool = False,
         **kwargs,
     ) -> ConnectDataSourceResponsePydantic:
         raw_response = await self.raw.aconnect_data_source(
             authentication=authentication,
             sync_options=sync_options,
@@ -406,15 +409,15 @@
         if validate:
             return ConnectDataSourceResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(ConnectDataSourceResponsePydantic, raw_response.body)
     
     
     def connect_data_source(
         self,
-        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication],
+        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication, GithubAuthentication],
         sync_options: typing.Optional[SyncOptions] = None,
         validate: bool = False,
     ) -> ConnectDataSourceResponsePydantic:
         raw_response = self.raw.connect_data_source(
             authentication=authentication,
             sync_options=sync_options,
         )
@@ -424,15 +427,15 @@
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication],
+        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication, GithubAuthentication],
         sync_options: typing.Optional[SyncOptions] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
@@ -443,15 +446,15 @@
         return await self._aconnect_data_source_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication],
+        authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication, GithubAuthentication],
         sync_options: typing.Optional[SyncOptions] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._connect_data_source_mapped_args(
             authentication=authentication,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_files_sync/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/upload_file_from_url/post.py`

 * *Files 13% similar despite different names*

```diff
@@ -29,61 +29,58 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullableSchema
-from carbon.model.sync_files_request import SyncFilesRequest as SyncFilesRequestSchema
-from carbon.model.sync_files_ids import SyncFilesIds as SyncFilesIdsSchema
-from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
+from carbon.model.upload_file_from_url_input import UploadFileFromUrlInput as UploadFileFromUrlInputSchema
+from carbon.model.user_file import UserFile as UserFileSchema
+from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
 
-from carbon.type.sync_files_request import SyncFilesRequest
+from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.generic_success_response import GenericSuccessResponse
-from carbon.type.sync_files_ids import SyncFilesIds
-from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.type.upload_file_from_url_input import UploadFileFromUrlInput
+from carbon.type.user_file import UserFile
 
 from ...api_client import Dictionary
-from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullablePydantic
-from carbon.pydantic.sync_files_request import SyncFilesRequest as SyncFilesRequestPydantic
+from carbon.pydantic.user_file import UserFile as UserFilePydantic
+from carbon.pydantic.upload_file_from_url_input import UploadFileFromUrlInput as UploadFileFromUrlInputPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
-from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
-from carbon.pydantic.sync_files_ids import SyncFilesIds as SyncFilesIdsPydantic
+from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
 
 from . import path
 
 # body param
-SchemaForRequestBodyApplicationJson = SyncFilesRequestSchema
+SchemaForRequestBodyApplicationJson = UploadFileFromUrlInputSchema
 
 
-request_body_sync_files_request = api_client.RequestBody(
+request_body_upload_file_from_url_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
 _auth = [
     'accessToken',
     'apiKey',
     'customerId',
 ]
-SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
+SchemaFor200ResponseBodyApplicationJson = UserFileSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
-    body: GenericSuccessResponse
+    body: UserFile
 
 
 @dataclass
 class ApiResponseFor200Async(api_client.AsyncApiResponse):
-    body: GenericSuccessResponse
+    body: UserFile
 
 
 _response_for_200 = api_client.OpenApiResponse(
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
@@ -118,71 +115,77 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _sync_files_mapped_args(
+    def _upload_from_url_mapped_args(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        url: str,
+        file_name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        generate_sparse_vectors: typing.Optional[bool] = None,
+        use_textract: typing.Optional[bool] = None,
+        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
-        if tags is not None:
-            _body["tags"] = tags
-        if data_source_id is not None:
-            _body["data_source_id"] = data_source_id
-        if ids is not None:
-            _body["ids"] = ids
+        if url is not None:
+            _body["url"] = url
+        if file_name is not None:
+            _body["file_name"] = file_name
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
             _body["skip_embedding_generation"] = skip_embedding_generation
+        if set_page_as_boundary is not None:
+            _body["set_page_as_boundary"] = set_page_as_boundary
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
+        if use_textract is not None:
+            _body["use_textract"] = use_textract
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
         if max_items_per_chunk is not None:
             _body["max_items_per_chunk"] = max_items_per_chunk
-        if set_page_as_boundary is not None:
-            _body["set_page_as_boundary"] = set_page_as_boundary
+        if parse_pdf_tables_with_ocr is not None:
+            _body["parse_pdf_tables_with_ocr"] = parse_pdf_tables_with_ocr
+        if detect_audio_language is not None:
+            _body["detect_audio_language"] = detect_audio_language
         args.body = _body
         return args
 
-    async def _async_files_oapg(
+    async def _aupload_from_url_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Sync Files
+        Create Upload File From Url
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -198,20 +201,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/files/sync',
+            path_template='/upload_file_from_url',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_sync_files_request.serialize(body, content_type)
+        serialized_data = request_body_upload_file_from_url_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -275,28 +278,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _sync_files_oapg(
+    def _upload_from_url_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Sync Files
+        Create Upload File From Url
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -312,20 +315,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/files/sync',
+            path_template='/upload_file_from_url',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_sync_files_request.serialize(body, content_type)
+        serialized_data = request_body_upload_file_from_url_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -358,225 +361,249 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class SyncFilesRaw(BaseApi):
+class UploadFromUrlRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def async_files(
+    async def aupload_from_url(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        url: str,
+        file_name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        generate_sparse_vectors: typing.Optional[bool] = None,
+        use_textract: typing.Optional[bool] = None,
+        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_files_mapped_args(
-            data_source_id=data_source_id,
-            ids=ids,
-            tags=tags,
+        args = self._upload_from_url_mapped_args(
+            url=url,
+            file_name=file_name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
+            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
         )
-        return await self._async_files_oapg(
+        return await self._aupload_from_url_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def sync_files(
+    def upload_from_url(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        url: str,
+        file_name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        generate_sparse_vectors: typing.Optional[bool] = None,
+        use_textract: typing.Optional[bool] = None,
+        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_files_mapped_args(
-            data_source_id=data_source_id,
-            ids=ids,
-            tags=tags,
+        args = self._upload_from_url_mapped_args(
+            url=url,
+            file_name=file_name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
+            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
         )
-        return self._sync_files_oapg(
+        return self._upload_from_url_oapg(
             body=args.body,
         )
 
-class SyncFiles(BaseApi):
+class UploadFromUrl(BaseApi):
 
-    async def async_files(
+    async def aupload_from_url(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        url: str,
+        file_name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        generate_sparse_vectors: typing.Optional[bool] = None,
+        use_textract: typing.Optional[bool] = None,
+        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
         validate: bool = False,
         **kwargs,
-    ) -> GenericSuccessResponsePydantic:
-        raw_response = await self.raw.async_files(
-            data_source_id=data_source_id,
-            ids=ids,
-            tags=tags,
+    ) -> UserFilePydantic:
+        raw_response = await self.raw.aupload_from_url(
+            url=url,
+            file_name=file_name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
+            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
             **kwargs,
         )
         if validate:
-            return GenericSuccessResponsePydantic(**raw_response.body)
-        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
+            return UserFilePydantic(**raw_response.body)
+        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
     
     
-    def sync_files(
+    def upload_from_url(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        url: str,
+        file_name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        generate_sparse_vectors: typing.Optional[bool] = None,
+        use_textract: typing.Optional[bool] = None,
+        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
         validate: bool = False,
-    ) -> GenericSuccessResponsePydantic:
-        raw_response = self.raw.sync_files(
-            data_source_id=data_source_id,
-            ids=ids,
-            tags=tags,
+    ) -> UserFilePydantic:
+        raw_response = self.raw.upload_from_url(
+            url=url,
+            file_name=file_name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
+            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
         )
         if validate:
-            return GenericSuccessResponsePydantic(**raw_response.body)
-        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
+            return UserFilePydantic(**raw_response.body)
+        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        url: str,
+        file_name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        generate_sparse_vectors: typing.Optional[bool] = None,
+        use_textract: typing.Optional[bool] = None,
+        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_files_mapped_args(
-            data_source_id=data_source_id,
-            ids=ids,
-            tags=tags,
+        args = self._upload_from_url_mapped_args(
+            url=url,
+            file_name=file_name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
+            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
         )
-        return await self._async_files_oapg(
+        return await self._aupload_from_url_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        url: str,
+        file_name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        generate_sparse_vectors: typing.Optional[bool] = None,
+        use_textract: typing.Optional[bool] = None,
+        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_files_mapped_args(
-            data_source_id=data_source_id,
-            ids=ids,
-            tags=tags,
+        args = self._upload_from_url_mapped_args(
+            url=url,
+            file_name=file_name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
+            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
         )
-        return self._sync_files_oapg(
+        return self._upload_from_url_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_files_sync/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_gitbook_sync/post.pyi`

 * *Files 12% similar despite different names*

```diff
@@ -28,55 +28,52 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
+from carbon.model.gitbook_sync_request_space_ids import GitbookSyncRequestSpaceIds as GitbookSyncRequestSpaceIdsSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullableSchema
-from carbon.model.sync_files_request import SyncFilesRequest as SyncFilesRequestSchema
-from carbon.model.sync_files_ids import SyncFilesIds as SyncFilesIdsSchema
-from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
+from carbon.model.gitbook_sync_request import GitbookSyncRequest as GitbookSyncRequestSchema
+from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
 
-from carbon.type.sync_files_request import SyncFilesRequest
+from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.generic_success_response import GenericSuccessResponse
-from carbon.type.sync_files_ids import SyncFilesIds
-from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.type.gitbook_sync_request_space_ids import GitbookSyncRequestSpaceIds
+from carbon.type.gitbook_sync_request import GitbookSyncRequest
 
 from ...api_client import Dictionary
-from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullablePydantic
-from carbon.pydantic.sync_files_request import SyncFilesRequest as SyncFilesRequestPydantic
+from carbon.pydantic.gitbook_sync_request import GitbookSyncRequest as GitbookSyncRequestPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
-from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
-from carbon.pydantic.sync_files_ids import SyncFilesIds as SyncFilesIdsPydantic
+from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
+from carbon.pydantic.gitbook_sync_request_space_ids import GitbookSyncRequestSpaceIds as GitbookSyncRequestSpaceIdsPydantic
 
 # body param
-SchemaForRequestBodyApplicationJson = SyncFilesRequestSchema
+SchemaForRequestBodyApplicationJson = GitbookSyncRequestSchema
 
 
-request_body_sync_files_request = api_client.RequestBody(
+request_body_gitbook_sync_request = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
-SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
+SchemaFor200ResponseBodyApplicationJson = schemas.DictSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
-    body: GenericSuccessResponse
+    body: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
 
 
 @dataclass
 class ApiResponseFor200Async(api_client.AsyncApiResponse):
-    body: GenericSuccessResponse
+    body: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
 
 
 _response_for_200 = api_client.OpenApiResponse(
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
@@ -107,71 +104,68 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _sync_files_mapped_args(
+    def _sync_gitbook_mapped_args(
         self,
+        space_ids: GitbookSyncRequestSpaceIds,
         data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if tags is not None:
             _body["tags"] = tags
+        if space_ids is not None:
+            _body["space_ids"] = space_ids
         if data_source_id is not None:
             _body["data_source_id"] = data_source_id
-        if ids is not None:
-            _body["ids"] = ids
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
             _body["skip_embedding_generation"] = skip_embedding_generation
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
-        if max_items_per_chunk is not None:
-            _body["max_items_per_chunk"] = max_items_per_chunk
-        if set_page_as_boundary is not None:
-            _body["set_page_as_boundary"] = set_page_as_boundary
+        if request_id is not None:
+            _body["request_id"] = request_id
         args.body = _body
         return args
 
-    async def _async_files_oapg(
+    async def _async_gitbook_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Sync Files
+        Gitbook Sync
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -187,20 +181,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/files/sync',
+            path_template='/integrations/gitbook/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_sync_files_request.serialize(body, content_type)
+        serialized_data = request_body_gitbook_sync_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -264,28 +258,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _sync_files_oapg(
+    def _sync_gitbook_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Sync Files
+        Gitbook Sync
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -301,20 +295,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/files/sync',
+            path_template='/integrations/gitbook/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_sync_files_request.serialize(body, content_type)
+        serialized_data = request_body_gitbook_sync_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -347,225 +341,213 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class SyncFilesRaw(BaseApi):
+class SyncGitbookRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def async_files(
+    async def async_gitbook(
         self,
+        space_ids: GitbookSyncRequestSpaceIds,
         data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_files_mapped_args(
+        args = self._sync_gitbook_mapped_args(
+            space_ids=space_ids,
             data_source_id=data_source_id,
-            ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
         )
-        return await self._async_files_oapg(
+        return await self._async_gitbook_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def sync_files(
+    def sync_gitbook(
         self,
+        space_ids: GitbookSyncRequestSpaceIds,
         data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_files_mapped_args(
+        args = self._sync_gitbook_mapped_args(
+            space_ids=space_ids,
             data_source_id=data_source_id,
-            ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
         )
-        return self._sync_files_oapg(
+        return self._sync_gitbook_oapg(
             body=args.body,
         )
 
-class SyncFiles(BaseApi):
+class SyncGitbook(BaseApi):
 
-    async def async_files(
+    async def async_gitbook(
         self,
+        space_ids: GitbookSyncRequestSpaceIds,
         data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
         validate: bool = False,
         **kwargs,
-    ) -> GenericSuccessResponsePydantic:
-        raw_response = await self.raw.async_files(
+    ) -> Dictionary:
+        raw_response = await self.raw.async_gitbook(
+            space_ids=space_ids,
             data_source_id=data_source_id,
-            ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
             **kwargs,
         )
         if validate:
-            return GenericSuccessResponsePydantic(**raw_response.body)
-        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
+            return Dictionary(**raw_response.body)
+        return api_client.construct_model_instance(Dictionary, raw_response.body)
     
     
-    def sync_files(
+    def sync_gitbook(
         self,
+        space_ids: GitbookSyncRequestSpaceIds,
         data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
         validate: bool = False,
-    ) -> GenericSuccessResponsePydantic:
-        raw_response = self.raw.sync_files(
+    ) -> Dictionary:
+        raw_response = self.raw.sync_gitbook(
+            space_ids=space_ids,
             data_source_id=data_source_id,
-            ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
         )
         if validate:
-            return GenericSuccessResponsePydantic(**raw_response.body)
-        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
+            return Dictionary(**raw_response.body)
+        return api_client.construct_model_instance(Dictionary, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
+        space_ids: GitbookSyncRequestSpaceIds,
         data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_files_mapped_args(
+        args = self._sync_gitbook_mapped_args(
+            space_ids=space_ids,
             data_source_id=data_source_id,
-            ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
         )
-        return await self._async_files_oapg(
+        return await self._async_gitbook_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
+        space_ids: GitbookSyncRequestSpaceIds,
         data_source_id: int,
-        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_files_mapped_args(
+        args = self._sync_gitbook_mapped_args(
+            space_ids=space_ids,
             data_source_id=data_source_id,
-            ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
         )
-        return self._sync_files_oapg(
+        return self._sync_gitbook_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_freshdesk/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_gitbook/post.py`

 * *Files 8% similar despite different names*

```diff
@@ -29,36 +29,36 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullableSchema
+from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
+from carbon.model.gitbook_connect_request import GitbookConnectRequest as GitbookConnectRequestSchema
 from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
-from carbon.model.fresh_desk_connect_request import FreshDeskConnectRequest as FreshDeskConnectRequestSchema
 
+from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.fresh_desk_connect_request import FreshDeskConnectRequest
 from carbon.type.generic_success_response import GenericSuccessResponse
-from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.type.gitbook_connect_request import GitbookConnectRequest
 
 from ...api_client import Dictionary
-from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullablePydantic
-from carbon.pydantic.fresh_desk_connect_request import FreshDeskConnectRequest as FreshDeskConnectRequestPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
+from carbon.pydantic.gitbook_connect_request import GitbookConnectRequest as GitbookConnectRequestPydantic
+from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
 
 from . import path
 
 # body param
-SchemaForRequestBodyApplicationJson = FreshDeskConnectRequestSchema
+SchemaForRequestBodyApplicationJson = GitbookConnectRequestSchema
 
 
-request_body_fresh_desk_connect_request = api_client.RequestBody(
+request_body_gitbook_connect_request = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
 _auth = [
@@ -115,68 +115,74 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _connect_freshdesk_mapped_args(
+    def _connect_gitbook_mapped_args(
         self,
-        domain: str,
-        api_key: str,
+        organization: str,
+        access_token: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if tags is not None:
             _body["tags"] = tags
-        if domain is not None:
-            _body["domain"] = domain
-        if api_key is not None:
-            _body["api_key"] = api_key
+        if organization is not None:
+            _body["organization"] = organization
+        if access_token is not None:
+            _body["access_token"] = access_token
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
             _body["skip_embedding_generation"] = skip_embedding_generation
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
         if sync_files_on_connection is not None:
             _body["sync_files_on_connection"] = sync_files_on_connection
+        if request_id is not None:
+            _body["request_id"] = request_id
+        if sync_source_items is not None:
+            _body["sync_source_items"] = sync_source_items
         args.body = _body
         return args
 
-    async def _aconnect_freshdesk_oapg(
+    async def _aconnect_gitbook_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Freshdesk Connect
+        Gitbook Connect
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -192,20 +198,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/freshdesk',
+            path_template='/integrations/gitbook',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_fresh_desk_connect_request.serialize(body, content_type)
+        serialized_data = request_body_gitbook_connect_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -269,28 +275,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _connect_freshdesk_oapg(
+    def _connect_gitbook_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Freshdesk Connect
+        Gitbook Connect
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -306,20 +312,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/freshdesk',
+            path_template='/integrations/gitbook',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_fresh_desk_connect_request.serialize(body, content_type)
+        serialized_data = request_body_gitbook_connect_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -352,213 +358,237 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class ConnectFreshdeskRaw(BaseApi):
+class ConnectGitbookRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def aconnect_freshdesk(
+    async def aconnect_gitbook(
         self,
-        domain: str,
-        api_key: str,
+        organization: str,
+        access_token: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._connect_freshdesk_mapped_args(
-            domain=domain,
-            api_key=api_key,
+        args = self._connect_gitbook_mapped_args(
+            organization=organization,
+            access_token=access_token,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
         )
-        return await self._aconnect_freshdesk_oapg(
+        return await self._aconnect_gitbook_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def connect_freshdesk(
+    def connect_gitbook(
         self,
-        domain: str,
-        api_key: str,
+        organization: str,
+        access_token: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._connect_freshdesk_mapped_args(
-            domain=domain,
-            api_key=api_key,
+        args = self._connect_gitbook_mapped_args(
+            organization=organization,
+            access_token=access_token,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
         )
-        return self._connect_freshdesk_oapg(
+        return self._connect_gitbook_oapg(
             body=args.body,
         )
 
-class ConnectFreshdesk(BaseApi):
+class ConnectGitbook(BaseApi):
 
-    async def aconnect_freshdesk(
+    async def aconnect_gitbook(
         self,
-        domain: str,
-        api_key: str,
+        organization: str,
+        access_token: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
         validate: bool = False,
         **kwargs,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = await self.raw.aconnect_freshdesk(
-            domain=domain,
-            api_key=api_key,
+        raw_response = await self.raw.aconnect_gitbook(
+            organization=organization,
+            access_token=access_token,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
             **kwargs,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
-    def connect_freshdesk(
+    def connect_gitbook(
         self,
-        domain: str,
-        api_key: str,
+        organization: str,
+        access_token: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
         validate: bool = False,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = self.raw.connect_freshdesk(
-            domain=domain,
-            api_key=api_key,
+        raw_response = self.raw.connect_gitbook(
+            organization=organization,
+            access_token=access_token,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        domain: str,
-        api_key: str,
+        organization: str,
+        access_token: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._connect_freshdesk_mapped_args(
-            domain=domain,
-            api_key=api_key,
+        args = self._connect_gitbook_mapped_args(
+            organization=organization,
+            access_token=access_token,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
         )
-        return await self._aconnect_freshdesk_oapg(
+        return await self._aconnect_gitbook_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        domain: str,
-        api_key: str,
+        organization: str,
+        access_token: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._connect_freshdesk_mapped_args(
-            domain=domain,
-            api_key=api_key,
+        args = self._connect_gitbook_mapped_args(
+            organization=organization,
+            access_token=access_token,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
         )
-        return self._connect_freshdesk_oapg(
+        return self._connect_gitbook_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_freshdesk/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_gitbook/post.pyi`

 * *Files 9% similar despite different names*

```diff
@@ -29,34 +29,34 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullableSchema
+from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
+from carbon.model.gitbook_connect_request import GitbookConnectRequest as GitbookConnectRequestSchema
 from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
-from carbon.model.fresh_desk_connect_request import FreshDeskConnectRequest as FreshDeskConnectRequestSchema
 
+from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.fresh_desk_connect_request import FreshDeskConnectRequest
 from carbon.type.generic_success_response import GenericSuccessResponse
-from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.type.gitbook_connect_request import GitbookConnectRequest
 
 from ...api_client import Dictionary
-from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullablePydantic
-from carbon.pydantic.fresh_desk_connect_request import FreshDeskConnectRequest as FreshDeskConnectRequestPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
+from carbon.pydantic.gitbook_connect_request import GitbookConnectRequest as GitbookConnectRequestPydantic
+from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
 
 # body param
-SchemaForRequestBodyApplicationJson = FreshDeskConnectRequestSchema
+SchemaForRequestBodyApplicationJson = GitbookConnectRequestSchema
 
 
-request_body_fresh_desk_connect_request = api_client.RequestBody(
+request_body_gitbook_connect_request = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
 SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
@@ -104,68 +104,74 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _connect_freshdesk_mapped_args(
+    def _connect_gitbook_mapped_args(
         self,
-        domain: str,
-        api_key: str,
+        organization: str,
+        access_token: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if tags is not None:
             _body["tags"] = tags
-        if domain is not None:
-            _body["domain"] = domain
-        if api_key is not None:
-            _body["api_key"] = api_key
+        if organization is not None:
+            _body["organization"] = organization
+        if access_token is not None:
+            _body["access_token"] = access_token
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
             _body["skip_embedding_generation"] = skip_embedding_generation
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
         if sync_files_on_connection is not None:
             _body["sync_files_on_connection"] = sync_files_on_connection
+        if request_id is not None:
+            _body["request_id"] = request_id
+        if sync_source_items is not None:
+            _body["sync_source_items"] = sync_source_items
         args.body = _body
         return args
 
-    async def _aconnect_freshdesk_oapg(
+    async def _aconnect_gitbook_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Freshdesk Connect
+        Gitbook Connect
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -181,20 +187,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/freshdesk',
+            path_template='/integrations/gitbook',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_fresh_desk_connect_request.serialize(body, content_type)
+        serialized_data = request_body_gitbook_connect_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -258,28 +264,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _connect_freshdesk_oapg(
+    def _connect_gitbook_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Freshdesk Connect
+        Gitbook Connect
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -295,20 +301,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/freshdesk',
+            path_template='/integrations/gitbook',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_fresh_desk_connect_request.serialize(body, content_type)
+        serialized_data = request_body_gitbook_connect_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -341,213 +347,237 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class ConnectFreshdeskRaw(BaseApi):
+class ConnectGitbookRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def aconnect_freshdesk(
+    async def aconnect_gitbook(
         self,
-        domain: str,
-        api_key: str,
+        organization: str,
+        access_token: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._connect_freshdesk_mapped_args(
-            domain=domain,
-            api_key=api_key,
+        args = self._connect_gitbook_mapped_args(
+            organization=organization,
+            access_token=access_token,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
         )
-        return await self._aconnect_freshdesk_oapg(
+        return await self._aconnect_gitbook_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def connect_freshdesk(
+    def connect_gitbook(
         self,
-        domain: str,
-        api_key: str,
+        organization: str,
+        access_token: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._connect_freshdesk_mapped_args(
-            domain=domain,
-            api_key=api_key,
+        args = self._connect_gitbook_mapped_args(
+            organization=organization,
+            access_token=access_token,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
         )
-        return self._connect_freshdesk_oapg(
+        return self._connect_gitbook_oapg(
             body=args.body,
         )
 
-class ConnectFreshdesk(BaseApi):
+class ConnectGitbook(BaseApi):
 
-    async def aconnect_freshdesk(
+    async def aconnect_gitbook(
         self,
-        domain: str,
-        api_key: str,
+        organization: str,
+        access_token: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
         validate: bool = False,
         **kwargs,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = await self.raw.aconnect_freshdesk(
-            domain=domain,
-            api_key=api_key,
+        raw_response = await self.raw.aconnect_gitbook(
+            organization=organization,
+            access_token=access_token,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
             **kwargs,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
-    def connect_freshdesk(
+    def connect_gitbook(
         self,
-        domain: str,
-        api_key: str,
+        organization: str,
+        access_token: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
         validate: bool = False,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = self.raw.connect_freshdesk(
-            domain=domain,
-            api_key=api_key,
+        raw_response = self.raw.connect_gitbook(
+            organization=organization,
+            access_token=access_token,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        domain: str,
-        api_key: str,
+        organization: str,
+        access_token: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._connect_freshdesk_mapped_args(
-            domain=domain,
-            api_key=api_key,
+        args = self._connect_gitbook_mapped_args(
+            organization=organization,
+            access_token=access_token,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
         )
-        return await self._aconnect_freshdesk_oapg(
+        return await self._aconnect_gitbook_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        domain: str,
-        api_key: str,
+        organization: str,
+        access_token: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._connect_freshdesk_mapped_args(
-            domain=domain,
-            api_key=api_key,
+        args = self._connect_gitbook_mapped_args(
+            organization=organization,
+            access_token=access_token,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
         )
-        return self._connect_freshdesk_oapg(
+        return self._connect_gitbook_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_gitbook/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_freshdesk/post.py`

 * *Files 10% similar despite different names*

```diff
@@ -29,36 +29,39 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
-from carbon.model.gitbook_connect_request import GitbookConnectRequest as GitbookConnectRequestSchema
+from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullableSchema
 from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
+from carbon.model.fresh_desk_connect_request import FreshDeskConnectRequest as FreshDeskConnectRequestSchema
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullableSchema
 
-from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
+from carbon.type.fresh_desk_connect_request import FreshDeskConnectRequest
+from carbon.type.file_sync_config_nullable import FileSyncConfigNullable
 from carbon.type.generic_success_response import GenericSuccessResponse
-from carbon.type.gitbook_connect_request import GitbookConnectRequest
+from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
 
 from ...api_client import Dictionary
+from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullablePydantic
+from carbon.pydantic.fresh_desk_connect_request import FreshDeskConnectRequest as FreshDeskConnectRequestPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
-from carbon.pydantic.gitbook_connect_request import GitbookConnectRequest as GitbookConnectRequestPydantic
-from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
+from carbon.pydantic.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullablePydantic
 
 from . import path
 
 # body param
-SchemaForRequestBodyApplicationJson = GitbookConnectRequestSchema
+SchemaForRequestBodyApplicationJson = FreshDeskConnectRequestSchema
 
 
-request_body_gitbook_connect_request = api_client.RequestBody(
+request_body_fresh_desk_connect_request = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
 _auth = [
@@ -115,68 +118,77 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _connect_gitbook_mapped_args(
+    def _connect_freshdesk_mapped_args(
         self,
-        organization: str,
-        access_token: str,
+        domain: str,
+        api_key: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if tags is not None:
             _body["tags"] = tags
-        if organization is not None:
-            _body["organization"] = organization
-        if access_token is not None:
-            _body["access_token"] = access_token
+        if domain is not None:
+            _body["domain"] = domain
+        if api_key is not None:
+            _body["api_key"] = api_key
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
             _body["skip_embedding_generation"] = skip_embedding_generation
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
         if sync_files_on_connection is not None:
             _body["sync_files_on_connection"] = sync_files_on_connection
+        if request_id is not None:
+            _body["request_id"] = request_id
+        if sync_source_items is not None:
+            _body["sync_source_items"] = sync_source_items
+        if file_sync_config is not None:
+            _body["file_sync_config"] = file_sync_config
         args.body = _body
         return args
 
-    async def _aconnect_gitbook_oapg(
+    async def _aconnect_freshdesk_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Gitbook Connect
+        Freshdesk Connect
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -192,20 +204,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/gitbook',
+            path_template='/integrations/freshdesk',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_gitbook_connect_request.serialize(body, content_type)
+        serialized_data = request_body_fresh_desk_connect_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -269,28 +281,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _connect_gitbook_oapg(
+    def _connect_freshdesk_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Gitbook Connect
+        Freshdesk Connect
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -306,20 +318,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/gitbook',
+            path_template='/integrations/freshdesk',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_gitbook_connect_request.serialize(body, content_type)
+        serialized_data = request_body_fresh_desk_connect_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -352,213 +364,249 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class ConnectGitbookRaw(BaseApi):
+class ConnectFreshdeskRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def aconnect_gitbook(
+    async def aconnect_freshdesk(
         self,
-        organization: str,
-        access_token: str,
+        domain: str,
+        api_key: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._connect_gitbook_mapped_args(
-            organization=organization,
-            access_token=access_token,
+        args = self._connect_freshdesk_mapped_args(
+            domain=domain,
+            api_key=api_key,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
+            file_sync_config=file_sync_config,
         )
-        return await self._aconnect_gitbook_oapg(
+        return await self._aconnect_freshdesk_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def connect_gitbook(
+    def connect_freshdesk(
         self,
-        organization: str,
-        access_token: str,
+        domain: str,
+        api_key: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._connect_gitbook_mapped_args(
-            organization=organization,
-            access_token=access_token,
+        args = self._connect_freshdesk_mapped_args(
+            domain=domain,
+            api_key=api_key,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
+            file_sync_config=file_sync_config,
         )
-        return self._connect_gitbook_oapg(
+        return self._connect_freshdesk_oapg(
             body=args.body,
         )
 
-class ConnectGitbook(BaseApi):
+class ConnectFreshdesk(BaseApi):
 
-    async def aconnect_gitbook(
+    async def aconnect_freshdesk(
         self,
-        organization: str,
-        access_token: str,
+        domain: str,
+        api_key: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         validate: bool = False,
         **kwargs,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = await self.raw.aconnect_gitbook(
-            organization=organization,
-            access_token=access_token,
+        raw_response = await self.raw.aconnect_freshdesk(
+            domain=domain,
+            api_key=api_key,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
+            file_sync_config=file_sync_config,
             **kwargs,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
-    def connect_gitbook(
+    def connect_freshdesk(
         self,
-        organization: str,
-        access_token: str,
+        domain: str,
+        api_key: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         validate: bool = False,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = self.raw.connect_gitbook(
-            organization=organization,
-            access_token=access_token,
+        raw_response = self.raw.connect_freshdesk(
+            domain=domain,
+            api_key=api_key,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
+            file_sync_config=file_sync_config,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        organization: str,
-        access_token: str,
+        domain: str,
+        api_key: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._connect_gitbook_mapped_args(
-            organization=organization,
-            access_token=access_token,
+        args = self._connect_freshdesk_mapped_args(
+            domain=domain,
+            api_key=api_key,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
+            file_sync_config=file_sync_config,
         )
-        return await self._aconnect_gitbook_oapg(
+        return await self._aconnect_freshdesk_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        organization: str,
-        access_token: str,
+        domain: str,
+        api_key: str,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_source_items: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._connect_gitbook_mapped_args(
-            organization=organization,
-            access_token=access_token,
+        args = self._connect_freshdesk_mapped_args(
+            domain=domain,
+            api_key=api_key,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
+            sync_source_items=sync_source_items,
+            file_sync_config=file_sync_config,
         )
-        return self._connect_gitbook_oapg(
+        return self._connect_freshdesk_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_gitbook/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_gitbook_sync/post.py`

 * *Files 11% similar despite different names*

```diff
@@ -28,52 +28,59 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
+from carbon.model.gitbook_sync_request_space_ids import GitbookSyncRequestSpaceIds as GitbookSyncRequestSpaceIdsSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
+from carbon.model.gitbook_sync_request import GitbookSyncRequest as GitbookSyncRequestSchema
 from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
-from carbon.model.gitbook_connect_request import GitbookConnectRequest as GitbookConnectRequestSchema
-from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
 
 from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.generic_success_response import GenericSuccessResponse
-from carbon.type.gitbook_connect_request import GitbookConnectRequest
+from carbon.type.gitbook_sync_request_space_ids import GitbookSyncRequestSpaceIds
+from carbon.type.gitbook_sync_request import GitbookSyncRequest
 
 from ...api_client import Dictionary
+from carbon.pydantic.gitbook_sync_request import GitbookSyncRequest as GitbookSyncRequestPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
-from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
-from carbon.pydantic.gitbook_connect_request import GitbookConnectRequest as GitbookConnectRequestPydantic
 from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
+from carbon.pydantic.gitbook_sync_request_space_ids import GitbookSyncRequestSpaceIds as GitbookSyncRequestSpaceIdsPydantic
+
+from . import path
 
 # body param
-SchemaForRequestBodyApplicationJson = GitbookConnectRequestSchema
+SchemaForRequestBodyApplicationJson = GitbookSyncRequestSchema
 
 
-request_body_gitbook_connect_request = api_client.RequestBody(
+request_body_gitbook_sync_request = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
-SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
+_auth = [
+    'accessToken',
+    'apiKey',
+    'customerId',
+]
+SchemaFor200ResponseBodyApplicationJson = schemas.DictSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
-    body: GenericSuccessResponse
+    body: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
 
 
 @dataclass
 class ApiResponseFor200Async(api_client.AsyncApiResponse):
-    body: GenericSuccessResponse
+    body: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
 
 
 _response_for_200 = api_client.OpenApiResponse(
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
@@ -97,75 +104,79 @@
     response_cls=ApiResponseFor422,
     response_cls_async=ApiResponseFor422Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor422ResponseBodyApplicationJson),
     },
 )
+_status_code_to_response = {
+    '200': _response_for_200,
+    '422': _response_for_422,
+}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _connect_gitbook_mapped_args(
+    def _sync_gitbook_mapped_args(
         self,
-        organization: str,
-        access_token: str,
+        space_ids: GitbookSyncRequestSpaceIds,
+        data_source_id: int,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if tags is not None:
             _body["tags"] = tags
-        if organization is not None:
-            _body["organization"] = organization
-        if access_token is not None:
-            _body["access_token"] = access_token
+        if space_ids is not None:
+            _body["space_ids"] = space_ids
+        if data_source_id is not None:
+            _body["data_source_id"] = data_source_id
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
             _body["skip_embedding_generation"] = skip_embedding_generation
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
-        if sync_files_on_connection is not None:
-            _body["sync_files_on_connection"] = sync_files_on_connection
+        if request_id is not None:
+            _body["request_id"] = request_id
         args.body = _body
         return args
 
-    async def _aconnect_gitbook_oapg(
+    async def _async_gitbook_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Gitbook Connect
+        Gitbook Sync
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -181,20 +192,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/gitbook',
+            path_template='/integrations/gitbook/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_gitbook_connect_request.serialize(body, content_type)
+        serialized_data = request_body_gitbook_sync_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -258,28 +269,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _connect_gitbook_oapg(
+    def _sync_gitbook_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Gitbook Connect
+        Gitbook Sync
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -295,20 +306,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/gitbook',
+            path_template='/integrations/gitbook/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_gitbook_connect_request.serialize(body, content_type)
+        serialized_data = request_body_gitbook_sync_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -341,213 +352,213 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class ConnectGitbookRaw(BaseApi):
+class SyncGitbookRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def aconnect_gitbook(
+    async def async_gitbook(
         self,
-        organization: str,
-        access_token: str,
+        space_ids: GitbookSyncRequestSpaceIds,
+        data_source_id: int,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._connect_gitbook_mapped_args(
-            organization=organization,
-            access_token=access_token,
+        args = self._sync_gitbook_mapped_args(
+            space_ids=space_ids,
+            data_source_id=data_source_id,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
         )
-        return await self._aconnect_gitbook_oapg(
+        return await self._async_gitbook_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def connect_gitbook(
+    def sync_gitbook(
         self,
-        organization: str,
-        access_token: str,
+        space_ids: GitbookSyncRequestSpaceIds,
+        data_source_id: int,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._connect_gitbook_mapped_args(
-            organization=organization,
-            access_token=access_token,
+        args = self._sync_gitbook_mapped_args(
+            space_ids=space_ids,
+            data_source_id=data_source_id,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
         )
-        return self._connect_gitbook_oapg(
+        return self._sync_gitbook_oapg(
             body=args.body,
         )
 
-class ConnectGitbook(BaseApi):
+class SyncGitbook(BaseApi):
 
-    async def aconnect_gitbook(
+    async def async_gitbook(
         self,
-        organization: str,
-        access_token: str,
+        space_ids: GitbookSyncRequestSpaceIds,
+        data_source_id: int,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
         validate: bool = False,
         **kwargs,
-    ) -> GenericSuccessResponsePydantic:
-        raw_response = await self.raw.aconnect_gitbook(
-            organization=organization,
-            access_token=access_token,
+    ) -> Dictionary:
+        raw_response = await self.raw.async_gitbook(
+            space_ids=space_ids,
+            data_source_id=data_source_id,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
             **kwargs,
         )
         if validate:
-            return GenericSuccessResponsePydantic(**raw_response.body)
-        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
+            return Dictionary(**raw_response.body)
+        return api_client.construct_model_instance(Dictionary, raw_response.body)
     
     
-    def connect_gitbook(
+    def sync_gitbook(
         self,
-        organization: str,
-        access_token: str,
+        space_ids: GitbookSyncRequestSpaceIds,
+        data_source_id: int,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
         validate: bool = False,
-    ) -> GenericSuccessResponsePydantic:
-        raw_response = self.raw.connect_gitbook(
-            organization=organization,
-            access_token=access_token,
+    ) -> Dictionary:
+        raw_response = self.raw.sync_gitbook(
+            space_ids=space_ids,
+            data_source_id=data_source_id,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
         )
         if validate:
-            return GenericSuccessResponsePydantic(**raw_response.body)
-        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
+            return Dictionary(**raw_response.body)
+        return api_client.construct_model_instance(Dictionary, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        organization: str,
-        access_token: str,
+        space_ids: GitbookSyncRequestSpaceIds,
+        data_source_id: int,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._connect_gitbook_mapped_args(
-            organization=organization,
-            access_token=access_token,
+        args = self._sync_gitbook_mapped_args(
+            space_ids=space_ids,
+            data_source_id=data_source_id,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
         )
-        return await self._aconnect_gitbook_oapg(
+        return await self._async_gitbook_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        organization: str,
-        access_token: str,
+        space_ids: GitbookSyncRequestSpaceIds,
+        data_source_id: int,
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._connect_gitbook_mapped_args(
-            organization=organization,
-            access_token=access_token,
+        args = self._sync_gitbook_mapped_args(
+            space_ids=space_ids,
+            data_source_id=data_source_id,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            sync_files_on_connection=sync_files_on_connection,
+            request_id=request_id,
         )
-        return self._connect_gitbook_oapg(
+        return self._sync_gitbook_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_gitbook_spaces/get.py` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_gitbook_spaces/get.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_gitbook_spaces/get.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_gitbook_spaces/get.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_gitbook_sync/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/upload_text/post.py`

 * *Files 15% similar despite different names*

```diff
@@ -28,59 +28,59 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
-from carbon.model.gitbook_sync_request_space_ids import GitbookSyncRequestSpaceIds as GitbookSyncRequestSpaceIdsSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.gitbook_sync_request import GitbookSyncRequest as GitbookSyncRequestSchema
-from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
+from carbon.model.user_file import UserFile as UserFileSchema
+from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullableSchema
+from carbon.model.raw_text_input import RawTextInput as RawTextInputSchema
 
-from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.gitbook_sync_request_space_ids import GitbookSyncRequestSpaceIds
-from carbon.type.gitbook_sync_request import GitbookSyncRequest
+from carbon.type.raw_text_input import RawTextInput
+from carbon.type.user_file import UserFile
+from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
 
 from ...api_client import Dictionary
-from carbon.pydantic.gitbook_sync_request import GitbookSyncRequest as GitbookSyncRequestPydantic
+from carbon.pydantic.user_file import UserFile as UserFilePydantic
+from carbon.pydantic.raw_text_input import RawTextInput as RawTextInputPydantic
+from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullablePydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
-from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
-from carbon.pydantic.gitbook_sync_request_space_ids import GitbookSyncRequestSpaceIds as GitbookSyncRequestSpaceIdsPydantic
 
 from . import path
 
 # body param
-SchemaForRequestBodyApplicationJson = GitbookSyncRequestSchema
+SchemaForRequestBodyApplicationJson = RawTextInputSchema
 
 
-request_body_gitbook_sync_request = api_client.RequestBody(
+request_body_raw_text_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
 _auth = [
     'accessToken',
     'apiKey',
     'customerId',
 ]
-SchemaFor200ResponseBodyApplicationJson = schemas.DictSchema
+SchemaFor200ResponseBodyApplicationJson = UserFileSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
-    body: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
+    body: UserFile
 
 
 @dataclass
 class ApiResponseFor200Async(api_client.AsyncApiResponse):
-    body: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
+    body: UserFile
 
 
 _response_for_200 = api_client.OpenApiResponse(
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
@@ -115,65 +115,62 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _sync_gitbook_mapped_args(
+    def _upload_text_mapped_args(
         self,
-        space_ids: GitbookSyncRequestSpaceIds,
-        data_source_id: int,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        contents: str,
+        name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
-        if tags is not None:
-            _body["tags"] = tags
-        if space_ids is not None:
-            _body["space_ids"] = space_ids
-        if data_source_id is not None:
-            _body["data_source_id"] = data_source_id
+        if contents is not None:
+            _body["contents"] = contents
+        if name is not None:
+            _body["name"] = name
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
             _body["skip_embedding_generation"] = skip_embedding_generation
+        if overwrite_file_id is not None:
+            _body["overwrite_file_id"] = overwrite_file_id
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
-        if prepend_filename_to_chunks is not None:
-            _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
         args.body = _body
         return args
 
-    async def _async_gitbook_oapg(
+    async def _aupload_text_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Gitbook Sync
+        Create Raw Text
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -189,20 +186,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/gitbook/sync',
+            path_template='/upload_text',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_gitbook_sync_request.serialize(body, content_type)
+        serialized_data = request_body_raw_text_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -266,28 +263,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _sync_gitbook_oapg(
+    def _upload_text_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Gitbook Sync
+        Create Raw Text
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -303,20 +300,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/gitbook/sync',
+            path_template='/upload_text',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_gitbook_sync_request.serialize(body, content_type)
+        serialized_data = request_body_raw_text_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -349,201 +346,189 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class SyncGitbookRaw(BaseApi):
+class UploadTextRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def async_gitbook(
+    async def aupload_text(
         self,
-        space_ids: GitbookSyncRequestSpaceIds,
-        data_source_id: int,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        contents: str,
+        name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_gitbook_mapped_args(
-            space_ids=space_ids,
-            data_source_id=data_source_id,
-            tags=tags,
+        args = self._upload_text_mapped_args(
+            contents=contents,
+            name=name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            overwrite_file_id=overwrite_file_id,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            prepend_filename_to_chunks=prepend_filename_to_chunks,
         )
-        return await self._async_gitbook_oapg(
+        return await self._aupload_text_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def sync_gitbook(
+    def upload_text(
         self,
-        space_ids: GitbookSyncRequestSpaceIds,
-        data_source_id: int,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        contents: str,
+        name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_gitbook_mapped_args(
-            space_ids=space_ids,
-            data_source_id=data_source_id,
-            tags=tags,
+        args = self._upload_text_mapped_args(
+            contents=contents,
+            name=name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            overwrite_file_id=overwrite_file_id,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            prepend_filename_to_chunks=prepend_filename_to_chunks,
         )
-        return self._sync_gitbook_oapg(
+        return self._upload_text_oapg(
             body=args.body,
         )
 
-class SyncGitbook(BaseApi):
+class UploadText(BaseApi):
 
-    async def async_gitbook(
+    async def aupload_text(
         self,
-        space_ids: GitbookSyncRequestSpaceIds,
-        data_source_id: int,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        contents: str,
+        name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         validate: bool = False,
         **kwargs,
-    ) -> Dictionary:
-        raw_response = await self.raw.async_gitbook(
-            space_ids=space_ids,
-            data_source_id=data_source_id,
-            tags=tags,
+    ) -> UserFilePydantic:
+        raw_response = await self.raw.aupload_text(
+            contents=contents,
+            name=name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            overwrite_file_id=overwrite_file_id,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            prepend_filename_to_chunks=prepend_filename_to_chunks,
             **kwargs,
         )
         if validate:
-            return Dictionary(**raw_response.body)
-        return api_client.construct_model_instance(Dictionary, raw_response.body)
+            return UserFilePydantic(**raw_response.body)
+        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
     
     
-    def sync_gitbook(
+    def upload_text(
         self,
-        space_ids: GitbookSyncRequestSpaceIds,
-        data_source_id: int,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        contents: str,
+        name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         validate: bool = False,
-    ) -> Dictionary:
-        raw_response = self.raw.sync_gitbook(
-            space_ids=space_ids,
-            data_source_id=data_source_id,
-            tags=tags,
+    ) -> UserFilePydantic:
+        raw_response = self.raw.upload_text(
+            contents=contents,
+            name=name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            overwrite_file_id=overwrite_file_id,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            prepend_filename_to_chunks=prepend_filename_to_chunks,
         )
         if validate:
-            return Dictionary(**raw_response.body)
-        return api_client.construct_model_instance(Dictionary, raw_response.body)
+            return UserFilePydantic(**raw_response.body)
+        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        space_ids: GitbookSyncRequestSpaceIds,
-        data_source_id: int,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        contents: str,
+        name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_gitbook_mapped_args(
-            space_ids=space_ids,
-            data_source_id=data_source_id,
-            tags=tags,
+        args = self._upload_text_mapped_args(
+            contents=contents,
+            name=name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            overwrite_file_id=overwrite_file_id,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            prepend_filename_to_chunks=prepend_filename_to_chunks,
         )
-        return await self._async_gitbook_oapg(
+        return await self._aupload_text_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        space_ids: GitbookSyncRequestSpaceIds,
-        data_source_id: int,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        contents: str,
+        name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_gitbook_mapped_args(
-            space_ids=space_ids,
-            data_source_id=data_source_id,
-            tags=tags,
+        args = self._upload_text_mapped_args(
+            contents=contents,
+            name=name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            overwrite_file_id=overwrite_file_id,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            prepend_filename_to_chunks=prepend_filename_to_chunks,
         )
-        return self._sync_gitbook_oapg(
+        return self._upload_text_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_gitbook_sync/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/upload_text/post.pyi`

 * *Files 15% similar despite different names*

```diff
@@ -28,52 +28,52 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
-from carbon.model.gitbook_sync_request_space_ids import GitbookSyncRequestSpaceIds as GitbookSyncRequestSpaceIdsSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.gitbook_sync_request import GitbookSyncRequest as GitbookSyncRequestSchema
-from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
+from carbon.model.user_file import UserFile as UserFileSchema
+from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullableSchema
+from carbon.model.raw_text_input import RawTextInput as RawTextInputSchema
 
-from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.gitbook_sync_request_space_ids import GitbookSyncRequestSpaceIds
-from carbon.type.gitbook_sync_request import GitbookSyncRequest
+from carbon.type.raw_text_input import RawTextInput
+from carbon.type.user_file import UserFile
+from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
 
 from ...api_client import Dictionary
-from carbon.pydantic.gitbook_sync_request import GitbookSyncRequest as GitbookSyncRequestPydantic
+from carbon.pydantic.user_file import UserFile as UserFilePydantic
+from carbon.pydantic.raw_text_input import RawTextInput as RawTextInputPydantic
+from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullablePydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
-from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
-from carbon.pydantic.gitbook_sync_request_space_ids import GitbookSyncRequestSpaceIds as GitbookSyncRequestSpaceIdsPydantic
 
 # body param
-SchemaForRequestBodyApplicationJson = GitbookSyncRequestSchema
+SchemaForRequestBodyApplicationJson = RawTextInputSchema
 
 
-request_body_gitbook_sync_request = api_client.RequestBody(
+request_body_raw_text_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
-SchemaFor200ResponseBodyApplicationJson = schemas.DictSchema
+SchemaFor200ResponseBodyApplicationJson = UserFileSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
-    body: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
+    body: UserFile
 
 
 @dataclass
 class ApiResponseFor200Async(api_client.AsyncApiResponse):
-    body: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
+    body: UserFile
 
 
 _response_for_200 = api_client.OpenApiResponse(
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
@@ -104,65 +104,62 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _sync_gitbook_mapped_args(
+    def _upload_text_mapped_args(
         self,
-        space_ids: GitbookSyncRequestSpaceIds,
-        data_source_id: int,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        contents: str,
+        name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
-        if tags is not None:
-            _body["tags"] = tags
-        if space_ids is not None:
-            _body["space_ids"] = space_ids
-        if data_source_id is not None:
-            _body["data_source_id"] = data_source_id
+        if contents is not None:
+            _body["contents"] = contents
+        if name is not None:
+            _body["name"] = name
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
             _body["skip_embedding_generation"] = skip_embedding_generation
+        if overwrite_file_id is not None:
+            _body["overwrite_file_id"] = overwrite_file_id
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
-        if prepend_filename_to_chunks is not None:
-            _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
         args.body = _body
         return args
 
-    async def _async_gitbook_oapg(
+    async def _aupload_text_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Gitbook Sync
+        Create Raw Text
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -178,20 +175,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/gitbook/sync',
+            path_template='/upload_text',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_gitbook_sync_request.serialize(body, content_type)
+        serialized_data = request_body_raw_text_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -255,28 +252,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _sync_gitbook_oapg(
+    def _upload_text_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Gitbook Sync
+        Create Raw Text
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -292,20 +289,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/gitbook/sync',
+            path_template='/upload_text',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_gitbook_sync_request.serialize(body, content_type)
+        serialized_data = request_body_raw_text_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -338,201 +335,189 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class SyncGitbookRaw(BaseApi):
+class UploadTextRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def async_gitbook(
+    async def aupload_text(
         self,
-        space_ids: GitbookSyncRequestSpaceIds,
-        data_source_id: int,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        contents: str,
+        name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_gitbook_mapped_args(
-            space_ids=space_ids,
-            data_source_id=data_source_id,
-            tags=tags,
+        args = self._upload_text_mapped_args(
+            contents=contents,
+            name=name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            overwrite_file_id=overwrite_file_id,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            prepend_filename_to_chunks=prepend_filename_to_chunks,
         )
-        return await self._async_gitbook_oapg(
+        return await self._aupload_text_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def sync_gitbook(
+    def upload_text(
         self,
-        space_ids: GitbookSyncRequestSpaceIds,
-        data_source_id: int,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        contents: str,
+        name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_gitbook_mapped_args(
-            space_ids=space_ids,
-            data_source_id=data_source_id,
-            tags=tags,
+        args = self._upload_text_mapped_args(
+            contents=contents,
+            name=name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            overwrite_file_id=overwrite_file_id,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            prepend_filename_to_chunks=prepend_filename_to_chunks,
         )
-        return self._sync_gitbook_oapg(
+        return self._upload_text_oapg(
             body=args.body,
         )
 
-class SyncGitbook(BaseApi):
+class UploadText(BaseApi):
 
-    async def async_gitbook(
+    async def aupload_text(
         self,
-        space_ids: GitbookSyncRequestSpaceIds,
-        data_source_id: int,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        contents: str,
+        name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         validate: bool = False,
         **kwargs,
-    ) -> Dictionary:
-        raw_response = await self.raw.async_gitbook(
-            space_ids=space_ids,
-            data_source_id=data_source_id,
-            tags=tags,
+    ) -> UserFilePydantic:
+        raw_response = await self.raw.aupload_text(
+            contents=contents,
+            name=name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            overwrite_file_id=overwrite_file_id,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            prepend_filename_to_chunks=prepend_filename_to_chunks,
             **kwargs,
         )
         if validate:
-            return Dictionary(**raw_response.body)
-        return api_client.construct_model_instance(Dictionary, raw_response.body)
+            return UserFilePydantic(**raw_response.body)
+        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
     
     
-    def sync_gitbook(
+    def upload_text(
         self,
-        space_ids: GitbookSyncRequestSpaceIds,
-        data_source_id: int,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        contents: str,
+        name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         validate: bool = False,
-    ) -> Dictionary:
-        raw_response = self.raw.sync_gitbook(
-            space_ids=space_ids,
-            data_source_id=data_source_id,
-            tags=tags,
+    ) -> UserFilePydantic:
+        raw_response = self.raw.upload_text(
+            contents=contents,
+            name=name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            overwrite_file_id=overwrite_file_id,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            prepend_filename_to_chunks=prepend_filename_to_chunks,
         )
         if validate:
-            return Dictionary(**raw_response.body)
-        return api_client.construct_model_instance(Dictionary, raw_response.body)
+            return UserFilePydantic(**raw_response.body)
+        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        space_ids: GitbookSyncRequestSpaceIds,
-        data_source_id: int,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        contents: str,
+        name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_gitbook_mapped_args(
-            space_ids=space_ids,
-            data_source_id=data_source_id,
-            tags=tags,
+        args = self._upload_text_mapped_args(
+            contents=contents,
+            name=name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            overwrite_file_id=overwrite_file_id,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            prepend_filename_to_chunks=prepend_filename_to_chunks,
         )
-        return await self._async_gitbook_oapg(
+        return await self._aupload_text_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        space_ids: GitbookSyncRequestSpaceIds,
-        data_source_id: int,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        contents: str,
+        name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_gitbook_mapped_args(
-            space_ids=space_ids,
-            data_source_id=data_source_id,
-            tags=tags,
+        args = self._upload_text_mapped_args(
+            contents=contents,
+            name=name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            overwrite_file_id=overwrite_file_id,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            prepend_filename_to_chunks=prepend_filename_to_chunks,
         )
-        return self._sync_gitbook_oapg(
+        return self._upload_text_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_gmail_sync/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_gmail_sync/post.py`

 * *Files 14% similar despite different names*

```diff
@@ -32,25 +32,28 @@
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
 from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
 from carbon.model.gmail_sync_input import GmailSyncInput as GmailSyncInputSchema
 from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullableSchema
 
 from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
+from carbon.type.file_sync_config_nullable import FileSyncConfigNullable
 from carbon.type.generic_success_response import GenericSuccessResponse
 from carbon.type.gmail_sync_input import GmailSyncInput
 
 from ...api_client import Dictionary
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
 from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
 from carbon.pydantic.gmail_sync_input import GmailSyncInput as GmailSyncInputPydantic
+from carbon.pydantic.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullablePydantic
 
 from . import path
 
 # body param
 SchemaForRequestBodyApplicationJson = GmailSyncInputSchema
 
 
@@ -126,14 +129,18 @@
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if tags is not None:
             _body["tags"] = tags
         if filters is not None:
             _body["filters"] = filters
@@ -147,14 +154,22 @@
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
         if data_source_id is not None:
             _body["data_source_id"] = data_source_id
+        if request_id is not None:
+            _body["request_id"] = request_id
+        if sync_attachments is not None:
+            _body["sync_attachments"] = sync_attachments
+        if file_sync_config is not None:
+            _body["file_sync_config"] = file_sync_config
+        if incremental_sync is not None:
+            _body["incremental_sync"] = incremental_sync
         args.body = _body
         return args
 
     async def _async_gmail_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
@@ -363,14 +378,18 @@
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         args = self._sync_gmail_mapped_args(
@@ -379,14 +398,18 @@
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
         return await self._async_gmail_oapg(
             body=args.body,
             **kwargs,
         )
     
     def sync_gmail(
@@ -396,28 +419,36 @@
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._sync_gmail_mapped_args(
             filters=filters,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
         return self._sync_gmail_oapg(
             body=args.body,
         )
 
 class SyncGmail(BaseApi):
 
@@ -428,27 +459,35 @@
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
         validate: bool = False,
         **kwargs,
     ) -> GenericSuccessResponsePydantic:
         raw_response = await self.raw.async_gmail(
             filters=filters,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
             **kwargs,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
@@ -459,26 +498,34 @@
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
         validate: bool = False,
     ) -> GenericSuccessResponsePydantic:
         raw_response = self.raw.sync_gmail(
             filters=filters,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
@@ -491,14 +538,18 @@
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         args = self._sync_gmail_mapped_args(
@@ -507,14 +558,18 @@
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
         return await self._async_gmail_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
@@ -524,26 +579,34 @@
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._sync_gmail_mapped_args(
             filters=filters,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
         return self._sync_gmail_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_gmail_sync/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_outlook_sync/post.pyi`

 * *Files 13% similar despite different names*

```diff
@@ -28,35 +28,38 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
+from carbon.model.outlook_sync_input import OutlookSyncInput as OutlookSyncInputSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
 from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
-from carbon.model.gmail_sync_input import GmailSyncInput as GmailSyncInputSchema
 from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullableSchema
 
 from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
+from carbon.type.file_sync_config_nullable import FileSyncConfigNullable
+from carbon.type.outlook_sync_input import OutlookSyncInput
 from carbon.type.generic_success_response import GenericSuccessResponse
-from carbon.type.gmail_sync_input import GmailSyncInput
 
 from ...api_client import Dictionary
+from carbon.pydantic.outlook_sync_input import OutlookSyncInput as OutlookSyncInputPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
 from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
-from carbon.pydantic.gmail_sync_input import GmailSyncInput as GmailSyncInputPydantic
+from carbon.pydantic.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullablePydantic
 
 # body param
-SchemaForRequestBodyApplicationJson = GmailSyncInputSchema
+SchemaForRequestBodyApplicationJson = OutlookSyncInputSchema
 
 
-request_body_gmail_sync_input = api_client.RequestBody(
+request_body_outlook_sync_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
 SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
@@ -104,30 +107,37 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _sync_gmail_mapped_args(
+    def _sync_outlook_mapped_args(
         self,
         filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if tags is not None:
             _body["tags"] = tags
+        if folder is not None:
+            _body["folder"] = folder
         if filters is not None:
             _body["filters"] = filters
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
@@ -136,33 +146,41 @@
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
         if data_source_id is not None:
             _body["data_source_id"] = data_source_id
+        if request_id is not None:
+            _body["request_id"] = request_id
+        if sync_attachments is not None:
+            _body["sync_attachments"] = sync_attachments
+        if file_sync_config is not None:
+            _body["file_sync_config"] = file_sync_config
+        if incremental_sync is not None:
+            _body["incremental_sync"] = incremental_sync
         args.body = _body
         return args
 
-    async def _async_gmail_oapg(
+    async def _async_outlook_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Gmail Sync
+        Outlook Sync
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -178,20 +196,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/gmail/sync',
+            path_template='/integrations/outlook/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_gmail_sync_input.serialize(body, content_type)
+        serialized_data = request_body_outlook_sync_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -255,28 +273,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _sync_gmail_oapg(
+    def _sync_outlook_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Gmail Sync
+        Outlook Sync
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -292,20 +310,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/gmail/sync',
+            path_template='/integrations/outlook/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_gmail_sync_input.serialize(body, content_type)
+        serialized_data = request_body_outlook_sync_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -338,201 +356,261 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class SyncGmailRaw(BaseApi):
+class SyncOutlookRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def async_gmail(
+    async def async_outlook(
         self,
         filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_gmail_mapped_args(
+        args = self._sync_outlook_mapped_args(
             filters=filters,
             tags=tags,
+            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
-        return await self._async_gmail_oapg(
+        return await self._async_outlook_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def sync_gmail(
+    def sync_outlook(
         self,
         filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_gmail_mapped_args(
+        args = self._sync_outlook_mapped_args(
             filters=filters,
             tags=tags,
+            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
-        return self._sync_gmail_oapg(
+        return self._sync_outlook_oapg(
             body=args.body,
         )
 
-class SyncGmail(BaseApi):
+class SyncOutlook(BaseApi):
 
-    async def async_gmail(
+    async def async_outlook(
         self,
         filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
         validate: bool = False,
         **kwargs,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = await self.raw.async_gmail(
+        raw_response = await self.raw.async_outlook(
             filters=filters,
             tags=tags,
+            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
             **kwargs,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
-    def sync_gmail(
+    def sync_outlook(
         self,
         filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
         validate: bool = False,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = self.raw.sync_gmail(
+        raw_response = self.raw.sync_outlook(
             filters=filters,
             tags=tags,
+            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
         filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_gmail_mapped_args(
+        args = self._sync_outlook_mapped_args(
             filters=filters,
             tags=tags,
+            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
-        return await self._async_gmail_oapg(
+        return await self._async_outlook_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
         filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_gmail_mapped_args(
+        args = self._sync_outlook_mapped_args(
             filters=filters,
             tags=tags,
+            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
-        return self._sync_gmail_oapg(
+        return self._sync_outlook_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_gmail_user_labels/get.py` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_gmail_user_labels/get.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_gmail_user_labels/get.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_gmail_user_labels/get.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_items_list/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/resync_file/post.pyi`

 * *Files 12% similar despite different names*

```diff
@@ -28,59 +28,49 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
-from carbon.model.pagination import Pagination as PaginationSchema
+from carbon.model.resync_file_query_input import ResyncFileQueryInput as ResyncFileQueryInputSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.list_data_source_items_request import ListDataSourceItemsRequest as ListDataSourceItemsRequestSchema
-from carbon.model.list_data_source_items_response import ListDataSourceItemsResponse as ListDataSourceItemsResponseSchema
+from carbon.model.user_file import UserFile as UserFileSchema
 
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.pagination import Pagination
-from carbon.type.list_data_source_items_request import ListDataSourceItemsRequest
-from carbon.type.list_data_source_items_response import ListDataSourceItemsResponse
+from carbon.type.resync_file_query_input import ResyncFileQueryInput
+from carbon.type.user_file import UserFile
 
 from ...api_client import Dictionary
+from carbon.pydantic.user_file import UserFile as UserFilePydantic
+from carbon.pydantic.resync_file_query_input import ResyncFileQueryInput as ResyncFileQueryInputPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
-from carbon.pydantic.list_data_source_items_response import ListDataSourceItemsResponse as ListDataSourceItemsResponsePydantic
-from carbon.pydantic.list_data_source_items_request import ListDataSourceItemsRequest as ListDataSourceItemsRequestPydantic
-from carbon.pydantic.pagination import Pagination as PaginationPydantic
-
-from . import path
 
 # body param
-SchemaForRequestBodyApplicationJson = ListDataSourceItemsRequestSchema
+SchemaForRequestBodyApplicationJson = ResyncFileQueryInputSchema
 
 
-request_body_list_data_source_items_request = api_client.RequestBody(
+request_body_resync_file_query_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
-_auth = [
-    'accessToken',
-    'apiKey',
-    'customerId',
-]
-SchemaFor200ResponseBodyApplicationJson = ListDataSourceItemsResponseSchema
+SchemaFor200ResponseBodyApplicationJson = UserFileSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
-    body: ListDataSourceItemsResponse
+    body: UserFile
 
 
 @dataclass
 class ApiResponseFor200Async(api_client.AsyncApiResponse):
-    body: ListDataSourceItemsResponse
+    body: UserFile
 
 
 _response_for_200 = api_client.OpenApiResponse(
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
@@ -104,58 +94,57 @@
     response_cls=ApiResponseFor422,
     response_cls_async=ApiResponseFor422Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor422ResponseBodyApplicationJson),
     },
 )
-_status_code_to_response = {
-    '200': _response_for_200,
-    '422': _response_for_422,
-}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _list_data_source_items_mapped_args(
+    def _resync_mapped_args(
         self,
-        data_source_id: int,
-        parent_id: typing.Optional[typing.Optional[str]] = None,
-        pagination: typing.Optional[Pagination] = None,
+        file_id: int,
+        chunk_size: typing.Optional[typing.Optional[int]] = None,
+        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
+        force_embedding_generation: typing.Optional[bool] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
-        if data_source_id is not None:
-            _body["data_source_id"] = data_source_id
-        if parent_id is not None:
-            _body["parent_id"] = parent_id
-        if pagination is not None:
-            _body["pagination"] = pagination
+        if file_id is not None:
+            _body["file_id"] = file_id
+        if chunk_size is not None:
+            _body["chunk_size"] = chunk_size
+        if chunk_overlap is not None:
+            _body["chunk_overlap"] = chunk_overlap
+        if force_embedding_generation is not None:
+            _body["force_embedding_generation"] = force_embedding_generation
         args.body = _body
         return args
 
-    async def _alist_data_source_items_oapg(
+    async def _aresync_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        List Data Source Items
+        Resync File
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -171,20 +160,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/items/list',
+            path_template='/resync_file',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_list_data_source_items_request.serialize(body, content_type)
+        serialized_data = request_body_resync_file_query_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -248,28 +237,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _list_data_source_items_oapg(
+    def _resync_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        List Data Source Items
+        Resync File
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -285,20 +274,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/items/list',
+            path_template='/resync_file',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_list_data_source_items_request.serialize(body, content_type)
+        serialized_data = request_body_resync_file_query_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -331,129 +320,141 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class ListDataSourceItemsRaw(BaseApi):
+class ResyncRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def alist_data_source_items(
+    async def aresync(
         self,
-        data_source_id: int,
-        parent_id: typing.Optional[typing.Optional[str]] = None,
-        pagination: typing.Optional[Pagination] = None,
+        file_id: int,
+        chunk_size: typing.Optional[typing.Optional[int]] = None,
+        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
+        force_embedding_generation: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._list_data_source_items_mapped_args(
-            data_source_id=data_source_id,
-            parent_id=parent_id,
-            pagination=pagination,
+        args = self._resync_mapped_args(
+            file_id=file_id,
+            chunk_size=chunk_size,
+            chunk_overlap=chunk_overlap,
+            force_embedding_generation=force_embedding_generation,
         )
-        return await self._alist_data_source_items_oapg(
+        return await self._aresync_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def list_data_source_items(
+    def resync(
         self,
-        data_source_id: int,
-        parent_id: typing.Optional[typing.Optional[str]] = None,
-        pagination: typing.Optional[Pagination] = None,
+        file_id: int,
+        chunk_size: typing.Optional[typing.Optional[int]] = None,
+        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
+        force_embedding_generation: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._list_data_source_items_mapped_args(
-            data_source_id=data_source_id,
-            parent_id=parent_id,
-            pagination=pagination,
+        args = self._resync_mapped_args(
+            file_id=file_id,
+            chunk_size=chunk_size,
+            chunk_overlap=chunk_overlap,
+            force_embedding_generation=force_embedding_generation,
         )
-        return self._list_data_source_items_oapg(
+        return self._resync_oapg(
             body=args.body,
         )
 
-class ListDataSourceItems(BaseApi):
+class Resync(BaseApi):
 
-    async def alist_data_source_items(
+    async def aresync(
         self,
-        data_source_id: int,
-        parent_id: typing.Optional[typing.Optional[str]] = None,
-        pagination: typing.Optional[Pagination] = None,
+        file_id: int,
+        chunk_size: typing.Optional[typing.Optional[int]] = None,
+        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
+        force_embedding_generation: typing.Optional[bool] = None,
         validate: bool = False,
         **kwargs,
-    ) -> ListDataSourceItemsResponsePydantic:
-        raw_response = await self.raw.alist_data_source_items(
-            data_source_id=data_source_id,
-            parent_id=parent_id,
-            pagination=pagination,
+    ) -> UserFilePydantic:
+        raw_response = await self.raw.aresync(
+            file_id=file_id,
+            chunk_size=chunk_size,
+            chunk_overlap=chunk_overlap,
+            force_embedding_generation=force_embedding_generation,
             **kwargs,
         )
         if validate:
-            return ListDataSourceItemsResponsePydantic(**raw_response.body)
-        return api_client.construct_model_instance(ListDataSourceItemsResponsePydantic, raw_response.body)
+            return UserFilePydantic(**raw_response.body)
+        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
     
     
-    def list_data_source_items(
+    def resync(
         self,
-        data_source_id: int,
-        parent_id: typing.Optional[typing.Optional[str]] = None,
-        pagination: typing.Optional[Pagination] = None,
+        file_id: int,
+        chunk_size: typing.Optional[typing.Optional[int]] = None,
+        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
+        force_embedding_generation: typing.Optional[bool] = None,
         validate: bool = False,
-    ) -> ListDataSourceItemsResponsePydantic:
-        raw_response = self.raw.list_data_source_items(
-            data_source_id=data_source_id,
-            parent_id=parent_id,
-            pagination=pagination,
+    ) -> UserFilePydantic:
+        raw_response = self.raw.resync(
+            file_id=file_id,
+            chunk_size=chunk_size,
+            chunk_overlap=chunk_overlap,
+            force_embedding_generation=force_embedding_generation,
         )
         if validate:
-            return ListDataSourceItemsResponsePydantic(**raw_response.body)
-        return api_client.construct_model_instance(ListDataSourceItemsResponsePydantic, raw_response.body)
+            return UserFilePydantic(**raw_response.body)
+        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        data_source_id: int,
-        parent_id: typing.Optional[typing.Optional[str]] = None,
-        pagination: typing.Optional[Pagination] = None,
+        file_id: int,
+        chunk_size: typing.Optional[typing.Optional[int]] = None,
+        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
+        force_embedding_generation: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._list_data_source_items_mapped_args(
-            data_source_id=data_source_id,
-            parent_id=parent_id,
-            pagination=pagination,
+        args = self._resync_mapped_args(
+            file_id=file_id,
+            chunk_size=chunk_size,
+            chunk_overlap=chunk_overlap,
+            force_embedding_generation=force_embedding_generation,
         )
-        return await self._alist_data_source_items_oapg(
+        return await self._aresync_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        data_source_id: int,
-        parent_id: typing.Optional[typing.Optional[str]] = None,
-        pagination: typing.Optional[Pagination] = None,
+        file_id: int,
+        chunk_size: typing.Optional[typing.Optional[int]] = None,
+        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
+        force_embedding_generation: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._list_data_source_items_mapped_args(
-            data_source_id=data_source_id,
-            parent_id=parent_id,
-            pagination=pagination,
+        args = self._resync_mapped_args(
+            file_id=file_id,
+            chunk_size=chunk_size,
+            chunk_overlap=chunk_overlap,
+            force_embedding_generation=force_embedding_generation,
         )
-        return self._list_data_source_items_oapg(
+        return self._resync_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_items_list/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_items_sync/post.pyi`

 * *Files 12% similar despite different names*

```diff
@@ -28,52 +28,49 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
-from carbon.model.pagination import Pagination as PaginationSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.list_data_source_items_request import ListDataSourceItemsRequest as ListDataSourceItemsRequestSchema
-from carbon.model.list_data_source_items_response import ListDataSourceItemsResponse as ListDataSourceItemsResponseSchema
+from carbon.model.organization_user_data_source_api import OrganizationUserDataSourceAPI as OrganizationUserDataSourceAPISchema
+from carbon.model.sync_directory_request import SyncDirectoryRequest as SyncDirectoryRequestSchema
 
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.pagination import Pagination
-from carbon.type.list_data_source_items_request import ListDataSourceItemsRequest
-from carbon.type.list_data_source_items_response import ListDataSourceItemsResponse
+from carbon.type.sync_directory_request import SyncDirectoryRequest
+from carbon.type.organization_user_data_source_api import OrganizationUserDataSourceAPI
 
 from ...api_client import Dictionary
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
-from carbon.pydantic.list_data_source_items_response import ListDataSourceItemsResponse as ListDataSourceItemsResponsePydantic
-from carbon.pydantic.list_data_source_items_request import ListDataSourceItemsRequest as ListDataSourceItemsRequestPydantic
-from carbon.pydantic.pagination import Pagination as PaginationPydantic
+from carbon.pydantic.organization_user_data_source_api import OrganizationUserDataSourceAPI as OrganizationUserDataSourceAPIPydantic
+from carbon.pydantic.sync_directory_request import SyncDirectoryRequest as SyncDirectoryRequestPydantic
 
 # body param
-SchemaForRequestBodyApplicationJson = ListDataSourceItemsRequestSchema
+SchemaForRequestBodyApplicationJson = SyncDirectoryRequestSchema
 
 
-request_body_list_data_source_items_request = api_client.RequestBody(
+request_body_sync_directory_request = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
-SchemaFor200ResponseBodyApplicationJson = ListDataSourceItemsResponseSchema
+SchemaFor200ResponseBodyApplicationJson = OrganizationUserDataSourceAPISchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
-    body: ListDataSourceItemsResponse
+    body: OrganizationUserDataSourceAPI
 
 
 @dataclass
 class ApiResponseFor200Async(api_client.AsyncApiResponse):
-    body: ListDataSourceItemsResponse
+    body: OrganizationUserDataSourceAPI
 
 
 _response_for_200 = api_client.OpenApiResponse(
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
@@ -104,47 +101,41 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _list_data_source_items_mapped_args(
+    def _sync_data_source_items_mapped_args(
         self,
         data_source_id: int,
-        parent_id: typing.Optional[typing.Optional[str]] = None,
-        pagination: typing.Optional[Pagination] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if data_source_id is not None:
             _body["data_source_id"] = data_source_id
-        if parent_id is not None:
-            _body["parent_id"] = parent_id
-        if pagination is not None:
-            _body["pagination"] = pagination
         args.body = _body
         return args
 
-    async def _alist_data_source_items_oapg(
+    async def _async_data_source_items_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        List Data Source Items
+        Sync Data Source Items
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -160,20 +151,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/items/list',
+            path_template='/integrations/items/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_list_data_source_items_request.serialize(body, content_type)
+        serialized_data = request_body_sync_directory_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -237,28 +228,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _list_data_source_items_oapg(
+    def _sync_data_source_items_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        List Data Source Items
+        Sync Data Source Items
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -274,20 +265,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/items/list',
+            path_template='/integrations/items/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_list_data_source_items_request.serialize(body, content_type)
+        serialized_data = request_body_sync_directory_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -320,129 +311,105 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class ListDataSourceItemsRaw(BaseApi):
+class SyncDataSourceItemsRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def alist_data_source_items(
+    async def async_data_source_items(
         self,
         data_source_id: int,
-        parent_id: typing.Optional[typing.Optional[str]] = None,
-        pagination: typing.Optional[Pagination] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._list_data_source_items_mapped_args(
+        args = self._sync_data_source_items_mapped_args(
             data_source_id=data_source_id,
-            parent_id=parent_id,
-            pagination=pagination,
         )
-        return await self._alist_data_source_items_oapg(
+        return await self._async_data_source_items_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def list_data_source_items(
+    def sync_data_source_items(
         self,
         data_source_id: int,
-        parent_id: typing.Optional[typing.Optional[str]] = None,
-        pagination: typing.Optional[Pagination] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._list_data_source_items_mapped_args(
+        args = self._sync_data_source_items_mapped_args(
             data_source_id=data_source_id,
-            parent_id=parent_id,
-            pagination=pagination,
         )
-        return self._list_data_source_items_oapg(
+        return self._sync_data_source_items_oapg(
             body=args.body,
         )
 
-class ListDataSourceItems(BaseApi):
+class SyncDataSourceItems(BaseApi):
 
-    async def alist_data_source_items(
+    async def async_data_source_items(
         self,
         data_source_id: int,
-        parent_id: typing.Optional[typing.Optional[str]] = None,
-        pagination: typing.Optional[Pagination] = None,
         validate: bool = False,
         **kwargs,
-    ) -> ListDataSourceItemsResponsePydantic:
-        raw_response = await self.raw.alist_data_source_items(
+    ) -> OrganizationUserDataSourceAPIPydantic:
+        raw_response = await self.raw.async_data_source_items(
             data_source_id=data_source_id,
-            parent_id=parent_id,
-            pagination=pagination,
             **kwargs,
         )
         if validate:
-            return ListDataSourceItemsResponsePydantic(**raw_response.body)
-        return api_client.construct_model_instance(ListDataSourceItemsResponsePydantic, raw_response.body)
+            return OrganizationUserDataSourceAPIPydantic(**raw_response.body)
+        return api_client.construct_model_instance(OrganizationUserDataSourceAPIPydantic, raw_response.body)
     
     
-    def list_data_source_items(
+    def sync_data_source_items(
         self,
         data_source_id: int,
-        parent_id: typing.Optional[typing.Optional[str]] = None,
-        pagination: typing.Optional[Pagination] = None,
         validate: bool = False,
-    ) -> ListDataSourceItemsResponsePydantic:
-        raw_response = self.raw.list_data_source_items(
+    ) -> OrganizationUserDataSourceAPIPydantic:
+        raw_response = self.raw.sync_data_source_items(
             data_source_id=data_source_id,
-            parent_id=parent_id,
-            pagination=pagination,
         )
         if validate:
-            return ListDataSourceItemsResponsePydantic(**raw_response.body)
-        return api_client.construct_model_instance(ListDataSourceItemsResponsePydantic, raw_response.body)
+            return OrganizationUserDataSourceAPIPydantic(**raw_response.body)
+        return api_client.construct_model_instance(OrganizationUserDataSourceAPIPydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
         data_source_id: int,
-        parent_id: typing.Optional[typing.Optional[str]] = None,
-        pagination: typing.Optional[Pagination] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._list_data_source_items_mapped_args(
+        args = self._sync_data_source_items_mapped_args(
             data_source_id=data_source_id,
-            parent_id=parent_id,
-            pagination=pagination,
         )
-        return await self._alist_data_source_items_oapg(
+        return await self._async_data_source_items_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
         data_source_id: int,
-        parent_id: typing.Optional[typing.Optional[str]] = None,
-        pagination: typing.Optional[Pagination] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._list_data_source_items_mapped_args(
+        args = self._sync_data_source_items_mapped_args(
             data_source_id=data_source_id,
-            parent_id=parent_id,
-            pagination=pagination,
         )
-        return self._list_data_source_items_oapg(
+        return self._sync_data_source_items_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_items_sync/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_items_sync/post.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_items_sync/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_github/post.pyi`

 * *Files 9% similar despite different names*

```diff
@@ -29,48 +29,48 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.organization_user_data_source_api import OrganizationUserDataSourceAPI as OrganizationUserDataSourceAPISchema
-from carbon.model.sync_directory_request import SyncDirectoryRequest as SyncDirectoryRequestSchema
+from carbon.model.github_connect_request import GithubConnectRequest as GithubConnectRequestSchema
+from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
 
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.sync_directory_request import SyncDirectoryRequest
-from carbon.type.organization_user_data_source_api import OrganizationUserDataSourceAPI
+from carbon.type.generic_success_response import GenericSuccessResponse
+from carbon.type.github_connect_request import GithubConnectRequest
 
 from ...api_client import Dictionary
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
-from carbon.pydantic.organization_user_data_source_api import OrganizationUserDataSourceAPI as OrganizationUserDataSourceAPIPydantic
-from carbon.pydantic.sync_directory_request import SyncDirectoryRequest as SyncDirectoryRequestPydantic
+from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
+from carbon.pydantic.github_connect_request import GithubConnectRequest as GithubConnectRequestPydantic
 
 # body param
-SchemaForRequestBodyApplicationJson = SyncDirectoryRequestSchema
+SchemaForRequestBodyApplicationJson = GithubConnectRequestSchema
 
 
-request_body_sync_directory_request = api_client.RequestBody(
+request_body_github_connect_request = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
-SchemaFor200ResponseBodyApplicationJson = OrganizationUserDataSourceAPISchema
+SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
-    body: OrganizationUserDataSourceAPI
+    body: GenericSuccessResponse
 
 
 @dataclass
 class ApiResponseFor200Async(api_client.AsyncApiResponse):
-    body: OrganizationUserDataSourceAPI
+    body: GenericSuccessResponse
 
 
 _response_for_200 = api_client.OpenApiResponse(
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
@@ -101,41 +101,47 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _sync_data_source_items_mapped_args(
+    def _sync_git_hub_mapped_args(
         self,
-        data_source_id: int,
+        username: str,
+        access_token: str,
+        sync_source_items: typing.Optional[bool] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
-        if data_source_id is not None:
-            _body["data_source_id"] = data_source_id
+        if username is not None:
+            _body["username"] = username
+        if access_token is not None:
+            _body["access_token"] = access_token
+        if sync_source_items is not None:
+            _body["sync_source_items"] = sync_source_items
         args.body = _body
         return args
 
-    async def _async_data_source_items_oapg(
+    async def _async_git_hub_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Sync Data Source Items
+        Github Connect
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -151,20 +157,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/items/sync',
+            path_template='/integrations/github',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_sync_directory_request.serialize(body, content_type)
+        serialized_data = request_body_github_connect_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -228,28 +234,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _sync_data_source_items_oapg(
+    def _sync_git_hub_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Sync Data Source Items
+        Github Connect
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -265,20 +271,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/items/sync',
+            path_template='/integrations/github',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_sync_directory_request.serialize(body, content_type)
+        serialized_data = request_body_github_connect_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -311,105 +317,129 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class SyncDataSourceItemsRaw(BaseApi):
+class SyncGitHubRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def async_data_source_items(
+    async def async_git_hub(
         self,
-        data_source_id: int,
+        username: str,
+        access_token: str,
+        sync_source_items: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_data_source_items_mapped_args(
-            data_source_id=data_source_id,
+        args = self._sync_git_hub_mapped_args(
+            username=username,
+            access_token=access_token,
+            sync_source_items=sync_source_items,
         )
-        return await self._async_data_source_items_oapg(
+        return await self._async_git_hub_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def sync_data_source_items(
+    def sync_git_hub(
         self,
-        data_source_id: int,
+        username: str,
+        access_token: str,
+        sync_source_items: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_data_source_items_mapped_args(
-            data_source_id=data_source_id,
+        args = self._sync_git_hub_mapped_args(
+            username=username,
+            access_token=access_token,
+            sync_source_items=sync_source_items,
         )
-        return self._sync_data_source_items_oapg(
+        return self._sync_git_hub_oapg(
             body=args.body,
         )
 
-class SyncDataSourceItems(BaseApi):
+class SyncGitHub(BaseApi):
 
-    async def async_data_source_items(
+    async def async_git_hub(
         self,
-        data_source_id: int,
+        username: str,
+        access_token: str,
+        sync_source_items: typing.Optional[bool] = None,
         validate: bool = False,
         **kwargs,
-    ) -> OrganizationUserDataSourceAPIPydantic:
-        raw_response = await self.raw.async_data_source_items(
-            data_source_id=data_source_id,
+    ) -> GenericSuccessResponsePydantic:
+        raw_response = await self.raw.async_git_hub(
+            username=username,
+            access_token=access_token,
+            sync_source_items=sync_source_items,
             **kwargs,
         )
         if validate:
-            return OrganizationUserDataSourceAPIPydantic(**raw_response.body)
-        return api_client.construct_model_instance(OrganizationUserDataSourceAPIPydantic, raw_response.body)
+            return GenericSuccessResponsePydantic(**raw_response.body)
+        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
-    def sync_data_source_items(
+    def sync_git_hub(
         self,
-        data_source_id: int,
+        username: str,
+        access_token: str,
+        sync_source_items: typing.Optional[bool] = None,
         validate: bool = False,
-    ) -> OrganizationUserDataSourceAPIPydantic:
-        raw_response = self.raw.sync_data_source_items(
-            data_source_id=data_source_id,
+    ) -> GenericSuccessResponsePydantic:
+        raw_response = self.raw.sync_git_hub(
+            username=username,
+            access_token=access_token,
+            sync_source_items=sync_source_items,
         )
         if validate:
-            return OrganizationUserDataSourceAPIPydantic(**raw_response.body)
-        return api_client.construct_model_instance(OrganizationUserDataSourceAPIPydantic, raw_response.body)
+            return GenericSuccessResponsePydantic(**raw_response.body)
+        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        data_source_id: int,
+        username: str,
+        access_token: str,
+        sync_source_items: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_data_source_items_mapped_args(
-            data_source_id=data_source_id,
+        args = self._sync_git_hub_mapped_args(
+            username=username,
+            access_token=access_token,
+            sync_source_items=sync_source_items,
         )
-        return await self._async_data_source_items_oapg(
+        return await self._async_git_hub_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        data_source_id: int,
+        username: str,
+        access_token: str,
+        sync_source_items: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_data_source_items_mapped_args(
-            data_source_id=data_source_id,
+        args = self._sync_git_hub_mapped_args(
+            username=username,
+            access_token=access_token,
+            sync_source_items=sync_source_items,
         )
-        return self._sync_data_source_items_oapg(
+        return self._sync_git_hub_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_oauth_url/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_gmail_sync/post.pyi`

 * *Files 19% similar despite different names*

```diff
@@ -29,61 +29,54 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullableSchema
-from carbon.model.data_source_type import DataSourceType as DataSourceTypeSchema
-from carbon.model.o_auth_url_request import OAuthURLRequest as OAuthURLRequestSchema
-from carbon.model.outh_url_response import OuthURLResponse as OuthURLResponseSchema
+from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
+from carbon.model.gmail_sync_input import GmailSyncInput as GmailSyncInputSchema
+from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullableSchema
 
-from carbon.type.outh_url_response import OuthURLResponse
+from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.o_auth_url_request import OAuthURLRequest
-from carbon.type.data_source_type import DataSourceType
-from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.type.file_sync_config_nullable import FileSyncConfigNullable
+from carbon.type.generic_success_response import GenericSuccessResponse
+from carbon.type.gmail_sync_input import GmailSyncInput
 
 from ...api_client import Dictionary
-from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullablePydantic
-from carbon.pydantic.data_source_type import DataSourceType as DataSourceTypePydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
-from carbon.pydantic.o_auth_url_request import OAuthURLRequest as OAuthURLRequestPydantic
-from carbon.pydantic.outh_url_response import OuthURLResponse as OuthURLResponsePydantic
-
-from . import path
+from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
+from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
+from carbon.pydantic.gmail_sync_input import GmailSyncInput as GmailSyncInputPydantic
+from carbon.pydantic.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullablePydantic
 
 # body param
-SchemaForRequestBodyApplicationJson = OAuthURLRequestSchema
+SchemaForRequestBodyApplicationJson = GmailSyncInputSchema
 
 
-request_body_o_auth_url_request = api_client.RequestBody(
+request_body_gmail_sync_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
-_auth = [
-    'accessToken',
-    'apiKey',
-    'customerId',
-]
-SchemaFor200ResponseBodyApplicationJson = OuthURLResponseSchema
+SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
-    body: OuthURLResponse
+    body: GenericSuccessResponse
 
 
 @dataclass
 class ApiResponseFor200Async(api_client.AsyncApiResponse):
-    body: OuthURLResponse
+    body: GenericSuccessResponse
 
 
 _response_for_200 = api_client.OpenApiResponse(
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
@@ -107,106 +100,84 @@
     response_cls=ApiResponseFor422,
     response_cls_async=ApiResponseFor422Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor422ResponseBodyApplicationJson),
     },
 )
-_status_code_to_response = {
-    '200': _response_for_200,
-    '422': _response_for_422,
-}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _get_oauth_url_mapped_args(
+    def _sync_gmail_mapped_args(
         self,
-        service: DataSourceType,
-        tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
-        scope: typing.Optional[typing.Optional[str]] = None,
+        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        zendesk_subdomain: typing.Optional[typing.Optional[str]] = None,
-        microsoft_tenant: typing.Optional[typing.Optional[str]] = None,
-        sharepoint_site_name: typing.Optional[typing.Optional[str]] = None,
-        confluence_subdomain: typing.Optional[typing.Optional[str]] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        salesforce_domain: typing.Optional[typing.Optional[str]] = None,
-        sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
-        connecting_new_account: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if tags is not None:
             _body["tags"] = tags
-        if scope is not None:
-            _body["scope"] = scope
-        if service is not None:
-            _body["service"] = service
+        if filters is not None:
+            _body["filters"] = filters
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
             _body["skip_embedding_generation"] = skip_embedding_generation
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
-        if zendesk_subdomain is not None:
-            _body["zendesk_subdomain"] = zendesk_subdomain
-        if microsoft_tenant is not None:
-            _body["microsoft_tenant"] = microsoft_tenant
-        if sharepoint_site_name is not None:
-            _body["sharepoint_site_name"] = sharepoint_site_name
-        if confluence_subdomain is not None:
-            _body["confluence_subdomain"] = confluence_subdomain
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
-        if max_items_per_chunk is not None:
-            _body["max_items_per_chunk"] = max_items_per_chunk
-        if salesforce_domain is not None:
-            _body["salesforce_domain"] = salesforce_domain
-        if sync_files_on_connection is not None:
-            _body["sync_files_on_connection"] = sync_files_on_connection
-        if set_page_as_boundary is not None:
-            _body["set_page_as_boundary"] = set_page_as_boundary
         if data_source_id is not None:
             _body["data_source_id"] = data_source_id
-        if connecting_new_account is not None:
-            _body["connecting_new_account"] = connecting_new_account
+        if request_id is not None:
+            _body["request_id"] = request_id
+        if sync_attachments is not None:
+            _body["sync_attachments"] = sync_attachments
+        if file_sync_config is not None:
+            _body["file_sync_config"] = file_sync_config
+        if incremental_sync is not None:
+            _body["incremental_sync"] = incremental_sync
         args.body = _body
         return args
 
-    async def _aget_oauth_url_oapg(
+    async def _async_gmail_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Get Oauth Url
+        Gmail Sync
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -222,20 +193,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/oauth_url',
+            path_template='/integrations/gmail/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_o_auth_url_request.serialize(body, content_type)
+        serialized_data = request_body_gmail_sync_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -299,28 +270,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _get_oauth_url_oapg(
+    def _sync_gmail_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Get Oauth Url
+        Gmail Sync
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -336,20 +307,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/oauth_url',
+            path_template='/integrations/gmail/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_o_auth_url_request.serialize(body, content_type)
+        serialized_data = request_body_gmail_sync_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -382,321 +353,249 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class GetOauthUrlRaw(BaseApi):
+class SyncGmailRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def aget_oauth_url(
+    async def async_gmail(
         self,
-        service: DataSourceType,
-        tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
-        scope: typing.Optional[typing.Optional[str]] = None,
+        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        zendesk_subdomain: typing.Optional[typing.Optional[str]] = None,
-        microsoft_tenant: typing.Optional[typing.Optional[str]] = None,
-        sharepoint_site_name: typing.Optional[typing.Optional[str]] = None,
-        confluence_subdomain: typing.Optional[typing.Optional[str]] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        salesforce_domain: typing.Optional[typing.Optional[str]] = None,
-        sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
-        connecting_new_account: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._get_oauth_url_mapped_args(
-            service=service,
+        args = self._sync_gmail_mapped_args(
+            filters=filters,
             tags=tags,
-            scope=scope,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
-            zendesk_subdomain=zendesk_subdomain,
-            microsoft_tenant=microsoft_tenant,
-            sharepoint_site_name=sharepoint_site_name,
-            confluence_subdomain=confluence_subdomain,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            salesforce_domain=salesforce_domain,
-            sync_files_on_connection=sync_files_on_connection,
-            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
-            connecting_new_account=connecting_new_account,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
-        return await self._aget_oauth_url_oapg(
+        return await self._async_gmail_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def get_oauth_url(
+    def sync_gmail(
         self,
-        service: DataSourceType,
-        tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
-        scope: typing.Optional[typing.Optional[str]] = None,
+        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        zendesk_subdomain: typing.Optional[typing.Optional[str]] = None,
-        microsoft_tenant: typing.Optional[typing.Optional[str]] = None,
-        sharepoint_site_name: typing.Optional[typing.Optional[str]] = None,
-        confluence_subdomain: typing.Optional[typing.Optional[str]] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        salesforce_domain: typing.Optional[typing.Optional[str]] = None,
-        sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
-        connecting_new_account: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._get_oauth_url_mapped_args(
-            service=service,
+        args = self._sync_gmail_mapped_args(
+            filters=filters,
             tags=tags,
-            scope=scope,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
-            zendesk_subdomain=zendesk_subdomain,
-            microsoft_tenant=microsoft_tenant,
-            sharepoint_site_name=sharepoint_site_name,
-            confluence_subdomain=confluence_subdomain,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            salesforce_domain=salesforce_domain,
-            sync_files_on_connection=sync_files_on_connection,
-            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
-            connecting_new_account=connecting_new_account,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
-        return self._get_oauth_url_oapg(
+        return self._sync_gmail_oapg(
             body=args.body,
         )
 
-class GetOauthUrl(BaseApi):
+class SyncGmail(BaseApi):
 
-    async def aget_oauth_url(
+    async def async_gmail(
         self,
-        service: DataSourceType,
-        tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
-        scope: typing.Optional[typing.Optional[str]] = None,
+        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        zendesk_subdomain: typing.Optional[typing.Optional[str]] = None,
-        microsoft_tenant: typing.Optional[typing.Optional[str]] = None,
-        sharepoint_site_name: typing.Optional[typing.Optional[str]] = None,
-        confluence_subdomain: typing.Optional[typing.Optional[str]] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        salesforce_domain: typing.Optional[typing.Optional[str]] = None,
-        sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
-        connecting_new_account: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
         validate: bool = False,
         **kwargs,
-    ) -> OuthURLResponsePydantic:
-        raw_response = await self.raw.aget_oauth_url(
-            service=service,
+    ) -> GenericSuccessResponsePydantic:
+        raw_response = await self.raw.async_gmail(
+            filters=filters,
             tags=tags,
-            scope=scope,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
-            zendesk_subdomain=zendesk_subdomain,
-            microsoft_tenant=microsoft_tenant,
-            sharepoint_site_name=sharepoint_site_name,
-            confluence_subdomain=confluence_subdomain,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            salesforce_domain=salesforce_domain,
-            sync_files_on_connection=sync_files_on_connection,
-            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
-            connecting_new_account=connecting_new_account,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
             **kwargs,
         )
         if validate:
-            return OuthURLResponsePydantic(**raw_response.body)
-        return api_client.construct_model_instance(OuthURLResponsePydantic, raw_response.body)
+            return GenericSuccessResponsePydantic(**raw_response.body)
+        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
-    def get_oauth_url(
+    def sync_gmail(
         self,
-        service: DataSourceType,
-        tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
-        scope: typing.Optional[typing.Optional[str]] = None,
+        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        zendesk_subdomain: typing.Optional[typing.Optional[str]] = None,
-        microsoft_tenant: typing.Optional[typing.Optional[str]] = None,
-        sharepoint_site_name: typing.Optional[typing.Optional[str]] = None,
-        confluence_subdomain: typing.Optional[typing.Optional[str]] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        salesforce_domain: typing.Optional[typing.Optional[str]] = None,
-        sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
-        connecting_new_account: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
         validate: bool = False,
-    ) -> OuthURLResponsePydantic:
-        raw_response = self.raw.get_oauth_url(
-            service=service,
+    ) -> GenericSuccessResponsePydantic:
+        raw_response = self.raw.sync_gmail(
+            filters=filters,
             tags=tags,
-            scope=scope,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
-            zendesk_subdomain=zendesk_subdomain,
-            microsoft_tenant=microsoft_tenant,
-            sharepoint_site_name=sharepoint_site_name,
-            confluence_subdomain=confluence_subdomain,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            salesforce_domain=salesforce_domain,
-            sync_files_on_connection=sync_files_on_connection,
-            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
-            connecting_new_account=connecting_new_account,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
         if validate:
-            return OuthURLResponsePydantic(**raw_response.body)
-        return api_client.construct_model_instance(OuthURLResponsePydantic, raw_response.body)
+            return GenericSuccessResponsePydantic(**raw_response.body)
+        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        service: DataSourceType,
-        tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
-        scope: typing.Optional[typing.Optional[str]] = None,
+        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        zendesk_subdomain: typing.Optional[typing.Optional[str]] = None,
-        microsoft_tenant: typing.Optional[typing.Optional[str]] = None,
-        sharepoint_site_name: typing.Optional[typing.Optional[str]] = None,
-        confluence_subdomain: typing.Optional[typing.Optional[str]] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        salesforce_domain: typing.Optional[typing.Optional[str]] = None,
-        sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
-        connecting_new_account: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._get_oauth_url_mapped_args(
-            service=service,
+        args = self._sync_gmail_mapped_args(
+            filters=filters,
             tags=tags,
-            scope=scope,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
-            zendesk_subdomain=zendesk_subdomain,
-            microsoft_tenant=microsoft_tenant,
-            sharepoint_site_name=sharepoint_site_name,
-            confluence_subdomain=confluence_subdomain,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            salesforce_domain=salesforce_domain,
-            sync_files_on_connection=sync_files_on_connection,
-            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
-            connecting_new_account=connecting_new_account,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
-        return await self._aget_oauth_url_oapg(
+        return await self._async_gmail_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        service: DataSourceType,
-        tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = None,
-        scope: typing.Optional[typing.Optional[str]] = None,
+        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        zendesk_subdomain: typing.Optional[typing.Optional[str]] = None,
-        microsoft_tenant: typing.Optional[typing.Optional[str]] = None,
-        sharepoint_site_name: typing.Optional[typing.Optional[str]] = None,
-        confluence_subdomain: typing.Optional[typing.Optional[str]] = None,
+        embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        salesforce_domain: typing.Optional[typing.Optional[str]] = None,
-        sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
-        connecting_new_account: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._get_oauth_url_mapped_args(
-            service=service,
+        args = self._sync_gmail_mapped_args(
+            filters=filters,
             tags=tags,
-            scope=scope,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
-            zendesk_subdomain=zendesk_subdomain,
-            microsoft_tenant=microsoft_tenant,
-            sharepoint_site_name=sharepoint_site_name,
-            confluence_subdomain=confluence_subdomain,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            salesforce_domain=salesforce_domain,
-            sync_files_on_connection=sync_files_on_connection,
-            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
-            connecting_new_account=connecting_new_account,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
-        return self._get_oauth_url_oapg(
+        return self._sync_gmail_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_oauth_url/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_oauth_url/post.pyi`

 * *Files 15% similar despite different names*

```diff
@@ -33,27 +33,30 @@
 from carbon import schemas  # noqa: F401
 
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
 from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullableSchema
 from carbon.model.data_source_type import DataSourceType as DataSourceTypeSchema
 from carbon.model.o_auth_url_request import OAuthURLRequest as OAuthURLRequestSchema
 from carbon.model.outh_url_response import OuthURLResponse as OuthURLResponseSchema
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullableSchema
 
 from carbon.type.outh_url_response import OuthURLResponse
 from carbon.type.http_validation_error import HTTPValidationError
 from carbon.type.o_auth_url_request import OAuthURLRequest
+from carbon.type.file_sync_config_nullable import FileSyncConfigNullable
 from carbon.type.data_source_type import DataSourceType
 from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
 
 from ...api_client import Dictionary
 from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullablePydantic
 from carbon.pydantic.data_source_type import DataSourceType as DataSourceTypePydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.o_auth_url_request import OAuthURLRequest as OAuthURLRequestPydantic
 from carbon.pydantic.outh_url_response import OuthURLResponse as OuthURLResponsePydantic
+from carbon.pydantic.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullablePydantic
 
 # body param
 SchemaForRequestBodyApplicationJson = OAuthURLRequestSchema
 
 
 request_body_o_auth_url_request = api_client.RequestBody(
     content={
@@ -128,14 +131,21 @@
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
         salesforce_domain: typing.Optional[typing.Optional[str]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
         connecting_new_account: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        enable_file_picker: typing.Optional[bool] = None,
+        sync_source_items: typing.Optional[bool] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if tags is not None:
             _body["tags"] = tags
         if scope is not None:
             _body["scope"] = scope
@@ -169,14 +179,28 @@
             _body["sync_files_on_connection"] = sync_files_on_connection
         if set_page_as_boundary is not None:
             _body["set_page_as_boundary"] = set_page_as_boundary
         if data_source_id is not None:
             _body["data_source_id"] = data_source_id
         if connecting_new_account is not None:
             _body["connecting_new_account"] = connecting_new_account
+        if request_id is not None:
+            _body["request_id"] = request_id
+        if use_ocr is not None:
+            _body["use_ocr"] = use_ocr
+        if parse_pdf_tables_with_ocr is not None:
+            _body["parse_pdf_tables_with_ocr"] = parse_pdf_tables_with_ocr
+        if enable_file_picker is not None:
+            _body["enable_file_picker"] = enable_file_picker
+        if sync_source_items is not None:
+            _body["sync_source_items"] = sync_source_items
+        if incremental_sync is not None:
+            _body["incremental_sync"] = incremental_sync
+        if file_sync_config is not None:
+            _body["file_sync_config"] = file_sync_config
         args.body = _body
         return args
 
     async def _aget_oauth_url_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
@@ -395,14 +419,21 @@
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
         salesforce_domain: typing.Optional[typing.Optional[str]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
         connecting_new_account: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        enable_file_picker: typing.Optional[bool] = None,
+        sync_source_items: typing.Optional[bool] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         args = self._get_oauth_url_mapped_args(
@@ -421,14 +452,21 @@
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
             salesforce_domain=salesforce_domain,
             sync_files_on_connection=sync_files_on_connection,
             set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
             connecting_new_account=connecting_new_account,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            enable_file_picker=enable_file_picker,
+            sync_source_items=sync_source_items,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
         return await self._aget_oauth_url_oapg(
             body=args.body,
             **kwargs,
         )
     
     def get_oauth_url(
@@ -448,14 +486,21 @@
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
         salesforce_domain: typing.Optional[typing.Optional[str]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
         connecting_new_account: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        enable_file_picker: typing.Optional[bool] = None,
+        sync_source_items: typing.Optional[bool] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._get_oauth_url_mapped_args(
             service=service,
             tags=tags,
@@ -472,14 +517,21 @@
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
             salesforce_domain=salesforce_domain,
             sync_files_on_connection=sync_files_on_connection,
             set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
             connecting_new_account=connecting_new_account,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            enable_file_picker=enable_file_picker,
+            sync_source_items=sync_source_items,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
         return self._get_oauth_url_oapg(
             body=args.body,
         )
 
 class GetOauthUrl(BaseApi):
 
@@ -500,14 +552,21 @@
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
         salesforce_domain: typing.Optional[typing.Optional[str]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
         connecting_new_account: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        enable_file_picker: typing.Optional[bool] = None,
+        sync_source_items: typing.Optional[bool] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         validate: bool = False,
         **kwargs,
     ) -> OuthURLResponsePydantic:
         raw_response = await self.raw.aget_oauth_url(
             service=service,
             tags=tags,
             scope=scope,
@@ -523,14 +582,21 @@
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
             salesforce_domain=salesforce_domain,
             sync_files_on_connection=sync_files_on_connection,
             set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
             connecting_new_account=connecting_new_account,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            enable_file_picker=enable_file_picker,
+            sync_source_items=sync_source_items,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
             **kwargs,
         )
         if validate:
             return OuthURLResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(OuthURLResponsePydantic, raw_response.body)
     
     
@@ -551,14 +617,21 @@
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
         salesforce_domain: typing.Optional[typing.Optional[str]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
         connecting_new_account: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        enable_file_picker: typing.Optional[bool] = None,
+        sync_source_items: typing.Optional[bool] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         validate: bool = False,
     ) -> OuthURLResponsePydantic:
         raw_response = self.raw.get_oauth_url(
             service=service,
             tags=tags,
             scope=scope,
             chunk_size=chunk_size,
@@ -573,14 +646,21 @@
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
             salesforce_domain=salesforce_domain,
             sync_files_on_connection=sync_files_on_connection,
             set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
             connecting_new_account=connecting_new_account,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            enable_file_picker=enable_file_picker,
+            sync_source_items=sync_source_items,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
         if validate:
             return OuthURLResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(OuthURLResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
@@ -603,14 +683,21 @@
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
         salesforce_domain: typing.Optional[typing.Optional[str]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
         connecting_new_account: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        enable_file_picker: typing.Optional[bool] = None,
+        sync_source_items: typing.Optional[bool] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         args = self._get_oauth_url_mapped_args(
@@ -629,14 +716,21 @@
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
             salesforce_domain=salesforce_domain,
             sync_files_on_connection=sync_files_on_connection,
             set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
             connecting_new_account=connecting_new_account,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            enable_file_picker=enable_file_picker,
+            sync_source_items=sync_source_items,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
         return await self._aget_oauth_url_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
@@ -656,14 +750,21 @@
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
         salesforce_domain: typing.Optional[typing.Optional[str]] = None,
         sync_files_on_connection: typing.Optional[typing.Optional[bool]] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
         connecting_new_account: typing.Optional[typing.Optional[bool]] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        enable_file_picker: typing.Optional[bool] = None,
+        sync_source_items: typing.Optional[bool] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._get_oauth_url_mapped_args(
             service=service,
             tags=tags,
@@ -680,12 +781,19 @@
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
             salesforce_domain=salesforce_domain,
             sync_files_on_connection=sync_files_on_connection,
             set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
             connecting_new_account=connecting_new_account,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            enable_file_picker=enable_file_picker,
+            sync_source_items=sync_source_items,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
         return self._get_oauth_url_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_outlook_sync/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_s3_files/post.py`

 * *Files 10% similar despite different names*

```diff
@@ -28,37 +28,43 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
-from carbon.model.outlook_sync_input import OutlookSyncInput as OutlookSyncInputSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
+from carbon.model.s3_file_sync_input import S3FileSyncInput as S3FileSyncInputSchema
 from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
+from carbon.model.s3_get_file_input import S3GetFileInput as S3GetFileInputSchema
 from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullableSchema
 
 from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.outlook_sync_input import OutlookSyncInput
+from carbon.type.file_sync_config_nullable import FileSyncConfigNullable
+from carbon.type.s3_file_sync_input import S3FileSyncInput
 from carbon.type.generic_success_response import GenericSuccessResponse
+from carbon.type.s3_get_file_input import S3GetFileInput
 
 from ...api_client import Dictionary
-from carbon.pydantic.outlook_sync_input import OutlookSyncInput as OutlookSyncInputPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
+from carbon.pydantic.s3_file_sync_input import S3FileSyncInput as S3FileSyncInputPydantic
 from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
 from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
+from carbon.pydantic.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullablePydantic
+from carbon.pydantic.s3_get_file_input import S3GetFileInput as S3GetFileInputPydantic
 
 from . import path
 
 # body param
-SchemaForRequestBodyApplicationJson = OutlookSyncInputSchema
+SchemaForRequestBodyApplicationJson = S3FileSyncInputSchema
 
 
-request_body_outlook_sync_input = api_client.RequestBody(
+request_body_s3_file_sync_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
 _auth = [
@@ -115,68 +121,83 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _sync_outlook_mapped_args(
+    def _sync_s3_files_mapped_args(
         self,
-        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        ids: typing.List[S3GetFileInput],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
-        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if tags is not None:
             _body["tags"] = tags
-        if folder is not None:
-            _body["folder"] = folder
-        if filters is not None:
-            _body["filters"] = filters
+        if ids is not None:
+            _body["ids"] = ids
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
             _body["skip_embedding_generation"] = skip_embedding_generation
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
+        if max_items_per_chunk is not None:
+            _body["max_items_per_chunk"] = max_items_per_chunk
+        if set_page_as_boundary is not None:
+            _body["set_page_as_boundary"] = set_page_as_boundary
         if data_source_id is not None:
             _body["data_source_id"] = data_source_id
+        if request_id is not None:
+            _body["request_id"] = request_id
+        if use_ocr is not None:
+            _body["use_ocr"] = use_ocr
+        if parse_pdf_tables_with_ocr is not None:
+            _body["parse_pdf_tables_with_ocr"] = parse_pdf_tables_with_ocr
+        if file_sync_config is not None:
+            _body["file_sync_config"] = file_sync_config
         args.body = _body
         return args
 
-    async def _async_outlook_oapg(
+    async def _async_s3_files_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Outlook Sync
+        S3 Files
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -192,20 +213,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/outlook/sync',
+            path_template='/integrations/s3/files',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_outlook_sync_input.serialize(body, content_type)
+        serialized_data = request_body_s3_file_sync_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -269,28 +290,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _sync_outlook_oapg(
+    def _sync_s3_files_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Outlook Sync
+        S3 Files
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -306,20 +327,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/outlook/sync',
+            path_template='/integrations/s3/files',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_outlook_sync_input.serialize(body, content_type)
+        serialized_data = request_body_s3_file_sync_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -352,213 +373,273 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class SyncOutlookRaw(BaseApi):
+class SyncS3FilesRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def async_outlook(
+    async def async_s3_files(
         self,
-        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        ids: typing.List[S3GetFileInput],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
-        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_outlook_mapped_args(
-            filters=filters,
+        args = self._sync_s3_files_mapped_args(
+            ids=ids,
             tags=tags,
-            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            file_sync_config=file_sync_config,
         )
-        return await self._async_outlook_oapg(
+        return await self._async_s3_files_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def sync_outlook(
+    def sync_s3_files(
         self,
-        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        ids: typing.List[S3GetFileInput],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
-        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_outlook_mapped_args(
-            filters=filters,
+        args = self._sync_s3_files_mapped_args(
+            ids=ids,
             tags=tags,
-            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            file_sync_config=file_sync_config,
         )
-        return self._sync_outlook_oapg(
+        return self._sync_s3_files_oapg(
             body=args.body,
         )
 
-class SyncOutlook(BaseApi):
+class SyncS3Files(BaseApi):
 
-    async def async_outlook(
+    async def async_s3_files(
         self,
-        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        ids: typing.List[S3GetFileInput],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
-        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         validate: bool = False,
         **kwargs,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = await self.raw.async_outlook(
-            filters=filters,
+        raw_response = await self.raw.async_s3_files(
+            ids=ids,
             tags=tags,
-            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            file_sync_config=file_sync_config,
             **kwargs,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
-    def sync_outlook(
+    def sync_s3_files(
         self,
-        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        ids: typing.List[S3GetFileInput],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
-        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         validate: bool = False,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = self.raw.sync_outlook(
-            filters=filters,
+        raw_response = self.raw.sync_s3_files(
+            ids=ids,
             tags=tags,
-            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            file_sync_config=file_sync_config,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        ids: typing.List[S3GetFileInput],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
-        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_outlook_mapped_args(
-            filters=filters,
+        args = self._sync_s3_files_mapped_args(
+            ids=ids,
             tags=tags,
-            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            file_sync_config=file_sync_config,
         )
-        return await self._async_outlook_oapg(
+        return await self._async_s3_files_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        ids: typing.List[S3GetFileInput],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
-        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_outlook_mapped_args(
-            filters=filters,
+        args = self._sync_s3_files_mapped_args(
+            ids=ids,
             tags=tags,
-            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            file_sync_config=file_sync_config,
         )
-        return self._sync_outlook_oapg(
+        return self._sync_s3_files_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_outlook_sync/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_s3_files/post.pyi`

 * *Files 10% similar despite different names*

```diff
@@ -28,35 +28,41 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
-from carbon.model.outlook_sync_input import OutlookSyncInput as OutlookSyncInputSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
+from carbon.model.s3_file_sync_input import S3FileSyncInput as S3FileSyncInputSchema
 from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
+from carbon.model.s3_get_file_input import S3GetFileInput as S3GetFileInputSchema
 from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullableSchema
 
 from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.outlook_sync_input import OutlookSyncInput
+from carbon.type.file_sync_config_nullable import FileSyncConfigNullable
+from carbon.type.s3_file_sync_input import S3FileSyncInput
 from carbon.type.generic_success_response import GenericSuccessResponse
+from carbon.type.s3_get_file_input import S3GetFileInput
 
 from ...api_client import Dictionary
-from carbon.pydantic.outlook_sync_input import OutlookSyncInput as OutlookSyncInputPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
+from carbon.pydantic.s3_file_sync_input import S3FileSyncInput as S3FileSyncInputPydantic
 from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
 from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
+from carbon.pydantic.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullablePydantic
+from carbon.pydantic.s3_get_file_input import S3GetFileInput as S3GetFileInputPydantic
 
 # body param
-SchemaForRequestBodyApplicationJson = OutlookSyncInputSchema
+SchemaForRequestBodyApplicationJson = S3FileSyncInputSchema
 
 
-request_body_outlook_sync_input = api_client.RequestBody(
+request_body_s3_file_sync_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
 SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
@@ -104,68 +110,83 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _sync_outlook_mapped_args(
+    def _sync_s3_files_mapped_args(
         self,
-        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        ids: typing.List[S3GetFileInput],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
-        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if tags is not None:
             _body["tags"] = tags
-        if folder is not None:
-            _body["folder"] = folder
-        if filters is not None:
-            _body["filters"] = filters
+        if ids is not None:
+            _body["ids"] = ids
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
             _body["skip_embedding_generation"] = skip_embedding_generation
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
+        if max_items_per_chunk is not None:
+            _body["max_items_per_chunk"] = max_items_per_chunk
+        if set_page_as_boundary is not None:
+            _body["set_page_as_boundary"] = set_page_as_boundary
         if data_source_id is not None:
             _body["data_source_id"] = data_source_id
+        if request_id is not None:
+            _body["request_id"] = request_id
+        if use_ocr is not None:
+            _body["use_ocr"] = use_ocr
+        if parse_pdf_tables_with_ocr is not None:
+            _body["parse_pdf_tables_with_ocr"] = parse_pdf_tables_with_ocr
+        if file_sync_config is not None:
+            _body["file_sync_config"] = file_sync_config
         args.body = _body
         return args
 
-    async def _async_outlook_oapg(
+    async def _async_s3_files_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Outlook Sync
+        S3 Files
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -181,20 +202,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/outlook/sync',
+            path_template='/integrations/s3/files',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_outlook_sync_input.serialize(body, content_type)
+        serialized_data = request_body_s3_file_sync_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -258,28 +279,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _sync_outlook_oapg(
+    def _sync_s3_files_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Outlook Sync
+        S3 Files
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -295,20 +316,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/outlook/sync',
+            path_template='/integrations/s3/files',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_outlook_sync_input.serialize(body, content_type)
+        serialized_data = request_body_s3_file_sync_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -341,213 +362,273 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class SyncOutlookRaw(BaseApi):
+class SyncS3FilesRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def async_outlook(
+    async def async_s3_files(
         self,
-        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        ids: typing.List[S3GetFileInput],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
-        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_outlook_mapped_args(
-            filters=filters,
+        args = self._sync_s3_files_mapped_args(
+            ids=ids,
             tags=tags,
-            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            file_sync_config=file_sync_config,
         )
-        return await self._async_outlook_oapg(
+        return await self._async_s3_files_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def sync_outlook(
+    def sync_s3_files(
         self,
-        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        ids: typing.List[S3GetFileInput],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
-        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_outlook_mapped_args(
-            filters=filters,
+        args = self._sync_s3_files_mapped_args(
+            ids=ids,
             tags=tags,
-            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            file_sync_config=file_sync_config,
         )
-        return self._sync_outlook_oapg(
+        return self._sync_s3_files_oapg(
             body=args.body,
         )
 
-class SyncOutlook(BaseApi):
+class SyncS3Files(BaseApi):
 
-    async def async_outlook(
+    async def async_s3_files(
         self,
-        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        ids: typing.List[S3GetFileInput],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
-        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         validate: bool = False,
         **kwargs,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = await self.raw.async_outlook(
-            filters=filters,
+        raw_response = await self.raw.async_s3_files(
+            ids=ids,
             tags=tags,
-            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            file_sync_config=file_sync_config,
             **kwargs,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
-    def sync_outlook(
+    def sync_s3_files(
         self,
-        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        ids: typing.List[S3GetFileInput],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
-        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         validate: bool = False,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = self.raw.sync_outlook(
-            filters=filters,
+        raw_response = self.raw.sync_s3_files(
+            ids=ids,
             tags=tags,
-            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            file_sync_config=file_sync_config,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        ids: typing.List[S3GetFileInput],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
-        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_outlook_mapped_args(
-            filters=filters,
+        args = self._sync_s3_files_mapped_args(
+            ids=ids,
             tags=tags,
-            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            file_sync_config=file_sync_config,
         )
-        return await self._async_outlook_oapg(
+        return await self._async_s3_files_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
+        ids: typing.List[S3GetFileInput],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
-        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_outlook_mapped_args(
-            filters=filters,
+        args = self._sync_s3_files_mapped_args(
+            ids=ids,
             tags=tags,
-            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            file_sync_config=file_sync_config,
         )
-        return self._sync_outlook_oapg(
+        return self._sync_s3_files_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_outlook_user_categories/get.py` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_outlook_user_categories/get.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_outlook_user_categories/get.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_outlook_user_categories/get.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_outlook_user_folders/get.py` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_outlook_user_folders/get.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_outlook_user_folders/get.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_outlook_user_folders/get.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_rss_feed/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/upload_file_from_url/post.pyi`

 * *Files 10% similar despite different names*

```diff
@@ -29,58 +29,51 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.rss_feed_input import RSSFeedInput as RSSFeedInputSchema
+from carbon.model.upload_file_from_url_input import UploadFileFromUrlInput as UploadFileFromUrlInputSchema
+from carbon.model.user_file import UserFile as UserFileSchema
 from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
-from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
 
 from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.generic_success_response import GenericSuccessResponse
-from carbon.type.rss_feed_input import RSSFeedInput
+from carbon.type.upload_file_from_url_input import UploadFileFromUrlInput
+from carbon.type.user_file import UserFile
 
 from ...api_client import Dictionary
+from carbon.pydantic.user_file import UserFile as UserFilePydantic
+from carbon.pydantic.upload_file_from_url_input import UploadFileFromUrlInput as UploadFileFromUrlInputPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
-from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
 from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
-from carbon.pydantic.rss_feed_input import RSSFeedInput as RSSFeedInputPydantic
-
-from . import path
 
 # body param
-SchemaForRequestBodyApplicationJson = RSSFeedInputSchema
+SchemaForRequestBodyApplicationJson = UploadFileFromUrlInputSchema
 
 
-request_body_rss_feed_input = api_client.RequestBody(
+request_body_upload_file_from_url_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
-_auth = [
-    'accessToken',
-    'apiKey',
-    'customerId',
-]
-SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
+SchemaFor200ResponseBodyApplicationJson = UserFileSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
-    body: GenericSuccessResponse
+    body: UserFile
 
 
 @dataclass
 class ApiResponseFor200Async(api_client.AsyncApiResponse):
-    body: GenericSuccessResponse
+    body: UserFile
 
 
 _response_for_200 = api_client.OpenApiResponse(
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
@@ -104,73 +97,84 @@
     response_cls=ApiResponseFor422,
     response_cls_async=ApiResponseFor422Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor422ResponseBodyApplicationJson),
     },
 )
-_status_code_to_response = {
-    '200': _response_for_200,
-    '422': _response_for_422,
-}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _sync_rss_feed_mapped_args(
+    def _upload_from_url_mapped_args(
         self,
         url: str,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        file_name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        generate_sparse_vectors: typing.Optional[bool] = None,
+        use_textract: typing.Optional[bool] = None,
+        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
-        if tags is not None:
-            _body["tags"] = tags
         if url is not None:
             _body["url"] = url
+        if file_name is not None:
+            _body["file_name"] = file_name
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
             _body["skip_embedding_generation"] = skip_embedding_generation
+        if set_page_as_boundary is not None:
+            _body["set_page_as_boundary"] = set_page_as_boundary
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
+        if use_textract is not None:
+            _body["use_textract"] = use_textract
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
+        if max_items_per_chunk is not None:
+            _body["max_items_per_chunk"] = max_items_per_chunk
+        if parse_pdf_tables_with_ocr is not None:
+            _body["parse_pdf_tables_with_ocr"] = parse_pdf_tables_with_ocr
+        if detect_audio_language is not None:
+            _body["detect_audio_language"] = detect_audio_language
         args.body = _body
         return args
 
-    async def _async_rss_feed_oapg(
+    async def _aupload_from_url_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Rss Feed
+        Create Upload File From Url
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -186,20 +190,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/rss_feed',
+            path_template='/upload_file_from_url',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_rss_feed_input.serialize(body, content_type)
+        serialized_data = request_body_upload_file_from_url_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -263,28 +267,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _sync_rss_feed_oapg(
+    def _upload_from_url_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Rss Feed
+        Create Upload File From Url
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -300,20 +304,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/rss_feed',
+            path_template='/upload_file_from_url',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_rss_feed_input.serialize(body, content_type)
+        serialized_data = request_body_upload_file_from_url_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -346,189 +350,249 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class SyncRssFeedRaw(BaseApi):
+class UploadFromUrlRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def async_rss_feed(
+    async def aupload_from_url(
         self,
         url: str,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        file_name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        generate_sparse_vectors: typing.Optional[bool] = None,
+        use_textract: typing.Optional[bool] = None,
+        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_rss_feed_mapped_args(
+        args = self._upload_from_url_mapped_args(
             url=url,
-            tags=tags,
+            file_name=file_name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
+            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
         )
-        return await self._async_rss_feed_oapg(
+        return await self._aupload_from_url_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def sync_rss_feed(
+    def upload_from_url(
         self,
         url: str,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        file_name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        generate_sparse_vectors: typing.Optional[bool] = None,
+        use_textract: typing.Optional[bool] = None,
+        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_rss_feed_mapped_args(
+        args = self._upload_from_url_mapped_args(
             url=url,
-            tags=tags,
+            file_name=file_name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
+            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
         )
-        return self._sync_rss_feed_oapg(
+        return self._upload_from_url_oapg(
             body=args.body,
         )
 
-class SyncRssFeed(BaseApi):
+class UploadFromUrl(BaseApi):
 
-    async def async_rss_feed(
+    async def aupload_from_url(
         self,
         url: str,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        file_name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        generate_sparse_vectors: typing.Optional[bool] = None,
+        use_textract: typing.Optional[bool] = None,
+        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
         validate: bool = False,
         **kwargs,
-    ) -> GenericSuccessResponsePydantic:
-        raw_response = await self.raw.async_rss_feed(
+    ) -> UserFilePydantic:
+        raw_response = await self.raw.aupload_from_url(
             url=url,
-            tags=tags,
+            file_name=file_name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
+            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
             **kwargs,
         )
         if validate:
-            return GenericSuccessResponsePydantic(**raw_response.body)
-        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
+            return UserFilePydantic(**raw_response.body)
+        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
     
     
-    def sync_rss_feed(
+    def upload_from_url(
         self,
         url: str,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        file_name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        generate_sparse_vectors: typing.Optional[bool] = None,
+        use_textract: typing.Optional[bool] = None,
+        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
         validate: bool = False,
-    ) -> GenericSuccessResponsePydantic:
-        raw_response = self.raw.sync_rss_feed(
+    ) -> UserFilePydantic:
+        raw_response = self.raw.upload_from_url(
             url=url,
-            tags=tags,
+            file_name=file_name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
+            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
         )
         if validate:
-            return GenericSuccessResponsePydantic(**raw_response.body)
-        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
+            return UserFilePydantic(**raw_response.body)
+        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
         url: str,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        file_name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        generate_sparse_vectors: typing.Optional[bool] = None,
+        use_textract: typing.Optional[bool] = None,
+        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_rss_feed_mapped_args(
+        args = self._upload_from_url_mapped_args(
             url=url,
-            tags=tags,
+            file_name=file_name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
+            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
         )
-        return await self._async_rss_feed_oapg(
+        return await self._aupload_from_url_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
         url: str,
-        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        file_name: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        skip_embedding_generation: typing.Optional[bool] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
-        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        generate_sparse_vectors: typing.Optional[bool] = None,
+        use_textract: typing.Optional[bool] = None,
+        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_rss_feed_mapped_args(
+        args = self._upload_from_url_mapped_args(
             url=url,
-            tags=tags,
+            file_name=file_name,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
+            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
+            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
         )
-        return self._sync_rss_feed_oapg(
+        return self._upload_from_url_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_rss_feed/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_files_sync/post.py`

 * *Files 18% similar despite different names*

```diff
@@ -29,40 +29,53 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.rss_feed_input import RSSFeedInput as RSSFeedInputSchema
-from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
+from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullableSchema
+from carbon.model.sync_files_request import SyncFilesRequest as SyncFilesRequestSchema
+from carbon.model.sync_files_ids import SyncFilesIds as SyncFilesIdsSchema
 from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullableSchema
 
-from carbon.type.embedding_generators import EmbeddingGenerators
+from carbon.type.sync_files_request import SyncFilesRequest
 from carbon.type.http_validation_error import HTTPValidationError
+from carbon.type.file_sync_config_nullable import FileSyncConfigNullable
 from carbon.type.generic_success_response import GenericSuccessResponse
-from carbon.type.rss_feed_input import RSSFeedInput
+from carbon.type.sync_files_ids import SyncFilesIds
+from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
 
 from ...api_client import Dictionary
+from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullablePydantic
+from carbon.pydantic.sync_files_request import SyncFilesRequest as SyncFilesRequestPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
-from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
-from carbon.pydantic.rss_feed_input import RSSFeedInput as RSSFeedInputPydantic
+from carbon.pydantic.sync_files_ids import SyncFilesIds as SyncFilesIdsPydantic
+from carbon.pydantic.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullablePydantic
+
+from . import path
 
 # body param
-SchemaForRequestBodyApplicationJson = RSSFeedInputSchema
+SchemaForRequestBodyApplicationJson = SyncFilesRequestSchema
 
 
-request_body_rss_feed_input = api_client.RequestBody(
+request_body_sync_files_request = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
+_auth = [
+    'accessToken',
+    'apiKey',
+    'customerId',
+]
 SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
     body: GenericSuccessResponse
 
@@ -97,69 +110,97 @@
     response_cls=ApiResponseFor422,
     response_cls_async=ApiResponseFor422Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor422ResponseBodyApplicationJson),
     },
 )
+_status_code_to_response = {
+    '200': _response_for_200,
+    '422': _response_for_422,
+}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _sync_rss_feed_mapped_args(
+    def _sync_files_mapped_args(
         self,
-        url: str,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if tags is not None:
             _body["tags"] = tags
-        if url is not None:
-            _body["url"] = url
+        if data_source_id is not None:
+            _body["data_source_id"] = data_source_id
+        if ids is not None:
+            _body["ids"] = ids
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
             _body["skip_embedding_generation"] = skip_embedding_generation
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
+        if max_items_per_chunk is not None:
+            _body["max_items_per_chunk"] = max_items_per_chunk
+        if set_page_as_boundary is not None:
+            _body["set_page_as_boundary"] = set_page_as_boundary
+        if request_id is not None:
+            _body["request_id"] = request_id
+        if use_ocr is not None:
+            _body["use_ocr"] = use_ocr
+        if parse_pdf_tables_with_ocr is not None:
+            _body["parse_pdf_tables_with_ocr"] = parse_pdf_tables_with_ocr
+        if incremental_sync is not None:
+            _body["incremental_sync"] = incremental_sync
+        if file_sync_config is not None:
+            _body["file_sync_config"] = file_sync_config
         args.body = _body
         return args
 
-    async def _async_rss_feed_oapg(
+    async def _async_files_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Rss Feed
+        Sync Files
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -175,20 +216,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/rss_feed',
+            path_template='/integrations/files/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_rss_feed_input.serialize(body, content_type)
+        serialized_data = request_body_sync_files_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -252,28 +293,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _sync_rss_feed_oapg(
+    def _sync_files_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Rss Feed
+        Sync Files
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -289,20 +330,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/rss_feed',
+            path_template='/integrations/files/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_rss_feed_input.serialize(body, content_type)
+        serialized_data = request_body_sync_files_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -335,189 +376,285 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class SyncRssFeedRaw(BaseApi):
+class SyncFilesRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def async_rss_feed(
+    async def async_files(
         self,
-        url: str,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_rss_feed_mapped_args(
-            url=url,
+        args = self._sync_files_mapped_args(
+            data_source_id=data_source_id,
+            ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
-        return await self._async_rss_feed_oapg(
+        return await self._async_files_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def sync_rss_feed(
+    def sync_files(
         self,
-        url: str,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_rss_feed_mapped_args(
-            url=url,
+        args = self._sync_files_mapped_args(
+            data_source_id=data_source_id,
+            ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
-        return self._sync_rss_feed_oapg(
+        return self._sync_files_oapg(
             body=args.body,
         )
 
-class SyncRssFeed(BaseApi):
+class SyncFiles(BaseApi):
 
-    async def async_rss_feed(
+    async def async_files(
         self,
-        url: str,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         validate: bool = False,
         **kwargs,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = await self.raw.async_rss_feed(
-            url=url,
+        raw_response = await self.raw.async_files(
+            data_source_id=data_source_id,
+            ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
             **kwargs,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
-    def sync_rss_feed(
+    def sync_files(
         self,
-        url: str,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         validate: bool = False,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = self.raw.sync_rss_feed(
-            url=url,
+        raw_response = self.raw.sync_files(
+            data_source_id=data_source_id,
+            ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        url: str,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_rss_feed_mapped_args(
-            url=url,
+        args = self._sync_files_mapped_args(
+            data_source_id=data_source_id,
+            ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
-        return await self._async_rss_feed_oapg(
+        return await self._async_files_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        url: str,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
+        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_rss_feed_mapped_args(
-            url=url,
+        args = self._sync_files_mapped_args(
+            data_source_id=data_source_id,
+            ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
+            max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
-        return self._sync_rss_feed_oapg(
+        return self._sync_files_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_s3/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_s3/post.pyi`

 * *Files 8% similar despite different names*

```diff
@@ -41,32 +41,25 @@
 from carbon.type.organization_user_data_source_api import OrganizationUserDataSourceAPI
 
 from ...api_client import Dictionary
 from carbon.pydantic.s3_auth_request import S3AuthRequest as S3AuthRequestPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.organization_user_data_source_api import OrganizationUserDataSourceAPI as OrganizationUserDataSourceAPIPydantic
 
-from . import path
-
 # body param
 SchemaForRequestBodyApplicationJson = S3AuthRequestSchema
 
 
 request_body_s3_auth_request = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
-_auth = [
-    'accessToken',
-    'apiKey',
-    'customerId',
-]
 SchemaFor200ResponseBodyApplicationJson = OrganizationUserDataSourceAPISchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
     body: OrganizationUserDataSourceAPI
 
@@ -101,36 +94,35 @@
     response_cls=ApiResponseFor422,
     response_cls_async=ApiResponseFor422Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor422ResponseBodyApplicationJson),
     },
 )
-_status_code_to_response = {
-    '200': _response_for_200,
-    '422': _response_for_422,
-}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
     def _create_aws_iam_user_mapped_args(
         self,
         access_key: str,
         access_key_secret: str,
+        sync_source_items: typing.Optional[bool] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if access_key is not None:
             _body["access_key"] = access_key
         if access_key_secret is not None:
             _body["access_key_secret"] = access_key_secret
+        if sync_source_items is not None:
+            _body["sync_source_items"] = sync_source_items
         args.body = _body
         return args
 
     async def _acreate_aws_iam_user_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
@@ -332,110 +324,122 @@
 class CreateAwsIamUserRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
     async def acreate_aws_iam_user(
         self,
         access_key: str,
         access_key_secret: str,
+        sync_source_items: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         args = self._create_aws_iam_user_mapped_args(
             access_key=access_key,
             access_key_secret=access_key_secret,
+            sync_source_items=sync_source_items,
         )
         return await self._acreate_aws_iam_user_oapg(
             body=args.body,
             **kwargs,
         )
     
     def create_aws_iam_user(
         self,
         access_key: str,
         access_key_secret: str,
+        sync_source_items: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._create_aws_iam_user_mapped_args(
             access_key=access_key,
             access_key_secret=access_key_secret,
+            sync_source_items=sync_source_items,
         )
         return self._create_aws_iam_user_oapg(
             body=args.body,
         )
 
 class CreateAwsIamUser(BaseApi):
 
     async def acreate_aws_iam_user(
         self,
         access_key: str,
         access_key_secret: str,
+        sync_source_items: typing.Optional[bool] = None,
         validate: bool = False,
         **kwargs,
     ) -> OrganizationUserDataSourceAPIPydantic:
         raw_response = await self.raw.acreate_aws_iam_user(
             access_key=access_key,
             access_key_secret=access_key_secret,
+            sync_source_items=sync_source_items,
             **kwargs,
         )
         if validate:
             return OrganizationUserDataSourceAPIPydantic(**raw_response.body)
         return api_client.construct_model_instance(OrganizationUserDataSourceAPIPydantic, raw_response.body)
     
     
     def create_aws_iam_user(
         self,
         access_key: str,
         access_key_secret: str,
+        sync_source_items: typing.Optional[bool] = None,
         validate: bool = False,
     ) -> OrganizationUserDataSourceAPIPydantic:
         raw_response = self.raw.create_aws_iam_user(
             access_key=access_key,
             access_key_secret=access_key_secret,
+            sync_source_items=sync_source_items,
         )
         if validate:
             return OrganizationUserDataSourceAPIPydantic(**raw_response.body)
         return api_client.construct_model_instance(OrganizationUserDataSourceAPIPydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
         access_key: str,
         access_key_secret: str,
+        sync_source_items: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         args = self._create_aws_iam_user_mapped_args(
             access_key=access_key,
             access_key_secret=access_key_secret,
+            sync_source_items=sync_source_items,
         )
         return await self._acreate_aws_iam_user_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
         access_key: str,
         access_key_secret: str,
+        sync_source_items: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._create_aws_iam_user_mapped_args(
             access_key=access_key,
             access_key_secret=access_key_secret,
+            sync_source_items=sync_source_items,
         )
         return self._create_aws_iam_user_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_s3/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_s3/post.py`

 * *Files 6% similar despite different names*

```diff
@@ -41,25 +41,32 @@
 from carbon.type.organization_user_data_source_api import OrganizationUserDataSourceAPI
 
 from ...api_client import Dictionary
 from carbon.pydantic.s3_auth_request import S3AuthRequest as S3AuthRequestPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.organization_user_data_source_api import OrganizationUserDataSourceAPI as OrganizationUserDataSourceAPIPydantic
 
+from . import path
+
 # body param
 SchemaForRequestBodyApplicationJson = S3AuthRequestSchema
 
 
 request_body_s3_auth_request = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
+_auth = [
+    'accessToken',
+    'apiKey',
+    'customerId',
+]
 SchemaFor200ResponseBodyApplicationJson = OrganizationUserDataSourceAPISchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
     body: OrganizationUserDataSourceAPI
 
@@ -94,32 +101,39 @@
     response_cls=ApiResponseFor422,
     response_cls_async=ApiResponseFor422Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor422ResponseBodyApplicationJson),
     },
 )
+_status_code_to_response = {
+    '200': _response_for_200,
+    '422': _response_for_422,
+}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
     def _create_aws_iam_user_mapped_args(
         self,
         access_key: str,
         access_key_secret: str,
+        sync_source_items: typing.Optional[bool] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if access_key is not None:
             _body["access_key"] = access_key
         if access_key_secret is not None:
             _body["access_key_secret"] = access_key_secret
+        if sync_source_items is not None:
+            _body["sync_source_items"] = sync_source_items
         args.body = _body
         return args
 
     async def _acreate_aws_iam_user_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
@@ -321,110 +335,122 @@
 class CreateAwsIamUserRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
     async def acreate_aws_iam_user(
         self,
         access_key: str,
         access_key_secret: str,
+        sync_source_items: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         args = self._create_aws_iam_user_mapped_args(
             access_key=access_key,
             access_key_secret=access_key_secret,
+            sync_source_items=sync_source_items,
         )
         return await self._acreate_aws_iam_user_oapg(
             body=args.body,
             **kwargs,
         )
     
     def create_aws_iam_user(
         self,
         access_key: str,
         access_key_secret: str,
+        sync_source_items: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._create_aws_iam_user_mapped_args(
             access_key=access_key,
             access_key_secret=access_key_secret,
+            sync_source_items=sync_source_items,
         )
         return self._create_aws_iam_user_oapg(
             body=args.body,
         )
 
 class CreateAwsIamUser(BaseApi):
 
     async def acreate_aws_iam_user(
         self,
         access_key: str,
         access_key_secret: str,
+        sync_source_items: typing.Optional[bool] = None,
         validate: bool = False,
         **kwargs,
     ) -> OrganizationUserDataSourceAPIPydantic:
         raw_response = await self.raw.acreate_aws_iam_user(
             access_key=access_key,
             access_key_secret=access_key_secret,
+            sync_source_items=sync_source_items,
             **kwargs,
         )
         if validate:
             return OrganizationUserDataSourceAPIPydantic(**raw_response.body)
         return api_client.construct_model_instance(OrganizationUserDataSourceAPIPydantic, raw_response.body)
     
     
     def create_aws_iam_user(
         self,
         access_key: str,
         access_key_secret: str,
+        sync_source_items: typing.Optional[bool] = None,
         validate: bool = False,
     ) -> OrganizationUserDataSourceAPIPydantic:
         raw_response = self.raw.create_aws_iam_user(
             access_key=access_key,
             access_key_secret=access_key_secret,
+            sync_source_items=sync_source_items,
         )
         if validate:
             return OrganizationUserDataSourceAPIPydantic(**raw_response.body)
         return api_client.construct_model_instance(OrganizationUserDataSourceAPIPydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
         access_key: str,
         access_key_secret: str,
+        sync_source_items: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         args = self._create_aws_iam_user_mapped_args(
             access_key=access_key,
             access_key_secret=access_key_secret,
+            sync_source_items=sync_source_items,
         )
         return await self._acreate_aws_iam_user_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
         access_key: str,
         access_key_secret: str,
+        sync_source_items: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._create_aws_iam_user_mapped_args(
             access_key=access_key,
             access_key_secret=access_key_secret,
+            sync_source_items=sync_source_items,
         )
         return self._create_aws_iam_user_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_s3_files/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_outlook_sync/post.py`

 * *Files 11% similar despite different names*

```diff
@@ -28,40 +28,40 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
+from carbon.model.outlook_sync_input import OutlookSyncInput as OutlookSyncInputSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.s3_file_sync_input import S3FileSyncInput as S3FileSyncInputSchema
 from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
-from carbon.model.s3_get_file_input import S3GetFileInput as S3GetFileInputSchema
 from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullableSchema
 
 from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.s3_file_sync_input import S3FileSyncInput
+from carbon.type.file_sync_config_nullable import FileSyncConfigNullable
+from carbon.type.outlook_sync_input import OutlookSyncInput
 from carbon.type.generic_success_response import GenericSuccessResponse
-from carbon.type.s3_get_file_input import S3GetFileInput
 
 from ...api_client import Dictionary
+from carbon.pydantic.outlook_sync_input import OutlookSyncInput as OutlookSyncInputPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
-from carbon.pydantic.s3_file_sync_input import S3FileSyncInput as S3FileSyncInputPydantic
 from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
 from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
-from carbon.pydantic.s3_get_file_input import S3GetFileInput as S3GetFileInputPydantic
+from carbon.pydantic.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullablePydantic
 
 from . import path
 
 # body param
-SchemaForRequestBodyApplicationJson = S3FileSyncInputSchema
+SchemaForRequestBodyApplicationJson = OutlookSyncInputSchema
 
 
-request_body_s3_file_sync_input = api_client.RequestBody(
+request_body_outlook_sync_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
 _auth = [
@@ -118,71 +118,80 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _sync_s3_files_mapped_args(
+    def _sync_outlook_mapped_args(
         self,
-        ids: typing.List[S3GetFileInput],
+        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if tags is not None:
             _body["tags"] = tags
-        if ids is not None:
-            _body["ids"] = ids
+        if folder is not None:
+            _body["folder"] = folder
+        if filters is not None:
+            _body["filters"] = filters
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
             _body["skip_embedding_generation"] = skip_embedding_generation
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
-        if max_items_per_chunk is not None:
-            _body["max_items_per_chunk"] = max_items_per_chunk
-        if set_page_as_boundary is not None:
-            _body["set_page_as_boundary"] = set_page_as_boundary
         if data_source_id is not None:
             _body["data_source_id"] = data_source_id
+        if request_id is not None:
+            _body["request_id"] = request_id
+        if sync_attachments is not None:
+            _body["sync_attachments"] = sync_attachments
+        if file_sync_config is not None:
+            _body["file_sync_config"] = file_sync_config
+        if incremental_sync is not None:
+            _body["incremental_sync"] = incremental_sync
         args.body = _body
         return args
 
-    async def _async_s3_files_oapg(
+    async def _async_outlook_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        S3 Files
+        Outlook Sync
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -198,20 +207,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/s3/files',
+            path_template='/integrations/outlook/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_s3_file_sync_input.serialize(body, content_type)
+        serialized_data = request_body_outlook_sync_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -275,28 +284,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _sync_s3_files_oapg(
+    def _sync_outlook_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        S3 Files
+        Outlook Sync
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -312,20 +321,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/s3/files',
+            path_template='/integrations/outlook/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_s3_file_sync_input.serialize(body, content_type)
+        serialized_data = request_body_outlook_sync_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -358,225 +367,261 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class SyncS3FilesRaw(BaseApi):
+class SyncOutlookRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def async_s3_files(
+    async def async_outlook(
         self,
-        ids: typing.List[S3GetFileInput],
+        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_s3_files_mapped_args(
-            ids=ids,
+        args = self._sync_outlook_mapped_args(
+            filters=filters,
             tags=tags,
+            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
-        return await self._async_s3_files_oapg(
+        return await self._async_outlook_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def sync_s3_files(
+    def sync_outlook(
         self,
-        ids: typing.List[S3GetFileInput],
+        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_s3_files_mapped_args(
-            ids=ids,
+        args = self._sync_outlook_mapped_args(
+            filters=filters,
             tags=tags,
+            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
-        return self._sync_s3_files_oapg(
+        return self._sync_outlook_oapg(
             body=args.body,
         )
 
-class SyncS3Files(BaseApi):
+class SyncOutlook(BaseApi):
 
-    async def async_s3_files(
+    async def async_outlook(
         self,
-        ids: typing.List[S3GetFileInput],
+        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
         validate: bool = False,
         **kwargs,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = await self.raw.async_s3_files(
-            ids=ids,
+        raw_response = await self.raw.async_outlook(
+            filters=filters,
             tags=tags,
+            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
             **kwargs,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
-    def sync_s3_files(
+    def sync_outlook(
         self,
-        ids: typing.List[S3GetFileInput],
+        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
         validate: bool = False,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = self.raw.sync_s3_files(
-            ids=ids,
+        raw_response = self.raw.sync_outlook(
+            filters=filters,
             tags=tags,
+            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        ids: typing.List[S3GetFileInput],
+        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_s3_files_mapped_args(
-            ids=ids,
+        args = self._sync_outlook_mapped_args(
+            filters=filters,
             tags=tags,
+            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
-        return await self._async_s3_files_oapg(
+        return await self._async_outlook_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        ids: typing.List[S3GetFileInput],
+        filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
+        folder: typing.Optional[typing.Optional[str]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
         embedding_model: typing.Optional[EmbeddingGenerators] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
-        max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
         data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[typing.Optional[str]] = None,
+        sync_attachments: typing.Optional[typing.Optional[bool]] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
+        incremental_sync: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_s3_files_mapped_args(
-            ids=ids,
+        args = self._sync_outlook_mapped_args(
+            filters=filters,
             tags=tags,
+            folder=folder,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
-            max_items_per_chunk=max_items_per_chunk,
-            set_page_as_boundary=set_page_as_boundary,
             data_source_id=data_source_id,
+            request_id=request_id,
+            sync_attachments=sync_attachments,
+            file_sync_config=file_sync_config,
+            incremental_sync=incremental_sync,
         )
-        return self._sync_s3_files_oapg(
+        return self._sync_outlook_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/integrations_s3_files/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_files_sync/post.pyi`

 * *Files 12% similar despite different names*

```diff
@@ -29,37 +29,40 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.s3_file_sync_input import S3FileSyncInput as S3FileSyncInputSchema
-from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
-from carbon.model.s3_get_file_input import S3GetFileInput as S3GetFileInputSchema
+from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullableSchema
+from carbon.model.sync_files_request import SyncFilesRequest as SyncFilesRequestSchema
+from carbon.model.sync_files_ids import SyncFilesIds as SyncFilesIdsSchema
 from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullableSchema
 
-from carbon.type.embedding_generators import EmbeddingGenerators
+from carbon.type.sync_files_request import SyncFilesRequest
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.s3_file_sync_input import S3FileSyncInput
+from carbon.type.file_sync_config_nullable import FileSyncConfigNullable
 from carbon.type.generic_success_response import GenericSuccessResponse
-from carbon.type.s3_get_file_input import S3GetFileInput
+from carbon.type.sync_files_ids import SyncFilesIds
+from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
 
 from ...api_client import Dictionary
+from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullablePydantic
+from carbon.pydantic.sync_files_request import SyncFilesRequest as SyncFilesRequestPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
-from carbon.pydantic.s3_file_sync_input import S3FileSyncInput as S3FileSyncInputPydantic
 from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
-from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
-from carbon.pydantic.s3_get_file_input import S3GetFileInput as S3GetFileInputPydantic
+from carbon.pydantic.sync_files_ids import SyncFilesIds as SyncFilesIdsPydantic
+from carbon.pydantic.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullablePydantic
 
 # body param
-SchemaForRequestBodyApplicationJson = S3FileSyncInputSchema
+SchemaForRequestBodyApplicationJson = SyncFilesRequestSchema
 
 
-request_body_s3_file_sync_input = api_client.RequestBody(
+request_body_sync_files_request = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
 SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
@@ -107,32 +110,39 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _sync_s3_files_mapped_args(
+    def _sync_files_mapped_args(
         self,
-        ids: typing.List[S3GetFileInput],
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
-        data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if tags is not None:
             _body["tags"] = tags
+        if data_source_id is not None:
+            _body["data_source_id"] = data_source_id
         if ids is not None:
             _body["ids"] = ids
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
@@ -143,35 +153,43 @@
             _body["generate_sparse_vectors"] = generate_sparse_vectors
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
         if max_items_per_chunk is not None:
             _body["max_items_per_chunk"] = max_items_per_chunk
         if set_page_as_boundary is not None:
             _body["set_page_as_boundary"] = set_page_as_boundary
-        if data_source_id is not None:
-            _body["data_source_id"] = data_source_id
+        if request_id is not None:
+            _body["request_id"] = request_id
+        if use_ocr is not None:
+            _body["use_ocr"] = use_ocr
+        if parse_pdf_tables_with_ocr is not None:
+            _body["parse_pdf_tables_with_ocr"] = parse_pdf_tables_with_ocr
+        if incremental_sync is not None:
+            _body["incremental_sync"] = incremental_sync
+        if file_sync_config is not None:
+            _body["file_sync_config"] = file_sync_config
         args.body = _body
         return args
 
-    async def _async_s3_files_oapg(
+    async def _async_files_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        S3 Files
+        Sync Files
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -187,20 +205,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/s3/files',
+            path_template='/integrations/files/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_s3_file_sync_input.serialize(body, content_type)
+        serialized_data = request_body_sync_files_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -264,28 +282,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _sync_s3_files_oapg(
+    def _sync_files_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        S3 Files
+        Sync Files
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -301,20 +319,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/integrations/s3/files',
+            path_template='/integrations/files/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_s3_file_sync_input.serialize(body, content_type)
+        serialized_data = request_body_sync_files_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -347,225 +365,285 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class SyncS3FilesRaw(BaseApi):
+class SyncFilesRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def async_s3_files(
+    async def async_files(
         self,
-        ids: typing.List[S3GetFileInput],
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
-        data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_s3_files_mapped_args(
+        args = self._sync_files_mapped_args(
+            data_source_id=data_source_id,
             ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
             set_page_as_boundary=set_page_as_boundary,
-            data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
-        return await self._async_s3_files_oapg(
+        return await self._async_files_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def sync_s3_files(
+    def sync_files(
         self,
-        ids: typing.List[S3GetFileInput],
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
-        data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_s3_files_mapped_args(
+        args = self._sync_files_mapped_args(
+            data_source_id=data_source_id,
             ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
             set_page_as_boundary=set_page_as_boundary,
-            data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
-        return self._sync_s3_files_oapg(
+        return self._sync_files_oapg(
             body=args.body,
         )
 
-class SyncS3Files(BaseApi):
+class SyncFiles(BaseApi):
 
-    async def async_s3_files(
+    async def async_files(
         self,
-        ids: typing.List[S3GetFileInput],
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
-        data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         validate: bool = False,
         **kwargs,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = await self.raw.async_s3_files(
+        raw_response = await self.raw.async_files(
+            data_source_id=data_source_id,
             ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
             set_page_as_boundary=set_page_as_boundary,
-            data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
             **kwargs,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
-    def sync_s3_files(
+    def sync_files(
         self,
-        ids: typing.List[S3GetFileInput],
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
-        data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         validate: bool = False,
     ) -> GenericSuccessResponsePydantic:
-        raw_response = self.raw.sync_s3_files(
+        raw_response = self.raw.sync_files(
+            data_source_id=data_source_id,
             ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
             set_page_as_boundary=set_page_as_boundary,
-            data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        ids: typing.List[S3GetFileInput],
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
-        data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._sync_s3_files_mapped_args(
+        args = self._sync_files_mapped_args(
+            data_source_id=data_source_id,
             ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
             set_page_as_boundary=set_page_as_boundary,
-            data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
-        return await self._async_s3_files_oapg(
+        return await self._async_files_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        ids: typing.List[S3GetFileInput],
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
         tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
         skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
         generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
         prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
-        data_source_id: typing.Optional[typing.Optional[int]] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._sync_s3_files_mapped_args(
+        args = self._sync_files_mapped_args(
+            data_source_id=data_source_id,
             ids=ids,
             tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
             set_page_as_boundary=set_page_as_boundary,
-            data_source_id=data_source_id,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
-        return self._sync_s3_files_oapg(
+        return self._sync_files_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/modify_user_configuration/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/modify_user_configuration/post.pyi`

 * *Files 2% similar despite different names*

```diff
@@ -41,32 +41,25 @@
 from carbon.type.modify_user_configuration_input import ModifyUserConfigurationInput
 
 from ...api_client import Dictionary
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
 from carbon.pydantic.modify_user_configuration_input import ModifyUserConfigurationInput as ModifyUserConfigurationInputPydantic
 
-from . import path
-
 # body param
 SchemaForRequestBodyApplicationJson = ModifyUserConfigurationInputSchema
 
 
 request_body_modify_user_configuration_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
-_auth = [
-    'accessToken',
-    'apiKey',
-    'customerId',
-]
 SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
     body: GenericSuccessResponse
 
@@ -101,18 +94,14 @@
     response_cls=ApiResponseFor422,
     response_cls_async=ApiResponseFor422Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor422ResponseBodyApplicationJson),
     },
 )
-_status_code_to_response = {
-    '200': _response_for_200,
-    '422': _response_for_422,
-}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
@@ -328,14 +317,15 @@
     
         return api_response
 
 
 class ToggleUserFeaturesRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
+    @api_client.DeprecationWarningOnce(prefix="users")
     async def atoggle_user_features(
         self,
         configuration_key_name: str,
         value: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
@@ -347,14 +337,15 @@
             value=value,
         )
         return await self._atoggle_user_features_oapg(
             body=args.body,
             **kwargs,
         )
     
+    @api_client.DeprecationWarningOnce(prefix="users")
     def toggle_user_features(
         self,
         configuration_key_name: str,
         value: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
@@ -365,14 +356,15 @@
         )
         return self._toggle_user_features_oapg(
             body=args.body,
         )
 
 class ToggleUserFeatures(BaseApi):
 
+    @api_client.DeprecationWarningOnce(prefix="users")
     async def atoggle_user_features(
         self,
         configuration_key_name: str,
         value: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         validate: bool = False,
         **kwargs,
     ) -> GenericSuccessResponsePydantic:
@@ -382,14 +374,15 @@
             **kwargs,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
+    @api_client.DeprecationWarningOnce(prefix="users")
     def toggle_user_features(
         self,
         configuration_key_name: str,
         value: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         validate: bool = False,
     ) -> GenericSuccessResponsePydantic:
         raw_response = self.raw.toggle_user_features(
@@ -400,14 +393,15 @@
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
+    @api_client.DeprecationWarningOnce(prefix="users")
     async def apost(
         self,
         configuration_key_name: str,
         value: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
@@ -419,14 +413,15 @@
             value=value,
         )
         return await self._atoggle_user_features_oapg(
             body=args.body,
             **kwargs,
         )
     
+    @api_client.DeprecationWarningOnce(prefix="users")
     def post(
         self,
         configuration_key_name: str,
         value: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/modify_user_configuration/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/modify_user_configuration/post.py`

 * *Files 6% similar despite different names*

```diff
@@ -41,25 +41,32 @@
 from carbon.type.modify_user_configuration_input import ModifyUserConfigurationInput
 
 from ...api_client import Dictionary
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
 from carbon.pydantic.modify_user_configuration_input import ModifyUserConfigurationInput as ModifyUserConfigurationInputPydantic
 
+from . import path
+
 # body param
 SchemaForRequestBodyApplicationJson = ModifyUserConfigurationInputSchema
 
 
 request_body_modify_user_configuration_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
+_auth = [
+    'accessToken',
+    'apiKey',
+    'customerId',
+]
 SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
     body: GenericSuccessResponse
 
@@ -94,14 +101,18 @@
     response_cls=ApiResponseFor422,
     response_cls_async=ApiResponseFor422Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor422ResponseBodyApplicationJson),
     },
 )
+_status_code_to_response = {
+    '200': _response_for_200,
+    '422': _response_for_422,
+}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
@@ -317,14 +328,15 @@
     
         return api_response
 
 
 class ToggleUserFeaturesRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
+    @api_client.DeprecationWarningOnce(prefix="users")
     async def atoggle_user_features(
         self,
         configuration_key_name: str,
         value: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
@@ -336,14 +348,15 @@
             value=value,
         )
         return await self._atoggle_user_features_oapg(
             body=args.body,
             **kwargs,
         )
     
+    @api_client.DeprecationWarningOnce(prefix="users")
     def toggle_user_features(
         self,
         configuration_key_name: str,
         value: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
@@ -354,14 +367,15 @@
         )
         return self._toggle_user_features_oapg(
             body=args.body,
         )
 
 class ToggleUserFeatures(BaseApi):
 
+    @api_client.DeprecationWarningOnce(prefix="users")
     async def atoggle_user_features(
         self,
         configuration_key_name: str,
         value: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         validate: bool = False,
         **kwargs,
     ) -> GenericSuccessResponsePydantic:
@@ -371,14 +385,15 @@
             **kwargs,
         )
         if validate:
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
+    @api_client.DeprecationWarningOnce(prefix="users")
     def toggle_user_features(
         self,
         configuration_key_name: str,
         value: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         validate: bool = False,
     ) -> GenericSuccessResponsePydantic:
         raw_response = self.raw.toggle_user_features(
@@ -389,14 +404,15 @@
             return GenericSuccessResponsePydantic(**raw_response.body)
         return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
+    @api_client.DeprecationWarningOnce(prefix="users")
     async def apost(
         self,
         configuration_key_name: str,
         value: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
@@ -408,14 +424,15 @@
             value=value,
         )
         return await self._atoggle_user_features_oapg(
             body=args.body,
             **kwargs,
         )
     
+    @api_client.DeprecationWarningOnce(prefix="users")
     def post(
         self,
         configuration_key_name: str,
         value: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]],
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/organization/get.py` & `carbon_python_sdk-0.2.0/carbon/paths/organization/get.pyi`

 * *Files 3% similar despite different names*

```diff
@@ -28,29 +28,21 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
-from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
 from carbon.model.organization_response import OrganizationResponse as OrganizationResponseSchema
 
-from carbon.type.http_validation_error import HTTPValidationError
 from carbon.type.organization_response import OrganizationResponse
 
 from ...api_client import Dictionary
-from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.organization_response import OrganizationResponse as OrganizationResponsePydantic
 
-from . import path
-
-_auth = [
-    'accessToken',
-]
 SchemaFor200ResponseBodyApplicationJson = OrganizationResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
     body: OrganizationResponse
 
@@ -64,39 +56,14 @@
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor200ResponseBodyApplicationJson),
     },
 )
-SchemaFor422ResponseBodyApplicationJson = HTTPValidationErrorSchema
-
-
-@dataclass
-class ApiResponseFor422(api_client.ApiResponse):
-    body: HTTPValidationError
-
-
-@dataclass
-class ApiResponseFor422Async(api_client.AsyncApiResponse):
-    body: HTTPValidationError
-
-
-_response_for_422 = api_client.OpenApiResponse(
-    response_cls=ApiResponseFor422,
-    response_cls_async=ApiResponseFor422Async,
-    content={
-        'application/json': api_client.MediaType(
-            schema=SchemaFor422ResponseBodyApplicationJson),
-    },
-)
-_status_code_to_response = {
-    '200': _response_for_200,
-    '422': _response_for_422,
-}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/organization/get.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/organization/get.py`

 * *Files 4% similar despite different names*

```diff
@@ -28,24 +28,26 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
-from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
 from carbon.model.organization_response import OrganizationResponse as OrganizationResponseSchema
 
-from carbon.type.http_validation_error import HTTPValidationError
 from carbon.type.organization_response import OrganizationResponse
 
 from ...api_client import Dictionary
-from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.organization_response import OrganizationResponse as OrganizationResponsePydantic
 
+from . import path
+
+_auth = [
+    'apiKey',
+]
 SchemaFor200ResponseBodyApplicationJson = OrganizationResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
     body: OrganizationResponse
 
@@ -59,35 +61,17 @@
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor200ResponseBodyApplicationJson),
     },
 )
-SchemaFor422ResponseBodyApplicationJson = HTTPValidationErrorSchema
-
-
-@dataclass
-class ApiResponseFor422(api_client.ApiResponse):
-    body: HTTPValidationError
-
-
-@dataclass
-class ApiResponseFor422Async(api_client.AsyncApiResponse):
-    body: HTTPValidationError
-
-
-_response_for_422 = api_client.OpenApiResponse(
-    response_cls=ApiResponseFor422,
-    response_cls_async=ApiResponseFor422Async,
-    content={
-        'application/json': api_client.MediaType(
-            schema=SchemaFor422ResponseBodyApplicationJson),
-    },
-)
+_status_code_to_response = {
+    '200': _response_for_200,
+}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/parsed_file_file_id/get.py` & `carbon_python_sdk-0.2.0/carbon/paths/parsed_file_file_id/get.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/parsed_file_file_id/get.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/parsed_file_file_id/get.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/process_sitemap/get.py` & `carbon_python_sdk-0.2.0/carbon/paths/process_sitemap/get.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/process_sitemap/get.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/process_sitemap/get.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/raw_file_file_id/get.py` & `carbon_python_sdk-0.2.0/carbon/paths/raw_file_file_id/get.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/raw_file_file_id/get.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/raw_file_file_id/get.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/resync_file/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/resync_file/post.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/resync_file/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/delete_files_v2/post.pyi`

 * *Files 12% similar despite different names*

```diff
@@ -28,49 +28,52 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
-from carbon.model.resync_file_query_input import ResyncFileQueryInput as ResyncFileQueryInputSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.user_file import UserFile as UserFileSchema
+from carbon.model.organization_user_files_to_sync_filters import OrganizationUserFilesToSyncFilters as OrganizationUserFilesToSyncFiltersSchema
+from carbon.model.delete_files_v2_query_input import DeleteFilesV2QueryInput as DeleteFilesV2QueryInputSchema
+from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
 
+from carbon.type.delete_files_v2_query_input import DeleteFilesV2QueryInput
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.resync_file_query_input import ResyncFileQueryInput
-from carbon.type.user_file import UserFile
+from carbon.type.generic_success_response import GenericSuccessResponse
+from carbon.type.organization_user_files_to_sync_filters import OrganizationUserFilesToSyncFilters
 
 from ...api_client import Dictionary
-from carbon.pydantic.user_file import UserFile as UserFilePydantic
-from carbon.pydantic.resync_file_query_input import ResyncFileQueryInput as ResyncFileQueryInputPydantic
+from carbon.pydantic.organization_user_files_to_sync_filters import OrganizationUserFilesToSyncFilters as OrganizationUserFilesToSyncFiltersPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
+from carbon.pydantic.delete_files_v2_query_input import DeleteFilesV2QueryInput as DeleteFilesV2QueryInputPydantic
+from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
 
 # body param
-SchemaForRequestBodyApplicationJson = ResyncFileQueryInputSchema
+SchemaForRequestBodyApplicationJson = DeleteFilesV2QueryInputSchema
 
 
-request_body_resync_file_query_input = api_client.RequestBody(
+request_body_delete_files_v2_query_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
-SchemaFor200ResponseBodyApplicationJson = UserFileSchema
+SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
-    body: UserFile
+    body: GenericSuccessResponse
 
 
 @dataclass
 class ApiResponseFor200Async(api_client.AsyncApiResponse):
-    body: UserFile
+    body: GenericSuccessResponse
 
 
 _response_for_200 = api_client.OpenApiResponse(
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
@@ -101,50 +104,44 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _resync_mapped_args(
+    def _delete_v2_mapped_args(
         self,
-        file_id: int,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        force_embedding_generation: typing.Optional[bool] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        send_webhook: typing.Optional[bool] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
-        if file_id is not None:
-            _body["file_id"] = file_id
-        if chunk_size is not None:
-            _body["chunk_size"] = chunk_size
-        if chunk_overlap is not None:
-            _body["chunk_overlap"] = chunk_overlap
-        if force_embedding_generation is not None:
-            _body["force_embedding_generation"] = force_embedding_generation
+        if filters is not None:
+            _body["filters"] = filters
+        if send_webhook is not None:
+            _body["send_webhook"] = send_webhook
         args.body = _body
         return args
 
-    async def _aresync_oapg(
+    async def _adelete_v2_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Resync File
+        Delete Files V2 Endpoint
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -160,20 +157,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/resync_file',
+            path_template='/delete_files_v2',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_resync_file_query_input.serialize(body, content_type)
+        serialized_data = request_body_delete_files_v2_query_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -237,28 +234,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _resync_oapg(
+    def _delete_v2_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Resync File
+        Delete Files V2 Endpoint
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -274,20 +271,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/resync_file',
+            path_template='/delete_files_v2',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_resync_file_query_input.serialize(body, content_type)
+        serialized_data = request_body_delete_files_v2_query_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -320,141 +317,117 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class ResyncRaw(BaseApi):
+class DeleteV2Raw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def aresync(
+    async def adelete_v2(
         self,
-        file_id: int,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        force_embedding_generation: typing.Optional[bool] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        send_webhook: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._resync_mapped_args(
-            file_id=file_id,
-            chunk_size=chunk_size,
-            chunk_overlap=chunk_overlap,
-            force_embedding_generation=force_embedding_generation,
+        args = self._delete_v2_mapped_args(
+            filters=filters,
+            send_webhook=send_webhook,
         )
-        return await self._aresync_oapg(
+        return await self._adelete_v2_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def resync(
+    def delete_v2(
         self,
-        file_id: int,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        force_embedding_generation: typing.Optional[bool] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        send_webhook: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._resync_mapped_args(
-            file_id=file_id,
-            chunk_size=chunk_size,
-            chunk_overlap=chunk_overlap,
-            force_embedding_generation=force_embedding_generation,
+        args = self._delete_v2_mapped_args(
+            filters=filters,
+            send_webhook=send_webhook,
         )
-        return self._resync_oapg(
+        return self._delete_v2_oapg(
             body=args.body,
         )
 
-class Resync(BaseApi):
+class DeleteV2(BaseApi):
 
-    async def aresync(
+    async def adelete_v2(
         self,
-        file_id: int,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        force_embedding_generation: typing.Optional[bool] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        send_webhook: typing.Optional[bool] = None,
         validate: bool = False,
         **kwargs,
-    ) -> UserFilePydantic:
-        raw_response = await self.raw.aresync(
-            file_id=file_id,
-            chunk_size=chunk_size,
-            chunk_overlap=chunk_overlap,
-            force_embedding_generation=force_embedding_generation,
+    ) -> GenericSuccessResponsePydantic:
+        raw_response = await self.raw.adelete_v2(
+            filters=filters,
+            send_webhook=send_webhook,
             **kwargs,
         )
         if validate:
-            return UserFilePydantic(**raw_response.body)
-        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
+            return GenericSuccessResponsePydantic(**raw_response.body)
+        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
-    def resync(
+    def delete_v2(
         self,
-        file_id: int,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        force_embedding_generation: typing.Optional[bool] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        send_webhook: typing.Optional[bool] = None,
         validate: bool = False,
-    ) -> UserFilePydantic:
-        raw_response = self.raw.resync(
-            file_id=file_id,
-            chunk_size=chunk_size,
-            chunk_overlap=chunk_overlap,
-            force_embedding_generation=force_embedding_generation,
+    ) -> GenericSuccessResponsePydantic:
+        raw_response = self.raw.delete_v2(
+            filters=filters,
+            send_webhook=send_webhook,
         )
         if validate:
-            return UserFilePydantic(**raw_response.body)
-        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
+            return GenericSuccessResponsePydantic(**raw_response.body)
+        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        file_id: int,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        force_embedding_generation: typing.Optional[bool] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        send_webhook: typing.Optional[bool] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._resync_mapped_args(
-            file_id=file_id,
-            chunk_size=chunk_size,
-            chunk_overlap=chunk_overlap,
-            force_embedding_generation=force_embedding_generation,
+        args = self._delete_v2_mapped_args(
+            filters=filters,
+            send_webhook=send_webhook,
         )
-        return await self._aresync_oapg(
+        return await self._adelete_v2_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        file_id: int,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        force_embedding_generation: typing.Optional[bool] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        send_webhook: typing.Optional[bool] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._resync_mapped_args(
-            file_id=file_id,
-            chunk_size=chunk_size,
-            chunk_overlap=chunk_overlap,
-            force_embedding_generation=force_embedding_generation,
+        args = self._delete_v2_mapped_args(
+            filters=filters,
+            send_webhook=send_webhook,
         )
-        return self._resync_oapg(
+        return self._delete_v2_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/revoke_access_token/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/revoke_access_token/post.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/revoke_access_token/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/revoke_access_token/post.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/scrape_sitemap/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/scrape_sitemap/post.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/scrape_sitemap/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/scrape_sitemap/post.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/search_urls/get.py` & `carbon_python_sdk-0.2.0/carbon/paths/search_urls/get.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/search_urls/get.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/search_urls/get.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/text_chunks/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/text_chunks/post.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/text_chunks/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/text_chunks/post.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/upload_chunks_and_embeddings/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/upload_chunks_and_embeddings/post.py`

 * *Files 6% similar despite different names*

```diff
@@ -30,28 +30,31 @@
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
 from carbon.model.chunks_and_embeddings_upload_input import ChunksAndEmbeddingsUploadInput as ChunksAndEmbeddingsUploadInputSchema
+from carbon.model.chunks_and_embeddings_upload_input_custom_credentials import ChunksAndEmbeddingsUploadInputCustomCredentials as ChunksAndEmbeddingsUploadInputCustomCredentialsSchema
 from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
 from carbon.model.single_chunks_and_embeddings_upload_input import SingleChunksAndEmbeddingsUploadInput as SingleChunksAndEmbeddingsUploadInputSchema
 from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
 
 from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
+from carbon.type.chunks_and_embeddings_upload_input_custom_credentials import ChunksAndEmbeddingsUploadInputCustomCredentials
 from carbon.type.generic_success_response import GenericSuccessResponse
 from carbon.type.single_chunks_and_embeddings_upload_input import SingleChunksAndEmbeddingsUploadInput
 from carbon.type.chunks_and_embeddings_upload_input import ChunksAndEmbeddingsUploadInput
 
 from ...api_client import Dictionary
 from carbon.pydantic.chunks_and_embeddings_upload_input import ChunksAndEmbeddingsUploadInput as ChunksAndEmbeddingsUploadInputPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.single_chunks_and_embeddings_upload_input import SingleChunksAndEmbeddingsUploadInput as SingleChunksAndEmbeddingsUploadInputPydantic
+from carbon.pydantic.chunks_and_embeddings_upload_input_custom_credentials import ChunksAndEmbeddingsUploadInputCustomCredentials as ChunksAndEmbeddingsUploadInputCustomCredentialsPydantic
 from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
 from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
 
 from . import path
 
 # body param
 SchemaForRequestBodyApplicationJson = ChunksAndEmbeddingsUploadInputSchema
@@ -124,15 +127,15 @@
 
     def _upload_chunks_and_embeddings_mapped_args(
         self,
         embedding_model: EmbeddingGenerators,
         chunks_and_embeddings: typing.List[SingleChunksAndEmbeddingsUploadInput],
         overwrite_existing: typing.Optional[bool] = None,
         chunks_only: typing.Optional[bool] = None,
-        custom_credentials: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]] = None,
+        custom_credentials: typing.Optional[ChunksAndEmbeddingsUploadInputCustomCredentials] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if chunks_and_embeddings is not None:
             _body["chunks_and_embeddings"] = chunks_and_embeddings
@@ -349,15 +352,15 @@
 
     async def aupload_chunks_and_embeddings(
         self,
         embedding_model: EmbeddingGenerators,
         chunks_and_embeddings: typing.List[SingleChunksAndEmbeddingsUploadInput],
         overwrite_existing: typing.Optional[bool] = None,
         chunks_only: typing.Optional[bool] = None,
-        custom_credentials: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]] = None,
+        custom_credentials: typing.Optional[ChunksAndEmbeddingsUploadInputCustomCredentials] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         args = self._upload_chunks_and_embeddings_mapped_args(
@@ -374,15 +377,15 @@
     
     def upload_chunks_and_embeddings(
         self,
         embedding_model: EmbeddingGenerators,
         chunks_and_embeddings: typing.List[SingleChunksAndEmbeddingsUploadInput],
         overwrite_existing: typing.Optional[bool] = None,
         chunks_only: typing.Optional[bool] = None,
-        custom_credentials: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]] = None,
+        custom_credentials: typing.Optional[ChunksAndEmbeddingsUploadInputCustomCredentials] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._upload_chunks_and_embeddings_mapped_args(
             embedding_model=embedding_model,
             chunks_and_embeddings=chunks_and_embeddings,
@@ -398,15 +401,15 @@
 
     async def aupload_chunks_and_embeddings(
         self,
         embedding_model: EmbeddingGenerators,
         chunks_and_embeddings: typing.List[SingleChunksAndEmbeddingsUploadInput],
         overwrite_existing: typing.Optional[bool] = None,
         chunks_only: typing.Optional[bool] = None,
-        custom_credentials: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]] = None,
+        custom_credentials: typing.Optional[ChunksAndEmbeddingsUploadInputCustomCredentials] = None,
         validate: bool = False,
         **kwargs,
     ) -> GenericSuccessResponsePydantic:
         raw_response = await self.raw.aupload_chunks_and_embeddings(
             embedding_model=embedding_model,
             chunks_and_embeddings=chunks_and_embeddings,
             overwrite_existing=overwrite_existing,
@@ -421,15 +424,15 @@
     
     def upload_chunks_and_embeddings(
         self,
         embedding_model: EmbeddingGenerators,
         chunks_and_embeddings: typing.List[SingleChunksAndEmbeddingsUploadInput],
         overwrite_existing: typing.Optional[bool] = None,
         chunks_only: typing.Optional[bool] = None,
-        custom_credentials: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]] = None,
+        custom_credentials: typing.Optional[ChunksAndEmbeddingsUploadInputCustomCredentials] = None,
         validate: bool = False,
     ) -> GenericSuccessResponsePydantic:
         raw_response = self.raw.upload_chunks_and_embeddings(
             embedding_model=embedding_model,
             chunks_and_embeddings=chunks_and_embeddings,
             overwrite_existing=overwrite_existing,
             chunks_only=chunks_only,
@@ -445,15 +448,15 @@
 
     async def apost(
         self,
         embedding_model: EmbeddingGenerators,
         chunks_and_embeddings: typing.List[SingleChunksAndEmbeddingsUploadInput],
         overwrite_existing: typing.Optional[bool] = None,
         chunks_only: typing.Optional[bool] = None,
-        custom_credentials: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]] = None,
+        custom_credentials: typing.Optional[ChunksAndEmbeddingsUploadInputCustomCredentials] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         args = self._upload_chunks_and_embeddings_mapped_args(
@@ -470,15 +473,15 @@
     
     def post(
         self,
         embedding_model: EmbeddingGenerators,
         chunks_and_embeddings: typing.List[SingleChunksAndEmbeddingsUploadInput],
         overwrite_existing: typing.Optional[bool] = None,
         chunks_only: typing.Optional[bool] = None,
-        custom_credentials: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]] = None,
+        custom_credentials: typing.Optional[ChunksAndEmbeddingsUploadInputCustomCredentials] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._upload_chunks_and_embeddings_mapped_args(
             embedding_model=embedding_model,
             chunks_and_embeddings=chunks_and_embeddings,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/upload_chunks_and_embeddings/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/upload_chunks_and_embeddings/post.pyi`

 * *Files 7% similar despite different names*

```diff
@@ -30,28 +30,31 @@
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
 from carbon.model.chunks_and_embeddings_upload_input import ChunksAndEmbeddingsUploadInput as ChunksAndEmbeddingsUploadInputSchema
+from carbon.model.chunks_and_embeddings_upload_input_custom_credentials import ChunksAndEmbeddingsUploadInputCustomCredentials as ChunksAndEmbeddingsUploadInputCustomCredentialsSchema
 from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
 from carbon.model.single_chunks_and_embeddings_upload_input import SingleChunksAndEmbeddingsUploadInput as SingleChunksAndEmbeddingsUploadInputSchema
 from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
 
 from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.http_validation_error import HTTPValidationError
+from carbon.type.chunks_and_embeddings_upload_input_custom_credentials import ChunksAndEmbeddingsUploadInputCustomCredentials
 from carbon.type.generic_success_response import GenericSuccessResponse
 from carbon.type.single_chunks_and_embeddings_upload_input import SingleChunksAndEmbeddingsUploadInput
 from carbon.type.chunks_and_embeddings_upload_input import ChunksAndEmbeddingsUploadInput
 
 from ...api_client import Dictionary
 from carbon.pydantic.chunks_and_embeddings_upload_input import ChunksAndEmbeddingsUploadInput as ChunksAndEmbeddingsUploadInputPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.single_chunks_and_embeddings_upload_input import SingleChunksAndEmbeddingsUploadInput as SingleChunksAndEmbeddingsUploadInputPydantic
+from carbon.pydantic.chunks_and_embeddings_upload_input_custom_credentials import ChunksAndEmbeddingsUploadInputCustomCredentials as ChunksAndEmbeddingsUploadInputCustomCredentialsPydantic
 from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
 from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
 
 # body param
 SchemaForRequestBodyApplicationJson = ChunksAndEmbeddingsUploadInputSchema
 
 
@@ -113,15 +116,15 @@
 
     def _upload_chunks_and_embeddings_mapped_args(
         self,
         embedding_model: EmbeddingGenerators,
         chunks_and_embeddings: typing.List[SingleChunksAndEmbeddingsUploadInput],
         overwrite_existing: typing.Optional[bool] = None,
         chunks_only: typing.Optional[bool] = None,
-        custom_credentials: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]] = None,
+        custom_credentials: typing.Optional[ChunksAndEmbeddingsUploadInputCustomCredentials] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if chunks_and_embeddings is not None:
             _body["chunks_and_embeddings"] = chunks_and_embeddings
@@ -338,15 +341,15 @@
 
     async def aupload_chunks_and_embeddings(
         self,
         embedding_model: EmbeddingGenerators,
         chunks_and_embeddings: typing.List[SingleChunksAndEmbeddingsUploadInput],
         overwrite_existing: typing.Optional[bool] = None,
         chunks_only: typing.Optional[bool] = None,
-        custom_credentials: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]] = None,
+        custom_credentials: typing.Optional[ChunksAndEmbeddingsUploadInputCustomCredentials] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         args = self._upload_chunks_and_embeddings_mapped_args(
@@ -363,15 +366,15 @@
     
     def upload_chunks_and_embeddings(
         self,
         embedding_model: EmbeddingGenerators,
         chunks_and_embeddings: typing.List[SingleChunksAndEmbeddingsUploadInput],
         overwrite_existing: typing.Optional[bool] = None,
         chunks_only: typing.Optional[bool] = None,
-        custom_credentials: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]] = None,
+        custom_credentials: typing.Optional[ChunksAndEmbeddingsUploadInputCustomCredentials] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._upload_chunks_and_embeddings_mapped_args(
             embedding_model=embedding_model,
             chunks_and_embeddings=chunks_and_embeddings,
@@ -387,15 +390,15 @@
 
     async def aupload_chunks_and_embeddings(
         self,
         embedding_model: EmbeddingGenerators,
         chunks_and_embeddings: typing.List[SingleChunksAndEmbeddingsUploadInput],
         overwrite_existing: typing.Optional[bool] = None,
         chunks_only: typing.Optional[bool] = None,
-        custom_credentials: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]] = None,
+        custom_credentials: typing.Optional[ChunksAndEmbeddingsUploadInputCustomCredentials] = None,
         validate: bool = False,
         **kwargs,
     ) -> GenericSuccessResponsePydantic:
         raw_response = await self.raw.aupload_chunks_and_embeddings(
             embedding_model=embedding_model,
             chunks_and_embeddings=chunks_and_embeddings,
             overwrite_existing=overwrite_existing,
@@ -410,15 +413,15 @@
     
     def upload_chunks_and_embeddings(
         self,
         embedding_model: EmbeddingGenerators,
         chunks_and_embeddings: typing.List[SingleChunksAndEmbeddingsUploadInput],
         overwrite_existing: typing.Optional[bool] = None,
         chunks_only: typing.Optional[bool] = None,
-        custom_credentials: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]] = None,
+        custom_credentials: typing.Optional[ChunksAndEmbeddingsUploadInputCustomCredentials] = None,
         validate: bool = False,
     ) -> GenericSuccessResponsePydantic:
         raw_response = self.raw.upload_chunks_and_embeddings(
             embedding_model=embedding_model,
             chunks_and_embeddings=chunks_and_embeddings,
             overwrite_existing=overwrite_existing,
             chunks_only=chunks_only,
@@ -434,15 +437,15 @@
 
     async def apost(
         self,
         embedding_model: EmbeddingGenerators,
         chunks_and_embeddings: typing.List[SingleChunksAndEmbeddingsUploadInput],
         overwrite_existing: typing.Optional[bool] = None,
         chunks_only: typing.Optional[bool] = None,
-        custom_credentials: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]] = None,
+        custom_credentials: typing.Optional[ChunksAndEmbeddingsUploadInputCustomCredentials] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         args = self._upload_chunks_and_embeddings_mapped_args(
@@ -459,15 +462,15 @@
     
     def post(
         self,
         embedding_model: EmbeddingGenerators,
         chunks_and_embeddings: typing.List[SingleChunksAndEmbeddingsUploadInput],
         overwrite_existing: typing.Optional[bool] = None,
         chunks_only: typing.Optional[bool] = None,
-        custom_credentials: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]] = None,
+        custom_credentials: typing.Optional[ChunksAndEmbeddingsUploadInputCustomCredentials] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._upload_chunks_and_embeddings_mapped_args(
             embedding_model=embedding_model,
             chunks_and_embeddings=chunks_and_embeddings,
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/upload_file_from_url/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_confluence_sync/post.pyi`

 * *Files 18% similar despite different names*

```diff
@@ -29,58 +29,57 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.upload_file_from_url_input import UploadFileFromUrlInput as UploadFileFromUrlInputSchema
-from carbon.model.user_file import UserFile as UserFileSchema
-from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
+from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullableSchema
+from carbon.model.sync_files_request import SyncFilesRequest as SyncFilesRequestSchema
+from carbon.model.sync_files_ids import SyncFilesIds as SyncFilesIdsSchema
+from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullableSchema
 
-from carbon.type.embedding_generators import EmbeddingGenerators
+from carbon.type.sync_files_request import SyncFilesRequest
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.upload_file_from_url_input import UploadFileFromUrlInput
-from carbon.type.user_file import UserFile
+from carbon.type.file_sync_config_nullable import FileSyncConfigNullable
+from carbon.type.generic_success_response import GenericSuccessResponse
+from carbon.type.sync_files_ids import SyncFilesIds
+from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
 
 from ...api_client import Dictionary
-from carbon.pydantic.user_file import UserFile as UserFilePydantic
-from carbon.pydantic.upload_file_from_url_input import UploadFileFromUrlInput as UploadFileFromUrlInputPydantic
+from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullablePydantic
+from carbon.pydantic.sync_files_request import SyncFilesRequest as SyncFilesRequestPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
-from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
-
-from . import path
+from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
+from carbon.pydantic.sync_files_ids import SyncFilesIds as SyncFilesIdsPydantic
+from carbon.pydantic.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullablePydantic
 
 # body param
-SchemaForRequestBodyApplicationJson = UploadFileFromUrlInputSchema
+SchemaForRequestBodyApplicationJson = SyncFilesRequestSchema
 
 
-request_body_upload_file_from_url_input = api_client.RequestBody(
+request_body_sync_files_request = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
-_auth = [
-    'accessToken',
-    'apiKey',
-    'customerId',
-]
-SchemaFor200ResponseBodyApplicationJson = UserFileSchema
+SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
-    body: UserFile
+    body: GenericSuccessResponse
 
 
 @dataclass
 class ApiResponseFor200Async(api_client.AsyncApiResponse):
-    body: UserFile
+    body: GenericSuccessResponse
 
 
 _response_for_200 = api_client.OpenApiResponse(
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
@@ -104,82 +103,93 @@
     response_cls=ApiResponseFor422,
     response_cls_async=ApiResponseFor422Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor422ResponseBodyApplicationJson),
     },
 )
-_status_code_to_response = {
-    '200': _response_for_200,
-    '422': _response_for_422,
-}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _upload_from_url_mapped_args(
+    def _sync_confluence_mapped_args(
         self,
-        url: str,
-        file_name: typing.Optional[typing.Optional[str]] = None,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[bool] = None,
-        use_textract: typing.Optional[bool] = None,
-        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
-        if url is not None:
-            _body["url"] = url
-        if file_name is not None:
-            _body["file_name"] = file_name
+        if tags is not None:
+            _body["tags"] = tags
+        if data_source_id is not None:
+            _body["data_source_id"] = data_source_id
+        if ids is not None:
+            _body["ids"] = ids
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
             _body["skip_embedding_generation"] = skip_embedding_generation
-        if set_page_as_boundary is not None:
-            _body["set_page_as_boundary"] = set_page_as_boundary
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
-        if use_textract is not None:
-            _body["use_textract"] = use_textract
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
         if max_items_per_chunk is not None:
             _body["max_items_per_chunk"] = max_items_per_chunk
+        if set_page_as_boundary is not None:
+            _body["set_page_as_boundary"] = set_page_as_boundary
+        if request_id is not None:
+            _body["request_id"] = request_id
+        if use_ocr is not None:
+            _body["use_ocr"] = use_ocr
+        if parse_pdf_tables_with_ocr is not None:
+            _body["parse_pdf_tables_with_ocr"] = parse_pdf_tables_with_ocr
+        if incremental_sync is not None:
+            _body["incremental_sync"] = incremental_sync
+        if file_sync_config is not None:
+            _body["file_sync_config"] = file_sync_config
         args.body = _body
         return args
 
-    async def _aupload_from_url_oapg(
+    async def _async_confluence_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Create Upload File From Url
+        Confluence Sync
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -195,20 +205,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/upload_file_from_url',
+            path_template='/integrations/confluence/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_upload_file_from_url_input.serialize(body, content_type)
+        serialized_data = request_body_sync_files_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -272,28 +282,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _upload_from_url_oapg(
+    def _sync_confluence_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Create Upload File From Url
+        Confluence Sync
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -309,20 +319,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/upload_file_from_url',
+            path_template='/integrations/confluence/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_upload_file_from_url_input.serialize(body, content_type)
+        serialized_data = request_body_sync_files_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -355,225 +365,285 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class UploadFromUrlRaw(BaseApi):
+class SyncConfluenceRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def aupload_from_url(
+    async def async_confluence(
         self,
-        url: str,
-        file_name: typing.Optional[typing.Optional[str]] = None,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[bool] = None,
-        use_textract: typing.Optional[bool] = None,
-        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._upload_from_url_mapped_args(
-            url=url,
-            file_name=file_name,
+        args = self._sync_confluence_mapped_args(
+            data_source_id=data_source_id,
+            ids=ids,
+            tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
-            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
-        return await self._aupload_from_url_oapg(
+        return await self._async_confluence_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def upload_from_url(
+    def sync_confluence(
         self,
-        url: str,
-        file_name: typing.Optional[typing.Optional[str]] = None,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[bool] = None,
-        use_textract: typing.Optional[bool] = None,
-        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._upload_from_url_mapped_args(
-            url=url,
-            file_name=file_name,
+        args = self._sync_confluence_mapped_args(
+            data_source_id=data_source_id,
+            ids=ids,
+            tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
-            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
-        return self._upload_from_url_oapg(
+        return self._sync_confluence_oapg(
             body=args.body,
         )
 
-class UploadFromUrl(BaseApi):
+class SyncConfluence(BaseApi):
 
-    async def aupload_from_url(
+    async def async_confluence(
         self,
-        url: str,
-        file_name: typing.Optional[typing.Optional[str]] = None,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[bool] = None,
-        use_textract: typing.Optional[bool] = None,
-        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         validate: bool = False,
         **kwargs,
-    ) -> UserFilePydantic:
-        raw_response = await self.raw.aupload_from_url(
-            url=url,
-            file_name=file_name,
+    ) -> GenericSuccessResponsePydantic:
+        raw_response = await self.raw.async_confluence(
+            data_source_id=data_source_id,
+            ids=ids,
+            tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
-            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
             **kwargs,
         )
         if validate:
-            return UserFilePydantic(**raw_response.body)
-        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
+            return GenericSuccessResponsePydantic(**raw_response.body)
+        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
-    def upload_from_url(
+    def sync_confluence(
         self,
-        url: str,
-        file_name: typing.Optional[typing.Optional[str]] = None,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[bool] = None,
-        use_textract: typing.Optional[bool] = None,
-        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         validate: bool = False,
-    ) -> UserFilePydantic:
-        raw_response = self.raw.upload_from_url(
-            url=url,
-            file_name=file_name,
+    ) -> GenericSuccessResponsePydantic:
+        raw_response = self.raw.sync_confluence(
+            data_source_id=data_source_id,
+            ids=ids,
+            tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
-            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
         if validate:
-            return UserFilePydantic(**raw_response.body)
-        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
+            return GenericSuccessResponsePydantic(**raw_response.body)
+        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        url: str,
-        file_name: typing.Optional[typing.Optional[str]] = None,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[bool] = None,
-        use_textract: typing.Optional[bool] = None,
-        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._upload_from_url_mapped_args(
-            url=url,
-            file_name=file_name,
+        args = self._sync_confluence_mapped_args(
+            data_source_id=data_source_id,
+            ids=ids,
+            tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
-            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
-        return await self._aupload_from_url_oapg(
+        return await self._async_confluence_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        url: str,
-        file_name: typing.Optional[typing.Optional[str]] = None,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[bool] = None,
-        use_textract: typing.Optional[bool] = None,
-        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._upload_from_url_mapped_args(
-            url=url,
-            file_name=file_name,
+        args = self._sync_confluence_mapped_args(
+            data_source_id=data_source_id,
+            ids=ids,
+            tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
-            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
-        return self._upload_from_url_oapg(
+        return self._sync_confluence_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/upload_file_from_url/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_confluence_sync/post.py`

 * *Files 21% similar despite different names*

```diff
@@ -29,51 +29,64 @@
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.upload_file_from_url_input import UploadFileFromUrlInput as UploadFileFromUrlInputSchema
-from carbon.model.user_file import UserFile as UserFileSchema
-from carbon.model.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsSchema
+from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullableSchema
+from carbon.model.sync_files_request import SyncFilesRequest as SyncFilesRequestSchema
+from carbon.model.sync_files_ids import SyncFilesIds as SyncFilesIdsSchema
+from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
+from carbon.model.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullableSchema
 
-from carbon.type.embedding_generators import EmbeddingGenerators
+from carbon.type.sync_files_request import SyncFilesRequest
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.upload_file_from_url_input import UploadFileFromUrlInput
-from carbon.type.user_file import UserFile
+from carbon.type.file_sync_config_nullable import FileSyncConfigNullable
+from carbon.type.generic_success_response import GenericSuccessResponse
+from carbon.type.sync_files_ids import SyncFilesIds
+from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
 
 from ...api_client import Dictionary
-from carbon.pydantic.user_file import UserFile as UserFilePydantic
-from carbon.pydantic.upload_file_from_url_input import UploadFileFromUrlInput as UploadFileFromUrlInputPydantic
+from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullablePydantic
+from carbon.pydantic.sync_files_request import SyncFilesRequest as SyncFilesRequestPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
-from carbon.pydantic.embedding_generators import EmbeddingGenerators as EmbeddingGeneratorsPydantic
+from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
+from carbon.pydantic.sync_files_ids import SyncFilesIds as SyncFilesIdsPydantic
+from carbon.pydantic.file_sync_config_nullable import FileSyncConfigNullable as FileSyncConfigNullablePydantic
+
+from . import path
 
 # body param
-SchemaForRequestBodyApplicationJson = UploadFileFromUrlInputSchema
+SchemaForRequestBodyApplicationJson = SyncFilesRequestSchema
 
 
-request_body_upload_file_from_url_input = api_client.RequestBody(
+request_body_sync_files_request = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
-SchemaFor200ResponseBodyApplicationJson = UserFileSchema
+_auth = [
+    'accessToken',
+    'apiKey',
+    'customerId',
+]
+SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
-    body: UserFile
+    body: GenericSuccessResponse
 
 
 @dataclass
 class ApiResponseFor200Async(api_client.AsyncApiResponse):
-    body: UserFile
+    body: GenericSuccessResponse
 
 
 _response_for_200 = api_client.OpenApiResponse(
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
@@ -97,78 +110,97 @@
     response_cls=ApiResponseFor422,
     response_cls_async=ApiResponseFor422Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor422ResponseBodyApplicationJson),
     },
 )
+_status_code_to_response = {
+    '200': _response_for_200,
+    '422': _response_for_422,
+}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _upload_from_url_mapped_args(
+    def _sync_confluence_mapped_args(
         self,
-        url: str,
-        file_name: typing.Optional[typing.Optional[str]] = None,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[bool] = None,
-        use_textract: typing.Optional[bool] = None,
-        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
-        if url is not None:
-            _body["url"] = url
-        if file_name is not None:
-            _body["file_name"] = file_name
+        if tags is not None:
+            _body["tags"] = tags
+        if data_source_id is not None:
+            _body["data_source_id"] = data_source_id
+        if ids is not None:
+            _body["ids"] = ids
         if chunk_size is not None:
             _body["chunk_size"] = chunk_size
         if chunk_overlap is not None:
             _body["chunk_overlap"] = chunk_overlap
         if skip_embedding_generation is not None:
             _body["skip_embedding_generation"] = skip_embedding_generation
-        if set_page_as_boundary is not None:
-            _body["set_page_as_boundary"] = set_page_as_boundary
         if embedding_model is not None:
             _body["embedding_model"] = embedding_model
         if generate_sparse_vectors is not None:
             _body["generate_sparse_vectors"] = generate_sparse_vectors
-        if use_textract is not None:
-            _body["use_textract"] = use_textract
         if prepend_filename_to_chunks is not None:
             _body["prepend_filename_to_chunks"] = prepend_filename_to_chunks
         if max_items_per_chunk is not None:
             _body["max_items_per_chunk"] = max_items_per_chunk
+        if set_page_as_boundary is not None:
+            _body["set_page_as_boundary"] = set_page_as_boundary
+        if request_id is not None:
+            _body["request_id"] = request_id
+        if use_ocr is not None:
+            _body["use_ocr"] = use_ocr
+        if parse_pdf_tables_with_ocr is not None:
+            _body["parse_pdf_tables_with_ocr"] = parse_pdf_tables_with_ocr
+        if incremental_sync is not None:
+            _body["incremental_sync"] = incremental_sync
+        if file_sync_config is not None:
+            _body["file_sync_config"] = file_sync_config
         args.body = _body
         return args
 
-    async def _aupload_from_url_oapg(
+    async def _async_confluence_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Create Upload File From Url
+        Confluence Sync
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -184,20 +216,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/upload_file_from_url',
+            path_template='/integrations/confluence/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_upload_file_from_url_input.serialize(body, content_type)
+        serialized_data = request_body_sync_files_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -261,28 +293,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _upload_from_url_oapg(
+    def _sync_confluence_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Create Upload File From Url
+        Confluence Sync
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -298,20 +330,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/upload_file_from_url',
+            path_template='/integrations/confluence/sync',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_upload_file_from_url_input.serialize(body, content_type)
+        serialized_data = request_body_sync_files_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -344,225 +376,285 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class UploadFromUrlRaw(BaseApi):
+class SyncConfluenceRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def aupload_from_url(
+    async def async_confluence(
         self,
-        url: str,
-        file_name: typing.Optional[typing.Optional[str]] = None,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[bool] = None,
-        use_textract: typing.Optional[bool] = None,
-        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._upload_from_url_mapped_args(
-            url=url,
-            file_name=file_name,
+        args = self._sync_confluence_mapped_args(
+            data_source_id=data_source_id,
+            ids=ids,
+            tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
-            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
-        return await self._aupload_from_url_oapg(
+        return await self._async_confluence_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def upload_from_url(
+    def sync_confluence(
         self,
-        url: str,
-        file_name: typing.Optional[typing.Optional[str]] = None,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[bool] = None,
-        use_textract: typing.Optional[bool] = None,
-        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._upload_from_url_mapped_args(
-            url=url,
-            file_name=file_name,
+        args = self._sync_confluence_mapped_args(
+            data_source_id=data_source_id,
+            ids=ids,
+            tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
-            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
-        return self._upload_from_url_oapg(
+        return self._sync_confluence_oapg(
             body=args.body,
         )
 
-class UploadFromUrl(BaseApi):
+class SyncConfluence(BaseApi):
 
-    async def aupload_from_url(
+    async def async_confluence(
         self,
-        url: str,
-        file_name: typing.Optional[typing.Optional[str]] = None,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[bool] = None,
-        use_textract: typing.Optional[bool] = None,
-        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         validate: bool = False,
         **kwargs,
-    ) -> UserFilePydantic:
-        raw_response = await self.raw.aupload_from_url(
-            url=url,
-            file_name=file_name,
+    ) -> GenericSuccessResponsePydantic:
+        raw_response = await self.raw.async_confluence(
+            data_source_id=data_source_id,
+            ids=ids,
+            tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
-            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
             **kwargs,
         )
         if validate:
-            return UserFilePydantic(**raw_response.body)
-        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
+            return GenericSuccessResponsePydantic(**raw_response.body)
+        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
-    def upload_from_url(
+    def sync_confluence(
         self,
-        url: str,
-        file_name: typing.Optional[typing.Optional[str]] = None,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[bool] = None,
-        use_textract: typing.Optional[bool] = None,
-        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         validate: bool = False,
-    ) -> UserFilePydantic:
-        raw_response = self.raw.upload_from_url(
-            url=url,
-            file_name=file_name,
+    ) -> GenericSuccessResponsePydantic:
+        raw_response = self.raw.sync_confluence(
+            data_source_id=data_source_id,
+            ids=ids,
+            tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
-            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
         if validate:
-            return UserFilePydantic(**raw_response.body)
-        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
+            return GenericSuccessResponsePydantic(**raw_response.body)
+        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        url: str,
-        file_name: typing.Optional[typing.Optional[str]] = None,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[bool] = None,
-        use_textract: typing.Optional[bool] = None,
-        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._upload_from_url_mapped_args(
-            url=url,
-            file_name=file_name,
+        args = self._sync_confluence_mapped_args(
+            data_source_id=data_source_id,
+            ids=ids,
+            tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
-            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
-        return await self._aupload_from_url_oapg(
+        return await self._async_confluence_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        url: str,
-        file_name: typing.Optional[typing.Optional[str]] = None,
+        data_source_id: int,
+        ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]],
+        tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = None,
         chunk_size: typing.Optional[typing.Optional[int]] = None,
         chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        set_page_as_boundary: typing.Optional[bool] = None,
-        embedding_model: typing.Optional[EmbeddingGenerators] = None,
-        generate_sparse_vectors: typing.Optional[bool] = None,
-        use_textract: typing.Optional[bool] = None,
-        prepend_filename_to_chunks: typing.Optional[bool] = None,
+        skip_embedding_generation: typing.Optional[typing.Optional[bool]] = None,
+        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
+        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        set_page_as_boundary: typing.Optional[bool] = None,
+        request_id: typing.Optional[str] = None,
+        use_ocr: typing.Optional[typing.Optional[bool]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = None,
+        incremental_sync: typing.Optional[bool] = None,
+        file_sync_config: typing.Optional[FileSyncConfigNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._upload_from_url_mapped_args(
-            url=url,
-            file_name=file_name,
+        args = self._sync_confluence_mapped_args(
+            data_source_id=data_source_id,
+            ids=ids,
+            tags=tags,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
-            set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             generate_sparse_vectors=generate_sparse_vectors,
-            use_textract=use_textract,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            set_page_as_boundary=set_page_as_boundary,
+            request_id=request_id,
+            use_ocr=use_ocr,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            incremental_sync=incremental_sync,
+            file_sync_config=file_sync_config,
         )
-        return self._upload_from_url_oapg(
+        return self._sync_confluence_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/upload_text/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/user_files_v2/post.pyi`

 * *Files 18% similar despite different names*

```diff
@@ -28,59 +28,61 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
+from carbon.model.pagination import Pagination as PaginationSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.user_file import UserFile as UserFileSchema
-from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullableSchema
-from carbon.model.raw_text_input import RawTextInput as RawTextInputSchema
+from carbon.model.organization_user_files_to_sync_order_by_types import OrganizationUserFilesToSyncOrderByTypes as OrganizationUserFilesToSyncOrderByTypesSchema
+from carbon.model.organization_user_files_to_sync_query_input import OrganizationUserFilesToSyncQueryInput as OrganizationUserFilesToSyncQueryInputSchema
+from carbon.model.organization_user_files_to_sync_filters import OrganizationUserFilesToSyncFilters as OrganizationUserFilesToSyncFiltersSchema
+from carbon.model.user_files_v2 import UserFilesV2 as UserFilesV2Schema
+from carbon.model.order_dir import OrderDir as OrderDirSchema
 
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.raw_text_input import RawTextInput
-from carbon.type.user_file import UserFile
-from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.type.pagination import Pagination
+from carbon.type.organization_user_files_to_sync_order_by_types import OrganizationUserFilesToSyncOrderByTypes
+from carbon.type.organization_user_files_to_sync_filters import OrganizationUserFilesToSyncFilters
+from carbon.type.user_files_v2 import UserFilesV2
+from carbon.type.order_dir import OrderDir
+from carbon.type.organization_user_files_to_sync_query_input import OrganizationUserFilesToSyncQueryInput
 
 from ...api_client import Dictionary
-from carbon.pydantic.user_file import UserFile as UserFilePydantic
-from carbon.pydantic.raw_text_input import RawTextInput as RawTextInputPydantic
-from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullablePydantic
+from carbon.pydantic.organization_user_files_to_sync_filters import OrganizationUserFilesToSyncFilters as OrganizationUserFilesToSyncFiltersPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
-
-from . import path
+from carbon.pydantic.organization_user_files_to_sync_query_input import OrganizationUserFilesToSyncQueryInput as OrganizationUserFilesToSyncQueryInputPydantic
+from carbon.pydantic.order_dir import OrderDir as OrderDirPydantic
+from carbon.pydantic.user_files_v2 import UserFilesV2 as UserFilesV2Pydantic
+from carbon.pydantic.organization_user_files_to_sync_order_by_types import OrganizationUserFilesToSyncOrderByTypes as OrganizationUserFilesToSyncOrderByTypesPydantic
+from carbon.pydantic.pagination import Pagination as PaginationPydantic
 
 # body param
-SchemaForRequestBodyApplicationJson = RawTextInputSchema
+SchemaForRequestBodyApplicationJson = OrganizationUserFilesToSyncQueryInputSchema
 
 
-request_body_raw_text_input = api_client.RequestBody(
+request_body_organization_user_files_to_sync_query_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
-_auth = [
-    'accessToken',
-    'apiKey',
-    'customerId',
-]
-SchemaFor200ResponseBodyApplicationJson = UserFileSchema
+SchemaFor200ResponseBodyApplicationJson = UserFilesV2Schema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
-    body: UserFile
+    body: UserFilesV2
 
 
 @dataclass
 class ApiResponseFor200Async(api_client.AsyncApiResponse):
-    body: UserFile
+    body: UserFilesV2
 
 
 _response_for_200 = api_client.OpenApiResponse(
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
@@ -104,73 +106,66 @@
     response_cls=ApiResponseFor422,
     response_cls_async=ApiResponseFor422Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor422ResponseBodyApplicationJson),
     },
 )
-_status_code_to_response = {
-    '200': _response_for_200,
-    '422': _response_for_422,
-}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _upload_text_mapped_args(
+    def _query_user_files_mapped_args(
         self,
-        contents: str,
-        name: typing.Optional[typing.Optional[str]] = None,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        pagination: typing.Optional[Pagination] = None,
+        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_dir: typing.Optional[OrderDir] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
+        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
+        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
-        if contents is not None:
-            _body["contents"] = contents
-        if name is not None:
-            _body["name"] = name
-        if chunk_size is not None:
-            _body["chunk_size"] = chunk_size
-        if chunk_overlap is not None:
-            _body["chunk_overlap"] = chunk_overlap
-        if skip_embedding_generation is not None:
-            _body["skip_embedding_generation"] = skip_embedding_generation
-        if overwrite_file_id is not None:
-            _body["overwrite_file_id"] = overwrite_file_id
-        if embedding_model is not None:
-            _body["embedding_model"] = embedding_model
-        if generate_sparse_vectors is not None:
-            _body["generate_sparse_vectors"] = generate_sparse_vectors
+        if pagination is not None:
+            _body["pagination"] = pagination
+        if order_by is not None:
+            _body["order_by"] = order_by
+        if order_dir is not None:
+            _body["order_dir"] = order_dir
+        if filters is not None:
+            _body["filters"] = filters
+        if include_raw_file is not None:
+            _body["include_raw_file"] = include_raw_file
+        if include_parsed_text_file is not None:
+            _body["include_parsed_text_file"] = include_parsed_text_file
+        if include_additional_files is not None:
+            _body["include_additional_files"] = include_additional_files
         args.body = _body
         return args
 
-    async def _aupload_text_oapg(
+    async def _aquery_user_files_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Create Raw Text
+        User Files V2
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -186,20 +181,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/upload_text',
+            path_template='/user_files_v2',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_raw_text_input.serialize(body, content_type)
+        serialized_data = request_body_organization_user_files_to_sync_query_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -263,28 +258,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _upload_text_oapg(
+    def _query_user_files_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Create Raw Text
+        User Files V2
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -300,20 +295,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/upload_text',
+            path_template='/user_files_v2',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_raw_text_input.serialize(body, content_type)
+        serialized_data = request_body_organization_user_files_to_sync_query_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -346,189 +341,177 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class UploadTextRaw(BaseApi):
+class QueryUserFilesRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def aupload_text(
+    async def aquery_user_files(
         self,
-        contents: str,
-        name: typing.Optional[typing.Optional[str]] = None,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        pagination: typing.Optional[Pagination] = None,
+        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_dir: typing.Optional[OrderDir] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
+        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
+        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._upload_text_mapped_args(
-            contents=contents,
-            name=name,
-            chunk_size=chunk_size,
-            chunk_overlap=chunk_overlap,
-            skip_embedding_generation=skip_embedding_generation,
-            overwrite_file_id=overwrite_file_id,
-            embedding_model=embedding_model,
-            generate_sparse_vectors=generate_sparse_vectors,
+        args = self._query_user_files_mapped_args(
+            pagination=pagination,
+            order_by=order_by,
+            order_dir=order_dir,
+            filters=filters,
+            include_raw_file=include_raw_file,
+            include_parsed_text_file=include_parsed_text_file,
+            include_additional_files=include_additional_files,
         )
-        return await self._aupload_text_oapg(
+        return await self._aquery_user_files_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def upload_text(
+    def query_user_files(
         self,
-        contents: str,
-        name: typing.Optional[typing.Optional[str]] = None,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        pagination: typing.Optional[Pagination] = None,
+        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_dir: typing.Optional[OrderDir] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
+        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
+        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._upload_text_mapped_args(
-            contents=contents,
-            name=name,
-            chunk_size=chunk_size,
-            chunk_overlap=chunk_overlap,
-            skip_embedding_generation=skip_embedding_generation,
-            overwrite_file_id=overwrite_file_id,
-            embedding_model=embedding_model,
-            generate_sparse_vectors=generate_sparse_vectors,
+        args = self._query_user_files_mapped_args(
+            pagination=pagination,
+            order_by=order_by,
+            order_dir=order_dir,
+            filters=filters,
+            include_raw_file=include_raw_file,
+            include_parsed_text_file=include_parsed_text_file,
+            include_additional_files=include_additional_files,
         )
-        return self._upload_text_oapg(
+        return self._query_user_files_oapg(
             body=args.body,
         )
 
-class UploadText(BaseApi):
+class QueryUserFiles(BaseApi):
 
-    async def aupload_text(
+    async def aquery_user_files(
         self,
-        contents: str,
-        name: typing.Optional[typing.Optional[str]] = None,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        pagination: typing.Optional[Pagination] = None,
+        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_dir: typing.Optional[OrderDir] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
+        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
+        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
         validate: bool = False,
         **kwargs,
-    ) -> UserFilePydantic:
-        raw_response = await self.raw.aupload_text(
-            contents=contents,
-            name=name,
-            chunk_size=chunk_size,
-            chunk_overlap=chunk_overlap,
-            skip_embedding_generation=skip_embedding_generation,
-            overwrite_file_id=overwrite_file_id,
-            embedding_model=embedding_model,
-            generate_sparse_vectors=generate_sparse_vectors,
+    ) -> UserFilesV2Pydantic:
+        raw_response = await self.raw.aquery_user_files(
+            pagination=pagination,
+            order_by=order_by,
+            order_dir=order_dir,
+            filters=filters,
+            include_raw_file=include_raw_file,
+            include_parsed_text_file=include_parsed_text_file,
+            include_additional_files=include_additional_files,
             **kwargs,
         )
         if validate:
-            return UserFilePydantic(**raw_response.body)
-        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
+            return UserFilesV2Pydantic(**raw_response.body)
+        return api_client.construct_model_instance(UserFilesV2Pydantic, raw_response.body)
     
     
-    def upload_text(
+    def query_user_files(
         self,
-        contents: str,
-        name: typing.Optional[typing.Optional[str]] = None,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        pagination: typing.Optional[Pagination] = None,
+        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_dir: typing.Optional[OrderDir] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
+        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
+        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
         validate: bool = False,
-    ) -> UserFilePydantic:
-        raw_response = self.raw.upload_text(
-            contents=contents,
-            name=name,
-            chunk_size=chunk_size,
-            chunk_overlap=chunk_overlap,
-            skip_embedding_generation=skip_embedding_generation,
-            overwrite_file_id=overwrite_file_id,
-            embedding_model=embedding_model,
-            generate_sparse_vectors=generate_sparse_vectors,
+    ) -> UserFilesV2Pydantic:
+        raw_response = self.raw.query_user_files(
+            pagination=pagination,
+            order_by=order_by,
+            order_dir=order_dir,
+            filters=filters,
+            include_raw_file=include_raw_file,
+            include_parsed_text_file=include_parsed_text_file,
+            include_additional_files=include_additional_files,
         )
         if validate:
-            return UserFilePydantic(**raw_response.body)
-        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
+            return UserFilesV2Pydantic(**raw_response.body)
+        return api_client.construct_model_instance(UserFilesV2Pydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        contents: str,
-        name: typing.Optional[typing.Optional[str]] = None,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        pagination: typing.Optional[Pagination] = None,
+        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_dir: typing.Optional[OrderDir] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
+        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
+        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._upload_text_mapped_args(
-            contents=contents,
-            name=name,
-            chunk_size=chunk_size,
-            chunk_overlap=chunk_overlap,
-            skip_embedding_generation=skip_embedding_generation,
-            overwrite_file_id=overwrite_file_id,
-            embedding_model=embedding_model,
-            generate_sparse_vectors=generate_sparse_vectors,
+        args = self._query_user_files_mapped_args(
+            pagination=pagination,
+            order_by=order_by,
+            order_dir=order_dir,
+            filters=filters,
+            include_raw_file=include_raw_file,
+            include_parsed_text_file=include_parsed_text_file,
+            include_additional_files=include_additional_files,
         )
-        return await self._aupload_text_oapg(
+        return await self._aquery_user_files_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        contents: str,
-        name: typing.Optional[typing.Optional[str]] = None,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        pagination: typing.Optional[Pagination] = None,
+        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_dir: typing.Optional[OrderDir] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
+        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
+        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._upload_text_mapped_args(
-            contents=contents,
-            name=name,
-            chunk_size=chunk_size,
-            chunk_overlap=chunk_overlap,
-            skip_embedding_generation=skip_embedding_generation,
-            overwrite_file_id=overwrite_file_id,
-            embedding_model=embedding_model,
-            generate_sparse_vectors=generate_sparse_vectors,
+        args = self._query_user_files_mapped_args(
+            pagination=pagination,
+            order_by=order_by,
+            order_dir=order_dir,
+            filters=filters,
+            include_raw_file=include_raw_file,
+            include_parsed_text_file=include_parsed_text_file,
+            include_additional_files=include_additional_files,
         )
-        return self._upload_text_oapg(
+        return self._query_user_files_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/upload_text/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/user_files_v2/post.py`

 * *Files 20% similar despite different names*

```diff
@@ -28,52 +28,68 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
+from carbon.model.pagination import Pagination as PaginationSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.user_file import UserFile as UserFileSchema
-from carbon.model.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullableSchema
-from carbon.model.raw_text_input import RawTextInput as RawTextInputSchema
+from carbon.model.organization_user_files_to_sync_order_by_types import OrganizationUserFilesToSyncOrderByTypes as OrganizationUserFilesToSyncOrderByTypesSchema
+from carbon.model.organization_user_files_to_sync_query_input import OrganizationUserFilesToSyncQueryInput as OrganizationUserFilesToSyncQueryInputSchema
+from carbon.model.organization_user_files_to_sync_filters import OrganizationUserFilesToSyncFilters as OrganizationUserFilesToSyncFiltersSchema
+from carbon.model.user_files_v2 import UserFilesV2 as UserFilesV2Schema
+from carbon.model.order_dir import OrderDir as OrderDirSchema
 
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.raw_text_input import RawTextInput
-from carbon.type.user_file import UserFile
-from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.type.pagination import Pagination
+from carbon.type.organization_user_files_to_sync_order_by_types import OrganizationUserFilesToSyncOrderByTypes
+from carbon.type.organization_user_files_to_sync_filters import OrganizationUserFilesToSyncFilters
+from carbon.type.user_files_v2 import UserFilesV2
+from carbon.type.order_dir import OrderDir
+from carbon.type.organization_user_files_to_sync_query_input import OrganizationUserFilesToSyncQueryInput
 
 from ...api_client import Dictionary
-from carbon.pydantic.user_file import UserFile as UserFilePydantic
-from carbon.pydantic.raw_text_input import RawTextInput as RawTextInputPydantic
-from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable as EmbeddingGeneratorsNullablePydantic
+from carbon.pydantic.organization_user_files_to_sync_filters import OrganizationUserFilesToSyncFilters as OrganizationUserFilesToSyncFiltersPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
+from carbon.pydantic.organization_user_files_to_sync_query_input import OrganizationUserFilesToSyncQueryInput as OrganizationUserFilesToSyncQueryInputPydantic
+from carbon.pydantic.order_dir import OrderDir as OrderDirPydantic
+from carbon.pydantic.user_files_v2 import UserFilesV2 as UserFilesV2Pydantic
+from carbon.pydantic.organization_user_files_to_sync_order_by_types import OrganizationUserFilesToSyncOrderByTypes as OrganizationUserFilesToSyncOrderByTypesPydantic
+from carbon.pydantic.pagination import Pagination as PaginationPydantic
+
+from . import path
 
 # body param
-SchemaForRequestBodyApplicationJson = RawTextInputSchema
+SchemaForRequestBodyApplicationJson = OrganizationUserFilesToSyncQueryInputSchema
 
 
-request_body_raw_text_input = api_client.RequestBody(
+request_body_organization_user_files_to_sync_query_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
-SchemaFor200ResponseBodyApplicationJson = UserFileSchema
+_auth = [
+    'accessToken',
+    'apiKey',
+    'customerId',
+]
+SchemaFor200ResponseBodyApplicationJson = UserFilesV2Schema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
-    body: UserFile
+    body: UserFilesV2
 
 
 @dataclass
 class ApiResponseFor200Async(api_client.AsyncApiResponse):
-    body: UserFile
+    body: UserFilesV2
 
 
 _response_for_200 = api_client.OpenApiResponse(
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
@@ -97,69 +113,70 @@
     response_cls=ApiResponseFor422,
     response_cls_async=ApiResponseFor422Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor422ResponseBodyApplicationJson),
     },
 )
+_status_code_to_response = {
+    '200': _response_for_200,
+    '422': _response_for_422,
+}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _upload_text_mapped_args(
+    def _query_user_files_mapped_args(
         self,
-        contents: str,
-        name: typing.Optional[typing.Optional[str]] = None,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        pagination: typing.Optional[Pagination] = None,
+        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_dir: typing.Optional[OrderDir] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
+        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
+        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
-        if contents is not None:
-            _body["contents"] = contents
-        if name is not None:
-            _body["name"] = name
-        if chunk_size is not None:
-            _body["chunk_size"] = chunk_size
-        if chunk_overlap is not None:
-            _body["chunk_overlap"] = chunk_overlap
-        if skip_embedding_generation is not None:
-            _body["skip_embedding_generation"] = skip_embedding_generation
-        if overwrite_file_id is not None:
-            _body["overwrite_file_id"] = overwrite_file_id
-        if embedding_model is not None:
-            _body["embedding_model"] = embedding_model
-        if generate_sparse_vectors is not None:
-            _body["generate_sparse_vectors"] = generate_sparse_vectors
+        if pagination is not None:
+            _body["pagination"] = pagination
+        if order_by is not None:
+            _body["order_by"] = order_by
+        if order_dir is not None:
+            _body["order_dir"] = order_dir
+        if filters is not None:
+            _body["filters"] = filters
+        if include_raw_file is not None:
+            _body["include_raw_file"] = include_raw_file
+        if include_parsed_text_file is not None:
+            _body["include_parsed_text_file"] = include_parsed_text_file
+        if include_additional_files is not None:
+            _body["include_additional_files"] = include_additional_files
         args.body = _body
         return args
 
-    async def _aupload_text_oapg(
+    async def _aquery_user_files_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Create Raw Text
+        User Files V2
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -175,20 +192,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/upload_text',
+            path_template='/user_files_v2',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_raw_text_input.serialize(body, content_type)
+        serialized_data = request_body_organization_user_files_to_sync_query_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -252,28 +269,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _upload_text_oapg(
+    def _query_user_files_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Create Raw Text
+        User Files V2
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -289,20 +306,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/upload_text',
+            path_template='/user_files_v2',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_raw_text_input.serialize(body, content_type)
+        serialized_data = request_body_organization_user_files_to_sync_query_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -335,189 +352,177 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class UploadTextRaw(BaseApi):
+class QueryUserFilesRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def aupload_text(
+    async def aquery_user_files(
         self,
-        contents: str,
-        name: typing.Optional[typing.Optional[str]] = None,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        pagination: typing.Optional[Pagination] = None,
+        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_dir: typing.Optional[OrderDir] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
+        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
+        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._upload_text_mapped_args(
-            contents=contents,
-            name=name,
-            chunk_size=chunk_size,
-            chunk_overlap=chunk_overlap,
-            skip_embedding_generation=skip_embedding_generation,
-            overwrite_file_id=overwrite_file_id,
-            embedding_model=embedding_model,
-            generate_sparse_vectors=generate_sparse_vectors,
+        args = self._query_user_files_mapped_args(
+            pagination=pagination,
+            order_by=order_by,
+            order_dir=order_dir,
+            filters=filters,
+            include_raw_file=include_raw_file,
+            include_parsed_text_file=include_parsed_text_file,
+            include_additional_files=include_additional_files,
         )
-        return await self._aupload_text_oapg(
+        return await self._aquery_user_files_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def upload_text(
+    def query_user_files(
         self,
-        contents: str,
-        name: typing.Optional[typing.Optional[str]] = None,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        pagination: typing.Optional[Pagination] = None,
+        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_dir: typing.Optional[OrderDir] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
+        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
+        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._upload_text_mapped_args(
-            contents=contents,
-            name=name,
-            chunk_size=chunk_size,
-            chunk_overlap=chunk_overlap,
-            skip_embedding_generation=skip_embedding_generation,
-            overwrite_file_id=overwrite_file_id,
-            embedding_model=embedding_model,
-            generate_sparse_vectors=generate_sparse_vectors,
+        args = self._query_user_files_mapped_args(
+            pagination=pagination,
+            order_by=order_by,
+            order_dir=order_dir,
+            filters=filters,
+            include_raw_file=include_raw_file,
+            include_parsed_text_file=include_parsed_text_file,
+            include_additional_files=include_additional_files,
         )
-        return self._upload_text_oapg(
+        return self._query_user_files_oapg(
             body=args.body,
         )
 
-class UploadText(BaseApi):
+class QueryUserFiles(BaseApi):
 
-    async def aupload_text(
+    async def aquery_user_files(
         self,
-        contents: str,
-        name: typing.Optional[typing.Optional[str]] = None,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        pagination: typing.Optional[Pagination] = None,
+        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_dir: typing.Optional[OrderDir] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
+        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
+        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
         validate: bool = False,
         **kwargs,
-    ) -> UserFilePydantic:
-        raw_response = await self.raw.aupload_text(
-            contents=contents,
-            name=name,
-            chunk_size=chunk_size,
-            chunk_overlap=chunk_overlap,
-            skip_embedding_generation=skip_embedding_generation,
-            overwrite_file_id=overwrite_file_id,
-            embedding_model=embedding_model,
-            generate_sparse_vectors=generate_sparse_vectors,
+    ) -> UserFilesV2Pydantic:
+        raw_response = await self.raw.aquery_user_files(
+            pagination=pagination,
+            order_by=order_by,
+            order_dir=order_dir,
+            filters=filters,
+            include_raw_file=include_raw_file,
+            include_parsed_text_file=include_parsed_text_file,
+            include_additional_files=include_additional_files,
             **kwargs,
         )
         if validate:
-            return UserFilePydantic(**raw_response.body)
-        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
+            return UserFilesV2Pydantic(**raw_response.body)
+        return api_client.construct_model_instance(UserFilesV2Pydantic, raw_response.body)
     
     
-    def upload_text(
+    def query_user_files(
         self,
-        contents: str,
-        name: typing.Optional[typing.Optional[str]] = None,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        pagination: typing.Optional[Pagination] = None,
+        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_dir: typing.Optional[OrderDir] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
+        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
+        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
         validate: bool = False,
-    ) -> UserFilePydantic:
-        raw_response = self.raw.upload_text(
-            contents=contents,
-            name=name,
-            chunk_size=chunk_size,
-            chunk_overlap=chunk_overlap,
-            skip_embedding_generation=skip_embedding_generation,
-            overwrite_file_id=overwrite_file_id,
-            embedding_model=embedding_model,
-            generate_sparse_vectors=generate_sparse_vectors,
+    ) -> UserFilesV2Pydantic:
+        raw_response = self.raw.query_user_files(
+            pagination=pagination,
+            order_by=order_by,
+            order_dir=order_dir,
+            filters=filters,
+            include_raw_file=include_raw_file,
+            include_parsed_text_file=include_parsed_text_file,
+            include_additional_files=include_additional_files,
         )
         if validate:
-            return UserFilePydantic(**raw_response.body)
-        return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
+            return UserFilesV2Pydantic(**raw_response.body)
+        return api_client.construct_model_instance(UserFilesV2Pydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        contents: str,
-        name: typing.Optional[typing.Optional[str]] = None,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        pagination: typing.Optional[Pagination] = None,
+        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_dir: typing.Optional[OrderDir] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
+        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
+        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._upload_text_mapped_args(
-            contents=contents,
-            name=name,
-            chunk_size=chunk_size,
-            chunk_overlap=chunk_overlap,
-            skip_embedding_generation=skip_embedding_generation,
-            overwrite_file_id=overwrite_file_id,
-            embedding_model=embedding_model,
-            generate_sparse_vectors=generate_sparse_vectors,
+        args = self._query_user_files_mapped_args(
+            pagination=pagination,
+            order_by=order_by,
+            order_dir=order_dir,
+            filters=filters,
+            include_raw_file=include_raw_file,
+            include_parsed_text_file=include_parsed_text_file,
+            include_additional_files=include_additional_files,
         )
-        return await self._aupload_text_oapg(
+        return await self._aquery_user_files_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        contents: str,
-        name: typing.Optional[typing.Optional[str]] = None,
-        chunk_size: typing.Optional[typing.Optional[int]] = None,
-        chunk_overlap: typing.Optional[typing.Optional[int]] = None,
-        skip_embedding_generation: typing.Optional[bool] = None,
-        overwrite_file_id: typing.Optional[typing.Optional[int]] = None,
-        embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = None,
-        generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = None,
+        pagination: typing.Optional[Pagination] = None,
+        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_dir: typing.Optional[OrderDir] = None,
+        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
+        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
+        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
+        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._upload_text_mapped_args(
-            contents=contents,
-            name=name,
-            chunk_size=chunk_size,
-            chunk_overlap=chunk_overlap,
-            skip_embedding_generation=skip_embedding_generation,
-            overwrite_file_id=overwrite_file_id,
-            embedding_model=embedding_model,
-            generate_sparse_vectors=generate_sparse_vectors,
+        args = self._query_user_files_mapped_args(
+            pagination=pagination,
+            order_by=order_by,
+            order_dir=order_dir,
+            filters=filters,
+            include_raw_file=include_raw_file,
+            include_parsed_text_file=include_parsed_text_file,
+            include_additional_files=include_additional_files,
         )
-        return self._upload_text_oapg(
+        return self._query_user_files_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/uploadfile/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/uploadfile/post.pyi`

 * *Files 6% similar despite different names*

```diff
@@ -31,29 +31,30 @@
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.text_embedding_generators import TextEmbeddingGenerators as TextEmbeddingGeneratorsSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
 from carbon.model.user_file import UserFile as UserFileSchema
+from carbon.model.file_content_types_nullable import FileContentTypesNullable as FileContentTypesNullableSchema
 from carbon.model.body_create_upload_file_uploadfile_post import BodyCreateUploadFileUploadfilePost as BodyCreateUploadFileUploadfilePostSchema
 
 from carbon.type.http_validation_error import HTTPValidationError
+from carbon.type.file_content_types_nullable import FileContentTypesNullable
 from carbon.type.user_file import UserFile
 from carbon.type.body_create_upload_file_uploadfile_post import BodyCreateUploadFileUploadfilePost
 from carbon.type.text_embedding_generators import TextEmbeddingGenerators
 
 from ...api_client import Dictionary
+from carbon.pydantic.file_content_types_nullable import FileContentTypesNullable as FileContentTypesNullablePydantic
 from carbon.pydantic.user_file import UserFile as UserFilePydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.body_create_upload_file_uploadfile_post import BodyCreateUploadFileUploadfilePost as BodyCreateUploadFileUploadfilePostPydantic
 from carbon.pydantic.text_embedding_generators import TextEmbeddingGenerators as TextEmbeddingGeneratorsPydantic
 
-from . import path
-
 # Query params
 
 
 class ChunkSizeSchema(
     schemas.IntBase,
     schemas.NoneBase,
     schemas.Schema,
@@ -113,14 +114,17 @@
         _configuration: typing.Optional[schemas.Configuration] = None,
     ) -> 'MaxItemsPerChunkSchema':
         return super().__new__(
             cls,
             *args,
             _configuration=_configuration,
         )
+ParsePdfTablesWithOcrSchema = schemas.BoolSchema
+DetectAudioLanguageSchema = schemas.BoolSchema
+MediaTypeSchema = FileContentTypesNullableSchema
 RequestRequiredQueryParams = typing_extensions.TypedDict(
     'RequestRequiredQueryParams',
     {
     }
 )
 RequestOptionalQueryParams = typing_extensions.TypedDict(
     'RequestOptionalQueryParams',
@@ -130,14 +134,17 @@
         'skip_embedding_generation': typing.Union[SkipEmbeddingGenerationSchema, bool, ],
         'set_page_as_boundary': typing.Union[SetPageAsBoundarySchema, bool, ],
         'embedding_model': typing.Union[EmbeddingModelSchema, ],
         'use_ocr': typing.Union[UseOcrSchema, bool, ],
         'generate_sparse_vectors': typing.Union[GenerateSparseVectorsSchema, bool, ],
         'prepend_filename_to_chunks': typing.Union[PrependFilenameToChunksSchema, bool, ],
         'max_items_per_chunk': typing.Union[MaxItemsPerChunkSchema, None, decimal.Decimal, int, ],
+        'parse_pdf_tables_with_ocr': typing.Union[ParsePdfTablesWithOcrSchema, bool, ],
+        'detect_audio_language': typing.Union[DetectAudioLanguageSchema, bool, ],
+        'media_type': typing.Union[MediaTypeSchema, ],
     },
     total=False
 )
 
 
 class RequestQueryParams(RequestRequiredQueryParams, RequestOptionalQueryParams):
     pass
@@ -193,30 +200,43 @@
 )
 request_query_max_items_per_chunk = api_client.QueryParameter(
     name="max_items_per_chunk",
     style=api_client.ParameterStyle.FORM,
     schema=MaxItemsPerChunkSchema,
     explode=True,
 )
+request_query_parse_pdf_tables_with_ocr = api_client.QueryParameter(
+    name="parse_pdf_tables_with_ocr",
+    style=api_client.ParameterStyle.FORM,
+    schema=ParsePdfTablesWithOcrSchema,
+    explode=True,
+)
+request_query_detect_audio_language = api_client.QueryParameter(
+    name="detect_audio_language",
+    style=api_client.ParameterStyle.FORM,
+    schema=DetectAudioLanguageSchema,
+    explode=True,
+)
+request_query_media_type = api_client.QueryParameter(
+    name="media_type",
+    style=api_client.ParameterStyle.FORM,
+    schema=FileContentTypesNullableSchema,
+    explode=True,
+)
 # body param
 SchemaForRequestBodyMultipartFormData = BodyCreateUploadFileUploadfilePostSchema
 
 
 request_body_body_create_upload_file_uploadfile_post = api_client.RequestBody(
     content={
         'multipart/form-data': api_client.MediaType(
             schema=SchemaForRequestBodyMultipartFormData),
     },
     required=True,
 )
-_auth = [
-    'accessToken',
-    'apiKey',
-    'customerId',
-]
 SchemaFor200ResponseBodyApplicationJson = UserFileSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
     body: UserFile
 
@@ -251,18 +271,14 @@
     response_cls=ApiResponseFor422,
     response_cls_async=ApiResponseFor422Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor422ResponseBodyApplicationJson),
     },
 )
-_status_code_to_response = {
-    '200': _response_for_200,
-    '422': _response_for_422,
-}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
@@ -274,14 +290,17 @@
         skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[TextEmbeddingGenerators] = None,
         use_ocr: typing.Optional[bool] = None,
         generate_sparse_vectors: typing.Optional[bool] = None,
         prepend_filename_to_chunks: typing.Optional[bool] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
+        media_type: typing.Optional[FileContentTypesNullable] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _query_params = {}
         _body = {}
         if file is not None:
             _body["file"] = file
         args.body = _body
@@ -299,14 +318,20 @@
             _query_params["use_ocr"] = use_ocr
         if generate_sparse_vectors is not None:
             _query_params["generate_sparse_vectors"] = generate_sparse_vectors
         if prepend_filename_to_chunks is not None:
             _query_params["prepend_filename_to_chunks"] = prepend_filename_to_chunks
         if max_items_per_chunk is not None:
             _query_params["max_items_per_chunk"] = max_items_per_chunk
+        if parse_pdf_tables_with_ocr is not None:
+            _query_params["parse_pdf_tables_with_ocr"] = parse_pdf_tables_with_ocr
+        if detect_audio_language is not None:
+            _query_params["detect_audio_language"] = detect_audio_language
+        if media_type is not None:
+            _query_params["media_type"] = media_type
         args.query = _query_params
         return args
 
     async def _aupload_oapg(
         self,
         body: typing.Any = None,
             query_params: typing.Optional[dict] = {},
@@ -337,14 +362,17 @@
             request_query_skip_embedding_generation,
             request_query_set_page_as_boundary,
             request_query_embedding_model,
             request_query_use_ocr,
             request_query_generate_sparse_vectors,
             request_query_prepend_filename_to_chunks,
             request_query_max_items_per_chunk,
+            request_query_parse_pdf_tables_with_ocr,
+            request_query_detect_audio_language,
+            request_query_media_type,
         ):
             parameter_data = query_params.get(parameter.name, schemas.unset)
             if parameter_data is schemas.unset:
                 continue
             if prefix_separator_iterator is None:
                 prefix_separator_iterator = parameter.get_prefix_separator_iterator()
             serialized_data = parameter.serialize(parameter_data, prefix_separator_iterator)
@@ -475,14 +503,17 @@
             request_query_skip_embedding_generation,
             request_query_set_page_as_boundary,
             request_query_embedding_model,
             request_query_use_ocr,
             request_query_generate_sparse_vectors,
             request_query_prepend_filename_to_chunks,
             request_query_max_items_per_chunk,
+            request_query_parse_pdf_tables_with_ocr,
+            request_query_detect_audio_language,
+            request_query_media_type,
         ):
             parameter_data = query_params.get(parameter.name, schemas.unset)
             if parameter_data is schemas.unset:
                 continue
             if prefix_separator_iterator is None:
                 prefix_separator_iterator = parameter.get_prefix_separator_iterator()
             serialized_data = parameter.serialize(parameter_data, prefix_separator_iterator)
@@ -564,14 +595,17 @@
         skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[TextEmbeddingGenerators] = None,
         use_ocr: typing.Optional[bool] = None,
         generate_sparse_vectors: typing.Optional[bool] = None,
         prepend_filename_to_chunks: typing.Optional[bool] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
+        media_type: typing.Optional[FileContentTypesNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         args = self._upload_mapped_args(
@@ -581,14 +615,17 @@
             skip_embedding_generation=skip_embedding_generation,
             set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             use_ocr=use_ocr,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
+            media_type=media_type,
         )
         return await self._aupload_oapg(
             body=args.body,
             query_params=args.query,
             **kwargs,
         )
     
@@ -600,14 +637,17 @@
         skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[TextEmbeddingGenerators] = None,
         use_ocr: typing.Optional[bool] = None,
         generate_sparse_vectors: typing.Optional[bool] = None,
         prepend_filename_to_chunks: typing.Optional[bool] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
+        media_type: typing.Optional[FileContentTypesNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._upload_mapped_args(
             file=file,
             chunk_size=chunk_size,
@@ -615,14 +655,17 @@
             skip_embedding_generation=skip_embedding_generation,
             set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             use_ocr=use_ocr,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
+            media_type=media_type,
         )
         return self._upload_oapg(
             body=args.body,
             query_params=args.query,
         )
 
 class Upload(BaseApi):
@@ -635,28 +678,34 @@
         skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[TextEmbeddingGenerators] = None,
         use_ocr: typing.Optional[bool] = None,
         generate_sparse_vectors: typing.Optional[bool] = None,
         prepend_filename_to_chunks: typing.Optional[bool] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
+        media_type: typing.Optional[FileContentTypesNullable] = None,
         validate: bool = False,
         **kwargs,
     ) -> UserFilePydantic:
         raw_response = await self.raw.aupload(
             file=file,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             use_ocr=use_ocr,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
+            media_type=media_type,
             **kwargs,
         )
         if validate:
             return UserFilePydantic(**raw_response.body)
         return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
     
     
@@ -668,27 +717,33 @@
         skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[TextEmbeddingGenerators] = None,
         use_ocr: typing.Optional[bool] = None,
         generate_sparse_vectors: typing.Optional[bool] = None,
         prepend_filename_to_chunks: typing.Optional[bool] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
+        media_type: typing.Optional[FileContentTypesNullable] = None,
         validate: bool = False,
     ) -> UserFilePydantic:
         raw_response = self.raw.upload(
             file=file,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             use_ocr=use_ocr,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
+            media_type=media_type,
         )
         if validate:
             return UserFilePydantic(**raw_response.body)
         return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
@@ -702,14 +757,17 @@
         skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[TextEmbeddingGenerators] = None,
         use_ocr: typing.Optional[bool] = None,
         generate_sparse_vectors: typing.Optional[bool] = None,
         prepend_filename_to_chunks: typing.Optional[bool] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
+        media_type: typing.Optional[FileContentTypesNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         args = self._upload_mapped_args(
@@ -719,14 +777,17 @@
             skip_embedding_generation=skip_embedding_generation,
             set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             use_ocr=use_ocr,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
+            media_type=media_type,
         )
         return await self._aupload_oapg(
             body=args.body,
             query_params=args.query,
             **kwargs,
         )
     
@@ -738,14 +799,17 @@
         skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[TextEmbeddingGenerators] = None,
         use_ocr: typing.Optional[bool] = None,
         generate_sparse_vectors: typing.Optional[bool] = None,
         prepend_filename_to_chunks: typing.Optional[bool] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
+        media_type: typing.Optional[FileContentTypesNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._upload_mapped_args(
             file=file,
             chunk_size=chunk_size,
@@ -753,13 +817,16 @@
             skip_embedding_generation=skip_embedding_generation,
             set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             use_ocr=use_ocr,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
+            media_type=media_type,
         )
         return self._upload_oapg(
             body=args.body,
             query_params=args.query,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/uploadfile/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/uploadfile/post.py`

 * *Files 6% similar despite different names*

```diff
@@ -31,27 +31,32 @@
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.text_embedding_generators import TextEmbeddingGenerators as TextEmbeddingGeneratorsSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
 from carbon.model.user_file import UserFile as UserFileSchema
+from carbon.model.file_content_types_nullable import FileContentTypesNullable as FileContentTypesNullableSchema
 from carbon.model.body_create_upload_file_uploadfile_post import BodyCreateUploadFileUploadfilePost as BodyCreateUploadFileUploadfilePostSchema
 
 from carbon.type.http_validation_error import HTTPValidationError
+from carbon.type.file_content_types_nullable import FileContentTypesNullable
 from carbon.type.user_file import UserFile
 from carbon.type.body_create_upload_file_uploadfile_post import BodyCreateUploadFileUploadfilePost
 from carbon.type.text_embedding_generators import TextEmbeddingGenerators
 
 from ...api_client import Dictionary
+from carbon.pydantic.file_content_types_nullable import FileContentTypesNullable as FileContentTypesNullablePydantic
 from carbon.pydantic.user_file import UserFile as UserFilePydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
 from carbon.pydantic.body_create_upload_file_uploadfile_post import BodyCreateUploadFileUploadfilePost as BodyCreateUploadFileUploadfilePostPydantic
 from carbon.pydantic.text_embedding_generators import TextEmbeddingGenerators as TextEmbeddingGeneratorsPydantic
 
+from . import path
+
 # Query params
 
 
 class ChunkSizeSchema(
     schemas.IntBase,
     schemas.NoneBase,
     schemas.Schema,
@@ -111,14 +116,17 @@
         _configuration: typing.Optional[schemas.Configuration] = None,
     ) -> 'MaxItemsPerChunkSchema':
         return super().__new__(
             cls,
             *args,
             _configuration=_configuration,
         )
+ParsePdfTablesWithOcrSchema = schemas.BoolSchema
+DetectAudioLanguageSchema = schemas.BoolSchema
+MediaTypeSchema = FileContentTypesNullableSchema
 RequestRequiredQueryParams = typing_extensions.TypedDict(
     'RequestRequiredQueryParams',
     {
     }
 )
 RequestOptionalQueryParams = typing_extensions.TypedDict(
     'RequestOptionalQueryParams',
@@ -128,14 +136,17 @@
         'skip_embedding_generation': typing.Union[SkipEmbeddingGenerationSchema, bool, ],
         'set_page_as_boundary': typing.Union[SetPageAsBoundarySchema, bool, ],
         'embedding_model': typing.Union[EmbeddingModelSchema, ],
         'use_ocr': typing.Union[UseOcrSchema, bool, ],
         'generate_sparse_vectors': typing.Union[GenerateSparseVectorsSchema, bool, ],
         'prepend_filename_to_chunks': typing.Union[PrependFilenameToChunksSchema, bool, ],
         'max_items_per_chunk': typing.Union[MaxItemsPerChunkSchema, None, decimal.Decimal, int, ],
+        'parse_pdf_tables_with_ocr': typing.Union[ParsePdfTablesWithOcrSchema, bool, ],
+        'detect_audio_language': typing.Union[DetectAudioLanguageSchema, bool, ],
+        'media_type': typing.Union[MediaTypeSchema, ],
     },
     total=False
 )
 
 
 class RequestQueryParams(RequestRequiredQueryParams, RequestOptionalQueryParams):
     pass
@@ -191,25 +202,48 @@
 )
 request_query_max_items_per_chunk = api_client.QueryParameter(
     name="max_items_per_chunk",
     style=api_client.ParameterStyle.FORM,
     schema=MaxItemsPerChunkSchema,
     explode=True,
 )
+request_query_parse_pdf_tables_with_ocr = api_client.QueryParameter(
+    name="parse_pdf_tables_with_ocr",
+    style=api_client.ParameterStyle.FORM,
+    schema=ParsePdfTablesWithOcrSchema,
+    explode=True,
+)
+request_query_detect_audio_language = api_client.QueryParameter(
+    name="detect_audio_language",
+    style=api_client.ParameterStyle.FORM,
+    schema=DetectAudioLanguageSchema,
+    explode=True,
+)
+request_query_media_type = api_client.QueryParameter(
+    name="media_type",
+    style=api_client.ParameterStyle.FORM,
+    schema=FileContentTypesNullableSchema,
+    explode=True,
+)
 # body param
 SchemaForRequestBodyMultipartFormData = BodyCreateUploadFileUploadfilePostSchema
 
 
 request_body_body_create_upload_file_uploadfile_post = api_client.RequestBody(
     content={
         'multipart/form-data': api_client.MediaType(
             schema=SchemaForRequestBodyMultipartFormData),
     },
     required=True,
 )
+_auth = [
+    'accessToken',
+    'apiKey',
+    'customerId',
+]
 SchemaFor200ResponseBodyApplicationJson = UserFileSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
     body: UserFile
 
@@ -244,14 +278,18 @@
     response_cls=ApiResponseFor422,
     response_cls_async=ApiResponseFor422Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor422ResponseBodyApplicationJson),
     },
 )
+_status_code_to_response = {
+    '200': _response_for_200,
+    '422': _response_for_422,
+}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
@@ -263,14 +301,17 @@
         skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[TextEmbeddingGenerators] = None,
         use_ocr: typing.Optional[bool] = None,
         generate_sparse_vectors: typing.Optional[bool] = None,
         prepend_filename_to_chunks: typing.Optional[bool] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
+        media_type: typing.Optional[FileContentTypesNullable] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _query_params = {}
         _body = {}
         if file is not None:
             _body["file"] = file
         args.body = _body
@@ -288,14 +329,20 @@
             _query_params["use_ocr"] = use_ocr
         if generate_sparse_vectors is not None:
             _query_params["generate_sparse_vectors"] = generate_sparse_vectors
         if prepend_filename_to_chunks is not None:
             _query_params["prepend_filename_to_chunks"] = prepend_filename_to_chunks
         if max_items_per_chunk is not None:
             _query_params["max_items_per_chunk"] = max_items_per_chunk
+        if parse_pdf_tables_with_ocr is not None:
+            _query_params["parse_pdf_tables_with_ocr"] = parse_pdf_tables_with_ocr
+        if detect_audio_language is not None:
+            _query_params["detect_audio_language"] = detect_audio_language
+        if media_type is not None:
+            _query_params["media_type"] = media_type
         args.query = _query_params
         return args
 
     async def _aupload_oapg(
         self,
         body: typing.Any = None,
             query_params: typing.Optional[dict] = {},
@@ -326,14 +373,17 @@
             request_query_skip_embedding_generation,
             request_query_set_page_as_boundary,
             request_query_embedding_model,
             request_query_use_ocr,
             request_query_generate_sparse_vectors,
             request_query_prepend_filename_to_chunks,
             request_query_max_items_per_chunk,
+            request_query_parse_pdf_tables_with_ocr,
+            request_query_detect_audio_language,
+            request_query_media_type,
         ):
             parameter_data = query_params.get(parameter.name, schemas.unset)
             if parameter_data is schemas.unset:
                 continue
             if prefix_separator_iterator is None:
                 prefix_separator_iterator = parameter.get_prefix_separator_iterator()
             serialized_data = parameter.serialize(parameter_data, prefix_separator_iterator)
@@ -464,14 +514,17 @@
             request_query_skip_embedding_generation,
             request_query_set_page_as_boundary,
             request_query_embedding_model,
             request_query_use_ocr,
             request_query_generate_sparse_vectors,
             request_query_prepend_filename_to_chunks,
             request_query_max_items_per_chunk,
+            request_query_parse_pdf_tables_with_ocr,
+            request_query_detect_audio_language,
+            request_query_media_type,
         ):
             parameter_data = query_params.get(parameter.name, schemas.unset)
             if parameter_data is schemas.unset:
                 continue
             if prefix_separator_iterator is None:
                 prefix_separator_iterator = parameter.get_prefix_separator_iterator()
             serialized_data = parameter.serialize(parameter_data, prefix_separator_iterator)
@@ -553,14 +606,17 @@
         skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[TextEmbeddingGenerators] = None,
         use_ocr: typing.Optional[bool] = None,
         generate_sparse_vectors: typing.Optional[bool] = None,
         prepend_filename_to_chunks: typing.Optional[bool] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
+        media_type: typing.Optional[FileContentTypesNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         args = self._upload_mapped_args(
@@ -570,14 +626,17 @@
             skip_embedding_generation=skip_embedding_generation,
             set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             use_ocr=use_ocr,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
+            media_type=media_type,
         )
         return await self._aupload_oapg(
             body=args.body,
             query_params=args.query,
             **kwargs,
         )
     
@@ -589,14 +648,17 @@
         skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[TextEmbeddingGenerators] = None,
         use_ocr: typing.Optional[bool] = None,
         generate_sparse_vectors: typing.Optional[bool] = None,
         prepend_filename_to_chunks: typing.Optional[bool] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
+        media_type: typing.Optional[FileContentTypesNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._upload_mapped_args(
             file=file,
             chunk_size=chunk_size,
@@ -604,14 +666,17 @@
             skip_embedding_generation=skip_embedding_generation,
             set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             use_ocr=use_ocr,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
+            media_type=media_type,
         )
         return self._upload_oapg(
             body=args.body,
             query_params=args.query,
         )
 
 class Upload(BaseApi):
@@ -624,28 +689,34 @@
         skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[TextEmbeddingGenerators] = None,
         use_ocr: typing.Optional[bool] = None,
         generate_sparse_vectors: typing.Optional[bool] = None,
         prepend_filename_to_chunks: typing.Optional[bool] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
+        media_type: typing.Optional[FileContentTypesNullable] = None,
         validate: bool = False,
         **kwargs,
     ) -> UserFilePydantic:
         raw_response = await self.raw.aupload(
             file=file,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             use_ocr=use_ocr,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
+            media_type=media_type,
             **kwargs,
         )
         if validate:
             return UserFilePydantic(**raw_response.body)
         return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
     
     
@@ -657,27 +728,33 @@
         skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[TextEmbeddingGenerators] = None,
         use_ocr: typing.Optional[bool] = None,
         generate_sparse_vectors: typing.Optional[bool] = None,
         prepend_filename_to_chunks: typing.Optional[bool] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
+        media_type: typing.Optional[FileContentTypesNullable] = None,
         validate: bool = False,
     ) -> UserFilePydantic:
         raw_response = self.raw.upload(
             file=file,
             chunk_size=chunk_size,
             chunk_overlap=chunk_overlap,
             skip_embedding_generation=skip_embedding_generation,
             set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             use_ocr=use_ocr,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
+            media_type=media_type,
         )
         if validate:
             return UserFilePydantic(**raw_response.body)
         return api_client.construct_model_instance(UserFilePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
@@ -691,14 +768,17 @@
         skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[TextEmbeddingGenerators] = None,
         use_ocr: typing.Optional[bool] = None,
         generate_sparse_vectors: typing.Optional[bool] = None,
         prepend_filename_to_chunks: typing.Optional[bool] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
+        media_type: typing.Optional[FileContentTypesNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         args = self._upload_mapped_args(
@@ -708,14 +788,17 @@
             skip_embedding_generation=skip_embedding_generation,
             set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             use_ocr=use_ocr,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
+            media_type=media_type,
         )
         return await self._aupload_oapg(
             body=args.body,
             query_params=args.query,
             **kwargs,
         )
     
@@ -727,14 +810,17 @@
         skip_embedding_generation: typing.Optional[bool] = None,
         set_page_as_boundary: typing.Optional[bool] = None,
         embedding_model: typing.Optional[TextEmbeddingGenerators] = None,
         use_ocr: typing.Optional[bool] = None,
         generate_sparse_vectors: typing.Optional[bool] = None,
         prepend_filename_to_chunks: typing.Optional[bool] = None,
         max_items_per_chunk: typing.Optional[typing.Optional[int]] = None,
+        parse_pdf_tables_with_ocr: typing.Optional[bool] = None,
+        detect_audio_language: typing.Optional[bool] = None,
+        media_type: typing.Optional[FileContentTypesNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         args = self._upload_mapped_args(
             file=file,
             chunk_size=chunk_size,
@@ -742,13 +828,16 @@
             skip_embedding_generation=skip_embedding_generation,
             set_page_as_boundary=set_page_as_boundary,
             embedding_model=embedding_model,
             use_ocr=use_ocr,
             generate_sparse_vectors=generate_sparse_vectors,
             prepend_filename_to_chunks=prepend_filename_to_chunks,
             max_items_per_chunk=max_items_per_chunk,
+            parse_pdf_tables_with_ocr=parse_pdf_tables_with_ocr,
+            detect_audio_language=detect_audio_language,
+            media_type=media_type,
         )
         return self._upload_oapg(
             body=args.body,
             query_params=args.query,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/user/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/user/post.py`

 * *Files 2% similar despite different names*

```diff
@@ -55,15 +55,15 @@
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
 _auth = [
-    'accessToken',
+    'apiKey',
 ]
 SchemaFor200ResponseBodyApplicationJson = UserResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
     body: UserResponse
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/user/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/user/post.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/user_data_sources/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/user_data_sources/post.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/user_data_sources/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/user_data_sources/post.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/user_files/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/user_files/post.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/user_files/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/user_files/post.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/user_files_v2/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/integrations_items_list/post.pyi`

 * *Files 26% similar despite different names*

```diff
@@ -30,66 +30,59 @@
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
 from carbon.model.pagination import Pagination as PaginationSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.organization_user_files_to_sync_order_by_types import OrganizationUserFilesToSyncOrderByTypes as OrganizationUserFilesToSyncOrderByTypesSchema
-from carbon.model.organization_user_files_to_sync_query_input import OrganizationUserFilesToSyncQueryInput as OrganizationUserFilesToSyncQueryInputSchema
-from carbon.model.organization_user_files_to_sync_filters import OrganizationUserFilesToSyncFilters as OrganizationUserFilesToSyncFiltersSchema
-from carbon.model.user_files_v2 import UserFilesV2 as UserFilesV2Schema
-from carbon.model.order_dir import OrderDir as OrderDirSchema
+from carbon.model.list_data_source_items_request import ListDataSourceItemsRequest as ListDataSourceItemsRequestSchema
+from carbon.model.order_dir_v2 import OrderDirV2 as OrderDirV2Schema
+from carbon.model.external_source_items_order_by import ExternalSourceItemsOrderBy as ExternalSourceItemsOrderBySchema
+from carbon.model.list_data_source_items_response import ListDataSourceItemsResponse as ListDataSourceItemsResponseSchema
+from carbon.model.list_items_filters_nullable import ListItemsFiltersNullable as ListItemsFiltersNullableSchema
 
 from carbon.type.http_validation_error import HTTPValidationError
+from carbon.type.order_dir_v2 import OrderDirV2
 from carbon.type.pagination import Pagination
-from carbon.type.organization_user_files_to_sync_order_by_types import OrganizationUserFilesToSyncOrderByTypes
-from carbon.type.organization_user_files_to_sync_filters import OrganizationUserFilesToSyncFilters
-from carbon.type.user_files_v2 import UserFilesV2
-from carbon.type.order_dir import OrderDir
-from carbon.type.organization_user_files_to_sync_query_input import OrganizationUserFilesToSyncQueryInput
+from carbon.type.list_items_filters_nullable import ListItemsFiltersNullable
+from carbon.type.list_data_source_items_request import ListDataSourceItemsRequest
+from carbon.type.external_source_items_order_by import ExternalSourceItemsOrderBy
+from carbon.type.list_data_source_items_response import ListDataSourceItemsResponse
 
 from ...api_client import Dictionary
-from carbon.pydantic.organization_user_files_to_sync_filters import OrganizationUserFilesToSyncFilters as OrganizationUserFilesToSyncFiltersPydantic
+from carbon.pydantic.order_dir_v2 import OrderDirV2 as OrderDirV2Pydantic
+from carbon.pydantic.external_source_items_order_by import ExternalSourceItemsOrderBy as ExternalSourceItemsOrderByPydantic
+from carbon.pydantic.list_items_filters_nullable import ListItemsFiltersNullable as ListItemsFiltersNullablePydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
-from carbon.pydantic.organization_user_files_to_sync_query_input import OrganizationUserFilesToSyncQueryInput as OrganizationUserFilesToSyncQueryInputPydantic
-from carbon.pydantic.order_dir import OrderDir as OrderDirPydantic
-from carbon.pydantic.user_files_v2 import UserFilesV2 as UserFilesV2Pydantic
-from carbon.pydantic.organization_user_files_to_sync_order_by_types import OrganizationUserFilesToSyncOrderByTypes as OrganizationUserFilesToSyncOrderByTypesPydantic
+from carbon.pydantic.list_data_source_items_response import ListDataSourceItemsResponse as ListDataSourceItemsResponsePydantic
+from carbon.pydantic.list_data_source_items_request import ListDataSourceItemsRequest as ListDataSourceItemsRequestPydantic
 from carbon.pydantic.pagination import Pagination as PaginationPydantic
 
-from . import path
-
 # body param
-SchemaForRequestBodyApplicationJson = OrganizationUserFilesToSyncQueryInputSchema
+SchemaForRequestBodyApplicationJson = ListDataSourceItemsRequestSchema
 
 
-request_body_organization_user_files_to_sync_query_input = api_client.RequestBody(
+request_body_list_data_source_items_request = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
-_auth = [
-    'accessToken',
-    'apiKey',
-    'customerId',
-]
-SchemaFor200ResponseBodyApplicationJson = UserFilesV2Schema
+SchemaFor200ResponseBodyApplicationJson = ListDataSourceItemsResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
-    body: UserFilesV2
+    body: ListDataSourceItemsResponse
 
 
 @dataclass
 class ApiResponseFor200Async(api_client.AsyncApiResponse):
-    body: UserFilesV2
+    body: ListDataSourceItemsResponse
 
 
 _response_for_200 = api_client.OpenApiResponse(
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
@@ -113,70 +106,63 @@
     response_cls=ApiResponseFor422,
     response_cls_async=ApiResponseFor422Async,
     content={
         'application/json': api_client.MediaType(
             schema=SchemaFor422ResponseBodyApplicationJson),
     },
 )
-_status_code_to_response = {
-    '200': _response_for_200,
-    '422': _response_for_422,
-}
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _query_user_files_mapped_args(
+    def _list_data_source_items_mapped_args(
         self,
+        data_source_id: int,
+        parent_id: typing.Optional[typing.Optional[str]] = None,
+        filters: typing.Optional[ListItemsFiltersNullable] = None,
         pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
-        order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
-        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
-        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
-        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
+        order_by: typing.Optional[ExternalSourceItemsOrderBy] = None,
+        order_dir: typing.Optional[OrderDirV2] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
+        if data_source_id is not None:
+            _body["data_source_id"] = data_source_id
+        if parent_id is not None:
+            _body["parent_id"] = parent_id
+        if filters is not None:
+            _body["filters"] = filters
         if pagination is not None:
             _body["pagination"] = pagination
         if order_by is not None:
             _body["order_by"] = order_by
         if order_dir is not None:
             _body["order_dir"] = order_dir
-        if filters is not None:
-            _body["filters"] = filters
-        if include_raw_file is not None:
-            _body["include_raw_file"] = include_raw_file
-        if include_parsed_text_file is not None:
-            _body["include_parsed_text_file"] = include_parsed_text_file
-        if include_additional_files is not None:
-            _body["include_additional_files"] = include_additional_files
         args.body = _body
         return args
 
-    async def _aquery_user_files_oapg(
+    async def _alist_data_source_items_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        User Files V2
+        List Data Source Items
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -192,20 +178,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/user_files_v2',
+            path_template='/integrations/items/list',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_organization_user_files_to_sync_query_input.serialize(body, content_type)
+        serialized_data = request_body_list_data_source_items_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -269,28 +255,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _query_user_files_oapg(
+    def _list_data_source_items_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        User Files V2
+        List Data Source Items
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -306,20 +292,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/user_files_v2',
+            path_template='/integrations/items/list',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_organization_user_files_to_sync_query_input.serialize(body, content_type)
+        serialized_data = request_body_list_data_source_items_request.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -352,177 +338,165 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class QueryUserFilesRaw(BaseApi):
+class ListDataSourceItemsRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def aquery_user_files(
+    async def alist_data_source_items(
         self,
+        data_source_id: int,
+        parent_id: typing.Optional[typing.Optional[str]] = None,
+        filters: typing.Optional[ListItemsFiltersNullable] = None,
         pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
-        order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
-        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
-        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
-        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
+        order_by: typing.Optional[ExternalSourceItemsOrderBy] = None,
+        order_dir: typing.Optional[OrderDirV2] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._query_user_files_mapped_args(
+        args = self._list_data_source_items_mapped_args(
+            data_source_id=data_source_id,
+            parent_id=parent_id,
+            filters=filters,
             pagination=pagination,
             order_by=order_by,
             order_dir=order_dir,
-            filters=filters,
-            include_raw_file=include_raw_file,
-            include_parsed_text_file=include_parsed_text_file,
-            include_additional_files=include_additional_files,
         )
-        return await self._aquery_user_files_oapg(
+        return await self._alist_data_source_items_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def query_user_files(
+    def list_data_source_items(
         self,
+        data_source_id: int,
+        parent_id: typing.Optional[typing.Optional[str]] = None,
+        filters: typing.Optional[ListItemsFiltersNullable] = None,
         pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
-        order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
-        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
-        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
-        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
+        order_by: typing.Optional[ExternalSourceItemsOrderBy] = None,
+        order_dir: typing.Optional[OrderDirV2] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._query_user_files_mapped_args(
+        args = self._list_data_source_items_mapped_args(
+            data_source_id=data_source_id,
+            parent_id=parent_id,
+            filters=filters,
             pagination=pagination,
             order_by=order_by,
             order_dir=order_dir,
-            filters=filters,
-            include_raw_file=include_raw_file,
-            include_parsed_text_file=include_parsed_text_file,
-            include_additional_files=include_additional_files,
         )
-        return self._query_user_files_oapg(
+        return self._list_data_source_items_oapg(
             body=args.body,
         )
 
-class QueryUserFiles(BaseApi):
+class ListDataSourceItems(BaseApi):
 
-    async def aquery_user_files(
+    async def alist_data_source_items(
         self,
+        data_source_id: int,
+        parent_id: typing.Optional[typing.Optional[str]] = None,
+        filters: typing.Optional[ListItemsFiltersNullable] = None,
         pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
-        order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
-        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
-        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
-        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
+        order_by: typing.Optional[ExternalSourceItemsOrderBy] = None,
+        order_dir: typing.Optional[OrderDirV2] = None,
         validate: bool = False,
         **kwargs,
-    ) -> UserFilesV2Pydantic:
-        raw_response = await self.raw.aquery_user_files(
+    ) -> ListDataSourceItemsResponsePydantic:
+        raw_response = await self.raw.alist_data_source_items(
+            data_source_id=data_source_id,
+            parent_id=parent_id,
+            filters=filters,
             pagination=pagination,
             order_by=order_by,
             order_dir=order_dir,
-            filters=filters,
-            include_raw_file=include_raw_file,
-            include_parsed_text_file=include_parsed_text_file,
-            include_additional_files=include_additional_files,
             **kwargs,
         )
         if validate:
-            return UserFilesV2Pydantic(**raw_response.body)
-        return api_client.construct_model_instance(UserFilesV2Pydantic, raw_response.body)
+            return ListDataSourceItemsResponsePydantic(**raw_response.body)
+        return api_client.construct_model_instance(ListDataSourceItemsResponsePydantic, raw_response.body)
     
     
-    def query_user_files(
+    def list_data_source_items(
         self,
+        data_source_id: int,
+        parent_id: typing.Optional[typing.Optional[str]] = None,
+        filters: typing.Optional[ListItemsFiltersNullable] = None,
         pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
-        order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
-        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
-        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
-        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
+        order_by: typing.Optional[ExternalSourceItemsOrderBy] = None,
+        order_dir: typing.Optional[OrderDirV2] = None,
         validate: bool = False,
-    ) -> UserFilesV2Pydantic:
-        raw_response = self.raw.query_user_files(
+    ) -> ListDataSourceItemsResponsePydantic:
+        raw_response = self.raw.list_data_source_items(
+            data_source_id=data_source_id,
+            parent_id=parent_id,
+            filters=filters,
             pagination=pagination,
             order_by=order_by,
             order_dir=order_dir,
-            filters=filters,
-            include_raw_file=include_raw_file,
-            include_parsed_text_file=include_parsed_text_file,
-            include_additional_files=include_additional_files,
         )
         if validate:
-            return UserFilesV2Pydantic(**raw_response.body)
-        return api_client.construct_model_instance(UserFilesV2Pydantic, raw_response.body)
+            return ListDataSourceItemsResponsePydantic(**raw_response.body)
+        return api_client.construct_model_instance(ListDataSourceItemsResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
+        data_source_id: int,
+        parent_id: typing.Optional[typing.Optional[str]] = None,
+        filters: typing.Optional[ListItemsFiltersNullable] = None,
         pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
-        order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
-        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
-        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
-        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
+        order_by: typing.Optional[ExternalSourceItemsOrderBy] = None,
+        order_dir: typing.Optional[OrderDirV2] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._query_user_files_mapped_args(
+        args = self._list_data_source_items_mapped_args(
+            data_source_id=data_source_id,
+            parent_id=parent_id,
+            filters=filters,
             pagination=pagination,
             order_by=order_by,
             order_dir=order_dir,
-            filters=filters,
-            include_raw_file=include_raw_file,
-            include_parsed_text_file=include_parsed_text_file,
-            include_additional_files=include_additional_files,
         )
-        return await self._aquery_user_files_oapg(
+        return await self._alist_data_source_items_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
+        data_source_id: int,
+        parent_id: typing.Optional[typing.Optional[str]] = None,
+        filters: typing.Optional[ListItemsFiltersNullable] = None,
         pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
-        order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
-        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
-        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
-        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
+        order_by: typing.Optional[ExternalSourceItemsOrderBy] = None,
+        order_dir: typing.Optional[OrderDirV2] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._query_user_files_mapped_args(
+        args = self._list_data_source_items_mapped_args(
+            data_source_id=data_source_id,
+            parent_id=parent_id,
+            filters=filters,
             pagination=pagination,
             order_by=order_by,
             order_dir=order_dir,
-            filters=filters,
-            include_raw_file=include_raw_file,
-            include_parsed_text_file=include_parsed_text_file,
-            include_additional_files=include_additional_files,
         )
-        return self._query_user_files_oapg(
+        return self._list_data_source_items_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/user_files_v2/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/webhooks/post.pyi`

 * *Files 23% similar despite different names*

```diff
@@ -28,61 +28,61 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
+from carbon.model.webhook_filters import WebhookFilters as WebhookFiltersSchema
 from carbon.model.pagination import Pagination as PaginationSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.organization_user_files_to_sync_order_by_types import OrganizationUserFilesToSyncOrderByTypes as OrganizationUserFilesToSyncOrderByTypesSchema
-from carbon.model.organization_user_files_to_sync_query_input import OrganizationUserFilesToSyncQueryInput as OrganizationUserFilesToSyncQueryInputSchema
-from carbon.model.organization_user_files_to_sync_filters import OrganizationUserFilesToSyncFilters as OrganizationUserFilesToSyncFiltersSchema
-from carbon.model.user_files_v2 import UserFilesV2 as UserFilesV2Schema
+from carbon.model.webhook_query_response import WebhookQueryResponse as WebhookQueryResponseSchema
 from carbon.model.order_dir import OrderDir as OrderDirSchema
+from carbon.model.webhook_query_input import WebhookQueryInput as WebhookQueryInputSchema
+from carbon.model.webhook_order_by_columns import WebhookOrderByColumns as WebhookOrderByColumnsSchema
 
 from carbon.type.http_validation_error import HTTPValidationError
+from carbon.type.webhook_query_input import WebhookQueryInput
 from carbon.type.pagination import Pagination
-from carbon.type.organization_user_files_to_sync_order_by_types import OrganizationUserFilesToSyncOrderByTypes
-from carbon.type.organization_user_files_to_sync_filters import OrganizationUserFilesToSyncFilters
-from carbon.type.user_files_v2 import UserFilesV2
 from carbon.type.order_dir import OrderDir
-from carbon.type.organization_user_files_to_sync_query_input import OrganizationUserFilesToSyncQueryInput
+from carbon.type.webhook_order_by_columns import WebhookOrderByColumns
+from carbon.type.webhook_filters import WebhookFilters
+from carbon.type.webhook_query_response import WebhookQueryResponse
 
 from ...api_client import Dictionary
-from carbon.pydantic.organization_user_files_to_sync_filters import OrganizationUserFilesToSyncFilters as OrganizationUserFilesToSyncFiltersPydantic
+from carbon.pydantic.webhook_filters import WebhookFilters as WebhookFiltersPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
-from carbon.pydantic.organization_user_files_to_sync_query_input import OrganizationUserFilesToSyncQueryInput as OrganizationUserFilesToSyncQueryInputPydantic
+from carbon.pydantic.webhook_order_by_columns import WebhookOrderByColumns as WebhookOrderByColumnsPydantic
 from carbon.pydantic.order_dir import OrderDir as OrderDirPydantic
-from carbon.pydantic.user_files_v2 import UserFilesV2 as UserFilesV2Pydantic
-from carbon.pydantic.organization_user_files_to_sync_order_by_types import OrganizationUserFilesToSyncOrderByTypes as OrganizationUserFilesToSyncOrderByTypesPydantic
 from carbon.pydantic.pagination import Pagination as PaginationPydantic
+from carbon.pydantic.webhook_query_input import WebhookQueryInput as WebhookQueryInputPydantic
+from carbon.pydantic.webhook_query_response import WebhookQueryResponse as WebhookQueryResponsePydantic
 
 # body param
-SchemaForRequestBodyApplicationJson = OrganizationUserFilesToSyncQueryInputSchema
+SchemaForRequestBodyApplicationJson = WebhookQueryInputSchema
 
 
-request_body_organization_user_files_to_sync_query_input = api_client.RequestBody(
+request_body_webhook_query_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
-SchemaFor200ResponseBodyApplicationJson = UserFilesV2Schema
+SchemaFor200ResponseBodyApplicationJson = WebhookQueryResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
-    body: UserFilesV2
+    body: WebhookQueryResponse
 
 
 @dataclass
 class ApiResponseFor200Async(api_client.AsyncApiResponse):
-    body: UserFilesV2
+    body: WebhookQueryResponse
 
 
 _response_for_200 = api_client.OpenApiResponse(
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
@@ -113,59 +113,50 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _query_user_files_mapped_args(
+    def _urls_mapped_args(
         self,
         pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_by: typing.Optional[WebhookOrderByColumns] = None,
         order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
-        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
-        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
-        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
+        filters: typing.Optional[WebhookFilters] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
         if pagination is not None:
             _body["pagination"] = pagination
         if order_by is not None:
             _body["order_by"] = order_by
         if order_dir is not None:
             _body["order_dir"] = order_dir
         if filters is not None:
             _body["filters"] = filters
-        if include_raw_file is not None:
-            _body["include_raw_file"] = include_raw_file
-        if include_parsed_text_file is not None:
-            _body["include_parsed_text_file"] = include_parsed_text_file
-        if include_additional_files is not None:
-            _body["include_additional_files"] = include_additional_files
         args.body = _body
         return args
 
-    async def _aquery_user_files_oapg(
+    async def _aurls_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        User Files V2
+        Webhook Urls
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -181,20 +172,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/user_files_v2',
+            path_template='/webhooks',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_organization_user_files_to_sync_query_input.serialize(body, content_type)
+        serialized_data = request_body_webhook_query_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -258,28 +249,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _query_user_files_oapg(
+    def _urls_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        User Files V2
+        Webhook Urls
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -295,20 +286,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/user_files_v2',
+            path_template='/webhooks',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_organization_user_files_to_sync_query_input.serialize(body, content_type)
+        serialized_data = request_body_webhook_query_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -341,177 +332,141 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class QueryUserFilesRaw(BaseApi):
+class UrlsRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def aquery_user_files(
+    async def aurls(
         self,
         pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_by: typing.Optional[WebhookOrderByColumns] = None,
         order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
-        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
-        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
-        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
+        filters: typing.Optional[WebhookFilters] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._query_user_files_mapped_args(
+        args = self._urls_mapped_args(
             pagination=pagination,
             order_by=order_by,
             order_dir=order_dir,
             filters=filters,
-            include_raw_file=include_raw_file,
-            include_parsed_text_file=include_parsed_text_file,
-            include_additional_files=include_additional_files,
         )
-        return await self._aquery_user_files_oapg(
+        return await self._aurls_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def query_user_files(
+    def urls(
         self,
         pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_by: typing.Optional[WebhookOrderByColumns] = None,
         order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
-        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
-        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
-        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
+        filters: typing.Optional[WebhookFilters] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._query_user_files_mapped_args(
+        args = self._urls_mapped_args(
             pagination=pagination,
             order_by=order_by,
             order_dir=order_dir,
             filters=filters,
-            include_raw_file=include_raw_file,
-            include_parsed_text_file=include_parsed_text_file,
-            include_additional_files=include_additional_files,
         )
-        return self._query_user_files_oapg(
+        return self._urls_oapg(
             body=args.body,
         )
 
-class QueryUserFiles(BaseApi):
+class Urls(BaseApi):
 
-    async def aquery_user_files(
+    async def aurls(
         self,
         pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_by: typing.Optional[WebhookOrderByColumns] = None,
         order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
-        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
-        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
-        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
+        filters: typing.Optional[WebhookFilters] = None,
         validate: bool = False,
         **kwargs,
-    ) -> UserFilesV2Pydantic:
-        raw_response = await self.raw.aquery_user_files(
+    ) -> WebhookQueryResponsePydantic:
+        raw_response = await self.raw.aurls(
             pagination=pagination,
             order_by=order_by,
             order_dir=order_dir,
             filters=filters,
-            include_raw_file=include_raw_file,
-            include_parsed_text_file=include_parsed_text_file,
-            include_additional_files=include_additional_files,
             **kwargs,
         )
         if validate:
-            return UserFilesV2Pydantic(**raw_response.body)
-        return api_client.construct_model_instance(UserFilesV2Pydantic, raw_response.body)
+            return WebhookQueryResponsePydantic(**raw_response.body)
+        return api_client.construct_model_instance(WebhookQueryResponsePydantic, raw_response.body)
     
     
-    def query_user_files(
+    def urls(
         self,
         pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_by: typing.Optional[WebhookOrderByColumns] = None,
         order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
-        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
-        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
-        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
+        filters: typing.Optional[WebhookFilters] = None,
         validate: bool = False,
-    ) -> UserFilesV2Pydantic:
-        raw_response = self.raw.query_user_files(
+    ) -> WebhookQueryResponsePydantic:
+        raw_response = self.raw.urls(
             pagination=pagination,
             order_by=order_by,
             order_dir=order_dir,
             filters=filters,
-            include_raw_file=include_raw_file,
-            include_parsed_text_file=include_parsed_text_file,
-            include_additional_files=include_additional_files,
         )
         if validate:
-            return UserFilesV2Pydantic(**raw_response.body)
-        return api_client.construct_model_instance(UserFilesV2Pydantic, raw_response.body)
+            return WebhookQueryResponsePydantic(**raw_response.body)
+        return api_client.construct_model_instance(WebhookQueryResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
         pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_by: typing.Optional[WebhookOrderByColumns] = None,
         order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
-        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
-        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
-        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
+        filters: typing.Optional[WebhookFilters] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._query_user_files_mapped_args(
+        args = self._urls_mapped_args(
             pagination=pagination,
             order_by=order_by,
             order_dir=order_dir,
             filters=filters,
-            include_raw_file=include_raw_file,
-            include_parsed_text_file=include_parsed_text_file,
-            include_additional_files=include_additional_files,
         )
-        return await self._aquery_user_files_oapg(
+        return await self._aurls_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
         pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[OrganizationUserFilesToSyncOrderByTypes] = None,
+        order_by: typing.Optional[WebhookOrderByColumns] = None,
         order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[OrganizationUserFilesToSyncFilters] = None,
-        include_raw_file: typing.Optional[typing.Optional[bool]] = None,
-        include_parsed_text_file: typing.Optional[typing.Optional[bool]] = None,
-        include_additional_files: typing.Optional[typing.Optional[bool]] = None,
+        filters: typing.Optional[WebhookFilters] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._query_user_files_mapped_args(
+        args = self._urls_mapped_args(
             pagination=pagination,
             order_by=order_by,
             order_dir=order_dir,
             filters=filters,
-            include_raw_file=include_raw_file,
-            include_parsed_text_file=include_parsed_text_file,
-            include_additional_files=include_additional_files,
         )
-        return self._query_user_files_oapg(
+        return self._urls_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/web_scrape/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/web_scrape/post.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/web_scrape/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/web_scrape/post.pyi`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/webhooks/post.py` & `carbon_python_sdk-0.2.0/carbon/paths/webhooks/post.py`

 * *Files 0% similar despite different names*

```diff
@@ -67,15 +67,15 @@
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
 _auth = [
-    'accessToken',
+    'apiKey',
 ]
 SchemaFor200ResponseBodyApplicationJson = WebhookQueryResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
     body: WebhookQueryResponse
```

### Comparing `carbon_python_sdk-0.1.9/carbon/paths/webhooks/post.pyi` & `carbon_python_sdk-0.2.0/carbon/paths/organization_update/post.pyi`

 * *Files 20% similar despite different names*

```diff
@@ -28,61 +28,52 @@
 import typing_extensions  # noqa: F401
 import uuid  # noqa: F401
 
 import frozendict  # noqa: F401
 
 from carbon import schemas  # noqa: F401
 
-from carbon.model.webhook_filters import WebhookFilters as WebhookFiltersSchema
-from carbon.model.pagination import Pagination as PaginationSchema
 from carbon.model.http_validation_error import HTTPValidationError as HTTPValidationErrorSchema
-from carbon.model.webhook_query_response import WebhookQueryResponse as WebhookQueryResponseSchema
-from carbon.model.order_dir import OrderDir as OrderDirSchema
-from carbon.model.webhook_query_input import WebhookQueryInput as WebhookQueryInputSchema
-from carbon.model.webhook_order_by_columns import WebhookOrderByColumns as WebhookOrderByColumnsSchema
+from carbon.model.user_configuration_nullable import UserConfigurationNullable as UserConfigurationNullableSchema
+from carbon.model.update_organization_input import UpdateOrganizationInput as UpdateOrganizationInputSchema
+from carbon.model.generic_success_response import GenericSuccessResponse as GenericSuccessResponseSchema
 
+from carbon.type.user_configuration_nullable import UserConfigurationNullable
 from carbon.type.http_validation_error import HTTPValidationError
-from carbon.type.webhook_query_input import WebhookQueryInput
-from carbon.type.pagination import Pagination
-from carbon.type.order_dir import OrderDir
-from carbon.type.webhook_order_by_columns import WebhookOrderByColumns
-from carbon.type.webhook_filters import WebhookFilters
-from carbon.type.webhook_query_response import WebhookQueryResponse
+from carbon.type.update_organization_input import UpdateOrganizationInput
+from carbon.type.generic_success_response import GenericSuccessResponse
 
 from ...api_client import Dictionary
-from carbon.pydantic.webhook_filters import WebhookFilters as WebhookFiltersPydantic
+from carbon.pydantic.update_organization_input import UpdateOrganizationInput as UpdateOrganizationInputPydantic
 from carbon.pydantic.http_validation_error import HTTPValidationError as HTTPValidationErrorPydantic
-from carbon.pydantic.webhook_order_by_columns import WebhookOrderByColumns as WebhookOrderByColumnsPydantic
-from carbon.pydantic.order_dir import OrderDir as OrderDirPydantic
-from carbon.pydantic.pagination import Pagination as PaginationPydantic
-from carbon.pydantic.webhook_query_input import WebhookQueryInput as WebhookQueryInputPydantic
-from carbon.pydantic.webhook_query_response import WebhookQueryResponse as WebhookQueryResponsePydantic
+from carbon.pydantic.generic_success_response import GenericSuccessResponse as GenericSuccessResponsePydantic
+from carbon.pydantic.user_configuration_nullable import UserConfigurationNullable as UserConfigurationNullablePydantic
 
 # body param
-SchemaForRequestBodyApplicationJson = WebhookQueryInputSchema
+SchemaForRequestBodyApplicationJson = UpdateOrganizationInputSchema
 
 
-request_body_webhook_query_input = api_client.RequestBody(
+request_body_update_organization_input = api_client.RequestBody(
     content={
         'application/json': api_client.MediaType(
             schema=SchemaForRequestBodyApplicationJson),
     },
     required=True,
 )
-SchemaFor200ResponseBodyApplicationJson = WebhookQueryResponseSchema
+SchemaFor200ResponseBodyApplicationJson = GenericSuccessResponseSchema
 
 
 @dataclass
 class ApiResponseFor200(api_client.ApiResponse):
-    body: WebhookQueryResponse
+    body: GenericSuccessResponse
 
 
 @dataclass
 class ApiResponseFor200Async(api_client.AsyncApiResponse):
-    body: WebhookQueryResponse
+    body: GenericSuccessResponse
 
 
 _response_for_200 = api_client.OpenApiResponse(
     response_cls=ApiResponseFor200,
     response_cls_async=ApiResponseFor200Async,
     content={
         'application/json': api_client.MediaType(
@@ -113,50 +104,41 @@
 _all_accept_content_types = (
     'application/json',
 )
 
 
 class BaseApi(api_client.Api):
 
-    def _urls_mapped_args(
+    def _update_mapped_args(
         self,
-        pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[WebhookOrderByColumns] = None,
-        order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[WebhookFilters] = None,
+        global_user_config: typing.Optional[UserConfigurationNullable] = None,
     ) -> api_client.MappedArgs:
         args: api_client.MappedArgs = api_client.MappedArgs()
         _body = {}
-        if pagination is not None:
-            _body["pagination"] = pagination
-        if order_by is not None:
-            _body["order_by"] = order_by
-        if order_dir is not None:
-            _body["order_dir"] = order_dir
-        if filters is not None:
-            _body["filters"] = filters
+        if global_user_config is not None:
+            _body["global_user_config"] = global_user_config
         args.body = _body
         return args
 
-    async def _aurls_oapg(
+    async def _aupdate_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
         """
-        Webhook Urls
+        Update Organization
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -172,20 +154,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/webhooks',
+            path_template='/organization/update',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_webhook_query_input.serialize(body, content_type)
+        serialized_data = request_body_update_organization_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = await self.api_client.async_call_api(
             resource_path=used_path,
@@ -249,28 +231,28 @@
         # cleanup session / response
         response.http_response.close()
         await response.session.close()
     
         return api_response
 
 
-    def _urls_oapg(
+    def _update_oapg(
         self,
         body: typing.Any = None,
         skip_deserialization: bool = True,
         timeout: typing.Optional[typing.Union[float, typing.Tuple]] = None,
         accept_content_types: typing.Tuple[str] = _all_accept_content_types,
         content_type: str = 'application/json',
         stream: bool = False,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
         """
-        Webhook Urls
+        Update Organization
         :param skip_deserialization: If true then api_response.response will be set but
             api_response.body and api_response.headers will not be deserialized into schema
             class instances
         """
         used_path = path.value
     
         _headers = HTTPHeaderDict()
@@ -286,20 +268,20 @@
                 'The required body parameter has an invalid value of: unset. Set a valid value instead')
         _fields = None
         _body = None
         request_before_hook(
             resource_path=used_path,
             method=method,
             configuration=self.api_client.configuration,
-            path_template='/webhooks',
+            path_template='/organization/update',
             body=body,
             auth_settings=_auth,
             headers=_headers,
         )
-        serialized_data = request_body_webhook_query_input.serialize(body, content_type)
+        serialized_data = request_body_update_organization_input.serialize(body, content_type)
         if 'fields' in serialized_data:
             _fields = serialized_data['fields']
         elif 'body' in serialized_data:
             _body = serialized_data['body']
     
         response = self.api_client.call_api(
             resource_path=used_path,
@@ -332,141 +314,105 @@
     
         if not 200 <= api_response.status <= 299:
             raise exceptions.ApiException(api_response=api_response)
     
         return api_response
 
 
-class UrlsRaw(BaseApi):
+class UpdateRaw(BaseApi):
     # this class is used by api classes that refer to endpoints with operationId fn names
 
-    async def aurls(
+    async def aupdate(
         self,
-        pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[WebhookOrderByColumns] = None,
-        order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[WebhookFilters] = None,
+        global_user_config: typing.Optional[UserConfigurationNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._urls_mapped_args(
-            pagination=pagination,
-            order_by=order_by,
-            order_dir=order_dir,
-            filters=filters,
+        args = self._update_mapped_args(
+            global_user_config=global_user_config,
         )
-        return await self._aurls_oapg(
+        return await self._aupdate_oapg(
             body=args.body,
             **kwargs,
         )
     
-    def urls(
+    def update(
         self,
-        pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[WebhookOrderByColumns] = None,
-        order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[WebhookFilters] = None,
+        global_user_config: typing.Optional[UserConfigurationNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._urls_mapped_args(
-            pagination=pagination,
-            order_by=order_by,
-            order_dir=order_dir,
-            filters=filters,
+        args = self._update_mapped_args(
+            global_user_config=global_user_config,
         )
-        return self._urls_oapg(
+        return self._update_oapg(
             body=args.body,
         )
 
-class Urls(BaseApi):
+class Update(BaseApi):
 
-    async def aurls(
+    async def aupdate(
         self,
-        pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[WebhookOrderByColumns] = None,
-        order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[WebhookFilters] = None,
+        global_user_config: typing.Optional[UserConfigurationNullable] = None,
         validate: bool = False,
         **kwargs,
-    ) -> WebhookQueryResponsePydantic:
-        raw_response = await self.raw.aurls(
-            pagination=pagination,
-            order_by=order_by,
-            order_dir=order_dir,
-            filters=filters,
+    ) -> GenericSuccessResponsePydantic:
+        raw_response = await self.raw.aupdate(
+            global_user_config=global_user_config,
             **kwargs,
         )
         if validate:
-            return WebhookQueryResponsePydantic(**raw_response.body)
-        return api_client.construct_model_instance(WebhookQueryResponsePydantic, raw_response.body)
+            return GenericSuccessResponsePydantic(**raw_response.body)
+        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
     
     
-    def urls(
+    def update(
         self,
-        pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[WebhookOrderByColumns] = None,
-        order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[WebhookFilters] = None,
+        global_user_config: typing.Optional[UserConfigurationNullable] = None,
         validate: bool = False,
-    ) -> WebhookQueryResponsePydantic:
-        raw_response = self.raw.urls(
-            pagination=pagination,
-            order_by=order_by,
-            order_dir=order_dir,
-            filters=filters,
+    ) -> GenericSuccessResponsePydantic:
+        raw_response = self.raw.update(
+            global_user_config=global_user_config,
         )
         if validate:
-            return WebhookQueryResponsePydantic(**raw_response.body)
-        return api_client.construct_model_instance(WebhookQueryResponsePydantic, raw_response.body)
+            return GenericSuccessResponsePydantic(**raw_response.body)
+        return api_client.construct_model_instance(GenericSuccessResponsePydantic, raw_response.body)
 
 
 class ApiForpost(BaseApi):
     # this class is used by api classes that refer to endpoints by path and http method names
 
     async def apost(
         self,
-        pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[WebhookOrderByColumns] = None,
-        order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[WebhookFilters] = None,
+        global_user_config: typing.Optional[UserConfigurationNullable] = None,
         **kwargs,
     ) -> typing.Union[
         ApiResponseFor200Async,
         api_client.ApiResponseWithoutDeserializationAsync,
         AsyncGeneratorResponse,
     ]:
-        args = self._urls_mapped_args(
-            pagination=pagination,
-            order_by=order_by,
-            order_dir=order_dir,
-            filters=filters,
+        args = self._update_mapped_args(
+            global_user_config=global_user_config,
         )
-        return await self._aurls_oapg(
+        return await self._aupdate_oapg(
             body=args.body,
             **kwargs,
         )
     
     def post(
         self,
-        pagination: typing.Optional[Pagination] = None,
-        order_by: typing.Optional[WebhookOrderByColumns] = None,
-        order_dir: typing.Optional[OrderDir] = None,
-        filters: typing.Optional[WebhookFilters] = None,
+        global_user_config: typing.Optional[UserConfigurationNullable] = None,
     ) -> typing.Union[
         ApiResponseFor200,
         api_client.ApiResponseWithoutDeserialization,
     ]:
-        args = self._urls_mapped_args(
-            pagination=pagination,
-            order_by=order_by,
-            order_dir=order_dir,
-            filters=filters,
+        args = self._update_mapped_args(
+            global_user_config=global_user_config,
         )
-        return self._urls_oapg(
+        return self._update_oapg(
             body=args.body,
         )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/body_create_upload_file_uploadfile_post.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/body_create_upload_file_uploadfile_post.py`

 * *Files 13% similar despite different names*

```diff
@@ -9,14 +9,17 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
 class BodyCreateUploadFileUploadfilePost(BaseModel):
     file: typing.IO = Field(alias='file')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/chunk_properties.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/chunk_properties_nullable.py`

 * *Files 16% similar despite different names*

```diff
@@ -9,18 +9,21 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-class ChunkProperties(BaseModel):
+class ChunkPropertiesNullable(BaseModel):
     set_page_as_boundary: bool = Field(alias='set_page_as_boundary')
 
     prepend_filename_to_chunks: bool = Field(alias='prepend_filename_to_chunks')
 
     max_items_per_chunk: typing.Optional[int] = Field(alias='max_items_per_chunk')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/chunk_properties_nullable.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/chunk_properties.py`

 * *Files 19% similar despite different names*

```diff
@@ -9,18 +9,21 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-class ChunkPropertiesNullable(BaseModel):
+class ChunkProperties(BaseModel):
     set_page_as_boundary: bool = Field(alias='set_page_as_boundary')
 
     prepend_filename_to_chunks: bool = Field(alias='prepend_filename_to_chunks')
 
     max_items_per_chunk: typing.Optional[int] = Field(alias='max_items_per_chunk')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/chunks_and_embeddings.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/hybrid_search_tuning_params.py`

 * *Files 21% similar despite different names*

```diff
@@ -9,19 +9,19 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
-from carbon.pydantic.chunks_and_embeddings_embedding import ChunksAndEmbeddingsEmbedding
 
-class ChunksAndEmbeddings(BaseModel):
-    chunk_number: typing.Optional[int] = Field(alias='chunk_number')
+class HybridSearchTuningParams(BaseModel):
+    weight_a: typing.Union[int, float] = Field(alias='weight_a')
 
-    chunk: str = Field(alias='chunk')
+    weight_b: typing.Union[int, float] = Field(alias='weight_b')
 
-    embedding: typing.Optional[ChunksAndEmbeddingsEmbedding] = Field(None, alias='embedding')
-    class Config:
-        arbitrary_types_allowed = True
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/chunks_and_embeddings_upload_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/chunks_and_embeddings_upload_input.py`

 * *Files 12% similar despite different names*

```diff
@@ -9,24 +9,28 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
+from carbon.pydantic.chunks_and_embeddings_upload_input_custom_credentials import ChunksAndEmbeddingsUploadInputCustomCredentials
 from carbon.pydantic.embedding_generators import EmbeddingGenerators
 from carbon.pydantic.single_chunks_and_embeddings_upload_input import SingleChunksAndEmbeddingsUploadInput
 
 class ChunksAndEmbeddingsUploadInput(BaseModel):
     embedding_model: EmbeddingGenerators = Field(alias='embedding_model')
 
     chunks_and_embeddings: typing.List[SingleChunksAndEmbeddingsUploadInput] = Field(alias='chunks_and_embeddings')
 
     overwrite_existing: typing.Optional[bool] = Field(None, alias='overwrite_existing')
 
     chunks_only: typing.Optional[bool] = Field(None, alias='chunks_only')
 
-    custom_credentials: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]] = Field(None, alias='custom_credentials')
-    class Config:
-        arbitrary_types_allowed = True
+    custom_credentials: typing.Optional[ChunksAndEmbeddingsUploadInputCustomCredentials] = Field(None, alias='custom_credentials')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/confluence_authentication.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/confluence_authentication.py`

 * *Files 15% similar despite different names*

```diff
@@ -9,20 +9,23 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
 class ConfluenceAuthentication(BaseModel):
     source: typing.Union[bool, date, datetime, dict, float, int, list, str, None] = Field(alias='source')
 
     access_token: str = Field(alias='access_token')
 
     subdomain: str = Field(alias='subdomain')
 
     refresh_token: typing.Optional[typing.Optional[str]] = Field(None, alias='refresh_token')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/connect_data_source_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/connect_data_source_input.py`

 * *Files 6% similar despite different names*

```diff
@@ -9,27 +9,31 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.confluence_authentication import ConfluenceAuthentication
 from carbon.pydantic.freskdesk_authentication import FreskdeskAuthentication
 from carbon.pydantic.gitbook_authetication import GitbookAuthetication
+from carbon.pydantic.github_authentication import GithubAuthentication
 from carbon.pydantic.notion_authentication import NotionAuthentication
 from carbon.pydantic.o_auth_authentication import OAuthAuthentication
 from carbon.pydantic.s3_authentication import S3Authentication
 from carbon.pydantic.salesforce_authentication import SalesforceAuthentication
 from carbon.pydantic.sharepoint_authentication import SharepointAuthentication
 from carbon.pydantic.sync_options import SyncOptions
 from carbon.pydantic.zendesk_authentication import ZendeskAuthentication
 from carbon.pydantic.zotero_authentication import ZoteroAuthentication
 
 class ConnectDataSourceInput(BaseModel):
-    authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication] = Field(alias='authentication')
+    authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication, GithubAuthentication] = Field(alias='authentication')
 
     sync_options: typing.Optional[SyncOptions] = Field(None, alias='sync_options')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/connect_data_source_response.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/connect_data_source_response.py`

 * *Files 15% similar despite different names*

```diff
@@ -9,17 +9,20 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.organization_user_data_source_api import OrganizationUserDataSourceAPI
 
 class ConnectDataSourceResponse(BaseModel):
     data_source: OrganizationUserDataSourceAPI = Field(alias='data_source')
 
     sync_url: typing.Optional[str] = Field(alias='sync_url')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/data_source_type_nullable.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/file_formats_nullable.py`

 * *Files 27% similar despite different names*

```diff
@@ -9,11 +9,11 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-DataSourceTypeNullable = Literal["GOOGLE_DRIVE", "NOTION", "NOTION_DATABASE", "INTERCOM", "DROPBOX", "ONEDRIVE", "SHAREPOINT", "CONFLUENCE", "BOX", "ZENDESK", "ZOTERO", "S3", "GMAIL", "OUTLOOK", "TEXT", "CSV", "TSV", "PDF", "DOCX", "PPTX", "XLSX", "MD", "RTF", "JSON", "RAW_TEXT", "WEB_SCRAPE", "RSS_FEED", "FRESHDESK", "GITBOOK", "SALESFORCE", "JPG", "PNG", "MP3", "MP4", "MP2", "AAC", "WAV", "FLAC", "PCM", "M4A", "OGG", "OPUS", "WEBM"]
+FileFormatsNullable = Literal["TXT", "CSV", "TSV", "PDF", "DOCX", "PPTX", "XLSX", "MD", "RTF", "JSON", "HTML", "NOTION", "GOOGLE_DOCS", "GOOGLE_SHEETS", "GOOGLE_SLIDES", "INTERCOM", "CONFLUENCE", "RSS_FEED", "GMAIL", "OUTLOOK", "ZENDESK", "FRESHDESK", "WEB_SCRAPE", "GITBOOK", "SALESFORCE", "GITHUB", "JPG", "PNG", "MP3", "MP2", "AAC", "WAV", "FLAC", "PCM", "M4A", "OGG", "OPUS", "MPEG", "MPG", "MP4", "WMV", "AVI", "MOV", "MKV", "FLV", "WEBM"]
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/delete_files_query_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/delete_files_query_input.py`

 * *Files 5% similar despite different names*

```diff
@@ -9,24 +9,27 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.delete_files_query_input_file_ids import DeleteFilesQueryInputFileIds
 from carbon.pydantic.external_file_sync_statuses import ExternalFileSyncStatuses
 
 class DeleteFilesQueryInput(BaseModel):
     file_ids: typing.Optional[DeleteFilesQueryInputFileIds] = Field(None, alias='file_ids')
 
     sync_statuses: typing.Optional[typing.Optional[typing.List[ExternalFileSyncStatuses]]] = Field(None, alias='sync_statuses')
 
     delete_non_synced_only: typing.Optional[bool] = Field(None, alias='delete_non_synced_only')
 
     send_webhook: typing.Optional[bool] = Field(None, alias='send_webhook')
 
     delete_child_files: typing.Optional[bool] = Field(None, alias='delete_child_files')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/delete_users_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/delete_users_input.py`

 * *Files 13% similar despite different names*

```diff
@@ -9,15 +9,18 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.delete_users_input_customer_ids import DeleteUsersInputCustomerIds
 
 class DeleteUsersInput(BaseModel):
     customer_ids: DeleteUsersInputCustomerIds = Field(alias='customer_ids')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/directory_item.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/validation_error.py`

 * *Files 18% similar despite different names*

```diff
@@ -9,20 +9,22 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
+from carbon.pydantic.validation_error_loc import ValidationErrorLoc
 
-class DirectoryItem(BaseModel):
-    id: str = Field(alias='id')
+class ValidationError(BaseModel):
+    loc: ValidationErrorLoc = Field(alias='loc')
 
-    name: str = Field(alias='name')
+    msg: str = Field(alias='msg')
 
-    is_synced: bool = Field(alias='is_synced')
+    type: str = Field(alias='type')
 
-    has_children: bool = Field(alias='has_children')
-    class Config:
-        arbitrary_types_allowed = True
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/document_response.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/document_response.py`

 * *Files 14% similar despite different names*

```diff
@@ -9,27 +9,29 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.data_source_type_nullable import DataSourceTypeNullable
 from carbon.pydantic.document_response_tags import DocumentResponseTags
 from carbon.pydantic.document_response_vector import DocumentResponseVector
 
 class DocumentResponse(BaseModel):
     tags: DocumentResponseTags = Field(alias='tags')
 
     content: str = Field(alias='content')
 
     file_id: int = Field(alias='file_id')
 
+    parent_file_id: typing.Optional[int] = Field(alias='parent_file_id')
+
     source: typing.Optional[str] = Field(alias='source')
 
     source_url: typing.Optional[str] = Field(alias='source_url')
 
     source_type: DataSourceTypeNullable = Field(alias='source_type')
 
     presigned_url: typing.Optional[str] = Field(alias='presigned_url')
@@ -37,9 +39,14 @@
     vector: DocumentResponseVector = Field(alias='vector')
 
     score: typing.Optional[typing.Union[int, float]] = Field(alias='score')
 
     rank: typing.Union[typing.Union[int, float], int] = Field(alias='rank')
 
     content_metadata: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]] = Field(alias='content_metadata')
-    class Config:
-        arbitrary_types_allowed = True
+
+    chunk_index: typing.Optional[int] = Field(alias='chunk_index')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/document_response_list.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/sync_directory_request.py`

 * *Files 16% similar despite different names*

```diff
@@ -9,15 +9,17 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
-from carbon.pydantic.document_response import DocumentResponse
 
-class DocumentResponseList(BaseModel):
-    documents: typing.List[DocumentResponse] = Field(alias='documents')
-    class Config:
-        arbitrary_types_allowed = True
+class SyncDirectoryRequest(BaseModel):
+    data_source_id: int = Field(alias='data_source_id')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/embedding_and_chunk.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/embedding_and_chunk.py`

 * *Files 12% similar despite different names*

```diff
@@ -9,21 +9,26 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.embedding_and_chunk_embedding import EmbeddingAndChunkEmbedding
 
 class EmbeddingAndChunk(BaseModel):
     user_file_id: int = Field(alias='user_file_id')
 
     chunk_index: typing.Optional[int] = Field(alias='chunk_index')
 
     source_content: str = Field(alias='source_content')
 
     embedding: EmbeddingAndChunkEmbedding = Field(alias='embedding')
-    class Config:
-        arbitrary_types_allowed = True
+
+    content_metadata: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]] = Field(alias='content_metadata')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/embedding_generators.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/embedding_generators_nullable.py`

 * *Files 4% similar despite different names*

```diff
@@ -9,11 +9,11 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-EmbeddingGenerators = Literal["OPENAI", "AZURE_OPENAI", "AZURE_ADA_LARGE_256", "AZURE_ADA_LARGE_1024", "AZURE_ADA_LARGE_3072", "AZURE_ADA_SMALL_512", "AZURE_ADA_SMALL_1536", "COHERE_MULTILINGUAL_V3", "VERTEX_MULTIMODAL", "OPENAI_ADA_LARGE_256", "OPENAI_ADA_LARGE_1024", "OPENAI_ADA_LARGE_3072", "OPENAI_ADA_SMALL_512", "OPENAI_ADA_SMALL_1536"]
+EmbeddingGeneratorsNullable = Literal["OPENAI", "AZURE_OPENAI", "AZURE_ADA_LARGE_256", "AZURE_ADA_LARGE_1024", "AZURE_ADA_LARGE_3072", "AZURE_ADA_SMALL_512", "AZURE_ADA_SMALL_1536", "COHERE_MULTILINGUAL_V3", "VERTEX_MULTIMODAL", "OPENAI_ADA_LARGE_256", "OPENAI_ADA_LARGE_1024", "OPENAI_ADA_LARGE_3072", "OPENAI_ADA_SMALL_512", "OPENAI_ADA_SMALL_1536", "SOLAR_1_MINI"]
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/embedding_generators_nullable.py` & `carbon_python_sdk-0.2.0/carbon/type/embedding_generators_nullable.py`

 * *Files 6% similar despite different names*

```diff
@@ -9,11 +9,10 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
 
 
-EmbeddingGeneratorsNullable = Literal["OPENAI", "AZURE_OPENAI", "AZURE_ADA_LARGE_256", "AZURE_ADA_LARGE_1024", "AZURE_ADA_LARGE_3072", "AZURE_ADA_SMALL_512", "AZURE_ADA_SMALL_1536", "COHERE_MULTILINGUAL_V3", "VERTEX_MULTIMODAL", "OPENAI_ADA_LARGE_256", "OPENAI_ADA_LARGE_1024", "OPENAI_ADA_LARGE_3072", "OPENAI_ADA_SMALL_512", "OPENAI_ADA_SMALL_1536"]
+EmbeddingGeneratorsNullable = Literal["OPENAI", "AZURE_OPENAI", "AZURE_ADA_LARGE_256", "AZURE_ADA_LARGE_1024", "AZURE_ADA_LARGE_3072", "AZURE_ADA_SMALL_512", "AZURE_ADA_SMALL_1536", "COHERE_MULTILINGUAL_V3", "VERTEX_MULTIMODAL", "OPENAI_ADA_LARGE_256", "OPENAI_ADA_LARGE_1024", "OPENAI_ADA_LARGE_3072", "OPENAI_ADA_SMALL_512", "OPENAI_ADA_SMALL_1536", "SOLAR_1_MINI"]
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/embedding_properties.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/embedding_properties.py`

 * *Files 13% similar despite different names*

```diff
@@ -9,16 +9,19 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
 class EmbeddingProperties(BaseModel):
     chunk_size: typing.Optional[int] = Field(alias='chunk_size')
 
     chunk_overlap: typing.Optional[int] = Field(alias='chunk_overlap')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/embeddings_and_chunks_filters.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/embeddings_and_chunks_filters.py`

 * *Files 8% similar despite different names*

```diff
@@ -9,17 +9,20 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable
 
 class EmbeddingsAndChunksFilters(BaseModel):
     user_file_id: int = Field(alias='user_file_id')
 
     embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = Field(None, alias='embedding_model')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/embeddings_and_chunks_query_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/embeddings_and_chunks_query_input.py`

 * *Files 8% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.embeddings_and_chunks_filters import EmbeddingsAndChunksFilters
 from carbon.pydantic.embeddings_and_chunks_order_by_columns import EmbeddingsAndChunksOrderByColumns
 from carbon.pydantic.order_dir import OrderDir
 from carbon.pydantic.pagination import Pagination
 
 class EmbeddingsAndChunksQueryInput(BaseModel):
@@ -26,9 +26,12 @@
     pagination: typing.Optional[Pagination] = Field(None, alias='pagination')
 
     order_by: typing.Optional[EmbeddingsAndChunksOrderByColumns] = Field(None, alias='order_by')
 
     order_dir: typing.Optional[OrderDir] = Field(None, alias='order_dir')
 
     include_vectors: typing.Optional[bool] = Field(None, alias='include_vectors')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/embeddings_and_chunks_response.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/gitbook_authetication.py`

 * *Files 18% similar despite different names*

```diff
@@ -9,17 +9,21 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
-from carbon.pydantic.embedding_and_chunk import EmbeddingAndChunk
 
-class EmbeddingsAndChunksResponse(BaseModel):
-    results: typing.List[EmbeddingAndChunk] = Field(alias='results')
+class GitbookAuthetication(BaseModel):
+    source: typing.Union[bool, date, datetime, dict, float, int, list, str, None] = Field(alias='source')
 
-    count: int = Field(alias='count')
-    class Config:
-        arbitrary_types_allowed = True
+    access_token: str = Field(alias='access_token')
+
+    organization_name: str = Field(alias='organization_name')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/external_file_sync_statuses.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/external_file_sync_statuses.py`

 * *Files 4% similar despite different names*

```diff
@@ -9,11 +9,11 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
 ExternalFileSyncStatuses = Literal["DELAYED", "QUEUED_FOR_SYNC", "SYNCING", "READY", "SYNC_ERROR", "EVALUATING_RESYNC", "RATE_LIMITED", "SYNC_ABORTED", "QUEUED_FOR_OCR"]
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/external_source_item.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/external_source_item.py`

 * *Files 8% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.data_source_type import DataSourceType
 
 class ExternalSourceItem(BaseModel):
     id: int = Field(alias='id')
 
     external_id: str = Field(alias='external_id')
@@ -44,12 +44,17 @@
 
     parent_external_id: typing.Optional[str] = Field(alias='parent_external_id')
 
     item_type: typing.Optional[str] = Field(alias='item_type')
 
     root_external_id: typing.Optional[str] = Field(alias='root_external_id')
 
+    external_url: typing.Optional[str] = Field(alias='external_url')
+
     created_at: datetime = Field(alias='created_at')
 
     updated_at: datetime = Field(alias='updated_at')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/fetch_urls_response.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/pagination.py`

 * *Files 18% similar despite different names*

```diff
@@ -9,17 +9,19 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
-from carbon.pydantic.fetch_urls_response_urls import FetchURLsResponseUrls
 
-class FetchURLsResponse(BaseModel):
-    urls: FetchURLsResponseUrls = Field(alias='urls')
+class Pagination(BaseModel):
+    limit: typing.Optional[int] = Field(None, alias='limit')
 
-    html_content: str = Field(alias='html_content')
-    class Config:
-        arbitrary_types_allowed = True
+    offset: typing.Optional[int] = Field(None, alias='offset')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/file_formats.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/file_formats.py`

 * *Files 8% similar despite different names*

```diff
@@ -9,11 +9,11 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-FileFormats = Literal["TXT", "CSV", "TSV", "PDF", "DOCX", "PPTX", "XLSX", "MD", "RTF", "JSON", "NOTION", "GOOGLE_DOCS", "GOOGLE_SHEETS", "GOOGLE_SLIDES", "INTERCOM", "CONFLUENCE", "RSS_FEED", "GMAIL", "OUTLOOK", "ZENDESK", "FRESHDESK", "WEB_SCRAPE", "GITBOOK", "SALESFORCE", "JPG", "PNG", "MP3", "MP4", "MP2", "AAC", "WAV", "FLAC", "PCM", "M4A", "OGG", "OPUS", "WEBM"]
+FileFormats = Literal["TXT", "CSV", "TSV", "PDF", "DOCX", "PPTX", "XLSX", "MD", "RTF", "JSON", "HTML", "NOTION", "GOOGLE_DOCS", "GOOGLE_SHEETS", "GOOGLE_SLIDES", "INTERCOM", "CONFLUENCE", "RSS_FEED", "GMAIL", "OUTLOOK", "ZENDESK", "FRESHDESK", "WEB_SCRAPE", "GITBOOK", "SALESFORCE", "GITHUB", "JPG", "PNG", "MP3", "MP2", "AAC", "WAV", "FLAC", "PCM", "M4A", "OGG", "OPUS", "MPEG", "MPG", "MP4", "WMV", "AVI", "MOV", "MKV", "FLV", "WEBM"]
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/file_formats_nullable.py` & `carbon_python_sdk-0.2.0/carbon/type/file_formats_nullable.py`

 * *Files 27% similar despite different names*

```diff
@@ -9,11 +9,10 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
 
 
-FileFormatsNullable = Literal["TXT", "CSV", "TSV", "PDF", "DOCX", "PPTX", "XLSX", "MD", "RTF", "JSON", "NOTION", "GOOGLE_DOCS", "GOOGLE_SHEETS", "GOOGLE_SLIDES", "INTERCOM", "CONFLUENCE", "RSS_FEED", "GMAIL", "OUTLOOK", "ZENDESK", "FRESHDESK", "WEB_SCRAPE", "GITBOOK", "SALESFORCE", "JPG", "PNG", "MP3", "MP4", "MP2", "AAC", "WAV", "FLAC", "PCM", "M4A", "OGG", "OPUS", "WEBM"]
+FileFormatsNullable = Literal["TXT", "CSV", "TSV", "PDF", "DOCX", "PPTX", "XLSX", "MD", "RTF", "JSON", "HTML", "NOTION", "GOOGLE_DOCS", "GOOGLE_SHEETS", "GOOGLE_SLIDES", "INTERCOM", "CONFLUENCE", "RSS_FEED", "GMAIL", "OUTLOOK", "ZENDESK", "FRESHDESK", "WEB_SCRAPE", "GITBOOK", "SALESFORCE", "GITHUB", "JPG", "PNG", "MP3", "MP2", "AAC", "WAV", "FLAC", "PCM", "M4A", "OGG", "OPUS", "MPEG", "MPG", "MP4", "WMV", "AVI", "MOV", "MKV", "FLV", "WEBM"]
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/file_statistics.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/file_statistics.py`

 * *Files 13% similar despite different names*

```diff
@@ -9,23 +9,28 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.file_formats_nullable import FileFormatsNullable
 
 class FileStatistics(BaseModel):
     file_format: FileFormatsNullable = Field(alias='file_format')
 
     file_size: typing.Optional[int] = Field(alias='file_size')
 
     num_characters: typing.Optional[int] = Field(alias='num_characters')
 
     num_tokens: typing.Optional[int] = Field(alias='num_tokens')
 
     num_embeddings: typing.Optional[int] = Field(alias='num_embeddings')
-    class Config:
-        arbitrary_types_allowed = True
+
+    mime_type: typing.Optional[str] = Field(alias='mime_type')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/file_statistics_nullable.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/file_statistics_nullable.py`

 * *Files 10% similar despite different names*

```diff
@@ -9,23 +9,28 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.file_formats_nullable import FileFormatsNullable
 
 class FileStatisticsNullable(BaseModel):
     file_format: FileFormatsNullable = Field(alias='file_format')
 
     file_size: typing.Optional[int] = Field(alias='file_size')
 
     num_characters: typing.Optional[int] = Field(alias='num_characters')
 
     num_tokens: typing.Optional[int] = Field(alias='num_tokens')
 
     num_embeddings: typing.Optional[int] = Field(alias='num_embeddings')
-    class Config:
-        arbitrary_types_allowed = True
+
+    mime_type: typing.Optional[str] = Field(alias='mime_type')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/fresh_desk_connect_request.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/gitbook_connect_request.py`

 * *Files 11% similar despite different names*

```diff
@@ -9,33 +9,41 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
-from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.pydantic.embedding_generators import EmbeddingGenerators
 
-class FreshDeskConnectRequest(BaseModel):
-    domain: str = Field(alias='domain')
+class GitbookConnectRequest(BaseModel):
+    organization: str = Field(alias='organization')
 
-    api_key: str = Field(alias='api_key')
+    access_token: str = Field(alias='access_token')
 
     tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = Field(None, alias='tags')
 
     chunk_size: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_size')
 
     chunk_overlap: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_overlap')
 
     skip_embedding_generation: typing.Optional[typing.Optional[bool]] = Field(None, alias='skip_embedding_generation')
 
-    embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = Field(None, alias='embedding_model')
+    embedding_model: typing.Optional[EmbeddingGenerators] = Field(None, alias='embedding_model')
 
     generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = Field(None, alias='generate_sparse_vectors')
 
     prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = Field(None, alias='prepend_filename_to_chunks')
 
     sync_files_on_connection: typing.Optional[typing.Optional[bool]] = Field(None, alias='sync_files_on_connection')
-    class Config:
-        arbitrary_types_allowed = True
+
+    request_id: typing.Optional[typing.Optional[str]] = Field(None, alias='request_id')
+
+    # Enabling this flag will fetch all available content from the source to be listed via list items endpoint
+    sync_source_items: typing.Optional[bool] = Field(None, alias='sync_source_items')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/freskdesk_authentication.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/s3_authentication.py`

 * *Files 13% similar despite different names*

```diff
@@ -9,18 +9,21 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-class FreskdeskAuthentication(BaseModel):
+class S3Authentication(BaseModel):
     source: typing.Union[bool, date, datetime, dict, float, int, list, str, None] = Field(alias='source')
 
-    domain: str = Field(alias='domain')
+    access_key: str = Field(alias='access_key')
 
-    api_key: str = Field(alias='api_key')
-    class Config:
-        arbitrary_types_allowed = True
+    access_key_secret: str = Field(alias='access_key_secret')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/generic_success_response.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/delete_files_v2_query_input.py`

 * *Files 18% similar despite different names*

```diff
@@ -9,14 +9,20 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
+from carbon.pydantic.organization_user_files_to_sync_filters import OrganizationUserFilesToSyncFilters
 
-class GenericSuccessResponse(BaseModel):
-    success: bool = Field(alias='success')
-    class Config:
-        arbitrary_types_allowed = True
+class DeleteFilesV2QueryInput(BaseModel):
+    filters: typing.Optional[OrganizationUserFilesToSyncFilters] = Field(None, alias='filters')
+
+    send_webhook: typing.Optional[bool] = Field(None, alias='send_webhook')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/get_embedding_documents_body.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/get_embedding_documents_body.py`

 * *Files 8% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable
 from carbon.pydantic.file_content_types_nullable import FileContentTypesNullable
 from carbon.pydantic.get_embedding_documents_body_file_ids import GetEmbeddingDocumentsBodyFileIds
 from carbon.pydantic.get_embedding_documents_body_parent_file_ids import GetEmbeddingDocumentsBodyParentFileIds
 from carbon.pydantic.get_embedding_documents_body_query_vector import GetEmbeddingDocumentsBodyQueryVector
 from carbon.pydantic.get_embedding_documents_body_tags import GetEmbeddingDocumentsBodyTags
@@ -32,16 +32,20 @@
 
     tags: typing.Optional[GetEmbeddingDocumentsBodyTags] = Field(None, alias='tags')
 
     query_vector: typing.Optional[GetEmbeddingDocumentsBodyQueryVector] = Field(None, alias='query_vector')
 
     file_ids: typing.Optional[GetEmbeddingDocumentsBodyFileIds] = Field(None, alias='file_ids')
 
+    # WARNING: This property is deprecated
     parent_file_ids: typing.Optional[GetEmbeddingDocumentsBodyParentFileIds] = Field(None, alias='parent_file_ids')
 
+    # Flag to control whether or not to include all children of filtered files in the embedding search.
+    include_all_children: typing.Optional[bool] = Field(None, alias='include_all_children')
+
     # A set of tags to limit the search to. Use this instead of `tags`, which is deprecated.
     tags_v2: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = Field(None, alias='tags_v2')
 
     # Flag to control whether or not to include tags for each chunk in the response.
     include_tags: typing.Optional[typing.Optional[bool]] = Field(None, alias='include_tags')
 
     # Flag to control whether or not to include embedding vectors in the response.
@@ -54,9 +58,12 @@
     hybrid_search: typing.Optional[typing.Optional[bool]] = Field(None, alias='hybrid_search')
 
     hybrid_search_tuning_parameters: typing.Optional[HybridSearchTuningParamsNullable] = Field(None, alias='hybrid_search_tuning_parameters')
 
     media_type: typing.Optional[FileContentTypesNullable] = Field(None, alias='media_type')
 
     embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = Field(None, alias='embedding_model')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/gitbook_authetication.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/github_authentication.py`

 * *Files 16% similar despite different names*

```diff
@@ -9,18 +9,21 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-class GitbookAuthetication(BaseModel):
+class GithubAuthentication(BaseModel):
     source: typing.Union[bool, date, datetime, dict, float, int, list, str, None] = Field(alias='source')
 
     access_token: str = Field(alias='access_token')
 
-    organization_name: str = Field(alias='organization_name')
-    class Config:
-        arbitrary_types_allowed = True
+    username: str = Field(alias='username')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/gitbook_connect_request.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/outlook_sync_input.py`

 * *Files 20% similar despite different names*

```diff
@@ -9,33 +9,45 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.embedding_generators import EmbeddingGenerators
+from carbon.pydantic.file_sync_config_nullable import FileSyncConfigNullable
 
-class GitbookConnectRequest(BaseModel):
-    organization: str = Field(alias='organization')
-
-    access_token: str = Field(alias='access_token')
+class OutlookSyncInput(BaseModel):
+    filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = Field(alias='filters')
 
     tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = Field(None, alias='tags')
 
+    folder: typing.Optional[typing.Optional[str]] = Field(None, alias='folder')
+
     chunk_size: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_size')
 
     chunk_overlap: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_overlap')
 
     skip_embedding_generation: typing.Optional[typing.Optional[bool]] = Field(None, alias='skip_embedding_generation')
 
     embedding_model: typing.Optional[EmbeddingGenerators] = Field(None, alias='embedding_model')
 
     generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = Field(None, alias='generate_sparse_vectors')
 
     prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = Field(None, alias='prepend_filename_to_chunks')
 
-    sync_files_on_connection: typing.Optional[typing.Optional[bool]] = Field(None, alias='sync_files_on_connection')
-    class Config:
-        arbitrary_types_allowed = True
+    data_source_id: typing.Optional[typing.Optional[int]] = Field(None, alias='data_source_id')
+
+    request_id: typing.Optional[typing.Optional[str]] = Field(None, alias='request_id')
+
+    sync_attachments: typing.Optional[typing.Optional[bool]] = Field(None, alias='sync_attachments')
+
+    file_sync_config: typing.Optional[FileSyncConfigNullable] = Field(None, alias='file_sync_config')
+
+    incremental_sync: typing.Optional[bool] = Field(None, alias='incremental_sync')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/gitbook_sync_request.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/gitbook_sync_request.py`

 * *Files 6% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.embedding_generators import EmbeddingGenerators
 from carbon.pydantic.gitbook_sync_request_space_ids import GitbookSyncRequestSpaceIds
 
 class GitbookSyncRequest(BaseModel):
     space_ids: GitbookSyncRequestSpaceIds = Field(alias='space_ids')
 
@@ -32,9 +32,14 @@
     skip_embedding_generation: typing.Optional[typing.Optional[bool]] = Field(None, alias='skip_embedding_generation')
 
     embedding_model: typing.Optional[EmbeddingGenerators] = Field(None, alias='embedding_model')
 
     generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = Field(None, alias='generate_sparse_vectors')
 
     prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = Field(None, alias='prepend_filename_to_chunks')
-    class Config:
-        arbitrary_types_allowed = True
+
+    request_id: typing.Optional[typing.Optional[str]] = Field(None, alias='request_id')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/gmail_sync_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/rss_feed_input.py`

 * *Files 6% similar despite different names*

```diff
@@ -9,20 +9,20 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.embedding_generators import EmbeddingGenerators
 
-class GmailSyncInput(BaseModel):
-    filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = Field(alias='filters')
+class RSSFeedInput(BaseModel):
+    url: str = Field(alias='url')
 
     tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = Field(None, alias='tags')
 
     chunk_size: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_size')
 
     chunk_overlap: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_overlap')
 
@@ -30,10 +30,13 @@
 
     embedding_model: typing.Optional[EmbeddingGenerators] = Field(None, alias='embedding_model')
 
     generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = Field(None, alias='generate_sparse_vectors')
 
     prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = Field(None, alias='prepend_filename_to_chunks')
 
-    data_source_id: typing.Optional[typing.Optional[int]] = Field(None, alias='data_source_id')
-    class Config:
-        arbitrary_types_allowed = True
+    request_id: typing.Optional[typing.Optional[str]] = Field(None, alias='request_id')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/http_validation_error.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/http_validation_error.py`

 * *Files 14% similar despite different names*

```diff
@@ -9,15 +9,18 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.validation_error import ValidationError
 
 class HTTPValidationError(BaseModel):
     detail: typing.Optional[typing.List[ValidationError]] = Field(None, alias='detail')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/hybrid_search_tuning_params.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/hybrid_search_tuning_params_nullable.py`

 * *Files 19% similar despite different names*

```diff
@@ -9,16 +9,19 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-class HybridSearchTuningParams(BaseModel):
+class HybridSearchTuningParamsNullable(BaseModel):
     weight_a: typing.Union[int, float] = Field(alias='weight_a')
 
     weight_b: typing.Union[int, float] = Field(alias='weight_b')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/hybrid_search_tuning_params_nullable.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/token_response.py`

 * *Files 21% similar despite different names*

```diff
@@ -9,16 +9,19 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-class HybridSearchTuningParamsNullable(BaseModel):
-    weight_a: typing.Union[int, float] = Field(alias='weight_a')
+class TokenResponse(BaseModel):
+    access_token: str = Field(alias='access_token')
 
-    weight_b: typing.Union[int, float] = Field(alias='weight_b')
-    class Config:
-        arbitrary_types_allowed = True
+    refresh_token: str = Field(alias='refresh_token')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/list_data_source_items_request.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/zendesk_authentication.py`

 * *Files 18% similar despite different names*

```diff
@@ -9,19 +9,21 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
-from carbon.pydantic.pagination import Pagination
 
-class ListDataSourceItemsRequest(BaseModel):
-    data_source_id: int = Field(alias='data_source_id')
+class ZendeskAuthentication(BaseModel):
+    source: typing.Union[bool, date, datetime, dict, float, int, list, str, None] = Field(alias='source')
 
-    parent_id: typing.Optional[typing.Optional[str]] = Field(None, alias='parent_id')
+    access_token: str = Field(alias='access_token')
 
-    pagination: typing.Optional[Pagination] = Field(None, alias='pagination')
-    class Config:
-        arbitrary_types_allowed = True
+    subdomain: str = Field(alias='subdomain')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/list_data_source_items_response.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/presigned_url_response.py`

 * *Files 19% similar despite different names*

```diff
@@ -9,17 +9,17 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
-from carbon.pydantic.external_source_item import ExternalSourceItem
 
-class ListDataSourceItemsResponse(BaseModel):
-    items: typing.List[ExternalSourceItem] = Field(alias='items')
+class PresignedURLResponse(BaseModel):
+    presigned_url: str = Field(alias='presigned_url')
 
-    count: int = Field(alias='count')
-    class Config:
-        arbitrary_types_allowed = True
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/list_request.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/salesforce_authentication.py`

 * *Files 17% similar despite different names*

```diff
@@ -9,16 +9,23 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-class ListRequest(BaseModel):
-    data_source_id: int = Field(alias='data_source_id')
+class SalesforceAuthentication(BaseModel):
+    source: typing.Union[bool, date, datetime, dict, float, int, list, str, None] = Field(alias='source')
 
-    parent_id: typing.Optional[typing.Optional[str]] = Field(None, alias='parent_id')
-    class Config:
-        arbitrary_types_allowed = True
+    access_token: str = Field(alias='access_token')
+
+    domain: str = Field(alias='domain')
+
+    refresh_token: typing.Optional[typing.Optional[str]] = Field(None, alias='refresh_token')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/list_response.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/list_response.py`

 * *Files 12% similar despite different names*

```diff
@@ -9,15 +9,18 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.directory_item import DirectoryItem
 
 class ListResponse(BaseModel):
     data: typing.List[DirectoryItem] = Field(alias='data')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/modify_user_configuration_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/modify_user_configuration_input.py`

 * *Files 20% similar despite different names*

```diff
@@ -9,16 +9,19 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
 class ModifyUserConfigurationInput(BaseModel):
     configuration_key_name: str = Field(alias='configuration_key_name')
 
     value: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = Field(alias='value')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/notion_authentication.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/notion_authentication.py`

 * *Files 14% similar despite different names*

```diff
@@ -9,18 +9,21 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
 class NotionAuthentication(BaseModel):
     source: typing.Union[bool, date, datetime, dict, float, int, list, str, None] = Field(alias='source')
 
     access_token: str = Field(alias='access_token')
 
     workspace_id: str = Field(alias='workspace_id')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/o_auth_authentication.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/sharepoint_authentication.py`

 * *Files 12% similar despite different names*

```diff
@@ -9,19 +9,25 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
-from carbon.pydantic.simple_o_auth_data_sources import SimpleOAuthDataSources
 
-class OAuthAuthentication(BaseModel):
-    source: SimpleOAuthDataSources = Field(alias='source')
+class SharepointAuthentication(BaseModel):
+    source: typing.Union[bool, date, datetime, dict, float, int, list, str, None] = Field(alias='source')
 
     access_token: str = Field(alias='access_token')
 
+    tenant_name: str = Field(alias='tenant_name')
+
+    site_name: str = Field(alias='site_name')
+
     refresh_token: typing.Optional[typing.Optional[str]] = Field(None, alias='refresh_token')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/o_auth_url_request.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/fresh_desk_connect_request.py`

 * *Files 24% similar despite different names*

```diff
@@ -9,55 +9,44 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
-from carbon.pydantic.data_source_type import DataSourceType
 from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.pydantic.file_sync_config_nullable import FileSyncConfigNullable
 
-class OAuthURLRequest(BaseModel):
-    service: DataSourceType = Field(alias='service')
+class FreshDeskConnectRequest(BaseModel):
+    domain: str = Field(alias='domain')
 
-    tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = Field(None, alias='tags')
+    api_key: str = Field(alias='api_key')
 
-    scope: typing.Optional[typing.Optional[str]] = Field(None, alias='scope')
+    tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = Field(None, alias='tags')
 
     chunk_size: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_size')
 
     chunk_overlap: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_overlap')
 
     skip_embedding_generation: typing.Optional[typing.Optional[bool]] = Field(None, alias='skip_embedding_generation')
 
     embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = Field(None, alias='embedding_model')
 
-    zendesk_subdomain: typing.Optional[typing.Optional[str]] = Field(None, alias='zendesk_subdomain')
-
-    microsoft_tenant: typing.Optional[typing.Optional[str]] = Field(None, alias='microsoft_tenant')
-
-    sharepoint_site_name: typing.Optional[typing.Optional[str]] = Field(None, alias='sharepoint_site_name')
-
-    confluence_subdomain: typing.Optional[typing.Optional[str]] = Field(None, alias='confluence_subdomain')
-
     generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = Field(None, alias='generate_sparse_vectors')
 
     prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = Field(None, alias='prepend_filename_to_chunks')
 
-    max_items_per_chunk: typing.Optional[typing.Optional[int]] = Field(None, alias='max_items_per_chunk')
-
-    salesforce_domain: typing.Optional[typing.Optional[str]] = Field(None, alias='salesforce_domain')
-
-    # Used to specify whether Carbon should attempt to sync all your files automatically when authorization         is complete. This is only supported for a subset of connectors and will be ignored for the rest. Supported         connectors: Intercom, Zendesk, Gitbook, Confluence, Salesforce, Freshdesk
     sync_files_on_connection: typing.Optional[typing.Optional[bool]] = Field(None, alias='sync_files_on_connection')
 
-    set_page_as_boundary: typing.Optional[bool] = Field(None, alias='set_page_as_boundary')
+    request_id: typing.Optional[typing.Optional[str]] = Field(None, alias='request_id')
+
+    # Enabling this flag will fetch all available content from the source to be listed via list items endpoint
+    sync_source_items: typing.Optional[bool] = Field(None, alias='sync_source_items')
 
-    # Used to specify a data source to sync from if you have multiple connected. It can be skipped if          you only have one data source of that type connected or are connecting a new account.
-    data_source_id: typing.Optional[typing.Optional[int]] = Field(None, alias='data_source_id')
+    file_sync_config: typing.Optional[FileSyncConfigNullable] = Field(None, alias='file_sync_config')
 
-    # Used to connect a new data source. If not specified, we will attempt to create a sync URL         for an existing data source based on type and ID.
-    connecting_new_account: typing.Optional[typing.Optional[bool]] = Field(None, alias='connecting_new_account')
-    class Config:
-        arbitrary_types_allowed = True
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/organization_response.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/organization_response.py`

 * *Files 12% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
 class OrganizationResponse(BaseModel):
     id: int = Field(alias='id')
 
     name: str = Field(alias='name')
 
@@ -33,16 +33,27 @@
 
     aggregate_num_characters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = Field(alias='aggregate_num_characters')
 
     aggregate_num_tokens: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = Field(alias='aggregate_num_tokens')
 
     aggregate_num_embeddings: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = Field(alias='aggregate_num_embeddings')
 
+    aggregate_num_files_by_source: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = Field(alias='aggregate_num_files_by_source')
+
+    aggregate_num_files_by_file_format: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = Field(alias='aggregate_num_files_by_file_format')
+
+    file_statistics_aggregated_at: typing.Optional[datetime] = Field(alias='file_statistics_aggregated_at')
+
     period_ends_at: typing.Optional[datetime] = Field(alias='period_ends_at')
 
     cancel_at_period_end: typing.Optional[bool] = Field(alias='cancel_at_period_end')
 
+    global_user_config: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = Field(alias='global_user_config')
+
     created_at: datetime = Field(alias='created_at')
 
     updated_at: datetime = Field(alias='updated_at')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_data_source_api.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_data_source_api.py`

 * *Files 9% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.data_source_last_sync_actions import DataSourceLastSyncActions
 from carbon.pydantic.data_source_sync_statuses import DataSourceSyncStatuses
 from carbon.pydantic.data_source_type import DataSourceType
 
 class OrganizationUserDataSourceAPI(BaseModel):
     id: int = Field(alias='id')
@@ -40,12 +40,21 @@
 
     revoked_access: bool = Field(alias='revoked_access')
 
     last_synced_at: datetime = Field(alias='last_synced_at')
 
     last_sync_action: DataSourceLastSyncActions = Field(alias='last_sync_action')
 
+    enable_auto_sync: typing.Optional[bool] = Field(alias='enable_auto_sync')
+
     created_at: datetime = Field(alias='created_at')
 
     updated_at: datetime = Field(alias='updated_at')
-    class Config:
-        arbitrary_types_allowed = True
+
+    files_synced_at: typing.Optional[datetime] = Field(alias='files_synced_at')
+
+    data_source_metadata: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = Field(alias='data_source_metadata')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_data_source_filters.py` & `carbon_python_sdk-0.2.0/carbon/type/organization_user_data_source_filters.py`

 * *Files 20% similar despite different names*

```diff
@@ -9,20 +9,23 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
 
-from carbon.pydantic.data_source_type_nullable import DataSourceTypeNullable
-from carbon.pydantic.organization_user_data_source_filters_ids import OrganizationUserDataSourceFiltersIds
+from carbon.type.data_source_type_nullable import DataSourceTypeNullable
+from carbon.type.organization_user_data_source_filters_ids import OrganizationUserDataSourceFiltersIds
 
-class OrganizationUserDataSourceFilters(BaseModel):
-    source: typing.Optional[DataSourceTypeNullable] = Field(None, alias='source')
+class RequiredOrganizationUserDataSourceFilters(TypedDict):
+    pass
 
-    ids: typing.Optional[OrganizationUserDataSourceFiltersIds] = Field(None, alias='ids')
+class OptionalOrganizationUserDataSourceFilters(TypedDict, total=False):
+    source: typing.Optional[DataSourceTypeNullable]
 
-    revoked_access: typing.Optional[typing.Optional[bool]] = Field(None, alias='revoked_access')
-    class Config:
-        arbitrary_types_allowed = True
+    ids: typing.Optional[OrganizationUserDataSourceFiltersIds]
+
+    revoked_access: typing.Optional[bool]
+
+class OrganizationUserDataSourceFilters(RequiredOrganizationUserDataSourceFilters, OptionalOrganizationUserDataSourceFilters):
+    pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_data_source_query_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_data_source_query_input.py`

 * *Files 5% similar despite different names*

```diff
@@ -9,24 +9,27 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.order_dir import OrderDir
 from carbon.pydantic.organization_user_data_source_filters import OrganizationUserDataSourceFilters
 from carbon.pydantic.organization_user_data_source_order_by_columns import OrganizationUserDataSourceOrderByColumns
 from carbon.pydantic.pagination import Pagination
 
 class OrganizationUserDataSourceQueryInput(BaseModel):
     pagination: typing.Optional[Pagination] = Field(None, alias='pagination')
 
     order_by: typing.Optional[OrganizationUserDataSourceOrderByColumns] = Field(None, alias='order_by')
 
     order_dir: typing.Optional[OrderDir] = Field(None, alias='order_dir')
 
     filters: typing.Optional[OrganizationUserDataSourceFilters] = Field(None, alias='filters')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_data_source_response.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_data_source_response.py`

 * *Files 14% similar despite different names*

```diff
@@ -9,17 +9,20 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.organization_user_data_source_api import OrganizationUserDataSourceAPI
 
 class OrganizationUserDataSourceResponse(BaseModel):
     results: typing.List[OrganizationUserDataSourceAPI] = Field(alias='results')
 
     count: int = Field(alias='count')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_file_tag_create.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_file_tag_create.py`

 * *Files 12% similar despite different names*

```diff
@@ -9,17 +9,20 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.organization_user_file_tag_create_tags import OrganizationUserFileTagCreateTags
 
 class OrganizationUserFileTagCreate(BaseModel):
     tags: OrganizationUserFileTagCreateTags = Field(alias='tags')
 
     organization_user_file_id: int = Field(alias='organization_user_file_id')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_file_tags_remove.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_file_tags_remove.py`

 * *Files 8% similar despite different names*

```diff
@@ -9,17 +9,20 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.organization_user_file_tags_remove_tags import OrganizationUserFileTagsRemoveTags
 
 class OrganizationUserFileTagsRemove(BaseModel):
     tags: OrganizationUserFileTagsRemoveTags = Field(alias='tags')
 
     organization_user_file_id: int = Field(alias='organization_user_file_id')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/organization_user_files_to_sync_query_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_files_to_sync_query_input.py`

 * *Files 5% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.order_dir import OrderDir
 from carbon.pydantic.organization_user_files_to_sync_filters import OrganizationUserFilesToSyncFilters
 from carbon.pydantic.organization_user_files_to_sync_order_by_types import OrganizationUserFilesToSyncOrderByTypes
 from carbon.pydantic.pagination import Pagination
 
 class OrganizationUserFilesToSyncQueryInput(BaseModel):
@@ -30,9 +30,12 @@
     filters: typing.Optional[OrganizationUserFilesToSyncFilters] = Field(None, alias='filters')
 
     include_raw_file: typing.Optional[typing.Optional[bool]] = Field(None, alias='include_raw_file')
 
     include_parsed_text_file: typing.Optional[typing.Optional[bool]] = Field(None, alias='include_parsed_text_file')
 
     include_additional_files: typing.Optional[typing.Optional[bool]] = Field(None, alias='include_additional_files')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/outlook_sync_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/gmail_sync_input.py`

 * *Files 22% similar despite different names*

```diff
@@ -9,33 +9,43 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.embedding_generators import EmbeddingGenerators
+from carbon.pydantic.file_sync_config_nullable import FileSyncConfigNullable
 
-class OutlookSyncInput(BaseModel):
+class GmailSyncInput(BaseModel):
     filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = Field(alias='filters')
 
     tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = Field(None, alias='tags')
 
-    folder: typing.Optional[typing.Optional[str]] = Field(None, alias='folder')
-
     chunk_size: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_size')
 
     chunk_overlap: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_overlap')
 
     skip_embedding_generation: typing.Optional[typing.Optional[bool]] = Field(None, alias='skip_embedding_generation')
 
     embedding_model: typing.Optional[EmbeddingGenerators] = Field(None, alias='embedding_model')
 
     generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = Field(None, alias='generate_sparse_vectors')
 
     prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = Field(None, alias='prepend_filename_to_chunks')
 
     data_source_id: typing.Optional[typing.Optional[int]] = Field(None, alias='data_source_id')
-    class Config:
-        arbitrary_types_allowed = True
+
+    request_id: typing.Optional[typing.Optional[str]] = Field(None, alias='request_id')
+
+    sync_attachments: typing.Optional[typing.Optional[bool]] = Field(None, alias='sync_attachments')
+
+    file_sync_config: typing.Optional[FileSyncConfigNullable] = Field(None, alias='file_sync_config')
+
+    incremental_sync: typing.Optional[bool] = Field(None, alias='incremental_sync')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/pagination.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/document_response_list.py`

 * *Files 24% similar despite different names*

```diff
@@ -9,16 +9,18 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
+from carbon.pydantic.document_response import DocumentResponse
 
-class Pagination(BaseModel):
-    limit: typing.Optional[int] = Field(None, alias='limit')
+class DocumentResponseList(BaseModel):
+    documents: typing.List[DocumentResponse] = Field(alias='documents')
 
-    offset: typing.Optional[int] = Field(None, alias='offset')
-    class Config:
-        arbitrary_types_allowed = True
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/presigned_url_response.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/generic_success_response.py`

 * *Files 18% similar despite different names*

```diff
@@ -9,14 +9,17 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-class PresignedURLResponse(BaseModel):
-    presigned_url: str = Field(alias='presigned_url')
-    class Config:
-        arbitrary_types_allowed = True
+class GenericSuccessResponse(BaseModel):
+    success: bool = Field(alias='success')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/raw_text_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/raw_text_input.py`

 * *Files 15% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable
 
 class RawTextInput(BaseModel):
     contents: str = Field(alias='contents')
 
     name: typing.Optional[typing.Optional[str]] = Field(None, alias='name')
@@ -29,9 +29,12 @@
     skip_embedding_generation: typing.Optional[bool] = Field(None, alias='skip_embedding_generation')
 
     overwrite_file_id: typing.Optional[typing.Optional[int]] = Field(None, alias='overwrite_file_id')
 
     embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = Field(None, alias='embedding_model')
 
     generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = Field(None, alias='generate_sparse_vectors')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/resync_file_query_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/resync_file_query_input.py`

 * *Files 21% similar despite different names*

```diff
@@ -9,20 +9,23 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
 class ResyncFileQueryInput(BaseModel):
     file_id: int = Field(alias='file_id')
 
     chunk_size: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_size')
 
     chunk_overlap: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_overlap')
 
     force_embedding_generation: typing.Optional[bool] = Field(None, alias='force_embedding_generation')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/revoke_access_token_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/list_data_source_items_response.py`

 * *Files 19% similar despite different names*

```diff
@@ -9,14 +9,20 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
+from carbon.pydantic.external_source_item import ExternalSourceItem
 
-class RevokeAccessTokenInput(BaseModel):
-    data_source_id: int = Field(alias='data_source_id')
-    class Config:
-        arbitrary_types_allowed = True
+class ListDataSourceItemsResponse(BaseModel):
+    items: typing.List[ExternalSourceItem] = Field(alias='items')
+
+    count: int = Field(alias='count')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/rss_feed_input.py` & `carbon_python_sdk-0.2.0/carbon/type/s3_file_sync_input.py`

 * *Files 19% similar despite different names*

```diff
@@ -9,29 +9,48 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
 
-from carbon.pydantic.embedding_generators import EmbeddingGenerators
+from carbon.type.embedding_generators import EmbeddingGenerators
+from carbon.type.file_sync_config_nullable import FileSyncConfigNullable
+from carbon.type.s3_get_file_input import S3GetFileInput
 
-class RSSFeedInput(BaseModel):
-    url: str = Field(alias='url')
+class RequiredS3FileSyncInput(TypedDict):
+    ids: typing.List[S3GetFileInput]
 
-    tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = Field(None, alias='tags')
 
-    chunk_size: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_size')
+class OptionalS3FileSyncInput(TypedDict, total=False):
+    tags: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
 
-    chunk_overlap: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_overlap')
+    chunk_size: typing.Optional[int]
 
-    skip_embedding_generation: typing.Optional[typing.Optional[bool]] = Field(None, alias='skip_embedding_generation')
+    chunk_overlap: typing.Optional[int]
 
-    embedding_model: typing.Optional[EmbeddingGenerators] = Field(None, alias='embedding_model')
+    skip_embedding_generation: typing.Optional[bool]
 
-    generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = Field(None, alias='generate_sparse_vectors')
+    embedding_model: EmbeddingGenerators
 
-    prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = Field(None, alias='prepend_filename_to_chunks')
-    class Config:
-        arbitrary_types_allowed = True
+    generate_sparse_vectors: typing.Optional[bool]
+
+    prepend_filename_to_chunks: typing.Optional[bool]
+
+    # Number of objects per chunk. For csv, tsv, xlsx, and json files only.
+    max_items_per_chunk: typing.Optional[int]
+
+    set_page_as_boundary: bool
+
+    data_source_id: typing.Optional[int]
+
+    request_id: typing.Optional[str]
+
+    use_ocr: typing.Optional[bool]
+
+    parse_pdf_tables_with_ocr: typing.Optional[bool]
+
+    file_sync_config: typing.Optional[FileSyncConfigNullable]
+
+class S3FileSyncInput(RequiredS3FileSyncInput, OptionalS3FileSyncInput):
+    pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/s3_auth_request.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/s3_auth_request.py`

 * *Files 24% similar despite different names*

```diff
@@ -9,16 +9,22 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
 class S3AuthRequest(BaseModel):
     access_key: str = Field(alias='access_key')
 
     access_key_secret: str = Field(alias='access_key_secret')
-    class Config:
-        arbitrary_types_allowed = True
+
+    # Enabling this flag will fetch all available content from the source to be listed via list items endpoint
+    sync_source_items: typing.Optional[bool] = Field(None, alias='sync_source_items')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/s3_authentication.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/zotero_authentication.py`

 * *Files 18% similar despite different names*

```diff
@@ -9,18 +9,25 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-class S3Authentication(BaseModel):
+class ZoteroAuthentication(BaseModel):
     source: typing.Union[bool, date, datetime, dict, float, int, list, str, None] = Field(alias='source')
 
-    access_key: str = Field(alias='access_key')
+    access_token: str = Field(alias='access_token')
 
-    access_key_secret: str = Field(alias='access_key_secret')
-    class Config:
-        arbitrary_types_allowed = True
+    access_token_secret: str = Field(alias='access_token_secret')
+
+    username: str = Field(alias='username')
+
+    zotero_id: str = Field(alias='zotero_id')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/s3_file_sync_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/s3_file_sync_input.py`

 * *Files 13% similar despite different names*

```diff
@@ -9,17 +9,18 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.embedding_generators import EmbeddingGenerators
+from carbon.pydantic.file_sync_config_nullable import FileSyncConfigNullable
 from carbon.pydantic.s3_get_file_input import S3GetFileInput
 
 class S3FileSyncInput(BaseModel):
     ids: typing.List[S3GetFileInput] = Field(alias='ids')
 
     tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = Field(None, alias='tags')
 
@@ -31,14 +32,26 @@
 
     embedding_model: typing.Optional[EmbeddingGenerators] = Field(None, alias='embedding_model')
 
     generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = Field(None, alias='generate_sparse_vectors')
 
     prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = Field(None, alias='prepend_filename_to_chunks')
 
+    # Number of objects per chunk. For csv, tsv, xlsx, and json files only.
     max_items_per_chunk: typing.Optional[typing.Optional[int]] = Field(None, alias='max_items_per_chunk')
 
     set_page_as_boundary: typing.Optional[bool] = Field(None, alias='set_page_as_boundary')
 
     data_source_id: typing.Optional[typing.Optional[int]] = Field(None, alias='data_source_id')
-    class Config:
-        arbitrary_types_allowed = True
+
+    request_id: typing.Optional[typing.Optional[str]] = Field(None, alias='request_id')
+
+    use_ocr: typing.Optional[typing.Optional[bool]] = Field(None, alias='use_ocr')
+
+    parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = Field(None, alias='parse_pdf_tables_with_ocr')
+
+    file_sync_config: typing.Optional[FileSyncConfigNullable] = Field(None, alias='file_sync_config')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/s3_get_file_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/outh_url_response.py`

 * *Files 18% similar despite different names*

```diff
@@ -9,16 +9,17 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-class S3GetFileInput(BaseModel):
-    id: typing.Optional[typing.Optional[str]] = Field(None, alias='id')
+class OuthURLResponse(BaseModel):
+    oauth_url: str = Field(alias='oauth_url')
 
-    bucket: typing.Optional[typing.Optional[str]] = Field(None, alias='bucket')
-    class Config:
-        arbitrary_types_allowed = True
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/salesforce_authentication.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/sync_files_ids.py`

 * *Files 18% similar despite different names*

```diff
@@ -9,20 +9,19 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-class SalesforceAuthentication(BaseModel):
-    source: typing.Union[bool, date, datetime, dict, float, int, list, str, None] = Field(alias='source')
+class SyncFilesIds(BaseModel):
+    id: str = Field(alias='id')
 
-    access_token: str = Field(alias='access_token')
+    root_id: str = Field(alias='root_id')
 
-    domain: str = Field(alias='domain')
-
-    refresh_token: typing.Optional[typing.Optional[str]] = Field(None, alias='refresh_token')
-    class Config:
-        arbitrary_types_allowed = True
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/sharepoint_authentication.py` & `carbon_python_sdk-0.2.0/carbon/type/sharepoint_authentication.py`

 * *Files 24% similar despite different names*

```diff
@@ -9,22 +9,24 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
 
 
-class SharepointAuthentication(BaseModel):
-    source: typing.Union[bool, date, datetime, dict, float, int, list, str, None] = Field(alias='source')
+class RequiredSharepointAuthentication(TypedDict):
+    source: typing.Union[bool, date, datetime, dict, float, int, list, str, None]
 
-    access_token: str = Field(alias='access_token')
+    access_token: str
 
-    tenant_name: str = Field(alias='tenant_name')
+    tenant_name: str
 
-    site_name: str = Field(alias='site_name')
+    site_name: str
 
-    refresh_token: typing.Optional[typing.Optional[str]] = Field(None, alias='refresh_token')
-    class Config:
-        arbitrary_types_allowed = True
+
+class OptionalSharepointAuthentication(TypedDict, total=False):
+    refresh_token: typing.Optional[str]
+
+class SharepointAuthentication(RequiredSharepointAuthentication, OptionalSharepointAuthentication):
+    pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/single_chunks_and_embeddings_upload_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/single_chunks_and_embeddings_upload_input.py`

 * *Files 6% similar despite different names*

```diff
@@ -9,21 +9,24 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.chunks_and_embeddings import ChunksAndEmbeddings
 
 class SingleChunksAndEmbeddingsUploadInput(BaseModel):
     file_id: int = Field(alias='file_id')
 
     chunks_and_embeddings: typing.List[ChunksAndEmbeddings] = Field(alias='chunks_and_embeddings')
 
     chunk_size: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_size')
 
     chunk_overlap: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_overlap')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/sitemap_scrape_request.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/sitemap_scrape_request.py`

 * *Files 12% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.embedding_generators import EmbeddingGenerators
 from carbon.pydantic.sitemap_scrape_request_css_classes_to_skip import SitemapScrapeRequestCssClassesToSkip
 from carbon.pydantic.sitemap_scrape_request_css_selectors_to_skip import SitemapScrapeRequestCssSelectorsToSkip
 from carbon.pydantic.sitemap_scrape_request_html_tags_to_skip import SitemapScrapeRequestHtmlTagsToSkip
 from carbon.pydantic.sitemap_scrape_request_tags import SitemapScrapeRequestTags
 
@@ -43,9 +43,12 @@
     html_tags_to_skip: typing.Optional[SitemapScrapeRequestHtmlTagsToSkip] = Field(None, alias='html_tags_to_skip')
 
     css_classes_to_skip: typing.Optional[SitemapScrapeRequestCssClassesToSkip] = Field(None, alias='css_classes_to_skip')
 
     css_selectors_to_skip: typing.Optional[SitemapScrapeRequestCssSelectorsToSkip] = Field(None, alias='css_selectors_to_skip')
 
     embedding_model: typing.Optional[EmbeddingGenerators] = Field(None, alias='embedding_model')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/sync_directory_request.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/embeddings_and_chunks_response.py`

 * *Files 18% similar despite different names*

```diff
@@ -9,14 +9,20 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
+from carbon.pydantic.embedding_and_chunk import EmbeddingAndChunk
 
-class SyncDirectoryRequest(BaseModel):
-    data_source_id: int = Field(alias='data_source_id')
-    class Config:
-        arbitrary_types_allowed = True
+class EmbeddingsAndChunksResponse(BaseModel):
+    results: typing.List[EmbeddingAndChunk] = Field(alias='results')
+
+    count: int = Field(alias='count')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/sync_files_ids.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/freskdesk_authentication.py`

 * *Files 16% similar despite different names*

```diff
@@ -9,16 +9,21 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-class SyncFilesIds(BaseModel):
-    id: str = Field(alias='id')
+class FreskdeskAuthentication(BaseModel):
+    source: typing.Union[bool, date, datetime, dict, float, int, list, str, None] = Field(alias='source')
 
-    root_id: str = Field(alias='root_id')
-    class Config:
-        arbitrary_types_allowed = True
+    domain: str = Field(alias='domain')
+
+    api_key: str = Field(alias='api_key')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/sync_files_request.py` & `carbon_python_sdk-0.2.0/carbon/type/gmail_sync_input.py`

 * *Files 26% similar despite different names*

```diff
@@ -9,36 +9,42 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
 
-from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable
-from carbon.pydantic.sync_files_ids import SyncFilesIds
+from carbon.type.embedding_generators import EmbeddingGenerators
+from carbon.type.file_sync_config_nullable import FileSyncConfigNullable
 
-class SyncFilesRequest(BaseModel):
-    data_source_id: int = Field(alias='data_source_id')
+class RequiredGmailSyncInput(TypedDict):
+    filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
 
-    ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]] = Field(alias='ids')
 
-    tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = Field(None, alias='tags')
+class OptionalGmailSyncInput(TypedDict, total=False):
+    tags: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
 
-    chunk_size: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_size')
+    chunk_size: typing.Optional[int]
 
-    chunk_overlap: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_overlap')
+    chunk_overlap: typing.Optional[int]
 
-    skip_embedding_generation: typing.Optional[typing.Optional[bool]] = Field(None, alias='skip_embedding_generation')
+    skip_embedding_generation: typing.Optional[bool]
 
-    embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = Field(None, alias='embedding_model')
+    embedding_model: EmbeddingGenerators
 
-    generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = Field(None, alias='generate_sparse_vectors')
+    generate_sparse_vectors: typing.Optional[bool]
 
-    prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = Field(None, alias='prepend_filename_to_chunks')
+    prepend_filename_to_chunks: typing.Optional[bool]
 
-    max_items_per_chunk: typing.Optional[typing.Optional[int]] = Field(None, alias='max_items_per_chunk')
+    data_source_id: typing.Optional[int]
 
-    set_page_as_boundary: typing.Optional[bool] = Field(None, alias='set_page_as_boundary')
-    class Config:
-        arbitrary_types_allowed = True
+    request_id: typing.Optional[str]
+
+    sync_attachments: typing.Optional[bool]
+
+    file_sync_config: typing.Optional[FileSyncConfigNullable]
+
+    incremental_sync: bool
+
+class GmailSyncInput(RequiredGmailSyncInput, OptionalGmailSyncInput):
+    pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/sync_options.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/sync_options.py`

 * *Files 10% similar despite different names*

```diff
@@ -9,17 +9,18 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.pydantic.file_sync_config_nullable import FileSyncConfigNullable
 
 class SyncOptions(BaseModel):
     tags: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = Field(None, alias='tags')
 
     chunk_size: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_size')
 
     chunk_overlap: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_overlap')
@@ -28,15 +29,31 @@
 
     embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = Field(None, alias='embedding_model')
 
     generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = Field(None, alias='generate_sparse_vectors')
 
     prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = Field(None, alias='prepend_filename_to_chunks')
 
+    # Number of objects per chunk. For csv, tsv, xlsx, and json files only.
     max_items_per_chunk: typing.Optional[typing.Optional[int]] = Field(None, alias='max_items_per_chunk')
 
     # Used to specify whether Carbon should attempt to sync all your files automatically when authorization         is complete. This is only supported for a subset of connectors and will be ignored for the rest. Supported         connectors: Intercom, Zendesk, Gitbook, Confluence, Salesforce, Freshdesk
     sync_files_on_connection: typing.Optional[typing.Optional[bool]] = Field(None, alias='sync_files_on_connection')
 
     set_page_as_boundary: typing.Optional[bool] = Field(None, alias='set_page_as_boundary')
-    class Config:
-        arbitrary_types_allowed = True
+
+    request_id: typing.Optional[str] = Field(None, alias='request_id')
+
+    enable_file_picker: typing.Optional[bool] = Field(None, alias='enable_file_picker')
+
+    # Enabling this flag will fetch all available content from the source to be listed via list items endpoint
+    sync_source_items: typing.Optional[bool] = Field(None, alias='sync_source_items')
+
+    # Only sync files if they have not already been synced or if the embedding properties have changed.         This flag is currently supported by ONEDRIVE, GOOGLE_DRIVE, BOX, DROPBOX. It will be ignored for other data sources.
+    incremental_sync: typing.Optional[bool] = Field(None, alias='incremental_sync')
+
+    file_sync_config: typing.Optional[FileSyncConfigNullable] = Field(None, alias='file_sync_config')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/token_response.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/white_labeling_response.py`

 * *Files 16% similar despite different names*

```diff
@@ -9,16 +9,19 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-class TokenResponse(BaseModel):
-    access_token: str = Field(alias='access_token')
+class WhiteLabelingResponse(BaseModel):
+    remove_branding: bool = Field(alias='remove_branding')
 
-    refresh_token: str = Field(alias='refresh_token')
-    class Config:
-        arbitrary_types_allowed = True
+    integrations: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = Field(alias='integrations')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/upload_file_from_url_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/upload_file_from_url_input.py`

 * *Files 6% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.embedding_generators import EmbeddingGenerators
 
 class UploadFileFromUrlInput(BaseModel):
     url: str = Field(alias='url')
 
     file_name: typing.Optional[typing.Optional[str]] = Field(None, alias='file_name')
@@ -34,10 +34,18 @@
 
     generate_sparse_vectors: typing.Optional[bool] = Field(None, alias='generate_sparse_vectors')
 
     use_textract: typing.Optional[bool] = Field(None, alias='use_textract')
 
     prepend_filename_to_chunks: typing.Optional[bool] = Field(None, alias='prepend_filename_to_chunks')
 
+    # Number of objects per chunk. For csv, tsv, xlsx, and json files only.
     max_items_per_chunk: typing.Optional[typing.Optional[int]] = Field(None, alias='max_items_per_chunk')
-    class Config:
-        arbitrary_types_allowed = True
+
+    parse_pdf_tables_with_ocr: typing.Optional[bool] = Field(None, alias='parse_pdf_tables_with_ocr')
+
+    detect_audio_language: typing.Optional[bool] = Field(None, alias='detect_audio_language')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/user_files_v2.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/user_request_content.py`

 * *Files 20% similar despite different names*

```diff
@@ -9,17 +9,17 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
-from carbon.pydantic.user_file import UserFile
 
-class UserFilesV2(BaseModel):
-    results: typing.List[UserFile] = Field(alias='results')
+class UserRequestContent(BaseModel):
+    customer_id: str = Field(alias='customer_id')
 
-    count: int = Field(alias='count')
-    class Config:
-        arbitrary_types_allowed = True
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/user_request_content.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/directory_item.py`

 * *Files 20% similar despite different names*

```diff
@@ -9,14 +9,23 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-class UserRequestContent(BaseModel):
-    customer_id: str = Field(alias='customer_id')
-    class Config:
-        arbitrary_types_allowed = True
+class DirectoryItem(BaseModel):
+    id: str = Field(alias='id')
+
+    name: str = Field(alias='name')
+
+    is_synced: bool = Field(alias='is_synced')
+
+    has_children: bool = Field(alias='has_children')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/user_response.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/webhook_no_key.py`

 * *Files 23% similar despite different names*

```diff
@@ -9,35 +9,30 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
-from carbon.pydantic.user_response_unique_file_tags import UserResponseUniqueFileTags
+from carbon.pydantic.webhook_status import WebhookStatus
 
-class UserResponse(BaseModel):
+class WebhookNoKey(BaseModel):
     id: int = Field(alias='id')
 
     organization_id: int = Field(alias='organization_id')
 
-    organization_supplied_user_id: str = Field(alias='organization_supplied_user_id')
+    url: str = Field(alias='url')
 
-    created_at: datetime = Field(alias='created_at')
-
-    updated_at: datetime = Field(alias='updated_at')
-
-    deleted_at: typing.Optional[datetime] = Field(alias='deleted_at')
+    status: WebhookStatus = Field(alias='status')
 
-    num_files_synced: int = Field(alias='num_files_synced')
+    status_reason: typing.Optional[str] = Field(alias='status_reason')
 
-    num_characters_synced: int = Field(alias='num_characters_synced')
-
-    num_tokens_synced: int = Field(alias='num_tokens_synced')
+    created_at: datetime = Field(alias='created_at')
 
-    unique_file_tags: UserResponseUniqueFileTags = Field(alias='unique_file_tags')
+    updated_at: datetime = Field(alias='updated_at')
 
-    enabled_features: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]] = Field(alias='enabled_features')
-    class Config:
-        arbitrary_types_allowed = True
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/validation_error.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/fetch_urls_response.py`

 * *Files 24% similar despite different names*

```diff
@@ -9,19 +9,22 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
-from carbon.pydantic.validation_error_loc import ValidationErrorLoc
+from carbon.pydantic.fetch_urls_response_urls import FetchURLsResponseUrls
 
-class ValidationError(BaseModel):
-    loc: ValidationErrorLoc = Field(alias='loc')
+class FetchURLsResponse(BaseModel):
+    urls: FetchURLsResponseUrls = Field(alias='urls')
 
-    msg: str = Field(alias='msg')
+    html_content: str = Field(alias='html_content')
 
-    type: str = Field(alias='type')
-    class Config:
-        arbitrary_types_allowed = True
+    error_message: typing.Optional[str] = Field(alias='error_message')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/webhook.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/webhook.py`

 * *Files 10% similar despite different names*

```diff
@@ -9,24 +9,32 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
+from carbon.pydantic.webhook_status import WebhookStatus
 
 class Webhook(BaseModel):
     id: int = Field(alias='id')
 
     organization_id: int = Field(alias='organization_id')
 
     url: str = Field(alias='url')
 
     signing_key: str = Field(alias='signing_key')
 
+    status: WebhookStatus = Field(alias='status')
+
+    status_reason: typing.Optional[str] = Field(alias='status_reason')
+
     created_at: datetime = Field(alias='created_at')
 
     updated_at: datetime = Field(alias='updated_at')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/webhook_filters.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/webhook_filters.py`

 * *Files 14% similar despite different names*

```diff
@@ -9,15 +9,18 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.webhook_filters_ids import WebhookFiltersIds
 
 class WebhookFilters(BaseModel):
     ids: typing.Optional[WebhookFiltersIds] = Field(None, alias='ids')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/webhook_no_key.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/revoke_access_token_input.py`

 * *Files 24% similar despite different names*

```diff
@@ -9,22 +9,17 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-class WebhookNoKey(BaseModel):
-    id: int = Field(alias='id')
+class RevokeAccessTokenInput(BaseModel):
+    data_source_id: int = Field(alias='data_source_id')
 
-    organization_id: int = Field(alias='organization_id')
-
-    url: str = Field(alias='url')
-
-    created_at: datetime = Field(alias='created_at')
-
-    updated_at: datetime = Field(alias='updated_at')
-    class Config:
-        arbitrary_types_allowed = True
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/webhook_query_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/webhook_query_input.py`

 * *Files 18% similar despite different names*

```diff
@@ -9,24 +9,27 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.order_dir import OrderDir
 from carbon.pydantic.pagination import Pagination
 from carbon.pydantic.webhook_filters import WebhookFilters
 from carbon.pydantic.webhook_order_by_columns import WebhookOrderByColumns
 
 class WebhookQueryInput(BaseModel):
     pagination: typing.Optional[Pagination] = Field(None, alias='pagination')
 
     order_by: typing.Optional[WebhookOrderByColumns] = Field(None, alias='order_by')
 
     order_dir: typing.Optional[OrderDir] = Field(None, alias='order_dir')
 
     filters: typing.Optional[WebhookFilters] = Field(None, alias='filters')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/webscrape_request.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/webscrape_request.py`

 * *Files 16% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.embedding_generators import EmbeddingGenerators
 from carbon.pydantic.webscrape_request_css_classes_to_skip import WebscrapeRequestCssClassesToSkip
 from carbon.pydantic.webscrape_request_css_selectors_to_skip import WebscrapeRequestCssSelectorsToSkip
 from carbon.pydantic.webscrape_request_html_tags_to_skip import WebscrapeRequestHtmlTagsToSkip
 from carbon.pydantic.webscrape_request_tags import WebscrapeRequestTags
 
@@ -45,9 +45,12 @@
     html_tags_to_skip: typing.Optional[WebscrapeRequestHtmlTagsToSkip] = Field(None, alias='html_tags_to_skip')
 
     css_classes_to_skip: typing.Optional[WebscrapeRequestCssClassesToSkip] = Field(None, alias='css_classes_to_skip')
 
     css_selectors_to_skip: typing.Optional[WebscrapeRequestCssSelectorsToSkip] = Field(None, alias='css_selectors_to_skip')
 
     embedding_model: typing.Optional[EmbeddingGenerators] = Field(None, alias='embedding_model')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/white_labeling_response.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/user_files_v2.py`

 * *Files 16% similar despite different names*

```diff
@@ -9,16 +9,20 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
+from carbon.pydantic.user_file import UserFile
 
-class WhiteLabelingResponse(BaseModel):
-    remove_branding: bool = Field(alias='remove_branding')
+class UserFilesV2(BaseModel):
+    results: typing.List[UserFile] = Field(alias='results')
 
-    integrations: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = Field(alias='integrations')
-    class Config:
-        arbitrary_types_allowed = True
+    count: int = Field(alias='count')
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/youtube_transcript_response.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/youtube_transcript_response.py`

 * *Files 10% similar despite different names*

```diff
@@ -9,21 +9,24 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.youtube_transcript_response_raw_transcript import YoutubeTranscriptResponseRawTranscript
 
 class YoutubeTranscriptResponse(BaseModel):
     status: str = Field(alias='status')
 
     error: typing.Optional[str] = Field(alias='error')
 
     data: typing.Optional[str] = Field(alias='data')
 
     raw_transcript: YoutubeTranscriptResponseRawTranscript = Field(alias='raw_transcript')
-    class Config:
-        arbitrary_types_allowed = True
+
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/youtube_transcript_response_raw_transcript.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/youtube_transcript_response_raw_transcript.py`

 * *Files 3% similar despite different names*

```diff
@@ -9,12 +9,12 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 from carbon.pydantic.youtube_transcript_response_raw_transcript_item import YoutubeTranscriptResponseRawTranscriptItem
 
 YoutubeTranscriptResponseRawTranscript = typing.Optional[typing.List[YoutubeTranscriptResponseRawTranscriptItem]]
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/zendesk_authentication.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/s3_get_file_input.py`

 * *Files 17% similar despite different names*

```diff
@@ -9,18 +9,19 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-class ZendeskAuthentication(BaseModel):
-    source: typing.Union[bool, date, datetime, dict, float, int, list, str, None] = Field(alias='source')
+class S3GetFileInput(BaseModel):
+    id: typing.Optional[typing.Optional[str]] = Field(None, alias='id')
 
-    access_token: str = Field(alias='access_token')
+    bucket: typing.Optional[typing.Optional[str]] = Field(None, alias='bucket')
 
-    subdomain: str = Field(alias='subdomain')
-    class Config:
-        arbitrary_types_allowed = True
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/pydantic/zotero_authentication.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/github_fetch_repos_request.py`

 * *Files 24% similar despite different names*

```diff
@@ -9,22 +9,20 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
-from pydantic import BaseModel, Field, RootModel
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
+from carbon.pydantic.github_fetch_repos_request_repos import GithubFetchReposRequestRepos
 
-class ZoteroAuthentication(BaseModel):
-    source: typing.Union[bool, date, datetime, dict, float, int, list, str, None] = Field(alias='source')
+class GithubFetchReposRequest(BaseModel):
+    repos: GithubFetchReposRequestRepos = Field(alias='repos')
 
-    access_token: str = Field(alias='access_token')
+    data_source_id: typing.Optional[typing.Optional[int]] = Field(None, alias='data_source_id')
 
-    access_token_secret: str = Field(alias='access_token_secret')
-
-    username: str = Field(alias='username')
-
-    zotero_id: str = Field(alias='zotero_id')
-    class Config:
-        arbitrary_types_allowed = True
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/request_after_hook.py` & `carbon_python_sdk-0.2.0/carbon/request_after_hook.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/request_before_hook.py` & `carbon_python_sdk-0.2.0/carbon/request_before_hook.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/request_before_url_hook.py` & `carbon_python_sdk-0.2.0/carbon/request_before_url_hook.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/rest.py` & `carbon_python_sdk-0.2.0/carbon/rest.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/schemas.py` & `carbon_python_sdk-0.2.0/carbon/schemas.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/add_webhook_props.py` & `carbon_python_sdk-0.2.0/carbon/type/add_webhook_props.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/body_create_upload_file_uploadfile_post.py` & `carbon_python_sdk-0.2.0/carbon/type/body_create_upload_file_uploadfile_post.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/chunk_properties.py` & `carbon_python_sdk-0.2.0/carbon/type/chunk_properties.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/chunk_properties_nullable.py` & `carbon_python_sdk-0.2.0/carbon/type/chunk_properties_nullable.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/chunks_and_embeddings.py` & `carbon_python_sdk-0.2.0/carbon/type/embeddings_and_chunks_response.py`

 * *Files 16% similar despite different names*

```diff
@@ -10,19 +10,19 @@
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
-from carbon.type.chunks_and_embeddings_embedding import ChunksAndEmbeddingsEmbedding
+from carbon.type.embedding_and_chunk import EmbeddingAndChunk
 
-class RequiredChunksAndEmbeddings(TypedDict):
-    chunk_number: typing.Optional[int]
+class RequiredEmbeddingsAndChunksResponse(TypedDict):
+    results: typing.List[EmbeddingAndChunk]
 
-    chunk: str
+    count: int
 
-class OptionalChunksAndEmbeddings(TypedDict, total=False):
-    embedding: ChunksAndEmbeddingsEmbedding
+class OptionalEmbeddingsAndChunksResponse(TypedDict, total=False):
+    pass
 
-class ChunksAndEmbeddings(RequiredChunksAndEmbeddings, OptionalChunksAndEmbeddings):
+class EmbeddingsAndChunksResponse(RequiredEmbeddingsAndChunksResponse, OptionalEmbeddingsAndChunksResponse):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/chunks_and_embeddings_upload_input.py` & `carbon_python_sdk-0.2.0/carbon/type/chunks_and_embeddings_upload_input.py`

 * *Files 12% similar despite different names*

```diff
@@ -10,24 +10,26 @@
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
+from carbon.type.chunks_and_embeddings_upload_input_custom_credentials import ChunksAndEmbeddingsUploadInputCustomCredentials
 from carbon.type.embedding_generators import EmbeddingGenerators
 from carbon.type.single_chunks_and_embeddings_upload_input import SingleChunksAndEmbeddingsUploadInput
 
 class RequiredChunksAndEmbeddingsUploadInput(TypedDict):
     embedding_model: EmbeddingGenerators
 
     chunks_and_embeddings: typing.List[SingleChunksAndEmbeddingsUploadInput]
 
+
 class OptionalChunksAndEmbeddingsUploadInput(TypedDict, total=False):
     overwrite_existing: bool
 
     chunks_only: bool
 
-    custom_credentials: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
+    custom_credentials: ChunksAndEmbeddingsUploadInputCustomCredentials
 
 class ChunksAndEmbeddingsUploadInput(RequiredChunksAndEmbeddingsUploadInput, OptionalChunksAndEmbeddingsUploadInput):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/confluence_authentication.py` & `carbon_python_sdk-0.2.0/carbon/type/confluence_authentication.py`

 * *Files 1% similar despite different names*

```diff
@@ -18,12 +18,13 @@
 class RequiredConfluenceAuthentication(TypedDict):
     source: typing.Union[bool, date, datetime, dict, float, int, list, str, None]
 
     access_token: str
 
     subdomain: str
 
+
 class OptionalConfluenceAuthentication(TypedDict, total=False):
     refresh_token: typing.Optional[str]
 
 class ConfluenceAuthentication(RequiredConfluenceAuthentication, OptionalConfluenceAuthentication):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/connect_data_source_input.py` & `carbon_python_sdk-0.2.0/carbon/type/connect_data_source_input.py`

 * *Files 8% similar despite different names*

```diff
@@ -13,24 +13,26 @@
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
 from carbon.type.confluence_authentication import ConfluenceAuthentication
 from carbon.type.freskdesk_authentication import FreskdeskAuthentication
 from carbon.type.gitbook_authetication import GitbookAuthetication
+from carbon.type.github_authentication import GithubAuthentication
 from carbon.type.notion_authentication import NotionAuthentication
 from carbon.type.o_auth_authentication import OAuthAuthentication
 from carbon.type.s3_authentication import S3Authentication
 from carbon.type.salesforce_authentication import SalesforceAuthentication
 from carbon.type.sharepoint_authentication import SharepointAuthentication
 from carbon.type.sync_options import SyncOptions
 from carbon.type.zendesk_authentication import ZendeskAuthentication
 from carbon.type.zotero_authentication import ZoteroAuthentication
 
 class RequiredConnectDataSourceInput(TypedDict):
-    authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication]
+    authentication: typing.Union[OAuthAuthentication, NotionAuthentication, SharepointAuthentication, ConfluenceAuthentication, ZendeskAuthentication, ZoteroAuthentication, GitbookAuthetication, SalesforceAuthentication, FreskdeskAuthentication, S3Authentication, GithubAuthentication]
+
 
 class OptionalConnectDataSourceInput(TypedDict, total=False):
     sync_options: SyncOptions
 
 class ConnectDataSourceInput(RequiredConnectDataSourceInput, OptionalConnectDataSourceInput):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/connect_data_source_response.py` & `carbon_python_sdk-0.2.0/carbon/type/connect_data_source_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/data_source_type.py` & `carbon_python_sdk-0.2.0/carbon/type/data_source_type_nullable.py`

 * *Files 9% similar despite different names*

```diff
@@ -11,8 +11,8 @@
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
 
-DataSourceType = Literal["GOOGLE_DRIVE", "NOTION", "NOTION_DATABASE", "INTERCOM", "DROPBOX", "ONEDRIVE", "SHAREPOINT", "CONFLUENCE", "BOX", "ZENDESK", "ZOTERO", "S3", "GMAIL", "OUTLOOK", "TEXT", "CSV", "TSV", "PDF", "DOCX", "PPTX", "XLSX", "MD", "RTF", "JSON", "RAW_TEXT", "WEB_SCRAPE", "RSS_FEED", "FRESHDESK", "GITBOOK", "SALESFORCE", "JPG", "PNG", "MP3", "MP4", "MP2", "AAC", "WAV", "FLAC", "PCM", "M4A", "OGG", "OPUS", "WEBM"]
+DataSourceTypeNullable = Literal["GOOGLE_DRIVE", "NOTION", "NOTION_DATABASE", "INTERCOM", "DROPBOX", "ONEDRIVE", "SHAREPOINT", "CONFLUENCE", "BOX", "ZENDESK", "ZOTERO", "S3", "GMAIL", "OUTLOOK", "TEXT", "CSV", "TSV", "PDF", "DOCX", "PPTX", "XLSX", "MD", "RTF", "JSON", "HTML", "RAW_TEXT", "WEB_SCRAPE", "RSS_FEED", "FRESHDESK", "GITBOOK", "SALESFORCE", "GITHUB", "JPG", "PNG", "JPEG", "MP3", "MP2", "AAC", "WAV", "FLAC", "PCM", "M4A", "OGG", "OPUS", "MPEG", "MPG", "MP4", "WMV", "AVI", "MOV", "MKV", "FLV", "WEBM"]
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/delete_files_query_input.py` & `carbon_python_sdk-0.2.0/carbon/type/delete_files_query_input.py`

 * *Files 10% similar despite different names*

```diff
@@ -17,15 +17,15 @@
 from carbon.type.delete_files_query_input_file_ids import DeleteFilesQueryInputFileIds
 from carbon.type.external_file_sync_statuses import ExternalFileSyncStatuses
 
 class RequiredDeleteFilesQueryInput(TypedDict):
     pass
 
 class OptionalDeleteFilesQueryInput(TypedDict, total=False):
-    file_ids: DeleteFilesQueryInputFileIds
+    file_ids: typing.Optional[DeleteFilesQueryInputFileIds]
 
     sync_statuses: typing.Optional[typing.List[ExternalFileSyncStatuses]]
 
     delete_non_synced_only: bool
 
     send_webhook: bool
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/delete_users_input.py` & `carbon_python_sdk-0.2.0/carbon/type/delete_users_input.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/directory_item.py` & `carbon_python_sdk-0.2.0/carbon/type/directory_item.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/document_response.py` & `carbon_python_sdk-0.2.0/carbon/type/document_response.py`

 * *Files 14% similar despite different names*

```diff
@@ -15,34 +15,38 @@
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
 from carbon.type.data_source_type_nullable import DataSourceTypeNullable
 from carbon.type.document_response_tags import DocumentResponseTags
 from carbon.type.document_response_vector import DocumentResponseVector
 
 class RequiredDocumentResponse(TypedDict):
-    tags: DocumentResponseTags
+    tags: typing.Optional[DocumentResponseTags]
 
     content: str
 
     file_id: int
 
+    parent_file_id: typing.Optional[int]
+
     source: typing.Optional[str]
 
     source_url: typing.Optional[str]
 
-    source_type: DataSourceTypeNullable
+    source_type: typing.Optional[DataSourceTypeNullable]
 
     presigned_url: typing.Optional[str]
 
-    vector: DocumentResponseVector
+    vector: typing.Optional[DocumentResponseVector]
 
     score: typing.Optional[typing.Union[int, float]]
 
     rank: typing.Union[typing.Union[int, float], int]
 
     content_metadata: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
 
+    chunk_index: typing.Optional[int]
+
 class OptionalDocumentResponse(TypedDict, total=False):
     pass
 
 class DocumentResponse(RequiredDocumentResponse, OptionalDocumentResponse):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/document_response_list.py` & `carbon_python_sdk-0.2.0/carbon/type/document_response_list.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/embedding_and_chunk.py` & `carbon_python_sdk-0.2.0/carbon/type/embedding_and_chunk.py`

 * *Files 25% similar despite different names*

```diff
@@ -19,14 +19,16 @@
 class RequiredEmbeddingAndChunk(TypedDict):
     user_file_id: int
 
     chunk_index: typing.Optional[int]
 
     source_content: str
 
-    embedding: EmbeddingAndChunkEmbedding
+    embedding: typing.Optional[EmbeddingAndChunkEmbedding]
+
+    content_metadata: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
 
 class OptionalEmbeddingAndChunk(TypedDict, total=False):
     pass
 
 class EmbeddingAndChunk(RequiredEmbeddingAndChunk, OptionalEmbeddingAndChunk):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/embedding_generators.py` & `carbon_python_sdk-0.2.0/carbon/type/text_embedding_generators.py`

 * *Files 6% similar despite different names*

```diff
@@ -11,8 +11,8 @@
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
 
-EmbeddingGenerators = Literal["OPENAI", "AZURE_OPENAI", "AZURE_ADA_LARGE_256", "AZURE_ADA_LARGE_1024", "AZURE_ADA_LARGE_3072", "AZURE_ADA_SMALL_512", "AZURE_ADA_SMALL_1536", "COHERE_MULTILINGUAL_V3", "VERTEX_MULTIMODAL", "OPENAI_ADA_LARGE_256", "OPENAI_ADA_LARGE_1024", "OPENAI_ADA_LARGE_3072", "OPENAI_ADA_SMALL_512", "OPENAI_ADA_SMALL_1536"]
+TextEmbeddingGenerators = Literal["OPENAI", "AZURE_OPENAI", "COHERE_MULTILINGUAL_V3", "OPENAI_ADA_LARGE_256", "OPENAI_ADA_LARGE_1024", "OPENAI_ADA_LARGE_3072", "OPENAI_ADA_SMALL_512", "OPENAI_ADA_SMALL_1536", "AZURE_ADA_LARGE_256", "AZURE_ADA_LARGE_1024", "AZURE_ADA_LARGE_3072", "AZURE_ADA_SMALL_512", "AZURE_ADA_SMALL_1536", "SOLAR_1_MINI"]
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/embedding_generators_nullable.py` & `carbon_python_sdk-0.2.0/carbon/type/embedding_generators.py`

 * *Files 15% similar despite different names*

```diff
@@ -11,8 +11,8 @@
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
 
-EmbeddingGeneratorsNullable = Literal["OPENAI", "AZURE_OPENAI", "AZURE_ADA_LARGE_256", "AZURE_ADA_LARGE_1024", "AZURE_ADA_LARGE_3072", "AZURE_ADA_SMALL_512", "AZURE_ADA_SMALL_1536", "COHERE_MULTILINGUAL_V3", "VERTEX_MULTIMODAL", "OPENAI_ADA_LARGE_256", "OPENAI_ADA_LARGE_1024", "OPENAI_ADA_LARGE_3072", "OPENAI_ADA_SMALL_512", "OPENAI_ADA_SMALL_1536"]
+EmbeddingGenerators = Literal["OPENAI", "AZURE_OPENAI", "AZURE_ADA_LARGE_256", "AZURE_ADA_LARGE_1024", "AZURE_ADA_LARGE_3072", "AZURE_ADA_SMALL_512", "AZURE_ADA_SMALL_1536", "COHERE_MULTILINGUAL_V3", "VERTEX_MULTIMODAL", "OPENAI_ADA_LARGE_256", "OPENAI_ADA_LARGE_1024", "OPENAI_ADA_LARGE_3072", "OPENAI_ADA_SMALL_512", "OPENAI_ADA_SMALL_1536", "SOLAR_1_MINI"]
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/embedding_properties.py` & `carbon_python_sdk-0.2.0/carbon/type/embedding_properties.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/embeddings_and_chunks_filters.py` & `carbon_python_sdk-0.2.0/carbon/type/embeddings_and_chunks_filters.py`

 * *Files 13% similar despite different names*

```diff
@@ -15,12 +15,13 @@
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
 from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
 
 class RequiredEmbeddingsAndChunksFilters(TypedDict):
     user_file_id: int
 
+
 class OptionalEmbeddingsAndChunksFilters(TypedDict, total=False):
-    embedding_model: EmbeddingGeneratorsNullable
+    embedding_model: typing.Optional[EmbeddingGeneratorsNullable]
 
 class EmbeddingsAndChunksFilters(RequiredEmbeddingsAndChunksFilters, OptionalEmbeddingsAndChunksFilters):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/embeddings_and_chunks_query_input.py` & `carbon_python_sdk-0.2.0/carbon/type/embeddings_and_chunks_query_input.py`

 * *Files 0% similar despite different names*

```diff
@@ -18,14 +18,15 @@
 from carbon.type.embeddings_and_chunks_order_by_columns import EmbeddingsAndChunksOrderByColumns
 from carbon.type.order_dir import OrderDir
 from carbon.type.pagination import Pagination
 
 class RequiredEmbeddingsAndChunksQueryInput(TypedDict):
     filters: EmbeddingsAndChunksFilters
 
+
 class OptionalEmbeddingsAndChunksQueryInput(TypedDict, total=False):
     pagination: Pagination
 
     order_by: EmbeddingsAndChunksOrderByColumns
 
     order_dir: OrderDir
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/external_source_item.py` & `carbon_python_sdk-0.2.0/carbon/type/external_source_item.py`

 * *Files 16% similar despite different names*

```diff
@@ -43,14 +43,16 @@
 
     parent_external_id: typing.Optional[str]
 
     item_type: typing.Optional[str]
 
     root_external_id: typing.Optional[str]
 
+    external_url: typing.Optional[str]
+
     created_at: datetime
 
     updated_at: datetime
 
 class OptionalExternalSourceItem(TypedDict, total=False):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/file_formats.py` & `carbon_python_sdk-0.2.0/carbon/type/data_source_type.py`

 * *Files 14% similar despite different names*

```diff
@@ -11,8 +11,8 @@
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
 
-FileFormats = Literal["TXT", "CSV", "TSV", "PDF", "DOCX", "PPTX", "XLSX", "MD", "RTF", "JSON", "NOTION", "GOOGLE_DOCS", "GOOGLE_SHEETS", "GOOGLE_SLIDES", "INTERCOM", "CONFLUENCE", "RSS_FEED", "GMAIL", "OUTLOOK", "ZENDESK", "FRESHDESK", "WEB_SCRAPE", "GITBOOK", "SALESFORCE", "JPG", "PNG", "MP3", "MP4", "MP2", "AAC", "WAV", "FLAC", "PCM", "M4A", "OGG", "OPUS", "WEBM"]
+DataSourceType = Literal["GOOGLE_DRIVE", "NOTION", "NOTION_DATABASE", "INTERCOM", "DROPBOX", "ONEDRIVE", "SHAREPOINT", "CONFLUENCE", "BOX", "ZENDESK", "ZOTERO", "S3", "GMAIL", "OUTLOOK", "TEXT", "CSV", "TSV", "PDF", "DOCX", "PPTX", "XLSX", "MD", "RTF", "JSON", "HTML", "RAW_TEXT", "WEB_SCRAPE", "RSS_FEED", "FRESHDESK", "GITBOOK", "SALESFORCE", "GITHUB", "JPG", "PNG", "JPEG", "MP3", "MP2", "AAC", "WAV", "FLAC", "PCM", "M4A", "OGG", "OPUS", "MPEG", "MPG", "MP4", "WMV", "AVI", "MOV", "MKV", "FLV", "WEBM"]
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/file_formats_nullable.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/data_source_type.py`

 * *Files 16% similar despite different names*

```diff
@@ -9,10 +9,11 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-FileFormatsNullable = Literal["TXT", "CSV", "TSV", "PDF", "DOCX", "PPTX", "XLSX", "MD", "RTF", "JSON", "NOTION", "GOOGLE_DOCS", "GOOGLE_SHEETS", "GOOGLE_SLIDES", "INTERCOM", "CONFLUENCE", "RSS_FEED", "GMAIL", "OUTLOOK", "ZENDESK", "FRESHDESK", "WEB_SCRAPE", "GITBOOK", "SALESFORCE", "JPG", "PNG", "MP3", "MP4", "MP2", "AAC", "WAV", "FLAC", "PCM", "M4A", "OGG", "OPUS", "WEBM"]
+DataSourceType = Literal["GOOGLE_DRIVE", "NOTION", "NOTION_DATABASE", "INTERCOM", "DROPBOX", "ONEDRIVE", "SHAREPOINT", "CONFLUENCE", "BOX", "ZENDESK", "ZOTERO", "S3", "GMAIL", "OUTLOOK", "TEXT", "CSV", "TSV", "PDF", "DOCX", "PPTX", "XLSX", "MD", "RTF", "JSON", "HTML", "RAW_TEXT", "WEB_SCRAPE", "RSS_FEED", "FRESHDESK", "GITBOOK", "SALESFORCE", "GITHUB", "JPG", "PNG", "JPEG", "MP3", "MP2", "AAC", "WAV", "FLAC", "PCM", "M4A", "OGG", "OPUS", "MPEG", "MPG", "MP4", "WMV", "AVI", "MOV", "MKV", "FLV", "WEBM"]
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/file_statistics.py` & `carbon_python_sdk-0.2.0/carbon/type/file_statistics_nullable.py`

 * *Files 24% similar despite different names*

```diff
@@ -12,23 +12,25 @@
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
 from carbon.type.file_formats_nullable import FileFormatsNullable
 
-class RequiredFileStatistics(TypedDict):
-    file_format: FileFormatsNullable
+class RequiredFileStatisticsNullable(TypedDict):
+    file_format: typing.Optional[FileFormatsNullable]
 
     file_size: typing.Optional[int]
 
     num_characters: typing.Optional[int]
 
     num_tokens: typing.Optional[int]
 
     num_embeddings: typing.Optional[int]
 
-class OptionalFileStatistics(TypedDict, total=False):
+    mime_type: typing.Optional[str]
+
+class OptionalFileStatisticsNullable(TypedDict, total=False):
     pass
 
-class FileStatistics(RequiredFileStatistics, OptionalFileStatistics):
+class FileStatisticsNullable(RequiredFileStatisticsNullable, OptionalFileStatisticsNullable):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/file_statistics_nullable.py` & `carbon_python_sdk-0.2.0/carbon/type/s3_authentication.py`

 * *Files 27% similar despite different names*

```diff
@@ -10,25 +10,20 @@
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
-from carbon.type.file_formats_nullable import FileFormatsNullable
 
-class RequiredFileStatisticsNullable(TypedDict):
-    file_format: FileFormatsNullable
+class RequiredS3Authentication(TypedDict):
+    source: typing.Union[bool, date, datetime, dict, float, int, list, str, None]
 
-    file_size: typing.Optional[int]
+    access_key: str
 
-    num_characters: typing.Optional[int]
+    access_key_secret: str
 
-    num_tokens: typing.Optional[int]
-
-    num_embeddings: typing.Optional[int]
-
-class OptionalFileStatisticsNullable(TypedDict, total=False):
+class OptionalS3Authentication(TypedDict, total=False):
     pass
 
-class FileStatisticsNullable(RequiredFileStatisticsNullable, OptionalFileStatisticsNullable):
+class S3Authentication(RequiredS3Authentication, OptionalS3Authentication):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/fresh_desk_connect_request.py` & `carbon_python_sdk-0.2.0/carbon/type/gitbook_sync_request.py`

 * *Files 15% similar despite different names*

```diff
@@ -10,33 +10,35 @@
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
-from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.type.embedding_generators import EmbeddingGenerators
+from carbon.type.gitbook_sync_request_space_ids import GitbookSyncRequestSpaceIds
 
-class RequiredFreshDeskConnectRequest(TypedDict):
-    domain: str
+class RequiredGitbookSyncRequest(TypedDict):
+    space_ids: GitbookSyncRequestSpaceIds
 
-    api_key: str
+    data_source_id: int
 
-class OptionalFreshDeskConnectRequest(TypedDict, total=False):
+
+class OptionalGitbookSyncRequest(TypedDict, total=False):
     tags: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
 
     chunk_size: typing.Optional[int]
 
     chunk_overlap: typing.Optional[int]
 
     skip_embedding_generation: typing.Optional[bool]
 
-    embedding_model: EmbeddingGeneratorsNullable
+    embedding_model: EmbeddingGenerators
 
     generate_sparse_vectors: typing.Optional[bool]
 
     prepend_filename_to_chunks: typing.Optional[bool]
 
-    sync_files_on_connection: typing.Optional[bool]
+    request_id: typing.Optional[str]
 
-class FreshDeskConnectRequest(RequiredFreshDeskConnectRequest, OptionalFreshDeskConnectRequest):
+class GitbookSyncRequest(RequiredGitbookSyncRequest, OptionalGitbookSyncRequest):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/freskdesk_authentication.py` & `carbon_python_sdk-0.2.0/carbon/type/freskdesk_authentication.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/generic_success_response.py` & `carbon_python_sdk-0.2.0/carbon/type/generic_success_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/get_embedding_documents_body.py` & `carbon_python_sdk-0.2.0/carbon/type/get_embedding_documents_body.py`

 * *Files 5% similar despite different names*

```diff
@@ -25,22 +25,27 @@
 class RequiredGetEmbeddingDocumentsBody(TypedDict):
     # Query for which to get related chunks and embeddings.
     query: str
 
     # Number of related chunks to return.
     k: int
 
+
 class OptionalGetEmbeddingDocumentsBody(TypedDict, total=False):
-    tags: GetEmbeddingDocumentsBodyTags
+    tags: typing.Optional[GetEmbeddingDocumentsBodyTags]
+
+    query_vector: typing.Optional[GetEmbeddingDocumentsBodyQueryVector]
 
-    query_vector: GetEmbeddingDocumentsBodyQueryVector
+    file_ids: typing.Optional[GetEmbeddingDocumentsBodyFileIds]
 
-    file_ids: GetEmbeddingDocumentsBodyFileIds
+    # WARNING: This property is deprecated
+    parent_file_ids: typing.Optional[GetEmbeddingDocumentsBodyParentFileIds]
 
-    parent_file_ids: GetEmbeddingDocumentsBodyParentFileIds
+    # Flag to control whether or not to include all children of filtered files in the embedding search.
+    include_all_children: bool
 
     # A set of tags to limit the search to. Use this instead of `tags`, which is deprecated.
     tags_v2: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
 
     # Flag to control whether or not to include tags for each chunk in the response.
     include_tags: typing.Optional[bool]
 
@@ -49,15 +54,15 @@
 
     # Flag to control whether or not to include a signed URL to the raw file containing each chunk         in the response.
     include_raw_file: typing.Optional[bool]
 
     # Flag to control whether or not to perform hybrid search.
     hybrid_search: typing.Optional[bool]
 
-    hybrid_search_tuning_parameters: HybridSearchTuningParamsNullable
+    hybrid_search_tuning_parameters: typing.Optional[HybridSearchTuningParamsNullable]
 
-    media_type: FileContentTypesNullable
+    media_type: typing.Optional[FileContentTypesNullable]
 
-    embedding_model: EmbeddingGeneratorsNullable
+    embedding_model: typing.Optional[EmbeddingGeneratorsNullable]
 
 class GetEmbeddingDocumentsBody(RequiredGetEmbeddingDocumentsBody, OptionalGetEmbeddingDocumentsBody):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/gitbook_authetication.py` & `carbon_python_sdk-0.2.0/carbon/type/gitbook_authetication.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/gitbook_connect_request.py` & `carbon_python_sdk-0.2.0/carbon/type/gitbook_connect_request.py`

 * *Files 17% similar despite different names*

```diff
@@ -17,14 +17,15 @@
 from carbon.type.embedding_generators import EmbeddingGenerators
 
 class RequiredGitbookConnectRequest(TypedDict):
     organization: str
 
     access_token: str
 
+
 class OptionalGitbookConnectRequest(TypedDict, total=False):
     tags: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
 
     chunk_size: typing.Optional[int]
 
     chunk_overlap: typing.Optional[int]
 
@@ -34,9 +35,14 @@
 
     generate_sparse_vectors: typing.Optional[bool]
 
     prepend_filename_to_chunks: typing.Optional[bool]
 
     sync_files_on_connection: typing.Optional[bool]
 
+    request_id: typing.Optional[str]
+
+    # Enabling this flag will fetch all available content from the source to be listed via list items endpoint
+    sync_source_items: bool
+
 class GitbookConnectRequest(RequiredGitbookConnectRequest, OptionalGitbookConnectRequest):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/gitbook_sync_request.py` & `carbon_python_sdk-0.2.0/carbon/type/outlook_sync_input.py`

 * *Files 26% similar despite different names*

```diff
@@ -11,31 +11,42 @@
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
 from carbon.type.embedding_generators import EmbeddingGenerators
-from carbon.type.gitbook_sync_request_space_ids import GitbookSyncRequestSpaceIds
+from carbon.type.file_sync_config_nullable import FileSyncConfigNullable
 
-class RequiredGitbookSyncRequest(TypedDict):
-    space_ids: GitbookSyncRequestSpaceIds
+class RequiredOutlookSyncInput(TypedDict):
+    filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
 
-    data_source_id: int
 
-class OptionalGitbookSyncRequest(TypedDict, total=False):
+class OptionalOutlookSyncInput(TypedDict, total=False):
     tags: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
 
+    folder: typing.Optional[str]
+
     chunk_size: typing.Optional[int]
 
     chunk_overlap: typing.Optional[int]
 
     skip_embedding_generation: typing.Optional[bool]
 
     embedding_model: EmbeddingGenerators
 
     generate_sparse_vectors: typing.Optional[bool]
 
     prepend_filename_to_chunks: typing.Optional[bool]
 
-class GitbookSyncRequest(RequiredGitbookSyncRequest, OptionalGitbookSyncRequest):
+    data_source_id: typing.Optional[int]
+
+    request_id: typing.Optional[str]
+
+    sync_attachments: typing.Optional[bool]
+
+    file_sync_config: typing.Optional[FileSyncConfigNullable]
+
+    incremental_sync: bool
+
+class OutlookSyncInput(RequiredOutlookSyncInput, OptionalOutlookSyncInput):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/gmail_sync_input.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/organization_user_data_source_filters.py`

 * *Files 22% similar despite different names*

```diff
@@ -9,32 +9,23 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
-from carbon.type.embedding_generators import EmbeddingGenerators
+from carbon.pydantic.data_source_type_nullable import DataSourceTypeNullable
+from carbon.pydantic.organization_user_data_source_filters_ids import OrganizationUserDataSourceFiltersIds
 
-class RequiredGmailSyncInput(TypedDict):
-    filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
+class OrganizationUserDataSourceFilters(BaseModel):
+    source: typing.Optional[DataSourceTypeNullable] = Field(None, alias='source')
 
-class OptionalGmailSyncInput(TypedDict, total=False):
-    tags: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
+    ids: typing.Optional[OrganizationUserDataSourceFiltersIds] = Field(None, alias='ids')
 
-    chunk_size: typing.Optional[int]
+    revoked_access: typing.Optional[typing.Optional[bool]] = Field(None, alias='revoked_access')
 
-    chunk_overlap: typing.Optional[int]
-
-    skip_embedding_generation: typing.Optional[bool]
-
-    embedding_model: EmbeddingGenerators
-
-    generate_sparse_vectors: typing.Optional[bool]
-
-    prepend_filename_to_chunks: typing.Optional[bool]
-
-    data_source_id: typing.Optional[int]
-
-class GmailSyncInput(RequiredGmailSyncInput, OptionalGmailSyncInput):
-    pass
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/http_validation_error.py` & `carbon_python_sdk-0.2.0/carbon/type/http_validation_error.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/hybrid_search_tuning_params.py` & `carbon_python_sdk-0.2.0/carbon/type/hybrid_search_tuning_params.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/hybrid_search_tuning_params_nullable.py` & `carbon_python_sdk-0.2.0/carbon/type/hybrid_search_tuning_params_nullable.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/list_data_source_items_request.py` & `carbon_python_sdk-0.2.0/carbon/type/list_data_source_items_request.py`

 * *Files 15% similar despite different names*

```diff
@@ -10,19 +10,29 @@
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
+from carbon.type.external_source_items_order_by import ExternalSourceItemsOrderBy
+from carbon.type.list_items_filters_nullable import ListItemsFiltersNullable
+from carbon.type.order_dir_v2 import OrderDirV2
 from carbon.type.pagination import Pagination
 
 class RequiredListDataSourceItemsRequest(TypedDict):
     data_source_id: int
 
+
 class OptionalListDataSourceItemsRequest(TypedDict, total=False):
     parent_id: typing.Optional[str]
 
+    filters: typing.Optional[ListItemsFiltersNullable]
+
     pagination: Pagination
 
+    order_by: ExternalSourceItemsOrderBy
+
+    order_dir: OrderDirV2
+
 class ListDataSourceItemsRequest(RequiredListDataSourceItemsRequest, OptionalListDataSourceItemsRequest):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/list_data_source_items_response.py` & `carbon_python_sdk-0.2.0/carbon/type/list_data_source_items_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/list_request.py` & `carbon_python_sdk-0.2.0/carbon/type/list_request.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,12 +14,13 @@
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
 
 class RequiredListRequest(TypedDict):
     data_source_id: int
 
+
 class OptionalListRequest(TypedDict, total=False):
     parent_id: typing.Optional[str]
 
 class ListRequest(RequiredListRequest, OptionalListRequest):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/list_response.py` & `carbon_python_sdk-0.2.0/carbon/type/list_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/modify_user_configuration_input.py` & `carbon_python_sdk-0.2.0/carbon/type/modify_user_configuration_input.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/notion_authentication.py` & `carbon_python_sdk-0.2.0/carbon/type/notion_authentication.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/o_auth_authentication.py` & `carbon_python_sdk-0.2.0/carbon/type/o_auth_authentication.py`

 * *Files 0% similar despite different names*

```diff
@@ -17,12 +17,13 @@
 from carbon.type.simple_o_auth_data_sources import SimpleOAuthDataSources
 
 class RequiredOAuthAuthentication(TypedDict):
     source: SimpleOAuthDataSources
 
     access_token: str
 
+
 class OptionalOAuthAuthentication(TypedDict, total=False):
     refresh_token: typing.Optional[str]
 
 class OAuthAuthentication(RequiredOAuthAuthentication, OptionalOAuthAuthentication):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/o_auth_url_request.py` & `carbon_python_sdk-0.2.0/carbon/type/fresh_desk_connect_request.py`

 * *Files 23% similar despite different names*

```diff
@@ -10,55 +10,42 @@
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
-from carbon.type.data_source_type import DataSourceType
 from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.type.file_sync_config_nullable import FileSyncConfigNullable
 
-class RequiredOAuthURLRequest(TypedDict):
-    service: DataSourceType
+class RequiredFreshDeskConnectRequest(TypedDict):
+    domain: str
 
-class OptionalOAuthURLRequest(TypedDict, total=False):
-    tags: typing.Union[bool, date, datetime, dict, float, int, list, str, None]
+    api_key: str
 
-    scope: typing.Optional[str]
+
+class OptionalFreshDeskConnectRequest(TypedDict, total=False):
+    tags: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
 
     chunk_size: typing.Optional[int]
 
     chunk_overlap: typing.Optional[int]
 
     skip_embedding_generation: typing.Optional[bool]
 
-    embedding_model: EmbeddingGeneratorsNullable
-
-    zendesk_subdomain: typing.Optional[str]
-
-    microsoft_tenant: typing.Optional[str]
-
-    sharepoint_site_name: typing.Optional[str]
-
-    confluence_subdomain: typing.Optional[str]
+    embedding_model: typing.Optional[EmbeddingGeneratorsNullable]
 
     generate_sparse_vectors: typing.Optional[bool]
 
     prepend_filename_to_chunks: typing.Optional[bool]
 
-    max_items_per_chunk: typing.Optional[int]
-
-    salesforce_domain: typing.Optional[str]
-
-    # Used to specify whether Carbon should attempt to sync all your files automatically when authorization         is complete. This is only supported for a subset of connectors and will be ignored for the rest. Supported         connectors: Intercom, Zendesk, Gitbook, Confluence, Salesforce, Freshdesk
     sync_files_on_connection: typing.Optional[bool]
 
-    set_page_as_boundary: bool
+    request_id: typing.Optional[str]
 
-    # Used to specify a data source to sync from if you have multiple connected. It can be skipped if          you only have one data source of that type connected or are connecting a new account.
-    data_source_id: typing.Optional[int]
+    # Enabling this flag will fetch all available content from the source to be listed via list items endpoint
+    sync_source_items: bool
 
-    # Used to connect a new data source. If not specified, we will attempt to create a sync URL         for an existing data source based on type and ID.
-    connecting_new_account: typing.Optional[bool]
+    file_sync_config: typing.Optional[FileSyncConfigNullable]
 
-class OAuthURLRequest(RequiredOAuthURLRequest, OptionalOAuthURLRequest):
+class FreshDeskConnectRequest(RequiredFreshDeskConnectRequest, OptionalFreshDeskConnectRequest):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/organization_response.py` & `carbon_python_sdk-0.2.0/carbon/type/user_response.py`

 * *Files 15% similar despite different names*

```diff
@@ -10,42 +10,54 @@
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
+from carbon.type.user_response_auto_sync_enabled_sources import UserResponseAutoSyncEnabledSources
+from carbon.type.user_response_unique_file_tags import UserResponseUniqueFileTags
 
-class RequiredOrganizationResponse(TypedDict):
+class RequiredUserResponse(TypedDict):
     id: int
 
-    name: str
+    organization_id: int
 
-    nickname: typing.Optional[str]
+    organization_supplied_user_id: str
 
-    remove_branding: bool
+    created_at: datetime
+
+    updated_at: datetime
+
+    deleted_at: typing.Optional[datetime]
+
+    num_files_synced: int
 
-    custom_branding: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
+    num_characters_synced: int
 
-    custom_limits: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
+    num_tokens_synced: int
 
     aggregate_file_size: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
 
     aggregate_num_characters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
 
     aggregate_num_tokens: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
 
     aggregate_num_embeddings: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
 
-    period_ends_at: typing.Optional[datetime]
+    aggregate_num_files_by_source: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
 
-    cancel_at_period_end: typing.Optional[bool]
+    aggregate_num_files_by_file_format: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
 
-    created_at: datetime
+    unique_file_tags: UserResponseUniqueFileTags
 
-    updated_at: datetime
+    enabled_features: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
+
+    custom_limits: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
+
+    auto_sync_enabled_sources: UserResponseAutoSyncEnabledSources
 
-class OptionalOrganizationResponse(TypedDict, total=False):
+class OptionalUserResponse(TypedDict, total=False):
     pass
 
-class OrganizationResponse(RequiredOrganizationResponse, OptionalOrganizationResponse):
+class UserResponse(RequiredUserResponse, OptionalUserResponse):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/organization_user_data_source_api.py` & `carbon_python_sdk-0.2.0/carbon/type/organization_user_data_source_api.py`

 * *Files 16% similar despite different names*

```diff
@@ -39,16 +39,22 @@
 
     revoked_access: bool
 
     last_synced_at: datetime
 
     last_sync_action: DataSourceLastSyncActions
 
+    enable_auto_sync: typing.Optional[bool]
+
     created_at: datetime
 
     updated_at: datetime
 
+    files_synced_at: typing.Optional[datetime]
+
+    data_source_metadata: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
+
 class OptionalOrganizationUserDataSourceAPI(TypedDict, total=False):
     pass
 
 class OrganizationUserDataSourceAPI(RequiredOrganizationUserDataSourceAPI, OptionalOrganizationUserDataSourceAPI):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/organization_user_data_source_filters.py` & `carbon_python_sdk-0.2.0/carbon/type/organization_user_data_source_response.py`

 * *Files 13% similar despite different names*

```diff
@@ -10,22 +10,19 @@
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
-from carbon.type.data_source_type_nullable import DataSourceTypeNullable
-from carbon.type.organization_user_data_source_filters_ids import OrganizationUserDataSourceFiltersIds
+from carbon.type.organization_user_data_source_api import OrganizationUserDataSourceAPI
 
-class RequiredOrganizationUserDataSourceFilters(TypedDict):
-    pass
-
-class OptionalOrganizationUserDataSourceFilters(TypedDict, total=False):
-    source: DataSourceTypeNullable
+class RequiredOrganizationUserDataSourceResponse(TypedDict):
+    results: typing.List[OrganizationUserDataSourceAPI]
 
-    ids: OrganizationUserDataSourceFiltersIds
+    count: int
 
-    revoked_access: typing.Optional[bool]
+class OptionalOrganizationUserDataSourceResponse(TypedDict, total=False):
+    pass
 
-class OrganizationUserDataSourceFilters(RequiredOrganizationUserDataSourceFilters, OptionalOrganizationUserDataSourceFilters):
+class OrganizationUserDataSourceResponse(RequiredOrganizationUserDataSourceResponse, OptionalOrganizationUserDataSourceResponse):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/organization_user_data_source_query_input.py` & `carbon_python_sdk-0.2.0/carbon/type/organization_user_data_source_query_input.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/organization_user_data_source_response.py` & `carbon_python_sdk-0.2.0/carbon/type/zotero_authentication.py`

 * *Files 25% similar despite different names*

```diff
@@ -10,19 +10,24 @@
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
-from carbon.type.organization_user_data_source_api import OrganizationUserDataSourceAPI
 
-class RequiredOrganizationUserDataSourceResponse(TypedDict):
-    results: typing.List[OrganizationUserDataSourceAPI]
+class RequiredZoteroAuthentication(TypedDict):
+    source: typing.Union[bool, date, datetime, dict, float, int, list, str, None]
 
-    count: int
+    access_token: str
 
-class OptionalOrganizationUserDataSourceResponse(TypedDict, total=False):
+    access_token_secret: str
+
+    username: str
+
+    zotero_id: str
+
+class OptionalZoteroAuthentication(TypedDict, total=False):
     pass
 
-class OrganizationUserDataSourceResponse(RequiredOrganizationUserDataSourceResponse, OptionalOrganizationUserDataSourceResponse):
+class ZoteroAuthentication(RequiredZoteroAuthentication, OptionalZoteroAuthentication):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/organization_user_file_tag_create.py` & `carbon_python_sdk-0.2.0/carbon/type/organization_user_file_tag_create.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/organization_user_file_tags_remove.py` & `carbon_python_sdk-0.2.0/carbon/type/organization_user_file_tags_remove.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/organization_user_files_to_sync_query_input.py` & `carbon_python_sdk-0.2.0/carbon/type/organization_user_files_to_sync_query_input.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/outh_url_response.py` & `carbon_python_sdk-0.2.0/carbon/type/outh_url_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/outlook_sync_input.py` & `carbon_python_sdk-0.2.0/carbon/type/user_file.py`

 * *Files 26% similar despite different names*

```diff
@@ -10,33 +10,83 @@
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
-from carbon.type.embedding_generators import EmbeddingGenerators
+from carbon.type.chunk_properties_nullable import ChunkPropertiesNullable
+from carbon.type.data_source_type import DataSourceType
+from carbon.type.external_file_sync_statuses import ExternalFileSyncStatuses
+from carbon.type.file_statistics_nullable import FileStatisticsNullable
+from carbon.type.user_file_embedding_properties import UserFileEmbeddingProperties
 
-class RequiredOutlookSyncInput(TypedDict):
-    filters: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
-
-class OptionalOutlookSyncInput(TypedDict, total=False):
+class RequiredUserFile(TypedDict):
     tags: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
 
-    folder: typing.Optional[str]
+    id: int
+
+    source: DataSourceType
+
+    organization_id: int
+
+    organization_supplied_user_id: str
+
+    organization_user_data_source_id: typing.Optional[int]
+
+    external_file_id: str
+
+    external_url: typing.Optional[str]
+
+    sync_status: ExternalFileSyncStatuses
+
+    sync_error_message: typing.Optional[str]
+
+    last_sync: typing.Optional[datetime]
+
+    file_statistics: typing.Optional[FileStatisticsNullable]
+
+    file_metadata: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
+
+    embedding_properties: typing.Optional[UserFileEmbeddingProperties]
 
     chunk_size: typing.Optional[int]
 
     chunk_overlap: typing.Optional[int]
 
-    skip_embedding_generation: typing.Optional[bool]
+    chunk_properties: typing.Optional[ChunkPropertiesNullable]
 
-    embedding_model: EmbeddingGenerators
+    ocr_properties: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
+
+    ocr_job_started_at: typing.Optional[datetime]
+
+    name: typing.Optional[str]
+
+    parent_id: typing.Optional[int]
+
+    enable_auto_sync: typing.Optional[bool]
+
+    presigned_url: typing.Optional[str]
+
+    parsed_text_url: typing.Optional[str]
+
+    additional_presigned_urls: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
+
+    skip_embedding_generation: bool
+
+    source_created_at: typing.Optional[datetime]
 
     generate_sparse_vectors: typing.Optional[bool]
 
-    prepend_filename_to_chunks: typing.Optional[bool]
+    request_id: typing.Optional[str]
+
+    sync_properties: typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]
 
-    data_source_id: typing.Optional[int]
+    created_at: datetime
+
+    updated_at: datetime
+
+class OptionalUserFile(TypedDict, total=False):
+    pass
 
-class OutlookSyncInput(RequiredOutlookSyncInput, OptionalOutlookSyncInput):
+class UserFile(RequiredUserFile, OptionalUserFile):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/pagination.py` & `carbon_python_sdk-0.2.0/carbon/type/pagination.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/presigned_url_response.py` & `carbon_python_sdk-0.2.0/carbon/type/presigned_url_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/raw_text_input.py` & `carbon_python_sdk-0.2.0/carbon/type/raw_text_input.py`

 * *Files 12% similar despite different names*

```diff
@@ -15,24 +15,25 @@
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
 from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
 
 class RequiredRawTextInput(TypedDict):
     contents: str
 
+
 class OptionalRawTextInput(TypedDict, total=False):
     name: typing.Optional[str]
 
     chunk_size: typing.Optional[int]
 
     chunk_overlap: typing.Optional[int]
 
     skip_embedding_generation: bool
 
     overwrite_file_id: typing.Optional[int]
 
-    embedding_model: EmbeddingGeneratorsNullable
+    embedding_model: typing.Optional[EmbeddingGeneratorsNullable]
 
     generate_sparse_vectors: typing.Optional[bool]
 
 class RawTextInput(RequiredRawTextInput, OptionalRawTextInput):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/resync_file_query_input.py` & `carbon_python_sdk-0.2.0/carbon/type/resync_file_query_input.py`

 * *Files 0% similar despite different names*

```diff
@@ -14,14 +14,15 @@
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
 
 class RequiredResyncFileQueryInput(TypedDict):
     file_id: int
 
+
 class OptionalResyncFileQueryInput(TypedDict, total=False):
     chunk_size: typing.Optional[int]
 
     chunk_overlap: typing.Optional[int]
 
     force_embedding_generation: bool
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/revoke_access_token_input.py` & `carbon_python_sdk-0.2.0/carbon/type/revoke_access_token_input.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/rss_feed_input.py` & `carbon_python_sdk-0.2.0/carbon/type/rss_feed_input.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,14 +15,15 @@
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
 from carbon.type.embedding_generators import EmbeddingGenerators
 
 class RequiredRSSFeedInput(TypedDict):
     url: str
 
+
 class OptionalRSSFeedInput(TypedDict, total=False):
     tags: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
 
     chunk_size: typing.Optional[int]
 
     chunk_overlap: typing.Optional[int]
 
@@ -30,9 +31,11 @@
 
     embedding_model: EmbeddingGenerators
 
     generate_sparse_vectors: typing.Optional[bool]
 
     prepend_filename_to_chunks: typing.Optional[bool]
 
+    request_id: typing.Optional[str]
+
 class RSSFeedInput(RequiredRSSFeedInput, OptionalRSSFeedInput):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/s3_authentication.py` & `carbon_python_sdk-0.2.0/carbon/type/s3_auth_request.py`

 * *Files 24% similar despite different names*

```diff
@@ -11,19 +11,19 @@
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
 
-class RequiredS3Authentication(TypedDict):
-    source: typing.Union[bool, date, datetime, dict, float, int, list, str, None]
-
+class RequiredS3AuthRequest(TypedDict):
     access_key: str
 
     access_key_secret: str
 
-class OptionalS3Authentication(TypedDict, total=False):
-    pass
 
-class S3Authentication(RequiredS3Authentication, OptionalS3Authentication):
+class OptionalS3AuthRequest(TypedDict, total=False):
+    # Enabling this flag will fetch all available content from the source to be listed via list items endpoint
+    sync_source_items: bool
+
+class S3AuthRequest(RequiredS3AuthRequest, OptionalS3AuthRequest):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/s3_get_file_input.py` & `carbon_python_sdk-0.2.0/carbon/type/s3_get_file_input.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/salesforce_authentication.py` & `carbon_python_sdk-0.2.0/carbon/type/salesforce_authentication.py`

 * *Files 0% similar despite different names*

```diff
@@ -18,12 +18,13 @@
 class RequiredSalesforceAuthentication(TypedDict):
     source: typing.Union[bool, date, datetime, dict, float, int, list, str, None]
 
     access_token: str
 
     domain: str
 
+
 class OptionalSalesforceAuthentication(TypedDict, total=False):
     refresh_token: typing.Optional[str]
 
 class SalesforceAuthentication(RequiredSalesforceAuthentication, OptionalSalesforceAuthentication):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/single_chunks_and_embeddings_upload_input.py` & `carbon_python_sdk-0.2.0/carbon/type/single_chunks_and_embeddings_upload_input.py`

 * *Files 0% similar despite different names*

```diff
@@ -17,14 +17,15 @@
 from carbon.type.chunks_and_embeddings import ChunksAndEmbeddings
 
 class RequiredSingleChunksAndEmbeddingsUploadInput(TypedDict):
     file_id: int
 
     chunks_and_embeddings: typing.List[ChunksAndEmbeddings]
 
+
 class OptionalSingleChunksAndEmbeddingsUploadInput(TypedDict, total=False):
     chunk_size: typing.Optional[int]
 
     chunk_overlap: typing.Optional[int]
 
 class SingleChunksAndEmbeddingsUploadInput(RequiredSingleChunksAndEmbeddingsUploadInput, OptionalSingleChunksAndEmbeddingsUploadInput):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/sitemap_scrape_request.py` & `carbon_python_sdk-0.2.0/carbon/type/sitemap_scrape_request.py`

 * *Files 20% similar despite different names*

```diff
@@ -19,16 +19,17 @@
 from carbon.type.sitemap_scrape_request_css_selectors_to_skip import SitemapScrapeRequestCssSelectorsToSkip
 from carbon.type.sitemap_scrape_request_html_tags_to_skip import SitemapScrapeRequestHtmlTagsToSkip
 from carbon.type.sitemap_scrape_request_tags import SitemapScrapeRequestTags
 
 class RequiredSitemapScrapeRequest(TypedDict):
     url: str
 
+
 class OptionalSitemapScrapeRequest(TypedDict, total=False):
-    tags: SitemapScrapeRequestTags
+    tags: typing.Optional[SitemapScrapeRequestTags]
 
     max_pages_to_scrape: typing.Optional[int]
 
     chunk_size: typing.Optional[int]
 
     chunk_overlap: typing.Optional[int]
 
@@ -36,17 +37,17 @@
 
     enable_auto_sync: typing.Optional[bool]
 
     generate_sparse_vectors: typing.Optional[bool]
 
     prepend_filename_to_chunks: typing.Optional[bool]
 
-    html_tags_to_skip: SitemapScrapeRequestHtmlTagsToSkip
+    html_tags_to_skip: typing.Optional[SitemapScrapeRequestHtmlTagsToSkip]
 
-    css_classes_to_skip: SitemapScrapeRequestCssClassesToSkip
+    css_classes_to_skip: typing.Optional[SitemapScrapeRequestCssClassesToSkip]
 
-    css_selectors_to_skip: SitemapScrapeRequestCssSelectorsToSkip
+    css_selectors_to_skip: typing.Optional[SitemapScrapeRequestCssSelectorsToSkip]
 
     embedding_model: EmbeddingGenerators
 
 class SitemapScrapeRequest(RequiredSitemapScrapeRequest, OptionalSitemapScrapeRequest):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/sync_directory_request.py` & `carbon_python_sdk-0.2.0/carbon/type/sync_directory_request.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/sync_files_ids.py` & `carbon_python_sdk-0.2.0/carbon/type/sync_files_ids.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/sync_files_request.py` & `carbon_python_sdk-0.2.0/carbon/type/sync_files_request.py`

 * *Files 12% similar despite different names*

```diff
@@ -11,35 +11,49 @@
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
 from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.type.file_sync_config_nullable import FileSyncConfigNullable
 from carbon.type.sync_files_ids import SyncFilesIds
 
 class RequiredSyncFilesRequest(TypedDict):
     data_source_id: int
 
     ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]]
 
+
 class OptionalSyncFilesRequest(TypedDict, total=False):
     tags: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
 
     chunk_size: typing.Optional[int]
 
     chunk_overlap: typing.Optional[int]
 
     skip_embedding_generation: typing.Optional[bool]
 
-    embedding_model: EmbeddingGeneratorsNullable
+    embedding_model: typing.Optional[EmbeddingGeneratorsNullable]
 
     generate_sparse_vectors: typing.Optional[bool]
 
     prepend_filename_to_chunks: typing.Optional[bool]
 
+    # Number of objects per chunk. For csv, tsv, xlsx, and json files only.
     max_items_per_chunk: typing.Optional[int]
 
     set_page_as_boundary: bool
 
+    request_id: str
+
+    use_ocr: typing.Optional[bool]
+
+    parse_pdf_tables_with_ocr: typing.Optional[bool]
+
+    # Only sync files if they have not already been synced or if the embedding properties have changed.         This flag is currently supported by ONEDRIVE, GOOGLE_DRIVE, BOX, DROPBOX. It will be ignored for other data sources.
+    incremental_sync: bool
+
+    file_sync_config: typing.Optional[FileSyncConfigNullable]
+
 class SyncFilesRequest(RequiredSyncFilesRequest, OptionalSyncFilesRequest):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/sync_options.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/list_items_filters.py`

 * *Files 25% similar despite different names*

```diff
@@ -9,37 +9,25 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
-from carbon.type.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.pydantic.list_items_filters_external_ids import ListItemsFiltersExternalIds
+from carbon.pydantic.list_items_filters_ids import ListItemsFiltersIds
 
-class RequiredSyncOptions(TypedDict):
-    pass
+class ListItemsFilters(BaseModel):
+    external_ids: typing.Optional[ListItemsFiltersExternalIds] = Field(None, alias='external_ids')
 
-class OptionalSyncOptions(TypedDict, total=False):
-    tags: typing.Union[bool, date, datetime, dict, float, int, list, str, None]
+    ids: typing.Optional[ListItemsFiltersIds] = Field(None, alias='ids')
 
-    chunk_size: typing.Optional[int]
+    name: typing.Optional[typing.Optional[str]] = Field(None, alias='name')
 
-    chunk_overlap: typing.Optional[int]
+    root_files_only: typing.Optional[typing.Optional[bool]] = Field(None, alias='root_files_only')
 
-    skip_embedding_generation: typing.Optional[bool]
-
-    embedding_model: EmbeddingGeneratorsNullable
-
-    generate_sparse_vectors: typing.Optional[bool]
-
-    prepend_filename_to_chunks: typing.Optional[bool]
-
-    max_items_per_chunk: typing.Optional[int]
-
-    # Used to specify whether Carbon should attempt to sync all your files automatically when authorization         is complete. This is only supported for a subset of connectors and will be ignored for the rest. Supported         connectors: Intercom, Zendesk, Gitbook, Confluence, Salesforce, Freshdesk
-    sync_files_on_connection: typing.Optional[bool]
-
-    set_page_as_boundary: bool
-
-class SyncOptions(RequiredSyncOptions, OptionalSyncOptions):
-    pass
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/text_embedding_generators.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/text_embedding_generators.py`

 * *Files 21% similar despite different names*

```diff
@@ -9,10 +9,11 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
 
-TextEmbeddingGenerators = Literal["OPENAI", "AZURE_OPENAI", "COHERE_MULTILINGUAL_V3", "OPENAI_ADA_LARGE_256", "OPENAI_ADA_LARGE_1024", "OPENAI_ADA_LARGE_3072", "OPENAI_ADA_SMALL_512", "OPENAI_ADA_SMALL_1536"]
+TextEmbeddingGenerators = Literal["OPENAI", "AZURE_OPENAI", "COHERE_MULTILINGUAL_V3", "OPENAI_ADA_LARGE_256", "OPENAI_ADA_LARGE_1024", "OPENAI_ADA_LARGE_3072", "OPENAI_ADA_SMALL_512", "OPENAI_ADA_SMALL_1536", "AZURE_ADA_LARGE_256", "AZURE_ADA_LARGE_1024", "AZURE_ADA_LARGE_3072", "AZURE_ADA_SMALL_512", "AZURE_ADA_SMALL_1536", "SOLAR_1_MINI"]
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/token_response.py` & `carbon_python_sdk-0.2.0/carbon/type/token_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/upload_file_from_url_input.py` & `carbon_python_sdk-0.2.0/carbon/type/upload_file_from_url_input.py`

 * *Files 7% similar despite different names*

```diff
@@ -15,14 +15,15 @@
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
 from carbon.type.embedding_generators import EmbeddingGenerators
 
 class RequiredUploadFileFromUrlInput(TypedDict):
     url: str
 
+
 class OptionalUploadFileFromUrlInput(TypedDict, total=False):
     file_name: typing.Optional[str]
 
     chunk_size: typing.Optional[int]
 
     chunk_overlap: typing.Optional[int]
 
@@ -34,11 +35,16 @@
 
     generate_sparse_vectors: bool
 
     use_textract: bool
 
     prepend_filename_to_chunks: bool
 
+    # Number of objects per chunk. For csv, tsv, xlsx, and json files only.
     max_items_per_chunk: typing.Optional[int]
 
+    parse_pdf_tables_with_ocr: bool
+
+    detect_audio_language: bool
+
 class UploadFileFromUrlInput(RequiredUploadFileFromUrlInput, OptionalUploadFileFromUrlInput):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/user_file.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/sync_files_request.py`

 * *Files 25% similar despite different names*

```diff
@@ -9,76 +9,52 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
-from carbon.type.chunk_properties_nullable import ChunkPropertiesNullable
-from carbon.type.data_source_type import DataSourceType
-from carbon.type.external_file_sync_statuses import ExternalFileSyncStatuses
-from carbon.type.file_statistics_nullable import FileStatisticsNullable
-from carbon.type.user_file_embedding_properties import UserFileEmbeddingProperties
+from carbon.pydantic.embedding_generators_nullable import EmbeddingGeneratorsNullable
+from carbon.pydantic.file_sync_config_nullable import FileSyncConfigNullable
+from carbon.pydantic.sync_files_ids import SyncFilesIds
 
-class RequiredUserFile(TypedDict):
-    tags: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
+class SyncFilesRequest(BaseModel):
+    data_source_id: int = Field(alias='data_source_id')
 
-    id: int
+    ids: typing.Union[typing.List[str], typing.List[SyncFilesIds]] = Field(alias='ids')
 
-    source: DataSourceType
+    tags: typing.Optional[typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]] = Field(None, alias='tags')
 
-    organization_id: int
+    chunk_size: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_size')
 
-    organization_supplied_user_id: str
+    chunk_overlap: typing.Optional[typing.Optional[int]] = Field(None, alias='chunk_overlap')
 
-    organization_user_data_source_id: typing.Optional[int]
+    skip_embedding_generation: typing.Optional[typing.Optional[bool]] = Field(None, alias='skip_embedding_generation')
 
-    external_file_id: str
+    embedding_model: typing.Optional[EmbeddingGeneratorsNullable] = Field(None, alias='embedding_model')
 
-    external_url: typing.Optional[str]
+    generate_sparse_vectors: typing.Optional[typing.Optional[bool]] = Field(None, alias='generate_sparse_vectors')
 
-    sync_status: ExternalFileSyncStatuses
+    prepend_filename_to_chunks: typing.Optional[typing.Optional[bool]] = Field(None, alias='prepend_filename_to_chunks')
 
-    sync_error_message: typing.Optional[str]
+    # Number of objects per chunk. For csv, tsv, xlsx, and json files only.
+    max_items_per_chunk: typing.Optional[typing.Optional[int]] = Field(None, alias='max_items_per_chunk')
 
-    last_sync: typing.Optional[datetime]
+    set_page_as_boundary: typing.Optional[bool] = Field(None, alias='set_page_as_boundary')
 
-    file_statistics: FileStatisticsNullable
+    request_id: typing.Optional[str] = Field(None, alias='request_id')
 
-    file_metadata: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
+    use_ocr: typing.Optional[typing.Optional[bool]] = Field(None, alias='use_ocr')
 
-    embedding_properties: UserFileEmbeddingProperties
+    parse_pdf_tables_with_ocr: typing.Optional[typing.Optional[bool]] = Field(None, alias='parse_pdf_tables_with_ocr')
 
-    chunk_size: typing.Optional[int]
+    # Only sync files if they have not already been synced or if the embedding properties have changed.         This flag is currently supported by ONEDRIVE, GOOGLE_DRIVE, BOX, DROPBOX. It will be ignored for other data sources.
+    incremental_sync: typing.Optional[bool] = Field(None, alias='incremental_sync')
 
-    chunk_overlap: typing.Optional[int]
+    file_sync_config: typing.Optional[FileSyncConfigNullable] = Field(None, alias='file_sync_config')
 
-    chunk_properties: ChunkPropertiesNullable
-
-    name: typing.Optional[str]
-
-    parent_id: typing.Optional[int]
-
-    enable_auto_sync: typing.Optional[bool]
-
-    presigned_url: typing.Optional[str]
-
-    parsed_text_url: typing.Optional[str]
-
-    additional_presigned_urls: typing.Optional[typing.Dict[str, typing.Union[bool, date, datetime, dict, float, int, list, str, None]]]
-
-    skip_embedding_generation: bool
-
-    source_created_at: typing.Optional[datetime]
-
-    generate_sparse_vectors: typing.Optional[bool]
-
-    created_at: datetime
-
-    updated_at: datetime
-
-class OptionalUserFile(TypedDict, total=False):
-    pass
-
-class UserFile(RequiredUserFile, OptionalUserFile):
-    pass
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/user_files_v2.py` & `carbon_python_sdk-0.2.0/carbon/type/user_files_v2.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/user_request_content.py` & `carbon_python_sdk-0.2.0/carbon/type/user_request_content.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/validation_error.py` & `carbon_python_sdk-0.2.0/carbon/type/validation_error.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/webhook.py` & `carbon_python_sdk-0.2.0/carbon/type/webhook.py`

 * *Files 10% similar despite different names*

```diff
@@ -10,24 +10,29 @@
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
+from carbon.type.webhook_status import WebhookStatus
 
 class RequiredWebhook(TypedDict):
     id: int
 
     organization_id: int
 
     url: str
 
     signing_key: str
 
+    status: WebhookStatus
+
+    status_reason: typing.Optional[str]
+
     created_at: datetime
 
     updated_at: datetime
 
 class OptionalWebhook(TypedDict, total=False):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/webhook_filters.py` & `carbon_python_sdk-0.2.0/carbon/pydantic/list_request.py`

 * *Files 22% similar despite different names*

```diff
@@ -9,18 +9,19 @@
     Generated by: https://konfigthis.com
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
+from pydantic import BaseModel, Field, RootModel, ConfigDict
 
-from carbon.type.webhook_filters_ids import WebhookFiltersIds
 
-class RequiredWebhookFilters(TypedDict):
-    pass
+class ListRequest(BaseModel):
+    data_source_id: int = Field(alias='data_source_id')
 
-class OptionalWebhookFilters(TypedDict, total=False):
-    ids: WebhookFiltersIds
+    parent_id: typing.Optional[typing.Optional[str]] = Field(None, alias='parent_id')
 
-class WebhookFilters(RequiredWebhookFilters, OptionalWebhookFilters):
-    pass
+    model_config = ConfigDict(
+        protected_namespaces=(),
+        arbitrary_types_allowed=True
+    )
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/webhook_no_key.py` & `carbon_python_sdk-0.2.0/carbon/type/webhook_filters.py`

 * *Files 16% similar despite different names*

```diff
@@ -10,24 +10,17 @@
 """
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
+from carbon.type.webhook_filters_ids import WebhookFiltersIds
 
-class RequiredWebhookNoKey(TypedDict):
-    id: int
-
-    organization_id: int
-
-    url: str
-
-    created_at: datetime
-
-    updated_at: datetime
-
-class OptionalWebhookNoKey(TypedDict, total=False):
+class RequiredWebhookFilters(TypedDict):
     pass
 
-class WebhookNoKey(RequiredWebhookNoKey, OptionalWebhookNoKey):
+class OptionalWebhookFilters(TypedDict, total=False):
+    ids: typing.Optional[WebhookFiltersIds]
+
+class WebhookFilters(RequiredWebhookFilters, OptionalWebhookFilters):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/webhook_query_input.py` & `carbon_python_sdk-0.2.0/carbon/type/webhook_query_input.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/webhook_query_response.py` & `carbon_python_sdk-0.2.0/carbon/type/webhook_query_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/webscrape_request.py` & `carbon_python_sdk-0.2.0/carbon/type/webscrape_request.py`

 * *Files 11% similar despite different names*

```diff
@@ -19,16 +19,17 @@
 from carbon.type.webscrape_request_css_selectors_to_skip import WebscrapeRequestCssSelectorsToSkip
 from carbon.type.webscrape_request_html_tags_to_skip import WebscrapeRequestHtmlTagsToSkip
 from carbon.type.webscrape_request_tags import WebscrapeRequestTags
 
 class RequiredWebscrapeRequest(TypedDict):
     url: str
 
+
 class OptionalWebscrapeRequest(TypedDict, total=False):
-    tags: WebscrapeRequestTags
+    tags: typing.Optional[WebscrapeRequestTags]
 
     recursion_depth: typing.Optional[int]
 
     max_pages_to_scrape: typing.Optional[int]
 
     chunk_size: typing.Optional[int]
 
@@ -38,17 +39,17 @@
 
     enable_auto_sync: typing.Optional[bool]
 
     generate_sparse_vectors: typing.Optional[bool]
 
     prepend_filename_to_chunks: typing.Optional[bool]
 
-    html_tags_to_skip: WebscrapeRequestHtmlTagsToSkip
+    html_tags_to_skip: typing.Optional[WebscrapeRequestHtmlTagsToSkip]
 
-    css_classes_to_skip: WebscrapeRequestCssClassesToSkip
+    css_classes_to_skip: typing.Optional[WebscrapeRequestCssClassesToSkip]
 
-    css_selectors_to_skip: WebscrapeRequestCssSelectorsToSkip
+    css_selectors_to_skip: typing.Optional[WebscrapeRequestCssSelectorsToSkip]
 
     embedding_model: EmbeddingGenerators
 
 class WebscrapeRequest(RequiredWebscrapeRequest, OptionalWebscrapeRequest):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/white_labeling_response.py` & `carbon_python_sdk-0.2.0/carbon/type/white_labeling_response.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/youtube_transcript_response.py` & `carbon_python_sdk-0.2.0/carbon/type/youtube_transcript_response.py`

 * *Files 8% similar despite different names*

```diff
@@ -19,14 +19,14 @@
 class RequiredYoutubeTranscriptResponse(TypedDict):
     status: str
 
     error: typing.Optional[str]
 
     data: typing.Optional[str]
 
-    raw_transcript: YoutubeTranscriptResponseRawTranscript
+    raw_transcript: typing.Optional[YoutubeTranscriptResponseRawTranscript]
 
 class OptionalYoutubeTranscriptResponse(TypedDict, total=False):
     pass
 
 class YoutubeTranscriptResponse(RequiredYoutubeTranscriptResponse, OptionalYoutubeTranscriptResponse):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type/youtube_transcript_response_raw_transcript.py` & `carbon_python_sdk-0.2.0/carbon/type/youtube_transcript_response_raw_transcript.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/zendesk_authentication.py` & `carbon_python_sdk-0.2.0/carbon/type/zendesk_authentication.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/type/zotero_authentication.py` & `carbon_python_sdk-0.2.0/carbon/type/github_authentication.py`

 * *Files 20% similar despite different names*

```diff
@@ -11,23 +11,19 @@
 
 from datetime import datetime, date
 import typing
 from enum import Enum
 from typing_extensions import TypedDict, Literal, TYPE_CHECKING
 
 
-class RequiredZoteroAuthentication(TypedDict):
+class RequiredGithubAuthentication(TypedDict):
     source: typing.Union[bool, date, datetime, dict, float, int, list, str, None]
 
     access_token: str
 
-    access_token_secret: str
-
     username: str
 
-    zotero_id: str
-
-class OptionalZoteroAuthentication(TypedDict, total=False):
+class OptionalGithubAuthentication(TypedDict, total=False):
     pass
 
-class ZoteroAuthentication(RequiredZoteroAuthentication, OptionalZoteroAuthentication):
+class GithubAuthentication(RequiredGithubAuthentication, OptionalGithubAuthentication):
     pass
```

### Comparing `carbon_python_sdk-0.1.9/carbon/type_util.py` & `carbon_python_sdk-0.2.0/carbon/type_util.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/carbon/validation_metadata.py` & `carbon_python_sdk-0.2.0/carbon/validation_metadata.py`

 * *Files identical despite different names*

### Comparing `carbon_python_sdk-0.1.9/pyproject.toml` & `carbon_python_sdk-0.2.0/pyproject.toml`

 * *Files 16% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 [tool.poetry]
 name = "carbon-python-sdk"
-version = "0.1.9"
+version = "0.2.0"
 description = "Client for Carbon"
 authors = ["Konfig <engineering@konfigthis.com>"]
 license = "MIT"
 readme = "README.md"
 packages = [{include = "carbon"}]
 
 [tool.poetry.dependencies]
 python = "^3.8"
 certifi = ">=2023.7.22"
 python-dateutil = "^2.8.2"
 typing_extensions = "^4.3.0"
-urllib3 = "^1.26.18"
-cryptography = "^41.0.6"
+urllib3 = "^1.26.18 || ^2.0.0"
+cryptography = "^42.0.5"
 frozendict = "^2.3.4"
 aiohttp = "^3.9.2"
 pydantic = "^2.4.2"
 
 [tool.poetry.group.dev.dependencies]
 setuptools = "^65.5.1"
 pytest = "^7.3.1"
```

### Comparing `carbon_python_sdk-0.1.9/PKG-INFO` & `carbon_python_sdk-0.2.0/README.md`

 * *Files 9% similar despite different names*

```diff
@@ -1,42 +1,17 @@
-Metadata-Version: 2.1
-Name: carbon-python-sdk
-Version: 0.1.9
-Summary: Client for Carbon
-License: MIT
-Author: Konfig
-Author-email: engineering@konfigthis.com
-Requires-Python: >=3.8,<4.0
-Classifier: License :: OSI Approved :: MIT License
-Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
-Classifier: Programming Language :: Python :: 3.10
-Classifier: Programming Language :: Python :: 3.11
-Classifier: Programming Language :: Python :: 3.12
-Requires-Dist: aiohttp (>=3.9.2,<4.0.0)
-Requires-Dist: certifi (>=2023.7.22)
-Requires-Dist: cryptography (>=41.0.6,<42.0.0)
-Requires-Dist: frozendict (>=2.3.4,<3.0.0)
-Requires-Dist: pydantic (>=2.4.2,<3.0.0)
-Requires-Dist: python-dateutil (>=2.8.2,<3.0.0)
-Requires-Dist: typing_extensions (>=4.3.0,<5.0.0)
-Requires-Dist: urllib3 (>=1.26.18,<2.0.0)
-Description-Content-Type: text/markdown
-
 <div align="center">
 
 [![Visit Carbon](https://raw.githubusercontent.com/Carbon-for-Developers/carbon-sdks/HEAD/python/header.png)](https://carbon.ai)
 
 # Carbon<a id="carbon"></a>
 
 Connect external data to LLMs, no matter the source.
 
 
-[![PyPI](https://img.shields.io/badge/PyPI-v0.1.9-blue)](https://pypi.org/project/carbon-python-sdk/0.1.9)
+[![PyPI](https://img.shields.io/badge/PyPI-v0.2.0-blue)](https://pypi.org/project/carbon-python-sdk/0.2.0)
 [![README.md](https://img.shields.io/badge/README-Click%20Here-green)](https://github.com/Carbon-for-Developers/carbon-sdks/tree/main/python#readme)
 
 </div>
 
 ## Table of Contents<a id="table-of-contents"></a>
 
 <!-- toc -->
@@ -54,14 +29,15 @@
   * [`carbon.embeddings.get_documents`](#carbonembeddingsget_documents)
   * [`carbon.embeddings.get_embeddings_and_chunks`](#carbonembeddingsget_embeddings_and_chunks)
   * [`carbon.embeddings.upload_chunks_and_embeddings`](#carbonembeddingsupload_chunks_and_embeddings)
   * [`carbon.files.create_user_file_tags`](#carbonfilescreate_user_file_tags)
   * [`carbon.files.delete`](#carbonfilesdelete)
   * [`carbon.files.delete_file_tags`](#carbonfilesdelete_file_tags)
   * [`carbon.files.delete_many`](#carbonfilesdelete_many)
+  * [`carbon.files.delete_v2`](#carbonfilesdelete_v2)
   * [`carbon.files.get_parsed_file`](#carbonfilesget_parsed_file)
   * [`carbon.files.get_raw_file`](#carbonfilesget_raw_file)
   * [`carbon.files.query_user_files`](#carbonfilesquery_user_files)
   * [`carbon.files.query_user_files_deprecated`](#carbonfilesquery_user_files_deprecated)
   * [`carbon.files.resync`](#carbonfilesresync)
   * [`carbon.files.upload`](#carbonfilesupload)
   * [`carbon.files.upload_from_url`](#carbonfilesupload_from_url)
@@ -74,26 +50,32 @@
   * [`carbon.integrations.get_oauth_url`](#carbonintegrationsget_oauth_url)
   * [`carbon.integrations.list_confluence_pages`](#carbonintegrationslist_confluence_pages)
   * [`carbon.integrations.list_data_source_items`](#carbonintegrationslist_data_source_items)
   * [`carbon.integrations.list_folders`](#carbonintegrationslist_folders)
   * [`carbon.integrations.list_gitbook_spaces`](#carbonintegrationslist_gitbook_spaces)
   * [`carbon.integrations.list_labels`](#carbonintegrationslist_labels)
   * [`carbon.integrations.list_outlook_categories`](#carbonintegrationslist_outlook_categories)
+  * [`carbon.integrations.list_repos`](#carbonintegrationslist_repos)
   * [`carbon.integrations.sync_confluence`](#carbonintegrationssync_confluence)
   * [`carbon.integrations.sync_data_source_items`](#carbonintegrationssync_data_source_items)
   * [`carbon.integrations.sync_files`](#carbonintegrationssync_files)
+  * [`carbon.integrations.sync_git_hub`](#carbonintegrationssync_git_hub)
   * [`carbon.integrations.sync_gitbook`](#carbonintegrationssync_gitbook)
   * [`carbon.integrations.sync_gmail`](#carbonintegrationssync_gmail)
   * [`carbon.integrations.sync_outlook`](#carbonintegrationssync_outlook)
+  * [`carbon.integrations.sync_repos`](#carbonintegrationssync_repos)
   * [`carbon.integrations.sync_rss_feed`](#carbonintegrationssync_rss_feed)
   * [`carbon.integrations.sync_s3_files`](#carbonintegrationssync_s3_files)
   * [`carbon.organizations.get`](#carbonorganizationsget)
+  * [`carbon.organizations.update`](#carbonorganizationsupdate)
+  * [`carbon.organizations.update_stats`](#carbonorganizationsupdate_stats)
   * [`carbon.users.delete`](#carbonusersdelete)
   * [`carbon.users.get`](#carbonusersget)
   * [`carbon.users.toggle_user_features`](#carbonuserstoggle_user_features)
+  * [`carbon.users.update_users`](#carbonusersupdate_users)
   * [`carbon.utilities.fetch_urls`](#carbonutilitiesfetch_urls)
   * [`carbon.utilities.fetch_youtube_transcripts`](#carbonutilitiesfetch_youtube_transcripts)
   * [`carbon.utilities.process_sitemap`](#carbonutilitiesprocess_sitemap)
   * [`carbon.utilities.scrape_sitemap`](#carbonutilitiesscrape_sitemap)
   * [`carbon.utilities.scrape_web`](#carbonutilitiesscrape_web)
   * [`carbon.utilities.search_urls`](#carbonutilitiessearch_urls)
   * [`carbon.webhooks.add_url`](#carbonwebhooksadd_url)
@@ -105,15 +87,15 @@
 ## Requirements<a id="requirements"></a>
 
 Python >=3.7
 
 ## Installation<a id="installation"></a>
 
 ```sh
-pip install carbon-python-sdk==0.1.9
+pip install carbon-python-sdk==0.2.0
 ```
 
 ## Getting Started<a id="getting-started"></a>
 
 ```python
 from carbon import Carbon
 
@@ -435,14 +417,15 @@
     k=1,
     tags={
         "key": "string_example",
     },
     query_vector=[3.14],
     file_ids=[1],
     parent_file_ids=[1],
+    include_all_children=False,
     tags_v2={},
     include_tags=True,
     include_vectors=True,
     include_raw_file=True,
     hybrid_search=True,
     hybrid_search_tuning_parameters={
         "weight_a": 0.5,
@@ -467,14 +450,18 @@
 
 ##### query_vector: [`GetEmbeddingDocumentsBodyQueryVector`](./carbon/type/get_embedding_documents_body_query_vector.py)<a id="query_vector-getembeddingdocumentsbodyqueryvectorcarbontypeget_embedding_documents_body_query_vectorpy"></a>
 
 ##### file_ids: [`GetEmbeddingDocumentsBodyFileIds`](./carbon/type/get_embedding_documents_body_file_ids.py)<a id="file_ids-getembeddingdocumentsbodyfileidscarbontypeget_embedding_documents_body_file_idspy"></a>
 
 ##### parent_file_ids: [`GetEmbeddingDocumentsBodyParentFileIds`](./carbon/type/get_embedding_documents_body_parent_file_ids.py)<a id="parent_file_ids-getembeddingdocumentsbodyparentfileidscarbontypeget_embedding_documents_body_parent_file_idspy"></a>
 
+##### include_all_children: `bool`<a id="include_all_children-bool"></a>
+
+Flag to control whether or not to include all children of filtered files in the embedding search.
+
 ##### tags_v2: `Optional[Dict[str, Union[bool, date, datetime, dict, float, int, list, str, None]]]`<a id="tags_v2-optionaldictstr-unionbool-date-datetime-dict-float-int-list-str-none"></a>
 
 A set of tags to limit the search to. Use this instead of `tags`, which is deprecated.
 
 ##### include_tags: `Optional[bool]`<a id="include_tags-optionalbool"></a>
 
 Flag to control whether or not to include tags for each chunk in the response.
@@ -582,29 +569,31 @@
                     "chunk": "chunk_example",
                 }
             ],
         }
     ],
     overwrite_existing=False,
     chunks_only=False,
-    custom_credentials={},
+    custom_credentials={
+        "key": {},
+    },
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### embedding_model: [`EmbeddingGenerators`](./carbon/type/embedding_generators.py)<a id="embedding_model-embeddinggeneratorscarbontypeembedding_generatorspy"></a>
 
 ##### chunks_and_embeddings: List[`SingleChunksAndEmbeddingsUploadInput`]<a id="chunks_and_embeddings-listsinglechunksandembeddingsuploadinput"></a>
 
 ##### overwrite_existing: `bool`<a id="overwrite_existing-bool"></a>
 
 ##### chunks_only: `bool`<a id="chunks_only-bool"></a>
 
-##### custom_credentials: `Dict[str, Union[bool, date, datetime, dict, float, int, list, str, None]]`<a id="custom_credentials-dictstr-unionbool-date-datetime-dict-float-int-list-str-none"></a>
+##### custom_credentials: [`ChunksAndEmbeddingsUploadInputCustomCredentials`](./carbon/type/chunks_and_embeddings_upload_input_custom_credentials.py)<a id="custom_credentials-chunksandembeddingsuploadinputcustomcredentialscarbontypechunks_and_embeddings_upload_input_custom_credentialspy"></a>
 
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`ChunksAndEmbeddingsUploadInput`](./carbon/type/chunks_and_embeddings_upload_input.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
@@ -660,14 +649,15 @@
 `/create_user_file_tags` `post`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
 ### `carbon.files.delete`<a id="carbonfilesdelete"></a>
+![Deprecated](https://img.shields.io/badge/deprecated-yellow)
 
 Delete File Endpoint
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
 delete_response = carbon.files.delete(
@@ -722,14 +712,15 @@
 `/delete_user_file_tags` `post`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
 ### `carbon.files.delete_many`<a id="carbonfilesdelete_many"></a>
+![Deprecated](https://img.shields.io/badge/deprecated-yellow)
 
 Delete Files Endpoint
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
 delete_many_response = carbon.files.delete_many(
@@ -764,15 +755,54 @@
 
 `/delete_files` `post`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
+### `carbon.files.delete_v2`<a id="carbonfilesdelete_v2"></a>
+
+Delete Files V2 Endpoint
+
+#### 🛠️ Usage<a id="🛠️-usage"></a>
+
+```python
+delete_v2_response = carbon.files.delete_v2(
+    filters={
+        "include_all_children": False,
+        "non_synced_only": False,
+    },
+    send_webhook=False,
+)
+```
+
+#### ⚙️ Parameters<a id="⚙️-parameters"></a>
+
+##### filters: [`OrganizationUserFilesToSyncFilters`](./carbon/type/organization_user_files_to_sync_filters.py)<a id="filters-organizationuserfilestosyncfilterscarbontypeorganization_user_files_to_sync_filterspy"></a>
+
+
+##### send_webhook: `bool`<a id="send_webhook-bool"></a>
+
+#### ⚙️ Request Body<a id="⚙️-request-body"></a>
+
+[`DeleteFilesV2QueryInput`](./carbon/type/delete_files_v2_query_input.py)
+#### 🔄 Return<a id="🔄-return"></a>
+
+[`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
+
+#### 🌐 Endpoint<a id="🌐-endpoint"></a>
+
+`/delete_files_v2` `post`
+
+[🔙 **Back to Table of Contents**](#table-of-contents)
+
+---
+
 ### `carbon.files.get_parsed_file`<a id="carbonfilesget_parsed_file"></a>
+![Deprecated](https://img.shields.io/badge/deprecated-yellow)
 
 This route is deprecated. Use `/user_files_v2` instead.
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
 get_parsed_file_response = carbon.files.get_parsed_file(
@@ -793,14 +823,15 @@
 `/parsed_file/{file_id}` `get`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
 ### `carbon.files.get_raw_file`<a id="carbonfilesget_raw_file"></a>
+![Deprecated](https://img.shields.io/badge/deprecated-yellow)
 
 This route is deprecated. Use `/user_files_v2` instead.
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
 get_raw_file_response = carbon.files.get_raw_file(
@@ -883,15 +914,18 @@
 query_user_files_response = carbon.files.query_user_files(
     pagination={
         "limit": 10,
         "offset": 0,
     },
     order_by="created_at",
     order_dir="desc",
-    filters={},
+    filters={
+        "include_all_children": False,
+        "non_synced_only": False,
+    },
     include_raw_file=True,
     include_parsed_text_file=True,
     include_additional_files=True,
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
@@ -924,28 +958,32 @@
 `/user_files_v2` `post`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
 ### `carbon.files.query_user_files_deprecated`<a id="carbonfilesquery_user_files_deprecated"></a>
+![Deprecated](https://img.shields.io/badge/deprecated-yellow)
 
 This route is deprecated. Use `/user_files_v2` instead.
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
 query_user_files_deprecated_response = carbon.files.query_user_files_deprecated(
     pagination={
         "limit": 10,
         "offset": 0,
     },
     order_by="created_at",
     order_dir="desc",
-    filters={},
+    filters={
+        "include_all_children": False,
+        "non_synced_only": False,
+    },
     include_raw_file=True,
     include_parsed_text_file=True,
     include_additional_files=True,
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
@@ -1059,14 +1097,17 @@
     skip_embedding_generation=False,
     set_page_as_boundary=False,
     embedding_model="OPENAI",
     use_ocr=False,
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
     max_items_per_chunk=1,
+    parse_pdf_tables_with_ocr=False,
+    detect_audio_language=False,
+    media_type="TEXT",
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### file: `IO`<a id="file-io"></a>
 
@@ -1100,15 +1141,27 @@
 
 ##### prepend_filename_to_chunks: `bool`<a id="prepend_filename_to_chunks-bool"></a>
 
 Whether or not to prepend the file's name to chunks.
 
 ##### max_items_per_chunk: `Optional[int]`<a id="max_items_per_chunk-optionalint"></a>
 
-Number of objects per chunk. For json files only.
+Number of objects per chunk. For csv, tsv, xlsx, and json files only.
+
+##### parse_pdf_tables_with_ocr: `bool`<a id="parse_pdf_tables_with_ocr-bool"></a>
+
+Whether to use rich table parsing when `use_ocr` is enabled.
+
+##### detect_audio_language: `bool`<a id="detect_audio_language-bool"></a>
+
+Whether to automatically detect the language of the uploaded audio file.
+
+##### media_type: [`FileContentTypesNullable`](./carbon/type/.py)<a id="media_type-filecontenttypesnullablecarbontypepy"></a>
+
+The media type of the file. If not provided, it will be inferred from the file extension.
 
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`BodyCreateUploadFileUploadfilePost`](./carbon/type/body_create_upload_file_uploadfile_post.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`UserFile`](./carbon/pydantic/user_file.py)
@@ -1136,14 +1189,16 @@
     skip_embedding_generation=False,
     set_page_as_boundary=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     use_textract=False,
     prepend_filename_to_chunks=False,
     max_items_per_chunk=1,
+    parse_pdf_tables_with_ocr=False,
+    detect_audio_language=False,
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### url: `str`<a id="url-str"></a>
 
@@ -1163,14 +1218,20 @@
 
 ##### use_textract: `bool`<a id="use_textract-bool"></a>
 
 ##### prepend_filename_to_chunks: `bool`<a id="prepend_filename_to_chunks-bool"></a>
 
 ##### max_items_per_chunk: `Optional[int]`<a id="max_items_per_chunk-optionalint"></a>
 
+Number of objects per chunk. For csv, tsv, xlsx, and json files only.
+
+##### parse_pdf_tables_with_ocr: `bool`<a id="parse_pdf_tables_with_ocr-bool"></a>
+
+##### detect_audio_language: `bool`<a id="detect_audio_language-bool"></a>
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`UploadFileFromUrlInput`](./carbon/type/upload_file_from_url_input.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`UserFile`](./carbon/pydantic/user_file.py)
 
@@ -1195,15 +1256,15 @@
 the set of all files you want considered for a query have embeddings generated via the same model. For now, **do not**
 set `VERTEX_MULTIMODAL` as an `embedding_model`. This model is used automatically by Carbon when it detects an image file.
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
 upload_text_response = carbon.files.upload_text(
-    contents="string_example",
+    contents="aaaaa",
     name="string_example",
     chunk_size=1,
     chunk_overlap=1,
     skip_embedding_generation=False,
     overwrite_file_id=1,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
@@ -1278,21 +1339,25 @@
         "chunk_overlap": 20,
         "skip_embedding_generation": False,
         "embedding_model": "OPENAI",
         "generate_sparse_vectors": False,
         "prepend_filename_to_chunks": False,
         "sync_files_on_connection": True,
         "set_page_as_boundary": False,
+        "request_id": "f5552316-5da3-46e6-ad9f-2f94e30d02cd",
+        "enable_file_picker": True,
+        "sync_source_items": True,
+        "incremental_sync": False,
     },
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
-##### authentication: Union[`OAuthAuthentication`, `NotionAuthentication`, `SharepointAuthentication`, `ConfluenceAuthentication`, `ZendeskAuthentication`, `ZoteroAuthentication`, `GitbookAuthetication`, `SalesforceAuthentication`, `FreskdeskAuthentication`, `S3Authentication`]<a id="authentication-unionoauthauthentication-notionauthentication-sharepointauthentication-confluenceauthentication-zendeskauthentication-zoteroauthentication-gitbookauthetication-salesforceauthentication-freskdeskauthentication-s3authentication"></a>
+##### authentication: Union[`OAuthAuthentication`, `NotionAuthentication`, `SharepointAuthentication`, `ConfluenceAuthentication`, `ZendeskAuthentication`, `ZoteroAuthentication`, `GitbookAuthetication`, `SalesforceAuthentication`, `FreskdeskAuthentication`, `S3Authentication`, `GithubAuthentication`]<a id="authentication-unionoauthauthentication-notionauthentication-sharepointauthentication-confluenceauthentication-zendeskauthentication-zoteroauthentication-gitbookauthetication-salesforceauthentication-freskdeskauthentication-s3authentication-githubauthentication"></a>
 
 
 ##### sync_options: [`SyncOptions`](./carbon/type/sync_options.py)<a id="sync_options-syncoptionscarbontypesync_optionspy"></a>
 
 
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
@@ -1327,14 +1392,21 @@
     chunk_size=1500,
     chunk_overlap=20,
     skip_embedding_generation=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
     sync_files_on_connection=True,
+    request_id="string_example",
+    sync_source_items=True,
+    file_sync_config={
+        "auto_synced_source_types": ["ARTICLE"],
+        "sync_attachments": False,
+        "detect_audio_language": False,
+    },
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### domain: `str`<a id="domain-str"></a>
 
@@ -1352,14 +1424,23 @@
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
 ##### sync_files_on_connection: `Optional[bool]`<a id="sync_files_on_connection-optionalbool"></a>
 
+##### request_id: `Optional[str]`<a id="request_id-optionalstr"></a>
+
+##### sync_source_items: `bool`<a id="sync_source_items-bool"></a>
+
+Enabling this flag will fetch all available content from the source to be listed via list items endpoint
+
+##### file_sync_config: [`FileSyncConfigNullable`](./carbon/type/file_sync_config_nullable.py)<a id="file_sync_config-filesyncconfignullablecarbontypefile_sync_config_nullablepy"></a>
+
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`FreshDeskConnectRequest`](./carbon/type/fresh_desk_connect_request.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
 
@@ -1388,14 +1469,16 @@
     chunk_size=1500,
     chunk_overlap=20,
     skip_embedding_generation=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
     sync_files_on_connection=True,
+    request_id="string_example",
+    sync_source_items=True,
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### organization: `str`<a id="organization-str"></a>
 
@@ -1413,14 +1496,20 @@
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
 ##### sync_files_on_connection: `Optional[bool]`<a id="sync_files_on_connection-optionalbool"></a>
 
+##### request_id: `Optional[str]`<a id="request_id-optionalstr"></a>
+
+##### sync_source_items: `bool`<a id="sync_source_items-bool"></a>
+
+Enabling this flag will fetch all available content from the source to be listed via list items endpoint
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`GitbookConnectRequest`](./carbon/type/gitbook_connect_request.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
 
@@ -1444,23 +1533,28 @@
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
 create_aws_iam_user_response = carbon.integrations.create_aws_iam_user(
     access_key="string_example",
     access_key_secret="string_example",
+    sync_source_items=True,
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### access_key: `str`<a id="access_key-str"></a>
 
 ##### access_key_secret: `str`<a id="access_key_secret-str"></a>
 
+##### sync_source_items: `bool`<a id="sync_source_items-bool"></a>
+
+Enabling this flag will fetch all available content from the source to be listed via list items endpoint
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`S3AuthRequest`](./carbon/type/s3_auth_request.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`OrganizationUserDataSourceAPI`](./carbon/pydantic/organization_user_data_source_api.py)
 
@@ -1498,14 +1592,25 @@
     prepend_filename_to_chunks=False,
     max_items_per_chunk=1,
     salesforce_domain="string_example",
     sync_files_on_connection=True,
     set_page_as_boundary=False,
     data_source_id=1,
     connecting_new_account=False,
+    request_id="273420dd-e05c-463f-a3cf-0ff28029639e",
+    use_ocr=False,
+    parse_pdf_tables_with_ocr=False,
+    enable_file_picker=True,
+    sync_source_items=True,
+    incremental_sync=False,
+    file_sync_config={
+        "auto_synced_source_types": ["ARTICLE"],
+        "sync_attachments": False,
+        "detect_audio_language": False,
+    },
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### service: [`DataSourceType`](./carbon/type/data_source_type.py)<a id="service-datasourcetypecarbontypedata_source_typepy"></a>
 
@@ -1531,14 +1636,16 @@
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
 ##### max_items_per_chunk: `Optional[int]`<a id="max_items_per_chunk-optionalint"></a>
 
+Number of objects per chunk. For csv, tsv, xlsx, and json files only.
+
 ##### salesforce_domain: `Optional[str]`<a id="salesforce_domain-optionalstr"></a>
 
 ##### sync_files_on_connection: `Optional[bool]`<a id="sync_files_on_connection-optionalbool"></a>
 
 Used to specify whether Carbon should attempt to sync all your files automatically when authorization         is complete. This is only supported for a subset of connectors and will be ignored for the rest. Supported         connectors: Intercom, Zendesk, Gitbook, Confluence, Salesforce, Freshdesk
 
 ##### set_page_as_boundary: `bool`<a id="set_page_as_boundary-bool"></a>
@@ -1547,14 +1654,39 @@
 
 Used to specify a data source to sync from if you have multiple connected. It can be skipped if          you only have one data source of that type connected or are connecting a new account.
 
 ##### connecting_new_account: `Optional[bool]`<a id="connecting_new_account-optionalbool"></a>
 
 Used to connect a new data source. If not specified, we will attempt to create a sync URL         for an existing data source based on type and ID.
 
+##### request_id: `str`<a id="request_id-str"></a>
+
+This request id will be added to all files that get synced using the generated OAuth URL
+
+##### use_ocr: `Optional[bool]`<a id="use_ocr-optionalbool"></a>
+
+Enable OCR for files that support it. Supported formats: pdf
+
+##### parse_pdf_tables_with_ocr: `Optional[bool]`<a id="parse_pdf_tables_with_ocr-optionalbool"></a>
+
+##### enable_file_picker: `bool`<a id="enable_file_picker-bool"></a>
+
+Enable integration's file picker for sources that support it. Supported sources: SHAREPOINT, DROPBOX, GOOGLE_DRIVE, BOX, ONEDRIVE
+
+##### sync_source_items: `bool`<a id="sync_source_items-bool"></a>
+
+Enabling this flag will fetch all available content from the source to be listed via list items endpoint
+
+##### incremental_sync: `bool`<a id="incremental_sync-bool"></a>
+
+Only sync files if they have not already been synced or if the embedding properties have changed.         This flag is currently supported by ONEDRIVE, GOOGLE_DRIVE, BOX, DROPBOX. It will be ignored for other data sources.
+
+##### file_sync_config: [`FileSyncConfigNullable`](./carbon/type/file_sync_config_nullable.py)<a id="file_sync_config-filesyncconfignullablecarbontypefile_sync_config_nullablepy"></a>
+
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`OAuthURLRequest`](./carbon/type/o_auth_url_request.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`OuthURLResponse`](./carbon/pydantic/outh_url_response.py)
 
@@ -1612,30 +1744,40 @@
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
 list_data_source_items_response = carbon.integrations.list_data_source_items(
     data_source_id=1,
     parent_id="string_example",
+    filters={},
     pagination={
         "limit": 10,
         "offset": 0,
     },
+    order_by="name",
+    order_dir="asc",
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### data_source_id: `int`<a id="data_source_id-int"></a>
 
 ##### parent_id: `Optional[str]`<a id="parent_id-optionalstr"></a>
 
+##### filters: [`ListItemsFiltersNullable`](./carbon/type/list_items_filters_nullable.py)<a id="filters-listitemsfiltersnullablecarbontypelist_items_filters_nullablepy"></a>
+
+
 ##### pagination: [`Pagination`](./carbon/type/pagination.py)<a id="pagination-paginationcarbontypepaginationpy"></a>
 
 
+##### order_by: [`ExternalSourceItemsOrderBy`](./carbon/type/external_source_items_order_by.py)<a id="order_by-externalsourceitemsorderbycarbontypeexternal_source_items_order_bypy"></a>
+
+##### order_dir: [`OrderDirV2`](./carbon/type/order_dir_v2.py)<a id="order_dir-orderdirv2carbontypeorder_dir_v2py"></a>
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`ListDataSourceItemsRequest`](./carbon/type/list_data_source_items_request.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`ListDataSourceItemsResponse`](./carbon/pydantic/list_data_source_items_response.py)
 
@@ -1742,14 +1884,45 @@
 
 `/integrations/outlook/user_categories` `get`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
+### `carbon.integrations.list_repos`<a id="carbonintegrationslist_repos"></a>
+
+Once you have connected your GitHub account, you can use this endpoint to list the 
+    repositories your account has access to. You can use a data source ID or username to fetch from a specific account.
+
+#### 🛠️ Usage<a id="🛠️-usage"></a>
+
+```python
+list_repos_response = carbon.integrations.list_repos(
+    per_page=30,
+    page=1,
+    data_source_id=1,
+)
+```
+
+#### ⚙️ Parameters<a id="⚙️-parameters"></a>
+
+##### per_page: `int`<a id="per_page-int"></a>
+
+##### page: `int`<a id="page-int"></a>
+
+##### data_source_id: `Optional[int]`<a id="data_source_id-optionalint"></a>
+
+#### 🌐 Endpoint<a id="🌐-endpoint"></a>
+
+`/integrations/github/repos` `get`
+
+[🔙 **Back to Table of Contents**](#table-of-contents)
+
+---
+
 ### `carbon.integrations.sync_confluence`<a id="carbonintegrationssync_confluence"></a>
 
 After listing pages in a user's Confluence account, the set of selected page `ids` and the
 connected account's `data_source_id` can be passed into this endpoint to sync them into
 Carbon. Additional parameters listed below can be used to associate data to the selected
 pages or alter the behavior of the sync.
 
@@ -1764,14 +1937,23 @@
     chunk_overlap=20,
     skip_embedding_generation=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
     max_items_per_chunk=1,
     set_page_as_boundary=False,
+    request_id="2782cb96-1bf6-452c-a8d9-60c2378fd079",
+    use_ocr=False,
+    parse_pdf_tables_with_ocr=False,
+    incremental_sync=False,
+    file_sync_config={
+        "auto_synced_source_types": ["ARTICLE"],
+        "sync_attachments": False,
+        "detect_audio_language": False,
+    },
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### data_source_id: `int`<a id="data_source_id-int"></a>
 
@@ -1790,16 +1972,31 @@
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
 ##### max_items_per_chunk: `Optional[int]`<a id="max_items_per_chunk-optionalint"></a>
 
+Number of objects per chunk. For csv, tsv, xlsx, and json files only.
+
 ##### set_page_as_boundary: `bool`<a id="set_page_as_boundary-bool"></a>
 
+##### request_id: `str`<a id="request_id-str"></a>
+
+##### use_ocr: `Optional[bool]`<a id="use_ocr-optionalbool"></a>
+
+##### parse_pdf_tables_with_ocr: `Optional[bool]`<a id="parse_pdf_tables_with_ocr-optionalbool"></a>
+
+##### incremental_sync: `bool`<a id="incremental_sync-bool"></a>
+
+Only sync files if they have not already been synced or if the embedding properties have changed.         This flag is currently supported by ONEDRIVE, GOOGLE_DRIVE, BOX, DROPBOX. It will be ignored for other data sources.
+
+##### file_sync_config: [`FileSyncConfigNullable`](./carbon/type/file_sync_config_nullable.py)<a id="file_sync_config-filesyncconfignullablecarbontypefile_sync_config_nullablepy"></a>
+
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`SyncFilesRequest`](./carbon/type/sync_files_request.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
 
@@ -1860,14 +2057,23 @@
     chunk_overlap=20,
     skip_embedding_generation=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
     max_items_per_chunk=1,
     set_page_as_boundary=False,
+    request_id="2782cb96-1bf6-452c-a8d9-60c2378fd079",
+    use_ocr=False,
+    parse_pdf_tables_with_ocr=False,
+    incremental_sync=False,
+    file_sync_config={
+        "auto_synced_source_types": ["ARTICLE"],
+        "sync_attachments": False,
+        "detect_audio_language": False,
+    },
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### data_source_id: `int`<a id="data_source_id-int"></a>
 
@@ -1886,16 +2092,31 @@
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
 ##### max_items_per_chunk: `Optional[int]`<a id="max_items_per_chunk-optionalint"></a>
 
+Number of objects per chunk. For csv, tsv, xlsx, and json files only.
+
 ##### set_page_as_boundary: `bool`<a id="set_page_as_boundary-bool"></a>
 
+##### request_id: `str`<a id="request_id-str"></a>
+
+##### use_ocr: `Optional[bool]`<a id="use_ocr-optionalbool"></a>
+
+##### parse_pdf_tables_with_ocr: `Optional[bool]`<a id="parse_pdf_tables_with_ocr-optionalbool"></a>
+
+##### incremental_sync: `bool`<a id="incremental_sync-bool"></a>
+
+Only sync files if they have not already been synced or if the embedding properties have changed.         This flag is currently supported by ONEDRIVE, GOOGLE_DRIVE, BOX, DROPBOX. It will be ignored for other data sources.
+
+##### file_sync_config: [`FileSyncConfigNullable`](./carbon/type/file_sync_config_nullable.py)<a id="file_sync_config-filesyncconfignullablecarbontypefile_sync_config_nullablepy"></a>
+
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`SyncFilesRequest`](./carbon/type/sync_files_request.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
 
@@ -1903,14 +2124,55 @@
 
 `/integrations/files/sync` `post`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
+### `carbon.integrations.sync_git_hub`<a id="carbonintegrationssync_git_hub"></a>
+
+Refer this article to obtain an access token https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens.
+Make sure that your access token has the permission to read content from your desired repos. Note that if your access token
+expires you will need to manually update it through this endpoint.
+
+#### 🛠️ Usage<a id="🛠️-usage"></a>
+
+```python
+sync_git_hub_response = carbon.integrations.sync_git_hub(
+    username="string_example",
+    access_token="string_example",
+    sync_source_items=False,
+)
+```
+
+#### ⚙️ Parameters<a id="⚙️-parameters"></a>
+
+##### username: `str`<a id="username-str"></a>
+
+##### access_token: `str`<a id="access_token-str"></a>
+
+##### sync_source_items: `bool`<a id="sync_source_items-bool"></a>
+
+Enabling this flag will fetch all available content from the source to be listed via list items endpoint
+
+#### ⚙️ Request Body<a id="⚙️-request-body"></a>
+
+[`GithubConnectRequest`](./carbon/type/github_connect_request.py)
+#### 🔄 Return<a id="🔄-return"></a>
+
+[`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
+
+#### 🌐 Endpoint<a id="🌐-endpoint"></a>
+
+`/integrations/github` `post`
+
+[🔙 **Back to Table of Contents**](#table-of-contents)
+
+---
+
 ### `carbon.integrations.sync_gitbook`<a id="carbonintegrationssync_gitbook"></a>
 
 You can sync upto 20 Gitbook spaces at a time using this endpoint. Additional parameters below can be used to associate 
 data with the synced pages or modify the sync behavior.
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
@@ -1921,14 +2183,15 @@
     tags={},
     chunk_size=1500,
     chunk_overlap=20,
     skip_embedding_generation=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
+    request_id="string_example",
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### space_ids: [`GitbookSyncRequestSpaceIds`](./carbon/type/gitbook_sync_request_space_ids.py)<a id="space_ids-gitbooksyncrequestspaceidscarbontypegitbook_sync_request_space_idspy"></a>
 
@@ -1944,14 +2207,16 @@
 
 ##### embedding_model: [`EmbeddingGenerators`](./carbon/type/embedding_generators.py)<a id="embedding_model-embeddinggeneratorscarbontypeembedding_generatorspy"></a>
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
+##### request_id: `Optional[str]`<a id="request_id-optionalstr"></a>
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`GitbookSyncRequest`](./carbon/type/gitbook_sync_request.py)
 #### 🌐 Endpoint<a id="🌐-endpoint"></a>
 
 `/integrations/gitbook/sync` `post`
 
@@ -2021,14 +2286,22 @@
     chunk_size=1500,
     chunk_overlap=20,
     skip_embedding_generation=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
     data_source_id=1,
+    request_id="string_example",
+    sync_attachments=False,
+    file_sync_config={
+        "auto_synced_source_types": ["ARTICLE"],
+        "sync_attachments": False,
+        "detect_audio_language": False,
+    },
+    incremental_sync=False,
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### filters: `Dict[str, Union[bool, date, datetime, dict, float, int, list, str, None]]`<a id="filters-dictstr-unionbool-date-datetime-dict-float-int-list-str-none"></a>
 
@@ -2044,14 +2317,23 @@
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
 ##### data_source_id: `Optional[int]`<a id="data_source_id-optionalint"></a>
 
+##### request_id: `Optional[str]`<a id="request_id-optionalstr"></a>
+
+##### sync_attachments: `Optional[bool]`<a id="sync_attachments-optionalbool"></a>
+
+##### file_sync_config: [`FileSyncConfigNullable`](./carbon/type/file_sync_config_nullable.py)<a id="file_sync_config-filesyncconfignullablecarbontypefile_sync_config_nullablepy"></a>
+
+
+##### incremental_sync: `bool`<a id="incremental_sync-bool"></a>
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`GmailSyncInput`](./carbon/type/gmail_sync_input.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
 
@@ -2136,14 +2418,22 @@
     chunk_size=1500,
     chunk_overlap=20,
     skip_embedding_generation=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
     data_source_id=1,
+    request_id="string_example",
+    sync_attachments=False,
+    file_sync_config={
+        "auto_synced_source_types": ["ARTICLE"],
+        "sync_attachments": False,
+        "detect_audio_language": False,
+    },
+    incremental_sync=False,
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### filters: `Dict[str, Union[bool, date, datetime, dict, float, int, list, str, None]]`<a id="filters-dictstr-unionbool-date-datetime-dict-float-int-list-str-none"></a>
 
@@ -2161,14 +2451,23 @@
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
 ##### data_source_id: `Optional[int]`<a id="data_source_id-optionalint"></a>
 
+##### request_id: `Optional[str]`<a id="request_id-optionalstr"></a>
+
+##### sync_attachments: `Optional[bool]`<a id="sync_attachments-optionalbool"></a>
+
+##### file_sync_config: [`FileSyncConfigNullable`](./carbon/type/file_sync_config_nullable.py)<a id="file_sync_config-filesyncconfignullablecarbontypefile_sync_config_nullablepy"></a>
+
+
+##### incremental_sync: `bool`<a id="incremental_sync-bool"></a>
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`OutlookSyncInput`](./carbon/type/outlook_sync_input.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
 
@@ -2176,14 +2475,46 @@
 
 `/integrations/outlook/sync` `post`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
+### `carbon.integrations.sync_repos`<a id="carbonintegrationssync_repos"></a>
+
+You can retreive repos your token has access to using /integrations/github/repos and sync their content. 
+You can also pass full name of any public repository (username/repo-name). This will store the repo content with 
+carbon which can be accessed through /integrations/items/list endpoint. Maximum of 25 repositories are accepted per request.
+
+#### 🛠️ Usage<a id="🛠️-usage"></a>
+
+```python
+sync_repos_response = carbon.integrations.sync_repos(
+    repos=["string_example"],
+    data_source_id=1,
+)
+```
+
+#### ⚙️ Parameters<a id="⚙️-parameters"></a>
+
+##### repos: [`GithubFetchReposRequestRepos`](./carbon/type/github_fetch_repos_request_repos.py)<a id="repos-githubfetchreposrequestreposcarbontypegithub_fetch_repos_request_repospy"></a>
+
+##### data_source_id: `Optional[int]`<a id="data_source_id-optionalint"></a>
+
+#### ⚙️ Request Body<a id="⚙️-request-body"></a>
+
+[`GithubFetchReposRequest`](./carbon/type/github_fetch_repos_request.py)
+#### 🌐 Endpoint<a id="🌐-endpoint"></a>
+
+`/integrations/github/sync_repos` `post`
+
+[🔙 **Back to Table of Contents**](#table-of-contents)
+
+---
+
 ### `carbon.integrations.sync_rss_feed`<a id="carbonintegrationssync_rss_feed"></a>
 
 Rss Feed
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
@@ -2192,14 +2523,15 @@
     tags={},
     chunk_size=1500,
     chunk_overlap=20,
     skip_embedding_generation=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
+    request_id="string_example",
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### url: `str`<a id="url-str"></a>
 
@@ -2213,14 +2545,16 @@
 
 ##### embedding_model: [`EmbeddingGenerators`](./carbon/type/embedding_generators.py)<a id="embedding_model-embeddinggeneratorscarbontypeembedding_generatorspy"></a>
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
+##### request_id: `Optional[str]`<a id="request_id-optionalstr"></a>
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`RSSFeedInput`](./carbon/type/rss_feed_input.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
 
@@ -2249,14 +2583,22 @@
     skip_embedding_generation=False,
     embedding_model="OPENAI",
     generate_sparse_vectors=False,
     prepend_filename_to_chunks=False,
     max_items_per_chunk=1,
     set_page_as_boundary=False,
     data_source_id=1,
+    request_id="string_example",
+    use_ocr=False,
+    parse_pdf_tables_with_ocr=False,
+    file_sync_config={
+        "auto_synced_source_types": ["ARTICLE"],
+        "sync_attachments": False,
+        "detect_audio_language": False,
+    },
 )
 ```
 
 #### ⚙️ Parameters<a id="⚙️-parameters"></a>
 
 ##### ids: List[`S3GetFileInput`]<a id="ids-lists3getfileinput"></a>
 
@@ -2272,18 +2614,29 @@
 
 ##### generate_sparse_vectors: `Optional[bool]`<a id="generate_sparse_vectors-optionalbool"></a>
 
 ##### prepend_filename_to_chunks: `Optional[bool]`<a id="prepend_filename_to_chunks-optionalbool"></a>
 
 ##### max_items_per_chunk: `Optional[int]`<a id="max_items_per_chunk-optionalint"></a>
 
+Number of objects per chunk. For csv, tsv, xlsx, and json files only.
+
 ##### set_page_as_boundary: `bool`<a id="set_page_as_boundary-bool"></a>
 
 ##### data_source_id: `Optional[int]`<a id="data_source_id-optionalint"></a>
 
+##### request_id: `Optional[str]`<a id="request_id-optionalstr"></a>
+
+##### use_ocr: `Optional[bool]`<a id="use_ocr-optionalbool"></a>
+
+##### parse_pdf_tables_with_ocr: `Optional[bool]`<a id="parse_pdf_tables_with_ocr-optionalbool"></a>
+
+##### file_sync_config: [`FileSyncConfigNullable`](./carbon/type/file_sync_config_nullable.py)<a id="file_sync_config-filesyncconfignullablecarbontypefile_sync_config_nullablepy"></a>
+
+
 #### ⚙️ Request Body<a id="⚙️-request-body"></a>
 
 [`S3FileSyncInput`](./carbon/type/s3_file_sync_input.py)
 #### 🔄 Return<a id="🔄-return"></a>
 
 [`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
 
@@ -2313,14 +2666,71 @@
 
 `/organization` `get`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
+### `carbon.organizations.update`<a id="carbonorganizationsupdate"></a>
+
+Update Organization
+
+#### 🛠️ Usage<a id="🛠️-usage"></a>
+
+```python
+update_response = carbon.organizations.update(
+    global_user_config={},
+)
+```
+
+#### ⚙️ Parameters<a id="⚙️-parameters"></a>
+
+##### global_user_config: [`UserConfigurationNullable`](./carbon/type/user_configuration_nullable.py)<a id="global_user_config-userconfigurationnullablecarbontypeuser_configuration_nullablepy"></a>
+
+
+#### ⚙️ Request Body<a id="⚙️-request-body"></a>
+
+[`UpdateOrganizationInput`](./carbon/type/update_organization_input.py)
+#### 🔄 Return<a id="🔄-return"></a>
+
+[`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
+
+#### 🌐 Endpoint<a id="🌐-endpoint"></a>
+
+`/organization/update` `post`
+
+[🔙 **Back to Table of Contents**](#table-of-contents)
+
+---
+
+### `carbon.organizations.update_stats`<a id="carbonorganizationsupdate_stats"></a>
+
+Use this endpoint to reaggregate the statistics for an organization, for example aggregate_file_size. The reaggregation
+process is asyncronous so a webhook will be sent with the event type being FILE_STATISTICS_AGGREGATED to notify when the
+process is complee. After this aggregation is complete, the updated statistics can be retrieved using the /organization
+endpoint. The response of /organization willalso contain a timestamp of the last time the statistics were reaggregated.
+
+#### 🛠️ Usage<a id="🛠️-usage"></a>
+
+```python
+update_stats_response = carbon.organizations.update_stats()
+```
+
+#### 🔄 Return<a id="🔄-return"></a>
+
+[`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
+
+#### 🌐 Endpoint<a id="🌐-endpoint"></a>
+
+`/organization/statistics` `post`
+
+[🔙 **Back to Table of Contents**](#table-of-contents)
+
+---
+
 ### `carbon.users.delete`<a id="carbonusersdelete"></a>
 
 Delete Users
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
@@ -2376,14 +2786,15 @@
 `/user` `post`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
 ### `carbon.users.toggle_user_features`<a id="carbonuserstoggle_user_features"></a>
+![Deprecated](https://img.shields.io/badge/deprecated-yellow)
 
 Toggle User Features
 
 #### 🛠️ Usage<a id="🛠️-usage"></a>
 
 ```python
 toggle_user_features_response = carbon.users.toggle_user_features(
@@ -2409,14 +2820,61 @@
 
 `/modify_user_configuration` `post`
 
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
+### `carbon.users.update_users`<a id="carbonusersupdate_users"></a>
+
+Update Users
+
+#### 🛠️ Usage<a id="🛠️-usage"></a>
+
+```python
+update_users_response = carbon.users.update_users(
+    customer_ids=["string_example"],
+    auto_sync_enabled_sources=["string_example"],
+    max_files=-1,
+    max_files_per_upload=-1,
+)
+```
+
+#### ⚙️ Parameters<a id="⚙️-parameters"></a>
+
+##### customer_ids: [`UpdateUsersInputCustomerIds`](./carbon/type/update_users_input_customer_ids.py)<a id="customer_ids-updateusersinputcustomeridscarbontypeupdate_users_input_customer_idspy"></a>
+
+##### auto_sync_enabled_sources: Union[List[[`DataSourceType`](./carbon/type/data_source_type.py)], `str`]<a id="auto_sync_enabled_sources-unionlistdatasourcetypecarbontypedata_source_typepy-str"></a>
+
+
+List of data source types to enable auto sync for. Empty array will remove all sources          and the string \\\"ALL\\\" will enable it for all data sources
+
+##### max_files: `Optional[int]`<a id="max_files-optionalint"></a>
+
+Custom file upload limit for the user over *all* user's files across all uploads.          If set, then the user will not be allowed to upload more files than this limit. If not set, or if set to -1,         then the user will have no limit.
+
+##### max_files_per_upload: `Optional[int]`<a id="max_files_per_upload-optionalint"></a>
+
+Custom file upload limit for the user across a single upload.         If set, then the user will not be allowed to upload more files than this limit in a single upload. If not set,         or if set to -1, then the user will have no limit.
+
+#### ⚙️ Request Body<a id="⚙️-request-body"></a>
+
+[`UpdateUsersInput`](./carbon/type/update_users_input.py)
+#### 🔄 Return<a id="🔄-return"></a>
+
+[`GenericSuccessResponse`](./carbon/pydantic/generic_success_response.py)
+
+#### 🌐 Endpoint<a id="🌐-endpoint"></a>
+
+`/update_users` `post`
+
+[🔙 **Back to Table of Contents**](#table-of-contents)
+
+---
+
 ### `carbon.utilities.fetch_urls`<a id="carbonutilitiesfetch_urls"></a>
 
 Extracts all URLs from a webpage. 
 
 Args:
     url (str): URL of the webpage
 
@@ -2783,8 +3241,7 @@
 [🔙 **Back to Table of Contents**](#table-of-contents)
 
 ---
 
 
 ## Author<a id="author"></a>
 This Python package is automatically generated by [Konfig](https://konfigthis.com)
-
```

