# Comparing `tmp/jarvis_ironman-4.4.2-py3-none-any.whl.zip` & `tmp/jarvis_ironman-4.5-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,152 +1,153 @@
-Zip file size: 3300856 bytes, number of entries: 150
--rw-r--r--  2.0 unx      839 b- defN 24-Feb-03 06:06 jarvis/__init__.py
--rw-r--r--  2.0 unx     9388 b- defN 24-Feb-03 06:06 jarvis/main.py
--rw-r--r--  2.0 unx     2781 b- defN 24-Feb-03 06:06 jarvis/_preexec/keywords_handler.py
--rw-r--r--  2.0 unx     1173 b- defN 24-Feb-03 06:06 jarvis/api/logger.py
--rw-r--r--  2.0 unx     3414 b- defN 24-Feb-03 06:06 jarvis/api/main.py
--rw-r--r--  2.0 unx     2272 b- defN 24-Feb-03 06:06 jarvis/api/server.py
--rw-r--r--  2.0 unx     2388 b- defN 24-Feb-03 06:06 jarvis/api/models/authenticator.py
--rw-r--r--  2.0 unx     1193 b- defN 24-Feb-03 06:06 jarvis/api/models/modals.py
--rw-r--r--  2.0 unx     2784 b- defN 24-Feb-03 06:06 jarvis/api/models/settings.py
--rw-r--r--  2.0 unx     1938 b- defN 24-Feb-03 06:06 jarvis/api/routers/basics.py
--rw-r--r--  2.0 unx    15406 b- defN 24-Feb-03 06:06 jarvis/api/routers/favicon.ico
--rw-r--r--  2.0 unx     3438 b- defN 24-Feb-03 06:06 jarvis/api/routers/fileio.py
--rw-r--r--  2.0 unx     5907 b- defN 24-Feb-03 06:06 jarvis/api/routers/investment.py
--rw-r--r--  2.0 unx     7913 b- defN 24-Feb-03 06:06 jarvis/api/routers/offline.py
--rw-r--r--  2.0 unx     2176 b- defN 24-Feb-03 06:06 jarvis/api/routers/secure_send.py
--rw-r--r--  2.0 unx     4294 b- defN 24-Feb-03 06:06 jarvis/api/routers/speech_synthesis.py
--rw-r--r--  2.0 unx     6672 b- defN 24-Feb-03 06:06 jarvis/api/routers/stock_analysis.py
--rw-r--r--  2.0 unx    13660 b- defN 24-Feb-03 06:06 jarvis/api/routers/stock_monitor.py
--rw-r--r--  2.0 unx    12313 b- defN 24-Feb-03 06:06 jarvis/api/routers/surveillance.py
--rw-r--r--  2.0 unx     2131 b- defN 24-Feb-03 06:06 jarvis/api/routers/telegram.py
--rw-r--r--  2.0 unx     2792 b- defN 24-Feb-03 06:06 jarvis/api/squire/discover.py
--rw-r--r--  2.0 unx     2722 b- defN 24-Feb-03 06:06 jarvis/api/squire/scheduler.py
--rw-r--r--  2.0 unx     4134 b- defN 24-Feb-03 06:06 jarvis/api/squire/stockanalysis_squire.py
--rw-r--r--  2.0 unx     4243 b- defN 24-Feb-03 06:06 jarvis/api/squire/stockmonitor_squire.py
--rw-r--r--  2.0 unx     5375 b- defN 24-Feb-03 06:06 jarvis/api/squire/surveillance_squire.py
--rw-r--r--  2.0 unx      647 b- defN 24-Feb-03 06:06 jarvis/api/squire/timeout_otp.py
--rw-r--r--  2.0 unx    13533 b- defN 24-Feb-03 06:06 jarvis/api/triggers/stock_monitor.py
--rw-r--r--  2.0 unx    11567 b- defN 24-Feb-03 06:06 jarvis/api/triggers/stock_report.py
--rw-r--r--  2.0 unx    13780 b- defN 24-Feb-03 06:06 jarvis/executors/alarm.py
--rw-r--r--  2.0 unx     6955 b- defN 24-Feb-03 06:06 jarvis/executors/automation.py
--rw-r--r--  2.0 unx     5617 b- defN 24-Feb-03 06:06 jarvis/executors/background_task.py
--rw-r--r--  2.0 unx    25308 b- defN 24-Feb-03 06:06 jarvis/executors/car.py
--rw-r--r--  2.0 unx     9157 b- defN 24-Feb-03 06:06 jarvis/executors/comm_squire.py
--rw-r--r--  2.0 unx     6159 b- defN 24-Feb-03 06:06 jarvis/executors/commander.py
--rw-r--r--  2.0 unx     5437 b- defN 24-Feb-03 06:06 jarvis/executors/communicator.py
--rw-r--r--  2.0 unx     4919 b- defN 24-Feb-03 06:06 jarvis/executors/conditions.py
--rw-r--r--  2.0 unx     2133 b- defN 24-Feb-03 06:06 jarvis/executors/connection.py
--rw-r--r--  2.0 unx    12942 b- defN 24-Feb-03 06:06 jarvis/executors/controls.py
--rw-r--r--  2.0 unx     3440 b- defN 24-Feb-03 06:06 jarvis/executors/crontab.py
--rw-r--r--  2.0 unx     1891 b- defN 24-Feb-03 06:06 jarvis/executors/custom_conditions.py
--rw-r--r--  2.0 unx     2433 b- defN 24-Feb-03 06:06 jarvis/executors/date_time.py
--rw-r--r--  2.0 unx     1319 b- defN 24-Feb-03 06:06 jarvis/executors/display_functions.py
--rw-r--r--  2.0 unx     4220 b- defN 24-Feb-03 06:06 jarvis/executors/face.py
--rw-r--r--  2.0 unx    10545 b- defN 24-Feb-03 06:06 jarvis/executors/files.py
--rw-r--r--  2.0 unx     3654 b- defN 24-Feb-03 06:06 jarvis/executors/functions.py
--rw-r--r--  2.0 unx     4014 b- defN 24-Feb-03 06:06 jarvis/executors/github.py
--rw-r--r--  2.0 unx    10561 b- defN 24-Feb-03 06:06 jarvis/executors/guard.py
--rw-r--r--  2.0 unx     8101 b- defN 24-Feb-03 06:06 jarvis/executors/internet.py
--rw-r--r--  2.0 unx     6207 b- defN 24-Feb-03 06:06 jarvis/executors/ios_functions.py
--rw-r--r--  2.0 unx    10738 b- defN 24-Feb-03 06:06 jarvis/executors/lights.py
--rw-r--r--  2.0 unx     5146 b- defN 24-Feb-03 06:06 jarvis/executors/lights_squire.py
--rw-r--r--  2.0 unx     2545 b- defN 24-Feb-03 06:06 jarvis/executors/listener_controls.py
--rw-r--r--  2.0 unx    13439 b- defN 24-Feb-03 06:06 jarvis/executors/location.py
--rw-r--r--  2.0 unx      596 b- defN 24-Feb-03 06:06 jarvis/executors/method.py
--rw-r--r--  2.0 unx    13082 b- defN 24-Feb-03 06:06 jarvis/executors/offline.py
--rw-r--r--  2.0 unx    23672 b- defN 24-Feb-03 06:06 jarvis/executors/others.py
--rw-r--r--  2.0 unx     2864 b- defN 24-Feb-03 06:06 jarvis/executors/port_handler.py
--rw-r--r--  2.0 unx     2358 b- defN 24-Feb-03 06:06 jarvis/executors/process_map.py
--rw-r--r--  2.0 unx     7644 b- defN 24-Feb-03 06:06 jarvis/executors/processor.py
--rw-r--r--  2.0 unx    10188 b- defN 24-Feb-03 06:06 jarvis/executors/remind.py
--rw-r--r--  2.0 unx     3967 b- defN 24-Feb-03 06:06 jarvis/executors/restrictions.py
--rw-r--r--  2.0 unx     3264 b- defN 24-Feb-03 06:06 jarvis/executors/robinhood.py
--rw-r--r--  2.0 unx     3548 b- defN 24-Feb-03 06:06 jarvis/executors/simulator.py
--rw-r--r--  2.0 unx     3918 b- defN 24-Feb-03 06:06 jarvis/executors/static_responses.py
--rw-r--r--  2.0 unx     8338 b- defN 24-Feb-03 06:06 jarvis/executors/system.py
--rw-r--r--  2.0 unx     3281 b- defN 24-Feb-03 06:06 jarvis/executors/telegram.py
--rw-r--r--  2.0 unx     6952 b- defN 24-Feb-03 06:06 jarvis/executors/thermostat.py
--rw-r--r--  2.0 unx     5097 b- defN 24-Feb-03 06:06 jarvis/executors/todo_list.py
--rw-r--r--  2.0 unx     7382 b- defN 24-Feb-03 06:06 jarvis/executors/tv.py
--rw-r--r--  2.0 unx     7378 b- defN 24-Feb-03 06:06 jarvis/executors/tv_controls.py
--rw-r--r--  2.0 unx     4831 b- defN 24-Feb-03 06:06 jarvis/executors/unconditional.py
--rw-r--r--  2.0 unx     1910 b- defN 24-Feb-03 06:06 jarvis/executors/volume.py
--rw-r--r--  2.0 unx     6341 b- defN 24-Feb-03 06:06 jarvis/executors/vpn_server.py
--rw-r--r--  2.0 unx    10249 b- defN 24-Feb-03 06:06 jarvis/executors/weather.py
--rw-r--r--  2.0 unx     3415 b- defN 24-Feb-03 06:06 jarvis/executors/weather_monitor.py
--rw-r--r--  2.0 unx     2261 b- defN 24-Feb-03 06:06 jarvis/executors/wiki.py
--rw-r--r--  2.0 unx     1787 b- defN 24-Feb-03 06:06 jarvis/executors/word_match.py
--rw-r--r--  2.0 unx     9239 b- defN 24-Feb-03 06:06 jarvis/indicators/acknowledgement.mp3
--rw-r--r--  2.0 unx  3087321 b- defN 24-Feb-03 06:06 jarvis/indicators/alarm.mp3
--rw-r--r--  2.0 unx    17350 b- defN 24-Feb-03 06:06 jarvis/indicators/coin.mp3
--rwxr-xr-x  2.0 unx     9448 b- defN 24-Feb-03 06:06 jarvis/indicators/end.mp3
--rwxr-xr-x  2.0 unx    11538 b- defN 24-Feb-03 06:06 jarvis/indicators/start.mp3
--rwxr-xr-x  2.0 unx     8581 b- defN 24-Feb-03 06:06 jarvis/lib/install.sh
--rw-r--r--  2.0 unx      531 b- defN 24-Feb-03 06:06 jarvis/lib/version_locked_requirements.txt
--rw-r--r--  2.0 unx      515 b- defN 24-Feb-03 06:06 jarvis/lib/version_pinned_requirements.txt
--rw-r--r--  2.0 unx      107 b- defN 24-Feb-03 06:06 jarvis/lib/version_upgrade_requirements.txt
--rw-r--r--  2.0 unx     1076 b- defN 24-Feb-03 06:06 jarvis/modules/auth_bearer.py
--rw-r--r--  2.0 unx     3359 b- defN 24-Feb-03 06:06 jarvis/modules/builtin_overrides.py
--rw-r--r--  2.0 unx     3989 b- defN 24-Feb-03 06:06 jarvis/modules/exceptions.py
--rw-r--r--  2.0 unx     4828 b- defN 24-Feb-03 06:06 jarvis/modules/logger.py
--rw-r--r--  2.0 unx     1401 b- defN 24-Feb-03 06:06 jarvis/modules/peripherals.py
--rw-r--r--  2.0 unx     4336 b- defN 24-Feb-03 06:06 jarvis/modules/audio/listener.py
--rw-r--r--  2.0 unx     6049 b- defN 24-Feb-03 06:06 jarvis/modules/audio/speaker.py
--rw-r--r--  2.0 unx     9213 b- defN 24-Feb-03 06:06 jarvis/modules/audio/speech_synthesis.py
--rw-r--r--  2.0 unx     2095 b- defN 24-Feb-03 06:06 jarvis/modules/audio/tts_stt.py
--rw-r--r--  2.0 unx     2661 b- defN 24-Feb-03 06:06 jarvis/modules/audio/voices.py
--rw-r--r--  2.0 unx     7084 b- defN 24-Feb-03 06:06 jarvis/modules/camera/camera.py
--rw-r--r--  2.0 unx     9425 b- defN 24-Feb-03 06:06 jarvis/modules/car/connector.py
--rw-r--r--  2.0 unx    30541 b- defN 24-Feb-03 06:06 jarvis/modules/car/controller.py
--rw-r--r--  2.0 unx     2846 b- defN 24-Feb-03 06:06 jarvis/modules/conditions/conversation.py
--rw-r--r--  2.0 unx     5926 b- defN 24-Feb-03 06:06 jarvis/modules/conditions/keywords.py
--rw-r--r--  2.0 unx    12259 b- defN 24-Feb-03 06:06 jarvis/modules/crontab/expression.py
--rw-r--r--  2.0 unx     4189 b- defN 24-Feb-03 06:06 jarvis/modules/database/database.py
--rw-r--r--  2.0 unx     1631 b- defN 24-Feb-03 06:06 jarvis/modules/dictionary/dictionary.py
--rw-r--r--  2.0 unx     7462 b- defN 24-Feb-03 06:06 jarvis/modules/facenet/face.py
--rw-r--r--  2.0 unx      639 b- defN 24-Feb-03 06:06 jarvis/modules/lights/preset_values.py
--rw-r--r--  2.0 unx     9715 b- defN 24-Feb-03 06:06 jarvis/modules/lights/smart_lights.py
--rw-r--r--  2.0 unx     8208 b- defN 24-Feb-03 06:06 jarvis/modules/meetings/events.py
--rw-r--r--  2.0 unx     4342 b- defN 24-Feb-03 06:06 jarvis/modules/meetings/ics.py
--rw-r--r--  2.0 unx     8069 b- defN 24-Feb-03 06:06 jarvis/modules/meetings/ics_meetings.py
--rw-r--r--  2.0 unx     8190 b- defN 24-Feb-03 06:06 jarvis/modules/microphone/graph_mic.py
--rw-r--r--  2.0 unx     2812 b- defN 24-Feb-03 06:06 jarvis/modules/microphone/recognizer.py
--rw-r--r--  2.0 unx    19437 b- defN 24-Feb-03 06:06 jarvis/modules/models/classes.py
--rw-r--r--  2.0 unx    11344 b- defN 24-Feb-03 06:06 jarvis/modules/models/models.py
--rw-r--r--  2.0 unx     2920 b- defN 24-Feb-03 06:06 jarvis/modules/retry/retry.py
--rw-r--r--  2.0 unx     6325 b- defN 24-Feb-03 06:06 jarvis/modules/speaker/speak.py
--rw-r--r--  2.0 unx     2023 b- defN 24-Feb-03 06:06 jarvis/modules/telegram/audio_handler.py
--rw-r--r--  2.0 unx    26158 b- defN 24-Feb-03 06:06 jarvis/modules/telegram/bot.py
--rw-r--r--  2.0 unx     3401 b- defN 24-Feb-03 06:06 jarvis/modules/telegram/file_handler.py
--rw-r--r--  2.0 unx     1766 b- defN 24-Feb-03 06:06 jarvis/modules/telegram/settings.py
--rw-r--r--  2.0 unx     1933 b- defN 24-Feb-03 06:06 jarvis/modules/telegram/webhook.py
--rw-r--r--  2.0 unx     1616 b- defN 24-Feb-03 06:06 jarvis/modules/temperature/temperature.py
--rw-r--r--  2.0 unx     2821 b- defN 24-Feb-03 06:06 jarvis/modules/templates/car_report.html
--rw-r--r--  2.0 unx    25812 b- defN 24-Feb-03 06:06 jarvis/modules/templates/email.html
--rw-r--r--  2.0 unx     3386 b- defN 24-Feb-03 06:06 jarvis/modules/templates/email_OTP.html
--rw-r--r--  2.0 unx      412 b- defN 24-Feb-03 06:06 jarvis/modules/templates/email_stock_alert.html
--rw-r--r--  2.0 unx      128 b- defN 24-Feb-03 06:06 jarvis/modules/templates/email_threat_audio.html
--rw-r--r--  2.0 unx      136 b- defN 24-Feb-03 06:06 jarvis/modules/templates/email_threat_image.html
--rw-r--r--  2.0 unx      180 b- defN 24-Feb-03 06:06 jarvis/modules/templates/email_threat_image_audio.html
--rw-r--r--  2.0 unx     2285 b- defN 24-Feb-03 06:06 jarvis/modules/templates/robinhood.html
--rw-r--r--  2.0 unx     2370 b- defN 24-Feb-03 06:06 jarvis/modules/templates/surveillance.html
--rw-r--r--  2.0 unx     2059 b- defN 24-Feb-03 06:06 jarvis/modules/templates/templates.py
--rw-r--r--  2.0 unx      637 b- defN 24-Feb-03 06:06 jarvis/modules/templates/win_wifi_config.xml
--rw-r--r--  2.0 unx     2070 b- defN 24-Feb-03 06:06 jarvis/modules/timeout/timeout.py
--rw-r--r--  2.0 unx     7065 b- defN 24-Feb-03 06:06 jarvis/modules/transformer/gpt.py
--rw-r--r--  2.0 unx     9402 b- defN 24-Feb-03 06:06 jarvis/modules/tv/lg.py
--rw-r--r--  2.0 unx     7760 b- defN 24-Feb-03 06:06 jarvis/modules/tv/roku.py
--rw-r--r--  2.0 unx      402 b- defN 24-Feb-03 06:06 jarvis/modules/utils/shared.py
--rw-r--r--  2.0 unx    20336 b- defN 24-Feb-03 06:06 jarvis/modules/utils/support.py
--rw-r--r--  2.0 unx    10011 b- defN 24-Feb-03 06:06 jarvis/modules/utils/util.py
--rw-r--r--  2.0 unx     2137 b- defN 24-Feb-03 06:06 jarvis/modules/wakeonlan/wakeonlan.py
--rwxr-xr-x  2.0 unx     1044 b- defN 24-Feb-03 06:06 jarvis/scripts/applauncher.scpt
--rwxr-xr-x  2.0 unx     2750 b- defN 24-Feb-03 06:06 jarvis/scripts/calendar.scpt
--rwxr-xr-x  2.0 unx     2504 b- defN 24-Feb-03 06:06 jarvis/scripts/outlook.scpt
--rwxr-xr-x  2.0 unx     8581 b- defN 24-Feb-03 06:06 jarvis_ironman-4.4.2.data/scripts/install.sh
--rw-r--r--  2.0 unx     1068 b- defN 24-Feb-03 06:06 jarvis_ironman-4.4.2.dist-info/LICENSE
--rw-r--r--  2.0 unx    13561 b- defN 24-Feb-03 06:06 jarvis_ironman-4.4.2.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Feb-03 06:06 jarvis_ironman-4.4.2.dist-info/WHEEL
--rw-r--r--  2.0 unx        7 b- defN 24-Feb-03 06:06 jarvis_ironman-4.4.2.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    13334 b- defN 24-Feb-03 06:06 jarvis_ironman-4.4.2.dist-info/RECORD
-150 files, 3998324 bytes uncompressed, 3279782 bytes compressed:  18.0%
+Zip file size: 3300888 bytes, number of entries: 151
+-rw-r--r--  2.0 unx      870 b- defN 24-May-29 02:16 jarvis/__init__.py
+-rw-r--r--  2.0 unx     9688 b- defN 24-May-29 02:16 jarvis/main.py
+-rw-r--r--  2.0 unx     2929 b- defN 24-May-29 02:16 jarvis/_preexec/keywords_handler.py
+-rw-r--r--  2.0 unx     1179 b- defN 24-May-29 02:16 jarvis/api/logger.py
+-rw-r--r--  2.0 unx     3650 b- defN 24-May-29 02:16 jarvis/api/main.py
+-rw-r--r--  2.0 unx     2328 b- defN 24-May-29 02:16 jarvis/api/server.py
+-rw-r--r--  2.0 unx     2437 b- defN 24-May-29 02:16 jarvis/api/models/authenticator.py
+-rw-r--r--  2.0 unx     1156 b- defN 24-May-12 19:32 jarvis/api/models/modals.py
+-rw-r--r--  2.0 unx     2902 b- defN 24-May-29 02:16 jarvis/api/models/settings.py
+-rw-r--r--  2.0 unx     1999 b- defN 24-May-29 02:16 jarvis/api/routers/basics.py
+-rw-r--r--  2.0 unx    15406 b- defN 24-May-12 00:54 jarvis/api/routers/favicon.ico
+-rw-r--r--  2.0 unx     3800 b- defN 24-May-29 02:16 jarvis/api/routers/fileio.py
+-rw-r--r--  2.0 unx     5964 b- defN 24-May-29 02:16 jarvis/api/routers/investment.py
+-rw-r--r--  2.0 unx     8386 b- defN 24-May-29 02:16 jarvis/api/routers/offline.py
+-rw-r--r--  2.0 unx     2050 b- defN 24-May-29 02:16 jarvis/api/routers/proxy_service.py
+-rw-r--r--  2.0 unx     2366 b- defN 24-May-29 02:16 jarvis/api/routers/secure_send.py
+-rw-r--r--  2.0 unx     4558 b- defN 24-May-29 02:16 jarvis/api/routers/speech_synthesis.py
+-rw-r--r--  2.0 unx     6994 b- defN 24-May-29 02:16 jarvis/api/routers/stock_analysis.py
+-rw-r--r--  2.0 unx    14288 b- defN 24-May-29 02:16 jarvis/api/routers/stock_monitor.py
+-rw-r--r--  2.0 unx    12566 b- defN 24-May-29 02:16 jarvis/api/routers/surveillance.py
+-rw-r--r--  2.0 unx     2261 b- defN 24-May-29 02:16 jarvis/api/routers/telegram.py
+-rw-r--r--  2.0 unx     2966 b- defN 24-May-29 02:16 jarvis/api/squire/discover.py
+-rw-r--r--  2.0 unx     2818 b- defN 24-May-29 02:16 jarvis/api/squire/scheduler.py
+-rw-r--r--  2.0 unx     4432 b- defN 24-May-29 02:16 jarvis/api/squire/stockanalysis_squire.py
+-rw-r--r--  2.0 unx     4286 b- defN 24-May-29 02:16 jarvis/api/squire/stockmonitor_squire.py
+-rw-r--r--  2.0 unx     5460 b- defN 24-May-29 02:16 jarvis/api/squire/surveillance_squire.py
+-rw-r--r--  2.0 unx      647 b- defN 24-May-12 00:54 jarvis/api/squire/timeout_otp.py
+-rw-r--r--  2.0 unx    14399 b- defN 24-May-29 02:16 jarvis/api/triggers/stock_monitor.py
+-rw-r--r--  2.0 unx    11823 b- defN 24-May-29 02:16 jarvis/api/triggers/stock_report.py
+-rw-r--r--  2.0 unx    13915 b- defN 24-May-29 02:16 jarvis/executors/alarm.py
+-rw-r--r--  2.0 unx     7561 b- defN 24-May-29 02:16 jarvis/executors/automation.py
+-rw-r--r--  2.0 unx     6241 b- defN 24-May-29 02:16 jarvis/executors/background_task.py
+-rw-r--r--  2.0 unx    26854 b- defN 24-May-29 02:16 jarvis/executors/car.py
+-rw-r--r--  2.0 unx     9465 b- defN 24-May-29 02:16 jarvis/executors/comm_squire.py
+-rw-r--r--  2.0 unx     5480 b- defN 24-May-29 02:16 jarvis/executors/commander.py
+-rw-r--r--  2.0 unx     7035 b- defN 24-May-29 02:16 jarvis/executors/communicator.py
+-rw-r--r--  2.0 unx     5491 b- defN 24-May-29 02:16 jarvis/executors/conditions.py
+-rw-r--r--  2.0 unx     2140 b- defN 24-May-29 02:16 jarvis/executors/connection.py
+-rw-r--r--  2.0 unx    13691 b- defN 24-May-29 02:16 jarvis/executors/controls.py
+-rw-r--r--  2.0 unx     2761 b- defN 24-May-29 02:16 jarvis/executors/crontab.py
+-rw-r--r--  2.0 unx     2044 b- defN 24-May-29 02:16 jarvis/executors/custom_conditions.py
+-rw-r--r--  2.0 unx     2539 b- defN 24-May-29 02:16 jarvis/executors/date_time.py
+-rw-r--r--  2.0 unx     1419 b- defN 24-May-29 02:16 jarvis/executors/display_functions.py
+-rw-r--r--  2.0 unx     4450 b- defN 24-May-29 02:16 jarvis/executors/face.py
+-rw-r--r--  2.0 unx    11580 b- defN 24-May-29 02:16 jarvis/executors/files.py
+-rw-r--r--  2.0 unx     3598 b- defN 24-May-29 02:16 jarvis/executors/functions.py
+-rw-r--r--  2.0 unx     4386 b- defN 24-May-29 02:16 jarvis/executors/github.py
+-rw-r--r--  2.0 unx    10813 b- defN 24-May-29 02:16 jarvis/executors/guard.py
+-rw-r--r--  2.0 unx     8414 b- defN 24-May-29 02:16 jarvis/executors/internet.py
+-rw-r--r--  2.0 unx     6520 b- defN 24-May-29 02:16 jarvis/executors/ios_functions.py
+-rw-r--r--  2.0 unx    11435 b- defN 24-May-29 02:16 jarvis/executors/lights.py
+-rw-r--r--  2.0 unx     5269 b- defN 24-May-29 02:16 jarvis/executors/lights_squire.py
+-rw-r--r--  2.0 unx     2575 b- defN 24-May-29 02:16 jarvis/executors/listener_controls.py
+-rw-r--r--  2.0 unx    14100 b- defN 24-May-29 02:16 jarvis/executors/location.py
+-rw-r--r--  2.0 unx      599 b- defN 24-May-29 02:16 jarvis/executors/method.py
+-rw-r--r--  2.0 unx    14253 b- defN 24-May-29 02:16 jarvis/executors/offline.py
+-rw-r--r--  2.0 unx    24567 b- defN 24-May-29 02:16 jarvis/executors/others.py
+-rw-r--r--  2.0 unx     3103 b- defN 24-May-29 02:16 jarvis/executors/port_handler.py
+-rw-r--r--  2.0 unx     5009 b- defN 24-May-29 02:16 jarvis/executors/process_map.py
+-rw-r--r--  2.0 unx     5784 b- defN 24-May-29 02:16 jarvis/executors/processor.py
+-rw-r--r--  2.0 unx    12483 b- defN 24-May-29 02:16 jarvis/executors/remind.py
+-rw-r--r--  2.0 unx     4040 b- defN 24-May-29 02:16 jarvis/executors/restrictions.py
+-rw-r--r--  2.0 unx     4201 b- defN 24-May-29 02:16 jarvis/executors/robinhood.py
+-rw-r--r--  2.0 unx     3510 b- defN 24-May-29 02:16 jarvis/executors/simulator.py
+-rw-r--r--  2.0 unx     3999 b- defN 24-May-29 02:16 jarvis/executors/static_responses.py
+-rw-r--r--  2.0 unx     8956 b- defN 24-May-29 02:16 jarvis/executors/system.py
+-rw-r--r--  2.0 unx     3343 b- defN 24-May-29 02:16 jarvis/executors/telegram.py
+-rw-r--r--  2.0 unx     7599 b- defN 24-May-29 02:16 jarvis/executors/thermostat.py
+-rw-r--r--  2.0 unx     5380 b- defN 24-May-29 02:16 jarvis/executors/todo_list.py
+-rw-r--r--  2.0 unx     7908 b- defN 24-May-29 02:16 jarvis/executors/tv.py
+-rw-r--r--  2.0 unx     8140 b- defN 24-May-29 02:16 jarvis/executors/tv_controls.py
+-rw-r--r--  2.0 unx     5140 b- defN 24-May-29 02:16 jarvis/executors/unconditional.py
+-rw-r--r--  2.0 unx     1924 b- defN 24-May-29 02:16 jarvis/executors/volume.py
+-rw-r--r--  2.0 unx     6600 b- defN 24-May-29 02:16 jarvis/executors/vpn_server.py
+-rw-r--r--  2.0 unx    11002 b- defN 24-May-29 02:16 jarvis/executors/weather.py
+-rw-r--r--  2.0 unx     3703 b- defN 24-May-29 02:16 jarvis/executors/weather_monitor.py
+-rw-r--r--  2.0 unx     2368 b- defN 24-May-29 02:16 jarvis/executors/wiki.py
+-rw-r--r--  2.0 unx     1723 b- defN 24-May-29 02:16 jarvis/executors/word_match.py
+-rw-r--r--  2.0 unx     9239 b- defN 24-May-12 00:54 jarvis/indicators/acknowledgement.mp3
+-rw-r--r--  2.0 unx  3087321 b- defN 24-May-12 00:54 jarvis/indicators/alarm.mp3
+-rw-r--r--  2.0 unx    17350 b- defN 24-May-12 00:54 jarvis/indicators/coin.mp3
+-rwxr-xr-x  2.0 unx     9448 b- defN 24-May-12 00:54 jarvis/indicators/end.mp3
+-rwxr-xr-x  2.0 unx    11538 b- defN 24-May-12 00:54 jarvis/indicators/start.mp3
+-rwxr-xr-x  2.0 unx    10392 b- defN 24-May-29 02:16 jarvis/lib/install.sh
+-rw-r--r--  2.0 unx      440 b- defN 24-May-29 02:16 jarvis/lib/version_locked_requirements.txt
+-rw-r--r--  2.0 unx      510 b- defN 24-May-29 02:16 jarvis/lib/version_pinned_requirements.txt
+-rw-r--r--  2.0 unx      129 b- defN 24-May-29 02:16 jarvis/lib/version_upgrade_requirements.txt
+-rw-r--r--  2.0 unx     1666 b- defN 24-May-29 02:16 jarvis/lib/squire/detector.sh
+-rw-r--r--  2.0 unx     1076 b- defN 24-May-12 00:54 jarvis/modules/auth_bearer.py
+-rw-r--r--  2.0 unx     3375 b- defN 24-May-29 02:16 jarvis/modules/builtin_overrides.py
+-rw-r--r--  2.0 unx     3825 b- defN 24-May-29 02:16 jarvis/modules/exceptions.py
+-rw-r--r--  2.0 unx     4898 b- defN 24-May-29 02:16 jarvis/modules/logger.py
+-rw-r--r--  2.0 unx     1565 b- defN 24-May-29 02:16 jarvis/modules/peripherals.py
+-rw-r--r--  2.0 unx     4429 b- defN 24-May-29 02:16 jarvis/modules/audio/listener.py
+-rw-r--r--  2.0 unx     6099 b- defN 24-May-29 02:16 jarvis/modules/audio/speaker.py
+-rw-r--r--  2.0 unx     9813 b- defN 24-May-29 02:16 jarvis/modules/audio/speech_synthesis.py
+-rw-r--r--  2.0 unx     2053 b- defN 24-May-12 19:32 jarvis/modules/audio/tts_stt.py
+-rw-r--r--  2.0 unx     2778 b- defN 24-May-29 02:16 jarvis/modules/audio/voices.py
+-rw-r--r--  2.0 unx     7290 b- defN 24-May-29 02:16 jarvis/modules/camera/camera.py
+-rw-r--r--  2.0 unx     3162 b- defN 24-May-29 02:16 jarvis/modules/conditions/conversation.py
+-rw-r--r--  2.0 unx     7355 b- defN 24-May-29 02:16 jarvis/modules/conditions/keywords.py
+-rw-r--r--  2.0 unx    12540 b- defN 24-May-29 02:16 jarvis/modules/crontab/expression.py
+-rw-r--r--  2.0 unx     4330 b- defN 24-May-29 02:16 jarvis/modules/database/database.py
+-rw-r--r--  2.0 unx     1618 b- defN 24-May-29 02:16 jarvis/modules/dictionary/dictionary.py
+-rw-r--r--  2.0 unx     7952 b- defN 24-May-29 02:16 jarvis/modules/facenet/face.py
+-rw-r--r--  2.0 unx      640 b- defN 24-May-29 02:16 jarvis/modules/lights/preset_values.py
+-rw-r--r--  2.0 unx    10186 b- defN 24-May-29 02:16 jarvis/modules/lights/smart_lights.py
+-rw-r--r--  2.0 unx     8657 b- defN 24-May-29 02:16 jarvis/modules/meetings/events.py
+-rw-r--r--  2.0 unx     4832 b- defN 24-May-29 02:16 jarvis/modules/meetings/ics.py
+-rw-r--r--  2.0 unx     8619 b- defN 24-May-29 02:16 jarvis/modules/meetings/ics_meetings.py
+-rw-r--r--  2.0 unx     8427 b- defN 24-May-29 02:16 jarvis/modules/microphone/graph_mic.py
+-rw-r--r--  2.0 unx     2792 b- defN 24-May-29 02:16 jarvis/modules/microphone/recognizer.py
+-rw-r--r--  2.0 unx    21937 b- defN 24-May-29 02:16 jarvis/modules/models/classes.py
+-rw-r--r--  2.0 unx    11769 b- defN 24-May-29 02:16 jarvis/modules/models/models.py
+-rw-r--r--  2.0 unx     2968 b- defN 24-May-29 02:16 jarvis/modules/retry/retry.py
+-rw-r--r--  2.0 unx     6604 b- defN 24-May-29 02:16 jarvis/modules/speaker/speak.py
+-rw-r--r--  2.0 unx     2047 b- defN 24-May-29 02:16 jarvis/modules/telegram/audio_handler.py
+-rw-r--r--  2.0 unx    26739 b- defN 24-May-29 02:16 jarvis/modules/telegram/bot.py
+-rw-r--r--  2.0 unx     3665 b- defN 24-May-29 02:16 jarvis/modules/telegram/file_handler.py
+-rw-r--r--  2.0 unx     1766 b- defN 24-May-12 00:54 jarvis/modules/telegram/settings.py
+-rw-r--r--  2.0 unx     1941 b- defN 24-May-29 02:16 jarvis/modules/telegram/webhook.py
+-rw-r--r--  2.0 unx     1616 b- defN 24-May-12 00:54 jarvis/modules/temperature/temperature.py
+-rw-r--r--  2.0 unx     2821 b- defN 24-May-12 00:54 jarvis/modules/templates/car_report.html
+-rw-r--r--  2.0 unx    25812 b- defN 24-May-12 00:54 jarvis/modules/templates/email.html
+-rw-r--r--  2.0 unx     3386 b- defN 24-May-12 00:54 jarvis/modules/templates/email_OTP.html
+-rw-r--r--  2.0 unx      412 b- defN 24-May-12 00:54 jarvis/modules/templates/email_stock_alert.html
+-rw-r--r--  2.0 unx      128 b- defN 24-May-12 00:54 jarvis/modules/templates/email_threat_audio.html
+-rw-r--r--  2.0 unx      136 b- defN 24-May-12 00:54 jarvis/modules/templates/email_threat_image.html
+-rw-r--r--  2.0 unx      180 b- defN 24-May-12 00:54 jarvis/modules/templates/email_threat_image_audio.html
+-rw-r--r--  2.0 unx     2421 b- defN 24-May-12 00:54 jarvis/modules/templates/robinhood.html
+-rw-r--r--  2.0 unx     2502 b- defN 24-May-12 00:54 jarvis/modules/templates/surveillance.html
+-rw-r--r--  2.0 unx     2169 b- defN 24-May-29 02:16 jarvis/modules/templates/templates.py
+-rw-r--r--  2.0 unx      637 b- defN 24-May-12 00:54 jarvis/modules/templates/win_wifi_config.xml
+-rw-r--r--  2.0 unx     2189 b- defN 24-May-29 02:16 jarvis/modules/timeout/timeout.py
+-rw-r--r--  2.0 unx     7282 b- defN 24-May-29 02:16 jarvis/modules/transformer/gpt.py
+-rw-r--r--  2.0 unx     9788 b- defN 24-May-29 02:16 jarvis/modules/tv/lg.py
+-rw-r--r--  2.0 unx     7954 b- defN 24-May-29 02:16 jarvis/modules/tv/roku.py
+-rw-r--r--  2.0 unx      402 b- defN 24-May-29 02:16 jarvis/modules/utils/shared.py
+-rw-r--r--  2.0 unx    20874 b- defN 24-May-29 02:16 jarvis/modules/utils/support.py
+-rw-r--r--  2.0 unx    10934 b- defN 24-May-29 02:16 jarvis/modules/utils/util.py
+-rw-r--r--  2.0 unx     2164 b- defN 24-May-29 02:16 jarvis/modules/wakeonlan/wakeonlan.py
+-rwxr-xr-x  2.0 unx     1044 b- defN 24-May-12 00:54 jarvis/scripts/applauncher.scpt
+-rwxr-xr-x  2.0 unx     2750 b- defN 24-May-12 00:54 jarvis/scripts/calendar.scpt
+-rwxr-xr-x  2.0 unx     2504 b- defN 24-May-12 00:54 jarvis/scripts/outlook.scpt
+-rwxr-xr-x  2.0 unx     1666 b- defN 24-May-29 02:16 jarvis_ironman-4.5.data/scripts/detector.sh
+-rwxr-xr-x  2.0 unx    10392 b- defN 24-May-29 02:16 jarvis_ironman-4.5.data/scripts/install.sh
+-rw-r--r--  2.0 unx     1068 b- defN 24-May-29 02:42 jarvis_ironman-4.5.dist-info/LICENSE
+-rw-r--r--  2.0 unx    15397 b- defN 24-May-29 02:42 jarvis_ironman-4.5.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-May-29 02:42 jarvis_ironman-4.5.dist-info/WHEEL
+-rw-r--r--  2.0 unx        7 b- defN 24-May-29 02:42 jarvis_ironman-4.5.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    13425 b- defN 24-May-29 02:42 jarvis_ironman-4.5.dist-info/RECORD
+151 files, 4007650 bytes uncompressed, 3279674 bytes compressed:  18.2%
```

## zipnote {}

```diff
@@ -36,14 +36,17 @@
 
 Filename: jarvis/api/routers/investment.py
 Comment: 
 
 Filename: jarvis/api/routers/offline.py
 Comment: 
 
+Filename: jarvis/api/routers/proxy_service.py
+Comment: 
+
 Filename: jarvis/api/routers/secure_send.py
 Comment: 
 
 Filename: jarvis/api/routers/speech_synthesis.py
 Comment: 
 
 Filename: jarvis/api/routers/stock_analysis.py
@@ -252,14 +255,17 @@
 
 Filename: jarvis/lib/version_pinned_requirements.txt
 Comment: 
 
 Filename: jarvis/lib/version_upgrade_requirements.txt
 Comment: 
 
+Filename: jarvis/lib/squire/detector.sh
+Comment: 
+
 Filename: jarvis/modules/auth_bearer.py
 Comment: 
 
 Filename: jarvis/modules/builtin_overrides.py
 Comment: 
 
 Filename: jarvis/modules/exceptions.py
@@ -285,20 +291,14 @@
 
 Filename: jarvis/modules/audio/voices.py
 Comment: 
 
 Filename: jarvis/modules/camera/camera.py
 Comment: 
 
-Filename: jarvis/modules/car/connector.py
-Comment: 
-
-Filename: jarvis/modules/car/controller.py
-Comment: 
-
 Filename: jarvis/modules/conditions/conversation.py
 Comment: 
 
 Filename: jarvis/modules/conditions/keywords.py
 Comment: 
 
 Filename: jarvis/modules/crontab/expression.py
@@ -426,26 +426,29 @@
 
 Filename: jarvis/scripts/calendar.scpt
 Comment: 
 
 Filename: jarvis/scripts/outlook.scpt
 Comment: 
 
-Filename: jarvis_ironman-4.4.2.data/scripts/install.sh
+Filename: jarvis_ironman-4.5.data/scripts/detector.sh
+Comment: 
+
+Filename: jarvis_ironman-4.5.data/scripts/install.sh
 Comment: 
 
-Filename: jarvis_ironman-4.4.2.dist-info/LICENSE
+Filename: jarvis_ironman-4.5.dist-info/LICENSE
 Comment: 
 
-Filename: jarvis_ironman-4.4.2.dist-info/METADATA
+Filename: jarvis_ironman-4.5.dist-info/METADATA
 Comment: 
 
-Filename: jarvis_ironman-4.4.2.dist-info/WHEEL
+Filename: jarvis_ironman-4.5.dist-info/WHEEL
 Comment: 
 
-Filename: jarvis_ironman-4.4.2.dist-info/top_level.txt
+Filename: jarvis_ironman-4.5.dist-info/top_level.txt
 Comment: 
 
-Filename: jarvis_ironman-4.4.2.dist-info/RECORD
+Filename: jarvis_ironman-4.5.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## jarvis/__init__.py

```diff
@@ -1,22 +1,28 @@
 import os
 from multiprocessing import current_process
 
-version = "4.4.2"
+version = "4.5"
 
-install_script = os.path.join(os.path.dirname(__file__), 'lib', 'install.sh')
+install_script = os.path.join(os.path.dirname(__file__), "lib", "install.sh")
 
 try:
-    if current_process().name == 'MainProcess':
-        current_process().name = os.environ.get('PROCESS_NAME', 'JARVIS')
+    if current_process().name == "MainProcess":
+        current_process().name = os.environ.get("PROCESS_NAME", "JARVIS")
     import pynotification  # noqa: F401
 
     from ._preexec import keywords_handler  # noqa: F401
     from .main import start  # noqa: F401
 except ImportError as error:
     try:
-        pynotification.pynotifier(title="First time user?", dialog=True, message=f"Please run\n\n{install_script}")
+        pynotification.pynotifier(
+            title="First time user?",
+            dialog=True,
+            message=f"Please run\n\n{install_script}",
+        )
     except NameError:
         pass
-    raise UserWarning(f"{error.__str__()}\n\nPlease run\n\n{install_script}\n\n"
-                      "Note: Shell script will quit for any non-zero exit status, "
-                      "so it might have to be triggered twice.")
+    raise UserWarning(
+        f"{error.__str__()}\n\nPlease run\n\n{install_script}\n\n"
+        "Note: Shell script will quit for any non-zero exit status, "
+        "so it might have to be triggered twice."
+    )
```

## jarvis/main.py

```diff
@@ -5,16 +5,23 @@
 from datetime import datetime
 
 import pvporcupine
 import pyaudio
 import pywifi
 from playsound import playsound
 
-from jarvis.executors import (commander, controls, internet, listener_controls,
-                              location, process_map, processor)
+from jarvis.executors import (
+    commander,
+    controls,
+    internet,
+    listener_controls,
+    location,
+    process_map,
+    processor,
+)
 from jarvis.modules.audio import listener, speaker
 from jarvis.modules.exceptions import StopSignal
 from jarvis.modules.logger import custom_handler, logger
 from jarvis.modules.models import models
 from jarvis.modules.peripherals import audio_engine
 from jarvis.modules.utils import shared, support
 
@@ -57,22 +64,26 @@
             - Instantiates an instance of Porcupine object and monitors audio stream for occurrences of keywords.
             - A higher sensitivity results in fewer misses at the cost of increasing the false alarm rate.
             - sensitivity: Tolerance/Sensitivity level. Takes argument or env var ``sensitivity`` or defaults to ``0.5``
 
         References:
             - `Audio Overflow <https://people.csail.mit.edu/hubert/pyaudio/docs/#pyaudio.Stream.read>`__ handling.
         """
-        label = ', '.join([f'{string.capwords(wake)!r}: {sens}' for wake, sens in
-                           zip(models.env.wake_words, models.env.sensitivity)])
+        label = ", ".join(
+            [
+                f"{string.capwords(wake)!r}: {sens}"
+                for wake, sens in zip(models.env.wake_words, models.env.sensitivity)
+            ]
+        )
         logger.info("Initiating hot-word detector with sensitivity: %s", label)
         keyword_paths = [pvporcupine.KEYWORD_PATHS[x] for x in models.env.wake_words]
 
         arguments = {
             "library_path": pvporcupine.LIBRARY_PATH,
-            "sensitivities": models.env.sensitivity
+            "sensitivities": models.env.sensitivity,
         }
         if models.settings.legacy:
             arguments["keywords"] = models.env.wake_words
             arguments["model_file_path"] = pvporcupine.MODEL_PATH
             arguments["keyword_file_paths"] = keyword_paths
         else:
             arguments["model_path"] = pvporcupine.MODEL_PATH
@@ -94,62 +105,68 @@
         """
         return audio_engine.open(
             rate=self.detector.sample_rate,
             channels=1,
             format=pyaudio.paInt16,
             input=True,
             frames_per_buffer=self.detector.frame_length,
-            input_device_index=models.env.microphone_index
+            input_device_index=models.env.microphone_index,
         )
 
     def executor(self) -> None:
         """Calls the listener for actionable phrase and runs the speaker node for response."""
-        logger.debug("Wake word detected at %s", datetime.now().strftime('%c'))
+        logger.debug("Wake word detected at %s", datetime.now().strftime("%c"))
         if listener_controls.get_listener_state():
             playsound(sound=models.indicators.acknowledgement, block=False)
         audio_engine.close(stream=self.audio_stream)
         # No confidence during initiation since this will interrupt with listener state
         if phrase := listener.listen(sound=False, no_conf=True):
             try:
                 commander.initiator(phrase=phrase)
             except Exception as error:
                 logger.critical(error)
                 logger.error(traceback.format_exc())
-                speaker.speak(text=f"I'm sorry {models.env.title}! I ran into an unknown error. "
-                                   "Please check the logs for more information.")
+                speaker.speak(
+                    text=f"I'm sorry {models.env.title}! I ran into an unknown error. "
+                    "Please check the logs for more information."
+                )
             speaker.speak(run=True)
         self.audio_stream = self.open_stream()
         support.write_screen(text=self.label)
 
     def start(self) -> None:
         """Runs ``audio_stream`` in a forever loop and calls ``initiator`` when the phrase ``Jarvis`` is heard."""
         try:
             wake_len = len(models.env.wake_words)
             support.write_screen(text=self.label)
             while True:
                 result = self.detector.process(
                     pcm=struct.unpack_from(
-                        "h" * self.detector.frame_length, self.audio_stream.read(
-                            num_frames=self.detector.frame_length, exception_on_overflow=False
-                        )
+                        "h" * self.detector.frame_length,
+                        self.audio_stream.read(
+                            num_frames=self.detector.frame_length,
+                            exception_on_overflow=False,
+                        ),
                     )
                 )
                 if models.settings.legacy:
                     if wake_len == 1 and result:
                         self.executor()
                     elif wake_len > 1 and result >= 0:
                         self.executor()
                 else:
                     if result >= 0:
                         self.executor()
                 if models.settings.limited:
                     continue
                 restart_checker()
                 if flag := support.check_stop():
-                    logger.info("Stopper condition is set to %s by %s", flag[0], flag[1])
+                    logger.info(
+                        "Stopper condition is set to %s by %s", flag[0], flag[1]
+                    )
                     self.stop()
                     controls.terminator()
         except StopSignal:
             controls.exit_process()
             self.audio_stream = None
             self.stop()
             controls.terminator()
@@ -177,32 +194,44 @@
 
 
 def start() -> None:
     """Starts main process to activate Jarvis after checking internet connection and initiating background processes."""
     logger.info("Current Process ID: %d", models.settings.pid)
     controls.starter()
     if internet.ip_address() and internet.public_ip_info():
-        support.write_screen(text=f"INTERNET::Connected to {internet.get_connection_info() or 'the internet'}.")
+        support.write_screen(
+            text=f"INTERNET::Connected to {internet.get_connection_info() or 'the internet'}."
+        )
     else:
         support.write_screen("Trying to toggle WiFi")
         pywifi.ControlPeripheral(logger=logger).enable()
         if models.env.wifi_ssid and models.env.wifi_password:
             time.sleep(5)
             support.write_screen(f"Trying to connect to {models.env.wifi_ssid!r}")
-            if pywifi.ControlConnection(wifi_ssid=models.env.wifi_ssid, wifi_password=models.env.wifi_password,
-                                        logger=logger).wifi_connector():
+            if pywifi.ControlConnection(
+                wifi_ssid=models.env.wifi_ssid,
+                wifi_password=models.env.wifi_password,
+                logger=logger,
+            ).wifi_connector():
                 support.write_screen(f"Connected to {models.env.wifi_ssid!r}")
             else:
                 support.write_screen(text="BUMMER::Unable to connect to the Internet")
-                speaker.speak(text=f"I was unable to connect to the internet {models.env.title}! "
-                                   "Please check your connection.", run=True)
-    support.write_screen(text=f"Current Process ID: {models.settings.pid}\tCurrent Volume: {models.env.volume}")
+                speaker.speak(
+                    text=f"I was unable to connect to the internet {models.env.title}! "
+                    "Please check your connection.",
+                    run=True,
+                )
+    support.write_screen(
+        text=f"Current Process ID: {models.settings.pid}\tCurrent Volume: {models.env.volume}"
+    )
     if models.settings.limited:
         # Write processes mapping file before calling start_processes with func_name flag,
         # as passing the flag will look for the file's presence
         process_map.add({"jarvis": {models.settings.pid: ["Main Process"]}})
         if models.settings.os != models.supported_platforms.macOS:
-            shared.processes = processor.start_processes(func_name="speech_synthesis_api")
+            shared.processes = processor.start_processes(
+                func_name="speech_synthesis_api"
+            )
     else:
         shared.processes = processor.start_processes()
     location.write_current_location()
     Activator().start()
```

## jarvis/_preexec/keywords_handler.py

```diff
@@ -9,27 +9,37 @@
 from jarvis.modules.models import classes, models
 from jarvis.modules.utils import support
 
 
 def load_ignores(data: dict) -> None:
     """Loads ``ignore_after`` and ``ignore_add`` list to avoid iterations on the same phrase."""
     # Keywords for which the ' after ' split should not happen.
-    keywords.ignore_after = data['meetings'] + data['avoid']
+    keywords.ignore_after = data["meetings"] + data["avoid"]
     # Keywords for which the ' and ' split should not happen.
-    keywords.ignore_and = data['send_notification'] + data['reminder'] + data['distance'] + data['avoid']
+    keywords.ignore_and = (
+        data["send_notification"] + data["reminder"] + data["distance"] + data["avoid"]
+    )
 
 
 def rewrite_keywords() -> None:
     """Loads keywords.yaml file if available, else loads the base keywords module as an object."""
-    keywords_src = OrderedDict(**keywords.keyword_mapping(), **conversation.conversation_mapping())
+    keywords_src = OrderedDict(
+        **keywords.keyword_mapping(), **conversation.conversation_mapping()
+    )
     # WATCH OUT: for changes in keyword/function name
     if models.env.event_app:
-        keywords_src['events'] = [models.env.event_app.lower(), support.ENGINE.plural(models.env.event_app)]
+        keywords_src["events"] = [
+            models.env.event_app.lower(),
+            support.ENGINE.plural(models.env.event_app),
+        ]
     else:
-        keywords_src['events'] = [classes.EventApp.CALENDAR.value, classes.EventApp.OUTLOOK.value]
+        keywords_src["events"] = [
+            classes.EventApp.CALENDAR.value,
+            classes.EventApp.OUTLOOK.value,
+        ]
     if os.path.isfile(models.fileio.keywords):
         with open(models.fileio.keywords) as dst_file:
             try:
                 data = ordered_load(stream=dst_file, Loader=yaml.FullLoader) or {}
             except yaml.YAMLError as error:
                 warnings.warn(message=str(error))
                 data = None
@@ -37,25 +47,29 @@
         if not data:  # Either an error occurred when reading or a manual deletion
             if data is {}:
                 warnings.warn(
                     f"\nSomething went wrong. {models.fileio.keywords!r} appears to be empty."
                     f"\nRe-sourcing {models.fileio.keywords!r} from base."
                 )
         # compare as sorted, since this will allow changing the order of keywords in the yaml file
-        elif sorted(list(data.keys())) == sorted(list(keywords_src.keys())) and data.values() and all(data.values()):
+        elif (
+            sorted(list(data.keys())) == sorted(list(keywords_src.keys()))
+            and data.values()
+            and all(data.values())
+        ):
             keywords.keywords = data
             load_ignores(data)
             return
         else:  # Mismatch in keys
             warnings.warn(
                 "\nData mismatch between base keywords and custom keyword mapping."
                 "\nPlease note: This mapping file is only to change the value for keywords, not the key(s) itself."
                 f"\nRe-sourcing {models.fileio.keywords!r} from base."
             )
 
-    with open(models.fileio.keywords, 'w') as dst_file:
+    with open(models.fileio.keywords, "w") as dst_file:
         ordered_dump(stream=dst_file, data=keywords_src, indent=4)
     keywords.keywords = keywords_src
     load_ignores(keywords_src)
 
 
 rewrite_keywords()
```

## jarvis/api/logger.py

```diff
@@ -28,9 +28,11 @@
 
 if not os.path.isfile(api_config.DEFAULT_LOG_FILENAME):
     pathlib.Path(api_config.DEFAULT_LOG_FILENAME).touch()
 
 # Configure logging
 importlib.reload(module=logging)
 dictConfig(config=api_config.LOG_CONFIG)
-logging.getLogger("uvicorn.access").propagate = False  # Disables access logger in default logger to log independently
+logging.getLogger(
+    "uvicorn.access"
+).propagate = False  # Disables access logger in default logger to log independently
 logger = logging.getLogger("uvicorn.default")
```

## jarvis/api/main.py

```diff
@@ -15,70 +15,90 @@
 from jarvis.executors import crontab
 from jarvis.modules.models import models
 
 # Initiate API
 app = FastAPI(
     title="Jarvis API",
     description="#### Gateway to communicate with Jarvis, and an entry point for the UI.\n\n"
-                "**Contact:** [https://vigneshrao.com/contact](https://vigneshrao.com/contact)",
-    version=version
+    "**Contact:** [https://vigneshrao.com/contact](https://vigneshrao.com/contact)",
+    version=version,
 )
 
 
 def enable_cors() -> None:
     """Allow CORS: Cross-Origin Resource Sharing to allow restricted resources on the API."""
-    logger.info('Setting CORS policy.')
+    logger.info("Setting CORS policy.")
     origins = [
         "http://localhost.com",
         "https://localhost.com",
-        f"http://{models.env.website.host}",
-        f"https://{models.env.website.host}",
     ]
+    for website in models.env.website:
+        origins.extend([f"http://{website.host}", f"https://{website.host}"])
 
     app.add_middleware(
         CORSMiddleware,
         allow_origins=origins,
         allow_credentials=True,
         allow_methods=["GET", "POST"],
-        allow_headers=["host", "user-agent",  # Default headers
-                       "authorization", "apikey",  # Offline auth and stock monitor apikey headers
-                       "email-otp", "email_otp",  # One time passcode sent via email
-                       "access-token", "access_token"],  # Access token sent via email
+        allow_headers=[
+            "host",
+            "user-agent",  # Default headers
+            "authorization",
+            "apikey",  # Offline auth and stock monitor apikey headers
+            "email-otp",
+            "email_otp",  # One time passcode sent via email
+            "access-token",
+            "access_token",
+        ],  # Access token sent via email
     )
 
 
 # Include all the routers
 # WATCH OUT: for changes in function name
 if models.settings.pname == "jarvis_api":  # Avoid looping when called by subprocesses
     # Cannot add middleware after an application has started
     enable_cors()
     for router in discover.routes(routers.__path__[0]):
         app.include_router(router)
 
 
-@app.on_event(event_type='startup')
+@app.on_event(event_type="startup")
 async def startup_func() -> None:
     """Simple startup function to add anything that has to be triggered when Jarvis API starts up."""
-    logger.info("Hosting at http://%s:%s", models.env.offline_host, models.env.offline_port)
+    logger.info(
+        "Hosting at http://%s:%s", models.env.offline_host, models.env.offline_port
+    )
     if models.env.author_mode:
         Thread(target=stockanalysis_squire.nasdaq).start()
     if not os.path.isdir(models.fileio.startup_dir):
         return
     for startup_script in os.listdir(models.fileio.startup_dir):
         startup_script = pathlib.Path(startup_script)
         logger.info("Executing startup script: '%s'", startup_script)
-        if startup_script.suffix in ('.py', '.sh', '.zsh') and not startup_script.stem.startswith('_'):
+        if startup_script.suffix in (
+            ".py",
+            ".sh",
+            ".zsh",
+        ) and not startup_script.stem.startswith("_"):
             starter = None
             if startup_script.suffix == ".py":
-                starter = shutil.which(cmd='python')
+                starter = shutil.which(cmd="python")
             if startup_script.suffix == ".sh":
-                starter = shutil.which(cmd='bash')
+                starter = shutil.which(cmd="bash")
             if startup_script.suffix == ".zsh":
-                starter = shutil.which(cmd='zsh')
+                starter = shutil.which(cmd="zsh")
             if not starter:
                 continue
-            script = starter + " " + os.path.join(models.fileio.startup_dir, startup_script)
+            script = (
+                starter + " " + os.path.join(models.fileio.startup_dir, startup_script)
+            )
             logger.debug("Running %s", script)
-            log_file = datetime.now().strftime(os.path.join('logs', 'startup_script_%d-%m-%Y.log'))
-            Process(target=crontab.executor, args=(script, log_file, 'startup_script')).start()
+            log_file = datetime.now().strftime(
+                os.path.join("logs", "startup_script_%d-%m-%Y.log")
+            )
+            Process(
+                target=crontab.executor, args=(script, log_file, "startup_script")
+            ).start()
         else:
-            logger.warning("Unsupported file format for startup script: %s", startup_script)
+            logger.warning(
+                "Unsupported file format for startup script: %s", startup_script
+            )
```

## jarvis/api/server.py

```diff
@@ -14,42 +14,48 @@
     """Initiates the fast API in a dedicated process using uvicorn server.
 
     See Also:
         - Checks if the port is being used. If so, makes a ``GET`` request to the endpoint.
         - Attempts to kill the process listening to the port, if the endpoint doesn't respond.
     """
     multiprocessing_logger(filename=APIConfig().DEFAULT_LOG_FILENAME)
-    url = f'http://{models.env.offline_host}:{models.env.offline_port}'
+    url = f"http://{models.env.offline_host}:{models.env.offline_port}"
 
     if port_handler.is_port_in_use(port=models.env.offline_port):
         logger.info("%d is currently in use.", models.env.offline_port)
 
         try:
             res = requests.get(url=url, timeout=1)
             if res.ok:
                 logger.info("'%s' is accessible.", url)
                 return
             raise requests.ConnectionError
         except EgressErrors:
-            logger.error('Unable to connect to existing uvicorn server.')
+            logger.error("Unable to connect to existing uvicorn server.")
 
-        if not port_handler.kill_port_pid(port=models.env.offline_port):  # This might terminate Jarvis
-            logger.critical('ATTENTION::Failed to kill existing PID. Attempting to re-create session.')
+        # This might terminate Jarvis
+        if not port_handler.kill_port_pid(port=models.env.offline_port):
+            logger.critical(
+                "ATTENTION::Failed to kill existing PID. Attempting to re-create session."
+            )
 
     # Uvicorn config supports the module as a value for the arg 'app' which can be from relative imports
     # However, in this case, using relative imports will mess with the logger since it is shared across multiple process
-    assert os.path.exists(os.path.join(os.path.dirname(__file__), "main.py")), \
-        "API path has either been modified or unreachable."
+    assert os.path.exists(
+        os.path.join(os.path.dirname(__file__), "main.py")
+    ), "API path has either been modified or unreachable."
     argument_dict = {
         "app": "jarvis.api.main:app",
         "host": models.env.offline_host,
         "port": models.env.offline_port,
         "ws_ping_interval": 20.0,
         "ws_ping_timeout": 20.0,
-        "workers": models.env.workers
+        "workers": models.env.workers,
     }
 
     logger.debug(argument_dict)
-    logger.info("Starting FastAPI on Uvicorn server with %d workers.", models.env.workers)
+    logger.info(
+        "Starting FastAPI on Uvicorn server with %d workers.", models.env.workers
+    )
 
     server_conf = uvicorn.Config(**argument_dict)
     APIServer(config=server_conf).run_in_parallel()
```

## jarvis/api/models/authenticator.py

```diff
@@ -16,54 +16,62 @@
     Args:
         token: Takes the authorization header token as an argument.
 
     Raises:
         APIResponse:
         - 401: If authorization is invalid.
     """
-    auth = token.dict().get('credentials', '')
-    if auth.startswith('\\'):
+    auth = token.dict().get("credentials", "")
+    if auth.startswith("\\"):
         auth = bytes(auth, "utf-8").decode(encoding="unicode_escape")
     if secrets.compare_digest(auth, models.env.offline_pass):
         return
-    raise APIResponse(status_code=HTTPStatus.UNAUTHORIZED.real, detail=HTTPStatus.UNAUTHORIZED.phrase)
+    raise APIResponse(
+        status_code=HTTPStatus.UNAUTHORIZED.real, detail=HTTPStatus.UNAUTHORIZED.phrase
+    )
 
 
 async def robinhood_has_access(token: HTTPBasicCredentials = Depends(SECURITY)) -> None:
     """Validates the token if mentioned as a dependency.
 
     Args:
         token: Takes the authorization header token as an argument.
 
     Raises:
         APIResponse:
         - 401: If authorization is invalid.
     """
-    auth = token.dict().get('credentials')
-    if auth.startswith('\\'):
+    auth = token.dict().get("credentials")
+    if auth.startswith("\\"):
         auth = bytes(auth, "utf-8").decode(encoding="unicode_escape")
     if secrets.compare_digest(auth, models.env.robinhood_endpoint_auth):
         return
-    raise APIResponse(status_code=HTTPStatus.UNAUTHORIZED.real, detail=HTTPStatus.UNAUTHORIZED.phrase)
+    raise APIResponse(
+        status_code=HTTPStatus.UNAUTHORIZED.real, detail=HTTPStatus.UNAUTHORIZED.phrase
+    )
 
 
-async def surveillance_has_access(token: HTTPBasicCredentials = Depends(SECURITY)) -> None:
+async def surveillance_has_access(
+    token: HTTPBasicCredentials = Depends(SECURITY),
+) -> None:
     """Validates the token if mentioned as a dependency.
 
     Args:
         token: Takes the authorization header token as an argument.
 
     Raises:
         APIResponse:
         - 401: If authorization is invalid.
     """
-    auth = token.dict().get('credentials')
-    if auth.startswith('\\'):
+    auth = token.dict().get("credentials")
+    if auth.startswith("\\"):
         auth = bytes(auth, "utf-8").decode(encoding="unicode_escape")
     if secrets.compare_digest(auth, models.env.surveillance_endpoint_auth):
         return
-    raise APIResponse(status_code=HTTPStatus.UNAUTHORIZED.real, detail=HTTPStatus.UNAUTHORIZED.phrase)
+    raise APIResponse(
+        status_code=HTTPStatus.UNAUTHORIZED.real, detail=HTTPStatus.UNAUTHORIZED.phrase
+    )
 
 
 OFFLINE_PROTECTOR = [Depends(dependency=offline_has_access)]
 ROBINHOOD_PROTECTOR = [Depends(dependency=robinhood_has_access)]
 SURVEILLANCE_PROTECTOR = [Depends(dependency=surveillance_has_access)]
```

## jarvis/api/models/modals.py

```diff
@@ -1,8 +1,8 @@
-from typing import Any, Optional, Union
+from typing import Any, Optional
 
 from pydantic import BaseModel, EmailStr
 
 from jarvis.modules.models import models
 
 
 class OfflineCommunicatorModal(BaseModel):
@@ -10,27 +10,27 @@
 
     >>> OfflineCommunicatorModal
 
     """
 
     command: str
     native_audio: Optional[bool] = False
-    speech_timeout: Optional[Union[int, float]] = 0
+    speech_timeout: Optional[int | float] = 0
 
 
 class StockMonitorModal(BaseModel):
     """BaseModel that handles input data for ``StockMonitorModal``.
 
     >>> StockMonitorModal
 
     """
 
-    email: Union[EmailStr, None] = None
-    token: Union[Any, None] = None
-    request: Union[Any, None] = None
+    email: EmailStr | None = None
+    token: Any | None = None
+    request: Any | None = None
     plaintext: bool = False
 
 
 class CameraIndexModal(BaseModel):
     """BaseModel that handles input data for ``CameraIndexModal``.
 
     >>> CameraIndexModal
@@ -44,10 +44,10 @@
     """BaseModel that handles input data for ``SpeechSynthesisModal``.
 
     >>> SpeechSynthesisModal
 
     """
 
     text: str
-    timeout: Optional[Union[int, float]] = None
+    timeout: Optional[int | float] = None
     quality: Optional[str] = models.env.speech_synthesis_quality
     voice: Optional[str] = models.env.speech_synthesis_voice
```

## jarvis/api/models/settings.py

```diff
@@ -55,18 +55,33 @@
 class StockMonitor(BaseModel):
     """Initiates ``StockMonitor`` object to handle members across modules.
 
     >>> StockMonitor
 
     """
 
-    user_info: Tuple[str, str, str, str, str, str] = ("ticker", "email", "max", "min", "correction", "repeat")
-    values: str = '(' + ','.join('?' for _ in user_info) + ')'
-    alerts: Tuple[str, str, str, str, str, str, str] = ("time", "ticker", "email", "max", "min", "correction", "repeat")
-    alert_values: str = '(' + ','.join('?' for _ in alerts) + ')'
+    user_info: Tuple[str, str, str, str, str, str] = (
+        "ticker",
+        "email",
+        "max",
+        "min",
+        "correction",
+        "repeat",
+    )
+    values: str = "(" + ",".join("?" for _ in user_info) + ")"
+    alerts: Tuple[str, str, str, str, str, str, str] = (
+        "time",
+        "ticker",
+        "email",
+        "max",
+        "min",
+        "correction",
+        "repeat",
+    )
+    alert_values: str = "(" + ",".join("?" for _ in alerts) + ")"
 
 
 stock_monitor = StockMonitor()
 
 
 class Trader(BaseModel):
     """Initiates ``Trader`` object to handle members across modules.
```

## jarvis/api/routers/basics.py

```diff
@@ -41,18 +41,24 @@
 
     Returns:
 
         FileResponse:
         Returns the favicon.ico file as FileResponse to support the front-end.
     """
     # This logger import should not be changed to make sure the path is detected using it
-    filepath = os.path.join(os.path.dirname(__file__), 'favicon.ico')
+    filepath = os.path.join(os.path.dirname(__file__), "favicon.ico")
     if os.path.exists(filepath):
-        return FileResponse(filename=os.path.basename(filepath), path=filepath, status_code=HTTPStatus.OK.real)
-    logger.warning("'favicon.ico' is missing or the path is messed up. Fix this to avoid errors in the UI")
+        return FileResponse(
+            filename=os.path.basename(filepath),
+            path=filepath,
+            status_code=HTTPStatus.OK.real,
+        )
+    logger.warning(
+        "'favicon.ico' is missing or the path is messed up. Fix this to avoid errors in the UI"
+    )
 
 
 @router.get(path="/keywords", dependencies=authenticator.OFFLINE_PROTECTOR)
 async def keywords():
     """Converts the keywords and conversations into a dictionary of key-value pairs.
 
     Returns:
```

## jarvis/api/routers/fileio.py

```diff
@@ -18,63 +18,105 @@
     """Get all YAML files from fileio and all log files from logs directory.
 
     Returns:
 
         Dict[str, List[str]]:
         Dictionary of files that can be downloaded or uploaded.
     """
-    return {**{"logs": [file_ for __path, __directory, __file in os.walk('logs') for file_ in __file]},
-            **{"fileio": [f for f in os.listdir(models.fileio.root) if f.endswith('.yaml')]},
-            **{"uploads": [f for f in os.listdir(models.fileio.uploads) if not f.startswith('.')]}}
-
-
-@router.get(path="/get-file", response_class=FileResponse, dependencies=authenticator.OFFLINE_PROTECTOR)
+    return {
+        **{
+            "logs": [
+                file_
+                for __path, __directory, __file in os.walk("logs")
+                for file_ in __file
+            ]
+        },
+        **{
+            "fileio": [f for f in os.listdir(models.fileio.root) if f.endswith(".yaml")]
+        },
+        **{
+            "uploads": [
+                f for f in os.listdir(models.fileio.uploads) if not f.startswith(".")
+            ]
+        },
+    }
+
+
+@router.get(
+    path="/get-file",
+    response_class=FileResponse,
+    dependencies=authenticator.OFFLINE_PROTECTOR,
+)
 async def get_file(filename: str):
     """Download a particular YAML file from fileio or log file from logs directory.
 
     Args:
 
         filename: Name of the file that has to be downloaded.
 
     Returns:
 
         FileResponse:
         Returns the FileResponse object of the file.
     """
     allowed_files = await list_files()
     if filename not in allowed_files["fileio"] + allowed_files["logs"]:
-        raise APIResponse(status_code=HTTPStatus.NOT_ACCEPTABLE.real,
-                          detail=f"{filename!r} is either unavailable or not allowed.\n"
-                                 f"Downloadable files:{allowed_files}")
+        raise APIResponse(
+            status_code=HTTPStatus.NOT_ACCEPTABLE.real,
+            detail=f"{filename!r} is either unavailable or not allowed.\n"
+            f"Downloadable files:{allowed_files}",
+        )
     if filename.endswith(".log"):
-        if path := [__path for __path, __directory, __file in os.walk("logs") if filename in __file]:
+        if path := [
+            __path
+            for __path, __directory, __file in os.walk("logs")
+            if filename in __file
+        ]:
             target_file = os.path.join(path[0], filename)
         else:
             logger.critical("ATTENTION::'%s' wasn't found.", filename)
-            raise APIResponse(status_code=HTTPStatus.NOT_FOUND.real, detail=HTTPStatus.NOT_FOUND.phrase)
+            raise APIResponse(
+                status_code=HTTPStatus.NOT_FOUND.real,
+                detail=HTTPStatus.NOT_FOUND.phrase,
+            )
     else:
         target_file = os.path.join(models.fileio.root, filename)
     logger.info("Requested file: '%s' for download.", filename)
-    return FileResponse(status_code=HTTPStatus.OK.real, path=target_file, media_type="text/yaml", filename=filename)
+    return FileResponse(
+        status_code=HTTPStatus.OK.real,
+        path=target_file,
+        media_type="text/yaml",
+        filename=filename,
+    )
 
 
 @router.post(path="/put-file", dependencies=authenticator.OFFLINE_PROTECTOR)
 async def put_file(file: UploadFile):
     """Upload a particular YAML file to the fileio directory.
 
     Args:
 
         file: Takes the UploadFile object as an argument.
     """
     logger.info("Requested file: '%s' for upload.", file.filename)
     content = await file.read()
     allowed_files = await list_files()
     if file.filename not in allowed_files["fileio"]:
-        with open(os.path.join(models.fileio.uploads,
-                               f"{datetime.now().strftime('%d_%B_%Y-%I_%M_%p')}-{file.filename}"), "wb") as f_stream:
+        with open(
+            os.path.join(
+                models.fileio.uploads,
+                f"{datetime.now().strftime('%d_%B_%Y-%I_%M_%p')}-{file.filename}",
+            ),
+            "wb",
+        ) as f_stream:
             f_stream.write(content)
-        raise APIResponse(status_code=HTTPStatus.ACCEPTED.real,
-                          detail=f"{file.filename!r} is not allowed for an update.\n"
-                                 "Hence storing as a standalone file.")
+        raise APIResponse(
+            status_code=HTTPStatus.ACCEPTED.real,
+            detail=f"{file.filename!r} is not allowed for an update.\n"
+            "Hence storing as a standalone file.",
+        )
     with open(os.path.join(models.fileio.root, file.filename), "wb") as f_stream:
         f_stream.write(content)
-    raise APIResponse(status_code=HTTPStatus.OK.real, detail=f"{file.filename!r} was uploaded to {models.fileio.root}.")
+    raise APIResponse(
+        status_code=HTTPStatus.OK.real,
+        detail=f"{file.filename!r} was uploaded to {models.fileio.root}.",
+    )
```

## jarvis/api/routers/investment.py

```diff
@@ -9,24 +9,25 @@
 import jinja2
 from fastapi import APIRouter, Request
 from fastapi.responses import HTMLResponse
 
 from jarvis.api.logger import logger
 from jarvis.api.models import authenticator, settings
 from jarvis.api.squire import timeout_otp
-from jarvis.modules.exceptions import (CONDITIONAL_ENDPOINT_RESTRICTION,
-                                       APIResponse)
+from jarvis.modules.exceptions import CONDITIONAL_ENDPOINT_RESTRICTION, APIResponse
 from jarvis.modules.models import models
 from jarvis.modules.templates import templates
 from jarvis.modules.utils import support, util
 
 router = APIRouter()
 
 
-@router.post(path="/robinhood-authenticate", dependencies=authenticator.ROBINHOOD_PROTECTOR)
+@router.post(
+    path="/robinhood-authenticate", dependencies=authenticator.ROBINHOOD_PROTECTOR
+)
 async def authenticate_robinhood():
     """Authenticates the request and generates single use token.
 
     Raises:
 
         APIResponse:
         - 200: If initial auth is successful and single use token is successfully sent via email.
@@ -36,41 +37,61 @@
 
         If basic auth (stored as an env var robinhood_endpoint_auth) succeeds:
 
         - Sends a token for MFA via email.
         - Also stores the token in the Robinhood object which is verified in the /investment endpoint.
         - The token is nullified in the object as soon as it is verified, making it single use.
     """
-    if not all([models.env.robinhood_user, models.env.robinhood_pass,
-                models.env.robinhood_pass, models.env.robinhood_endpoint_auth]):
+    if not all(
+        [
+            models.env.robinhood_user,
+            models.env.robinhood_pass,
+            models.env.robinhood_pass,
+            models.env.robinhood_endpoint_auth,
+        ]
+    ):
         raise CONDITIONAL_ENDPOINT_RESTRICTION
     reset_timeout = 300
-    timeout_in = support.pluralize(count=util.format_nos(input_=reset_timeout / 60), word="minute")
-    mail_obj = gmailconnector.SendEmail(gmail_user=models.env.open_gmail_user,
-                                        gmail_pass=models.env.open_gmail_pass)
+    timeout_in = support.pluralize(
+        count=util.format_nos(input_=reset_timeout / 60), word="minute"
+    )
+    mail_obj = gmailconnector.SendEmail(
+        gmail_user=models.env.open_gmail_user, gmail_pass=models.env.open_gmail_pass
+    )
     auth_stat = mail_obj.authenticate
     if not auth_stat.ok:
-        raise APIResponse(status_code=HTTPStatus.SERVICE_UNAVAILABLE.real, detail=auth_stat.body)
+        raise APIResponse(
+            status_code=HTTPStatus.SERVICE_UNAVAILABLE.real, detail=auth_stat.body
+        )
     settings.robinhood.token = util.keygen_uuid(length=16)
-    rendered = jinja2.Template(templates.email.one_time_passcode).render(TIMEOUT=timeout_in,
-                                                                         ENDPOINT="robinhood",
-                                                                         EMAIL=models.env.recipient,
-                                                                         TOKEN=settings.robinhood.token)
-    mail_stat = mail_obj.send_email(recipient=models.env.recipient, sender='Jarvis API',
-                                    subject=f"Robinhood Token - {datetime.now().strftime('%c')}",
-                                    html_body=rendered)
+    rendered = jinja2.Template(templates.email.one_time_passcode).render(
+        TIMEOUT=timeout_in,
+        ENDPOINT="robinhood",
+        EMAIL=models.env.recipient,
+        TOKEN=settings.robinhood.token,
+    )
+    mail_stat = mail_obj.send_email(
+        recipient=models.env.recipient,
+        sender="Jarvis API",
+        subject=f"Robinhood Token - {datetime.now().strftime('%c')}",
+        html_body=rendered,
+    )
     if mail_stat.ok:
         logger.debug(mail_stat.body)
         logger.info("Token will be reset in %s", timeout_in)
         Timer(function=timeout_otp.reset_robinhood, interval=reset_timeout).start()
-        raise APIResponse(status_code=HTTPStatus.OK.real,
-                          detail="Authentication success. Please enter the OTP sent via email:")
+        raise APIResponse(
+            status_code=HTTPStatus.OK.real,
+            detail="Authentication success. Please enter the OTP sent via email:",
+        )
     else:
         logger.error(mail_stat.json())
-        raise APIResponse(status_code=HTTPStatus.SERVICE_UNAVAILABLE.real, detail=mail_stat.body)
+        raise APIResponse(
+            status_code=HTTPStatus.SERVICE_UNAVAILABLE.real, detail=mail_stat.body
+        )
 
 
 @router.get(path="/investment", response_class=HTMLResponse)
 async def robinhood_path(request: Request, token: str = None):
     """Serves static file.
 
     Args:
@@ -95,30 +116,54 @@
         - This endpoint is secured behind single use token sent via email as MFA (Multi-Factor Authentication)
         - Initial check is done by the function authenticate_robinhood behind the path "/robinhood-authenticate"
         - Once the auth succeeds, a one-time usable hex-uuid is generated and stored in the Robinhood object.
         - This UUID is sent via email to the env var RECIPIENT, which should be entered as query string.
         - The UUID is deleted from the object as soon as the argument is checked for the first time.
         - Page refresh is useless because the value in memory is cleared as soon as it is authed once.
     """
-    logger.debug("Connection received from %s via %s using %s" %
-                 (request.client.host, request.headers.get('host'), request.headers.get('user-agent')))
-
-    if not all([models.env.robinhood_user, models.env.robinhood_pass,
-                models.env.robinhood_pass, models.env.robinhood_endpoint_auth]):
+    logger.debug(
+        "Connection received from %s via %s using %s"
+        % (
+            request.client.host,
+            request.headers.get("host"),
+            request.headers.get("user-agent"),
+        )
+    )
+
+    if not all(
+        [
+            models.env.robinhood_user,
+            models.env.robinhood_pass,
+            models.env.robinhood_pass,
+            models.env.robinhood_endpoint_auth,
+        ]
+    ):
         raise CONDITIONAL_ENDPOINT_RESTRICTION
 
     if not token:
-        raise APIResponse(status_code=HTTPStatus.UNAUTHORIZED.real,
-                          detail=HTTPStatus.UNAUTHORIZED.phrase)
+        raise APIResponse(
+            status_code=HTTPStatus.UNAUTHORIZED.real,
+            detail=HTTPStatus.UNAUTHORIZED.phrase,
+        )
     # token might be present because its added as headers but robinhood.token will be cleared after one time auth
-    if settings.robinhood.token and secrets.compare_digest(token, settings.robinhood.token):
+    if settings.robinhood.token and secrets.compare_digest(
+        token, settings.robinhood.token
+    ):
         settings.robinhood.token = None
         if not os.path.isfile(models.fileio.robinhood):
-            raise APIResponse(status_code=HTTPStatus.NOT_FOUND.real, detail='Static file was not found on server.')
+            raise APIResponse(
+                status_code=HTTPStatus.NOT_FOUND.real,
+                detail="Static file was not found on server.",
+            )
         with open(models.fileio.robinhood) as static_file:
             html_content = static_file.read()
         content_type, _ = mimetypes.guess_type(html_content)
-        return HTMLResponse(status_code=HTTPStatus.TEMPORARY_REDIRECT.real,
-                            content=html_content, media_type=content_type)  # serves as a static webpage
+        return HTMLResponse(
+            status_code=HTTPStatus.TEMPORARY_REDIRECT.real,
+            content=html_content,
+            media_type=content_type,
+        )  # serves as a static webpage
     else:
-        raise APIResponse(status_code=HTTPStatus.EXPECTATION_FAILED.real,
-                          detail='Requires authentication since endpoint uses single-use token.')
+        raise APIResponse(
+            status_code=HTTPStatus.EXPECTATION_FAILED.real,
+            detail="Requires authentication since endpoint uses single-use token.",
+        )
```

## jarvis/api/routers/offline.py

```diff
@@ -1,22 +1,20 @@
 import imghdr
 import os
 import traceback
 from http import HTTPStatus
 from threading import Thread
-from typing import Union
 
 from fastapi import APIRouter, Request
 from fastapi.responses import FileResponse
 
 from jarvis.api.logger import logger
 from jarvis.api.models import authenticator, modals
 from jarvis.api.routers import speech_synthesis
-from jarvis.executors import (commander, offline, others, restrictions,
-                              word_match)
+from jarvis.executors import commander, offline, others, restrictions, word_match
 from jarvis.modules.audio import tts_stt
 from jarvis.modules.conditions import keywords
 from jarvis.modules.database import database
 from jarvis.modules.exceptions import APIResponse, InvalidArgument
 from jarvis.modules.models import models
 from jarvis.modules.utils import support
 
@@ -24,50 +22,70 @@
 db = database.Database(database=models.fileio.base_db)
 
 
 def kill_power() -> None:
     """Inserts a flag into stopper table in base database."""
     with db.connection:
         cursor = db.connection.cursor()
-        cursor.execute("INSERT or REPLACE INTO stopper (flag, caller) VALUES (?,?);", (True, 'FastAPI'))
+        cursor.execute(
+            "INSERT or REPLACE INTO stopper (flag, caller) VALUES (?,?);",
+            (True, "FastAPI"),
+        )
         cursor.connection.commit()
 
 
-async def process_ok_response(response: str, input_data: modals.OfflineCommunicatorModal) -> Union[bytes, FileResponse]:
+async def process_ok_response(
+    response: str, input_data: modals.OfflineCommunicatorModal
+) -> bytes | FileResponse:
     """Processes responses for 200 messages. Response is framed as synthesized or native based on input data.
 
     Args:
         response: Takes the response as text.
         input_data: Input data modal.
 
     Returns:
-        Union[bytes, FileResponse]:
+        bytes | FileResponse:
         FileResponse in case of native audio or bytes in case of speech synthesized response.
     """
     if input_data.speech_timeout:
         logger.info("Storing response as %s", models.fileio.speech_synthesis_wav)
-        if binary := await speech_synthesis.speech_synthesis(input_data=modals.SpeechSynthesisModal(
-                text=response, timeout=input_data.speech_timeout, quality="low"  # low quality to speed up response
-        ), raise_for_status=False):
+        if binary := await speech_synthesis.speech_synthesis(
+            input_data=modals.SpeechSynthesisModal(
+                text=response,
+                timeout=input_data.speech_timeout,
+                quality="low",  # low quality to speed up response
+            ),
+            raise_for_status=False,
+        ):
             return binary
         else:
             input_data.native_audio = True  # try native voice if SpeechSynthesis fails
     if input_data.native_audio:
         if native_audio_wav := tts_stt.text_to_audio(text=response):
             logger.info("Storing response as %s in native audio.", native_audio_wav)
-            Thread(target=support.remove_file, kwargs={'delay': 2, 'filepath': native_audio_wav}, daemon=True).start()
-            return FileResponse(path=native_audio_wav, media_type='application/octet-stream',
-                                filename="synthesized.wav", status_code=HTTPStatus.OK.real)
+            Thread(
+                target=support.remove_file,
+                kwargs={"delay": 2, "filepath": native_audio_wav},
+                daemon=True,
+            ).start()
+            return FileResponse(
+                path=native_audio_wav,
+                media_type="application/octet-stream",
+                filename="synthesized.wav",
+                status_code=HTTPStatus.OK.real,
+            )
         logger.error("Failed to generate audio file in native voice.")
     # Send response as text if requested so or if all other options fail
     raise APIResponse(status_code=HTTPStatus.OK.real, detail=response)
 
 
 @router.post(path="/offline-communicator", dependencies=authenticator.OFFLINE_PROTECTOR)
-async def offline_communicator_api(request: Request, input_data: modals.OfflineCommunicatorModal):
+async def offline_communicator_api(
+    request: Request, input_data: modals.OfflineCommunicatorModal
+):
     """Offline Communicator API endpoint for Jarvis.
 
     Args:
 
         - request: Takes the Request class as an argument.
         - input_data: Takes the following arguments as an ``OfflineCommunicatorModal`` object.
 
@@ -82,75 +100,118 @@
         - 204: If empty command was received.
 
     Returns:
 
         FileResponse:
         Returns the audio file as a response if the output is requested as audio.
     """
-    logger.debug("Connection received from %s via %s using %s",
-                 request.client.host, request.headers.get('host'), request.headers.get('user-agent'))
+    logger.debug(
+        "Connection received from %s via %s using %s",
+        request.client.host,
+        request.headers.get("host"),
+        request.headers.get("user-agent"),
+    )
     if not (command := input_data.command.strip()):
-        raise APIResponse(status_code=HTTPStatus.NO_CONTENT.real, detail=HTTPStatus.NO_CONTENT.phrase)
+        raise APIResponse(
+            status_code=HTTPStatus.NO_CONTENT.real, detail=HTTPStatus.NO_CONTENT.phrase
+        )
 
     logger.info("Request: %s", command)
-    if command.lower() == 'test':
+    if command.lower() == "test":
         logger.info("Test message received.")
-        raise APIResponse(status_code=HTTPStatus.OK.real, detail="Test message received.")
-
-    if word_match.word_match(phrase=command, match_list=keywords.keywords['kill']) and 'override' in command.lower():
+        raise APIResponse(
+            status_code=HTTPStatus.OK.real, detail="Test message received."
+        )
+
+    if (
+        word_match.word_match(phrase=command, match_list=keywords.keywords["kill"])
+        and "override" in command.lower()
+    ):
         logger.info("STOP override has been requested.")
         Thread(target=kill_power).start()
-        return await process_ok_response(response=f"Shutting down now {models.env.title}!\n{support.exit_message()}",
-                                         input_data=input_data)
-
-    if word_match.word_match(phrase=command, match_list=keywords.keywords['restrictions']):
+        return await process_ok_response(
+            response=f"Shutting down now {models.env.title}!\n{support.exit_message()}",
+            input_data=input_data,
+        )
+
+    if word_match.word_match(
+        phrase=command, match_list=keywords.keywords["restrictions"]
+    ):
         try:
-            raise APIResponse(status_code=HTTPStatus.OK.real,
-                              detail=restrictions.handle_restrictions(phrase=command))
+            raise APIResponse(
+                status_code=HTTPStatus.OK.real,
+                detail=restrictions.handle_restrictions(phrase=command),
+            )
         except InvalidArgument as error:
-            raise APIResponse(status_code=HTTPStatus.BAD_REQUEST.real, detail=error.__str__())
-    if word_match.word_match(phrase=command, match_list=keywords.keywords['secrets']) and \
-            word_match.word_match(phrase=command, match_list=('list', 'get', 'send', 'create', 'share')):
+            raise APIResponse(
+                status_code=HTTPStatus.BAD_REQUEST.real, detail=error.__str__()
+            )
+    if word_match.word_match(
+        phrase=command, match_list=keywords.keywords["secrets"]
+    ) and word_match.word_match(
+        phrase=command, match_list=("list", "get", "send", "create", "share")
+    ):
         response = others.secrets(phrase=command)
         if len(response.split()) == 1:
-            response = "The secret requested can be accessed from 'secure-send' endpoint using the token below.\n" \
-                       "Note that the secret cannot be retrieved again using the same token and the token will " \
-                       f"expire in 5 minutes.\n\n{response}"
+            response = (
+                "The secret requested can be accessed from 'secure-send' endpoint using the token below.\n"
+                "Note that the secret cannot be retrieved again using the same token and the token will "
+                f"expire in 5 minutes.\n\n{response}"
+            )
         else:
             logger.error("Response: %s", response)
         raise APIResponse(status_code=HTTPStatus.OK.real, detail=response)
 
-    if 'alarm' in command.lower() or 'remind' in command.lower():
+    if "alarm" in command.lower() or "remind" in command.lower():
         command = command.lower()
-    if ' and ' in command and not word_match.word_match(phrase=command, match_list=keywords.ignore_and):
-        and_phrases = command.split(' and ')
+    if " and " in command and not word_match.word_match(
+        phrase=command, match_list=keywords.ignore_and
+    ):
+        and_phrases = command.split(" and ")
         logger.info("Looping through %s in iterations.", and_phrases)
         and_response = ""
         for each in and_phrases:
             try:
                 and_response += f"{offline.offline_communicator(command=each)}\n"
             except Exception as error:
                 logger.error(error)
                 logger.error(traceback.format_exc())
                 and_response += error.__str__()
         logger.info("Response: %s", and_response.strip())
         return await process_ok_response(response=and_response, input_data=input_data)
 
-    if ' after ' in command.lower() and not word_match.word_match(phrase=command, match_list=keywords.ignore_after):
+    if " after " in command.lower() and not word_match.word_match(
+        phrase=command, match_list=keywords.ignore_after
+    ):
         if delay_info := commander.timed_delay(phrase=command):
-            logger.info("%s will be executed after %s", delay_info[0], support.time_converter(second=delay_info[1]))
-            return await process_ok_response(response='I will execute it after '
-                                                      f'{support.time_converter(second=delay_info[1])} '
-                                                      f'{models.env.title}!', input_data=input_data)
+            logger.info(
+                "%s will be executed after %s",
+                delay_info[0],
+                support.time_converter(second=delay_info[1]),
+            )
+            return await process_ok_response(
+                response="I will execute it after "
+                f"{support.time_converter(second=delay_info[1])} "
+                f"{models.env.title}!",
+                input_data=input_data,
+            )
     try:
         response = offline.offline_communicator(command=command)
     except Exception as error:
         logger.error(error)
         logger.error(traceback.format_exc())
         response = error.__str__()
     logger.info("Response: %s", response)
-    if os.path.isfile(response) and response.endswith('.jpg'):
+    if os.path.isfile(response) and response.endswith(".jpg"):
         logger.info("Response received as a file.")
-        Thread(target=support.remove_file, kwargs={'delay': 2, 'filepath': response}, daemon=True).start()
-        return FileResponse(path=response, media_type=f'image/{imghdr.what(file=response)}',
-                            filename=os.path.basename(response), status_code=HTTPStatus.OK.real)
+        Thread(
+            target=support.remove_file,
+            kwargs={"delay": 2, "filepath": response},
+            daemon=True,
+        ).start()
+        return FileResponse(
+            path=response,
+            media_type=f"image/{imghdr.what(file=response)}",
+            filename=os.path.basename(response),
+            status_code=HTTPStatus.OK.real,
+        )
     return await process_ok_response(response=response, input_data=input_data)
```

## jarvis/api/routers/secure_send.py

```diff
@@ -23,27 +23,43 @@
     Raises:
 
         - 200: For a successful authentication (secret will be returned)
         - 400: For a bad request if headers are passed with underscore
         - 401: For a failed authentication (if the access token doesn't match)
         - 404: If the ``secure_send`` mapping file is unavailable
     """
-    logger.info("Connection received from %s via %s using %s",
-                request.client.host, request.headers.get('host'), request.headers.get('user-agent'))
-    key = access_token or request.headers.get('access-token')
+    logger.info(
+        "Connection received from %s via %s using %s",
+        request.client.host,
+        request.headers.get("host"),
+        request.headers.get("user-agent"),
+    )
+    key = access_token or request.headers.get("access-token")
     if not key:
         logger.warning("'access-token' not received in headers")
-        raise APIResponse(status_code=HTTPStatus.UNAUTHORIZED.real, detail=HTTPStatus.UNAUTHORIZED.phrase)
-    if key.startswith('\\'):
+        raise APIResponse(
+            status_code=HTTPStatus.UNAUTHORIZED.real,
+            detail=HTTPStatus.UNAUTHORIZED.phrase,
+        )
+    if key.startswith("\\"):
         key = bytes(key, "utf-8").decode(encoding="unicode_escape")
     if os.path.isfile(models.fileio.secure_send):
         secure_strings = files.get_secure_send()
         if secret := secure_strings.get(key):
             logger.info("secret was accessed using secure token, deleting secret")
             files.delete_secure_send(key)
             raise APIResponse(status_code=HTTPStatus.OK.real, detail=secret)
         else:
-            logger.info("secret access was denied for key: %s, available keys: %s", key, [*secure_strings.keys()])
-            raise APIResponse(status_code=HTTPStatus.UNAUTHORIZED.real, detail=HTTPStatus.UNAUTHORIZED.phrase)
+            logger.info(
+                "secret access was denied for key: %s, available keys: %s",
+                key,
+                [*secure_strings.keys()],
+            )
+            raise APIResponse(
+                status_code=HTTPStatus.UNAUTHORIZED.real,
+                detail=HTTPStatus.UNAUTHORIZED.phrase,
+            )
     else:
         logger.info("'%s' not found", models.fileio.secure_send)
-        raise APIResponse(status_code=HTTPStatus.NOT_FOUND.real, detail=HTTPStatus.NOT_FOUND.phrase)
+        raise APIResponse(
+            status_code=HTTPStatus.NOT_FOUND.real, detail=HTTPStatus.NOT_FOUND.phrase
+        )
```

## jarvis/api/routers/speech_synthesis.py

```diff
@@ -13,47 +13,62 @@
 from jarvis.modules.exceptions import APIResponse, EgressErrors
 from jarvis.modules.models import models
 from jarvis.modules.utils import support
 
 router = APIRouter()
 
 
-@router.get(path='/speech-synthesis-voices', dependencies=authenticator.OFFLINE_PROTECTOR)
+@router.get(
+    path="/speech-synthesis-voices", dependencies=authenticator.OFFLINE_PROTECTOR
+)
 async def speech_synthesis_voices():
     """Get all available voices in speech synthesis.
 
     Raises:
 
         - 200: If call to speech synthesis endpoint was successful.
         - 500: If call to speech synthesis fails.
     """
     try:
         response = requests.get(
-            url=f"http://{models.env.speech_synthesis_host}:{models.env.speech_synthesis_port}/api/voices", timeout=3
+            url=f"http://{models.env.speech_synthesis_host}:{models.env.speech_synthesis_port}/api/voices",
+            timeout=3,
         )
     except EgressErrors as error:
         logger.error(error)
-        raise APIResponse(status_code=HTTPStatus.INTERNAL_SERVER_ERROR.real, detail=str(error))
+        raise APIResponse(
+            status_code=HTTPStatus.INTERNAL_SERVER_ERROR.real, detail=str(error)
+        )
     if response.ok:
         try:
             json_response = response.json()
         except JSONDecodeError as error:
             logger.error(error)
-            raise APIResponse(status_code=HTTPStatus.INTERNAL_SERVER_ERROR.real, detail=str(error))
-        available_voices = [value.get('id').replace('/', '_') for key, value in json_response.items()]
+            raise APIResponse(
+                status_code=HTTPStatus.INTERNAL_SERVER_ERROR.real, detail=str(error)
+            )
+        available_voices = [
+            value.get("id").replace("/", "_") for key, value in json_response.items()
+        ]
         logger.info("Available voices: %d", len(available_voices))
         logger.debug(available_voices)
         raise APIResponse(status_code=HTTPStatus.OK.real, detail=available_voices)
     else:
         logger.error(response.content)
         raise APIResponse(status_code=response.status_code, detail=response.content)
 
 
-@router.post(path='/speech-synthesis', response_class=FileResponse, dependencies=authenticator.OFFLINE_PROTECTOR)
-async def speech_synthesis(input_data: modals.SpeechSynthesisModal, raise_for_status: bool = True):
+@router.post(
+    path="/speech-synthesis",
+    response_class=FileResponse,
+    dependencies=authenticator.OFFLINE_PROTECTOR,
+)
+async def speech_synthesis(
+    input_data: modals.SpeechSynthesisModal, raise_for_status: bool = True
+):
     """Process request to convert text to speech if docker container is running.
 
     Args:
 
         - input_data: Takes the following arguments as GetText class instead of a QueryString.
         - raise_for_status: Takes a boolean flag to determine whether the result should be raised as an API response.
 
@@ -71,29 +86,47 @@
 
     Returns:
 
         FileResponse:
         Audio file to be downloaded.
     """
     if not (text := input_data.text.strip()):
-        logger.error('Empty requests cannot be processed.')
+        logger.error("Empty requests cannot be processed.")
         if raise_for_status:
-            raise APIResponse(status_code=HTTPStatus.NO_CONTENT.real, detail=HTTPStatus.NO_CONTENT.phrase)
+            raise APIResponse(
+                status_code=HTTPStatus.NO_CONTENT.real,
+                detail=HTTPStatus.NO_CONTENT.phrase,
+            )
         else:
             return
-    if not speaker.speech_synthesizer(text=text, timeout=input_data.timeout or len(text), quality=input_data.quality,
-                                      voice=input_data.voice):
+    if not speaker.speech_synthesizer(
+        text=text,
+        timeout=input_data.timeout or len(text),
+        quality=input_data.quality,
+        voice=input_data.voice,
+    ):
         logger.error("Speech synthesis could not process the request.")
         if raise_for_status:
-            raise APIResponse(status_code=HTTPStatus.INTERNAL_SERVER_ERROR.real,
-                              detail=HTTPStatus.INTERNAL_SERVER_ERROR.phrase)
+            raise APIResponse(
+                status_code=HTTPStatus.INTERNAL_SERVER_ERROR.real,
+                detail=HTTPStatus.INTERNAL_SERVER_ERROR.phrase,
+            )
         else:
             return
     if os.path.isfile(path=models.fileio.speech_synthesis_wav):
         logger.debug("Speech synthesis file generated for '%s'", text)
-        Thread(target=support.remove_file, kwargs={'delay': 2, 'filepath': models.fileio.speech_synthesis_wav},
-               daemon=True).start()
-        return FileResponse(path=models.fileio.speech_synthesis_wav, media_type='application/octet-stream',
-                            filename="synthesized.wav", status_code=HTTPStatus.OK.real)
+        Thread(
+            target=support.remove_file,
+            kwargs={"delay": 2, "filepath": models.fileio.speech_synthesis_wav},
+            daemon=True,
+        ).start()
+        return FileResponse(
+            path=models.fileio.speech_synthesis_wav,
+            media_type="application/octet-stream",
+            filename="synthesized.wav",
+            status_code=HTTPStatus.OK.real,
+        )
     logger.error("File Not Found: %s", models.fileio.speech_synthesis_wav)
     if raise_for_status:
-        raise APIResponse(status_code=HTTPStatus.NOT_FOUND.real, detail=HTTPStatus.NOT_FOUND.phrase)
+        raise APIResponse(
+            status_code=HTTPStatus.NOT_FOUND.real, detail=HTTPStatus.NOT_FOUND.phrase
+        )
```

## jarvis/api/routers/stock_analysis.py

```diff
@@ -25,26 +25,33 @@
         - data_dict: Boolean flag to receive tickers as a dictionary with the ORG names. Applies only for `all` symbol.
     """
     symbol = symbol.strip().upper()
     logger.info("Received request for '%s'", symbol)
     if symbol == "ALL":
         if settings.trader.stock_list:
             if data_dict:
-                raise APIResponse(status_code=HTTPStatus.OK.real, detail=settings.trader.stock_list)
-            raise APIResponse(status_code=HTTPStatus.OK.real, detail=json.dumps(settings.trader.stock_list))
+                raise APIResponse(
+                    status_code=HTTPStatus.OK.real, detail=settings.trader.stock_list
+                )
+            raise APIResponse(
+                status_code=HTTPStatus.OK.real,
+                detail=json.dumps(settings.trader.stock_list),
+            )
             # TODO: repeated URL errors, no luck with traditional loop
             # thread_worker(function_to_call=get_signals_per_ticker)
             # result = {
             #     k: '\n'.join(v) for k, v in settings.trader.result.items()
             # }
             # logger.info(result)
             # raise APIResponse(status_code=HTTPStatus.OK.real, detail=result)
         else:
-            raise APIResponse(status_code=HTTPStatus.SERVICE_UNAVAILABLE.real,
-                              detail="Unable to process all tickers at the moment.")
+            raise APIResponse(
+                status_code=HTTPStatus.SERVICE_UNAVAILABLE.real,
+                detail="Unable to process all tickers at the moment.",
+            )
     get_signals_per_ticker(symbol=symbol, bar_count=bar_count)
 
 
 def thread_worker(function_to_call: Callable) -> None:
     """Initiates ``ThreadPoolExecutor`` with in a dedicated thread.
 
     Args:
@@ -55,18 +62,24 @@
     with executor:
         for iterator in settings.trader.stock_list:
             future = executor.submit(function_to_call, iterator)
             futures[future] = iterator
 
     for future in as_completed(futures):
         if future.exception():
-            logger.error("Thread processing for '%s' received an exception: %s", iterator, future.exception())
+            logger.error(
+                "Thread processing for '%s' received an exception: %s",
+                iterator,
+                future.exception(),
+            )
 
 
-def get_signals_per_ticker(symbol: str, bar_count: int = 100, all_tickers: bool = False):
+def get_signals_per_ticker(
+    symbol: str, bar_count: int = 100, all_tickers: bool = False
+):
     """Get buy, sell and hold signals for a particular stock.
 
     Args:
 
         symbol: Stock ticker.
         bar_count: Number of bars from webull.
         all_tickers: Boolean flag to get signals for all tickers.
@@ -81,85 +94,102 @@
     References:
 
         `https://github.com/thevickypedia/trading-algorithm <https://github.com/thevickypedia/trading-algorithm>`__
 
     """
     # Fetch historical stock data using the 'get_bars' method from the 'webull' package
     try:
-        bars = paper_webull().get_bars(stock=symbol, interval='d', count=bar_count)
+        bars = paper_webull().get_bars(stock=symbol, interval="d", count=bar_count)
     except ValueError as error:
         logger.error(f"{symbol} - {error.__str__()}")
         if all_tickers:
             return
         raise APIResponse(status_code=HTTPStatus.NOT_FOUND.real, detail=error.__str__())
     except Exception as error:
         logger.error(f"{symbol} - {error.__str__()}")
         logger.error(type(error))
         if all_tickers:
             return
-        raise APIResponse(status_code=HTTPStatus.BAD_REQUEST.real, detail=error.__str__())
+        raise APIResponse(
+            status_code=HTTPStatus.BAD_REQUEST.real, detail=error.__str__()
+        )
 
     # Create a DataFrame from the fetched data
     stock_data = pandas.DataFrame(bars)
 
     # Calculate short-term (e.g., 20-day) and long-term (e.g., 50-day) moving averages
-    stock_data['SMA_short'] = stock_data['close'].rolling(window=20).mean()
-    stock_data['SMA_long'] = stock_data['close'].rolling(window=50).mean()
+    stock_data["SMA_short"] = stock_data["close"].rolling(window=20).mean()
+    stock_data["SMA_long"] = stock_data["close"].rolling(window=50).mean()
 
     # Generate the buy, sell, and hold signals
-    stock_data['buy'] = stock_data['SMA_short'] > stock_data['SMA_long']
-    stock_data['sell'] = stock_data['SMA_short'] < stock_data['SMA_long']
-    stock_data['hold'] = ~(stock_data['buy'] | stock_data['sell'])
+    stock_data["buy"] = stock_data["SMA_short"] > stock_data["SMA_long"]
+    stock_data["sell"] = stock_data["SMA_short"] < stock_data["SMA_long"]
+    stock_data["hold"] = ~(stock_data["buy"] | stock_data["sell"])
 
     # Filter and display the buy, sell, and holds
-    buy_signals = stock_data[stock_data['buy']]
-    sell_signals = stock_data[stock_data['sell']]
-    hold_signals = stock_data[stock_data['hold']]
+    buy_signals = stock_data[stock_data["buy"]]
+    sell_signals = stock_data[stock_data["sell"]]
+    hold_signals = stock_data[stock_data["hold"]]
 
     buy_signals_timestamped = {
         pandas.Timestamp(timestamp).to_pydatetime(): "Buy"
         for timestamp in buy_signals.index.values
     }
     sell_signals_timestamped = {
         pandas.Timestamp(timestamp).to_pydatetime(): "Sell"
         for timestamp in sell_signals.index.values
     }
     hold_signals_timestamped = {
         pandas.Timestamp(timestamp).to_pydatetime(): "Hold"
         for timestamp in hold_signals.index.values
     }
 
-    all_signals = dict(sorted(
-        {**buy_signals_timestamped, **sell_signals_timestamped, **hold_signals_timestamped}.items(),
-        key=lambda x: x[0].timestamp()
-    ))
+    all_signals = dict(
+        sorted(
+            {
+                **buy_signals_timestamped,
+                **sell_signals_timestamped,
+                **hold_signals_timestamped,
+            }.items(),
+            key=lambda x: x[0].timestamp(),
+        )
+    )
 
     all_signals_ct = len(all_signals)
     assessment = {
         "Buy": round(len(buy_signals) / all_signals_ct * 100, 2),
         "Sell": round(len(sell_signals) / all_signals_ct * 100, 2),
-        "Hold": round(len(hold_signals) / all_signals_ct * 100, 2)
+        "Hold": round(len(hold_signals) / all_signals_ct * 100, 2),
     }
 
     if all_tickers:
-        settings.trader.result[max(assessment, key=assessment.get).upper()].append(symbol)
+        settings.trader.result[max(assessment, key=assessment.get).upper()].append(
+            symbol
+        )
         return
 
     extras = ""
     for key, value in assessment.items():
         logger.debug(f"{key} Signals: {value}%")
         extras += f"{key} Signals: {value}%\n"
 
     raw_details = webull().get_quote(symbol)
-    price = raw_details.get("last_trade_price") or raw_details.get("pPrice") or \
-        raw_details.get("open") or raw_details.get("close") or raw_details.get("preClose")
-    quote = (round(float(price), 2))
+    price = (
+        raw_details.get("last_trade_price")
+        or raw_details.get("pPrice")
+        or raw_details.get("open")
+        or raw_details.get("close")
+        or raw_details.get("preClose")
+    )
+    quote = round(float(price), 2)
     if settings.trader.stock_list.get(symbol):
         stock = f"{settings.trader.stock_list[symbol]} - [{symbol}] with a current price of ${quote}"
     else:
         stock = f"{symbol} with a current price of ${quote}"
 
     logger.info("%s is a %s", stock, max(assessment, key=assessment.get).upper())
 
-    raise APIResponse(status_code=HTTPStatus.OK.real,
-                      detail=f"{stock} is a {max(assessment, key=assessment.get).upper()}\n"
-                             f"\n{extras}")
+    raise APIResponse(
+        status_code=HTTPStatus.OK.real,
+        detail=f"{stock} is a {max(assessment, key=assessment.get).upper()}\n"
+        f"\n{extras}",
+    )
```

## jarvis/api/routers/stock_monitor.py

```diff
@@ -32,39 +32,60 @@
         reset_timeout: Seconds after which the token has to expire.
 
     Raises:
 
         - 200: If email delivery was successful.
         - 503: If failed to send an email.
     """
-    timeout_in = support.pluralize(count=util.format_nos(input_=reset_timeout / 60), word="minute")
-    mail_obj = gmailconnector.SendEmail(gmail_user=models.env.open_gmail_user, gmail_pass=models.env.open_gmail_pass)
+    timeout_in = support.pluralize(
+        count=util.format_nos(input_=reset_timeout / 60), word="minute"
+    )
+    mail_obj = gmailconnector.SendEmail(
+        gmail_user=models.env.open_gmail_user, gmail_pass=models.env.open_gmail_pass
+    )
     logger.info("Sending stock monitor token as OTP")
     settings.stock_monitor_helper.otp_sent[email_address] = util.keygen_uuid(length=16)
     rendered = jinja2.Template(templates.email.one_time_passcode).render(
-        TIMEOUT=timeout_in, ENDPOINT="stock-monitor", EMAIL=email_address,
-        TOKEN=settings.stock_monitor_helper.otp_sent[email_address]
+        TIMEOUT=timeout_in,
+        ENDPOINT="stock-monitor",
+        EMAIL=email_address,
+        TOKEN=settings.stock_monitor_helper.otp_sent[email_address],
+    )
+    mail_stat = mail_obj.send_email(
+        recipient=email_address,
+        sender="Jarvis API",
+        subject=f"Stock Monitor - {datetime.now().strftime('%c')}",
+        html_body=rendered,
     )
-    mail_stat = mail_obj.send_email(recipient=email_address, sender='Jarvis API',
-                                    subject=f"Stock Monitor - {datetime.now().strftime('%c')}",
-                                    html_body=rendered)
     if mail_stat.ok:
         logger.debug(mail_stat.body)
         logger.info("Token will be reset in %s", timeout_in)
-        Timer(function=timeout_otp.reset_stock_monitor, args=(email_address,), interval=reset_timeout).start()
-        raise APIResponse(status_code=HTTPStatus.OK.real,
-                          detail="Please enter the OTP sent via email to verify email address:")
+        Timer(
+            function=timeout_otp.reset_stock_monitor,
+            args=(email_address,),
+            interval=reset_timeout,
+        ).start()
+        raise APIResponse(
+            status_code=HTTPStatus.OK.real,
+            detail="Please enter the OTP sent via email to verify email address:",
+        )
     else:
         logger.error(mail_stat.json())
-        raise APIResponse(status_code=HTTPStatus.SERVICE_UNAVAILABLE.real, detail=mail_stat.body)
+        raise APIResponse(
+            status_code=HTTPStatus.SERVICE_UNAVAILABLE.real, detail=mail_stat.body
+        )
 
 
 @router.post(path="/stock-monitor")
-async def stock_monitor_api(request: Request, input_data: modals.StockMonitorModal,
-                            email_otp: Optional[str] = Header(None), apikey: Optional[str] = Header(None)):
+async def stock_monitor_api(
+    request: Request,
+    input_data: modals.StockMonitorModal,
+    email_otp: Optional[str] = Header(None),
+    apikey: Optional[str] = Header(None),
+):
     """`Stock monitor api endpoint <https://vigneshrao.com/stock-monitor>`__.
 
     Args:
 
         - request: Takes the Request class as an argument.
         - input_data: Takes the following arguments as OfflineCommunicatorModal class instead of a QueryString.
         - email_otp: One Time Passcode (OTP) received via email.
@@ -94,152 +115,233 @@
         - 502: If price check fails.
 
     See Also:
 
         - This API endpoint is simply the backend for stock price monitoring.
         - This function validates the user information and stores it to a database.
     """
-    logger.debug("Connection received from %s via %s using %s" %
-                 (request.client.host, request.headers.get('host'), request.headers.get('user-agent')))
+    logger.debug(
+        "Connection received from %s via %s using %s"
+        % (
+            request.client.host,
+            request.headers.get("host"),
+            request.headers.get("user-agent"),
+        )
+    )
 
     try:
         input_data.request = input_data.request.upper()
     except AttributeError as error:
         logger.error(error)
-        raise APIResponse(status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real, detail=error.__str__())
+        raise APIResponse(
+            status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real, detail=error.__str__()
+        )
     if input_data.request not in ("GET", "PUT", "DELETE"):
         logger.warning("'%s' is not in the allowed request list.", input_data.request)
-        raise APIResponse(status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real,
-                          detail=HTTPStatus.UNPROCESSABLE_ENTITY.phrase)
+        raise APIResponse(
+            status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real,
+            detail=HTTPStatus.UNPROCESSABLE_ENTITY.phrase,
+        )
 
     # apikey from user and env vars are present and it is allowed
-    apikey = apikey or request.headers.get('apikey')
-    if apikey and \
-            models.env.stock_monitor_api.get(input_data.email) and \
-            secrets.compare_digest(models.env.stock_monitor_api[input_data.email], apikey):
+    apikey = apikey or request.headers.get("apikey")
+    if (
+        apikey
+        and models.env.stock_monitor_api.get(input_data.email)
+        and secrets.compare_digest(
+            models.env.stock_monitor_api[input_data.email], apikey
+        )
+    ):
         logger.info("%s has been verified using apikey", input_data.email)
-    elif apikey and models.env.stock_monitor_api.get(input_data.email):  # both vars are present but don't match
+    # both vars are present but don't match
+    elif apikey and models.env.stock_monitor_api.get(input_data.email):
         logger.info("%s sent an invalid API key", input_data.email)
-        raise APIResponse(status_code=HTTPStatus.UNAUTHORIZED.real, detail=HTTPStatus.UNAUTHORIZED.phrase)
+        raise APIResponse(
+            status_code=HTTPStatus.UNAUTHORIZED.real,
+            detail=HTTPStatus.UNAUTHORIZED.phrase,
+        )
     else:  # If apikey auth fails or unsupported
         sent_dict = settings.stock_monitor_helper.otp_sent
         recd_dict = settings.stock_monitor_helper.otp_recd
-        email_otp = email_otp or request.headers.get('email-otp')  # variable will be _ but headers should always be `-`
+        email_otp = email_otp or request.headers.get(
+            "email-otp"
+        )  # variable will be _ but headers should always be `-`
         if email_otp:
             recd_dict[input_data.email] = email_otp
-        if secrets.compare_digest(recd_dict.get(input_data.email, 'DO_NOT'), sent_dict.get(input_data.email, 'MATCH')):
+        if secrets.compare_digest(
+            recd_dict.get(input_data.email, "DO_NOT"),
+            sent_dict.get(input_data.email, "MATCH"),
+        ):
             logger.info("%s has been verified.", input_data.email)
         else:
-            result = gmailconnector.validate_email(email_address=input_data.email, smtp_check=False)
+            result = gmailconnector.validate_email(
+                email_address=input_data.email, smtp_check=False
+            )
             logger.debug(result.body)
             if result.ok is False:
-                raise APIResponse(status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real, detail=result.body)
+                raise APIResponse(
+                    status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real, detail=result.body
+                )
             await send_otp_stock_monitor(email_address=input_data.email)
 
     if input_data.request == "GET":
         logger.info("'%s' requested their data.", input_data.email)
         # Token is not required for GET method
         # if input_data.token:
         #     decoded = jwt.decode(jwt=input_data.token, options={"verify_signature": False}, algorithms="HS256")
         #     logger.warning("Unwanted information received: '%s'", decoded)
-        if db_entry := stockmonitor_squire.get_stock_userdata(email=input_data.email):  # Filter data from DB by email
+
+        # Filter data from DB by email
+        if db_entry := stockmonitor_squire.get_stock_userdata(email=input_data.email):
             logger.info(db_entry)
             if input_data.plaintext:
-                raise APIResponse(status_code=HTTPStatus.OK.real,
-                                  detail=[dict(zip(settings.stock_monitor.user_info, each_entry))
-                                          for each_entry in db_entry])
+                raise APIResponse(
+                    status_code=HTTPStatus.OK.real,
+                    detail=[
+                        dict(zip(settings.stock_monitor.user_info, each_entry))
+                        for each_entry in db_entry
+                    ],
+                )
             # Format as an HTML table to serve in https://vigneshrao.com/stock-monitor
             # This is a mess, yet required because JavaScript can't handle dataframes and
             # pandas to html can't include custom buttons
             html_data = """<table border="1" class="dataframe" id="dataframe"><tbody><tr><td><b>Selector</b></td>"""
-            html_data += "<td><b>" + "</b></td><td><b>".join((string.capwords(p)
-                                                              for p in settings.stock_monitor.user_info)) + \
-                         "</b></td></tr>"
+            html_data += (
+                "<td><b>"
+                + "</b></td><td><b>".join(
+                    (string.capwords(p) for p in settings.stock_monitor.user_info)
+                )
+                + "</b></td></tr>"
+            )
             rows = ""
             for ind, each_entry in enumerate(db_entry):
                 # give same name to all the radio buttons to enable single select
                 row = f'<tr><td align="center"><input value="{ind}" id="radio_{ind}" type="radio" name="read"></td><td>'
                 row += "</td><td>".join(str(i) for i in each_entry) + "</td>"
                 rows += row
             html_data += rows + "</tr></tbody></table>"
             raise APIResponse(status_code=HTTPStatus.OK.real, detail=html_data)
-        raise APIResponse(status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real,
-                          detail=f"No entry found in database for {input_data.email!r}")
+        raise APIResponse(
+            status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real,
+            detail=f"No entry found in database for {input_data.email!r}",
+        )
 
     try:
-        decoded = jwt.decode(jwt=input_data.token, options={"verify_signature": False}, algorithms="HS256")
+        decoded = jwt.decode(
+            jwt=input_data.token,
+            options={"verify_signature": False},
+            algorithms="HS256",
+        )
     except jwt.DecodeError as error:
         logger.error(error)
-        raise APIResponse(status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real,
-                          detail="Invalid JWT received. Please re-check the input and try-again.")
+        raise APIResponse(
+            status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real,
+            detail="Invalid JWT received. Please re-check the input and try-again.",
+        )
     # Validated individually
     # if any(map(lambda x: x is None, (decoded.get('Ticker'), decoded.get('Max'), decoded.get('Min')))):
     #     raise APIResponse(status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real,
     #                       detail="Keys 'Ticker', 'Max' and 'Min' are mandatory.")
-    if not decoded.get('Ticker'):
-        raise APIResponse(status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real,
-                          detail="Cannot proceed without the key 'Ticker'")
-    decoded['Ticker'] = decoded['Ticker'].upper()
-    decoded['Max'] = util.extract_nos(input_=decoded['Max'], method=float)
-    decoded['Min'] = util.extract_nos(input_=decoded['Min'], method=float)
-    decoded['Correction'] = util.extract_nos(input_=decoded['Correction'], method=int)
-
-    if decoded['Correction'] is None:  # Consider 0 as valid in case user doesn't want any correction value
-        decoded['Correction'] = 5
-    if decoded['Max'] is None or decoded['Min'] is None:
-        raise APIResponse(status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real,
-                          detail="Minimum and maximum values should be integers. "
-                                 "If you don't want a notification for any one of of it, please mark it as 0.")
-    if decoded['Max'] and decoded['Max'] <= decoded['Min']:
-        raise APIResponse(status_code=HTTPStatus.CONFLICT.real,
-                          detail="'Max' should be greater than the 'Min' value.\n\nSet 'Max' or 'Min' as 0, "
-                                 "if you don't wish to receive a notification for it.")
-    if decoded['Correction'] > 20:
-        raise APIResponse(status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real,
-                          detail="Allowed correction values are only up to 20%\n\nFor anything greater, "
-                                 "it is better to increase/decrease the Max/Min values.")
+    if not decoded.get("Ticker"):
+        raise APIResponse(
+            status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real,
+            detail="Cannot proceed without the key 'Ticker'",
+        )
+    decoded["Ticker"] = decoded["Ticker"].upper()
+    decoded["Max"] = util.extract_nos(input_=decoded["Max"], method=float)
+    decoded["Min"] = util.extract_nos(input_=decoded["Min"], method=float)
+    decoded["Correction"] = util.extract_nos(input_=decoded["Correction"], method=int)
+
+    # Consider 0 as valid in case user doesn't want any correction value
+    if decoded["Correction"] is None:
+        decoded["Correction"] = 5
+    if decoded["Max"] is None or decoded["Min"] is None:
+        raise APIResponse(
+            status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real,
+            detail="Minimum and maximum values should be integers. "
+            "If you don't want a notification for any one of of it, please mark it as 0.",
+        )
+    if decoded["Max"] and decoded["Max"] <= decoded["Min"]:
+        raise APIResponse(
+            status_code=HTTPStatus.CONFLICT.real,
+            detail="'Max' should be greater than the 'Min' value.\n\nSet 'Max' or 'Min' as 0, "
+            "if you don't wish to receive a notification for it.",
+        )
+    if decoded["Correction"] > 20:
+        raise APIResponse(
+            status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real,
+            detail="Allowed correction values are only up to 20%\n\nFor anything greater, "
+            "it is better to increase/decrease the Max/Min values.",
+        )
 
     # Forms a tuple of the new entry provided by the user
-    new_entry = (str(decoded['Ticker']), input_data.email, float(decoded['Max']), float(decoded['Min']),
-                 int(decoded['Correction']), str(decoded['Daily Alerts']))
+    new_entry = (
+        str(decoded["Ticker"]),
+        input_data.email,
+        float(decoded["Max"]),
+        float(decoded["Min"]),
+        int(decoded["Correction"]),
+        str(decoded["Daily Alerts"]),
+    )
 
     # Deletes an entry that's present already when requested
     if input_data.request == "DELETE":
         logger.info("'%s' requested to delete '%s'", input_data.email, new_entry)
-        if new_entry not in stockmonitor_squire.get_stock_userdata(email=input_data.email):  # Checks if entry exists
-            raise APIResponse(status_code=HTTPStatus.NOT_FOUND.real, detail="Entry is not present in the database.")
+        # Checks if entry exists
+        if new_entry not in stockmonitor_squire.get_stock_userdata(
+            email=input_data.email
+        ):
+            raise APIResponse(
+                status_code=HTTPStatus.NOT_FOUND.real,
+                detail="Entry is not present in the database.",
+            )
         stockmonitor_squire.delete_stock_userdata(data=new_entry)
-        raise APIResponse(status_code=HTTPStatus.OK.real, detail="Entry has been removed from the database.")
+        raise APIResponse(
+            status_code=HTTPStatus.OK.real,
+            detail="Entry has been removed from the database.",
+        )
 
     # Check dupes and let know the user
     if new_entry in stockmonitor_squire.get_stock_userdata():
-        raise APIResponse(status_code=HTTPStatus.CONFLICT.real, detail="Duplicate request!\nEntry exists in database.")
+        raise APIResponse(
+            status_code=HTTPStatus.CONFLICT.real,
+            detail="Duplicate request!\nEntry exists in database.",
+        )
 
     logger.info("'%s' requested to add '%s'", input_data.email, new_entry)
     try:
-        price_check = webull().get_quote(decoded['Ticker'])
-        current_price = price_check.get('close') or price_check.get('open')
+        price_check = webull().get_quote(decoded["Ticker"])
+        current_price = price_check.get("close") or price_check.get("open")
         if current_price:
             current_price = float(current_price)
         else:
             raise ValueError(price_check)
     except ValueError as error:
         logger.error(error)
-        raise APIResponse(status_code=HTTPStatus.BAD_GATEWAY.real,
-                          detail=f"Failed to perform a price check on {decoded['Ticker']}\n\n{error.__str__()}")
-    if decoded['Max'] and current_price >= decoded['Max']:  # Ignore 0 which doesn't trigger a notification
-        raise APIResponse(status_code=HTTPStatus.CONFLICT.real,
-                          detail=f"Current price of {decoded['Ticker']} is {current_price}.\n"
-                                 "Please choose a higher 'Max' value or try at a later time.")
-    if decoded['Min'] and current_price <= decoded['Min']:  # Ignore 0 which doesn't trigger a notification
-        raise APIResponse(status_code=HTTPStatus.CONFLICT.real,
-                          detail=f"Current price of {decoded['Ticker']} is {current_price}.\n"
-                                 "Please choose a lower 'Min' value or try at a later time.")
+        raise APIResponse(
+            status_code=HTTPStatus.BAD_GATEWAY.real,
+            detail=f"Failed to perform a price check on {decoded['Ticker']}\n\n{error.__str__()}",
+        )
+    # Ignore 0 which doesn't trigger a notification
+    if decoded["Max"] and current_price >= decoded["Max"]:
+        raise APIResponse(
+            status_code=HTTPStatus.CONFLICT.real,
+            detail=f"Current price of {decoded['Ticker']} is {current_price}.\n"
+            "Please choose a higher 'Max' value or try at a later time.",
+        )
+    # Ignore 0 which doesn't trigger a notification
+    if decoded["Min"] and current_price <= decoded["Min"]:
+        raise APIResponse(
+            status_code=HTTPStatus.CONFLICT.real,
+            detail=f"Current price of {decoded['Ticker']} is {current_price}.\n"
+            "Please choose a lower 'Min' value or try at a later time.",
+        )
 
     stockmonitor_squire.insert_stock_userdata(params=new_entry)  # Store it in database
 
-    response = f"Entry added to the database. Jarvis will notify you at {input_data.email!r} when a " \
-               f"price change occurs in {decoded['Ticker']!r}."
-    if decoded['Daily Alerts'] == "on":
+    response = (
+        f"Entry added to the database. Jarvis will notify you at {input_data.email!r} when a "
+        f"price change occurs in {decoded['Ticker']!r}."
+    )
+    if decoded["Daily Alerts"] == "on":
         response += " Please note that these alerts will not be deleted from the database automatically."
-    raise APIResponse(status_code=HTTPStatus.OK.real,
-                      detail=response)
+    raise APIResponse(status_code=HTTPStatus.OK.real, detail=response)
```

## jarvis/api/routers/surveillance.py

```diff
@@ -12,27 +12,32 @@
 from fastapi import APIRouter, Request, WebSocket, WebSocketDisconnect
 from fastapi.responses import HTMLResponse, StreamingResponse
 
 from jarvis.api.logger import logger
 from jarvis.api.models import authenticator, modals, settings
 from jarvis.api.squire import surveillance_squire, timeout_otp
 from jarvis.modules.database import database
-from jarvis.modules.exceptions import (CONDITIONAL_ENDPOINT_RESTRICTION,
-                                       APIResponse, CameraError)
+from jarvis.modules.exceptions import (
+    CONDITIONAL_ENDPOINT_RESTRICTION,
+    APIResponse,
+    CameraError,
+)
 from jarvis.modules.models import models
 from jarvis.modules.templates import templates
 from jarvis.modules.utils import support, util
 
 router = APIRouter()
 db = database.Database(database=models.fileio.base_db)
 # Get websocket loaded
 ws_manager = settings.ConnectionManager()
 
 
-@router.post(path="/surveillance-authenticate", dependencies=authenticator.SURVEILLANCE_PROTECTOR)
+@router.post(
+    path="/surveillance-authenticate", dependencies=authenticator.SURVEILLANCE_PROTECTOR
+)
 async def authenticate_surveillance(cam: modals.CameraIndexModal):
     """Tests the given camera index, generates a token for the endpoint to authenticate.
 
     Args:
 
         cam: Index number of the chosen camera.
 
@@ -49,48 +54,62 @@
         - Sends a token for MFA via email.
         - Also stores the token in the Surveillance object which is verified in the /surveillance endpoint.
         - The token is nullified in the object as soon as it is verified, making it single use.
     """
     if not models.env.surveillance_endpoint_auth:
         raise CONDITIONAL_ENDPOINT_RESTRICTION
     reset_timeout = 300
-    timeout_in = support.pluralize(count=util.format_nos(input_=reset_timeout / 60), word="minute")
+    timeout_in = support.pluralize(
+        count=util.format_nos(input_=reset_timeout / 60), word="minute"
+    )
     settings.surveillance.camera_index = cam.index
     try:
         surveillance_squire.test_camera()
     except CameraError as error:
         logger.error(error)
         raise APIResponse(status_code=HTTPStatus.NOT_ACCEPTABLE.real, detail=str(error))
 
-    mail_obj = gmailconnector.SendEmail(gmail_user=models.env.open_gmail_user,
-                                        gmail_pass=models.env.open_gmail_pass)
+    mail_obj = gmailconnector.SendEmail(
+        gmail_user=models.env.open_gmail_user, gmail_pass=models.env.open_gmail_pass
+    )
     auth_stat = mail_obj.authenticate
     if not auth_stat.ok:
         logger.error(auth_stat.json())
-        raise APIResponse(status_code=HTTPStatus.SERVICE_UNAVAILABLE.real, detail=auth_stat.body)
+        raise APIResponse(
+            status_code=HTTPStatus.SERVICE_UNAVAILABLE.real, detail=auth_stat.body
+        )
     settings.surveillance.token = util.keygen_uuid(length=16)
-    rendered = jinja2.Template(templates.email.one_time_passcode).render(TIMEOUT=timeout_in,
-                                                                         ENDPOINT="surveillance",
-                                                                         EMAIL=models.env.recipient,
-                                                                         TOKEN=settings.surveillance.token)
-    mail_stat = mail_obj.send_email(recipient=models.env.recipient, sender='Jarvis API',
-                                    subject=f"Surveillance Token - {datetime.now().strftime('%c')}",
-                                    html_body=rendered)
+    rendered = jinja2.Template(templates.email.one_time_passcode).render(
+        TIMEOUT=timeout_in,
+        ENDPOINT="surveillance",
+        EMAIL=models.env.recipient,
+        TOKEN=settings.surveillance.token,
+    )
+    mail_stat = mail_obj.send_email(
+        recipient=models.env.recipient,
+        sender="Jarvis API",
+        subject=f"Surveillance Token - {datetime.now().strftime('%c')}",
+        html_body=rendered,
+    )
     if mail_stat.ok:
         logger.debug(mail_stat.body)
         logger.info("Token will be reset in %s", timeout_in)
         Timer(function=timeout_otp.reset_surveillance, interval=reset_timeout).start()
-        raise APIResponse(status_code=HTTPStatus.OK.real,
-                          detail="Authentication success. Please enter the OTP sent via email:")
+        raise APIResponse(
+            status_code=HTTPStatus.OK.real,
+            detail="Authentication success. Please enter the OTP sent via email:",
+        )
     else:
         logger.error(mail_stat.json())
-        raise APIResponse(status_code=HTTPStatus.SERVICE_UNAVAILABLE.real, detail=mail_stat.body)
+        raise APIResponse(
+            status_code=HTTPStatus.SERVICE_UNAVAILABLE.real, detail=mail_stat.body
+        )
 
 
-@router.get('/surveillance')
+@router.get("/surveillance")
 async def monitor(token: str = None):
     """Serves the monitor page's frontend after updating it with video origin and websocket origins.
 
     Args:
 
         - request: Takes the Request class as an argument.
         - token: Takes custom auth token as an argument.
@@ -115,32 +134,41 @@
         - This UUID is sent via email to the env var RECIPIENT, which should be entered as query string.
         - The UUID is deleted from the object as soon as the argument is checked for the last time.
         - Page refresh is useless because the value in memory is cleared as soon as the video is rendered.
     """
     if not models.env.surveillance_endpoint_auth:
         raise CONDITIONAL_ENDPOINT_RESTRICTION
     if not token:
-        raise APIResponse(status_code=HTTPStatus.UNAUTHORIZED.real,
-                          detail=HTTPStatus.UNAUTHORIZED.phrase)
+        raise APIResponse(
+            status_code=HTTPStatus.UNAUTHORIZED.real,
+            detail=HTTPStatus.UNAUTHORIZED.phrase,
+        )
     # token might be present because its added as headers but surveillance.token will be cleared after one time auth
-    if settings.surveillance.token and secrets.compare_digest(token, settings.surveillance.token):
+    if settings.surveillance.token and secrets.compare_digest(
+        token, settings.surveillance.token
+    ):
         # include milliseconds to avoid dupes
-        settings.surveillance.client_id = int(''.join(str(time.time()).split('.')))
+        settings.surveillance.client_id = int("".join(str(time.time()).split(".")))
         rendered = jinja2.Template(templates.endpoint.surveillance).render(
             CLIENT_ID=settings.surveillance.client_id
         )
         content_type, _ = mimetypes.guess_type(rendered)
-        return HTMLResponse(status_code=HTTPStatus.TEMPORARY_REDIRECT.real,
-                            content=rendered, media_type=content_type)
+        return HTMLResponse(
+            status_code=HTTPStatus.TEMPORARY_REDIRECT.real,
+            content=rendered,
+            media_type=content_type,
+        )
     else:
-        raise APIResponse(status_code=HTTPStatus.EXPECTATION_FAILED.real,
-                          detail='Requires authentication since endpoint uses single-use token.')
+        raise APIResponse(
+            status_code=HTTPStatus.EXPECTATION_FAILED.real,
+            detail="Requires authentication since endpoint uses single-use token.",
+        )
 
 
-@router.get('/video-feed', include_in_schema=False)
+@router.get("/video-feed", include_in_schema=False)
 async def video_feed(request: Request, token: str = None):
     """Authenticates the request, and returns the frames generated as a StreamingResponse.
 
     Raises:
 
         APIResponse:
         - 307: If token matches the auto-generated value.
@@ -153,43 +181,63 @@
         - token: Token generated in /surveillance-authenticate endpoint to restrict direct access.
 
     Returns:
 
         StreamingResponse:
         StreamingResponse with a collective of each frame.
     """
-    logger.debug("Connection received from %s via %s using %s" %
-                 (request.client.host, request.headers.get('host'), request.headers.get('user-agent')))
+    logger.debug(
+        "Connection received from %s via %s using %s"
+        % (
+            request.client.host,
+            request.headers.get("host"),
+            request.headers.get("user-agent"),
+        )
+    )
 
     if not models.env.surveillance_endpoint_auth:
         raise CONDITIONAL_ENDPOINT_RESTRICTION
 
     if not token:
-        logger.warning('/video-feed was accessed directly.')
-        raise APIResponse(status_code=HTTPStatus.UNAUTHORIZED.real,
-                          detail=HTTPStatus.UNAUTHORIZED.phrase)
+        logger.warning("/video-feed was accessed directly.")
+        raise APIResponse(
+            status_code=HTTPStatus.UNAUTHORIZED.real,
+            detail=HTTPStatus.UNAUTHORIZED.phrase,
+        )
     if token != settings.surveillance.token:
-        raise APIResponse(status_code=HTTPStatus.EXPECTATION_FAILED.real,
-                          detail='Requires authentication since endpoint uses single-use token.')
+        raise APIResponse(
+            status_code=HTTPStatus.EXPECTATION_FAILED.real,
+            detail="Requires authentication since endpoint uses single-use token.",
+        )
     settings.surveillance.token = None
     settings.surveillance.queue_manager[settings.surveillance.client_id] = Queue()
-    process = Process(target=surveillance_squire.gen_frames,
-                      kwargs={"manager": settings.surveillance.queue_manager[settings.surveillance.client_id],
-                              "index": settings.surveillance.camera_index,
-                              "available_cameras": settings.surveillance.available_cameras})
+    process = Process(
+        target=surveillance_squire.gen_frames,
+        kwargs={
+            "manager": settings.surveillance.queue_manager[
+                settings.surveillance.client_id
+            ],
+            "index": settings.surveillance.camera_index,
+            "available_cameras": settings.surveillance.available_cameras,
+        },
+    )
     process.start()
     # Insert process IDs into the children table to kill it in case, Jarvis is stopped during an active session
     with db.connection:
         cursor = db.connection.cursor()
-        cursor.execute("INSERT INTO children (surveillance) VALUES (?);", (process.pid,))
+        cursor.execute(
+            "INSERT INTO children (surveillance) VALUES (?);", (process.pid,)
+        )
         db.connection.commit()
     settings.surveillance.processes[settings.surveillance.client_id] = process
-    return StreamingResponse(content=surveillance_squire.streamer(),
-                             media_type='multipart/x-mixed-replace; boundary=frame',
-                             status_code=HTTPStatus.PARTIAL_CONTENT.real)
+    return StreamingResponse(
+        content=surveillance_squire.streamer(),
+        media_type="multipart/x-mixed-replace; boundary=frame",
+        status_code=HTTPStatus.PARTIAL_CONTENT.real,
+    )
 
 
 @router.websocket("/ws/{client_id}")
 async def websocket_endpoint(websocket: WebSocket, client_id: int):
     """Initiates a websocket connection.
 
     Args:
@@ -216,36 +264,52 @@
                 data = await asyncio.wait_for(fut=websocket.receive_text(), timeout=5)
             except asyncio.TimeoutError:
                 data = None
             if data:
                 logger.info("Client [%d] sent %s", client_id, data)
                 if data == "Healthy":
                     settings.surveillance.session_manager[client_id] = time.time()
-                    timestamp = settings.surveillance.session_manager[client_id] + \
-                        models.env.surveillance_session_timeout
-                    logger.info("Surveillance session will expire at %s",
-                                datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S'))
+                    timestamp = (
+                        settings.surveillance.session_manager[client_id]
+                        + models.env.surveillance_session_timeout
+                    )
+                    logger.info(
+                        "Surveillance session will expire at %s",
+                        datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S"),
+                    )
                 if data == "IMG_ERROR":
                     logger.info("Sending error image frame to client.")
                     bytes_, tmp_file = surveillance_squire.generate_error_frame(
                         dimension=settings.surveillance.frame,
                         text="Unable to get image frame from "
-                             f"{settings.surveillance.available_cameras[settings.surveillance.camera_index]}")
+                        f"{settings.surveillance.available_cameras[settings.surveillance.camera_index]}",
+                    )
                     await websocket.send_bytes(data=bytes_)
-                    Thread(target=support.remove_file, kwargs={'delay': 2, 'filepath': tmp_file},
-                           daemon=True).start()
+                    Thread(
+                        target=support.remove_file,
+                        kwargs={"delay": 2, "filepath": tmp_file},
+                        daemon=True,
+                    ).start()
                     raise WebSocketDisconnect  # Raise error to release camera after a failed read
-            if settings.surveillance.session_manager.get(client_id, time.time()) + \
-                    models.env.surveillance_session_timeout <= time.time():
+            if (
+                settings.surveillance.session_manager.get(client_id, time.time())
+                + models.env.surveillance_session_timeout
+                <= time.time()
+            ):
                 logger.info("Sending session timeout to client: %d", client_id)
                 bytes_, tmp_file = surveillance_squire.generate_error_frame(
                     dimension=settings.surveillance.frame,
-                    text="SESSION EXPIRED! Re-authenticate to continue live stream.")
+                    text="SESSION EXPIRED! Re-authenticate to continue live stream.",
+                )
                 await websocket.send_bytes(data=bytes_)
-                Thread(target=support.remove_file, kwargs={'delay': 2, 'filepath': tmp_file}, daemon=True).start()
+                Thread(
+                    target=support.remove_file,
+                    kwargs={"delay": 2, "filepath": tmp_file},
+                    daemon=True,
+                ).start()
                 raise WebSocketDisconnect  # Raise error to release camera after a failed read
     except WebSocketDisconnect:
         ws_manager.disconnect(websocket)
         logger.info("Client [%d] disconnected.", client_id)
         if ws_manager.active_connections:
             if process := settings.surveillance.processes.get(int(client_id)):
                 support.stop_process(pid=process.pid)
```

## jarvis/api/routers/telegram.py

```diff
@@ -20,15 +20,18 @@
         request: Request object from FastAPI.
 
     Returns:
         bool:
         Flag to indicate the calling function if the auth was successful.
     """
     if models.env.bot_secret:
-        if secrets.compare_digest(request.headers.get('X-Telegram-Bot-Api-Secret-Token', ''), models.env.bot_secret):
+        if secrets.compare_digest(
+            request.headers.get("X-Telegram-Bot-Api-Secret-Token", ""),
+            models.env.bot_secret,
+        ):
             return True
     else:
         logger.warning("Use the env var bot_secret to secure the webhook interaction")
         return True
 
 
 @router.post(path=models.env.bot_endpoint)
@@ -39,24 +42,35 @@
         request: Request instance.
 
     Raises:
 
         HTTPException:
             - 406: If the request payload is not JSON format-able.
     """
-    logger.debug("Connection received from %s via %s", request.client.host, request.headers.get('host'))
+    logger.debug(
+        "Connection received from %s via %s",
+        request.client.host,
+        request.headers.get("host"),
+    )
     try:
         response = await request.json()
     except JSONDecodeError as error:
         logger.error(error)
-        raise HTTPException(status_code=HTTPStatus.BAD_REQUEST.real, detail=HTTPStatus.BAD_REQUEST.phrase)
+        raise HTTPException(
+            status_code=HTTPStatus.BAD_REQUEST.real,
+            detail=HTTPStatus.BAD_REQUEST.phrase,
+        )
     # Ensure only the owner who set the webhook can interact with the Bot
     if not two_factor(request):
         logger.error("Request received from a non-webhook source")
         logger.error(response)
-        raise HTTPException(status_code=HTTPStatus.FORBIDDEN.real, detail=HTTPStatus.FORBIDDEN.phrase)
-    if payload := response.get('message'):
+        raise HTTPException(
+            status_code=HTTPStatus.FORBIDDEN.real, detail=HTTPStatus.FORBIDDEN.phrase
+        )
+    if payload := response.get("message"):
         logger.debug(response)
         bot.process_request(payload)
     else:
-        raise HTTPException(status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real,
-                            detail=HTTPStatus.UNPROCESSABLE_ENTITY.phrase)
+        raise HTTPException(
+            status_code=HTTPStatus.UNPROCESSABLE_ENTITY.real,
+            detail=HTTPStatus.UNPROCESSABLE_ENTITY.phrase,
+        )
```

## jarvis/api/squire/discover.py

```diff
@@ -43,44 +43,50 @@
     Yields:
         Entrypoint:
         Entrypoint object with router module and the bare name of it.
     """
     package = pathlib.Path(os.path.dirname(routers)).stem
     base_package = pathlib.Path(os.path.dirname(routers)).parent.stem
     for __path, __directory, __file in os.walk(routers):
-        if __path.endswith('__'):
+        if __path.endswith("__"):
             continue
         for file_ in __file:
-            if file_.startswith('__') or file_ == 'favicon.ico':
+            if file_.startswith("__") or file_ == "favicon.ico":
                 continue
             filepath = pathlib.PurePath(file_)
-            if filepath.suffix == '.py':
+            if filepath.suffix == ".py":
                 breaker = pathlib.PurePath(os.path.join(__path, filepath.stem)).parts
                 # Replace paths with . to make it appear as a module
-                yield Entrypoint(module='.'.join((base_package,) + breaker[breaker.index(package):]),
-                                 stem=filepath.stem)
+                # black formats to include space between '1' and ':', refer: https://github.com/psf/black/issues/1323
+                yield Entrypoint(
+                    module=".".join(
+                        (base_package,) + breaker[breaker.index(package):]  # fmt: skip
+                    ),
+                    stem=filepath.stem,
+                )
 
 
 def routes(routers: str) -> Generator[APIRouter]:
     """Scans routers directory to import all the routers available.
 
     Args:
         routers: Directory name where the potential router modules are present.
 
     Yields:
         APIRouter:
         API Router from scanned modules.
     """
-    entrypoints: List[Entrypoint] = sorted(get_entrypoints(routers=routers),
-                                           key=lambda ent: ent.stem)  # sort by name of the route
+    entrypoints: List[Entrypoint] = sorted(
+        get_entrypoints(routers=routers), key=lambda ent: ent.stem
+    )  # sort by name of the route
     for entrypoint in entrypoints:
         try:
             route = import_module(entrypoint.module)
         except ImportError as error:
             logger.error(error)
             warnings.warn(error.__str__())
             continue
-        if hasattr(route, 'router'):
+        if hasattr(route, "router"):
             logger.info("Loading router: %s", entrypoint.module)
-            yield getattr(route, 'router')
+            yield getattr(route, "router")
         else:
-            logger.warning('%s is missing the router attribute.', route.__name__)
+            logger.warning("%s is missing the router attribute.", route.__name__)
```

## jarvis/api/squire/scheduler.py

```diff
@@ -15,26 +15,34 @@
 
     Returns:
         Dict[str, Dict[str, int]]:
         Returns a dictionary of timezone and the market open and close hours.
     """
     if extended:
         return {
-            'EDT': {'OPEN': 7, 'CLOSE': 18}, 'EST': {'OPEN': 7, 'CLOSE': 18},
-            'CDT': {'OPEN': 6, 'CLOSE': 17}, 'CST': {'OPEN': 6, 'CLOSE': 17},
-            'MDT': {'OPEN': 5, 'CLOSE': 16}, 'MST': {'OPEN': 5, 'CLOSE': 16},
-            'PDT': {'OPEN': 4, 'CLOSE': 15}, 'PST': {'OPEN': 4, 'CLOSE': 15},
-            'OTHER': {'OPEN': 5, 'CLOSE': 21}  # 5 AM to 9 PM
+            "EDT": {"OPEN": 7, "CLOSE": 18},
+            "EST": {"OPEN": 7, "CLOSE": 18},
+            "CDT": {"OPEN": 6, "CLOSE": 17},
+            "CST": {"OPEN": 6, "CLOSE": 17},
+            "MDT": {"OPEN": 5, "CLOSE": 16},
+            "MST": {"OPEN": 5, "CLOSE": 16},
+            "PDT": {"OPEN": 4, "CLOSE": 15},
+            "PST": {"OPEN": 4, "CLOSE": 15},
+            "OTHER": {"OPEN": 5, "CLOSE": 21},  # 5 AM to 9 PM
         }
     return {
-        'EDT': {'OPEN': 9, 'CLOSE': 16}, 'EST': {'OPEN': 9, 'CLOSE': 16},
-        'CDT': {'OPEN': 8, 'CLOSE': 15}, 'CST': {'OPEN': 8, 'CLOSE': 15},
-        'MDT': {'OPEN': 7, 'CLOSE': 14}, 'MST': {'OPEN': 7, 'CLOSE': 14},
-        'PDT': {'OPEN': 6, 'CLOSE': 13}, 'PST': {'OPEN': 6, 'CLOSE': 13},
-        'OTHER': {'OPEN': 7, 'CLOSE': 19}  # 7 AM to 7 PM
+        "EDT": {"OPEN": 9, "CLOSE": 16},
+        "EST": {"OPEN": 9, "CLOSE": 16},
+        "CDT": {"OPEN": 8, "CLOSE": 15},
+        "CST": {"OPEN": 8, "CLOSE": 15},
+        "MDT": {"OPEN": 7, "CLOSE": 14},
+        "MST": {"OPEN": 7, "CLOSE": 14},
+        "PDT": {"OPEN": 6, "CLOSE": 13},
+        "PST": {"OPEN": 6, "CLOSE": 13},
+        "OTHER": {"OPEN": 7, "CLOSE": 19},  # 7 AM to 7 PM
     }
 
 
 def rh_cron_schedule(extended: bool = False) -> expression.CronExpression:
     """Creates a cron expression for ``stock_report.py``. Determines cron schedule based on current timezone.
 
     Args:
@@ -48,16 +56,18 @@
         CronExpression:
         Crontab expression object running every 30 minutes during market hours based on the current timezone.
     """
     hours = market_hours(extended)
     job = f"{shutil.which(cmd='python')} {os.path.join(triggers.__path__[0], 'stock_report.py')}"
     tz = util.get_timezone()
     if tz not in hours:
-        tz = 'OTHER'
-    return expression.CronExpression(f"*/30 {hours[tz]['OPEN']}-{hours[tz]['CLOSE']} * * 1-5 {job}")
+        tz = "OTHER"
+    return expression.CronExpression(
+        f"*/30 {hours[tz]['OPEN']}-{hours[tz]['CLOSE']} * * 1-5 {job}"
+    )
 
 
 def sm_cron_schedule(include_weekends: bool = False) -> expression.CronExpression:
     """Creates a cron expression for ``stock_monitor.py``.
 
     Args:
         include_weekends: Takes a boolean flag to run cron schedule over the weekends.
```

## jarvis/api/squire/stockanalysis_squire.py

```diff
@@ -1,13 +1,13 @@
 import os
 import string
 import time
 from concurrent.futures import ThreadPoolExecutor, as_completed
 from datetime import datetime
-from typing import Callable, Iterable, List, Union
+from typing import Callable, Iterable, List
 
 import requests
 import yaml
 from bs4 import BeautifulSoup
 from webull import webull
 
 from jarvis.api.logger import logger
@@ -19,30 +19,34 @@
 def ticker_gatherer(character: str) -> None:
     """Gathers the stock ticker in NASDAQ. Runs on ``multi-threading`` which drops run time by ~7 times.
 
     Args:
         character: ASCII character (alphabet) with which the stock ticker name starts.
     """
     try:
-        response = requests.get(url=f'https://www.eoddata.com/stocklist/NASDAQ/{character}.htm')
+        response = requests.get(
+            url=f"https://www.eoddata.com/stocklist/NASDAQ/{character}.htm"
+        )
     except EgressErrors as error:
         logger.error(error)
         return
     scrapped = BeautifulSoup(response.text, "html.parser")
-    d1 = scrapped.find_all('tr', {'class': 'ro'})
-    d2 = scrapped.find_all('tr', {'class': 're'})
+    d1 = scrapped.find_all("tr", {"class": "ro"})
+    d2 = scrapped.find_all("tr", {"class": "re"})
     for link in d1:
         td1 = link.findAll("td")
         settings.trader.stock_list[td1[0].text] = td1[1].text
     for link in d2:
         td2 = link.findAll("td")
         settings.trader.stock_list[td2[0].text] = td2[1].text
 
 
-def thread_worker(function_to_call: Callable, iterable: Union[List, Iterable], workers: int = None) -> None:
+def thread_worker(
+    function_to_call: Callable, iterable: List | Iterable, workers: int = None
+) -> None:
     """Initiates ``ThreadPoolExecutor`` with in a dedicated thread.
 
     Args:
         function_to_call: Takes the function/method that has to be called as an argument.
         iterable: List or iterable to be used as args.
         workers: Maximum number of workers to spin up.
     """
@@ -56,42 +60,59 @@
             future = executor.submit(function_to_call, iterator)
             futures[future] = iterator
 
     thread_except = 0
     for future in as_completed(futures):
         if future.exception():
             thread_except += 1
-            logger.error("Thread processing for %s received an exception: %s", futures[future], future.exception())
-    if thread_except > (len(iterable) * 10 / 100):  # Use backup file if more than 10% of the requests fail
+            logger.error(
+                "Thread processing for %s received an exception: %s",
+                futures[future],
+                future.exception(),
+            )
+    # Use backup file if more than 10% of the requests fail
+    if thread_except > (len(iterable) * 10 / 100):
         with open(models.fileio.stock_list_backup) as file:
             settings.trader.stock_list = yaml.load(stream=file, Loader=yaml.FullLoader)
 
 
 def nasdaq() -> None:
     """Get all stock tickers available. Creates/Updates backup file to be used."""
     if os.path.isfile(models.fileio.stock_list_backup):
         modified = int(os.stat(models.fileio.stock_list_backup).st_mtime)
-        if int(time.time()) - modified < 86_400:  # Gathers new stock list only if the file is older than a day
+        # Gathers new stock list only if the file is older than a day
+        if int(time.time()) - modified < 86_400:
             try:
                 with open(models.fileio.stock_list_backup) as file:
-                    settings.trader.stock_list = yaml.load(stream=file, Loader=yaml.FullLoader)
+                    settings.trader.stock_list = yaml.load(
+                        stream=file, Loader=yaml.FullLoader
+                    )
             except yaml.YAMLError as error:
                 logger.error(error)
-            if len(settings.trader.stock_list) > 5_000:
-                logger.info("%s generated with %d tickers on %s looks re-usable." %
-                            (models.fileio.stock_list_backup, len(settings.trader.stock_list),
-                             datetime.fromtimestamp(modified).strftime('%c')))
+            if len(settings.trader.stock_list) > 2_000:  # Usually close to ~5K
+                logger.info(
+                    "%s generated with %d tickers on %s looks re-usable."
+                    % (
+                        models.fileio.stock_list_backup,
+                        len(settings.trader.stock_list),
+                        datetime.fromtimestamp(modified).strftime("%c"),
+                    )
+                )
                 return
     logger.info("Gathering stock list from webull.")
     try:
-        settings.trader.stock_list = [ticker.get('symbol') for ticker in webull().get_all_tickers()]
+        settings.trader.stock_list = [
+            ticker.get("symbol") for ticker in webull().get_all_tickers()
+        ]
     except Exception as error:
         logger.error(error)
     if settings.trader.stock_list:
-        os.remove('did.bin') if os.path.isfile('did.bin') else None  # Created by webull module
+        os.remove("did.bin") if os.path.isfile(
+            "did.bin"
+        ) else None  # Created by webull module
     else:
         logger.info("Gathering stock list from eoddata.")
         thread_worker(function_to_call=ticker_gatherer, iterable=string.ascii_uppercase)
     logger.info("Total tickers gathered: %d", len(settings.trader.stock_list))
     # Writes to a backup file
-    with open(models.fileio.stock_list_backup, 'w') as file:
+    with open(models.fileio.stock_list_backup, "w") as file:
         yaml.dump(stream=file, data=settings.trader.stock_list)
```

## jarvis/api/squire/stockmonitor_squire.py

```diff
@@ -1,9 +1,9 @@
 from collections.abc import Generator
-from typing import Dict, List, Optional, Tuple, Union
+from typing import Dict, List, Optional, Tuple
 
 from pydantic import EmailStr
 
 from jarvis.api.logger import logger
 from jarvis.api.models import settings
 from jarvis.modules.database import database
 from jarvis.modules.models import models
@@ -19,88 +19,106 @@
     if dupes := [x for n, x in enumerate(data) if x in data[:n]]:
         logger.info("%d duplicate entries found.", len(dupes))
         cleaned = list(set(data))
         with stock_db.connection:
             cursor = stock_db.connection.cursor()
             cursor.execute("DELETE FROM stock")
             for params in cleaned:
-                query = f"INSERT or REPLACE INTO stock {settings.stock_monitor.user_info} " \
-                        f"VALUES {settings.stock_monitor.values};"
+                query = (
+                    f"INSERT or REPLACE INTO stock {settings.stock_monitor.user_info} "
+                    f"VALUES {settings.stock_monitor.values};"
+                )
                 cursor.execute(query, params)
             stock_db.connection.commit()
 
 
-def insert_stock_userdata(params: Tuple[str, EmailStr, Union[int, float], Union[int, float], int, str]) -> None:
+def insert_stock_userdata(
+    params: Tuple[str, EmailStr, int | float, int | float, int, str]
+) -> None:
     """Inserts new entry into the stock database.
 
     Args:
         params: Tuple of information that has to be inserted.
     """
     with stock_db.connection:
         cursor = stock_db.connection.cursor()
-        query = f"INSERT or REPLACE INTO stock {settings.stock_monitor.user_info} " \
-                f"VALUES {settings.stock_monitor.values};"
+        query = (
+            f"INSERT or REPLACE INTO stock {settings.stock_monitor.user_info} "
+            f"VALUES {settings.stock_monitor.values};"
+        )
         cursor.execute(query, params)
         stock_db.connection.commit()
 
 
-def get_stock_userdata(email: Optional[Union[EmailStr, str]] = None) -> \
-        List[Tuple[str, EmailStr, Union[int, float], Union[int, float], int, str]]:
+def get_stock_userdata(
+    email: Optional[EmailStr | str] = None,
+) -> List[Tuple[str, EmailStr, int | float, int | float, int, str]]:
     """Reads the stock database to get all the user data.
 
     Returns:
         list:
         List of tuple of user information.
     """
     with stock_db.connection:
         cursor = stock_db.connection.cursor()
         if email:
-            data = cursor.execute("SELECT * FROM stock WHERE email=(?)", (email,)).fetchall()
+            data = cursor.execute(
+                "SELECT * FROM stock WHERE email=(?)", (email,)
+            ).fetchall()
         else:
             data = cursor.execute("SELECT * FROM stock").fetchall()
     return data
 
 
-def get_daily_alerts() -> \
-        Generator[Dict[int, Tuple[int, str, EmailStr, Union[int, float], Union[int, float], int, str]]]:
+def get_daily_alerts() -> Generator[
+    Dict[int, Tuple[int, str, EmailStr, int | float, int | float, int, str]]
+]:
     """Get all the information stored in ``stock_daily`` database table.
 
     Yields:
         A dictionary of epoch time and tuple of user information stored as key value pairs.
     """
     with stock_db.connection:
         cursor = stock_db.connection.cursor()
         data = cursor.execute("SELECT * FROM stock_daily").fetchall()
         yield {record[0]: record[1:] for record in data}
 
 
 def put_daily_alerts(
-        params: List[Dict[int, Tuple[int, str, EmailStr, Union[int, float], Union[int, float], int, str]]]
+    params: List[
+        Dict[int, Tuple[int, str, EmailStr, int | float, int | float, int, str]]
+    ]
 ):
     """Updates the daily alerts into the ``stock_daily`` database table.
 
     Args:
         params: Takes the tuple of all entries that has to be inserted.
     """
     with stock_db.connection:
         cursor = stock_db.connection.cursor()
         params = [(key, *values) for param in params for key, values in param.items()]
         cursor.execute("DELETE FROM stock_daily")  # clear all existing data
-        query = f"INSERT OR REPLACE INTO stock_daily {settings.stock_monitor.alerts} VALUES " \
-                f"{settings.stock_monitor.alert_values};"
+        query = (
+            f"INSERT OR REPLACE INTO stock_daily {settings.stock_monitor.alerts} VALUES "
+            f"{settings.stock_monitor.alert_values};"
+        )
         for param in params:
             cursor.execute(query, param)  # write new data in db
         stock_db.connection.commit()
 
 
-def delete_stock_userdata(data: Tuple[str, EmailStr, Union[int, float], Union[int, float], int, str]) -> None:
+def delete_stock_userdata(
+    data: Tuple[str, EmailStr, int | float, int | float, int, str]
+) -> None:
     """Delete particular user data from stock database.
 
     Args:
         data: Tuple of user information to be deleted.
     """
     with stock_db.connection:
         cursor = stock_db.connection.cursor()
-        cursor.execute("DELETE FROM stock WHERE ticker=(?) AND email=(?) AND "
-                       "max=(?) AND min=(?) AND correction=(?) AND repeat=(?);",
-                       data)
+        cursor.execute(
+            "DELETE FROM stock WHERE ticker=(?) AND email=(?) AND "
+            "max=(?) AND min=(?) AND correction=(?) AND repeat=(?);",
+            data,
+        )
         stock_db.connection.commit()
```

## jarvis/api/squire/surveillance_squire.py

```diff
@@ -8,15 +8,17 @@
 
 from jarvis.api.logger import logger
 from jarvis.api.models import settings
 from jarvis.modules.camera import camera
 from jarvis.modules.exceptions import CameraError
 
 
-def generate_error_frame(text: str, dimension: Tuple[int, int, int]) -> Tuple[bytes, str]:
+def generate_error_frame(
+    text: str, dimension: Tuple[int, int, int]
+) -> Tuple[bytes, str]:
     """Generates a single frame for error image.
 
     Args:
         text: Text that should be in the image.
         dimension: Dimension (Height x Width x Channel) of the frame.
 
     Returns:
@@ -36,26 +38,28 @@
 
     line_type = 2
     text_size = cv2.getTextSize(text, font, 1, 2)[0]
 
     text_x = int((image.shape[1] - text_size[0]) / 2)
     text_y = int((image.shape[0] + text_size[1]) / 2)
 
-    cv2.putText(img=image,
-                text=text,
-                org=(text_x, text_y),
-                fontFace=font,
-                fontScale=font_scale,
-                color=font_color,
-                thickness=thickness,
-                lineType=line_type)
-    filename = text.translate(str.maketrans('', '', string.punctuation)).lower()
-    filename = filename.replace(' ', '_') + '.jpg'
+    cv2.putText(
+        img=image,
+        text=text,
+        org=(text_x, text_y),
+        fontFace=font,
+        fontScale=font_scale,
+        color=font_color,
+        thickness=thickness,
+        lineType=line_type,
+    )
+    filename = text.translate(str.maketrans("", "", string.punctuation)).lower()
+    filename = filename.replace(" ", "_") + ".jpg"
     cv2.imwrite(filename=filename, img=image)
-    with open(filename, 'rb') as image_file:
+    with open(filename, "rb") as image_file:
         encoded_string = base64.b64encode(image_file.read())
     return encoded_string, filename
 
 
 def test_camera() -> None:
     """Tests a camera connected on the index number provided by the user.
 
@@ -65,39 +69,48 @@
     """
     camera_object = camera.Camera()
     available_cameras = camera_object.list_cameras()
 
     if not available_cameras:
         raise CameraError("No available cameras to monitor.")
 
-    if settings.surveillance.camera_index is None \
-            or settings.surveillance.camera_index == "" \
-            or not str(settings.surveillance.camera_index).isdigit():  # Initial value is str but requests will be int
+    # Initial value is str but requests will be int
+    if (
+        settings.surveillance.camera_index is None
+        or settings.surveillance.camera_index == ""
+        or not str(settings.surveillance.camera_index).isdigit()
+    ):
         logger.info("Camera index received: %s", settings.surveillance.camera_index)
         logger.info("Available cameras: %s", available_cameras)
         raise CameraError(f"Available cameras:\n{camera_object.get_index()}")
 
     settings.surveillance.camera_index = int(settings.surveillance.camera_index)
 
     if settings.surveillance.camera_index >= len(available_cameras):
         logger.info("Available cameras: %s", available_cameras)
-        raise CameraError(f"Camera index [{settings.surveillance.camera_index}] is out of range.\n\n"
-                          f"Available cameras:\n{camera_object.get_index()}")
+        raise CameraError(
+            f"Camera index [{settings.surveillance.camera_index}] is out of range.\n\n"
+            f"Available cameras:\n{camera_object.get_index()}"
+        )
     cam = cv2.VideoCapture(settings.surveillance.camera_index)
-    error = CameraError(f"Unable to read the camera index [{settings.surveillance.camera_index}] - "
-                        f"{available_cameras[settings.surveillance.camera_index]}")
+    error = CameraError(
+        f"Unable to read the camera index [{settings.surveillance.camera_index}] - "
+        f"{available_cameras[settings.surveillance.camera_index]}"
+    )
     if cam is None or not cam.isOpened():
         raise error
     success, frame = cam.read()
     if not success:
         raise error
     settings.surveillance.frame = frame.shape
     if cam.isOpened():
         cam.release()
-    logger.info("%s is ready to use.", available_cameras[settings.surveillance.camera_index])
+    logger.info(
+        "%s is ready to use.", available_cameras[settings.surveillance.camera_index]
+    )
     settings.surveillance.available_cameras = available_cameras
 
 
 def gen_frames(manager: Queue, index: int, available_cameras: List[str]) -> None:
     """Generates frames from the camera, flips the image and stores the frame in a multiprocessing queue.
 
     Args:
@@ -106,20 +119,24 @@
         available_cameras: List of available cameras.
     """
     cam = cv2.VideoCapture(index)
     logger.info("Capturing frames from %s", available_cameras[index])
     while True:
         success, frame = cam.read()
         if not success:
-            logger.error("Failed to capture frames from [%d]: %s", index, available_cameras[index])
+            logger.error(
+                "Failed to capture frames from [%d]: %s",
+                index,
+                available_cameras[index],
+            )
             logger.info("Releasing camera: %s", available_cameras[index])
             cam.release()
             break
         frame = cv2.flip(src=frame, flipCode=1)  # mirrors the frame
-        ret, buffer = cv2.imencode(ext='.jpg', img=frame)
+        ret, buffer = cv2.imencode(ext=".jpg", img=frame)
         frame = buffer.tobytes()
         manager.put(frame)
 
 
 def streamer() -> AsyncIterable[bytes]:
     """Yields bytes string extracted from the multiprocessing queue, until the queue_manager is alive.
 
@@ -130,10 +147,12 @@
     Warnings:
         - | When pushing large items onto a multiprocess queue, the items are essentially buffered, despite the
           | immediate return of the queues put function. This may increase the latency during live feed.
     """
     queue = settings.surveillance.queue_manager[settings.surveillance.client_id]
     try:
         while queue:
-            yield b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' + bytearray(queue.get()) + b'\r\n'
+            yield b"--frame\r\nContent-Type: image/jpeg\r\n\r\n" + bytearray(
+                queue.get()
+            ) + b"\r\n"
     except (GeneratorExit, EOFError) as error:
         logger.error(error)
```

## jarvis/api/triggers/stock_monitor.py

```diff
@@ -2,39 +2,41 @@
 
 import collections
 import logging
 import math
 import os
 import time
 from datetime import datetime
-from typing import Any, Dict, Tuple, Union
+from typing import Any, Dict, Tuple
 
 import gmailconnector
 import jinja2
 import matplotlib.dates
 import matplotlib.pyplot as plt
 from webull import webull
 
 
-def generate_graph(logger: logging.Logger, ticker: str, bars: int = 300) -> Union[str, None]:
+def generate_graph(logger: logging.Logger, ticker: str, bars: int = 300) -> str | None:
     """Generate historical graph for stock price.
 
     Args:
         logger: Takes the class ``logging.Logger`` as an argument.
         ticker: Stock ticker.
         bars: Number of bars to be fetched
 
     References:
         https://stackoverflow.com/a/49729752
     """
     logger.info("Generating price chart for '%s'", ticker)
-    dataframe = webull().get_bars(stock=ticker, interval='m60', count=bars, extendTrading=1)  # ~ 1 month
-    refined = dataframe[['close']]
+    dataframe = webull().get_bars(
+        stock=ticker, interval="m60", count=bars, extendTrading=1
+    )  # ~ 1 month
+    refined = dataframe[["close"]]
     if len(refined) == 0:
-        refined = dataframe[['open']]
+        refined = dataframe[["open"]]
     x = util.matrix_to_flat_list(input_=refined.values.tolist())
     y = [i.to_pydatetime() for i in refined.iloc[:, 0].keys()]
 
     fig, ax = plt.subplots()
     ax.plot(y, x)
 
     plt.title(ticker)
@@ -80,55 +82,59 @@
         self.repeat_alerts = list(stockmonitor_squire.get_daily_alerts())
         if self.repeat_alerts == [{}]:
             self.repeat_alerts = []
 
     def at_exit(self):
         """Removes bin file created by webull client and updates the repeat alerts yaml mapping."""
         stockmonitor_squire.put_daily_alerts(params=self.repeat_alerts)
-        os.remove('did.bin') if os.path.isfile('did.bin') else None
+        os.remove("did.bin") if os.path.isfile("did.bin") else None
 
     def group_data(self) -> None:
         """Groups columns in the database by ticker to check the current prices and by email to send a notification.
 
         See Also:
             - For ticker grouping, first value in the list is the ticker, so key will be ticker and the rest are values.
             - For email grouping, first value among the rest is the email, so key is email and the rest are values.
         """
         self.logger.info("Grouping data extracted from database.")
         for k, *v in self.data:
             self.ticker_grouped[k].append(tuple(v))
             self.email_grouped[v[0]].append((k,) + tuple(v[1:]))
 
-    def get_prices(self) -> Dict[str, Dict[str, Union[float, str]]]:
+    def get_prices(self) -> Dict[str, Dict[str, float | str]]:
         """Get the price of each stock ticker along with the exchange code.
 
         Returns:
             dict:
             Returns a dictionary of prices for each ticker and their exchange code and key-value pairs.
         """
         prices = {}
         for ticker in self.ticker_grouped.keys():
             prices[ticker] = {}
             try:
                 price_check = webull().get_quote(ticker)
-                if current_price := round(float(price_check.get('close') or price_check.get('open')), 2):
-                    prices[ticker]['price'] = float(current_price)
+                if current_price := round(
+                    float(price_check.get("close") or price_check.get("open")), 2
+                ):
+                    prices[ticker]["price"] = float(current_price)
                 else:
                     raise ValueError(price_check)
-                if category := price_check.get('disExchangeCode'):
-                    prices[ticker]['exchange_code'] = category
+                if category := price_check.get("disExchangeCode"):
+                    prices[ticker]["exchange_code"] = category
                 else:
                     raise ValueError(price_check)
             except ValueError as error:
                 self.logger.error(error)
                 continue
         return prices
 
     @staticmethod
-    def closest_maximum(stock_price: Union[int, float], maximum: Union[int, float], correction: int) -> bool:
+    def closest_maximum(
+        stock_price: int | float, maximum: int | float, correction: int
+    ) -> bool:
         """Determines if a stock price is close to the maximum value.
 
         Examples:
             - Current stock price: 96
             - Maximum price after which notification has to trigger: 100
             - Correction: 15%
 
@@ -140,21 +146,24 @@
             maximum: Maximum price set by user.
             correction: Correction percentage.
 
         Returns:
             bool:
             Boolean flag to indicate whether the current stock price is less than set maximum by correction percentage.
         """
-        if correction < 1:  # Because math.floor will round it off to the previous whole number
+        # Because math.floor will round it off to the previous whole number
+        if correction < 1:
             return False
         max_corrected_amt = math.floor(maximum - (stock_price * correction / 100))
         return stock_price >= max_corrected_amt
 
     @staticmethod
-    def closest_minimum(stock_price: Union[int, float], minimum: Union[int, float], correction: int) -> bool:
+    def closest_minimum(
+        stock_price: int | float, minimum: int | float, correction: int
+    ) -> bool:
         """Determines if a stock price is close to the minimum value.
 
         Examples:
             - Current stock price: 225
             - Minimum price below which notification has to trigger: 220
             - Correction: 10%
 
@@ -166,113 +175,159 @@
             minimum: Minimum price set by user.
             correction: Correction percentage.
 
         Returns:
             bool:
             Boolean flag to indicate whether the current stock price is more than set maximum by correction percentage.
         """
-        if correction < 1:  # Because math.ceil will round it off to the next whole number
+        # Because math.ceil will round it off to the next whole number
+        if correction < 1:
             return False
         min_corrected_amt = math.ceil(minimum + (stock_price * correction / 100))
         return stock_price <= min_corrected_amt
 
-    def skip_signal(self, condition_list: Tuple[Any, Any, Any, Any, Any, Any], hours: int = 12) -> bool:
+    def skip_signal(
+        self, condition_list: Tuple[Any, Any, Any, Any, Any, Any], hours: int = 12
+    ) -> bool:
         """Generate a skip signal for a particular stock monitoring alert.
 
         Args:
             condition_list: Alert entry for which the validation should be done.
             hours: Number of hours of overlap to look for.
 
         Returns:
             bool:
             Returns a boolean flag indicating a repeat signal was generated.
         """
         for repeater in self.repeat_alerts:
             for alert_time, alert_entry in repeater.items():
                 if alert_entry == condition_list:
-                    if time.time() <= alert_time + hours * 60 * 60:  # no notification should be triggered
+                    # no notification should be triggered
+                    if time.time() <= alert_time + hours * 60 * 60:
                         return True
                     else:
                         self.repeat_alerts.remove({alert_time: alert_entry})
                         return False  # notification should be triggered if condition matches
 
     def send_notification(self) -> None:
         """Sends notification to the user when the stock price matches the requested condition."""
         if self.data:
             self.group_data()
         else:
             self.logger.info("Database is empty!")
             return
         subject = f"Stock Price Alert - {datetime.now().strftime('%c')}"
         prices = self.get_prices()
-        mail_obj = gmailconnector.SendEmail(gmail_user=models.env.open_gmail_user,
-                                            gmail_pass=models.env.open_gmail_pass)
+        mail_obj = gmailconnector.SendEmail(
+            gmail_user=models.env.open_gmail_user, gmail_pass=models.env.open_gmail_pass
+        )
 
         for email_addr, corresponding_alerts in self.email_grouped.items():
-            datastore = {'text_gathered': [], 'removals': [], 'attachments': []}  # unique datastore for each user
+            datastore = {
+                "text_gathered": [],
+                "removals": [],
+                "attachments": [],
+            }  # unique datastore for each user
             for trigger in corresponding_alerts:
                 ticker = trigger[0]
                 maximum = trigger[1]
                 minimum = trigger[2]
                 correction = trigger[3]
                 daily_alerts = trigger[4]
                 if not prices[ticker]:
                     continue
                 if daily_alerts == "on" and self.skip_signal(
-                        condition_list=(ticker, email_addr, maximum, minimum, correction, daily_alerts),
+                    condition_list=(
+                        ticker,
+                        email_addr,
+                        maximum,
+                        minimum,
+                        correction,
+                        daily_alerts,
+                    ),
                 ):
                     self.logger.info("Skipping validations due to daily alerts.")
                     continue
-                ticker_hyperlinked = '<a href="https://www.webull.com/quote/' \
-                                     f'{prices[ticker]["exchange_code"].lower()}-{ticker.lower()}">{ticker}</a>'
+                ticker_hyperlinked = (
+                    '<a href="https://www.webull.com/quote/'
+                    f'{prices[ticker]["exchange_code"].lower()}-{ticker.lower()}">{ticker}</a>'
+                )
                 if not maximum and not minimum:
                     raise ValueError("Un-processable without both min and max")
                 maximum = util.format_nos(maximum)
                 minimum = util.format_nos(minimum)
                 email_text = ""
-                if maximum and prices[ticker]['price'] >= maximum:
+                if maximum and prices[ticker]["price"] >= maximum:
                     email_text += f"{ticker_hyperlinked} has increased more than the set value: ${maximum:,}"
-                elif maximum and self.closest_maximum(prices[ticker]['price'], maximum, correction):
-                    email_text += f"{ticker_hyperlinked} is close (within {correction}% range) to the set " \
-                                  f"maximum value: ${maximum:,}"
-                elif minimum and prices[ticker]['price'] <= minimum:
+                elif maximum and self.closest_maximum(
+                    prices[ticker]["price"], maximum, correction
+                ):
+                    email_text += (
+                        f"{ticker_hyperlinked} is close (within {correction}% range) to the set "
+                        f"maximum value: ${maximum:,}"
+                    )
+                elif minimum and prices[ticker]["price"] <= minimum:
                     email_text += f"{ticker_hyperlinked} has decreased less than the set value: ${minimum:,}"
-                elif minimum and self.closest_minimum(prices[ticker]['price'], minimum, correction):
-                    email_text += f"{ticker_hyperlinked} is close (within {correction}% range) to the set " \
-                                  f"minimum value: ${minimum:,}"
+                elif minimum and self.closest_minimum(
+                    prices[ticker]["price"], minimum, correction
+                ):
+                    email_text += (
+                        f"{ticker_hyperlinked} is close (within {correction}% range) to the set "
+                        f"minimum value: ${minimum:,}"
+                    )
                 if email_text:
                     email_text += f"<br>Current price of {ticker_hyperlinked} is ${prices[ticker]['price']:,}"
-                    datastore['text_gathered'].append(email_text)
-                    datastore['removals'].append(
-                        (ticker, email_addr, float(maximum), float(minimum), correction, daily_alerts)
+                    datastore["text_gathered"].append(email_text)
+                    datastore["removals"].append(
+                        (
+                            ticker,
+                            email_addr,
+                            float(maximum),
+                            float(minimum),
+                            correction,
+                            daily_alerts,
+                        )
+                    )
+                    datastore["attachments"].append(
+                        generate_graph(ticker=ticker, logger=self.logger)
                     )
-                    datastore['attachments'].append(generate_graph(ticker=ticker, logger=self.logger))
-            if not datastore['text_gathered']:
+            if not datastore["text_gathered"]:
                 self.logger.info("Nothing to report")
                 return
             template = jinja2.Template(templates.email.stock_alert).render(
-                CONVERTED="<br><br>".join(datastore['text_gathered'])
+                CONVERTED="<br><br>".join(datastore["text_gathered"])
+            )
+            response = mail_obj.send_email(
+                subject=subject,
+                recipient=email_addr,
+                html_body=template,
+                sender="Jarvis",
+                attachment=datastore["attachments"],
             )
-            response = mail_obj.send_email(subject=subject, recipient=email_addr, html_body=template, sender="Jarvis",
-                                           attachment=datastore['attachments'])
             if response.ok:
                 self.logger.info("Email has been sent to '%s'", email_addr)
-                for entry in datastore['removals']:
+                for entry in datastore["removals"]:
                     if entry[5] == "off":
                         self.logger.info("Removing '%s' from database.", entry)
                         stockmonitor_squire.delete_stock_userdata(data=entry)
                     else:
-                        self.logger.info("Retaining '%s' as user subscribed for daily alerts.", entry)
+                        self.logger.info(
+                            "Retaining '%s' as user subscribed for daily alerts.", entry
+                        )
                         self.repeat_alerts.append({int(time.time()): entry})
             else:
                 self.logger.error(response.json())
-            [os.remove(stock_graph) for stock_graph in datastore['attachments'] if os.path.isfile(stock_graph)]
+            [
+                os.remove(stock_graph)
+                for stock_graph in datastore["attachments"]
+                if os.path.isfile(stock_graph)
+            ]
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     # imports within __main__ to avoid potential/future path error and circular import
     # override 'current_process().name' to avoid being set as 'MainProcess'
     # importing at top level requires setting current_process().name at top level which will in turn override any import
     from multiprocessing import current_process
 
     current_process().name = "StockMonitor"
     from jarvis.api.squire import stockmonitor_squire
```

## jarvis/api/triggers/stock_report.py

```diff
@@ -4,15 +4,15 @@
 import math
 from datetime import datetime
 from typing import Tuple
 
 import jinja2
 import requests
 from pyrh import Robinhood
-from pyrh.exceptions import InvalidTickerSymbol
+from pyrh.exceptions import PyrhException
 
 
 class Investment:
     """Initiates ``Investment`` which gathers portfolio information.
 
     >>> Investment
 
@@ -20,210 +20,241 @@
 
     def __init__(self, logger: logging.Logger):
         """Authenticates Robinhood object and gathers the portfolio information to store it in a variable.
 
         Args:
             logger: Takes the class ``logging.Logger`` as an argument.
         """
-        rh = Robinhood()
-        rh.login(username=models.env.robinhood_user, password=models.env.robinhood_pass,
-                 qr_code=models.env.robinhood_qr)
+        rh = Robinhood(
+            username=models.env.robinhood_user,
+            password=models.env.robinhood_pass,
+            mfa=models.env.robinhood_qr,
+        )
+        rh.login()
         raw_result = rh.positions()
         self.logger = logger
-        if result := raw_result.get('results'):
+        if result := raw_result.get("results"):
             self.result = result
         else:
-            self.logger.error(raw_result.get('detail', raw_result))
+            self.logger.error(raw_result.get("detail", raw_result))
             self.result = []
         self.rh = rh
 
     def watcher(self) -> Tuple[str, str, str, str, str]:
         """Gathers all the information and wraps into parts of strings to create an HTML file.
 
         Returns:
             Tuple[str, str, str, str, str]:
             Returns a tuple of portfolio header, profit, loss, and current profit/loss compared from purchased.
         """
         shares_total, loss_dict, profit_dict = [], {}, {}
         num_stocks, num_shares = 0, 0
-        self.logger.info('Gathering portfolio.')
+        self.logger.info("Gathering portfolio.")
         for data in self.result:
-            shares_count = int(data['quantity'].split('.')[0])
+            shares_count = int(data["quantity"].split(".")[0])
             if not shares_count:
                 continue
             num_stocks += 1
             num_shares += shares_count
-            share_id = str(data['instrument'].split('/')[-2])
+            share_id = str(data["instrument"].split("/")[-2])
             try:
                 raw_details = self.rh.get_quote(share_id)
-            except InvalidTickerSymbol as error:
-                if str(error).strip():
-                    self.logger.error(error)
-                continue
-            ticker = (raw_details['symbol'])
-            try:
-                stock_name = requests.get(url=raw_details['instrument']).json()['simple_name']
-            except EgressErrors as error:
+                stock_name = requests.get(url=raw_details["instrument"]).json()[
+                    "simple_name"
+                ]
+            except PyrhException as error:
                 self.logger.error(error)
                 continue
-            buy = round(float(data['average_buy_price']), 2)
+            ticker = raw_details["symbol"]
+            buy = round(float(data["average_buy_price"]), 2)
             total = round(shares_count * float(buy), 2)
             shares_total.append(total)
-            current = round(float(raw_details['last_trade_price']), 2)
+            current = round(float(raw_details["last_trade_price"]), 2)
             current_total = round(shares_count * current, 2)
             difference = round(float(current_total - total), 2)
             if difference < 0:
                 loss_dict[ticker] = [
                     -difference,
                     f'\n{stock_name}:\n{shares_count:,} shares of <a href="https://robinhood.com/stocks/{ticker}" '
                     f'target="_bottom">{ticker}</a> at ${buy:,} Currently: ${current:,}\n '
-                    f'Total bought: ${total:,} Current Total: ${current_total:,}'
-                    f'\nLOST ${-difference:,}\n'
+                    f"Total bought: ${total:,} Current Total: ${current_total:,}"
+                    f"\nLOST ${-difference:,}\n",
                 ]
             else:
                 profit_dict[ticker] = [
                     difference,
                     f'\n{stock_name}:\n{shares_count:,} shares of <a href="https://robinhood.com/stocks/{ticker}" '
                     f'target="_bottom">{ticker}</a> at ${buy:,} Currently: ${current:,}\n'
-                    f'Total bought: ${total:,} Current Total: ${current_total:,}'
-                    f'\nGained ${difference:,}\n'
+                    f"Total bought: ${total:,} Current Total: ${current_total:,}"
+                    f"\nGained ${difference:,}\n",
                 ]
 
         profit_output, profit_total, loss_output, loss_total = "", [], "", []
-        for key, value in sorted(profit_dict.items(), reverse=True, key=lambda item: item[1]):
+        for key, value in sorted(
+            profit_dict.items(), reverse=True, key=lambda item: item[1]
+        ):
             profit_output += value[1]
             profit_total.append(value[0])
-        for key, value in sorted(loss_dict.items(), reverse=True, key=lambda item: item[1]):
+        for key, value in sorted(
+            loss_dict.items(), reverse=True, key=lambda item: item[1]
+        ):
             loss_output += value[1]
             loss_total.append(value[0])
 
-        port_msg = f'\nTotal Profit: ${round(math.fsum(profit_total), 2):,}\n' \
-                   f'Total Loss: ${round(math.fsum(loss_total), 2):,}\n\n' \
-                   'The above values might differ from overall profit/loss if multiple shares ' \
-                   'of the stock were purchased at different prices.'
-        net_worth = round(float(self.rh.equity()), 2)
-        output = f'Total number of stocks purchased: {num_stocks:,}\n'
-        output += f'Total number of shares owned: {num_shares:,}\n'
-        output += f'\nCurrent value of your total investment is: ${net_worth:,}'
+        portfolio = self.rh.portfolio()
+        port_msg = (
+            f"\nTotal Profit: ${round(math.fsum(profit_total), 2):,}\n"
+            f"Total Loss: ${round(math.fsum(loss_total), 2):,}\n\n"
+            "The above values might differ from overall profit/loss if multiple shares "
+            "of the stock were purchased at different prices."
+        )
+        net_worth = round(float(portfolio.equity), 2)
+        withdrawable_amount = round(float(portfolio.withdrawable_amount))
+        output = f"Total number of stocks purchased: {num_stocks:,}\n"
+        output += f"Total number of shares owned: {num_shares:,}\n"
+        output += f"\nCurrent value of your total investment is: ${net_worth:,}"
         total_buy = round(math.fsum(shares_total), 2)
-        output += f'\nValue of your total investment while purchase is: ${total_buy:,}'
-        total_diff = round(float(net_worth - total_buy), 2)
-        rh_text = f"You have purchased {num_stocks:,} stocks and currently own {num_shares:,} shares sir. " \
-                  f"Your total investment is ${round(net_worth):,}, and it was ${round(total_buy):,} when you " \
-                  f"purchased. Currently we are on an overall "
+        output += f"\nValue of your total investment while purchase is: ${total_buy:,}"
+        total_diff = round(float(net_worth - total_buy), 2) - withdrawable_amount
+        rh_text = (
+            f"You have purchased {num_stocks:,} stocks and currently own {num_shares:,} shares {models.env.title}. "
+            f"Your total investment is ${round(net_worth):,}, and it was ${round(total_buy):,} when you purchased. "
+            f"Your current withdrawable amount is ${withdrawable_amount:,}. "
+            f"Currently we are on an overall "
+        )
         if total_diff < 0:
             rh_text += f"loss of ${round(total_diff):,} {models.env.title}"
-            output += f'\n\nOverall Loss: ${total_diff:,}'
+            output += f"\n\nOverall Loss: ${total_diff:,}"
         else:
             rh_text += f"profit of ${round(total_diff):,} {models.env.title}"
-            output += f'\n\nOverall Profit: ${total_diff:,}'
-        yesterday_close = round(float(self.rh.equity_previous_close()), 2)
+            output += f"\n\nOverall Profit: ${total_diff:,}"
+        yesterday_close = round(float(portfolio.equity_previous_close), 2)
         two_day_diff = round(float(net_worth - yesterday_close), 2)
         output += f"\n\nYesterday's closing value: ${yesterday_close:,}"
         if two_day_diff < 0:
             output += f"\nCurrent Dip: ${two_day_diff:,}"
         else:
             output += f"\nCurrent Spike: ${two_day_diff:,}"
+        output += f"\n\nWithdrawable Amount: ${withdrawable_amount:,}"
         return port_msg, profit_output, loss_output, output, rh_text
 
-    def watchlist(self, interval: str = 'hour', strict: bool = False) -> Tuple[str, str]:
+    def watchlist(
+        self, interval: str = "hour", strict: bool = False
+    ) -> Tuple[str, str]:
         """Sweeps all watchlist stocks and compares current price with historical data (24h ago) to wrap as a string.
 
         Args:
             interval: Takes interval for historic data. Defaults to ``hour``. Options are ``hour`` or ``10minute``
             strict: Flag to ignore the watchlist items if the stocks were purchased already.
 
         Returns:
             Tuple[str, str]:
             Returns a tuple of each watch list item and a unicode character to indicate if the price went up or down.
         """
-        r1, r2 = '', ''
-        self.logger.info('Gathering watchlist.')
-        watchlist = [self.rh.get_url(item['instrument'])
-                     for item in self.rh.get_url(url='https://api.robinhood.com/watchlists/Default').get('results', [])]
+        r1, r2 = "", ""
+        self.logger.info("Gathering watchlist.")
+        watchlist = [
+            self.rh.get_url(item["instrument"])
+            for item in self.rh.get_url(
+                url="https://api.robinhood.com/watchlists/Default"
+            ).get("results", [])
+        ]
         if not watchlist:
             return r1, r2
-        instruments = [data['instrument'] for data in self.result] if strict else []
+        instruments = [data["instrument"] for data in self.result] if strict else []
         for item in watchlist:
-            if strict and item['url'] in instruments:
+            if strict and item["url"] in instruments:
                 continue
-            stock = item['symbol']
-            if interval == 'hour':
-                historic_data = self.rh.get_historical_quotes(stock, 'hour', 'day')
+            stock = item["symbol"]
+            if interval == "hour":
+                historic_data = self.rh.get_historical_quotes(stock, "hour", "day")
             else:
-                historic_data = self.rh.get_historical_quotes(stock, '10minute', 'day')
-            historic_results = historic_data['results']
-            numbers = [round(float(close_price['close_price']), 2) for each_item in historic_results
-                       for close_price in each_item['historicals']]
+                historic_data = self.rh.get_historical_quotes(stock, "10minute", "day")
+            historic_results = historic_data["results"]
+            numbers = [
+                round(float(close_price["close_price"]), 2)
+                for each_item in historic_results
+                for close_price in each_item["historicals"]
+            ]
             if not numbers:
                 return r1, r2
             try:
                 raw_details = self.rh.get_quote(stock)
-            except InvalidTickerSymbol as error:
-                if str(error).strip():
-                    self.logger.error(error)
-                continue
-            try:
-                stock_name = requests.get(raw_details['instrument']).json()['simple_name']
-            except EgressErrors as error:
+                stock_name = requests.get(raw_details["instrument"]).json()[
+                    "simple_name"
+                ]
+            except PyrhException as error:
                 self.logger.error(error)
                 continue
-            price = round(float(raw_details['last_trade_price']), 2)
+            price = round(float(raw_details["last_trade_price"]), 2)
             difference = round(float(price - numbers[-1]), 2)
             if price < numbers[-1]:
-                r1 += f'{stock_name}\t<a href="https://robinhood.com/stocks/{stock}" target="_bottom">{stock}</a>: ' \
-                      f'{price:,} &#8595 {difference}\n'
+                r1 += (
+                    f'{stock_name}\t<a href="https://robinhood.com/stocks/{stock}" target="_bottom">{stock}</a>: '
+                    f"{price:,} &#8595 {difference}\n"
+                )
             else:
-                r2 += f'{stock_name}\t<a href="https://robinhood.com/stocks/{stock}" target="_bottom">{stock}</a>: ' \
-                      f'{price:,} &#8593 {difference}\n'
+                r2 += (
+                    f'{stock_name}\t<a href="https://robinhood.com/stocks/{stock}" target="_bottom">{stock}</a>: '
+                    f"{price:,} &#8593 {difference}\n"
+                )
         return r1, r2
 
     def gatherer(self) -> None:
         """Gathers all the necessary information and creates an ``index.html`` using a ``Jinja`` template."""
         if not self.result:
             return
         current_time = datetime.now()
 
         port_head, profit, loss, overall_result, summary = self.watcher()
         s1, s2 = self.watchlist()
-        self.logger.info('Generating HTMl file.')
+        self.logger.info("Generating HTMl file.")
 
         title = f'Investment Summary as of {current_time.strftime("%A, %B %d, %Y %I:%M %p")}'
-        web_text = f'\n{overall_result}\n{port_head}\n'
-        profit_web = f'\n{profit}\n'
-        loss_web = f'\n{loss}\n'
-        title = title.replace('\n', '\n\t\t\t')
-        web_text = web_text.replace('\n', '\n\t\t\t')
-        profit_web = profit_web.replace('\n', '\n\t\t\t\t')
-        loss_web = loss_web.replace('\n', '\n\t\t\t\t')
-        s2 = s2.replace('\n', '\n\t\t\t')
-        s1 = s1.replace('\n', '\n\t\t\t')
-
-        rendered = jinja2.Template(templates.endpoint.robinhood).render(TITLE=title, SUMMARY=web_text,
-                                                                        PROFIT=profit_web, LOSS=loss_web,
-                                                                        WATCHLIST_UP=s2, WATCHLIST_DOWN=s1)
-        with open(models.fileio.robinhood, 'w') as static_file:
+        web_text = f"\n{overall_result}\n{port_head}\n"
+        profit_web = f"\n{profit}\n"
+        loss_web = f"\n{loss}\n"
+        title = title.replace("\n", "\n\t\t\t")
+        web_text = web_text.replace("\n", "\n\t\t\t")
+        profit_web = profit_web.replace("\n", "\n\t\t\t\t")
+        loss_web = loss_web.replace("\n", "\n\t\t\t\t")
+        s2 = s2.replace("\n", "\n\t\t\t")
+        s1 = s1.replace("\n", "\n\t\t\t")
+
+        rendered = jinja2.Template(templates.endpoint.robinhood).render(
+            TITLE=title,
+            SUMMARY=web_text,
+            PROFIT=profit_web,
+            LOSS=loss_web,
+            WATCHLIST_UP=s2,
+            WATCHLIST_DOWN=s1,
+        )
+        with open(models.fileio.robinhood, "w") as static_file:
             static_file.write(rendered)
-        self.logger.info("Static file '%s' has been generated.", models.fileio.robinhood)
+        self.logger.info(
+            "Static file '%s' has been generated.", models.fileio.robinhood
+        )
         with db.connection:
             cursor = db.connection.cursor()
             cursor.execute("DELETE FROM robinhood;")
-            cursor.execute("INSERT or REPLACE INTO robinhood (summary) VALUES (?);", (summary,))
+            cursor.execute(
+                "INSERT or REPLACE INTO robinhood (summary) VALUES (?);", (summary,)
+            )
             db.connection.commit()
         self.logger.info("Stored summary in database.")
 
     def report_gatherer(self) -> None:
         """Runs gatherer to call other dependent methods."""
         try:
             self.gatherer()
         except EgressErrors as error:
             self.logger.error(error)
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     # imports within __main__ to avoid potential/future path error and circular import
     # override 'current_process().name' to avoid being set as 'MainProcess'
     # importing at top level requires setting current_process().name at top level which will in turn override any import
     from multiprocessing import current_process
 
     current_process().name = "StockReport"
     from jarvis.executors import crontab
```

## jarvis/executors/alarm.py

```diff
@@ -1,27 +1,28 @@
 import os
 import random
 import string
 import subprocess
 import time
 from datetime import datetime, timedelta
-from typing import Dict, List, Union
+from typing import Dict, List
 
 import pyvolume
 
 from jarvis.executors import files, word_match
 from jarvis.modules.audio import listener, speaker
 from jarvis.modules.conditions import conversation
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.utils import shared, support, util
 
 
-def check_overlap(new_alarm: Dict[str, Union[str, bool]],
-                  old_alarms: List[Dict[str, Union[str, bool]]]) -> bool:
+def check_overlap(
+    new_alarm: Dict[str, str | bool], old_alarms: List[Dict[str, str | bool]]
+) -> bool:
     """Checks to see if there is a possibility of an overlap.
 
     Args:
         new_alarm: Current alarm formatted as a dict.
         old_alarms: List of existing alarms.
 
     Returns:
@@ -29,30 +30,45 @@
         Returns a True flag if it is an overlap.
     """
     if new_alarm in old_alarms:
         speaker.speak(text=f"You have a duplicate alarm {models.env.title}!")
         return True
     for old_alarm in old_alarms:
         # old alarm is set for the same time and the old alarm is set for everyday
-        difference = abs((datetime.strptime(old_alarm['alarm_time'], '%I:%M %p') -
-                          datetime.strptime(new_alarm['alarm_time'], '%I:%M %p')).total_seconds())
+        difference = abs(
+            (
+                datetime.strptime(old_alarm["alarm_time"], "%I:%M %p")
+                - datetime.strptime(new_alarm["alarm_time"], "%I:%M %p")
+            ).total_seconds()
+        )
         # check if alarm time are the same or overlaps within 230 seconds (number of seconds an alarm will play)
         # check if the alarm is set daily ('repeat' is 'True' but 'day' is null)
-        if (new_alarm['alarm_time'] == old_alarm['alarm_time'] or difference <= 203) and \
-                old_alarm['repeat'] and \
-                not old_alarm.get('day'):
+        if (
+            (new_alarm["alarm_time"] == old_alarm["alarm_time"] or difference <= 203)
+            and old_alarm["repeat"]
+            and not old_alarm.get("day")
+        ):
             if difference <= 203:  # within 203 seconds of an existing alarm
-                logger.info("Difference between both the alarms in seconds: %.2f", difference)
-            speaker.speak(text=f"You have an existing alarm, at {old_alarm['alarm_time']} "
-                               f"that overlaps with this one {models.env.title}!")
+                logger.info(
+                    "Difference between both the alarms in seconds: %.2f", difference
+                )
+            speaker.speak(
+                text=f"You have an existing alarm, at {old_alarm['alarm_time']} "
+                f"that overlaps with this one {models.env.title}!"
+            )
             return True
 
 
-def create_alarm(alarm_time: datetime, phrase: str, timer: str = None,
-                 repeat: bool = False, day: str = None) -> None:
+def create_alarm(
+    alarm_time: datetime,
+    phrase: str,
+    timer: str = None,
+    repeat: bool = False,
+    day: str = None,
+) -> None:
     """Creates an entry in the alarms' mapping file.
 
     Args:
         alarm_time: Time of alarm as a datetime object.
         phrase: Takes the phrase spoken as an argument.
         timer: Number of minutes/hours to alarm.
         repeat: Boolean flag if the alarm should be repeated every day.
@@ -61,245 +77,308 @@
     existing_alarms = files.get_alarms()
     formatted = dict(
         alarm_time=alarm_time.strftime("%I:%M %p"),
         day=day,
         repeat=repeat,
     )
     if not day:
-        formatted.pop('day')
+        formatted.pop("day")
     if check_overlap(new_alarm=formatted, old_alarms=existing_alarms):
         return
     existing_alarms.append(formatted)
     files.put_alarms(data=existing_alarms)
     logger.info("Alarm/timer set at {%s}", alarm_time.strftime("%I:%M %p"))
-    if 'wake' in phrase:
-        speaker.speak(text=f"{random.choice(conversation.acknowledgement)}! "
-                           f"I will wake you up at {alarm_time.strftime('%I:%M %p')}.")
-    elif 'timer' in phrase and timer:
+    if "wake" in phrase:
+        speaker.speak(
+            text=f"{random.choice(conversation.acknowledgement)}! "
+            f"I will wake you up at {alarm_time.strftime('%I:%M %p')}."
+        )
+    elif "timer" in phrase and timer:
         response = [
             f"{random.choice(conversation.acknowledgement)}! I have set a timer for {timer}.",
-            f"{timer}! Counting down.."
+            f"{timer}! Counting down..",
         ]
         speaker.speak(text=random.choice(response))
     else:
         if day:  # If day is set, then it's obviously a repeat with a 'day' filter
             add = f"every {day}."
         elif repeat:  # If no day is set, then it's a repeat everyday
             add = "every day."
         elif alarm_time.date() > datetime.today().date():
             add = "tomorrow."
         else:
             add = "."
         response = [
             f"Alarm has been set for {alarm_time.strftime('%I:%M %p')} {add}",
-            f"Your alarm is set for {alarm_time.strftime('%I:%M %p')} {add}"
+            f"Your alarm is set for {alarm_time.strftime('%I:%M %p')} {add}",
         ]
-        speaker.speak(text=f"{random.choice(conversation.acknowledgement)}! {random.choice(response)}")
+        speaker.speak(
+            text=f"{random.choice(conversation.acknowledgement)}! {random.choice(response)}"
+        )
 
 
 def set_alarm(phrase: str) -> None:
     """Passes hour, minute and am/pm to ``Alarm`` class which initiates a thread for alarm clock in the background.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
     """
     if models.settings.limited:
-        speaker.speak(text="Alarm features are currently unavailable, as you're running on restricted mode.")
+        speaker.speak(
+            text="Alarm features are currently unavailable, as you're running on restricted mode."
+        )
         return
     phrase = phrase.lower()
-    if 'minute' in phrase:
+    if "minute" in phrase:
         if minutes := util.extract_nos(input_=phrase, method=int):
             create_alarm(
-                alarm_time=datetime.now() + timedelta(minutes=minutes), phrase=phrase,
-                timer=f"{minutes} {support.ENGINE.plural(text='minute', count=minutes)}"
+                alarm_time=datetime.now() + timedelta(minutes=minutes),
+                phrase=phrase,
+                timer=f"{minutes} {support.ENGINE.plural(text='minute', count=minutes)}",
             )
             return
-    elif 'hour' in phrase:
+    elif "hour" in phrase:
         if hours := util.extract_nos(input_=phrase, method=int):
             create_alarm(
-                alarm_time=datetime.now() + timedelta(hours=hours), phrase=phrase,
-                timer=f"{hours} {support.ENGINE.plural(text='hour', count=hours)}"
+                alarm_time=datetime.now() + timedelta(hours=hours),
+                phrase=phrase,
+                timer=f"{hours} {support.ENGINE.plural(text='hour', count=hours)}",
             )
             return
     if extracted_time := util.extract_time(input_=phrase) or word_match.word_match(
-            phrase=phrase, match_list=('noon', 'midnight', 'mid night')
+        phrase=phrase, match_list=("noon", "midnight", "mid night")
     ):
-        if 'noon' in phrase:
+        if "noon" in phrase:
             extracted_time = ["12:00 PM"]
-        elif 'night' in phrase:
+        elif "night" in phrase:
             extracted_time = ["12:00 AM"]
-        extracted_time = extracted_time[0]
-        alarm_time = extracted_time.split()[0]
-        if ":" in extracted_time:
-            hour = int(alarm_time.split(":")[0])
-            minute = int(alarm_time.split(":")[-1])
-        else:
-            hour = int(alarm_time.split()[0])
-            minute = 0
-        # makes sure hour and minutes are two digits
-        hour, minute = f"{hour:02}", f"{minute:02}"
-        am_pm = "AM" if "A" in extracted_time.split()[-1].upper() else "PM"
+        hour, minute, am_pm = util.split_time(input_=extracted_time[0])
         if int(hour) <= 12 and int(minute) <= 59:
             datetime_obj = datetime.strptime(f"{hour}:{minute} {am_pm}", "%I:%M %p")
-            if day := word_match.word_match(phrase=phrase, match_list=('sunday', 'monday', 'tuesday', 'wednesday',
-                                                                       'thursday', 'friday', 'saturday',
-                                                                       'sundays', 'mondays', 'tuesdays', 'wednesdays',
-                                                                       'thursdays', 'fridays', 'saturdays')):
-                create_alarm(phrase=phrase, alarm_time=datetime_obj, day=string.capwords(day), repeat=True)
-            elif word_match.word_match(phrase=phrase, match_list=('everyday', 'every day', 'daily')):
+            if day := word_match.word_match(
+                phrase=phrase,
+                match_list=(
+                    "sunday",
+                    "monday",
+                    "tuesday",
+                    "wednesday",
+                    "thursday",
+                    "friday",
+                    "saturday",
+                    "sundays",
+                    "mondays",
+                    "tuesdays",
+                    "wednesdays",
+                    "thursdays",
+                    "fridays",
+                    "saturdays",
+                ),
+            ):
+                create_alarm(
+                    phrase=phrase,
+                    alarm_time=datetime_obj,
+                    day=string.capwords(day),
+                    repeat=True,
+                )
+            elif word_match.word_match(
+                phrase=phrase, match_list=("everyday", "every day", "daily")
+            ):
                 create_alarm(phrase=phrase, alarm_time=datetime_obj, repeat=True)
             else:
                 create_alarm(phrase=phrase, alarm_time=datetime_obj)
         else:
-            speaker.speak(text=f"An alarm at {hour}:{minute} {am_pm}? Are you an alien? "
-                               "I don't think a time like that exists on Earth.")
+            speaker.speak(
+                text=f"An alarm at {hour}:{minute} {am_pm}? Are you an alien? "
+                "I don't think a time like that exists on Earth."
+            )
     else:
-        if word_match.word_match(phrase=phrase,
-                                 match_list=('get', 'what', 'send', 'list', 'exist', 'existing', 'do', 'have', 'i')):
+        if word_match.word_match(
+            phrase=phrase,
+            match_list=(
+                "get",
+                "what",
+                "send",
+                "list",
+                "exist",
+                "existing",
+                "do",
+                "have",
+                "i",
+            ),
+        ):
             if alarm_states := get_alarm_state():
                 if len(alarm_states) > 1:
-                    speaker.speak(text=f"Your alarms are at, {util.comma_separator(alarm_states)}.")
+                    speaker.speak(
+                        text=f"Your alarms are at, {util.comma_separator(alarm_states)}."
+                    )
                 else:
-                    speaker.speak(text=f"You have an alarm at, {util.comma_separator(alarm_states)}.")
+                    speaker.speak(
+                        text=f"You have an alarm at, {util.comma_separator(alarm_states)}."
+                    )
             else:
                 speaker.speak(text=f"You don't have any alarms set {models.env.title}!")
             return
         speaker.speak(text=f"Please tell me a time {models.env.title}!")
         if shared.called_by_offline:
             return
         speaker.speak(run=True)
         if converted := listener.listen():
-            if 'exit' in converted or 'quit' in converted or 'Xzibit' in converted:
+            if "exit" in converted or "quit" in converted or "Xzibit" in converted:
                 return
             else:
                 set_alarm(converted)
 
 
 def get_alarm_state(alarm_time: str = None) -> List[str]:
     """Frames a response text with all the alarms present.
 
     Returns:
         List[str]:
         Returns a list of alarms framed as a response.
     """
     _alarms = files.get_alarms()
     if alarm_time:
-        _alarms = [_alarm for _alarm in _alarms if _alarm['alarm_time'] == alarm_time]
+        _alarms = [_alarm for _alarm in _alarms if _alarm["alarm_time"] == alarm_time]
     response = []
     for _alarm in _alarms:
-        if _alarm['repeat']:
-            response.append(f"{_alarm['alarm_time']} on every {_alarm.get('day', 'day')}")
+        if _alarm["repeat"]:
+            response.append(
+                f"{_alarm['alarm_time']} on every {_alarm.get('day', 'day')}"
+            )
         else:
-            response.append(_alarm['alarm_time'])
+            response.append(_alarm["alarm_time"])
     return response
 
 
-def more_than_one_alarm_to_kill(alarms: List[Dict[str, Union[str, bool]]],
-                                phrase: str, alarm_states: List[str]) -> None:
+def more_than_one_alarm_to_kill(
+    alarms: List[Dict[str, str | bool]], phrase: str, alarm_states: List[str]
+) -> None:
     """Helper function for kill alarm, if there are multiple alarms set at the same time with different days.
 
     Args:
         alarms: All existing alarms.
         phrase: Takes the phrase spoken as an argument.
         alarm_states: Alarms that were converted as response.
     """
-    if day := word_match.word_match(phrase=phrase,
-                                    match_list=('sunday', 'monday', 'tuesday', 'wednesday',
-                                                'thursday', 'friday', 'saturday',
-                                                'sundays', 'mondays', 'tuesdays', 'wednesdays',
-                                                'thursdays', 'fridays', 'saturdays')):
+    if day := word_match.word_match(
+        phrase=phrase,
+        match_list=(
+            "sunday",
+            "monday",
+            "tuesday",
+            "wednesday",
+            "thursday",
+            "friday",
+            "saturday",
+            "sundays",
+            "mondays",
+            "tuesdays",
+            "wednesdays",
+            "thursdays",
+            "fridays",
+            "saturdays",
+        ),
+    ):
         del_alarm = None
         for __alarm in alarms:
-            if __alarm.get('day', '').lower() == day.lower():
+            if __alarm.get("day", "").lower() == day.lower():
                 del_alarm = __alarm
                 break
         if del_alarm:
-            if del_alarm['repeat']:
-                speaker.speak(text=f"Your alarm at {del_alarm['alarm_time']} on every "
-                                   f"{del_alarm.get('day', 'day')} has been silenced {models.env.title}!")
+            if del_alarm["repeat"]:
+                speaker.speak(
+                    text=f"Your alarm at {del_alarm['alarm_time']} on every "
+                    f"{del_alarm.get('day', 'day')} has been silenced {models.env.title}!"
+                )
             else:
-                speaker.speak(text=f"Your alarm at {del_alarm['alarm_time']} "
-                                   f"has been silenced {models.env.title}!")
+                speaker.speak(
+                    text=f"Your alarm at {del_alarm['alarm_time']} "
+                    f"has been silenced {models.env.title}!"
+                )
             alarms.remove(del_alarm)
             files.put_alarms(alarms)
         else:
             speaker.speak(text=f"There are no such alarms setup {models.env.title}!")
     else:
-        speaker.speak(f"You have {len(alarm_states)} alarms matching the same time {models.env.title}! "
-                      f"{util.comma_separator(alarm_states)}. Please be more specific.")
+        speaker.speak(
+            f"You have {len(alarm_states)} alarms matching the same time {models.env.title}! "
+            f"{util.comma_separator(alarm_states)}. Please be more specific."
+        )
 
 
 def kill_alarm(phrase: str) -> None:
     """Removes the entry from the alarms' mapping file.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
     """
-    word = 'timer' if 'timer' in phrase else 'alarm'
+    word = "timer" if "timer" in phrase else "alarm"
     alarms = files.get_alarms()
     if not alarms:
         speaker.speak(text=f"You have no {word}s set {models.env.title}!")
         return
     if len(alarms) == 1:
         _alarm = alarms[0]
         response = f"Your {word} at {_alarm['alarm_time']} "
-        if _alarm['repeat']:
+        if _alarm["repeat"]:
             response += f"on every {_alarm.get('day', 'day')} "
         response += f"has been silenced {models.env.title}!"
         speaker.speak(text=response)
         alarms.clear()
         files.put_alarms(data=alarms)
         return
     if "all" in phrase.split():
-        speaker.speak(text=f"I have silenced {len(alarms)} of your alarms {models.env.title}!")
+        speaker.speak(
+            text=f"I have silenced {len(alarms)} of your alarms {models.env.title}!"
+        )
         alarms.clear()
         files.put_alarms(data=alarms)
         return
     if extracted_time := util.extract_time(input_=phrase) or word_match.word_match(
-            phrase=phrase, match_list=('noon', 'midnight', 'mid night')
+        phrase=phrase, match_list=("noon", "midnight", "mid night")
     ):
-        if 'noon' in phrase:
+        if "noon" in phrase:
             extracted_time = ["12:00 PM"]
-        elif 'night' in phrase:
+        elif "night" in phrase:
             extracted_time = ["12:00 AM"]
-        extracted_time = extracted_time[0]
-        alarm_time = extracted_time.split()[0]
-        if ":" in extracted_time:
-            hour = int(alarm_time.split(":")[0])
-            minute = int(alarm_time.split(":")[-1])
-        else:
-            hour = int(alarm_time.split()[0])
-            minute = 0
-        # makes sure hour and minutes are two digits
-        hour, minute = f"{hour:02}", f"{minute:02}"
-        am_pm = "AM" if "A" in extracted_time.split()[-1].upper() else "PM"
+        hour, minute, am_pm = util.split_time(extracted_time[0])
         if int(hour) <= 12 and int(minute) <= 59:
             chosen_alarm = f"{hour}:{minute} {am_pm}"
-            if chosen_alarm in [_alarm['alarm_time'] for _alarm in alarms]:
+            if chosen_alarm in [_alarm["alarm_time"] for _alarm in alarms]:
                 # construct response before updating the base file
                 alarm_states = get_alarm_state(alarm_time=chosen_alarm)
                 if len(alarm_states) > 1:
                     more_than_one_alarm_to_kill(alarms, phrase, alarm_states)
                     return
                 response = f"Your alarm at {alarm_states[0]} has been silenced {models.env.title}!"
-                files.put_alarms(data=[_alarm for _alarm in alarms if _alarm['alarm_time'] != chosen_alarm])
+                files.put_alarms(
+                    data=[
+                        _alarm
+                        for _alarm in alarms
+                        if _alarm["alarm_time"] != chosen_alarm
+                    ]
+                )
                 speaker.speak(text=response)
             else:
-                speaker.speak(text=f"There are no such alarms setup {models.env.title}!")
+                speaker.speak(
+                    text=f"There are no such alarms setup {models.env.title}!"
+                )
         else:
             speaker.speak(text="Such an alarm time is impossible!")
     else:
         alarm_states = get_alarm_state()
-        response = f"Your alarms are at, {util.comma_separator(alarm_states)}. " \
-                   "Please let me know which one I should delete."
+        response = (
+            f"Your alarms are at, {util.comma_separator(alarm_states)}. "
+            "Please let me know which one I should delete."
+        )
         speaker.speak(text=response)
 
 
 def executor() -> None:
     """Runs the ``alarm.mp3`` file at max volume and reverts the volume after 3 minutes."""
     pyvolume.increase(logger)
     if models.settings.os != models.supported_platforms.windows:
         subprocess.call(["open", models.indicators.alarm])
     else:
-        os.system(f'start wmplayer {models.indicators.alarm}')
+        os.system(f"start wmplayer {models.indicators.alarm}")
     time.sleep(200)
     pyvolume.custom(models.env.volume, logger)
```

## jarvis/executors/automation.py

```diff
@@ -1,10 +1,9 @@
 import os
 from datetime import datetime, timedelta
-from typing import Union
 
 from deepdiff import DeepDiff
 
 from jarvis.executors import files
 from jarvis.modules.audio import speaker
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
@@ -19,23 +18,27 @@
     if "enable" in phrase.lower():
         if os.path.isfile(models.fileio.tmp_automation):
             os.rename(src=models.fileio.tmp_automation, dst=models.fileio.automation)
             speaker.speak(text=f"Automation has been enabled {models.env.title}!")
         elif os.path.isfile(models.fileio.automation):
             speaker.speak(text=f"Automation was never disabled {models.env.title}!")
         else:
-            speaker.speak(text=f"I couldn't not find the source file to enable automation {models.env.title}!")
+            speaker.speak(
+                text=f"I couldn't not find the source file to enable automation {models.env.title}!"
+            )
     elif "disable" in phrase.lower():
         if os.path.isfile(models.fileio.automation):
             os.rename(src=models.fileio.automation, dst=models.fileio.tmp_automation)
             speaker.speak(text=f"Automation has been disabled {models.env.title}!")
         elif os.path.isfile(models.fileio.tmp_automation):
             speaker.speak(text=f"Automation was never enabled {models.env.title}!")
         else:
-            speaker.speak(text=f"I couldn't not find the source file to disable automation {models.env.title}!")
+            speaker.speak(
+                text=f"I couldn't not find the source file to disable automation {models.env.title}!"
+            )
 
 
 def rewrite_automator(write_data: dict) -> None:
     """Rewrites the automation file with the updated dictionary.
 
     Args:
         write_data: Takes the new dictionary as an argument.
@@ -49,41 +52,58 @@
 def validate_weather_alert() -> None:
     """Adds the env var for weather alert (if present) to automation feed file."""
     if models.env.weather_alert:
         automation_data = files.get_automation()
         if tasks_overlap := automation_data.get(models.env.weather_alert):
             for task_overlap in tasks_overlap:
                 if "weather" in task_overlap.get("task"):
-                    logger.info("Redundancy found in env var and automation. Skipping..")
+                    logger.info(
+                        "Redundancy found in env var and automation. Skipping.."
+                    )
                     return
                 else:
-                    logger.warning("%s was found at '%s', appending a minute to weather alert",
-                                   task_overlap, models.env.weather_alert)
-                    time_overlap = datetime.strptime(models.env.weather_alert, '%I:%M %p')
-                    models.env.weather_alert = (time_overlap + timedelta(minutes=1)).strftime('%I:%M %p')
-                    automation_data[models.env.weather_alert].append({"task": "weather alert"})
+                    logger.warning(
+                        "%s was found at '%s', appending a minute to weather alert",
+                        task_overlap,
+                        models.env.weather_alert,
+                    )
+                    time_overlap = datetime.strptime(
+                        models.env.weather_alert, "%I:%M %p"
+                    )
+                    models.env.weather_alert = (
+                        time_overlap + timedelta(minutes=1)
+                    ).strftime("%I:%M %p")
+                    automation_data[models.env.weather_alert].append(
+                        {"task": "weather alert"}
+                    )
                     files.put_automation(data=automation_data)
         else:  # Write weather alert schedule to 'automation.yaml' since env var is not used to trigger the function
-            logger.info("Storing weather alert schedule '%s' to %s", models.env.weather_alert, models.fileio.automation)
+            logger.info(
+                "Storing weather alert schedule '%s' to %s",
+                models.env.weather_alert,
+                models.fileio.automation,
+            )
             automation_data[models.env.weather_alert] = [{"task": "weather alert"}]
             files.put_automation(data=automation_data)
 
 
-def auto_helper() -> Union[str, None]:
+def auto_helper() -> str | None:
     """Runs in a thread to help the automator function in the main module.
 
     Returns:
         str:
         Task to be executed.
     """
     automation_data = files.get_automation()
     for automation_time, automation_schedule in automation_data.items():
         try:
             datetime.strptime(automation_time, "%I:%M %p")
-            assert automation_schedule, "Following entry does not have the task information."
+            assert (
+                automation_schedule
+            ), "Following entry does not have the task information."
         except (ValueError, AssertionError) as error:
             logger.error(error)
             logger.error("%s - %s", automation_time, automation_schedule)
             automation_data.pop(automation_time)
             rewrite_automator(write_data=automation_data)
             # Use return as python doesn't like dict size change between a loop
             # Since this function is called every second, there is no need for recursion
@@ -114,24 +134,34 @@
                 if isinstance(day, list):
                     if today not in [d.upper() for d in day]:
                         continue
                 elif isinstance(day, str):
                     day = day.upper()
                     if day == "WEEKEND" and today in ["SATURDAY", "SUNDAY"]:
                         pass
-                    elif day == "WEEKDAY" and today in ["MONDAY", "TUESDAY", "WEDNESDAY", "THURSDAY", "FRIDAY"]:
+                    elif day == "WEEKDAY" and today in [
+                        "MONDAY",
+                        "TUESDAY",
+                        "WEDNESDAY",
+                        "THURSDAY",
+                        "FRIDAY",
+                    ]:
                         pass
                     elif today == day:
                         pass
                     else:
                         continue
 
             if automation_time != datetime.now().strftime("%I:%M %p"):
                 if automation_info.get("status"):
-                    logger.info("Reverting execution status flag for task: %s runs at %s", exec_task, automation_time)
+                    logger.info(
+                        "Reverting execution status flag for task: %s runs at %s",
+                        exec_task,
+                        automation_time,
+                    )
                     del automation_data[automation_time][index]["status"]
                     rewrite_automator(write_data=automation_data)
                 continue
 
             if automation_info.get("status"):
                 continue
             automation_data[automation_time][index]["status"] = True
```

## jarvis/executors/background_task.py

```diff
@@ -1,12 +1,11 @@
 import os
 import warnings
 from collections import OrderedDict
 from collections.abc import Generator
-from typing import Union
 
 import yaml
 from pydantic import ValidationError
 
 from jarvis.modules.audio import speaker
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
@@ -18,65 +17,94 @@
     """Handles background tasks file resets by renaming it to tmp if requested to disable.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
     """
     if "enable" in phrase.lower():
         if os.path.isfile(models.fileio.tmp_background_tasks):
-            os.rename(src=models.fileio.tmp_background_tasks, dst=models.fileio.background_tasks)
-            speaker.speak(text=f"Background tasks have been enabled {models.env.title}!")
+            os.rename(
+                src=models.fileio.tmp_background_tasks,
+                dst=models.fileio.background_tasks,
+            )
+            speaker.speak(
+                text=f"Background tasks have been enabled {models.env.title}!"
+            )
         elif os.path.isfile(models.fileio.background_tasks):
-            speaker.speak(text=f"Background tasks were never disabled {models.env.title}!")
+            speaker.speak(
+                text=f"Background tasks were never disabled {models.env.title}!"
+            )
         else:
-            speaker.speak(text=f"I couldn't not find the source file to enable background tasks {models.env.title}!")
+            speaker.speak(
+                text=f"I couldn't not find the source file to enable background tasks {models.env.title}!"
+            )
     elif "disable" in phrase.lower():
         if os.path.isfile(models.fileio.background_tasks):
-            os.rename(src=models.fileio.background_tasks, dst=models.fileio.tmp_background_tasks)
-            speaker.speak(text=f"Background tasks have been disabled {models.env.title}!")
+            os.rename(
+                src=models.fileio.background_tasks,
+                dst=models.fileio.tmp_background_tasks,
+            )
+            speaker.speak(
+                text=f"Background tasks have been disabled {models.env.title}!"
+            )
         elif os.path.isfile(models.fileio.tmp_background_tasks):
-            speaker.speak(text=f"Background tasks were never enabled {models.env.title}!")
+            speaker.speak(
+                text=f"Background tasks were never enabled {models.env.title}!"
+            )
         else:
-            speaker.speak(text=f"I couldn't not find the source file to disable background tasks {models.env.title}!")
+            speaker.speak(
+                text=f"I couldn't not find the source file to disable background tasks {models.env.title}!"
+            )
     else:
-        speaker.speak(text="Please specify whether you'd like to enable or disable background tasks.")
+        speaker.speak(
+            text="Please specify whether you'd like to enable or disable background tasks."
+        )
 
 
 def compare_tasks(dict1: dict, dict2: dict) -> bool:
     """Compares tasks currently in background tasks yaml file and the tasks already loaded.
 
     Args:
         dict1: Takes either the task in yaml file or loaded task as an argument.
         dict2: Takes either the task in yaml file or loaded task as an argument.
 
     Returns:
         bool:
         A boolean flag to if both the dictionaries are similar.
     """
-    if 'ignore_hours' in dict1 and dict1['ignore_hours'] == [] and 'ignore_hours' not in dict2:
-        dict1.pop('ignore_hours')
-    if 'ignore_hours' in dict2 and dict2['ignore_hours'] == [] and 'ignore_hours' not in dict1:
-        dict2.pop('ignore_hours')
+    if (
+        "ignore_hours" in dict1
+        and dict1["ignore_hours"] == []
+        and "ignore_hours" not in dict2
+    ):
+        dict1.pop("ignore_hours")
+    if (
+        "ignore_hours" in dict2
+        and dict2["ignore_hours"] == []
+        and "ignore_hours" not in dict1
+    ):
+        dict2.pop("ignore_hours")
     if OrderedDict(sorted(dict1.items())) == OrderedDict(sorted(dict2.items())):
         return True
 
 
-def remove_corrupted(task: Union[BackgroundTask, dict]) -> None:
+def remove_corrupted(task: BackgroundTask | dict) -> None:
     """Removes a corrupted task from the background tasks feed file.
 
     Args:
         task: Takes a background task object as an argument.
     """
     with open(models.fileio.background_tasks) as read_file:
         existing_data = yaml.load(stream=read_file, Loader=yaml.FullLoader)
     for task_ in existing_data:
-        if (isinstance(task, dict) and compare_tasks(task_, task)) or \
-                (isinstance(task, BackgroundTask) and compare_tasks(task_, task.__dict__)):
+        if (isinstance(task, dict) and compare_tasks(task_, task)) or (
+            isinstance(task, BackgroundTask) and compare_tasks(task_, task.__dict__)
+        ):
             logger.info("Removing corrupted task: %s", task_)
             existing_data.remove(task_)
-    with open(models.fileio.background_tasks, 'w') as write_file:
+    with open(models.fileio.background_tasks, "w") as write_file:
         yaml.dump(data=existing_data, stream=write_file)
 
 
 def validate_tasks(log: bool = True) -> Generator[BackgroundTask]:
     """Validates each of the background tasks.
 
     Args:
@@ -89,35 +117,50 @@
     if os.path.isfile(models.fileio.background_tasks):
         task_info = []
         with open(models.fileio.background_tasks) as file:
             try:
                 task_info = yaml.load(stream=file, Loader=yaml.FullLoader) or []
             except yaml.YAMLError as error:
                 logger.error(error)
-                warnings.warn(
-                    "BACKGROUND TASKS :: Invalid file format."
+                warnings.warn("BACKGROUND TASKS :: Invalid file format.")
+                logger.error(
+                    "Invalid file format. Logging background tasks and renaming the file to avoid repeated "
+                    "errors in a loop.\n%s\n\n%s\n\n%s"
+                    % (
+                        "".join(["*" for _ in range(120)]),
+                        file.read(),
+                        "".join(["*" for _ in range(120)]),
+                    )
+                )
+                os.rename(
+                    src=models.fileio.background_tasks,
+                    dst=models.fileio.tmp_background_tasks,
                 )
-                logger.error("Invalid file format. Logging background tasks and renaming the file to avoid repeated "
-                             "errors in a loop.\n%s\n\n%s\n\n%s" %
-                             (''.join(['*' for _ in range(120)]), file.read(), ''.join(['*' for _ in range(120)])))
-                os.rename(src=models.fileio.background_tasks, dst=models.fileio.tmp_background_tasks)
         if task_info:
             logger.info("Background tasks: %d", len(task_info)) if log else None
         else:
             return
         for t in task_info:
             try:
-                task = BackgroundTask(seconds=t.get('seconds'), task=t.get('task'), ignore_hours=t.get('ignore_hours'))
+                task = BackgroundTask(
+                    seconds=t.get("seconds"),
+                    task=t.get("task"),
+                    ignore_hours=t.get("ignore_hours"),
+                )
             except ValidationError as error:
                 logger.error(error)
                 remove_corrupted(t)
                 continue
             if "restart" in task.task.lower():
-                logger.warning("Unsupervised restarts are not allowed via background tasks. Use automation instead.")
-                warnings.warn("Unsupervised restarts are not allowed via background tasks. Use automation instead.")
+                logger.warning(
+                    "Unsupervised restarts are not allowed via background tasks. Use automation instead."
+                )
+                warnings.warn(
+                    "Unsupervised restarts are not allowed via background tasks. Use automation instead."
+                )
                 continue
             if log:
                 msg = f"{task.task!r} will be executed every {support.time_converter(second=task.seconds)!r}"
                 if task.ignore_hours:
                     msg += f" except for the hours {util.comma_separator(list(map(str, task.ignore_hours)))}"
                 logger.info(msg)
             yield task
```

## jarvis/executors/car.py

```diff
@@ -1,77 +1,88 @@
 import time
 from datetime import datetime
-from multiprocessing.context import \
-    TimeoutError as ThreadTimeoutError  # noqa: PyProtectedMember
+
+# noinspection PyProtectedMember
+from multiprocessing.context import TimeoutError as ThreadTimeoutError
 from multiprocessing.pool import ThreadPool
 from threading import Thread
-from typing import Dict, List, Tuple, Union
+from typing import Dict, List, Tuple
 
 import gmailconnector
 import jinja2
+import jlrpy
 
 from jarvis.executors import communicator, files, location, weather, word_match
 from jarvis.modules.audio import speaker
-from jarvis.modules.car import connector, controller
 from jarvis.modules.exceptions import EgressErrors
 from jarvis.modules.logger import logger
 from jarvis.modules.models import classes, models
 from jarvis.modules.templates import templates
 from jarvis.modules.utils import shared, support, util
 
 CONNECTION = classes.VehicleConnection()
-AUTHORIZATION = classes.VehicleAuthorization()
 
 
 def create_connection() -> None:
     """Creates a new connection and stores the refresh token and device ID in a dedicated object."""
-    if AUTHORIZATION.refresh_token and time.time() - AUTHORIZATION.expiration <= 86_400:
-        # this might never happen, as the connection and vin are reused until auth expiry anyway
-        connection = connector.Connect(username=models.env.car_username, refresh_token=AUTHORIZATION.refresh_token,
-                                       device_id=AUTHORIZATION.device_id)
-        logger.info("Using refresh token to create a connection with JLR API")
-    else:
-        connection = connector.Connect(username=models.env.car_username, password=models.env.car_password,
-                                       auth_expiry=time.time() + 86_400)  # local epoch time
-        logger.info("Using password to create a connection with JLR API")
     try:
+        if CONNECTION.refresh_token and time.time() - CONNECTION.expiration <= 86_400:
+            # this might never happen, as the connection and vin are reused until auth expiry anyway
+            connection = jlrpy.Connection(
+                email=models.env.car_username,
+                refresh_token=CONNECTION.refresh_token,
+                device_id=CONNECTION.device_id,
+            )
+            logger.info("Using refresh token to create a connection with JLR API")
+        else:
+            connection = jlrpy.Connection(
+                email=models.env.car_username, password=models.env.car_password
+            )
+            logger.info("Using password to create a connection with JLR API")
         connection.connect()
-    except EgressErrors as error:
+    except Exception as error:  # also raises type error in addition to connection errors
         logger.error(error)
-        connection.head = None
-    if connection.head:
-        AUTHORIZATION.device_id = connection.device_id
-        AUTHORIZATION.expiration = connection.expiration
-        AUTHORIZATION.refresh_token = connection.refresh_token
-        logger.debug(AUTHORIZATION.__dict__)
-        vehicles = connection.get_vehicles(headers=connection.head).get("vehicles")
-        if vin := [vehicle_.get('vin') for vehicle_ in vehicles if vehicle_.get('role', '') == 'Primary']:
-            logger.info("Created connection on VIN: %s", vin[0])
-            CONNECTION.connection = connection
-            CONNECTION.vin = vin[0]
+        connection = None
+    if connection and connection.head:
+        if len(connection.vehicles) == 1:
+            primary_vehicle = connection.vehicles[0]
+        else:
+            primary_vehicle = [
+                v for v in connection.vehicles if v["role"] == "Primary"
+            ][0]
+        logger.info("Created connection on VIN: %s", primary_vehicle.vin)
+        CONNECTION.expiration = connection.expiration
+        CONNECTION.control = primary_vehicle
+        CONNECTION.vin = primary_vehicle.vin
+        CONNECTION.refresh_token = connection.refresh_token
+    else:
+        logger.error("Vehicle connection received no headers!!")
 
 
 # Initiate connection only for main and offline communicators
 # WATCH OUT: for changes in function name
-if models.settings.pname in ('JARVIS', 'telegram_api', 'jarvis_api'):
+if models.settings.pname in ("JARVIS", "telegram_api", "jarvis_api"):
     if all((models.env.car_username, models.env.car_password, models.env.car_pin)):
-        logger.info("Creating a new vehicle authorization connection for '%s'", models.settings.pname)
+        logger.info(
+            "Creating a new vehicle authorization connection for '%s'",
+            models.settings.pname,
+        )
         Thread(target=create_connection).start()
 
 
-def current_set_temperature(latitude: float, longitude: float) -> Tuple[Union[int, str], int]:
+def current_set_temperature(latitude: float, longitude: float) -> Tuple[int | str, int]:
     """Get the current temperature at a given location.
 
     Returns:
         tuple:
         A tuple of current temperature and target temperature.
     """
     try:
         response = weather.make_request(lat=latitude, lon=longitude)
-        if not (current_temp := response.get('current', {}).get('temp')):
+        if not (current_temp := response.get("current", {}).get("temp")):
             return "unknown", 66
     except EgressErrors as error:
         logger.error(error)
         return "unknown", 66
     target_temp = 83 if current_temp < 45 else 57 if current_temp > 70 else 66
     return f"{current_temp}\N{DEGREE SIGN}F", target_temp
 
@@ -82,16 +93,18 @@
     >>> Operations
 
     """
 
     def __init__(self):
         """Initiates the callable function and a failure message."""
         self.object = vehicle
-        self.disconnect = f"I wasn't able to connect your car {models.env.title}! " \
-                          "Please check the logs for more information."
+        self.disconnect = (
+            f"I wasn't able to connect your car {models.env.title}! "
+            "Please check the logs for more information."
+        )
 
     def turn_on(self, phrase: str) -> str:
         """Calls the vehicle function to turn the car on with the requested climate setting.
 
         Args:
             phrase: Takes the phrase spoken as an argument.
 
@@ -116,29 +129,39 @@
                 target_temp = 83
         elif "high" in phrase or "highest" in phrase:
             target_temp = 83
         elif "low" in phrase or "lowest" in phrase:
             target_temp = 57
         else:
             if vehicle_position := vehicle(operation="LOCATE_INTERNAL"):
-                current_temp, target_temp = current_set_temperature(latitude=vehicle_position['latitude'],
-                                                                    longitude=vehicle_position['longitude'])
-                extras += f"Your car is in {vehicle_position['city']} {vehicle_position['state']}, where the " \
-                          f"current temperature is {current_temp}, so "
+                current_temp, target_temp = current_set_temperature(
+                    latitude=vehicle_position["latitude"],
+                    longitude=vehicle_position["longitude"],
+                )
+                extras += (
+                    f"Your car is in {vehicle_position['city']} {vehicle_position['state']}, where the "
+                    f"current temperature is {current_temp}, so "
+                )
             else:
                 host_location = files.get_location()
-                if host_location['latitude'] and host_location['longitude']:
-                    current_temp, target_temp = current_set_temperature(latitude=host_location['latitude'],
-                                                                        longitude=host_location['longitude'])
-                    extras += f"The current temperature in " \
-                              f"{host_location.get('address', {}).get('city', 'unknown city')} is {current_temp}, so "
+                if host_location["latitude"] and host_location["longitude"]:
+                    current_temp, target_temp = current_set_temperature(
+                        latitude=host_location["latitude"],
+                        longitude=host_location["longitude"],
+                    )
+                    extras += (
+                        f"The current temperature in "
+                        f"{host_location.get('address', {}).get('city', 'unknown city')} is {current_temp}, so "
+                    )
                 else:
                     target_temp = 69
-        extras += f"I've configured the climate setting to {target_temp}\N{DEGREE SIGN}F"
-        opr = "START-LOCK" if 'lock' in phrase else "START"
+        extras += (
+            f"I've configured the climate setting to {target_temp}\N{DEGREE SIGN}F"
+        )
+        opr = "START-LOCK" if "lock" in phrase else "START"
         if car_name := self.object(operation=opr, temp=target_temp - 26):
             return f"Your {car_name} has been started {models.env.title}. {extras}"
         else:
             return self.disconnect
 
     def turn_off(self) -> str:
         """Calls the vehicle function to turn off the vehicle.
@@ -161,24 +184,38 @@
         See Also:
             - Extracts a numeric value in the phrase or words that refer to a numeric value in the phrase
 
         Returns:
             str:
             Response after enabling guardian mode on the vehicle.
         """
-        requested_expiry = util.extract_nos(input_=phrase, method=int) or util.words_to_number(input_=phrase) or 1
-        if 'hour' in phrase:
-            seconds = requested_expiry * 3_600  # Defaults to 1 hour if no numeric value in phrase
-        elif 'day' in phrase:
-            seconds = requested_expiry * 86_400  # Defaults to 1 day if no numeric value in phrase
-        elif 'week' in phrase:
-            seconds = requested_expiry * 604_800  # Defaults to 1 week if no numeric value in phrase
+        if "disable" in phrase:
+            return "Guardian mode cannot be disabled via offline communicator, due to security reasons."
+        requested_expiry = (
+            util.extract_nos(input_=phrase, method=int)
+            or util.words_to_number(input_=phrase)
+            or 1
+        )
+        if "hour" in phrase:
+            seconds = (
+                requested_expiry * 3_600
+            )  # Defaults to 1 hour if no numeric value in phrase
+        elif "day" in phrase:
+            seconds = (
+                requested_expiry * 86_400
+            )  # Defaults to 1 day if no numeric value in phrase
+        elif "week" in phrase:
+            seconds = (
+                requested_expiry * 604_800
+            )  # Defaults to 1 week if no numeric value in phrase
         else:
             seconds = 3_600  # Defaults to 1 hour if no datetime conversion was received
-        expire = int((time.time() + seconds) * 1000)  # multiply by 1000 to including microseconds making it 13 digits
+        expire = int(
+            (time.time() + seconds) * 1000
+        )  # multiply by 1000 to including microseconds making it 13 digits
         if response := self.object(operation="SECURE", end_time=expire):
             return response
         else:
             return self.disconnect
 
     def lock(self) -> str:
         """Calls vehicle function to perform the lock operation.
@@ -197,18 +234,22 @@
 
         Returns:
             str:
             Response after unlocking the vehicle.
         """
         if car_name := self.object(operation="UNLOCK"):
             if dt_string and shared.called_by_offline:
-                communicator.send_email(body=f"Your {car_name} was successfully unlocked via offline communicator!",
-                                        recipient=models.env.recipient, subject=f"Car unlock alert: {dt_string}",
-                                        title="Vehicle Protection",
-                                        gmail_user=models.env.open_gmail_user, gmail_pass=models.env.open_gmail_pass)
+                communicator.send_email(
+                    body=f"Your {car_name} was successfully unlocked via offline communicator!",
+                    recipient=models.env.recipient,
+                    subject=f"Car unlock alert: {dt_string}",
+                    title="Vehicle Protection",
+                    gmail_user=models.env.open_gmail_user,
+                    gmail_pass=models.env.open_gmail_pass,
+                )
             return f"Your {car_name} has been unlocked {models.env.title}!"
         else:
             return self.disconnect
 
     def honk(self) -> str:
         """Calls vehicle function to honk the car.
 
@@ -255,50 +296,61 @@
     if all((models.env.car_username, models.env.car_password, models.env.car_pin)):
         phrase = phrase.lower()
     else:
         logger.warning("InControl email or password or PIN not found.")
         support.no_env_vars()
         return
 
-    allowed_dict = {'on': ['start', 'set', 'turn on'],
-                    'off': ['stop', 'turn off'],
-                    'report': ['report'],
-                    'guard': ['security', 'guardian', 'secure', 'guard'],
-                    'lock': ['lock'], 'unlock': ['unlock'],
-                    'honk': ['honk', 'blink', 'horn'],
-                    'locate': ['locate', 'where']}
-
-    if not word_match.word_match(phrase=phrase, match_list=util.matrix_to_flat_list(list(allowed_dict.values()))):
-        speaker.speak(text=f"I didn't quite get that {models.env.title}! What do you want me to do to your car?")
+    allowed_dict = {
+        "on": ["start", "set", "turn on"],
+        "off": ["stop", "turn off"],
+        "report": ["report"],
+        "guard": ["security", "guardian", "secure", "guard"],
+        "lock": ["lock"],
+        "unlock": ["unlock"],
+        "honk": ["honk", "blink", "horn"],
+        "locate": ["locate", "where"],
+    }
+
+    if not word_match.word_match(
+        phrase=phrase, match_list=util.matrix_to_flat_list(list(allowed_dict.values()))
+    ):
+        speaker.speak(
+            text=f"I didn't quite get that {models.env.title}! What do you want me to do to your car?"
+        )
         Thread(target=support.unrecognized_dumper, args=[{"CAR": phrase}]).start()
         return
 
     response = "Unsupported operation for car controls."
     caller = Operations()
-    if word_match.word_match(phrase=phrase, match_list=allowed_dict['on']):
+    if word_match.word_match(phrase=phrase, match_list=allowed_dict["on"]):
         response = caller.turn_on(phrase=phrase)
-    elif word_match.word_match(phrase=phrase, match_list=allowed_dict['off']):
+    elif word_match.word_match(phrase=phrase, match_list=allowed_dict["off"]):
         response = caller.turn_off()
-    elif word_match.word_match(phrase=phrase, match_list=allowed_dict['report']):
+    elif word_match.word_match(phrase=phrase, match_list=allowed_dict["report"]):
         response = caller.report()
-    elif word_match.word_match(phrase=phrase, match_list=allowed_dict['guard']):
+    elif word_match.word_match(phrase=phrase, match_list=allowed_dict["guard"]):
         response = caller.enable_guard(phrase=phrase)
-    elif word_match.word_match(phrase=phrase, match_list=allowed_dict['unlock']):
+    elif word_match.word_match(phrase=phrase, match_list=allowed_dict["unlock"]):
         dt_string = datetime.now().strftime("%B %d, %Y - %I:%M %p")
         if shared.called_by_offline:
-            communicator.send_email(body="Your vehicle has been requested to unlock via offline communicator!",
-                                    recipient=models.env.recipient, subject=f"Car unlock alert: {dt_string}",
-                                    title="Vehicle Protection",
-                                    gmail_user=models.env.open_gmail_user, gmail_pass=models.env.open_gmail_pass)
+            communicator.send_email(
+                body="Your vehicle has been requested to unlock via offline communicator!",
+                recipient=models.env.recipient,
+                subject=f"Car unlock alert: {dt_string}",
+                title="Vehicle Protection",
+                gmail_user=models.env.open_gmail_user,
+                gmail_pass=models.env.open_gmail_pass,
+            )
         response = caller.unlock(dt_string=dt_string)
-    elif word_match.word_match(phrase=phrase, match_list=allowed_dict['lock']):
+    elif word_match.word_match(phrase=phrase, match_list=allowed_dict["lock"]):
         response = caller.lock()
-    elif word_match.word_match(phrase=phrase, match_list=allowed_dict['honk']):
+    elif word_match.word_match(phrase=phrase, match_list=allowed_dict["honk"]):
         response = caller.honk()
-    elif word_match.word_match(phrase=phrase, match_list=allowed_dict['locate']):
+    elif word_match.word_match(phrase=phrase, match_list=allowed_dict["locate"]):
         response = caller.locate()
     speaker.speak(text=response)
 
 
 def convert_dt_report(dt_string: str) -> str:
     """Converts UTC to local datetime string. Helper function for generating car report.
 
@@ -309,93 +361,134 @@
         str:
         Returns the local datetime string.
     """
     utc_dt = datetime.strptime(dt_string, "%Y-%m-%dT%H:%M:%S+0000")
     return support.utc_to_local(utc_dt=utc_dt).strftime("%A, %B %d %Y - %I:%M %p")
 
 
-def report(status_data: Dict[str, Union[str, Union[Dict[str, str]]]],
-           subscription_data: List[Dict[str, str]],
-           attributes: Dict[str, Union[List[Dict[str, str]], Dict[str, str]]]) -> str:
+def report(
+    status_data: Dict[str, str | Dict[str, str]],
+    subscription_data: List[Dict[str, str]],
+    attributes: Dict[str, List[Dict[str, str]] | Dict[str, str]],
+) -> str:
     """Generates a report based on the vehicle's status and sends an email notification.
 
     Args:
         status_data: Raw status data.
         subscription_data: Raw subscription data.
         attributes: Raw attributes data.
 
     Returns:
         str:
         Response to the user.
     """
     default_dt_string = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%S+0000")
-    report_time = convert_dt_report(dt_string=status_data.get('lastUpdatedTime', default_dt_string))
-    overall_status = {'alerts': [], 'subscriptions': [], 'status': {}}
-    overall_status['status']: Dict[str, str]
-    overall_status['alerts']: List[Dict[str, str]]
-    overall_status['subscriptions']: List[Dict[str, List[str]]]
-    for alert in status_data.get('vehicleAlerts', [{}]):
-        if alert.get('active', False) and alert.get('value', 'false') == 'true':
-            alert['lastUpdatedTime'] = convert_dt_report(dt_string=alert.get('lastUpdatedTime', default_dt_string))
-            overall_status['alerts'].append({alert['key']: alert['lastUpdatedTime']})
-    for status in status_data.get('vehicleStatus', {}):
-        for dict_ in status_data['vehicleStatus'].get(status, [{}]):
-            if dict_.get('key', '') in ("SRS_STATUS", "DOOR_IS_ALL_DOORS_LOCKED"):
-                overall_status['status'][dict_['key']] = dict_['value']
-            if dict_.get('key', '') == "ENGINE_COOLANT_TEMP":
-                overall_status['status'][dict_['key']] = f"{dict_['value']}\N{DEGREE SIGN}F"
-            if dict_.get('key', '') == f"ODOMETER_{models.env.distance_unit.value.upper()}":
-                overall_status['status'][dict_['key']] = f"{int(dict_['value']):02,} {models.env.distance_unit.value}"
-            if dict_.get('key', '') == "FUEL_LEVEL_PERC":
-                overall_status['status'][dict_['key']] = dict_['value'] + '%'
-            if dict_.get('key', '') == "BATTERY_VOLTAGE":
-                overall_status['status'][dict_['key']] = dict_['value'] + 'v'
-            if dict_.get('key', '') == "DISTANCE_TO_EMPTY_FUEL":
-                distance_to_empty_fuel = float(dict_['value'])
-                if models.env.distance_unit == models.DistanceUnits.MILES:  # Convert to miles if custom unit is set
-                    distance_to_empty_fuel = util.kms_to_miles(float(dict_['value']))
-                overall_status['status'][dict_['key']] = f"{int(distance_to_empty_fuel):02,} " \
-                                                         f"{models.env.distance_unit.value}"
-            if dict_.get('key', '') in ["TYRE_PRESSURE_FRONT_LEFT", "TYRE_PRESSURE_FRONT_RIGHT",
-                                        "TYRE_PRESSURE_REAR_LEFT", "TYRE_PRESSURE_REAR_RIGHT"]:
-                overall_status['status'][dict_['key']] = f"{round(int(dict_['value']) * 14.696 / 100)} psi"
+    report_time = convert_dt_report(
+        dt_string=status_data.get("lastUpdatedTime", default_dt_string)
+    )
+    overall_status = {"alerts": [], "subscriptions": [], "status": {}}
+    overall_status["status"]: Dict[str, str]
+    overall_status["alerts"]: List[Dict[str, str]]
+    overall_status["subscriptions"]: List[Dict[str, List[str]]]
+    for alert in status_data.get("vehicleAlerts", [{}]):
+        if alert.get("active", False) and alert.get("value", "false") == "true":
+            alert["lastUpdatedTime"] = convert_dt_report(
+                dt_string=alert.get("lastUpdatedTime", default_dt_string)
+            )
+            overall_status["alerts"].append({alert["key"]: alert["lastUpdatedTime"]})
+    for status in status_data.get("vehicleStatus", {}):
+        for dict_ in status_data["vehicleStatus"].get(status, [{}]):
+            if dict_.get("key", "") in ("SRS_STATUS", "DOOR_IS_ALL_DOORS_LOCKED"):
+                overall_status["status"][dict_["key"]] = dict_["value"]
+            if dict_.get("key", "") == "ENGINE_COOLANT_TEMP":
+                overall_status["status"][
+                    dict_["key"]
+                ] = f"{dict_['value']}\N{DEGREE SIGN}F"
+            if (
+                dict_.get("key", "")
+                == f"ODOMETER_{models.env.distance_unit.value.upper()}"
+            ):
+                overall_status["status"][
+                    dict_["key"]
+                ] = f"{int(dict_['value']):02,} {models.env.distance_unit.value}"
+            if dict_.get("key", "") == "FUEL_LEVEL_PERC":
+                overall_status["status"][dict_["key"]] = dict_["value"] + "%"
+            if dict_.get("key", "") == "BATTERY_VOLTAGE":
+                overall_status["status"][dict_["key"]] = dict_["value"] + "v"
+            if dict_.get("key", "") == "DISTANCE_TO_EMPTY_FUEL":
+                distance_to_empty_fuel = float(dict_["value"])
+                # Convert to miles if custom unit is set
+                if models.env.distance_unit == models.DistanceUnits.MILES:
+                    distance_to_empty_fuel = util.kms_to_miles(float(dict_["value"]))
+                overall_status["status"][dict_["key"]] = (
+                    f"{int(distance_to_empty_fuel):02,} "
+                    f"{models.env.distance_unit.value}"
+                )
+            if dict_.get("key", "") in [
+                "TYRE_PRESSURE_FRONT_LEFT",
+                "TYRE_PRESSURE_FRONT_RIGHT",
+                "TYRE_PRESSURE_REAR_LEFT",
+                "TYRE_PRESSURE_REAR_RIGHT",
+            ]:
+                overall_status["status"][
+                    dict_["key"]
+                ] = f"{round(int(dict_['value']) * 14.696 / 100)} psi"
     for package in subscription_data:
-        expiration_date = package.get('expirationDate')
-        name = package.get('name')
-        pkg_status = package.get('status')
+        expiration_date = package.get("expirationDate")
+        name = package.get("name")
+        pkg_status = package.get("status")
         if name and pkg_status and expiration_date:
-            overall_status['subscriptions'].append({name: [convert_dt_report(dt_string=expiration_date), pkg_status]})
-    if overall_status['status']:  # sort dict by key
-        overall_status['status'] = dict(sorted(overall_status['status'].items()))
-    if overall_status['alerts']:  # sort list of dict by the key in each dict
-        overall_status['alerts'] = sorted(overall_status['alerts'], key=lambda d: list(d.keys()))
-    if overall_status['subscriptions']:  # sort list of dict by the key in each dict
-        overall_status['subscriptions'] = sorted(overall_status['subscriptions'], key=lambda d: list(d.values())[0])
+            overall_status["subscriptions"].append(
+                {name: [convert_dt_report(dt_string=expiration_date), pkg_status]}
+            )
+    if overall_status["status"]:  # sort dict by key
+        overall_status["status"] = dict(sorted(overall_status["status"].items()))
+    if overall_status["alerts"]:  # sort list of dict by the key in each dict
+        overall_status["alerts"] = sorted(
+            overall_status["alerts"], key=lambda d: list(d.keys())
+        )
+    if overall_status["subscriptions"]:  # sort list of dict by the key in each dict
+        overall_status["subscriptions"] = sorted(
+            overall_status["subscriptions"], key=lambda d: list(d.values())[0]
+        )
     logger.debug(overall_status)
     template = jinja2.Template(templates.EmailTemplates.car_report)
-    rendered = template.render(title=f"Last Connected: {report_time}",
-                               alerts=overall_status['alerts'] or [{'ALL_OK': report_time}],
-                               status=overall_status['status'] or {'NOTHING_TO_REPORT': report_time},
-                               subscriptions=overall_status['subscriptions'] or [{'NO_SUBSCRIPTIONS': ['N/A', 'N/A']}])
-    car_name = f"{attributes.get('vehicleBrand', 'Car')} " \
-               f"{attributes.get('vehicleType', '')} " \
-               f"{attributes.get('modelYear', '')}"
-    mail_obj = gmailconnector.SendEmail(gmail_user=models.env.open_gmail_user, gmail_pass=models.env.open_gmail_pass)
-    response = mail_obj.send_email(subject=f"{car_name} Report - {datetime.now().strftime('%c')}",
-                                   sender="Jarvis", html_body=rendered, recipient=models.env.recipient)
+    rendered = template.render(
+        title=f"Last Connected: {report_time}",
+        alerts=overall_status["alerts"] or [{"ALL_OK": report_time}],
+        status=overall_status["status"] or {"NOTHING_TO_REPORT": report_time},
+        subscriptions=overall_status["subscriptions"]
+        or [{"NO_SUBSCRIPTIONS": ["N/A", "N/A"]}],
+    )
+    car_name = (
+        f"{attributes.get('vehicleBrand', 'Car')} "
+        f"{attributes.get('vehicleType', '')} "
+        f"{attributes.get('modelYear', '')}"
+    )
+    mail_obj = gmailconnector.SendEmail(
+        gmail_user=models.env.open_gmail_user, gmail_pass=models.env.open_gmail_pass
+    )
+    response = mail_obj.send_email(
+        subject=f"{car_name} Report - {datetime.now().strftime('%c')}",
+        sender="Jarvis",
+        html_body=rendered,
+        recipient=models.env.recipient,
+    )
     if response.ok:
         logger.info("Report has been sent via email.")
         return f"Vehicle report has been sent via email {models.env.title}!"
     else:
         logger.error("Failed to send report.")
         logger.error(response.json())
         return f"Failed to send the vehicle report {models.env.title}! Please check the logs for more information."
 
 
-def vehicle(operation: str, temp: int = None, end_time: int = None, retry: bool = True) -> Union[str, dict, None]:
+def vehicle(
+    operation: str, temp: int = None, end_time: int = None, retry: bool = True
+) -> str | dict | None:
     """Establishes a connection with the car and returns an object to control the primary vehicle.
 
     Args:
         operation: Operation to be performed.
         temp: Temperature for climate control.
         end_time: End time for guardian mode. Should be a 13 digit integer including microseconds.
         retry: Retry logic used when guardian mode is enabled already.
@@ -403,100 +496,154 @@
     Returns:
         str:
         Returns the vehicle's name.
     """
     control = None
     try:
         # check for expiration as connection reset in connector module appears to be flaky
-        if AUTHORIZATION.refresh_token and time.time() - AUTHORIZATION.expiration <= 86_400 and CONNECTION.connection:
-            logger.info("Reusing refresh token, valid until: %s",
-                        util.epoch_to_datetime(seconds=AUTHORIZATION.expiration, format_="%B %d, %Y - %I:%M %p"))
-        else:
-            if AUTHORIZATION.expiration and time.time() - AUTHORIZATION.expiration >= 86_400:
-                logger.info("Creating a new connection since refresh token expired at: %s",
-                            util.epoch_to_datetime(seconds=AUTHORIZATION.expiration, format_="%B %d, %Y - %I:%M %p"))
+        if (
+            CONNECTION.refresh_token
+            and time.time() - CONNECTION.expiration <= 86_400
+            and CONNECTION.control
+        ):
+            logger.info(
+                "Reusing refresh token, valid until: %s",
+                util.epoch_to_datetime(
+                    seconds=CONNECTION.expiration, format_="%B %d, %Y - %I:%M %p"
+                ),
+            )
+        else:
+            if CONNECTION.expiration and time.time() - CONNECTION.expiration >= 86_400:
+                logger.info(
+                    "Creating a new connection since refresh token expired at: %s",
+                    util.epoch_to_datetime(
+                        seconds=CONNECTION.expiration, format_="%B %d, %Y - %I:%M %p"
+                    ),
+                )
             create_connection()
-        control = controller.Control(connection=CONNECTION.connection, vin=CONNECTION.vin)
+        if not CONNECTION.control:
+            logger.error("Unable to create session.")
+            return
+        control = CONNECTION.control
         attributes = ThreadPool(processes=1).apply_async(func=control.get_attributes)
         response = {}
         if operation == "LOCK":
             response = control.lock(pin=models.env.car_pin)
         elif operation == "UNLOCK":
             response = control.unlock(pin=models.env.car_pin)
         elif operation == "START" or operation == "START-LOCK":
             if operation == "START-LOCK":
-                lock_status = {each_dict['key']: each_dict['value'] for each_dict in
-                               [key for key in control.get_status().get('vehicleStatus').get('coreStatus')
-                                if key.get('key') in ["DOOR_IS_ALL_DOORS_LOCKED", "DOOR_BOOT_LOCK_STATUS"]]}
-                if lock_status.get('DOOR_IS_ALL_DOORS_LOCKED', 'FALSE') != 'TRUE' or \
-                        lock_status.get('DOOR_BOOT_LOCK_STATUS', 'UNLOCKED') != 'LOCKED':
+                lock_status = {
+                    each_dict["key"]: each_dict["value"]
+                    for each_dict in [
+                        key
+                        for key in control.get_status()
+                        .get("vehicleStatus")
+                        .get("coreStatus")
+                        if key.get("key")
+                        in ["DOOR_IS_ALL_DOORS_LOCKED", "DOOR_BOOT_LOCK_STATUS"]
+                    ]
+                }
+                if (
+                    lock_status.get("DOOR_IS_ALL_DOORS_LOCKED", "FALSE") != "TRUE"
+                    or lock_status.get("DOOR_BOOT_LOCK_STATUS", "UNLOCKED") != "LOCKED"
+                ):
                     logger.warning("Car is unlocked when tried to remote start!")
                     lock_response = control.lock(pin=models.env.car_pin)
                     if lock_response.get("failureDescription"):
                         logger.error(lock_response)
                     else:
                         logger.info("Vehicle has been locked!")
-                        time.sleep(3)  # Wait before locking the car, so that there is no overlap in refresh token
-            response = control.remote_engine_start(pin=models.env.car_pin, target_temperature=temp)
+                        time.sleep(
+                            3
+                        )  # Wait before locking the car, so that there is no overlap in refresh token
+            response = control.remote_engine_start(
+                pin=models.env.car_pin, target_value=temp
+            )
         elif operation == "STOP":
             response = control.remote_engine_stop(pin=models.env.car_pin)
         elif operation == "SECURE":
-            control.enable_guardian_mode(pin=models.env.car_pin, expiration_time=end_time)
-            until = datetime.fromtimestamp(end_time / 1000).strftime("%A, %B %d, %I:%M %p")  # Remove microseconds
-            return f"Guardian mode has been enabled {models.env.title}! " \
-                   f"Your {control.get_attributes().get('vehicleBrand', 'car')} will be guarded until " \
-                   f"{until} {util.get_timezone()}"
+            control.enable_guardian_mode(
+                pin=models.env.car_pin, expiration_time=end_time
+            )
+            # Remove microseconds
+            until = datetime.fromtimestamp(end_time / 1000).strftime(
+                "%A, %B %d, %I:%M %p"
+            )
+            return (
+                f"Guardian mode has been enabled {models.env.title}! "
+                f"Your {control.get_attributes().get('vehicleBrand', 'car')} will be guarded until "
+                f"{until} {util.get_timezone()}"
+            )
         elif operation == "SECURE_EXIST":  # Only called during recursion
-            current_end = control.get_guardian_mode_status().get('endTime')
+            current_end = control.get_guardian_mode_status().get("endTime")
             if not current_end:
                 return
-            utc_dt = datetime.strptime(current_end, "%Y-%m-%dT%H:%M:%S.%fZ")  # Convert str to datetime object
+            # Convert str to datetime object
+            utc_dt = datetime.strptime(current_end, "%Y-%m-%dT%H:%M:%S.%fZ")
             until = support.utc_to_local(utc_dt=utc_dt).strftime("%A, %B %d, %I:%M %p")
             return f"Guardian mode is already enabled until {until} {util.get_timezone()} {models.env.title}!"
         elif operation == "HONK":
             response = control.honk_blink()
         elif operation == "LOCATE" or operation == "LOCATE_INTERNAL":
-            if not (position := control.get_position().get('position')):
+            if not (position := control.get_position().get("position")):
                 logger.error("Unable to get position of the vehicle.")
                 return
-            logger.info("latitude: %f, longitude: %f", position['latitude'], position['longitude'])
-            data = location.get_location_from_coordinates(coordinates=(position['latitude'], position['longitude']))
-            number = data.get('streetNumber', data.get('house_number', ''))
-            street = data.get('street', data.get('road'))
-            state = data.get('region', data.get('state', data.get('county')))
-            city, country = data.get('city', data.get('residential')), data.get('country')
+            logger.info(
+                "latitude: %f, longitude: %f",
+                position["latitude"],
+                position["longitude"],
+            )
+            data = location.get_location_from_coordinates(
+                coordinates=(position["latitude"], position["longitude"])
+            )
+            number = data.get("streetNumber", data.get("house_number", ""))
+            street = data.get("street", data.get("road"))
+            state = data.get("region", data.get("state", data.get("county")))
+            city, country = data.get("city", data.get("residential")), data.get(
+                "country"
+            )
             if operation == "LOCATE_INTERNAL":
-                position['city'] = city
-                position['state'] = state
+                position["city"] = city
+                position["state"] = state
                 return position
             if all((street, state, city, country)):
                 address = f"{number} {street}, {city} {state}, {country}".strip()
-            elif data.get('formattedAddress'):
-                address = data['formattedAddress']
+            elif data.get("formattedAddress"):
+                address = data["formattedAddress"]
             else:
                 address = data
             return f"Your {control.get_attributes().get('vehicleBrand', 'car')} is at {address}"
         elif operation == "REPORT":
             status = ThreadPool(processes=1).apply_async(func=control.get_status)
-            subscriptions = ThreadPool(processes=1).apply_async(func=control.get_subscription_packages)
+            subscriptions = ThreadPool(processes=1).apply_async(
+                func=control.get_subscription_packages
+            )
             attributes = attributes.get()
             status = status.get()
             subscriptions = subscriptions.get()
-            return report(status_data=status, subscription_data=subscriptions, attributes=attributes)
+            return report(
+                status_data=status,
+                subscription_data=subscriptions.get("subscriptionPackages", []),
+                attributes=attributes,
+            )
         if response and response.get("failureDescription"):
             logger.critical(response)
             return
         try:
             car_name = attributes.get(timeout=3).get("vehicleBrand", "car")
         except ThreadTimeoutError as error:
             logger.error(error)
             car_name = "car"
         return car_name
     except EgressErrors as error:
         # Happens when security mode is already enabled
-        if operation == "SECURE" and \
-                error.__dict__.get('response') and \
-                error.__dict__['response'].status_code == 409 and \
-                control and retry:
+        if (
+            operation == "SECURE"
+            and error.__dict__.get("response")
+            and error.__dict__["response"].status_code == 409
+            and control
+            and retry
+        ):
             return vehicle(operation="SECURE_EXIST", retry=False)
         logger.error(error)
         logger.error("Failed to connect while performing %s", operation)
```

## jarvis/executors/comm_squire.py

```diff
@@ -1,214 +1,248 @@
 import re
-from typing import Union
 
 from pydantic import EmailStr
 
 from jarvis.executors import communicator, files, word_match
 from jarvis.modules.audio import listener, speaker
 from jarvis.modules.conditions import keywords
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.utils import shared, support, util
 
 
-def extract_contacts(name: str, key: str) -> Union[int, EmailStr, str, None]:
+def extract_contacts(name: str, key: str) -> int | EmailStr | str | None:
     """Extract contact destination for ``phone`` or ``email`` from the ``contacts.yaml`` file, if present.
 
     Args:
         name: Name for which the contact information has to be retrieved.
         key: Takes either ``phone`` or ``email`` as an argument.
 
     Returns:
-        Union[int, EmailStr]:
+        int | EmailStr | str:
         - EmailStr: If email address is requested.
         - int: If phone number is requested.
     """
     contacts = files.get_contacts()
     if contacts.get(key):
         logger.info("Looking for '%s' in contacts file.", name)
-        result = util.get_closest_match(text=name, match_list=list(contacts[key].keys()), get_ratio=True)
+        result = util.get_closest_match(
+            text=name, match_list=list(contacts[key].keys()), get_ratio=True
+        )
         logger.info(result)
         # Setting a higher threshold as the name is user given and can be easily adjusted
         # Also, better to re-configure the name to match the recognized value, than sending messages to wrong recipient
-        if result['ratio'] < 0.9:
-            logger.error("%.2f didn't meet the threshold for any name in contacts.", result['ratio'])
+        if result["ratio"] < 0.9:
+            logger.error(
+                "%.2f didn't meet the threshold for any name in contacts.",
+                result["ratio"],
+            )
             return
-        identifier = result['text']
+        identifier = result["text"]
         return contacts[key][identifier]
 
 
 def send_notification(phrase: str) -> None:
     """Initiates notification via SMS or email.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
     """
     if not all([models.env.gmail_user, models.env.gmail_pass]):
-        logger.error('Gmail credentials not stored in env vars to trigger an email notification.')
+        logger.error(
+            "Gmail credentials not stored in env vars to trigger an email notification."
+        )
         support.no_env_vars()
         return
 
-    to_words = ['2', 'to', 'To']
+    to_words = ["2", "to", "To"]
     body, to = None, None
     for word in to_words:
         # Catches the last occurrence of the to word
-        if msg_grouper := re.search(f'send (.*) {word}', phrase):
+        if msg_grouper := re.search(f"send (.*) {word}", phrase):
             body = msg_grouper.group(1)
         # Catches first occurrence of the to word, making 'to' clumpy but since regex is used for 'to' it is okay
-        if to_grouper := re.search(f'{word} (.*)', phrase):
+        if to_grouper := re.search(f"{word} (.*)", phrase):
             to = to_grouper.group(1)
         if body and to:
             body, to = body.strip(), to.strip()
             break
     else:
         logger.error("Invalid message or destination: %s -> %s", body, to)
-        speaker.speak(text="Messenger format should be::send some message using SMS or email to some number or name.")
+        speaker.speak(
+            text="Messenger format should be::send some message using SMS or email to some number or name."
+        )
         return
 
-    method_words = ['via', 'Via', 'using', 'Using']
+    method_words = ["via", "Via", "using", "Using"]
     for word in method_words:
-        if message := re.search(f'{word} (.*)', phrase):
+        if message := re.search(f"{word} (.*)", phrase):
             method = message.group(1)
             break
     else:
         logger.debug("Message portal not in right format. Looking into phrase to skim.")
         body = None if "text message" in body else body
         if "mail" in phrase:
             method = "email"
         else:
-            logger.warning("No valid portal found to send. Defaulting to SMS.") if "message" not in phrase else None
+            logger.warning(
+                "No valid portal found to send. Defaulting to SMS."
+            ) if "message" not in phrase else None
             method = "SMS"
         method_words.append(method)
 
     if body:
         for word in method.split() + method_words:
             if word in body:
-                body = body.replace(word, '')
+                body = body.replace(word, "")
         body = body.strip()
 
-    for word in method_words + to_words + ['sms', 'email', 'text message']:
-        to = to.lower().replace(word, '')
+    for word in method_words + to_words + ["sms", "email", "text message"]:
+        to = to.lower().replace(word, "")
     to = to.strip()
 
     if to[0].isdigit():
         method = "SMS"
 
-    logger.info("'{body}' -> '{to}' via '{method}'".format(body=body, to=to, method=method))
+    logger.info(
+        "'{body}' -> '{to}' via '{method}'".format(body=body, to=to, method=method)
+    )
 
     if "mail" in method.lower():
         initiate_email(body=body, to=to)
     else:
         initiate_sms(body=body, to=to)
 
 
-def initiate_sms(body: str, to: Union[str, int]) -> None:
+def initiate_sms(body: str, to: str | int) -> None:
     """Sends a message to the number received.
 
     If no number was received, it will ask for a number, looks if it is 10 digits and then sends a message.
 
     Args:
         body: Message that has to be sent.
         to: Target phone number or name.
     """
     number = None
     if not to[0].isdigit():
         # condition to avoid None type becoming a string
-        if numb := extract_contacts(name=to, key='phone'):
+        if numb := extract_contacts(name=to, key="phone"):
             number = str(numb)
     if not number:
         # condition to avoid None type becoming a string
         if numb := util.extract_nos(input_=to, method=int):
             number = str(numb)
 
     if number and len(number) != 10:
-        speaker.speak(text=f"I don't think that's a right number {models.env.title}! Phone numbers are 10 digits.")
+        speaker.speak(
+            text=f"I don't think that's a right number {models.env.title}! Phone numbers are 10 digits."
+        )
         return
 
     if number and shared.called_by_offline:  # Number is present and called by offline
         logger.info("'{body}' -> '{number}'".format(body=body, number=number))
-        sms_response = communicator.send_sms(user=models.env.gmail_user, password=models.env.gmail_pass,
-                                             number=number, body=body)
+        sms_response = communicator.send_sms(
+            user=models.env.gmail_user,
+            password=models.env.gmail_pass,
+            number=number,
+            body=body,
+        )
         if sms_response is True:
             speaker.speak(text=f"Message has been sent {models.env.title}!")
         else:
-            speaker.speak(text=f"I'm sorry {models.env.title}! I wasn't able to send the email. "
-                               f"{sms_response}")
+            speaker.speak(
+                text=f"I'm sorry {models.env.title}! I wasn't able to send the email. "
+                f"{sms_response}"
+            )
         return
     elif shared.called_by_offline:  # Number is not present but called by offline
-        speaker.speak(text="SMS format should be::send some message to some number or name using sms or email.")
+        speaker.speak(
+            text="SMS format should be::send some message to some number or name using sms or email."
+        )
         return
     if not number:  # Number is not present
         speaker.speak(text=f"Please tell me a number {models.env.title}!", run=True)
         if not (number := listener.listen()):
             return
-        if 'exit' in number or 'quit' in number or 'Xzibit' in number:
+        if "exit" in number or "quit" in number or "Xzibit" in number:
             return
     if not body:
         speaker.speak(text=f"What would you like to send {models.env.title}?", run=True)
         if not (body := listener.listen()):
             return
-        if 'exit' in body or 'quit' in body or 'Xzibit' in body:
+        if "exit" in body or "quit" in body or "Xzibit" in body:
             return
-    speaker.speak(text=f'{body} to {number}. Do you want me to proceed?', run=True)
+    speaker.speak(text=f"{body} to {number}. Do you want me to proceed?", run=True)
     if converted := listener.listen():
-        if word_match.word_match(phrase=converted, match_list=keywords.keywords['ok']):
+        if word_match.word_match(phrase=converted, match_list=keywords.keywords["ok"]):
             logger.info("{body} -> {number}".format(body=body, number=number))
-            sms_response = communicator.send_sms(user=models.env.gmail_user, password=models.env.gmail_pass,
-                                                 number=number, body=body)
+            sms_response = communicator.send_sms(
+                user=models.env.gmail_user,
+                password=models.env.gmail_pass,
+                number=number,
+                body=body,
+            )
             if sms_response is True:
                 speaker.speak(text=f"Message has been sent {models.env.title}!")
             else:
-                speaker.speak(text=f"I'm sorry {models.env.title}! I wasn't able to send the email. "
-                                   f"{sms_response}")
+                speaker.speak(
+                    text=f"I'm sorry {models.env.title}! I wasn't able to send the email. "
+                    f"{sms_response}"
+                )
         else:
             speaker.speak(text=f"Message will not be sent {models.env.title}!")
 
 
 def initiate_email(body: str, to: str) -> None:
     """Sends an email to the contact name receive after looking it up in the contacts.yaml file.
 
     Args:
         body: Text that has to be sent.
         to: Target name to fetch from the contacts file..
 
     See Also:
           - Requires ``contacts.yaml`` to be present in ``fileio`` directory.
     """
-    to = extract_contacts(name=to, key='email')
+    to = extract_contacts(name=to, key="email")
     if not to:
         logger.error("Contact file missing or '%s' not found in contact file.", to)
         support.no_env_vars()
         return
 
     if body and shared.called_by_offline:  # Body is present and called by offline
         logger.info("'%s' -> '%s'", body, to)
         mail_response = communicator.send_email(body=body, recipient=to)
         if mail_response is True:
             speaker.speak(text=f"Email has been sent {models.env.title}!")
         else:
-            speaker.speak(text=f"I'm sorry {models.env.title}! I wasn't able to send the email. "
-                               f"{mail_response}")
+            speaker.speak(
+                text=f"I'm sorry {models.env.title}! I wasn't able to send the email. "
+                f"{mail_response}"
+            )
         return
     elif shared.called_by_offline:  # Number is not present but called by offline
-        speaker.speak(text="Email format should be::send some message to some email address.")
+        speaker.speak(
+            text="Email format should be::send some message to some email address."
+        )
         return
 
     if not body:
         speaker.speak(text=f"What would you like to send {models.env.title}?", run=True)
         if not (body := listener.listen()):
             return
-        if 'exit' in body or 'quit' in body or 'Xzibit' in body:
+        if "exit" in body or "quit" in body or "Xzibit" in body:
             return
 
-    speaker.speak(text=f'{body} to {to}. Do you want me to proceed?', run=True)
+    speaker.speak(text=f"{body} to {to}. Do you want me to proceed?", run=True)
     if converted := listener.listen():
-        if word_match.word_match(phrase=converted, match_list=keywords.keywords['ok']):
+        if word_match.word_match(phrase=converted, match_list=keywords.keywords["ok"]):
             logger.info("'%s' -> '%s'", body, to)
             mail_response = communicator.send_email(body=body, recipient=to)
             if mail_response is True:
                 speaker.speak(text=f"Email has been sent {models.env.title}!")
             else:
-                speaker.speak(text=f"I'm sorry {models.env.title}! I wasn't able to send the email. "
-                                   f"{mail_response}")
+                speaker.speak(
+                    text=f"I'm sorry {models.env.title}! I wasn't able to send the email. "
+                    f"{mail_response}"
+                )
         else:
             speaker.speak(text=f"Email will not be sent {models.env.title}!")
```

## jarvis/executors/commander.py

```diff
@@ -1,145 +1,156 @@
 import random
 import time
 import traceback
 from multiprocessing import Process
 from threading import Thread
-from typing import Tuple, Union
+from typing import Tuple
 
-from jarvis.executors import (conditions, controls, listener_controls, offline,
-                              others, word_match)
-from jarvis.modules.audio import listener, speaker
+from jarvis.executors import (
+    conditions,
+    controls,
+    listener_controls,
+    offline,
+    others,
+    word_match,
+)
+from jarvis.modules.audio import speaker
 from jarvis.modules.conditions import conversation, keywords
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.utils import shared, support, util
 
 
-def split_phrase(phrase: str) -> 'conditions.conditions':
+def split_phrase(phrase: str) -> "conditions.conditions":
     """Splits the input at 'and' or 'also' and makes it multiple commands to execute if found in statement.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
 
     Returns:
         conditions.conditions:
         Return value from ``conditions()``
     """
     exit_check = False  # this is specifically to catch the sleep command which should break the loop in renew()
 
-    if ' after ' in phrase and not word_match.word_match(phrase=phrase, match_list=keywords.ignore_after):
+    if " after " in phrase and not word_match.word_match(
+        phrase=phrase, match_list=keywords.ignore_after
+    ):
         if delay_info := timed_delay(phrase=phrase):
-            speaker.speak(text=f"I will execute it after {support.time_converter(second=delay_info[1])} "
-                               f"{models.env.title}!")
+            speaker.speak(
+                text=f"I will execute it after {support.time_converter(second=delay_info[1])} "
+                f"{models.env.title}!"
+            )
             return False
 
-    if ' and ' in phrase and not word_match.word_match(phrase=phrase, match_list=keywords.ignore_and):
-        and_phrases = phrase.split(' and ')
+    if " and " in phrase and not word_match.word_match(
+        phrase=phrase, match_list=keywords.ignore_and
+    ):
+        and_phrases = phrase.split(" and ")
         logger.info("Looping through %s in iterations.", and_phrases)
         for each in and_phrases:
             exit_check = conditions.conditions(phrase=each.strip())
             speaker.speak(run=True)
     else:
         exit_check = conditions.conditions(phrase=phrase.strip())
     return exit_check
 
 
-def delay_condition(phrase: str, delay: Union[int, float]) -> None:
+def delay_condition(phrase: str, delay: int | float) -> None:
     """Delays the execution after sleeping for the said time, after which it is sent to ``offline_communicator``.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
         delay: Sleeps for the number of seconds.
     """
-    logger.info("'%s' will be executed after %s", phrase, support.time_converter(second=delay))
+    logger.info(
+        "'%s' will be executed after %s", phrase, support.time_converter(second=delay)
+    )
     time.sleep(delay)
     logger.info("Executing '%s'", phrase)
     try:
         offline.offline_communicator(command=phrase)
     except Exception as error:
         logger.error(error)
         logger.error(traceback.format_exc())
 
 
-def timed_delay(phrase: str) -> Tuple[str, Union[int, float]]:
+def timed_delay(phrase: str) -> Tuple[str, int | float]:
     """Checks pre-conditions if a delay is necessary.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
 
     Returns:
         bool:
         Returns a boolean flag whether the time delay should be applied.
     """
-    if not word_match.word_match(phrase=phrase, match_list=keywords.keywords['set_alarm']) and \
-            not word_match.word_match(phrase=phrase, match_list=keywords.keywords['reminder']):
-        split_ = phrase.split('after')
+    if not word_match.word_match(
+        phrase=phrase, match_list=keywords.keywords["set_alarm"]
+    ) and not word_match.word_match(
+        phrase=phrase, match_list=keywords.keywords["reminder"]
+    ):
+        split_ = phrase.split("after")
         if task := split_[0].strip():
             delay = util.delay_calculator(phrase=split_[1].strip())
-            Process(target=delay_condition, kwargs={'phrase': task, 'delay': delay}).start()
+            Process(
+                target=delay_condition, kwargs={"phrase": task, "delay": delay}
+            ).start()
             return task, delay
 
 
 def initialize() -> None:
     """Awakens from sleep mode. ``greet_check`` is to ensure greeting is given only for the first function call."""
     if shared.greeting:
         speaker.speak(text="What can I do for you?")
     else:
-        speaker.speak(text=f'Good {util.part_of_day()}.')
+        speaker.speak(text=f"Good {util.part_of_day()}.")
         shared.greeting = True
     speaker.speak(run=True)
-    renew()
-
-
-def renew() -> None:
-    """Keeps listening and sends the response to ``conditions()`` function.
-
-    Notes:
-        - This function runs only for a minute.
-        - split_phrase(converted) is a condition so that, loop breaks when if sleep in ``conditions()`` returns True.
-    """
-    for i in range(3):
-        if i:
-            converted = listener.listen(sound=False) or ""
-        else:
-            converted = listener.listen() or ""
-        if word_match.word_match(phrase=converted, match_list=models.env.wake_words):
-            continue
-        if split_phrase(phrase=converted):  # should_return flag is not passed which will default to False
-            break  # split_phrase() returns a boolean flag from conditions. conditions return True only for sleep
-        speaker.speak(run=True)
 
 
 def initiator(phrase: str = None) -> None:
     """When invoked by ``Activator``, checks for the right keyword to wake up and gets into action.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
     """
     if not phrase:
         return
     support.flush_screen()
     inactive_msg = f"My listeners are currently inactive {models.env.title}!"
-    if 'good' in phrase.lower() and word_match.word_match(
-            phrase=phrase, match_list=('morning', 'night', 'afternoon', 'after noon', 'evening', 'goodnight')
+    if "good" in phrase.lower() and word_match.word_match(
+        phrase=phrase,
+        match_list=(
+            "morning",
+            "night",
+            "afternoon",
+            "after noon",
+            "evening",
+            "goodnight",
+        ),
     ):
         if not listener_controls.get_listener_state():
             return
-        if (event := others.celebrate()) and 'night' not in phrase.lower():
-            speaker.speak(text=f'Happy {event}!')
-        if 'night' in phrase.split() or 'goodnight' in phrase.split():
+        if (event := others.celebrate()) and "night" not in phrase.lower():
+            speaker.speak(text=f"Happy {event}!")
+        if "night" in phrase.split() or "goodnight" in phrase.split():
             Thread(target=controls.sleep_control).start()
-    elif 'you there' in phrase.lower() or word_match.word_match(phrase=phrase, match_list=models.env.wake_words):
+    elif "you there" in phrase.lower() or word_match.word_match(
+        phrase=phrase, match_list=models.env.wake_words
+    ):
         if not listener_controls.get_listener_state():
             speaker.speak(text=inactive_msg)
             return
         speaker.speak(text=random.choice(conversation.wake_up1))
         initialize()
-    elif word_match.word_match(phrase=phrase, match_list=('look alive', 'wake up', 'wakeup',
-                                                          'show time', 'showtime')):
+    elif word_match.word_match(
+        phrase=phrase,
+        match_list=("look alive", "wake up", "wakeup", "show time", "showtime"),
+    ):
         if not listener_controls.get_listener_state():
             speaker.speak(text=inactive_msg)
             return
         speaker.speak(text=random.choice(conversation.wake_up2))
         initialize()
     else:
         if phrase:
```

## jarvis/executors/communicator.py

```diff
@@ -1,89 +1,124 @@
-from typing import Union
-
 import gmailconnector
 import jinja2
+import requests
 from pydantic import EmailStr
 
 from jarvis.executors import word_match
 from jarvis.modules.audio import listener, speaker
 from jarvis.modules.conditions import keywords
+from jarvis.modules.exceptions import EgressErrors
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.templates import templates
 from jarvis.modules.utils import shared, support
 
 
 def read_gmail(*args) -> None:
     """Reads unread emails from the gmail account for which the credentials are stored in env variables."""
     if not all([models.env.gmail_user, models.env.gmail_pass]):
         logger.warning("Gmail username and password not found.")
         support.no_env_vars()
         return
 
     support.write_screen(text="Fetching unread emails..")
-    reader = gmailconnector.ReadEmail(gmail_user=models.env.gmail_user, gmail_pass=models.env.gmail_pass)
+    reader = gmailconnector.ReadEmail(
+        gmail_user=models.env.gmail_user, gmail_pass=models.env.gmail_pass
+    )
     response = reader.instantiate()
     if response.ok:
         if shared.called_by_offline:
-            speaker.speak(text=f'You have {response.count} unread email {models.env.title}.') if response.count == 1 \
-                else speaker.speak(text=f'You have {response.count} unread emails {models.env.title}.')
+            speaker.speak(
+                text=f"You have {response.count} unread email {models.env.title}."
+            ) if response.count == 1 else speaker.speak(
+                text=f"You have {response.count} unread emails {models.env.title}."
+            )
             return
-        speaker.speak(text=f'You have {response.count} unread emails {models.env.title}. Do you want me to check it?',
-                      run=True)
+        speaker.speak(
+            text=f"You have {response.count} unread emails {models.env.title}. Do you want me to check it?",
+            run=True,
+        )
         if not (confirmation := listener.listen()):
             return
-        if not word_match.word_match(phrase=confirmation, match_list=keywords.keywords['ok']):
+        if not word_match.word_match(
+            phrase=confirmation, match_list=keywords.keywords["ok"]
+        ):
             return
         for mail in reader.read_mail(messages=response.body, humanize_datetime=True):
-            speaker.speak(text=f"You have an email from, {mail.sender}, with subject, "
-                               f"{mail.subject}, {mail.date_time}", run=True)
+            speaker.speak(
+                text=f"You have an email from, {mail.sender}, with subject, "
+                f"{mail.subject}, {mail.date_time}",
+                run=True,
+            )
     elif response.status == 204:
         speaker.speak(text=f"You don't have any emails to catch up {models.env.title}!")
     else:
         speaker.speak(text=f"I was unable to read your email {models.env.title}!")
 
 
-def send_sms(user: str, password: str, number: Union[str, int], body: str, subject: str = None) -> Union[bool, str]:
+def send_sms(
+    user: str, password: str, number: str | int, body: str, subject: str = None
+) -> bool | str:
     """Send text message through SMS gateway of destination number.
 
     References:
         Uses `gmail-connector <https://pypi.org/project/gmail-connector/>`__ to send the SMS.
 
     Args:
         user: Gmail username to authenticate SMTP lib.
         password: Gmail password to authenticate SMTP lib.
         number: Phone number stored as env var.
         body: Content of the message.
         subject: Takes subject as an optional argument.
 
     Returns:
-        Union[bool, str]:
+        bool | str:
         - Boolean flag to indicate the SMS was sent successfully.
         - Error response from gmail-connector.
     """
+    if not all([models.env.gmail_user, models.env.gmail_pass]):
+        logger.warning("Gmail username and password not found.")
+        support.no_env_vars()
+        return False
     if not any([models.env.phone_number, number]):
-        logger.error('No phone number was stored in env vars to trigger a notification.')
+        logger.error(
+            "No phone number was stored in env vars to trigger a notification."
+        )
         return False
     if not subject:
-        subject = "Message from Jarvis" if number == models.env.phone_number else f"Message from {models.env.name}"
+        subject = (
+            "Message from Jarvis"
+            if number == models.env.phone_number
+            else f"Message from {models.env.name}"
+        )
     sms_object = gmailconnector.SendSMS(gmail_user=user, gmail_pass=password)
-    response = sms_object.send_sms(phone=number or models.env.phone_number,
-                                   subject=subject, message=body, delete_sent=True)
+    response = sms_object.send_sms(
+        phone=number or models.env.phone_number,
+        subject=subject,
+        message=body,
+        delete_sent=True,
+    )
     if response.ok:
-        logger.info('SMS notification has been sent.')
+        logger.info("SMS notification has been sent.")
         return True
     else:
-        logger.error('Unable to send SMS notification.')
+        logger.error("Unable to send SMS notification.")
         return response.body
 
 
-def send_email(body: str, recipient: Union[EmailStr, str], subject: str = None, sender: str = None,
-               gmail_user: Union[EmailStr, str] = None, gmail_pass: str = None, title: str = None,
-               attachment: str = None) -> Union[bool, str]:
+def send_email(
+    body: str,
+    recipient: EmailStr | str,
+    subject: str = None,
+    sender: str = None,
+    gmail_user: EmailStr | str = None,
+    gmail_pass: str = None,
+    title: str = None,
+    attachment: str = None,
+) -> bool | str:
     """Sends an email using an email template formatted as html.
 
     Args:
         body: Message to be inserted as html body in the email.
         sender: Sender name of the email.
         subject: Subject of the email.
         recipient: Email address to which the mail has to be sent.
@@ -92,26 +127,78 @@
         title: Sender name on template.
         attachment: Attachment to include in notification.
 
     References:
         Uses `gmail-connector <https://pypi.org/project/gmail-connector/>`__ to send the Email.
 
     Returns:
-        Union[bool, str]:
+        bool | str:
         - Boolean flag to indicate the email was sent successfully.
         - Error response from gmail-connector.
     """
+    if not all([models.env.gmail_user, models.env.gmail_pass]):
+        logger.warning("Gmail username and password not found.")
+        support.no_env_vars()
+        return False
     if not subject:
-        subject = "Message from Jarvis" if recipient == models.env.recipient else f"Message from {models.env.name}"
-    rendered = jinja2.Template(source=templates.email.notification).render(SENDER=title or models.env.name,
-                                                                           MESSAGE=body)
-    email_object = gmailconnector.SendEmail(gmail_user=gmail_user or models.env.gmail_user,
-                                            gmail_pass=gmail_pass or models.env.gmail_pass)
-    mail_stat = email_object.send_email(recipient=recipient, sender=sender or 'Jarvis Communicator',
-                                        subject=subject, html_body=rendered, attachment=attachment)
+        subject = (
+            "Message from Jarvis"
+            if recipient == models.env.recipient
+            else f"Message from {models.env.name}"
+        )
+    rendered = jinja2.Template(source=templates.email.notification).render(
+        SENDER=title or models.env.name, MESSAGE=body
+    )
+    email_object = gmailconnector.SendEmail(
+        gmail_user=gmail_user or models.env.gmail_user,
+        gmail_pass=gmail_pass or models.env.gmail_pass,
+    )
+    mail_stat = email_object.send_email(
+        recipient=recipient,
+        sender=sender or "Jarvis Communicator",
+        subject=subject,
+        html_body=rendered,
+        attachment=attachment,
+    )
     if mail_stat.ok:
-        logger.info('Email notification has been sent')
+        logger.info("Email notification has been sent")
         return True
     else:
-        logger.error('Unable to send email notification.')
+        logger.error("Unable to send email notification.")
         logger.error(mail_stat.json())
         return mail_stat.body
+
+
+def ntfy_send(topic: str, title: str, message: str) -> bool:
+    """Uses `ntfy` to send notification to a specific topic.
+
+    Args:
+        topic: Topic to send notifications to.
+        title: Title of the notification.
+        message: Notification content.
+
+    Returns:
+        bool:
+        Boolean flag to indicate the results
+    """
+    if not all([models.env.ntfy_username, models.env.ntfy_password]):
+        logger.warning("Ntfy username and password not found.")
+        support.no_env_vars()
+        return False
+    headers = {
+        "X-Title": title,
+        "Content-Type": "application/x-www-form-urlencoded",
+    }
+    endpoint = f"{models.env.ntfy_url}{topic}"
+    try:
+        response = requests.post(
+            url=endpoint,
+            auth=(models.env.ntfy_username, models.env.ntfy_password),
+            headers=headers,
+            data=message,
+        )
+        response.raise_for_status()
+    except EgressErrors as error:
+        logger.error(error)
+        return False
+    logger.info(response.json())
+    return True
```

## jarvis/executors/conditions.py

```diff
@@ -1,13 +1,21 @@
 import warnings
 from threading import Thread
 
-from jarvis.executors import (custom_conditions, functions, listener_controls,
-                              method, others, restrictions, static_responses,
-                              unconditional, word_match)
+from jarvis.executors import (
+    custom_conditions,
+    functions,
+    listener_controls,
+    method,
+    others,
+    restrictions,
+    static_responses,
+    unconditional,
+    word_match,
+)
 from jarvis.modules.audio import speaker
 from jarvis.modules.conditions import keywords
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.transformer import gpt
 from jarvis.modules.utils import shared, support
 
@@ -25,18 +33,28 @@
         When requested to stop Jarvis.
 
     Returns:
         bool:
         Boolean True only when asked to sleep for conditioned sleep message.
     """
     # Allow conditions during offline communication
-    if not shared.called_by_offline and \
-            not listener_controls.get_listener_state() and \
-            not all(("activate" in phrase or "enable" in phrase,  # WATCH OUT: "activate" and "enable" are hard coded
-                     word_match.word_match(phrase=phrase, match_list=keywords.keywords['listener_control']))):
+    if (
+        not shared.called_by_offline
+        and not listener_controls.get_listener_state()
+        and not all(
+            (
+                "activate" in phrase
+                or "enable"
+                in phrase,  # WATCH OUT: "activate" and "enable" are hard coded
+                word_match.word_match(
+                    phrase=phrase, match_list=keywords.keywords["listener_control"]
+                ),
+            )
+        )
+    ):
         logger.info("Ignoring '%s' since listener is deactivated.", phrase)
         return False
     if "*" in phrase:
         others.abusive(phrase)
         return False
 
     function_map = functions.function_mapping()
@@ -50,51 +68,79 @@
             logger.debug("'%s' matched the category '%s'", matched, category)
 
             # custom rules for additional keyword matching
             if category == "send_notification":
                 if "send" not in phrase.lower():
                     continue
             if category in ("distance", "kill"):
-                if word_match.word_match(phrase=phrase, match_list=keywords.keywords['avoid']):
+                if word_match.word_match(
+                    phrase=phrase, match_list=keywords.keywords["avoid"]
+                ):
                     continue
             if category == "speed_test":
-                if not ('internet' in phrase.lower() or 'connection' in phrase.lower() or 'run' in phrase.lower()):
+                if not (
+                    "internet" in phrase.lower()
+                    or "connection" in phrase.lower()
+                    or "run" in phrase.lower()
+                ):
                     continue
 
             # Stand alone - Internally used [skip for both main and offline processes]
             if category in ("avoid", "ok", "exit_", "ngrok", "secrets"):
                 continue
 
             # Requires manual intervention [skip for offline communicator]
-            if shared.called_by_offline and category in ('kill', 'report', 'repeat', 'directions', 'notes', 'faces',
-                                                         'music', 'voice_changer', 'restart_control', 'shutdown'):
+            if shared.called_by_offline and category in (
+                "kill",
+                "report",
+                "repeat",
+                "directions",
+                "notes",
+                "faces",
+                "music",
+                "voice_changer",
+                "restart_control",
+                "shutdown",
+            ):
                 # WATCH OUT: for changes in function name
-                if models.settings.pname in ("background_tasks", "telegram_api", "jarvis_api") and \
-                        category == "restart_control":
-                    logger.info("Allowing '%s' through the category '%s', for the process: '%s'",
-                                phrase, category, models.settings.pname)
+                if (
+                    models.settings.pname
+                    in ("background_tasks", "telegram_api", "jarvis_api")
+                    and category == "restart_control"
+                ):
+                    logger.info(
+                        "Allowing '%s' through the category '%s', for the process: '%s'",
+                        phrase,
+                        category,
+                        models.settings.pname,
+                    )
                 else:
                     static_responses.not_allowed_offline()
                     return False
 
             if function_map.get(category):  # keyword category matches function name
-                method.executor(function_map[category], phrase)  # call function with phrase as arg by default
+                method.executor(
+                    function_map[category], phrase
+                )  # call function with phrase as arg by default
                 if category in ("sleep_control", "sentry"):
                     return True  # repeat listeners are ended and wake word detection is activated
             else:
                 # edge case scenario if a category has matched but the function name is incorrect or not imported
-                warnings.warn("Condition matched for '%s' but there is not function to call." % category)
+                warnings.warn(
+                    "Condition matched for '%s' but there is not function to call."
+                    % category
+                )
             return False
     # GPT instance available only for communicable processes
     # WATCH OUT: for changes in function name
-    if models.settings.pname not in ('JARVIS', 'telegram_api', 'jarvis_api'):
+    if models.settings.pname not in ("JARVIS", "telegram_api", "jarvis_api"):
         logger.warning("%s reached unrecognized category", models.settings.pname)
         return False
     logger.info("Received unrecognized lookup parameter: %s", phrase)
-    Thread(target=support.unrecognized_dumper, args=[{'CONDITIONS': phrase}]).start()
+    Thread(target=support.unrecognized_dumper, args=[{"CONDITIONS": phrase}]).start()
     if not unconditional.google_maps(query=phrase):
         if gpt.instance:
             gpt.instance.query(phrase=phrase)
         elif response := gpt.existing_response(request=phrase):
             speaker.speak(text=response)
         else:
             static_responses.un_processable()
```

## jarvis/executors/connection.py

```diff
@@ -1,49 +1,57 @@
 import socket
 import threading
 from http.client import HTTPSConnection
-from typing import Union
 
 import pywifi
 
 from jarvis.modules.logger import logger
 from jarvis.modules.models import classes, models
 
 
-def wifi(conn_object: classes.WiFiConnection) -> Union[classes.WiFiConnection, None]:
+def wifi(conn_object: classes.WiFiConnection) -> classes.WiFiConnection | None:
     """Checks for internet connection as per given frequency. Enables Wi-Fi and connects to SSID if connection fails.
 
     Args:
         conn_object: Takes an object of unknown errors and OSError as an argument.
 
     Returns:
         WiFiConnection:
         Returns the connection object to keep alive, None to stop calling this function.
     """
     socket_ = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
     try:
         if models.settings.os == models.supported_platforms.windows:
-            connection = HTTPSConnection("8.8.8.8", timeout=3)  # Recreate a new connection everytime
+            connection = HTTPSConnection(
+                "8.8.8.8", timeout=3
+            )  # Recreate a new connection everytime
             connection.request("HEAD", "/")
         else:
             socket_.connect(("8.8.8.8", 80))
         if conn_object.unknown_errors:
-            logger.info("Connection established with IP: %s. Resetting flags.", socket_.getsockname()[0])
+            logger.info(
+                "Connection established with IP: %s. Resetting flags.",
+                socket_.getsockname()[0],
+            )
             conn_object.unknown_errors = 0
             conn_object.os_errors = 0
     except OSError as error:
         conn_object.os_errors += 1
         logger.error("OSError [%d]: %s", error.errno, error.strerror)
         pywifi.ControlPeripheral(logger=logger).enable()  # Make sure Wi-Fi is enabled
-        connection_control = pywifi.ControlConnection(wifi_ssid=models.env.wifi_ssid,
-                                                      wifi_password=models.env.wifi_password,
-                                                      logger=logger)
+        connection_control = pywifi.ControlConnection(
+            wifi_ssid=models.env.wifi_ssid,
+            wifi_password=models.env.wifi_password,
+            logger=logger,
+        )
         threading.Timer(interval=5, function=connection_control.wifi_connector).start()
     except Exception as error:
         logger.critical(error)
         conn_object.unknown_errors += 1
 
     if conn_object.unknown_errors > 10 or conn_object.os_errors > 30:
         logger.warning(conn_object.model_dump_json())
-        logger.error("'%s' is running into repeated errors, hence stopping..!", wifi.__name__)
+        logger.error(
+            "'%s' is running into repeated errors, hence stopping..!", wifi.__name__
+        )
         return None
     return conn_object
```

## jarvis/executors/controls.py

```diff
@@ -9,18 +9,25 @@
 from threading import Thread, Timer
 from typing import NoReturn
 
 import docker
 import psutil
 import pybrightness
 import pywslocker
-from docker.errors import ContainerError, DockerException
+from docker.errors import APIError, ContainerError, DockerException
 
-from jarvis.executors import (alarm, files, listener_controls, remind, system,
-                              volume, word_match)
+from jarvis.executors import (
+    alarm,
+    files,
+    listener_controls,
+    remind,
+    system,
+    volume,
+    word_match,
+)
 from jarvis.modules.audio import listener, speaker, voices
 from jarvis.modules.conditions import conversation, keywords
 from jarvis.modules.database import database
 from jarvis.modules.exceptions import StopSignal
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.utils import shared, support, util
@@ -40,63 +47,75 @@
         ask: Boolean flag to get confirmation from user.
 
     Raises:
         StopSignal:
         To stop Jarvis' PID.
     """
     if ask:
-        speaker.speak(text=f"{random.choice(conversation.confirmation)} restart your "
-                           f"{shared.hosted_device.get('device', 'machine')}?",
-                      run=True)
+        speaker.speak(
+            text=f"{random.choice(conversation.confirmation)} restart your "
+            f"{shared.hosted_device.get('device', 'machine')}?",
+            run=True,
+        )
         converted = listener.listen()
     else:
-        converted = 'yes'
-    if word_match.word_match(phrase=converted, match_list=keywords.keywords['ok']):
+        converted = "yes"
+    if word_match.word_match(phrase=converted, match_list=keywords.keywords["ok"]):
         stop_terminals()
         if models.settings.os == models.supported_platforms.macOS:
-            subprocess.call(['osascript', '-e', 'tell app "System Events" to restart'])
+            subprocess.call(["osascript", "-e", 'tell app "System Events" to restart'])
         elif models.settings.os == models.supported_platforms.windows:
             os.system("shutdown /r /t 1")
         else:
             os.system(f"echo {models.env.root_password} | sudo -S reboot")
         raise StopSignal
     else:
         speaker.speak(text=f"Machine state is left intact {models.env.title}!")
 
 
 def exit_process() -> None:
     """Function that holds the list of operations done upon exit."""
     if reminders := remind.get_reminder_state():
         if len(reminders) == 1:
-            speaker.speak(text=f'You have a pending reminder {models.env.title}!')
+            speaker.speak(text=f"You have a pending reminder {models.env.title}!")
         else:
-            speaker.speak(text=f'You have {len(reminders)} pending reminders {models.env.title}!')
-        speaker.speak(text=util.comma_separator(reminders))  # No need for string.capwords as speaker runs in a new loop
+            speaker.speak(
+                text=f"You have {len(reminders)} pending reminders {models.env.title}!"
+            )
+        speaker.speak(
+            text=util.comma_separator(reminders)
+        )  # No need for string.capwords as speaker runs in a new loop
     if alarms := alarm.get_alarm_state():
         if len(alarms) == 1:
             speaker.speak(text="You have a pending alarm at ")
         else:
-            speaker.speak(text=f"You have {len(alarms)} pending alarms {models.env.title}!")
+            speaker.speak(
+                text=f"You have {len(alarms)} pending alarms {models.env.title}!"
+            )
         speaker.speak(text=util.comma_separator(alarms))
     if reminders or alarms:
         speaker.speak(text="This will not be executed while I'm deactivated!")
     speaker.speak(text=f"Shutting down now {models.env.title}!")
     try:
         speaker.speak(text=support.exit_message(), run=True)
     except RuntimeError as error:
-        logger.critical("ATTENTION::Received a RuntimeError while self terminating.\n%s", error)
-    support.write_screen(f"Memory consumed: {support.size_converter(0)}"
-                         f"\nTotal runtime: {support.time_converter(second=time.time() - shared.start_time)}")
+        logger.critical(
+            "ATTENTION::Received a RuntimeError while self terminating.\n%s", error
+        )
+    support.write_screen(
+        f"Memory consumed: {support.size_converter(0)}"
+        f"\nTotal runtime: {support.time_converter(second=time.time() - shared.start_time)}"
+    )
 
 
 def sleep_control(*args) -> bool:
     """Locks the screen and reduces brightness to bare minimum."""
     Thread(target=pybrightness.decrease, args=(logger,)).start()
     pywslocker.lock(logger)
-    if not shared.called['report']:
+    if not shared.called["report"]:
         speaker.speak(text=random.choice(conversation.acknowledgement))
     return True
 
 
 def sentry(*args) -> bool:
     """Speaks sentry mode message and sets greeting value to false."""
     speaker.speak(text=f"Activating sentry mode, enjoy yourself {models.env.title}!")
@@ -119,15 +138,18 @@
     """Writes an entry to the DB to restart the caller.
 
     Args:
         caller: Name of the process that has to be restarted.
     """
     with db.connection:
         cursor = db.connection.cursor()
-        cursor.execute("INSERT or REPLACE INTO restart (flag, caller) VALUES (?,?);", (True, caller))
+        cursor.execute(
+            "INSERT or REPLACE INTO restart (flag, caller) VALUES (?,?);",
+            (True, caller),
+        )
         cursor.connection.commit()
 
 
 def restart_control(phrase: str = None, quiet: bool = False) -> None:
     """Controls the restart functions based on the user request.
 
     Args:
@@ -141,40 +163,54 @@
         return
     if shared.called_by_offline:
         if phrase:
             if "all" in phrase.lower().split():
                 logger.info("Restarting all background processes!")
                 # set as timer, so that process doesn't get restarted without returning response to user
                 # without timer, the process will keep getting restarted in a loop
-                Timer(interval=5, function=db_restart_entry, kwargs=dict(caller="OFFLINE")).start()
+                Timer(
+                    interval=5, function=db_restart_entry, kwargs=dict(caller="OFFLINE")
+                ).start()
                 speaker.speak(text="Restarting all background processes!")
                 return
             if avail := list(files.get_processes().keys()):
-                avail.remove('jarvis')  # cannot be restarted
+                avail.remove("jarvis")  # cannot be restarted
             else:
-                speaker.speak(text="Unable to fetch background processes. Try specifying 'all'")
+                speaker.speak(
+                    text="Unable to fetch background processes. Try specifying 'all'"
+                )
                 return
-            if func := word_match.word_match(phrase=phrase, match_list=avail, strict=True):
+            if func := word_match.word_match(
+                phrase=phrase, match_list=avail, strict=True
+            ):
                 logger.info("Restarting %s", func)
                 # set as timer, so that process doesn't get restarted without returning response to user
                 # without timer, the process will keep getting restarted in a loop
-                Timer(interval=5, function=db_restart_entry, kwargs=dict(caller=func)).start()
+                Timer(
+                    interval=5, function=db_restart_entry, kwargs=dict(caller=func)
+                ).start()
                 speaker.speak(text=f"Restarting the background process {func!r}")
             else:
-                speaker.speak(text=f"Please specify a function name. Available: {util.comma_separator(avail)}")
+                speaker.speak(
+                    text=f"Please specify a function name. Available: {util.comma_separator(avail)}"
+                )
         else:
             speaker.speak(text="Invalid request to restart.")
         return
     if phrase:
-        if not shared.hosted_device.get('device'):
+        if not shared.hosted_device.get("device"):
             system.hosted_device_info()
-        logger.info("Restart for %s has been requested.", shared.hosted_device.get('device'))
+        logger.info(
+            "Restart for %s has been requested.", shared.hosted_device.get("device")
+        )
         restart()
     else:
-        speaker.speak(text="I didn't quite get that. Did you mean restart your computer?")
+        speaker.speak(
+            text="I didn't quite get that. Did you mean restart your computer?"
+        )
         return
 
 
 def stop_terminals(apps: tuple = ("iterm", "terminal")) -> None:
     """Stops background processes.
 
     Args:
@@ -205,31 +241,38 @@
         try:
             log_file.write(f"Stopping running container {container_id!r}\n")
             client.api.kill(container_id)
             log_file.write(f"Removing existing container {container_id!r}\n")
             client.api.remove_container(container_id)
         except ContainerError as error:
             err = f": {error.stderr}" if error.stderr else ""
-            log_file.write(f"Command '{error.command}' in image '{error.image}' "
-                           f"returned non-zero exit status {error.exit_status}{err}\n")
-        log_file.write(f"Removing cid file {models.fileio.speech_synthesis_cid!r}\n")
-        os.remove(models.fileio.speech_synthesis_cid)
+            log_file.write(
+                f"Command '{error.command}' in image '{error.image}' "
+                f"returned non-zero exit status {error.exit_status}{err}\n"
+            )
+        except APIError as error:
+            log_file.write(f"{error.response.status_code} - {error.response.text}")
+        else:
+            log_file.write(
+                f"Removing cid file {models.fileio.speech_synthesis_cid!r}\n"
+            )
+            os.remove(models.fileio.speech_synthesis_cid)
 
 
 def terminator() -> NoReturn:
     """Exits the process with specified status without calling cleanup handlers, flushing stdio buffers, etc."""
     logger.info("Removing docker container")
     delete_docker_container()
     if os.path.isfile(models.fileio.processes):
         logger.info("Removing %s", models.fileio.processes)
         os.remove(models.fileio.processes)
     proc = psutil.Process(pid=models.settings.pid)
     process_info = proc.as_dict()
-    if process_info.get('environ'):
-        del process_info['environ']  # To ensure env vars are not printed in log files
+    if process_info.get("environ"):
+        del process_info["environ"]  # To ensure env vars are not printed in log files
     logger.debug(process_info)
     support.stop_process(pid=proc.pid)
     # noinspection PyUnresolvedReferences,PyProtectedMember
     os._exit(1)
 
 
 def shutdown(*args, proceed: bool = False) -> None:
@@ -238,55 +281,67 @@
     Args:
         proceed: Boolean value whether to get confirmation.
 
     Raises:
         StopSignal: To stop Jarvis' PID.
     """
     if not proceed:
-        speaker.speak(text=f"{random.choice(conversation.confirmation)} turn off the machine?", run=True)
+        speaker.speak(
+            text=f"{random.choice(conversation.confirmation)} turn off the machine?",
+            run=True,
+        )
         converted = listener.listen()
     else:
-        converted = 'yes'
-    if word_match.word_match(phrase=converted, match_list=keywords.keywords['ok']):
+        converted = "yes"
+    if word_match.word_match(phrase=converted, match_list=keywords.keywords["ok"]):
         stop_terminals()
         if models.settings.os == models.supported_platforms.macOS:
-            subprocess.call(['osascript', '-e', 'tell app "System Events" to shut down'])
+            subprocess.call(
+                ["osascript", "-e", 'tell app "System Events" to shut down']
+            )
         elif models.settings.os == models.supported_platforms.windows:
             os.system("shutdown /s /t 1")
         else:
             os.system(f"echo {models.env.root_password} | sudo -S shutdown -P now")
         raise StopSignal
     else:
         speaker.speak(text=f"Machine state is left intact {models.env.title}!")
 
 
 def delete_logs() -> None:
     """Delete log files that were updated before the log retention period. Checks if file's inode was changed."""
-    for __path, __directory, __file in os.walk('logs'):
+    for __path, __directory, __file in os.walk("logs"):
         for file_ in __file:
             inode_modified = os.stat(os.path.join(__path, file_)).st_ctime
-            if timedelta(seconds=(time.time() - inode_modified)).days > models.env.log_retention:
+            if (
+                timedelta(seconds=(time.time() - inode_modified)).days
+                > models.env.log_retention
+            ):
                 logger.debug("Deleting log file: %s", os.path.join(__path, file_))
-                os.remove(os.path.join(__path, file_))  # removes the file if it is older than log retention time
+                os.remove(
+                    os.path.join(__path, file_)
+                )  # removes the file if it is older than log retention time
 
 
 def delete_pycache() -> None:
     """Deletes ``__pycache__`` folder from all sub-dir."""
     for __path, __directory, __file in os.walk(os.getcwd()):
-        if '__pycache__' in __directory:
-            if os.path.exists(os.path.join(__path, '__pycache__')):
-                logger.debug("Deleting pycache: %s", os.path.join(__path, '__pycache__'))
-                shutil.rmtree(os.path.join(__path, '__pycache__'))
+        if "__pycache__" in __directory:
+            if os.path.exists(os.path.join(__path, "__pycache__")):
+                logger.debug(
+                    "Deleting pycache: %s", os.path.join(__path, "__pycache__")
+                )
+                shutil.rmtree(os.path.join(__path, "__pycache__"))
 
 
 def set_executable() -> None:
     """Modify file permissions for all the files within the fileio directory."""
     for file in os.listdir("fileio"):
         f_path = os.path.join("fileio", file)
-        if not file.endswith('.cid'):
+        if not file.endswith(".cid"):
             os.chmod(f_path, os.stat(f_path).st_mode | stat.S_IEXEC)
     # [os.chmod(file, int('755', base=8) or 0o755) for file in os.listdir("fileio") if not file.endswith('.cid')]
 
 
 def starter() -> None:
     """Initiates crucial functions which needs to be called during start up.
```

## jarvis/executors/crontab.py

```diff
@@ -1,22 +1,21 @@
 import os
 import subprocess
-import warnings
 from collections.abc import Generator
-from datetime import datetime
-
-import yaml
 
 from jarvis.api.squire import scheduler
+from jarvis.executors import files
 from jarvis.modules.crontab import expression
 from jarvis.modules.exceptions import InvalidArgument
 from jarvis.modules.logger import logger, multiprocessing_logger
 from jarvis.modules.models import models
 
-LOG_FILE = os.path.join('logs', 'cron_%d-%m-%Y.log')  # Used by api functions that run on cron schedule
+LOG_FILE = os.path.join(
+    "logs", "cron_%d-%m-%Y.log"
+)  # Used by api functions that run on cron schedule
 
 
 def executor(statement: str, log_file: str = None, process_name: str = None) -> None:
     """Executes a cron statement.
 
     Args:
         statement: Cron statement to be executed.
@@ -27,24 +26,24 @@
         - Executions done by crontab executor are not stopped when Jarvis is stopped.
         - On the bright side, almost all executions made by Jarvis are short-lived.
     """
     if not log_file:
         log_file = multiprocessing_logger(filename=LOG_FILE)
     if not process_name:
         process_name = "crontab_executor"
-    process_name = '_'.join(process_name.split())
+    process_name = "_".join(process_name.split())
     command = f"export PROCESS_NAME={process_name} && {statement}"
     logger.debug("Executing '%s' as '%s'", statement, command)
-    with open(log_file, 'a') as file:
-        file.write('\n')
+    with open(log_file, "a") as file:
+        file.write("\n")
         try:
             subprocess.call(command, shell=True, stdout=file, stderr=file)
         except Exception as error:
             if isinstance(error, subprocess.CalledProcessError):
-                result = error.output.decode(encoding='UTF-8').strip()
+                result = error.output.decode(encoding="UTF-8").strip()
                 file.write(f"[{error.returncode}]: {result}")
             else:
                 file.write(error.__str__())
 
 
 def validate_jobs(log: bool = True) -> Generator[expression.CronExpression]:
     """Validates each of the cron job.
@@ -52,36 +51,28 @@
     Args:
         log: Takes a boolean flag to suppress info level logging.
 
     Yields:
         CronExpression:
         CronExpression object.
     """
-    if os.path.isfile(models.fileio.crontab):
-        cron_info = []
-        with open(models.fileio.crontab) as file:
-            try:
-                cron_info = yaml.load(stream=file, Loader=yaml.FullLoader) or []
-            except yaml.YAMLError as error:
-                logger.error(error)
-                warnings.warn(
-                    "CRONTAB :: Invalid file format."
-                )
-                # rename to avoid getting triggered in a loop
-                os.rename(src=models.fileio.crontab,
-                          dst=datetime.now().strftime(os.path.join(models.fileio.root, 'crontab_%d-%m-%Y.yaml')))
-        for idx in cron_info:
-            try:
-                cron = expression.CronExpression(idx)
-            except InvalidArgument as error:
-                logger.error(error)
-                os.rename(src=models.fileio.crontab,
-                          dst=datetime.now().strftime(os.path.join(models.fileio.root, 'crontab_%d-%m-%Y.yaml')))
-                continue
-            if log:
-                msg = f"{cron.comment!r} will be executed as per the schedule {cron.expression!r}"
-                logger.info(msg)
-            yield cron
+    for idx in files.get_crontab():
+        try:
+            cron = expression.CronExpression(idx)
+        except InvalidArgument as error:
+            logger.error(error)
+            os.rename(src=models.fileio.crontab, dst=models.fileio.tmp_crontab)
+            continue
+        if log:
+            msg = f"{cron.comment!r} will be executed as per the schedule {cron.expression!r}"
+            logger.info(msg)
+        yield cron
     if models.env.author_mode:
-        if all((models.env.robinhood_user, models.env.robinhood_pass, models.env.robinhood_pass)):
+        if all(
+            (
+                models.env.robinhood_user,
+                models.env.robinhood_pass,
+                models.env.robinhood_pass,
+            )
+        ):
             yield scheduler.rh_cron_schedule(extended=True)
         yield scheduler.sm_cron_schedule(include_weekends=True)
```

## jarvis/executors/custom_conditions.py

```diff
@@ -9,36 +9,48 @@
 
 
 def custom_conditions(phrase: str, function_map: OrderedDict[str, Callable]) -> bool:
     """Execute one or many functions based on custom conditions."""
     if not (custom_mapping := files.get_custom_conditions()):
         return False
     # noinspection PyTypeChecker
-    closest_match = util.get_closest_match(text=phrase.lower(), match_list=custom_mapping.keys(), get_ratio=True)
-    if closest_match['ratio'] < 0.9:
+    closest_match = util.get_closest_match(
+        text=phrase.lower(), match_list=custom_mapping.keys(), get_ratio=True
+    )
+    if closest_match["ratio"] < 0.9:
         return False
-    custom_phrase = closest_match['text']
+    custom_phrase = closest_match["text"]
     task_map = custom_mapping[custom_phrase]
-    logger.info("'%s' matches with the custom condition '%s' at the rate: %.2f",
-                phrase, custom_phrase, closest_match['ratio'])
+    logger.info(
+        "'%s' matches with the custom condition '%s' at the rate: %.2f",
+        phrase,
+        custom_phrase,
+        closest_match["ratio"],
+    )
     executed = False
     if shared.called_by_offline:
         response = ""
         for function_, task_ in task_map.items():
             if function_map.get(function_):
                 executed = True
                 method.executor(function_map[function_], task_)
                 response += shared.text_spoken + "\n"
             else:
-                warnings.warn("Custom condition map was found with incorrect function name: '%s'" % function_)
+                warnings.warn(
+                    "Custom condition map was found with incorrect function name: '%s'"
+                    % function_
+                )
         if response:
             speaker.speak(text=response)
     else:
         for function_, task_ in task_map.items():
             if function_map.get(function_):
                 executed = True
                 method.executor(function_map[function_], task_)
             else:
-                warnings.warn("Custom condition map was found with incorrect function name: '%s'" % function_)
+                warnings.warn(
+                    "Custom condition map was found with incorrect function name: '%s'"
+                    % function_
+                )
     if executed:
         return True
     logger.debug("Custom map was present but did not match with the current request.")
```

## jarvis/executors/date_time.py

```diff
@@ -15,41 +15,49 @@
     Args:
         converted: Takes the phrase as an argument.
     """
     place = support.get_capitalized(phrase=converted) if converted else None
     if place and len(place) > 3:
         place_tz = location.geo_locator.geocode(place)
         coordinates = place_tz.latitude, place_tz.longitude
-        located = location.geo_locator.reverse(coordinates, language='en')
-        address = located.raw.get('address', {})
-        city, state = address.get('city'), address.get('state')
-        time_location = f'{city} {state}'.replace('None', '') if city or state else place
-        zone = TimezoneFinder().timezone_at(lat=place_tz.latitude, lng=place_tz.longitude)
+        located = location.geo_locator.reverse(coordinates, language="en")
+        address = located.raw.get("address", {})
+        city, state = address.get("city"), address.get("state")
+        time_location = (
+            f"{city} {state}".replace("None", "") if city or state else place
+        )
+        zone = TimezoneFinder().timezone_at(
+            lat=place_tz.latitude, lng=place_tz.longitude
+        )
         datetime_zone = datetime.now(pytz.timezone(zone))
         date_tz = datetime_zone.strftime("%A, %B %d, %Y")
         time_tz = datetime_zone.strftime("%I:%M %p")
         dt_string = datetime.now().strftime("%A, %B %d, %Y")
         if date_tz != dt_string:
             date_tz = datetime_zone.strftime("%A, %B %d")
-            speaker.speak(text=f'The current time in {time_location} is {time_tz}, on {date_tz}.')
+            speaker.speak(
+                text=f"The current time in {time_location} is {time_tz}, on {date_tz}."
+            )
         else:
-            speaker.speak(text=f'The current time in {time_location} is {time_tz}.')
+            speaker.speak(text=f"The current time in {time_location} is {time_tz}.")
     else:
-        if shared.called['report']:
-            speaker.speak(text=f"The current time is, {datetime.now().strftime('%I:%M %p')}.")
+        if shared.called["report"]:
+            speaker.speak(
+                text=f"The current time is, {datetime.now().strftime('%I:%M %p')}."
+            )
             return
         speaker.speak(text=f"{datetime.now().strftime('%I:%M %p')}.")
 
 
 def current_date(*args) -> None:
     """Says today's date and adds the current time in speaker queue if report function was called."""
     dt_string = datetime.now().strftime("%A, %B")
     date_ = support.ENGINE.ordinal(datetime.now().strftime("%d"))
     year = str(datetime.now().year)
     event = others.celebrate()
-    dt_string = f'{dt_string} {date_}, {year}'
+    dt_string = f"{dt_string} {date_}, {year}"
     text = f"It's {dt_string}."
-    if event and event == 'Birthday':
+    if event and event == "Birthday":
         text += f" It's also your {event} {models.env.title}!"
     elif event:
         text += f" It's also {event} {models.env.title}!"
     speaker.speak(text=text)
```

## jarvis/executors/display_functions.py

```diff
@@ -13,21 +13,33 @@
     """Pre-process to check the phrase received and call the appropriate brightness function as necessary.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
     """
     phrase = phrase.lower()
     speaker.speak(text=random.choice(conversation.acknowledgement))
-    if 'set' in phrase:
+    if "set" in phrase:
         level = util.extract_nos(input_=phrase, method=int)
         try:
-            assert isinstance(level, int) and 0 <= level <= 100, "value should be an integer between 0 and 100"
+            assert (
+                isinstance(level, int) and 0 <= level <= 100
+            ), "value should be an integer between 0 and 100"
         except AssertionError as err:
             logger.warning(err)
             level = 50
         Thread(target=pybrightness.custom, args=(level, logger)).start()
-    elif 'decrease' in phrase or 'reduce' in phrase or 'lower' in phrase or \
-            'dark' in phrase or 'dim' in phrase:
+    elif (
+        "decrease" in phrase
+        or "reduce" in phrase
+        or "lower" in phrase
+        or "dark" in phrase
+        or "dim" in phrase
+    ):
         Thread(target=pybrightness.decrease, args=(logger,)).start()
-    elif 'increase' in phrase or 'bright' in phrase or 'max' in phrase or \
-            'brighten' in phrase or 'light up' in phrase:
+    elif (
+        "increase" in phrase
+        or "bright" in phrase
+        or "max" in phrase
+        or "brighten" in phrase
+        or "light up" in phrase
+    ):
         Thread(target=pybrightness.increase, args=(logger,)).start()
```

## jarvis/executors/face.py

```diff
@@ -10,73 +10,96 @@
 from jarvis.modules.exceptions import CameraError
 from jarvis.modules.facenet.face import FaceNet
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.utils import support
 
 TRAINING_DIR = os.path.realpath("train")
-FACE_DETECTION_TEMP_FILE = 'cv2_open.jpg'
+FACE_DETECTION_TEMP_FILE = "cv2_open.jpg"
 
 
 def detected_face() -> None:
     """Captures a picture, shows a preview and stores it for future recognition."""
-    support.write_screen(text='New face has been detected. Like to give it a name?')
-    speaker.speak(text='I was able to detect a face, but was unable to recognize it.')
+    support.write_screen(text="New face has been detected. Like to give it a name?")
+    speaker.speak(text="I was able to detect a face, but was unable to recognize it.")
     Image.open(FACE_DETECTION_TEMP_FILE).show()
-    speaker.speak(text=f"I've taken a photo of you. Preview on your screen {models.env.title}! "
-                       "Please tell me a name if you'd like to recognize this face in the future, or simply say exit.",
-                  run=True)
+    speaker.speak(
+        text=f"I've taken a photo of you. Preview on your screen {models.env.title}! "
+        "Please tell me a name if you'd like to recognize this face in the future, or simply say exit.",
+        run=True,
+    )
     phrase = listener.listen()
-    if not phrase or 'exit' in phrase or 'quit' in phrase or 'Xzibit' in phrase:
-        os.remove('cv2_open.jpg')
+    if not phrase or "exit" in phrase or "quit" in phrase or "Xzibit" in phrase:
+        os.remove("cv2_open.jpg")
         speaker.speak(text="I've deleted the image.", run=True)
     else:
-        phrase = phrase.replace(' ', '_')
+        phrase = phrase.replace(" ", "_")
         # creates a named directory if it is not found already
         if not os.path.exists(os.path.join(TRAINING_DIR, phrase)):
             os.makedirs(os.path.join(TRAINING_DIR, phrase))
         img_name = f"{phrase}_{datetime.now().strftime('%B_%d_%Y_%I-%M_%p')}.jpg"  # adds datetime to image name
         os.rename(FACE_DETECTION_TEMP_FILE, img_name)  # renames the files
-        shutil.move(src=img_name, dst=os.path.join(TRAINING_DIR, phrase))  # move under TRAINING_DIR -> named directory
-        speaker.speak(text=f"Image has been added to known database. I will be able to recognize {phrase} in future.")
+        shutil.move(
+            src=img_name, dst=os.path.join(TRAINING_DIR, phrase)
+        )  # move under TRAINING_DIR -> named directory
+        speaker.speak(
+            text=f"Image has been added to known database. I will be able to recognize {phrase} in future."
+        )
 
 
 def faces(phrase: str) -> None:
     """Initiates face recognition script and looks for images stored in named directories within ``train`` directory."""
     support.flush_screen()
-    if word_match.word_match(phrase=phrase, match_list=("detect", "detection", "faces", "look")):
+    if word_match.word_match(
+        phrase=phrase, match_list=("detect", "detection", "faces", "look")
+    ):
         try:
             face_detection = FaceNet().face_detection(retry_count=5)
         except FileNotFoundError as error:
             logger.error(error)
-            speaker.speak(text=f"I'm sorry {models.env.title}! I wasn't able to initiate face detection.")
+            speaker.speak(
+                text=f"I'm sorry {models.env.title}! I wasn't able to initiate face detection."
+            )
             return
         if face_detection:
             detected_face()
         else:
             speaker.speak(text=f"No faces were detected {models.env.title}!")
     else:
-        if os.path.isdir(TRAINING_DIR) and \
-                set(os.path.dirname(p) for p in glob.glob(os.path.join(TRAINING_DIR, "*", ""), recursive=True)):
-            speaker.speak(text='Initializing facial recognition. Please smile at the camera for me.', run=True)
-            support.write_screen(text='Looking for faces to recognize.')
+        if os.path.isdir(TRAINING_DIR) and set(
+            os.path.dirname(p)
+            for p in glob.glob(os.path.join(TRAINING_DIR, "*", ""), recursive=True)
+        ):
+            speaker.speak(
+                text="Initializing facial recognition. Please smile at the camera for me.",
+                run=True,
+            )
+            support.write_screen(text="Looking for faces to recognize.")
             try:
                 result = FaceNet().face_recognition(location=TRAINING_DIR)
             except CameraError:
                 support.flush_screen()
-                logger.error('Unable to access the camera.')
-                speaker.speak(text="I was unable to access the camera. Facial recognition can work only when a camera "
-                                   "is present and accessible.")
+                logger.error("Unable to access the camera.")
+                speaker.speak(
+                    text="I was unable to access the camera. Facial recognition can work only when a camera "
+                    "is present and accessible."
+                )
                 return
             if result:
-                speaker.speak(text=f'Hi {result}! How can I be of service to you?')
+                speaker.speak(text=f"Hi {result}! How can I be of service to you?")
                 return
-            speaker.speak(text="No faces were recognized. Switching to face detection.", run=True)
+            speaker.speak(
+                text="No faces were recognized. Switching to face detection.", run=True
+            )
         else:
             os.mkdir(TRAINING_DIR) if not os.path.isdir(TRAINING_DIR) else None
-            speaker.speak(text=f"No named training modules were found {models.env.title}. Switching to face detection",
-                          run=True)
+            speaker.speak(
+                text=f"No named training modules were found {models.env.title}. Switching to face detection",
+                run=True,
+            )
         if FaceNet().face_detection(filename=FACE_DETECTION_TEMP_FILE):
             detected_face()
         else:
-            speaker.speak(text='No faces were recognized. nor detected. Please check if your camera is working, '
-                               'and look at the camera when you retry.')
+            speaker.speak(
+                text="No faces were recognized. nor detected. Please check if your camera is working, "
+                "and look at the camera when you retry."
+            )
```

## jarvis/executors/files.py

```diff
@@ -1,75 +1,81 @@
 """Wrapper for frequently used mapping files."""
 
 import collections
+import os
+import warnings
+from datetime import datetime
 from threading import Timer
-from typing import Any, DefaultDict, Dict, List, Union
+from typing import Any, DefaultDict, Dict, List
 
 import yaml
 from pydantic import ValidationError
 
 from jarvis.modules.logger import logger
 from jarvis.modules.models import classes, models
 
 
-def get_contacts() -> Union[Dict[str, Dict[str, str]], DefaultDict[str, Dict[str, str]]]:
+def get_contacts() -> Dict[str, Dict[str, str]] | DefaultDict[str, Dict[str, str]]:
     """Reads the contact file and returns the data."""
     try:
         with open(models.fileio.contacts) as file:
             if contacts := yaml.load(stream=file, Loader=yaml.FullLoader):
                 return contacts
     except (yaml.YAMLError, FileNotFoundError) as error:
-        logger.error(error)
+        logger.debug(error)
     return collections.defaultdict(lambda: {}, phone={}, email={})
 
 
 def get_frequent() -> Dict[str, int]:
     """Support getting frequently used keywords' mapping file."""
     try:
         with open(models.fileio.frequent) as file:
             return yaml.load(stream=file, Loader=yaml.FullLoader) or {}
     except (yaml.YAMLError, FileNotFoundError) as error:
-        logger.error(error)
+        logger.debug(error)
     return {}
 
 
 def put_frequent(data: Dict[str, int]) -> None:
     """Support writing frequently used keywords' mapping file.
 
     Args:
         data: Takes the mapping dictionary as an argument.
     """
-    with open(models.fileio.frequent, 'w') as file:
+    with open(models.fileio.frequent, "w") as file:
         yaml.dump(data=data, stream=file, sort_keys=False)
         file.flush()  # Write everything in buffer to file right away
 
 
-def get_location() -> Dict:
+def get_location() -> DefaultDict[str, Dict | float | bool]:
     """Reads the location file and returns the location data."""
     try:
         with open(models.fileio.location) as file:
             if location := yaml.load(stream=file, Loader=yaml.FullLoader):
                 return location
     except (yaml.YAMLError, FileNotFoundError) as error:
-        logger.error(error)
-    return collections.defaultdict(lambda: {}, address={}, latitude=0.0, longitude=0.0, reserved=False)
+        logger.debug(error)
+    # noinspection PyTypeChecker
+    return collections.defaultdict(
+        lambda: {}, address={}, latitude=0.0, longitude=0.0, reserved=False
+    )
 
 
 def get_secure_send() -> Dict[str, Dict[str, Any]]:
     """Get existing secure string information from the mapping file.
 
     Returns:
         Dict[str, Dict[str, Any]]:
         Dictionary of secure send data.
     """
     try:
         with open(models.fileio.secure_send) as file:
             return yaml.load(stream=file, Loader=yaml.FullLoader) or {}
     except (yaml.YAMLError, FileNotFoundError) as error:
-        logger.error(error)
+        logger.debug(error)
     return {}
 
 
 def delete_secure_send(key: str) -> None:
     """Delete a particular secure key dictionary stored in the mapping file.
 
     Args:
@@ -77,69 +83,72 @@
     """
     current_data = get_secure_send()
     if current_data.get(key):
         logger.info("Deleting %s: %s", key, [*current_data[key].keys()][0])
         del current_data[key]
     else:
         logger.critical("data for key [%s] was removed unprecedentedly", key)
-    with open(models.fileio.secure_send, 'w') as file:
+    with open(models.fileio.secure_send, "w") as file:
         yaml.dump(data=current_data, stream=file, Dumper=yaml.Dumper)
         file.flush()  # Write buffer to file immediately
 
 
 def put_secure_send(data: Dict[str, Dict[str, Any]]):
     """Add a particular secure key dictionary to the mapping file.
 
     Args:
         data: Data dict that has to be added.
     """
     existing = get_secure_send()
-    with open(models.fileio.secure_send, 'w') as file:
+    with open(models.fileio.secure_send, "w") as file:
         yaml.dump(data={**existing, **data}, stream=file, Dumper=yaml.Dumper)
         file.flush()  # Write buffer to file immediately
-    logger.info("Secure dict for [%s] will be cleared after 5 minutes", [*[*data.values()][0].keys()][0])
+    logger.info(
+        "Secure dict for [%s] will be cleared after 5 minutes",
+        [*[*data.values()][0].keys()][0],
+    )
     Timer(function=delete_secure_send, args=data.keys(), interval=300).start()
 
 
 def get_custom_conditions() -> Dict[str, Dict[str, str]]:
     """Custom conditions to map specific keywords to one or many functions.
 
     Returns:
         Dict[str, Dict[str, str]]:
         A unique key value pair of custom phrase as key and an embedded dict of function name and phrase.
     """
     try:
         with open(models.fileio.conditions) as file:
             return yaml.load(stream=file, Loader=yaml.FullLoader)
     except (yaml.YAMLError, FileNotFoundError) as error:
-        logger.error(error)
+        logger.debug(error)
 
 
 def get_restrictions() -> List[str]:
     """Function level restrictions to restrict certain keywords via offline communicator.
 
     Returns:
         List[str]:
         A list of function names that has to be restricted.
     """
     try:
         with open(models.fileio.restrictions) as file:
             return yaml.load(stream=file, Loader=yaml.FullLoader)
     except (yaml.YAMLError, FileNotFoundError) as error:
-        logger.error(error)
+        logger.debug(error)
     return []
 
 
 def put_restrictions(restrictions: List[str]) -> None:
     """Function level restrictions to restrict certain keywords via offline communicator.
 
     Args:
         restrictions: A list of function names that has to be restricted.
     """
-    with open(models.fileio.restrictions, 'w') as file:
+    with open(models.fileio.restrictions, "w") as file:
         yaml.dump(data=restrictions, stream=file, indent=2, sort_keys=False)
         file.flush()  # Write buffer to file immediately
 
 
 def get_gpt_data() -> List[Dict[str, str]]:
     """Get history from Jarvis -> ChatGPT conversation.
 
@@ -147,150 +156,163 @@
         List[Dict[str, str]]:
         A list of dictionaries with request and response key-value pairs.
     """
     try:
         with open(models.fileio.gpt_data) as file:
             return yaml.load(stream=file, Loader=yaml.FullLoader)
     except (yaml.YAMLError, FileNotFoundError) as error:
-        logger.error(error)
+        logger.debug(error)
 
 
 def put_gpt_data(data: List[Dict[str, str]]) -> None:
     """Stores Jarvis -> ChatGPT conversations in a history file.
 
     Args:
         data: List of dictionaries that have to be saved for future reference.
     """
-    with open(models.fileio.gpt_data, 'w') as file:
+    with open(models.fileio.gpt_data, "w") as file:
         yaml.dump(data=data, stream=file, indent=4, Dumper=yaml.Dumper)
         file.flush()  # Write buffer to file immediately
 
 
-def get_automation() -> Dict[str, Union[List[Dict[str, Union[str, bool]]], Dict[str, Union[str, bool]]]]:
+def get_automation() -> Dict[str, List[Dict[str, str | bool]] | Dict[str, str | bool]]:
     """Load automation data from feed file.
 
     Returns:
-        Dict[str, Union[List[Dict[str, Union[str, bool]]], Dict[str, Union[str, bool]]]]:
+        Dict[str, List[Dict[str, str | bool]] | Dict[str, str | bool]]:
         Returns the automation data in the feed file.
     """
     try:
         with open(models.fileio.automation) as read_file:
             return yaml.load(stream=read_file, Loader=yaml.FullLoader) or {}
     except (yaml.YAMLError, FileNotFoundError) as error:
-        logger.error(error)
+        logger.debug(error)
     return {}
 
 
-def put_automation(data: Dict[str, Union[List[Dict[str, Union[str, bool]]], Dict[str, Union[str, bool]]]]) -> None:
+def put_automation(
+    data: Dict[str, List[Dict[str, str | bool]] | Dict[str, str | bool]]
+) -> None:
     """Dumps automation data into feed file.
 
     Args:
         data: Data that has to be dumped into the automation feed file.
     """
-    with open(models.fileio.automation, 'w') as file:
-        yaml.dump(data=data, stream=file, indent=2, sort_keys=False)
+    # Sort the keys by timestamp
+    try:
+        sorted_data = {
+            k: data[k]
+            for k in sorted(data.keys(), key=lambda x: datetime.strptime(x, "%I:%M %p"))
+        }
+    except ValueError as error:
+        logger.error(error)
+        logger.error("Writing automation data without sorting")
+        sorted_data = data
+
+    with open(models.fileio.automation, "w") as file:
+        yaml.dump(data=sorted_data, stream=file, indent=2)
         file.flush()  # Write buffer to file immediately
 
 
-def get_smart_devices() -> Union[dict, bool, None]:
+def get_smart_devices() -> dict | bool | None:
     """Load smart devices' data from feed file.
 
     Returns:
-        Union[dict, bool]:
+        dict | bool | None:
         Returns the smart devices' data in the feed file.
     """
     try:
         with open(models.fileio.smart_devices) as file:
             if smart_devices := yaml.load(stream=file, Loader=yaml.FullLoader):
                 return smart_devices
             else:
                 logger.warning("'%s' is empty.", models.fileio.smart_devices)
     except (yaml.YAMLError, FileNotFoundError) as error:
         if isinstance(error, FileNotFoundError):
             logger.warning("%s not found.", models.fileio.smart_devices)
             return
         else:
-            logger.error(error)
+            logger.debug(error)
             return False
 
 
 def put_smart_devices(data: dict) -> None:
     """Dumps smart devices' data into feed file.
 
     Args:
         data: Data that has to be dumped into the smart devices' feed file.
     """
-    with open(models.fileio.smart_devices, 'w') as file:
+    with open(models.fileio.smart_devices, "w") as file:
         yaml.dump(data=data, stream=file, indent=2, sort_keys=False)
         file.flush()  # Write buffer to file immediately
 
 
-def get_processes() -> Dict[str, List[Union[int, List[str]]]]:
+def get_processes() -> Dict[str, List[int | List[str]]]:
     """Get the processes' mapping from stored map file.
 
     Returns:
-        Dict[str, List[Union[int, List[str]]]]:
+        Dict[str, List[int | List[str]]]:
         Processes' mapping data.
     """
     try:
         with open(models.fileio.processes) as file:
             return yaml.load(stream=file, Loader=yaml.FullLoader) or {}
     except (yaml.YAMLError, FileNotFoundError) as error:
-        logger.error(error)
+        logger.debug(error)
     return {}
 
 
 def get_reminders() -> List[Dict[str, str]]:
     """Get all reminders stored.
 
     Returns:
         List[Dict[str, str]]:
         Returns a list of dictionary of information for stored reminders.
     """
     try:
         with open(models.fileio.reminders) as file:
             return yaml.load(stream=file, Loader=yaml.FullLoader) or []
     except (yaml.YAMLError, FileNotFoundError) as error:
-        logger.error(error)
+        logger.debug(error)
     return []
 
 
 def put_reminders(data: List[Dict[str, str]]):
     """Dumps the reminder data into the respective yaml file.
 
     Args:
         data: Data to be dumped.
     """
-    with open(models.fileio.reminders, 'w') as file:
+    with open(models.fileio.reminders, "w") as file:
         yaml.dump(data=data, stream=file, indent=2, sort_keys=False)
         file.flush()  # Write buffer to file immediately
 
 
-def get_alarms() -> List[Dict[str, Union[str, bool]]]:
+def get_alarms() -> List[Dict[str, str | bool]]:
     """Get all alarms stored.
 
     Returns:
-        Dict[str, Union[str, bool]]:
+        Dict[str, str | bool]:
         Returns a dictionary of information for stored alarms.
     """
     try:
         with open(models.fileio.alarms) as file:
             return yaml.load(stream=file, Loader=yaml.FullLoader) or []
     except (yaml.YAMLError, FileNotFoundError) as error:
-        logger.error(error)
+        logger.debug(error)
     return []
 
 
-def put_alarms(data: List[Dict[str, Union[str, bool]]]):
+def put_alarms(data: List[Dict[str, str | bool]]):
     """Dumps the alarm data into the respective yaml file.
 
     Args:
         data: Data to be dumped.
     """
-    with open(models.fileio.alarms, 'w') as file:
+    with open(models.fileio.alarms, "w") as file:
         yaml.dump(data=data, stream=file, indent=2, sort_keys=False)
         file.flush()  # Write buffer to file immediately
 
 
 def get_recognizer() -> classes.RecognizerSettings:
     """Get the stored settings for speech recognition.
 
@@ -299,9 +321,30 @@
         Returns the parsed recognizer settings or default.
     """
     try:
         with open(models.fileio.recognizer) as file:
             rec_data = yaml.load(stream=file, Loader=yaml.FullLoader) or {}
         return classes.RecognizerSettings(**rec_data)
     except (yaml.YAMLError, FileNotFoundError, TypeError, ValidationError) as error:
-        logger.error(error)
+        logger.debug(error)
     return classes.RecognizerSettings()
+
+
+def get_crontab() -> List[str]:
+    """Get the stored crontab settings.
+
+    Returns:
+        List[str]:
+        List of crontab entries.
+    """
+    try:
+        with open(models.fileio.crontab) as file:
+            data = yaml.load(stream=file, Loader=yaml.FullLoader) or []
+            assert isinstance(data, list)
+            return data
+    except FileNotFoundError as error:
+        logger.debug(error)
+    except (yaml.YAMLError, AssertionError) as error:
+        logger.error(error)
+        os.rename(src=models.fileio.crontab, dst=models.fileio.tmp_crontab)
+        warnings.warn("CRONTAB :: Invalid file format.")
+    return []
```

## jarvis/executors/functions.py

```diff
@@ -4,21 +4,46 @@
 >>> Functions
 
 """
 
 from collections import OrderedDict
 from typing import Callable
 
-from jarvis.executors import (alarm, automation, background_task, car,
-                              comm_squire, communicator, controls, date_time,
-                              display_functions, face, github, guard, internet,
-                              ios_functions, lights, listener_controls,
-                              location, others, remind, robinhood, simulator,
-                              static_responses, system, thermostat, todo_list,
-                              tv, volume, vpn_server, weather, wiki)
+from jarvis.executors import (
+    alarm,
+    automation,
+    background_task,
+    car,
+    comm_squire,
+    communicator,
+    controls,
+    date_time,
+    display_functions,
+    face,
+    github,
+    guard,
+    internet,
+    ios_functions,
+    lights,
+    listener_controls,
+    location,
+    others,
+    remind,
+    robinhood,
+    simulator,
+    static_responses,
+    system,
+    thermostat,
+    todo_list,
+    tv,
+    volume,
+    vpn_server,
+    weather,
+    wiki,
+)
 from jarvis.modules.audio import voices
 from jarvis.modules.meetings import events, ics_meetings
 
 
 def function_mapping() -> OrderedDict[str, Callable]:
     """Returns an ordered dictionary of functions mapping.
 
@@ -89,9 +114,9 @@
         capabilities=static_responses.capabilities,
         languages=static_responses.languages,
         what=static_responses.what,
         who=static_responses.who,
         age=static_responses.age,
         form=static_responses.form,
         whats_up=static_responses.whats_up,
-        about_me=static_responses.about_me
+        about_me=static_responses.about_me,
     )
```

## jarvis/executors/github.py

```diff
@@ -21,33 +21,51 @@
     """
     if not all([models.env.git_user, models.env.git_pass]):
         logger.warning("Github username or token not found.")
         support.no_env_vars()
         return
     auth = HTTPBasicAuth(models.env.git_user, models.env.git_pass)
     try:
-        response = requests.get('https://api.github.com/user/repos?type=all&per_page=100', auth=auth).json()
+        response = requests.get(
+            "https://api.github.com/user/repos?type=all&per_page=100", auth=auth
+        ).json()
     except EgressErrors as error:
         logger.error(error)
-        speaker.speak(text=f"I'm sorry {models.env.title}! I wasn't able to connect to the GitHub API.")
+        speaker.speak(
+            text=f"I'm sorry {models.env.title}! I wasn't able to connect to the GitHub API."
+        )
         return
     result, repos, total, forked, private, archived, licensed = [], [], 0, 0, 0, 0, 0
     for i in range(len(response)):
         total += 1
-        forked += 1 if response[i]['fork'] else 0
-        private += 1 if response[i]['private'] else 0
-        archived += 1 if response[i]['archived'] else 0
-        licensed += 1 if response[i]['license'] else 0
-        repos.append({response[i]['name'].replace('_', ' ').replace('-', ' '): response[i]['clone_url']})
-    if 'how many' in phrase:
-        speaker.speak(text=f'You have {total} repositories {models.env.title}, out of which {forked} are forked, '
-                           f'{private} are private, {licensed} are licensed, and {archived} archived.')
+        forked += 1 if response[i]["fork"] else 0
+        private += 1 if response[i]["private"] else 0
+        archived += 1 if response[i]["archived"] else 0
+        licensed += 1 if response[i]["license"] else 0
+        repos.append(
+            {
+                response[i]["name"]
+                .replace("_", " ")
+                .replace("-", " "): response[i]["clone_url"]
+            }
+        )
+    if "how many" in phrase:
+        speaker.speak(
+            text=f"You have {total} repositories {models.env.title}, out of which {forked} are forked, "
+            f"{private} are private, {licensed} are licensed, and {archived} archived."
+        )
     elif not shared.called_by_offline:
-        [result.append(clone_url) if clone_url not in result and re.search(rf'\b{word}\b', repo.lower()) else None
-         for word in phrase.lower().split() for item in repos for repo, clone_url in item.items()]
+        [
+            result.append(clone_url)
+            if clone_url not in result and re.search(rf"\b{word}\b", repo.lower())
+            else None
+            for word in phrase.lower().split()
+            for item in repos
+            for repo, clone_url in item.items()
+        ]
         if result:
             github_controller(target=result)
         else:
             speaker.speak(text=f"Sorry {models.env.title}! I did not find that repo.")
 
 
 def github_controller(target: list) -> None:
@@ -56,31 +74,44 @@
     Asks confirmation if the results are more than 1 but less than 3 else asks to be more specific.
 
     Args:
         target: Takes repository name as argument which has to be cloned.
     """
     if len(target) == 1:
         os.system(f"cd {models.env.home} && git clone -q {target[0]}")
-        cloned = target[0].split('/')[-1].replace('.git', '')
-        speaker.speak(text=f"I've cloned {cloned} on your home directory {models.env.title}!")
+        cloned = target[0].split("/")[-1].replace(".git", "")
+        speaker.speak(
+            text=f"I've cloned {cloned} on your home directory {models.env.title}!"
+        )
         return
     elif len(target) <= 3:
-        speaker.speak(text=f"I found {len(target)} results. On your screen {models.env.title}! "
-                           "Which one shall I clone?", run=True)
+        speaker.speak(
+            text=f"I found {len(target)} results. On your screen {models.env.title}! "
+            "Which one shall I clone?",
+            run=True,
+        )
         if not (converted := listener.listen()):
-            if word_match.word_match(phrase=converted, match_list=keywords.keywords['exit_']):
+            if word_match.word_match(
+                phrase=converted, match_list=keywords.keywords["exit_"]
+            ):
                 return
-            if 'first' in converted.lower():
+            if "first" in converted.lower():
                 item = 1
-            elif 'second' in converted.lower():
+            elif "second" in converted.lower():
                 item = 2
-            elif 'third' in converted.lower():
+            elif "third" in converted.lower():
                 item = 3
             else:
                 item = None
-                speaker.speak(text=f"Only first second or third can be accepted {models.env.title}! Try again!")
+                speaker.speak(
+                    text=f"Only first second or third can be accepted {models.env.title}! Try again!"
+                )
                 github_controller(target)
             os.system(f"cd {models.env.home} && git clone -q {target[item]}")
-            cloned = target[item].split('/')[-1].replace('.git', '')
-            speaker.speak(text=f"I've cloned {cloned} on your home directory {models.env.title}!")
+            cloned = target[item].split("/")[-1].replace(".git", "")
+            speaker.speak(
+                text=f"I've cloned {cloned} on your home directory {models.env.title}!"
+            )
     else:
-        speaker.speak(text=f"I found {len(target)} repositories {models.env.title}! You may want to be more specific.")
+        speaker.speak(
+            text=f"I found {len(target)} repositories {models.env.title}! You may want to be more specific."
+        )
```

## jarvis/executors/guard.py

```diff
@@ -1,14 +1,14 @@
 import os
 import shutil
 import time
 from datetime import datetime
 from multiprocessing import Process
 from threading import Thread, Timer
-from typing import Tuple, Union
+from typing import Tuple
 
 import gmailconnector
 import jinja2
 
 from jarvis.executors import communicator, word_match
 from jarvis.modules.audio import listener, speaker
 from jarvis.modules.conditions import keywords
@@ -53,15 +53,18 @@
         cursor = db.connection.cursor()
         if state is True:
             if shared.called_by_offline:
                 trigger = "GUARD_OFFLINE"
             else:
                 trigger = "GUARD_VOICE"
             logger.info("Enabling security mode.")
-            cursor.execute("INSERT or REPLACE INTO guard (state, trigger) VALUES (?,?);", (1, trigger))
+            cursor.execute(
+                "INSERT or REPLACE INTO guard (state, trigger) VALUES (?,?);",
+                (1, trigger),
+            )
         else:
             logger.info("Disabling security mode.")
             cursor.execute("DELETE FROM guard WHERE state = 1")
         db.connection.commit()
     time.sleep(0.5)
 
 
@@ -69,24 +72,26 @@
     """Stops security mode and responds accordingly.
 
     Args:
         stop: Boolean flag to stop or simply repsond.
     """
     if stop:
         put_state(state=False)
-    text = f'Welcome back {models.env.title}! Good {util.part_of_day()}.'
-    if [file for file in os.listdir('threat') if file.endswith('.jpg')]:
-        text += f" We had a potential threat {models.env.title}! Please check your email, or the " \
-                "threat directory to confirm."
+    text = f"Welcome back {models.env.title}! Good {util.part_of_day()}."
+    if [file for file in os.listdir("threat") if file.endswith(".jpg")]:
+        text += (
+            f" We had a potential threat {models.env.title}! Please check your email, or the "
+            "threat directory to confirm."
+        )
     speaker.speak(text=text)
-    new_dir = os.path.join('threat', datetime.now().strftime('%b_%d_%y'))
+    new_dir = os.path.join("threat", datetime.now().strftime("%b_%d_%y"))
     if not os.path.isdir(new_dir):
         os.mkdir(new_dir)
-    for file in os.listdir('threat'):
-        threat_file = os.path.join('threat', file)
+    for file in os.listdir("threat"):
+        threat_file = os.path.join("threat", file)
         if os.path.isfile(threat_file):
             shutil.move(src=threat_file, dst=os.path.join(new_dir, file))
     speaker.speak(run=True)
 
 
 def politely_disable() -> None:
     """Disable security mode in the background without any response."""
@@ -121,124 +126,162 @@
         else:
             speaker.speak(text=f"Security mode was never enabled {models.env.title}!")
 
 
 def security_runner(offline: bool = True) -> None:
     """Enables microphone and camera to watch and listen for potential threats. Notifies if any."""
     if offline:
-        multiprocessing_logger(filename=os.path.join('logs', 'guardian_mode_%d-%m-%Y.log'))
+        multiprocessing_logger(
+            filename=os.path.join("logs", "guardian_mode_%d-%m-%Y.log")
+        )
     notified, converted = None, None
     face_object = face.FaceNet()
     while True:
         # Listens for any recognizable speech and saves it to a notes file
         support.write_screen(text="SECURITY MODE")
         converted = listener.listen(sound=False, no_conf=True)
-        face_detected = datetime.now().strftime('%B_%d_%Y_%I_%M_%S_%p.jpg')
-        if not get_state(log=False) or word_match.word_match(phrase=converted,
-                                                             match_list=keywords.keywords['guard_disable']):
+        face_detected = datetime.now().strftime("%B_%d_%Y_%I_%M_%S_%p.jpg")
+        if not get_state(log=False) or word_match.word_match(
+            phrase=converted, match_list=keywords.keywords["guard_disable"]
+        ):
             guard_disable()
             break
         elif converted:
             logger.info("Conversation::%s", converted)
         try:
             if not models.env.debug:  # Skip face recognition when DEBUG mode is enabled
-                if recognized := face_object.face_recognition(location=os.path.realpath("train"), retry_count=1):
-                    logger.warning("Located '%s' when guardian mode was enabled.", recognized)
+                if recognized := face_object.face_recognition(
+                    location=os.path.realpath("train"), retry_count=1
+                ):
+                    logger.warning(
+                        "Located '%s' when guardian mode was enabled.", recognized
+                    )
                     continue
             if not face_object.face_detection(filename=face_detected, mirror=True):
                 face_detected = None
         except Exception as error:  # Catch wide exceptions here to prevent guardian mode from getting disabled
             logger.error(error)
             continue
         if not any((face_detected, converted)):
             continue
         elif face_detected:
-            shutil.move(src=face_detected, dst=os.path.join('threat', face_detected))
-            face_detected = os.path.join('threat', face_detected)
+            shutil.move(src=face_detected, dst=os.path.join("threat", face_detected))
+            face_detected = os.path.join("threat", face_detected)
 
         # if no notification was sent yet or if a phrase or face is detected notification thread will be triggered
         if not notified or float(time.time() - notified) > 300:
             notified = time.time()
-            Thread(target=threat_notify, args=(converted, face_detected,)).start()
+            Thread(
+                target=threat_notify,
+                args=(
+                    converted,
+                    face_detected,
+                ),
+            ).start()
 
 
 def guard_enable(*args) -> None:
     """Security Mode will enable camera and microphone in the background.
 
     Notes:
         - If any speech is recognized or a face is detected, there will another thread triggered to send notifications.
         - Notifications will be triggered only after 5 minutes of previous notification.
     """
     if get_state():
         speaker.speak(text=f"Security mode is already active {models.env.title}!")
         return
-    if not os.path.isdir('threat'):
-        os.mkdir('threat')
-    logger.info('Enabled Security Mode')
+    if not os.path.isdir("threat"):
+        os.mkdir("threat")
+    logger.info("Enabled Security Mode")
     put_state(state=True)
-    speaker.speak(text=f"Enabled security mode {models.env.title}! I will look out for potential threats and keep you "
-                       f"posted. Have a nice {util.part_of_day()}, and enjoy yourself {models.env.title}!")
+    speaker.speak(
+        text=f"Enabled security mode {models.env.title}! I will look out for potential threats and keep you "
+        f"posted. Have a nice {util.part_of_day()}, and enjoy yourself {models.env.title}!"
+    )
     if shared.called_by_offline:
         if models.settings.os == models.supported_platforms.linux:
-            pname = (models.settings.pname or "offline communicator").replace('_', ' ')
-            speaker.speak(text=f"Security mode cannot be enabled via {pname}, as the host "
-                               "machine is running on Linux OS")
+            pname = (models.settings.pname or "offline communicator").replace("_", " ")
+            speaker.speak(
+                text=f"Security mode cannot be enabled via {pname}, as the host "
+                "machine is running on Linux OS"
+            )
             return
         process = Process(target=security_runner)
         process.start()
         with db.connection:
             cursor = db.connection.cursor()
             cursor.execute("UPDATE children SET guard=null")
-            cursor.execute("INSERT or REPLACE INTO children (guard) VALUES (?);", (process.pid,))
+            cursor.execute(
+                "INSERT or REPLACE INTO children (guard) VALUES (?);", (process.pid,)
+            )
             db.connection.commit()
         return
     TRACE["status"] = True
     speaker.speak(run=True)
     security_runner(offline=False)
 
 
-def threat_notify(converted: str, face_detected: Union[str, None]) -> None:
+def threat_notify(converted: str, face_detected: str | None) -> None:
     """Sends an SMS and email notification in case of a threat.
 
     References:
         Uses `gmail-connector <https://pypi.org/project/gmail-connector/>`__ to send the SMS and email.
 
     Args:
         converted: Takes the voice recognized statement as argument.
         face_detected: Name of the attachment file which is the picture of the intruder.
     """
     recipient = models.env.recipient or models.env.open_gmail_user
     if converted and face_detected:
-        communicator.send_sms(user=models.env.open_gmail_user, password=models.env.open_gmail_pass,
-                              number=models.env.phone_number, subject="!!INTRUDER ALERT!!",
-                              body=f"{datetime.now().strftime('%B %d, %Y %I:%M %p')}\nINTRUDER SPOKE: {converted}\n\n"
-                                   f"Intruder picture has been sent to {recipient}")
-        rendered = jinja2.Template(templates.email.threat_image_audio).render(CONVERTED=converted)
+        communicator.send_sms(
+            user=models.env.open_gmail_user,
+            password=models.env.open_gmail_pass,
+            number=models.env.phone_number,
+            subject="!!INTRUDER ALERT!!",
+            body=f"{datetime.now().strftime('%B %d, %Y %I:%M %p')}\nINTRUDER SPOKE: {converted}\n\n"
+            f"Intruder picture has been sent to {recipient}",
+        )
+        rendered = jinja2.Template(templates.email.threat_image_audio).render(
+            CONVERTED=converted
+        )
     elif face_detected:
-        communicator.send_sms(user=models.env.open_gmail_user, password=models.env.open_gmail_pass,
-                              number=models.env.phone_number, subject="!!INTRUDER ALERT!!",
-                              body=f"{datetime.now().strftime('%B %d, %Y %I:%M %p')}\n"
-                                   "Check your email for more information.")
+        communicator.send_sms(
+            user=models.env.open_gmail_user,
+            password=models.env.open_gmail_pass,
+            number=models.env.phone_number,
+            subject="!!INTRUDER ALERT!!",
+            body=f"{datetime.now().strftime('%B %d, %Y %I:%M %p')}\n"
+            "Check your email for more information.",
+        )
         rendered = jinja2.Template(templates.email.threat_image).render()
     elif converted:
-        communicator.send_sms(user=models.env.open_gmail_user, password=models.env.open_gmail_pass,
-                              number=models.env.phone_number, subject="!!INTRUDER ALERT!!",
-                              body=f"{datetime.now().strftime('%B %d, %Y %I:%M %p')}\n"
-                                   "Check your email for more information.")
-        rendered = jinja2.Template(templates.email.threat_audio).render(CONVERTED=converted)
+        communicator.send_sms(
+            user=models.env.open_gmail_user,
+            password=models.env.open_gmail_pass,
+            number=models.env.phone_number,
+            subject="!!INTRUDER ALERT!!",
+            body=f"{datetime.now().strftime('%B %d, %Y %I:%M %p')}\n"
+            "Check your email for more information.",
+        )
+        rendered = jinja2.Template(templates.email.threat_audio).render(
+            CONVERTED=converted
+        )
     else:
         logger.warning("Un-processable arguments received.")
         return
 
-    kwargs = {"recipient": recipient,
-              "html_body": rendered,
-              "subject": f"Intruder Alert on {datetime.now().strftime('%B %d, %Y %I:%M %p')}"}
+    kwargs = {
+        "recipient": recipient,
+        "html_body": rendered,
+        "subject": f"Intruder Alert on {datetime.now().strftime('%B %d, %Y %I:%M %p')}",
+    }
 
     if face_detected:
         kwargs["attachment"] = face_detected
 
-    response_ = gmailconnector.SendEmail(gmail_user=models.env.open_gmail_user,
-                                         gmail_pass=models.env.open_gmail_pass).send_email(**kwargs)
+    response_ = gmailconnector.SendEmail(
+        gmail_user=models.env.open_gmail_user, gmail_pass=models.env.open_gmail_pass
+    ).send_email(**kwargs)
     if response_.ok:
-        logger.info('Email has been sent!')
+        logger.info("Email has been sent!")
     else:
         logger.error("Email dispatch failed with response: %s", response_.body)
```

## jarvis/executors/internet.py

```diff
@@ -1,29 +1,29 @@
 import json
 import socket
 import subprocess
 import urllib.error
 import urllib.request
 from multiprocessing import Process
-from typing import Dict, Union
+from typing import Dict
 
 import psutil
 import requests
 from pydantic import HttpUrl
 from speedtest import ConfigRetrievalError, Speedtest
 
 from jarvis.executors import location
 from jarvis.modules.audio import speaker
 from jarvis.modules.exceptions import EgressErrors
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.utils import shared, support
 
 
-def ip_address() -> Union[str, None]:
+def ip_address() -> str | None:
     """Uses simple check on network id to see if it is connected to local host or not.
 
     Returns:
         str:
         Private IP address of host machine.
     """
     socket_ = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
@@ -33,169 +33,207 @@
         logger.error(error)
         return
     ip_address_ = socket_.getsockname()[0]
     socket_.close()
     return ip_address_
 
 
-def vpn_checker() -> Union[bool, str]:
+def vpn_checker() -> bool | str:
     """Uses simple check on network id to see if it is connected to local host or not.
 
     Returns:
         bool or str:
         Returns a ``False`` flag if VPN is detected, else the IP address.
     """
     if not (ip_address_ := ip_address()):
-        speaker.speak(text=f"I was unable to connect to the internet {models.env.title}! Please check your connection.")
+        speaker.speak(
+            text=f"I was unable to connect to the internet {models.env.title}! Please check your connection."
+        )
         return False
     if ip_address_.startswith("192") or ip_address_.startswith("127"):
         return ip_address_
     else:
         if info := public_ip_info():
-            speaker.speak(text=f"You have your VPN turned on {models.env.title}! A connection has been detected to "
-                               f"{info.get('ip')} at {info.get('city')} {info.get('region')}, "
-                               f"maintained by {info.get('org')}. Please note that none of the home integrations will "
-                               "work with VPN enabled.")
+            speaker.speak(
+                text=f"You have your VPN turned on {models.env.title}! A connection has been detected to "
+                f"{info.get('ip')} at {info.get('city')} {info.get('region')}, "
+                f"maintained by {info.get('org')}. Please note that none of the home integrations will "
+                "work with VPN enabled."
+            )
         else:
-            speaker.speak(text=f"I was unable to connect to the internet {models.env.title}! "
-                               "Please check your connection.")
+            speaker.speak(
+                text=f"I was unable to connect to the internet {models.env.title}! "
+                "Please check your connection."
+            )
         return False
 
 
 def public_ip_info() -> Dict[str, str]:
     """Get public IP information.
 
     Returns:
         dict:
         Public IP information.
     """
     try:
-        return json.load(urllib.request.urlopen(url='https://ipinfo.io/json'))
+        return json.load(urllib.request.urlopen(url="https://ipinfo.io/json"))
     except (urllib.error.HTTPError, urllib.error.URLError) as error:
         logger.error(error)
     try:
-        return json.loads(urllib.request.urlopen(url='http://ip.jsontest.com').read())
+        return json.loads(urllib.request.urlopen(url="http://ip.jsontest.com").read())
     except (urllib.error.HTTPError, urllib.error.URLError) as error:
         logger.error(error)
 
 
 def ip_info(phrase: str) -> None:
     """Gets IP address of the host machine.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
     """
     if "public" in phrase.lower():
         if not ip_address():
-            speaker.speak(text=f"You are not connected to the internet {models.env.title}!")
+            speaker.speak(
+                text=f"You are not connected to the internet {models.env.title}!"
+            )
             return
         if ssid := get_connection_info():
             ssid = f"for the connection {ssid} "
         else:
             ssid = ""
         if public_ip := public_ip_info():
             output = f"My public IP {ssid}is {public_ip.get('ip')}"
         else:
             output = f"I was unable to fetch the public IP {models.env.title}!"
     else:
         output = f"My local IP address for {socket.gethostname().split('.')[0]} is {ip_address()}"
     speaker.speak(text=output)
 
 
-def get_connection_info(target: str = "SSID") -> Union[str, None]:
+def get_connection_info(target: str = "SSID") -> str | None:
     """Gets information about the network connected.
 
     Returns:
         str:
         Wi-Fi or Ethernet SSID or Name.
     """
     try:
         if models.settings.os == models.supported_platforms.macOS:
             process = subprocess.Popen(
-                ["/System/Library/PrivateFrameworks/Apple80211.framework/Versions/Current/Resources/airport", "-I"],
-                stdout=subprocess.PIPE
+                [
+                    "/System/Library/PrivateFrameworks/Apple80211.framework/Versions/Current/Resources/airport",
+                    "-I",
+                ],
+                stdout=subprocess.PIPE,
             )
         elif models.settings.os == models.supported_platforms.windows:
             process = subprocess.check_output("netsh wlan show interfaces", shell=True)
         else:
-            process = subprocess.check_output("nmcli -t -f name connection show --active | head -n 1", shell=True)
-    except (subprocess.CalledProcessError, subprocess.SubprocessError, FileNotFoundError) as error:
+            process = subprocess.check_output(
+                "nmcli -t -f name connection show --active | head -n 1", shell=True
+            )
+    except (
+        subprocess.CalledProcessError,
+        subprocess.SubprocessError,
+        FileNotFoundError,
+    ) as error:
         if isinstance(error, subprocess.CalledProcessError):
-            result = error.output.decode(encoding='UTF-8').strip()
+            result = error.output.decode(encoding="UTF-8").strip()
             logger.error("[%d]: %s", error.returncode, result)
         else:
             logger.error(error)
         return
     if models.settings.os == models.supported_platforms.macOS:
         out, err = process.communicate()
         if error := process.returncode:
-            logger.error("Failed to fetch %s with exit code [%s]: %s", target, error, err)
+            logger.error(
+                "Failed to fetch %s with exit code [%s]: %s", target, error, err
+            )
             return
         # noinspection PyTypeChecker
-        return dict(map(str.strip, info.split(": ")) for info in out.decode("utf-8").splitlines()[:-1] if
-                    len(info.split()) == 2).get(target)
+        return dict(
+            map(str.strip, info.split(": "))
+            for info in out.decode("utf-8").splitlines()[:-1]
+            if len(info.split()) == 2
+        ).get(target)
     elif models.settings.os == models.supported_platforms.windows:
-        if result := [i.decode().strip() for i in process.splitlines() if
-                      i.decode().strip().startswith(target)]:
-            return result[0].split(':')[-1].strip()
+        if result := [
+            i.decode().strip()
+            for i in process.splitlines()
+            if i.decode().strip().startswith(target)
+        ]:
+            return result[0].split(":")[-1].strip()
         else:
             logger.error("Failed to fetch %s", target)
     else:
         if process:
-            return process.decode(encoding='UTF-8').strip()
+            return process.decode(encoding="UTF-8").strip()
 
 
 def speed_test(*args) -> None:
     """Initiates speed test and says the ping rate, download and upload speed.
 
     References:
         Number of threads per core: https://psutil.readthedocs.io/en/latest/#psutil.cpu_count
     """
     try:
         st = Speedtest()
     except ConfigRetrievalError as error:
         logger.error(error)
-        speaker.speak(text=f"I'm sorry {models.env.title}! I wasn't able to connect to the speed test server.")
+        speaker.speak(
+            text=f"I'm sorry {models.env.title}! I wasn't able to connect to the speed test server."
+        )
         return
     client_location = location.get_location_from_coordinates(coordinates=st.lat_lon)
-    city = client_location.get("city") or client_location.get("residential") or \
-        client_location.get("hamlet") or client_location.get("county")
+    city = (
+        client_location.get("city")
+        or client_location.get("residential")
+        or client_location.get("hamlet")
+        or client_location.get("county")
+    )
     state = client_location.get("state")
     isp = st.results.client.get("isp").replace(",", "").replace(".", "")
     threads_per_core = int(psutil.cpu_count() / psutil.cpu_count(logical=False))
     upload_process = Process(target=st.upload, kwargs={"threads": threads_per_core})
     download_process = Process(target=st.download, kwargs={"threads": threads_per_core})
     upload_process.start()
     download_process.start()
     if not shared.called_by_offline:
-        speaker.speak(text=f"Starting speed test {models.env.title}! I.S.P: {isp}. Location: {city} {state}", run=True)
+        speaker.speak(
+            text=f"Starting speed test {models.env.title}! I.S.P: {isp}. Location: {city} {state}",
+            run=True,
+        )
     upload_process.join()
     download_process.join()
     ping = round(st.results.ping)
     download = support.size_converter(byte_size=st.results.download)
     upload = support.size_converter(byte_size=st.results.upload)
-    support.write_screen(text=f"Ping: {ping}m/s\tDownload: {download}\tUpload: {upload}")
-    speaker.speak(text=f"Ping rate: {ping} milli seconds. "
-                       f"Download speed: {download} per second. "
-                       f"Upload speed: {upload} per second.")
+    support.write_screen(
+        text=f"Ping: {ping}m/s\tDownload: {download}\tUpload: {upload}"
+    )
+    speaker.speak(
+        text=f"Ping rate: {ping} milli seconds. "
+        f"Download speed: {download} per second. "
+        f"Upload speed: {upload} per second."
+    )
 
 
 def get_tunnel() -> HttpUrl:
     """Checks for any active public URL tunneled using Ngrok.
 
     Returns:
         HttpUrl:
         Ngrok public URL.
     """
     try:
         response = requests.get(url="http://localhost:4040/api/tunnels")
         if response.ok:
-            tunnels = response.json().get('tunnels', [])
-            protocols = list(filter(None, [tunnel.get('proto') for tunnel in tunnels]))
+            tunnels = response.json().get("tunnels", [])
+            protocols = list(filter(None, [tunnel.get("proto") for tunnel in tunnels]))
             for tunnel in tunnels:
-                if 'https' in protocols and tunnel.get('proto') != 'https':
+                if "https" in protocols and tunnel.get("proto") != "https":
                     continue
-                if hosted := tunnel.get('config', {}).get('addr'):
-                    if int(hosted.split(':')[-1]) == models.env.offline_port:
-                        return tunnel.get('public_url')
+                if hosted := tunnel.get("config", {}).get("addr"):
+                    if int(hosted.split(":")[-1]) == models.env.offline_port:
+                        return tunnel.get("public_url")
     except EgressErrors + (requests.JSONDecodeError,) as error:
         logger.error(error)
```

## jarvis/executors/ios_functions.py

```diff
@@ -1,46 +1,55 @@
 import difflib
-from typing import Union
 
 from pyicloud import PyiCloudService
-from pyicloud.exceptions import (PyiCloudAPIResponseException,
-                                 PyiCloudFailedLoginException)
+from pyicloud.exceptions import (
+    PyiCloudAPIResponseException,
+    PyiCloudFailedLoginException,
+)
 from pyicloud.services.findmyiphone import AppleDevice
 
 from jarvis.executors import location, word_match
 from jarvis.modules.audio import listener, speaker
 from jarvis.modules.conditions import keywords
 from jarvis.modules.exceptions import EgressErrors
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.utils import shared, support
 
 
-def device_selector(phrase: str) -> Union[AppleDevice, None]:
+def device_selector(phrase: str) -> AppleDevice | None:
     """Selects a device using the received input string.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
 
     Returns:
         AppleDevice:
         Returns the selected device from the class ``AppleDevice``
     """
     icloud_api = PyiCloudService(models.env.icloud_user, models.env.icloud_pass)
     devices = [device for device in icloud_api.devices]
-    devices_str = [{str(device).split(":")[0].strip(): str(device).split(":")[1].strip()} for device in devices]
+    devices_str = [
+        {str(device).split(":")[0].strip(): str(device).split(":")[1].strip()}
+        for device in devices
+    ]
     closest_match = [
-        (difflib.SequenceMatcher(a=phrase, b=key).ratio() + difflib.SequenceMatcher(a=phrase, b=val).ratio()) / 2
-        for device in devices_str for key, val in device.items()
+        (
+            difflib.SequenceMatcher(a=phrase, b=key).ratio()
+            + difflib.SequenceMatcher(a=phrase, b=val).ratio()
+        )
+        / 2
+        for device in devices_str
+        for key, val in device.items()
     ]
     index = closest_match.index(max(closest_match))
     return icloud_api.devices[index]
 
 
-def location_services(device: AppleDevice) -> Union[None, dict]:
+def location_services(device: AppleDevice) -> dict | None:
     """Gets the current location of an Apple device.
 
     Args:
         device: Particular Apple device that has to be located.
 
     Returns:
         dict:
@@ -66,34 +75,48 @@
     Args:
         target_device: Takes the target device as an argument.
     """
     try:
         device_location = location_services(device=target_device)
     except EgressErrors as error:
         logger.error(error)
-        speaker.speak(text="I was unable to connect to the internet. Please check your connection settings and retry.",
-                      run=True)
+        speaker.speak(
+            text="I was unable to connect to the internet. Please check your connection settings and retry.",
+            run=True,
+        )
         return
     lookup = str(target_device).split(":")[0].strip()
     if device_location:
         if shared.called_by_offline:
             post_code = device_location.get("postcode", "").split("-")[0]
         else:
-            post_code = '"'.join(list(device_location.get("postcode", "").split("-")[0]))
-        iphone_location = f"Your {lookup} is near {device_location.get('road')}, " \
-                          f"{device_location.get('city', device_location.get('residential'))} " \
-                          f"{device_location.get('state')}. Zipcode: {post_code}, {device_location.get('country')}"
+            post_code = '"'.join(
+                list(device_location.get("postcode", "").split("-")[0])
+            )
+        iphone_location = (
+            f"Your {lookup} is near {device_location.get('road')}, "
+            f"{device_location.get('city', device_location.get('residential'))} "
+            f"{device_location.get('state')}. Zipcode: {post_code}, {device_location.get('country')}"
+        )
         stat = target_device.status()
-        bat_percent = f"Battery: {round(stat['batteryLevel'] * 100)} %, " if stat["batteryLevel"] else ""
+        bat_percent = (
+            f"Battery: {round(stat['batteryLevel'] * 100)} %, "
+            if stat["batteryLevel"]
+            else ""
+        )
         device_model = stat["deviceDisplayName"]
         phone_name = stat["name"]
-        speaker.speak(text=f"{iphone_location}. Some more details. {bat_percent} Name: {phone_name}, "
-                           f"Model: {device_model}")
+        speaker.speak(
+            text=f"{iphone_location}. Some more details. {bat_percent} Name: {phone_name}, "
+            f"Model: {device_model}"
+        )
     else:
-        speaker.speak(text=f"I wasn't able to locate your {lookup} {models.env.title}! It is probably offline.")
+        speaker.speak(
+            text=f"I wasn't able to locate your {lookup} {models.env.title}! It is probably offline."
+        )
 
 
 def locate(phrase: str) -> None:
     """Locates an Apple device using icloud api for python.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
@@ -102,41 +125,61 @@
         logger.warning("ICloud username or password not found.")
         support.no_env_vars()
         return
     try:
         target_device = device_selector(phrase=phrase)
     except PyiCloudFailedLoginException as error:
         logger.error(error)
-        speaker.speak(text=f"I ran into an authentication error {models.env.title}! "
-                           "Please check the logs for more information.")
+        speaker.speak(
+            text=f"I ran into an authentication error {models.env.title}! "
+            "Please check the logs for more information."
+        )
         return
     except PyiCloudAPIResponseException as error:
         logger.error(error)
-        speaker.speak(text=f"I was unable to get the device information {models.env.title}!"
-                           "Please check the logs for more information.")
+        speaker.speak(
+            text=f"I was unable to get the device information {models.env.title}!"
+            "Please check the logs for more information."
+        )
         return
     if shared.called_by_offline:
         locate_device(target_device=target_device)
         return
     logger.info("Locating your %s", target_device)
     target_device.play_sound()
-    before_keyword, keyword, after_keyword = str(target_device).partition(":")  # partitions the hostname info
+    before_keyword, keyword, after_keyword = str(target_device).partition(
+        ":"
+    )  # partitions the hostname info
     if before_keyword == "Accessory":
-        after_keyword = after_keyword.replace(f"{models.env.name}s", "").replace(f"{models.env.name}'s", "").strip()
+        after_keyword = (
+            after_keyword.replace(f"{models.env.name}s", "")
+            .replace(f"{models.env.name}'s", "")
+            .strip()
+        )
         speaker.speak(text=f"I've located your {after_keyword} {models.env.title}!")
     else:
-        speaker.speak(text=f"Your {before_keyword} should be ringing now {models.env.title}!")
+        speaker.speak(
+            text=f"Your {before_keyword} should be ringing now {models.env.title}!"
+        )
     speaker.speak(text="Would you like to get the location details?", run=True)
     if not (phrase_location := listener.listen()):
         return
-    elif not word_match.word_match(phrase=phrase_location, match_list=keywords.keywords['ok']):
+    elif not word_match.word_match(
+        phrase=phrase_location, match_list=keywords.keywords["ok"]
+    ):
         return
 
     locate_device(target_device=target_device)
     if models.env.icloud_recovery:
-        speaker.speak(text="I can also enable lost mode. Would you like to do it?", run=True)
+        speaker.speak(
+            text="I can also enable lost mode. Would you like to do it?", run=True
+        )
         phrase_lost = listener.listen()
-        if word_match.word_match(phrase=phrase_lost, match_list=keywords.keywords['ok']):
-            target_device.lost_device(number=models.env.icloud_recovery, text="Return my phone immediately.")
+        if word_match.word_match(
+            phrase=phrase_lost, match_list=keywords.keywords["ok"]
+        ):
+            target_device.lost_device(
+                number=models.env.icloud_recovery, text="Return my phone immediately."
+            )
             speaker.speak(text="I've enabled lost mode on your phone.")
         else:
             speaker.speak(text=f"No action taken {models.env.title}!")
```

## jarvis/executors/lights.py

```diff
@@ -64,43 +64,55 @@
         thread_except = {}
         for future in as_completed(futures):
             if future.exception():
                 light_location, ip = futures[future]
                 if light_location not in thread_except:
                     thread_except[light_location] = []
                 thread_except[light_location].append(ip)
-                logger.error("Thread processing for '%s' at IP '%s' received an exception: %s",
-                             light_location, ip, future.exception())
+                logger.error(
+                    "Thread processing for '%s' at IP '%s' received an exception: %s",
+                    light_location,
+                    ip,
+                    future.exception(),
+                )
         return thread_except
 
     def avail_check(self, function_to_call: Callable) -> None:
         """Speaks an error message if any of the lights aren't reachable.
 
         Args:
             function_to_call: Takes the function/method that has to be called as an argument.
         """
-        status = ThreadPool(processes=1).apply_async(func=self.thread_worker, args=(function_to_call,))
-        speaker.speak(run=True)  # Speak the initial response when the work is happening behind the scenes
+        status = ThreadPool(processes=1).apply_async(
+            func=self.thread_worker, args=(function_to_call,)
+        )
+        speaker.speak(
+            run=True
+        )  # Speak the initial response when the work is happening behind the scenes
         try:
             failed = status.get(5)
         except ThreadTimeout as error:
             logger.error(error)
             return
         if failed:
             failed_msg = []
             for light_location, ip_list in failed.items():
                 if failed_msg:
                     msg = f'{support.pluralize(count=len(ip_list), word="light", to_words=True)} '
                 else:
                     msg = f'{support.pluralize(count=len(ip_list), word="light", to_words=True, cap_word=True)} '
-                failed_msg.append(msg + f'from {light_location}')
-            if len(failed_msg) == 1 and failed_msg[0].startswith('One'):  # Failed only on a single lamp
+                failed_msg.append(msg + f"from {light_location}")
+            # Failed only on a single lamp
+            if len(failed_msg) == 1 and failed_msg[0].startswith("One"):
                 response = "".join(failed_msg) + " isn't available right now!"
             else:
-                response = util.comma_separator(list_=failed_msg) + " aren't available right now!"
+                response = (
+                    util.comma_separator(list_=failed_msg)
+                    + " aren't available right now!"
+                )
             logger.error(response)
             speaker.speak(text=f"I'm sorry {models.env.title}! {response}")
 
 
 def lights(phrase: str) -> None:
     """Controller for smart lights.
 
@@ -108,50 +120,66 @@
         phrase: Takes the phrase spoken as an argument.
     """
     if not internet.vpn_checker():
         return
 
     smart_devices = files.get_smart_devices()
     if smart_devices is False:
-        speaker.speak(text=f"I'm sorry {models.env.title}! I wasn't able to read the source information.")
+        speaker.speak(
+            text=f"I'm sorry {models.env.title}! I wasn't able to read the source information."
+        )
         return
     if smart_devices and (lights_map := get_lights(data=smart_devices)):
         logger.debug(lights_map)
     else:
         logger.warning("%s is empty for lights.", models.fileio.smart_devices)
         support.no_env_vars()
         return
 
     phrase = phrase.lower()
 
-    if 'all' in phrase.split():
+    if "all" in phrase.split():
         light_location = ""
         if "except" in phrase or "exclud" in phrase:
-            remove = util.matrix_to_flat_list(input_=squire.word_map.values()) + ['lights', 'light']
+            remove = util.matrix_to_flat_list(input_=squire.word_map.values()) + [
+                "lights",
+                "light",
+            ]
             phrase_location = phrase
             for word in remove:
-                phrase_location = phrase_location.replace(word, '')
-            exclusion = util.get_closest_match(text=phrase_location.strip(), match_list=list(lights_map.keys()))
+                phrase_location = phrase_location.replace(word, "")
+            exclusion = util.get_closest_match(
+                text=phrase_location.strip(), match_list=list(lights_map.keys())
+            )
             host_names: List[str] = util.remove_duplicates(
-                input_=util.matrix_to_flat_list([lights_map[light] for light in lights_map if light != exclusion])
+                input_=util.matrix_to_flat_list(
+                    [lights_map[light] for light in lights_map if light != exclusion]
+                )
             )
             host_names_len = len(host_names)
             logger.debug("%d lights' excluding %s", host_names_len, exclusion)
         else:
             host_names: List[str] = util.remove_duplicates(
-                input_=util.matrix_to_flat_list(input_=[v for k, v in lights_map.items() if v])
+                input_=util.matrix_to_flat_list(
+                    input_=[v for k, v in lights_map.items() if v]
+                )
             )
             host_names_len = len(host_names)
             logger.debug("All lights: %d", host_names_len)
     else:
-        remove = util.matrix_to_flat_list(input_=squire.word_map.values()) + ['lights', 'light']
+        remove = util.matrix_to_flat_list(input_=squire.word_map.values()) + [
+            "lights",
+            "light",
+        ]
         phrase_location = phrase
         for word in remove:
-            phrase_location = phrase_location.replace(word, '')
-        light_location = util.get_closest_match(text=phrase_location.strip(), match_list=list(lights_map.keys()))
+            phrase_location = phrase_location.replace(word, "")
+        light_location = util.get_closest_match(
+            text=phrase_location.strip(), match_list=list(lights_map.keys())
+        )
         host_names: List[str] = lights_map[light_location]
         host_names_len = len(host_names)
         logger.info("%d lights' location: %s", host_names_len, light_location)
     host_names = util.remove_none(input_=host_names)
 
     # extract IP addresses for hostnames that are required
     for _light_location, _light_hostname in lights_map.items():
@@ -162,65 +190,93 @@
                     logger.debug("Resolved IP %s for hostname %s", resolved, hostname)
                 else:
                     logger.debug("Unable to resolve IP for %s", hostname)
                     resolved = ["0.0.0.0"]  # Add placeholder IP to respond accordingly
                 lights_map[_light_location].extend(resolved)
     executor = ThreadExecutor(mapping=lights_map)
 
-    plural = 'lights' if host_names_len > 1 else 'light'
-    if word_match.word_match(phrase, squire.word_map['turn_on']):
-        tone = 'white' if 'white' in phrase else 'cool'
-        if 'turn on' in phrase:
-            speaker.speak(text=f'{random.choice(conversation.acknowledgement)}! Turning on {host_names_len} {plural}')
+    plural = "lights" if host_names_len > 1 else "light"
+    if word_match.word_match(phrase, squire.word_map["turn_on"]):
+        tone = "white" if "white" in phrase else "cool"
+        if "turn on" in phrase:
+            speaker.speak(
+                text=f"{random.choice(conversation.acknowledgement)}! Turning on {host_names_len} {plural}"
+            )
         else:
             speaker.speak(
-                text=f'{random.choice(conversation.acknowledgement)}! Setting {host_names_len} {plural} to {tone}!'
+                text=f"{random.choice(conversation.acknowledgement)}! Setting {host_names_len} {plural} to {tone}!"
             )
         executor.avail_check(function_to_call=squire.cool)
-    elif word_match.word_match(phrase, squire.word_map['turn_off']):
-        speaker.speak(text=f'{random.choice(conversation.acknowledgement)}! Turning off {host_names_len} {plural}')
+    elif word_match.word_match(phrase, squire.word_map["turn_off"]):
+        speaker.speak(
+            text=f"{random.choice(conversation.acknowledgement)}! Turning off {host_names_len} {plural}"
+        )
         if state := squire.check_status():
             support.stop_process(pid=int(state[0]))
-        if word_match.word_match(phrase, squire.word_map['reset']):
+        if word_match.word_match(phrase, squire.word_map["reset"]):
             Thread(target=executor.thread_worker, args=[squire.cool]).run()
         executor.avail_check(function_to_call=squire.turn_off)
-    elif word_match.word_match(phrase, squire.word_map['party_mode']):
-        host_ip = util.remove_duplicates(input_=util.matrix_to_flat_list(input_=list(lights_map.values())))
+    elif word_match.word_match(phrase, squire.word_map["party_mode"]):
+        host_ip = util.remove_duplicates(
+            input_=util.matrix_to_flat_list(input_=list(lights_map.values()))
+        )
         if squire.party_mode(host=host_ip, phrase=phrase):
             Thread(target=executor.thread_worker, args=[squire.cool]).run()
             Thread(target=executor.thread_worker, args=[squire.turn_off]).start()
-    elif word_match.word_match(phrase, squire.word_map['warm']):
-        if 'yellow' in phrase:
-            speaker.speak(text=f'{random.choice(conversation.acknowledgement)}! '
-                               f'Setting {host_names_len} {plural} to yellow!')
+    elif word_match.word_match(phrase, squire.word_map["warm"]):
+        if "yellow" in phrase:
+            speaker.speak(
+                text=f"{random.choice(conversation.acknowledgement)}! "
+                f"Setting {host_names_len} {plural} to yellow!"
+            )
         else:
-            speaker.speak(text=f'Sure {models.env.title}! Setting {host_names_len} {plural} to warm!')
+            speaker.speak(
+                text=f"Sure {models.env.title}! Setting {host_names_len} {plural} to warm!"
+            )
         executor.avail_check(function_to_call=squire.warm)
-    elif color := word_match.word_match(phrase=phrase, match_list=list(preset_values.PRESET_VALUES.keys())):
-        speaker.speak(text=f"{random.choice(conversation.acknowledgement)}! "
-                           f"I've changed {host_names_len} {plural} to {color}!")
-        host_ip = util.remove_duplicates(input_=util.matrix_to_flat_list(input_=list(lights_map.values())))
+    elif color := word_match.word_match(
+        phrase=phrase, match_list=list(preset_values.PRESET_VALUES.keys())
+    ):
+        speaker.speak(
+            text=f"{random.choice(conversation.acknowledgement)}! "
+            f"I've changed {host_names_len} {plural} to {color}!"
+        )
+        host_ip = util.remove_duplicates(
+            input_=util.matrix_to_flat_list(input_=list(lights_map.values()))
+        )
         for light_ip in host_ip:
-            squire.preset(host=light_ip, speed=50,
-                          color=[preset_values.PRESET_VALUES[_type] for _type in
-                                 list(preset_values.PRESET_VALUES.keys()) if _type in phrase][0])
-    elif word_match.word_match(phrase, squire.word_map['set']):
-        if 'bright' in phrase:
+            squire.preset(
+                host=light_ip,
+                speed=50,
+                color=[
+                    preset_values.PRESET_VALUES[_type]
+                    for _type in list(preset_values.PRESET_VALUES.keys())
+                    if _type in phrase
+                ][0],
+            )
+    elif word_match.word_match(phrase, squire.word_map["set"]):
+        if "bright" in phrase:
             level = 100
-        elif 'dim' in phrase:
+        elif "dim" in phrase:
             level = 50
         else:
             level = util.extract_nos(input_=phrase, method=int)
             if level is None:
                 level = 100
-        speaker.speak(text=f"{random.choice(conversation.acknowledgement)}! "
-                           f"I've set {host_names_len} {plural} to {level}%!")
+        speaker.speak(
+            text=f"{random.choice(conversation.acknowledgement)}! "
+            f"I've set {host_names_len} {plural} to {level}%!"
+        )
         level = round((255 * level) / 100)
         Thread(target=executor.thread_worker, args=[squire.turn_off]).run()
         time.sleep(1)
-        host_ip = util.remove_duplicates(input_=util.matrix_to_flat_list(input_=list(lights_map.values())))
+        host_ip = util.remove_duplicates(
+            input_=util.matrix_to_flat_list(input_=list(lights_map.values()))
+        )
         for light_ip in host_ip:
             squire.lumen(host=light_ip, rgb=level)
     else:
-        speaker.speak(text=f"I didn't quite get that {models.env.title}! What do you want me to do to your "
-                           f"{light_location} {plural}?")
-        Thread(target=support.unrecognized_dumper, args=[{'LIGHTS': phrase}]).start()
+        speaker.speak(
+            text=f"I didn't quite get that {models.env.title}! What do you want me to do to your "
+            f"{light_location} {plural}?"
+        )
+        Thread(target=support.unrecognized_dumper, args=[{"LIGHTS": phrase}]).start()
```

## jarvis/executors/lights_squire.py

```diff
@@ -1,26 +1,26 @@
 import random
 from concurrent.futures import ThreadPoolExecutor
 from multiprocessing import Process
-from typing import List, Union
+from typing import List
 
 from jarvis.modules.audio import speaker
 from jarvis.modules.database import database
 from jarvis.modules.lights import preset_values, smart_lights
 from jarvis.modules.models import models
 from jarvis.modules.utils import support
 
 db = database.Database(database=models.fileio.base_db)
 word_map = {
-    'turn_on': ['turn on', 'cool', 'white'],
-    'turn_off': ['turn off'],
-    'party_mode': ['party mode'],
-    'reset': ['reset'],
-    'warm': ['warm', 'yellow'],
-    'set': ['set', 'percentage', 'percent', '%', 'dim', 'bright']
+    "turn_on": ["turn on", "cool", "white"],
+    "turn_off": ["turn off"],
+    "party_mode": ["party mode"],
+    "reset": ["reset"],
+    "warm": ["warm", "yellow"],
+    "set": ["set", "percentage", "percent", "%", "dim", "bright"],
 }
 
 
 def turn_off(host: str) -> None:
     """Turns off the device.
 
     Args:
@@ -31,63 +31,68 @@
 
 def warm(host: str) -> None:
     """Sets lights to warm/yellow.
 
     Args:
         host: Takes target device's IP address as an argument.
     """
-    smart_lights.MagicHomeApi(device_ip=host, device_type=1).update_device(r=0, g=0, b=0, warm_white=255)
+    smart_lights.MagicHomeApi(device_ip=host, device_type=1).update_device(
+        r=0, g=0, b=0, warm_white=255
+    )
 
 
 def cool(host: str) -> None:
     """Sets lights to cool/white.
 
     Args:
         host: Takes target device's IP address as an argument.
     """
-    smart_lights.MagicHomeApi(device_ip=host,
-                              device_type=2).update_device(r=255, g=255, b=255, warm_white=255, cool_white=255)
+    smart_lights.MagicHomeApi(device_ip=host, device_type=2).update_device(
+        r=255, g=255, b=255, warm_white=255, cool_white=255
+    )
 
 
 def lumen(host: str, rgb: int = 255) -> None:
     """Sets lights to custom brightness.
 
     Args:
         host: Takes target device's IP address as an argument.
         rgb: Red, Green andBlue values to alter the brightness.
     """
-    args = {'r': 255, 'g': 255, 'b': 255, 'warm_white': rgb}
+    args = {"r": 255, "g": 255, "b": 255, "warm_white": rgb}
     smart_lights.MagicHomeApi(device_ip=host, device_type=1).update_device(**args)
 
 
 def preset(host: str, color: int = None, speed: int = 100) -> None:
     """Changes light colors to preset values.
 
     Args:
         host: Takes target device's IP address as an argument.
         color: Preset value extracted from list of color codes. Defaults to a random color code.
         speed: Speed of color change. Defaults to 100.
     """
     smart_lights.MagicHomeApi(device_ip=host, device_type=2).send_preset_function(
-        preset_number=color or random.choice(list(preset_values.PRESET_VALUES.values())), speed=speed
+        preset_number=color
+        or random.choice(list(preset_values.PRESET_VALUES.values())),
+        speed=speed,
     )
 
 
 def runner(host: List[str]) -> None:
     """Runs a never ending loop setting random light IP addresses to random color preset values.
 
     Args:
         host: Takes list of lights' IP addresses as argument.
     """
     while True:
         with ThreadPoolExecutor(max_workers=len(host)) as executor:
             executor.map(preset, host)
 
 
-def check_status() -> Union[str, int, None]:
+def check_status() -> str | int | None:
     """Retrieve process ID from the ``party`` table.
 
     Returns:
         Process.pid:
         Process ID if party mode is enabled.
     """
     with db.connection:
@@ -110,15 +115,17 @@
     Args:
         process: Process for which the PID has to be stored in database.
     """
     with db.connection:
         cursor = db.connection.cursor()
         cursor.execute("UPDATE children SET party=null")
         cursor.execute("INSERT or REPLACE INTO party (pid) VALUES (?);", (process.pid,))
-        cursor.execute("INSERT or REPLACE INTO children (party) VALUES (?);", (process.pid,))
+        cursor.execute(
+            "INSERT or REPLACE INTO children (party) VALUES (?);", (process.pid,)
+        )
         db.connection.commit()
 
 
 def party_mode(host: List[str], phrase: str) -> bool:
     """Handles party mode by altering colors in given light hostnames with random color codes.
 
     Args:
@@ -126,27 +133,35 @@
         phrase: Takes the phrase spoken as an argument.
 
     Returns:
         bool:
         True if party mode has to be disabled.
     """
     state = check_status()
-    if 'enable' in phrase:
+    if "enable" in phrase:
         if state:
-            speaker.speak(text=f'Party mode has already been enabled {models.env.title}!')
+            speaker.speak(
+                text=f"Party mode has already been enabled {models.env.title}!"
+            )
         else:
-            speaker.speak(text=f'Enabling party mode! Enjoy yourself {models.env.title}!')
+            speaker.speak(
+                text=f"Enabling party mode! Enjoy yourself {models.env.title}!"
+            )
             process = Process(target=runner, args=(host,))
             process.start()
             update_status(process=process)
-    elif 'disable' in phrase:
+    elif "disable" in phrase:
         if state:
-            speaker.speak(text=f'Party mode has been disabled {models.env.title}! Hope you enjoyed it.')
+            speaker.speak(
+                text=f"Party mode has been disabled {models.env.title}! Hope you enjoyed it."
+            )
             support.stop_process(pid=int(state[0]))
             remove_status()
             return True
         else:
-            speaker.speak(text=f'Party mode was never enabled {models.env.title}!')
+            speaker.speak(text=f"Party mode was never enabled {models.env.title}!")
     else:
-        state_ = 'enabled' if state else 'disabled'
-        speaker.speak(text=f"Party mode is currently {state_} {models.env.title}! "
-                           "You can ask me to enable or disable party mode.")
+        state_ = "enabled" if state else "disabled"
+        speaker.speak(
+            text=f"Party mode is currently {state_} {models.env.title}! "
+            "You can ask me to enable or disable party mode."
+        )
```

## jarvis/executors/listener_controls.py

```diff
@@ -61,12 +61,14 @@
     """
     logger.info("Current listener status: '%s'", get_listener_state())
     logger.info("Updating listener status to %s", state)
     with db.connection:
         cursor = db.connection.cursor()
         cursor.execute("DELETE FROM listener")
         if state:
-            cursor.execute("INSERT or REPLACE INTO listener (state) VALUES (?);", (state,))
+            cursor.execute(
+                "INSERT or REPLACE INTO listener (state) VALUES (?);", (state,)
+            )
             cursor.execute("UPDATE listener SET state=(?)", (state,))
         else:
             cursor.execute("UPDATE listener SET state=null")
         db.connection.commit()
```

## jarvis/executors/location.py

```diff
@@ -1,14 +1,14 @@
 import math
 import os
 import re
 import ssl
 import time
 import webbrowser
-from typing import Dict, Tuple, Union
+from typing import Dict, Tuple
 
 import certifi
 import yaml
 from geopy.distance import geodesic
 from geopy.exc import GeocoderUnavailable, GeopyError
 from geopy.geocoders import Nominatim, options
 from speedtest import ConfigRetrievalError, Speedtest
@@ -21,30 +21,32 @@
 from jarvis.modules.utils import shared, support
 
 # stores necessary values for geolocation to receive the latitude, longitude and address
 options.default_ssl_context = ssl.create_default_context(cafile=certifi.where())
 geo_locator = Nominatim(scheme="http", user_agent="test/1", timeout=3)
 
 
-def get_coordinates_from_ip() -> Union[Tuple[float, float], Tuple[float, ...]]:
+def get_coordinates_from_ip() -> Tuple[float, float] | Tuple[float, ...]:
     """Uses public IP to retrieve latitude and longitude. If fails, uses ``Speedtest`` module.
 
     Returns:
         tuple:
         Returns latitude and longitude as a tuple.
     """
-    if (info := internet.public_ip_info()) and info.get('lcc'):
-        return tuple(map(float, info.get('loc').split(',')))
+    if (info := internet.public_ip_info()) and info.get("lcc"):
+        return tuple(map(float, info.get("loc").split(",")))
     try:
         if results := Speedtest().results:
             return float(results.client["lat"]), float(results.client["lon"])
     except ConfigRetrievalError as error:
         logger.error(error)
-        support.write_screen(text="Failed to get location based on IP. Hand modify it at "
-                                  f"'{os.path.abspath(models.fileio.location)}'")
+        support.write_screen(
+            text="Failed to get location based on IP. Hand modify it at "
+            f"'{os.path.abspath(models.fileio.location)}'"
+        )
         time.sleep(5)
     return 37.230881, -93.3710393  # Default to SGF latitude and longitude
 
 
 def get_location_from_coordinates(coordinates: tuple) -> Dict[str, str]:
     """Uses the latitude and longitude information to get the address information.
 
@@ -63,51 +65,71 @@
         return {}
 
 
 def write_current_location() -> None:
     """Extracts location information from public IP address and writes it to a yaml file."""
     data = files.get_location()
     address = data.get("address")
-    if address and data.get("reserved") and data.get("latitude") and data.get("longitude") and \
-            address.get("city", address.get("hamlet")) and address.get("country") and \
-            address.get("state", address.get("county")):
+    if (
+        address
+        and data.get("reserved")
+        and data.get("latitude")
+        and data.get("longitude")
+        and address.get("city", address.get("hamlet"))
+        and address.get("country")
+        and address.get("state", address.get("county"))
+    ):
         logger.info("%s is reserved.", models.fileio.location)
         logger.warning("Automatic location detection has been disabled!")
         return
     current_lat, current_lon = get_coordinates_from_ip()
-    location_info = get_location_from_coordinates(coordinates=(current_lat, current_lon))
+    location_info = get_location_from_coordinates(
+        coordinates=(current_lat, current_lon)
+    )
     current_tz = TimezoneFinder().timezone_at(lat=current_lat, lng=current_lon)
     logger.info("Writing location info in %s", models.fileio.location)
-    with open(models.fileio.location, 'w') as location_writer:
-        yaml.dump(data={"timezone": current_tz, "latitude": current_lat, "longitude": current_lon,
-                        "address": location_info},
-                  stream=location_writer, default_flow_style=False)
+    with open(models.fileio.location, "w") as location_writer:
+        yaml.dump(
+            data={
+                "timezone": current_tz,
+                "latitude": current_lat,
+                "longitude": current_lon,
+                "address": location_info,
+            },
+            stream=location_writer,
+            default_flow_style=False,
+        )
 
 
 def location(*args) -> None:
     """Gets the user's current location."""
     current_location = files.get_location()
-    speaker.speak(text=f"I'm at {current_location.get('address', {}).get('road', '')} - "
-                       f"{current_location.get('address', {}).get('city', '')} "
-                       f"{current_location.get('address', {}).get('state', '')} - "
-                       f"in {current_location.get('address', {}).get('country', '')}")
+    speaker.speak(
+        text=f"I'm at {current_location.get('address', {}).get('road', '')} - "
+        f"{current_location.get('address', {}).get('city', '')} "
+        f"{current_location.get('address', {}).get('state', '')} - "
+        f"in {current_location.get('address', {}).get('country', '')}"
+    )
 
 
 def distance(phrase) -> None:
     """Extracts the start and end location to get the distance for it.
 
     Args:
         phrase:Takes the phrase spoken as an argument.
     """
     check = phrase.split()  # str to list
     places = []
     for word in check:
-        if word[0].isupper() or "." in word:  # looks for words that start with uppercase
+        # looks for words that start with uppercase
+        if word[0].isupper() or "." in word:
             try:
-                next_word = check[check.index(word) + 1]  # looks if words after an uppercase word is also one
+                next_word = check[
+                    check.index(word) + 1
+                ]  # looks if words after an uppercase word is also one
                 if next_word[0].isupper():
                     places.append(f"{word + ' ' + check[check.index(word) + 1]}")
                 else:
                     if word not in " ".join(places):
                         places.append(word)
             except IndexError:  # catches exception on lowercase word after an upper case word
                 if word not in " ".join(places):
@@ -138,17 +160,23 @@
     if not destination:
         speaker.speak(text="Destination please?")
         if shared.called_by_offline:
             return
         speaker.speak(run=True)
         if destination := listener.listen():
             if len(destination.split()) > 2:
-                speaker.speak(text=f"I asked for a destination {models.env.title}, not a sentence. Try again.")
+                speaker.speak(
+                    text=f"I asked for a destination {models.env.title}, not a sentence. Try again."
+                )
                 distance_controller()
-            if "exit" in destination or "quit" in destination or "Xzibit" in destination:
+            if (
+                "exit" in destination
+                or "quit" in destination
+                or "Xzibit" in destination
+            ):
                 return
 
     if origin:
         # if starting_point is received gets latitude and longitude of that location
         desired_start = geo_locator.geocode(origin)
         start = desired_start.latitude, desired_start.longitude
         start_check = None
@@ -157,42 +185,54 @@
         start = (current_location["latitude"], current_location["longitude"])
         start_check = "My Location"
     desired_location = geo_locator.geocode(destination)
     if desired_location:
         end = desired_location.latitude, desired_location.longitude
     else:
         end = destination[0], destination[1]
-    if not all(isinstance(v, float) for v in start) or not all(isinstance(v, float) for v in end):
+    if not all(isinstance(v, float) for v in start) or not all(
+        isinstance(v, float) for v in end
+    ):
         speaker.speak(text=f"I don't think {destination} exists {models.env.title}!")
         return
     if models.env.distance_unit == models.DistanceUnits.MILES:
-        dist = round(geodesic(start, end).miles)  # calculates miles from starting point to destination
+        dist = round(
+            geodesic(start, end).miles
+        )  # calculates miles from starting point to destination
     else:
         dist = round(geodesic(start, end).kilometers)
     if shared.called["directions"]:
         # calculates drive time using d = s/t and distance calculation is only if location is same country
         shared.called["directions"] = False
         avg_speed = 60
         t_taken = dist / avg_speed
         if dist < avg_speed:
             drive_time = int(t_taken * 60)
-            speaker.speak(text=f"It might take you about {drive_time} minutes to get there {models.env.title}!")
+            speaker.speak(
+                text=f"It might take you about {drive_time} minutes to get there {models.env.title}!"
+            )
         else:
             drive_time = math.ceil(t_taken)
             if drive_time == 1:
-                speaker.speak(text=f"It might take you about {drive_time} hour to get there {models.env.title}!")
+                speaker.speak(
+                    text=f"It might take you about {drive_time} hour to get there {models.env.title}!"
+                )
             else:
-                speaker.speak(text=f"It might take you about {drive_time} hours to get there {models.env.title}!")
+                speaker.speak(
+                    text=f"It might take you about {drive_time} hours to get there {models.env.title}!"
+                )
     elif start_check:
         text = f"{models.env.title}! You're {dist} {models.env.distance_unit.value} away from {destination}. "
         if not shared.called["locate_places"]:
             text += f"You may also ask where is {destination}"
         speaker.speak(text=text)
     else:
-        speaker.speak(text=f"{origin} is {dist} {models.env.distance_unit.value} away from {destination}.")
+        speaker.speak(
+            text=f"{origin} is {dist} {models.env.distance_unit.value} away from {destination}."
+        )
     return
 
 
 def locate_places(phrase: str = None) -> None:
     """Gets location details of a place.
 
     Args:
@@ -202,19 +242,25 @@
     # if no words found starting with an upper case letter, fetches word after the keyword 'is' eg: where is Chicago
     if not place:
         keyword = "is"
         before_keyword, keyword, after_keyword = phrase.partition(keyword)
         place = after_keyword.replace(" in", "").strip()
     if not place:
         if shared.called_by_offline:
-            speaker.speak(text=f"I need a location to get you the details {models.env.title}!")
+            speaker.speak(
+                text=f"I need a location to get you the details {models.env.title}!"
+            )
             return
         speaker.speak(text="Tell me the name of a place!", run=True)
-        if not (converted := listener.listen()) or "exit" in converted or "quit" in converted \
-                or "Xzibit" in converted:
+        if (
+            not (converted := listener.listen())
+            or "exit" in converted
+            or "quit" in converted
+            or "Xzibit" in converted
+        ):
             return
         place = support.get_capitalized(phrase=converted)
         if not place:
             keyword = "is"
             before_keyword, keyword, after_keyword = converted.partition(keyword)
             place = after_keyword.replace(" in", "").strip()
 
@@ -230,28 +276,34 @@
         city = address["city"] if "city" in address.keys() else None
         state = address["state"] if "state" in address.keys() else None
         country = address["country"] if "country" in address else None
         if place in country:
             speaker.speak(text=f"{place} is a country")
         elif place in (city or county):
             speaker.speak(
-                text=f"{place} is in {state}" if country == current_location["address"]["country"] else
-                f"{place} is in {state} in {country}")
+                text=f"{place} is in {state}"
+                if country == current_location["address"]["country"]
+                else f"{place} is in {state} in {country}"
+            )
         elif place in state:
             speaker.speak(text=f"{place} is a state in {country}")
         elif (city or county) and state and country:
             if country == current_location["address"]["country"]:
                 speaker.speak(text=f"{place} is in {city or county}, {state}")
             else:
-                speaker.speak(text=f"{place} is in {city or county}, {state}, in {country}")
+                speaker.speak(
+                    text=f"{place} is in {city or county}, {state}, in {country}"
+                )
         if shared.called_by_offline:
             return
         shared.called["locate_places"] = True
     except (TypeError, AttributeError):
-        speaker.speak(text=f"{place} is not a real place on Earth {models.env.title}! Try again.")
+        speaker.speak(
+            text=f"{place} is not a real place on Earth {models.env.title}! Try again."
+        )
         if shared.called_by_offline:
             return
         locate_places(phrase=None)
     distance_controller(origin=None, destination=place)
 
 
 def directions(phrase: str = None, no_repeat: bool = False) -> None:
@@ -267,15 +319,17 @@
     if not place:
         speaker.speak(text="You might want to give a location.", run=True)
         if converted := listener.listen():
             place = support.get_capitalized(phrase=converted, ignore=("I ",))
             if not place:
                 if no_repeat:
                     return
-                speaker.speak(text=f"I can't take you to anywhere without a location {models.env.title}!")
+                speaker.speak(
+                    text=f"I can't take you to anywhere without a location {models.env.title}!"
+                )
                 directions(phrase=None, no_repeat=True)
             if "exit" in place or "quit" in place or "Xzibit" in place:
                 return
     destination_location = geo_locator.geocode(place)
     if not destination_location:
         return
     try:
@@ -283,15 +337,21 @@
     except AttributeError:
         return
     located = geo_locator.reverse(coordinates, language="en")
     address = located.raw["address"]
     end_country = address["country"] if "country" in address else None
     end = f"{located.latitude},{located.longitude}"
     current_location = files.get_location()
-    if not all((current_location.get('address'), current_location.get('latitude'), current_location.get('longitude'))):
+    if not all(
+        (
+            current_location.get("address"),
+            current_location.get("latitude"),
+            current_location.get("longitude"),
+        )
+    ):
         return
     start_country = current_location["address"]["country"]
     start = current_location["latitude"], current_location["longitude"]
     maps_url = f"https://www.google.com/maps/dir/{start}/{end}/"
     webbrowser.open(maps_url)
     speaker.speak(text=f"Directions on your screen {models.env.title}!")
     if start_country and end_country:
```

## jarvis/executors/method.py

```diff
@@ -7,15 +7,16 @@
 def executor(func: Callable, phrase: str) -> None:
     """Executes a function.
 
     Args:
         func: Function to be called.
         phrase: Takes the phrase spoken as an argument.
     """
-    if shared.called_by_bg_tasks:  # disable logging for background tasks, as they are meant run very frequently
+    # disable logging for background tasks, as they are meant run very frequently
+    if shared.called_by_bg_tasks:
         logger.propagate = False
         logger.disabled = True
         func(phrase)
         logger.propagate = True
         logger.disabled = False
     else:
         func(phrase)
```

## jarvis/executors/offline.py

```diff
@@ -1,23 +1,35 @@
 import os
 import time
 import traceback
 from datetime import datetime
 from multiprocessing import Process, Queue
 from threading import Thread, Timer
-from typing import AnyStr, List, Union
+from typing import AnyStr, List
 
 import requests
 from deepdiff import DeepDiff
 from pydantic import HttpUrl
 
-from jarvis.executors import (alarm, automation, background_task, conditions,
-                              connection, controls, crontab, files, internet,
-                              listener_controls, others, remind,
-                              weather_monitor, word_match)
+from jarvis.executors import (
+    alarm,
+    automation,
+    background_task,
+    conditions,
+    connection,
+    controls,
+    crontab,
+    files,
+    internet,
+    listener_controls,
+    others,
+    remind,
+    weather_monitor,
+    word_match,
+)
 from jarvis.modules.auth_bearer import BearerAuth
 from jarvis.modules.conditions import keywords
 from jarvis.modules.database import database
 from jarvis.modules.exceptions import EgressErrors
 from jarvis.modules.logger import logger, multiprocessing_logger
 from jarvis.modules.meetings import events, ics_meetings
 from jarvis.modules.models import classes, models
@@ -33,40 +45,48 @@
     except Exception as error:
         logger.critical("ATTENTION: %s", error.__str__())
         controls.restart_control(quiet=True)
 
 
 def background_task_runner() -> None:
     """Trigger for background tasks, cron jobs, automation, alarms, reminders, events and meetings sync."""
-    multiprocessing_logger(filename=os.path.join('logs', 'background_tasks_%d-%m-%Y.log'))
+    multiprocessing_logger(
+        filename=os.path.join("logs", "background_tasks_%d-%m-%Y.log")
+    )
     # Since env vars are loaded only during startup, validate weather alert only then
     automation.validate_weather_alert()
     if all((models.env.wifi_ssid, models.env.wifi_password)):
         wifi_checker = classes.WiFiConnection()
     else:
         wifi_checker = None
     tasks: List[classes.BackgroundTask] = list(background_task.validate_tasks())
     cron_jobs: List[crontab.expression.CronExpression] = list(crontab.validate_jobs())
     meeting_muter = []
     start_events = start_meetings = start_cron = start_wifi = time.time()
-    task_dict = {i: time.time() for i in range(len(tasks))}  # Creates a start time for each task
+    task_dict = {
+        i: time.time() for i in range(len(tasks))
+    }  # Creates a start time for each task
     dry_run = True
     smart_listener = Queue()
     while True:
         now = datetime.now()
         # Trigger background tasks
         for i, task in enumerate(tasks):
-            if task_dict[i] + task.seconds <= time.time() or dry_run:  # Checks a particular tasks' elapsed time
+            # Checks a particular tasks' elapsed time
+            if task_dict[i] + task.seconds <= time.time() or dry_run:
                 task_dict[i] = time.time()  # Updates that particular tasks' start time
                 if now.hour in task.ignore_hours:
                     logger.debug("'%s' skipped honoring ignore hours", task)
                 else:
                     logger.debug("Executing: '%s'", task.task)
                     try:
-                        response = offline_communicator(task.task, True) or "No response for background task"
+                        response = (
+                            offline_communicator(task.task, True)
+                            or "No response for background task"
+                        )
                         logger.debug("Response: '%s'", response)
                     except Exception as error:
                         logger.error(error)
                         logger.warning("Removing %s from background tasks.", task)
                         background_task.remove_corrupted(task=task)
 
         # Trigger cron jobs once during start up (regardless of schedule) and follow schedule after that
@@ -75,177 +95,232 @@
             for job in cron_jobs:
                 if job.check_trigger():
                     logger.debug("Executing cron job: '%s'", job.comment)
                     cron_process = Process(target=crontab.executor, args=(job.comment,))
                     cron_process.start()
                     with db.connection:
                         cursor = db.connection.cursor()
-                        cursor.execute("INSERT or REPLACE INTO children (crontab) VALUES (?);", (cron_process.pid,))
+                        cursor.execute(
+                            "INSERT or REPLACE INTO children (crontab) VALUES (?);",
+                            (cron_process.pid,),
+                        )
                         db.connection.commit()
 
         # Trigger wifi checker
-        if (wifi_checker and start_wifi + models.env.connection_retry <= time.time()) or dry_run:
+        if wifi_checker and (
+            start_wifi + models.env.connection_retry <= time.time() or dry_run
+        ):
             start_wifi = time.time()
             logger.debug("Initiating WiFi connection checker")
             wifi_checker = connection.wifi(wifi_checker)
 
         # Trigger automation
         if exec_task := automation.auto_helper():
             # Check and trigger weather alert monitoring system
             if "weather" in exec_task.lower():
                 # run as daemon and not store in children table as this won't take long
                 logger.debug("Initiating weather alert monitor")
                 Process(target=weather_monitor.monitor, daemon=True).start()
             else:
                 logger.debug("Executing: '%s'", exec_task)
                 try:
-                    response = offline_communicator(command=exec_task) or "No response for automated task"
+                    response = (
+                        offline_communicator(command=exec_task)
+                        or "No response for automated task"
+                    )
                     logger.debug("Response: '%s'", response)
                 except Exception as error:
                     logger.error(error)
                     logger.error(traceback.format_exc())
 
         # Sync events from the event app specified (calendar/outlook)
         # Run either for macOS or during the initial run so the response gets stored in the DB
         if dry_run or models.settings.os == models.supported_platforms.macOS:
-            if (models.env.sync_events and start_events + models.env.sync_events <= time.time()) or dry_run:
+            if (
+                models.env.sync_events
+                and start_events + models.env.sync_events <= time.time()
+            ) or dry_run:
                 start_events = time.time()
                 event_process = Process(target=events.events_writer)
-                logger.info("Getting events from %s.", models.env.event_app) if dry_run else None
+                logger.info(
+                    "Getting events from %s.", models.env.event_app
+                ) if dry_run else None
                 event_process.start()
                 with db.connection:
                     cursor = db.connection.cursor()
                     cursor.execute("UPDATE children SET events=null")
-                    cursor.execute("INSERT or REPLACE INTO children (events) VALUES (?);", (event_process.pid,))
+                    cursor.execute(
+                        "INSERT or REPLACE INTO children (events) VALUES (?);",
+                        (event_process.pid,),
+                    )
                     db.connection.commit()
 
         # Sync meetings from the ICS url provided
         # Run either when an ICS url is present or during the initial run so the response gets stored in the DB
         if dry_run or models.env.ics_url:
             if dry_run and models.env.ics_url:
                 try:
                     if requests.get(url=models.env.ics_url).status_code == 503:
                         models.env.sync_meetings = 21_600  # Set to 6 hours if unable to connect to the meetings URL
                 except EgressErrors as error:
                     logger.error(error)
-                    models.env.sync_meetings = None  # NEVER RUNs, as env vars are loaded only during start up
-            if (models.env.sync_meetings and start_meetings + models.env.sync_meetings <= time.time()) or dry_run:
+                    models.env.sync_meetings = (
+                        None  # NEVER RUNs, as env vars are loaded only during start up
+                    )
+            if (
+                models.env.sync_meetings
+                and start_meetings + models.env.sync_meetings <= time.time()
+            ) or dry_run:
                 start_meetings = time.time()
-                meeting_process = Process(target=ics_meetings.meetings_writer, args=(smart_listener,))
+                meeting_process = Process(
+                    target=ics_meetings.meetings_writer, args=(smart_listener,)
+                )
                 logger.info("Getting meetings from ICS.") if dry_run else None
                 meeting_process.start()
                 with db.connection:
                     cursor = db.connection.cursor()
                     cursor.execute("UPDATE children SET meetings=null")
-                    cursor.execute("INSERT or REPLACE INTO children (meetings) VALUES (?);", (meeting_process.pid,))
+                    cursor.execute(
+                        "INSERT or REPLACE INTO children (meetings) VALUES (?);",
+                        (meeting_process.pid,),
+                    )
                     db.connection.commit()
 
         # Mute during meetings
         if models.env.mute_for_meetings and models.env.ics_url:
             while not smart_listener.empty():
                 mutes = smart_listener.get(timeout=2)
                 logger.debug(mutes)
-                meeting_muter.append(mutes)  # Write to a new list as queue will be empty after executing .get
+                meeting_muter.append(
+                    mutes
+                )  # Write to a new list as queue will be empty after executing .get
             if meeting_muter := util.remove_duplicates(input_=meeting_muter):
                 for each_muter in meeting_muter:
                     for meeting_name, timing_info in each_muter.items():
                         meeting_time = timing_info[0]
                         duration = timing_info[1]
                         if meeting_time == now.strftime("%I:%M %p"):
-                            logger.info("Disabling listener for the meeting '%s'. Will be enabled after %s",
-                                        meeting_name, support.time_converter(second=duration))
-                            meeting_muter.remove(each_muter)  # Remove event from new list to avoid repetition
+                            logger.info(
+                                "Disabling listener for the meeting '%s'. Will be enabled after %s",
+                                meeting_name,
+                                support.time_converter(second=duration),
+                            )
+                            meeting_muter.remove(
+                                each_muter
+                            )  # Remove event from new list to avoid repetition
                             listener_controls.put_listener_state(state=False)
-                            Timer(function=listener_controls.put_listener_state, interval=duration,
-                                  kwargs=dict(state=True)).start()
+                            Timer(
+                                function=listener_controls.put_listener_state,
+                                interval=duration,
+                                kwargs=dict(state=True),
+                            ).start()
 
         # Trigger alarms
         if alarms := files.get_alarms():
             copied_alarms = alarms.copy()
             for alarmer in alarms:
                 # alarms match 'time' and 'day' of alarm
-                if alarmer['alarm_time'] == now.strftime("%I:%M %p") and \
-                        alarmer.get('day', datetime.now().strftime('%A')) == datetime.now().strftime('%A'):
+                if alarmer["alarm_time"] == now.strftime("%I:%M %p") and alarmer.get(
+                    "day", datetime.now().strftime("%A")
+                ) == datetime.now().strftime("%A"):
                     logger.info("Executing alarm: %s", alarmer)
                     Process(target=alarm.executor).start()
-                    if not alarmer['repeat']:
+                    if not alarmer["repeat"]:
                         copied_alarms.remove(alarmer)
             if copied_alarms != alarms:
                 files.put_alarms(data=copied_alarms)
 
         # Trigger reminders
         if reminders := files.get_reminders():
             copied_reminders = reminders.copy()
             for reminder in reminders:
                 # reminders match the 'time' and 'date' of reminder
-                if reminder['reminder_time'] == now.strftime("%I:%M %p") and \
-                        reminder['date'] == datetime.now().date():
+                if (
+                    reminder["reminder_time"] == now.strftime("%I:%M %p")
+                    and reminder["date"] == datetime.now().date()
+                ):
                     logger.info("Executing reminder: %s", reminder)
-                    Thread(target=remind.executor,
-                           kwargs={'message': reminder['message'], 'contact': reminder['name']}).start()
+                    Thread(
+                        target=remind.executor,
+                        kwargs={
+                            "message": reminder["message"],
+                            "contact": reminder["name"],
+                        },
+                    ).start()
                     copied_reminders.remove(reminder)
             if copied_reminders != reminders:
                 files.put_reminders(data=copied_reminders)
 
         # Re-check for any newly added tasks with logger disabled
-        new_tasks: List[classes.BackgroundTask] = list(background_task.validate_tasks(log=False))
+        new_tasks: List[classes.BackgroundTask] = list(
+            background_task.validate_tasks(log=False)
+        )
         if new_tasks != tasks:
             logger.warning("Tasks list has been updated.")
             logger.info(DeepDiff(tasks, new_tasks, ignore_order=True))
             tasks = new_tasks
-            task_dict = {i: time.time() for i in range(len(tasks))}  # Re-create start time for each task
+            task_dict = {
+                i: time.time() for i in range(len(tasks))
+            }  # Re-create start time for each task
 
         # Re-check for any newly added cron_jobs with logger disabled
-        new_cron_jobs: List[crontab.expression.CronExpression] = list(crontab.validate_jobs(log=False))
+        new_cron_jobs: List[crontab.expression.CronExpression] = list(
+            crontab.validate_jobs(log=False)
+        )
         if new_cron_jobs != cron_jobs:
             # Don't log updated jobs since there will always be a difference when run on author mode
             cron_jobs = new_cron_jobs
         dry_run = False
-        time.sleep(0.5)  # Reduces CPU utilization as constant fileIO operations spike CPU %
+        time.sleep(
+            0.5
+        )  # Reduces CPU utilization as constant fileIO operations spike CPU %
 
 
-def ondemand_offline_automation(task: str) -> Union[str, None]:
+def ondemand_offline_automation(task: str) -> str | None:
     """Makes a ``POST`` call to offline-communicator to execute a said task.
 
     Args:
         task: Takes the command to be executed as an argument.
 
     Returns:
         str:
         Returns the response if request was successful.
     """
     try:
-        response = requests.post(url=f'http://{models.env.offline_host}:{models.env.offline_port}/offline-communicator',
-                                 json={'command': task}, auth=BearerAuth(token=models.env.offline_pass))
+        response = requests.post(
+            url=f"http://{models.env.offline_host}:{models.env.offline_port}/offline-communicator",
+            json={"command": task},
+            auth=BearerAuth(token=models.env.offline_pass),
+        )
     except EgressErrors:
         return
     if response.ok:
-        return response.json()['detail'].split('\n')[-1]
+        return response.json()["detail"].split("\n")[-1]
 
 
-def offline_communicator(command: str, bg_flag: bool = False) -> Union[AnyStr, HttpUrl]:
+def offline_communicator(command: str, bg_flag: bool = False) -> AnyStr | HttpUrl:
     """Initiates conditions after flipping ``status`` flag in ``called_by_offline`` dict which suppresses the speaker.
 
     Args:
         command: Takes the command that has to be executed as an argument.
         bg_flag: Takes the background flag caller as an argument.
 
     Returns:
         AnyStr:
         Response from Jarvis.
     """
     shared.called_by_offline = True
     shared.called_by_bg_tasks = bg_flag
     # Specific for offline communication and not needed for live conversations
-    if word_match.word_match(phrase=command, match_list=keywords.keywords['ngrok']):
+    if word_match.word_match(phrase=command, match_list=keywords.keywords["ngrok"]):
         if public_url := internet.get_tunnel():
             return public_url
         else:
             raise LookupError("Failed to retrieve the public URL")
-    if word_match.word_match(phrase=command, match_list=keywords.keywords['photo']):
+    if word_match.word_match(phrase=command, match_list=keywords.keywords["photo"]):
         return others.photo()
     # Call condition instead of split_phrase as the 'and' and 'also' filter will overwrite the first response
     conditions.conditions(phrase=command)
     shared.called_by_offline = False
     shared.called_by_bg_tasks = False
     if response := shared.text_spoken:
         shared.text_spoken = None
```

## jarvis/executors/others.py

```diff
@@ -5,15 +5,15 @@
 import string
 import subprocess
 import urllib.error
 import urllib.request
 from concurrent.futures import ThreadPoolExecutor
 from datetime import datetime
 from threading import Thread
-from typing import Dict, List, Tuple, Union
+from typing import List, Tuple
 
 import boto3
 from blockstdout import BlockPrint
 from googlehomepush import GoogleHome
 from googlehomepush.http_server import serve_file
 from holidays import country_holidays
 from holidays.registry import COUNTRIES
@@ -21,46 +21,54 @@
 from newsapi import NewsApiClient, newsapi_exception
 from packaging.version import Version
 from playsound import playsound
 from pychromecast.error import ChromecastConnectionError
 from randfacts import get_fact
 
 from jarvis import version as module_version
-from jarvis.executors import (communicator, date_time, files, internet,
-                              robinhood, todo_list, weather, word_match)
+from jarvis.executors import (
+    communicator,
+    date_time,
+    files,
+    internet,
+    robinhood,
+    todo_list,
+    weather,
+    word_match,
+)
 from jarvis.modules.audio import listener, speaker
 from jarvis.modules.conditions import keywords
 from jarvis.modules.database import database
 from jarvis.modules.dictionary import dictionary
 from jarvis.modules.exceptions import CameraError
 from jarvis.modules.facenet import face
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.utils import shared, support, util
 
 db = database.Database(database=models.fileio.base_db)
 # set to be accessible only via offline communicators
 # WATCH OUT: for changes in function name
 if models.settings.pname in ("jarvis_api", "telegram_api"):
-    SECRET_STORAGE = {'aws': [], 'local': []}
+    SECRET_STORAGE = {"aws": [], "local": []}
     SESSION = boto3.Session()
     SECRET_CLIENT = SESSION.client(service_name="secretsmanager")
     SSM_CLIENT = SESSION.client(service_name="ssm")
 
 
 def repeat(phrase: str) -> None:
     """Repeats whatever is heard or what was said earlier.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
     """
     if "i" in phrase.lower().split():
         speaker.speak(text="Please tell me what to repeat.", run=True)
         if keyword := listener.listen():
-            if 'exit' in keyword or 'quit' in keyword or 'Xzibit' in keyword:
+            if "exit" in keyword or "quit" in keyword or "Xzibit" in keyword:
                 pass
             else:
                 speaker.speak(text=f"I heard {keyword}")
     else:
         if text := shared.text_spoken:
             if text.startswith(f"Sure {models.env.title}, "):
                 speaker.speak(text)
@@ -80,79 +88,88 @@
         macOS ventura does not display built-in applications for the ls command.
     """
     if models.settings.os == models.supported_platforms.linux:
         support.unsupported_features()
         return
 
     keyword = phrase.split()[-1] if phrase else None
-    ignore = ['app', 'application']
+    ignore = ["app", "application"]
     if not keyword or keyword in ignore:
         if shared.called_by_offline:
-            speaker.speak(text=f'I need an app name to open {models.env.title}!')
+            speaker.speak(text=f"I need an app name to open {models.env.title}!")
             return
         speaker.speak(text=f"Which app shall I open {models.env.title}?", run=True)
         if keyword := listener.listen():
-            if 'exit' in keyword or 'quit' in keyword or 'Xzibit' in keyword:
+            if "exit" in keyword or "quit" in keyword or "Xzibit" in keyword:
                 return
         else:
             speaker.speak(text="I didn't quite get that. Try again.")
             return
 
     if models.settings.os == models.supported_platforms.windows:
-        status = os.system(f'start {keyword}')
+        status = os.system(f"start {keyword}")
         if status == 0:
-            speaker.speak(text=f'I have opened {keyword}')
+            speaker.speak(text=f"I have opened {keyword}")
         else:
             speaker.speak(text=f"I did not find the app {keyword}. Try again.")
         return
 
     all_apps = subprocess.check_output("ls /Applications/", shell=True)
-    apps_ = all_apps.decode('utf-8').split('\n')
+    apps_ = all_apps.decode("utf-8").split("\n")
 
     app_check = False
     for app in apps_:
         if re.search(keyword, app, flags=re.IGNORECASE) is not None:
             keyword = app
             app_check = True
             break
 
     if not app_check:
         speaker.speak(text=f"I did not find the app {keyword}. Try again.")
-        Thread(target=support.unrecognized_dumper, args=[{'APPLICATIONS': keyword}]).start()
+        Thread(
+            target=support.unrecognized_dumper, args=[{"APPLICATIONS": keyword}]
+        ).start()
         return
     app_status = os.system(f"open /Applications/{keyword!r} > /dev/null 2>&1")
-    keyword = keyword.replace('.app', '')
+    keyword = keyword.replace(".app", "")
     if app_status == 256:
-        speaker.speak(text=f"I'm sorry {models.env.title}! I wasn't able to launch {keyword}. "
-                           "You might need to check its permissions.")
+        speaker.speak(
+            text=f"I'm sorry {models.env.title}! I wasn't able to launch {keyword}. "
+            "You might need to check its permissions."
+        )
     else:
         speaker.speak(text=f"I have opened {keyword}")
 
 
 def music(phrase: str = None) -> None:
     """Scans music directory in the user profile for ``.mp3`` files and plays using default player.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
     """
-    get_all_files = (os.path.join(root, f) for root, _, file in os.walk(os.path.join(models.env.home, "Music")) for f
-                     in file)
-    if music_files := [file for file in get_all_files if os.path.splitext(file)[1] == '.mp3']:
+    get_all_files = (
+        os.path.join(root, f)
+        for root, _, file in os.walk(os.path.join(models.env.home, "Music"))
+        for f in file
+    )
+    if music_files := [
+        file for file in get_all_files if os.path.splitext(file)[1] == ".mp3"
+    ]:
         chosen = random.choice(music_files)
-        if phrase and 'speaker' in phrase:
+        if phrase and "speaker" in phrase:
             google_home(device=phrase, file=chosen)
         else:
             if models.settings.os == models.supported_platforms.windows:
                 os.system(f'start wmplayer "{chosen}"')
             else:
                 subprocess.call(["open", chosen])
             support.flush_screen()
             speaker.speak(text=f"Enjoy your music {models.env.title}!")
     else:
-        speaker.speak(text=f'No music files were found {models.env.title}!')
+        speaker.speak(text=f"No music files were found {models.env.title}!")
 
 
 def google_home(device: str = None, file: str = None) -> None:
     """Uses ``socket lib`` to extract ip address and scan ip range for Google home devices.
 
     Notes:
         - Can also play music on multiple devices at once.
@@ -176,16 +193,19 @@
         device: Name of the Google home device on which the music has to be played.
         file: Scanned audio file to be played.
     """
     if not (network_id := internet.vpn_checker()):
         return
 
     if not shared.called_by_offline:
-        speaker.speak(text=f'Scanning your IP range for Google Home devices {models.env.title}!', run=True)
-    network_id = '.'.join(network_id.split('.')[:3])
+        speaker.speak(
+            text=f"Scanning your IP range for Google Home devices {models.env.title}!",
+            run=True,
+        )
+    network_id = ".".join(network_id.split(".")[:3])
 
     def ip_scan(host_id: int) -> Tuple[str, str]:
         """Scans the IP range using the received args as host id in an IP address.
 
         Args:
             host_id: Host ID passed in a multithreaded fashion to scan for Google home devices in IP range.
 
@@ -201,152 +221,197 @@
             # port = sample.split("'")[2].split()[1].replace(',', '')
             return device_name, device_ip
         except ChromecastConnectionError:
             pass
 
     devices = []
     with ThreadPoolExecutor(max_workers=100) as executor:
-        for info in executor.map(ip_scan, range(1, 101)):  # scans host IDs 1 to 255 (eg: 192.168.1.1 to 192.168.1.255)
-            devices.append(info)  # this includes all the NoneType values returned by unassigned host IDs
-    devices = dict([i for i in devices if i])  # removes None values and converts list to dictionary of name and ip pair
+        # scans host IDs 1 to 255 (eg: 192.168.1.1 to 192.168.1.255)
+        for info in executor.map(ip_scan, range(1, 101)):
+            devices.append(
+                info
+            )  # this includes all the NoneType values returned by unassigned host IDs
+    devices = dict(
+        [i for i in devices if i]
+    )  # removes None values and converts list to dictionary of name and ip pair
 
     if not device or not file:
         support.flush_screen()
-        speaker.speak(text=f"You have {len(devices)} devices in your IP range {models.env.title}! "
-                           f"{util.comma_separator(list(devices.keys()))}. You can choose one and ask me to play "
-                           f"some music on any of these.")
+        speaker.speak(
+            text=f"You have {len(devices)} devices in your IP range {models.env.title}! "
+            f"{util.comma_separator(list(devices.keys()))}. You can choose one and ask me to play "
+            f"some music on any of these."
+        )
         return
     else:
-        chosen = [value for key, value in devices.items() if key.lower() in device.lower()]
+        chosen = [
+            value for key, value in devices.items() if key.lower() in device.lower()
+        ]
         if not chosen:
-            speaker.speak(text=f"I don't see any matching devices {models.env.title}!. Let me help you. "
-                               f"You have {len(devices)} devices in your IP range {models.env.title}! "
-                               f"{util.comma_separator(list(devices.keys()))}.")
+            speaker.speak(
+                text=f"I don't see any matching devices {models.env.title}!. Let me help you. "
+                f"You have {len(devices)} devices in your IP range {models.env.title}! "
+                f"{util.comma_separator(list(devices.keys()))}."
+            )
             return
         for target in chosen:
-            file_url = serve_file(file, "audio/mp3")  # serves the file on local host and generates the play url
+            file_url = serve_file(
+                file, "audio/mp3"
+            )  # serves the file on local host and generates the play url
             support.flush_screen()
             with BlockPrint():
                 GoogleHome(host=target).play(file_url, "audio/mp3")
         if len(chosen) > 1:
-            speaker.speak(text=f"That's interesting, you've asked me to play on {len(chosen)} devices at a time. "
-                               f"I hope you'll enjoy this {models.env.title}.", run=True)
+            speaker.speak(
+                text=f"That's interesting, you've asked me to play on {len(chosen)} devices at a time. "
+                f"I hope you'll enjoy this {models.env.title}.",
+                run=True,
+            )
         else:
             speaker.speak(text=f"Enjoy your music {models.env.title}!", run=True)
 
 
 def jokes(*args) -> None:
     """Uses jokes lib to say chucknorris jokes."""
     speaker.speak(text=random.choice([geek, icanhazdad, chucknorris, icndb])())
 
 
 def flip_a_coin(*args) -> None:
     """Says ``heads`` or ``tails`` from a random choice."""
-    playsound(sound=models.indicators.coin, block=True) if not shared.called_by_offline else None
-    speaker.speak(text=f"""{random.choice(['You got', 'It landed on',
-                                           "It's"])} {random.choice(['heads', 'tails'])} {models.env.title}""")
+    playsound(
+        sound=models.indicators.coin, block=True
+    ) if not shared.called_by_offline else None
+    speaker.speak(
+        text=f"""{random.choice(['You got', 'It landed on',
+                                           "It's"])} {random.choice(['heads', 'tails'])} {models.env.title}"""
+    )
 
 
 def facts(*args) -> None:
     """Tells a random fact."""
     speaker.speak(text=get_fact(filter_enabled=False))
 
 
 def meaning(phrase: str) -> None:
     """Gets meaning for a word skimmed from the user statement.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
     """
     keyword = phrase.split()[-1] if phrase else None
-    if not keyword or keyword == 'word':
+    if not keyword or keyword == "word":
         speaker.speak(text="Please tell a keyword.", run=True)
         response = listener.listen()
-        if not response or word_match.word_match(phrase=response, match_list=keywords.keywords['exit_']):
+        if not response or word_match.word_match(
+            phrase=response, match_list=keywords.keywords["exit_"]
+        ):
             return
         meaning(phrase=response)
     else:
         if definition := dictionary.meaning(term=keyword):
             n = 0
-            vowel = ['A', 'E', 'I', 'O', 'U']
+            vowel = ["A", "E", "I", "O", "U"]
             for key, value in definition.items():
-                insert = 'an' if key[0] in vowel else 'a'
-                repeated = ' also ' if n != 0 else ' '
+                insert = "an" if key[0] in vowel else "a"
+                repeated = " also " if n != 0 else " "
                 n += 1
-                mean = ', '.join(value[:2])
-                speaker.speak(text=f'{keyword} is{repeated}{insert} {key}, which means {mean}.')
+                mean = ", ".join(value[:2])
+                speaker.speak(
+                    text=f"{keyword} is{repeated}{insert} {key}, which means {mean}."
+                )
             if shared.called_by_offline:
                 return
-            speaker.speak(text=f'Do you wanna know how {keyword} is spelled?', run=True)
+            speaker.speak(text=f"Do you wanna know how {keyword} is spelled?", run=True)
             response = listener.listen()
-            if word_match.word_match(phrase=response, match_list=keywords.keywords['ok']):
+            if word_match.word_match(
+                phrase=response, match_list=keywords.keywords["ok"]
+            ):
                 for letter in list(keyword.lower()):
                     speaker.speak(text=letter)
                 speaker.speak(run=True)
         else:
-            speaker.speak(text=f"I'm sorry {models.env.title}! I was unable to get meaning for the word: {keyword}")
+            speaker.speak(
+                text=f"I'm sorry {models.env.title}! I was unable to get meaning for the word: {keyword}"
+            )
 
 
 def notes(*args) -> None:
     """Listens to the user and saves it as a text file."""
-    if (converted := listener.listen()) or 'exit' in converted or 'quit' in converted or \
-            'Xzibit' in converted:
-        return
-    with open(models.fileio.notes, 'a') as writer:
-        writer.write(f"{datetime.now().strftime('%A, %B %d, %Y')}\n{datetime.now().strftime('%I:%M %p')}\n"
-                     f"{converted}\n")
+    if (
+        (converted := listener.listen())
+        or "exit" in converted
+        or "quit" in converted
+        or "Xzibit" in converted
+    ):
+        return
+    with open(models.fileio.notes, "a") as writer:
+        writer.write(
+            f"{datetime.now().strftime('%A, %B %d, %Y')}\n{datetime.now().strftime('%I:%M %p')}\n"
+            f"{converted}\n"
+        )
 
 
-def news(news_source: str = 'fox') -> None:
+def news(news_source: str = "fox") -> None:
     """Says news around the user's location.
 
     Args:
         news_source: Source from where the news has to be fetched. Defaults to ``fox``.
     """
     if not models.env.news_api:
         logger.warning("News apikey not found.")
         support.no_env_vars()
         return
 
     news_client = NewsApiClient(api_key=models.env.news_api)
     try:
-        all_articles = news_client.get_top_headlines(sources=f'{news_source}-news')
+        all_articles = news_client.get_top_headlines(sources=f"{news_source}-news")
     except newsapi_exception.NewsAPIException as error:
         logger.error(error)
-        speaker.speak(text=f"I'm sorry {models.env.title}! I wasn't able to get the news {models.env.title}!")
+        speaker.speak(
+            text=f"I'm sorry {models.env.title}! I wasn't able to get the news {models.env.title}!"
+        )
         return
-    if all_articles.get('status', 'fail') != 'ok':
+    if all_articles.get("status", "fail") != "ok":
         logger.warning(all_articles)
-        speaker.speak(text=f"I'm sorry {models.env.title}! I wasn't able to get the news {models.env.title}!")
+        speaker.speak(
+            text=f"I'm sorry {models.env.title}! I wasn't able to get the news {models.env.title}!"
+        )
         return
-    if all_articles.get('totalResults', 0) == 0 or all_articles.get('articles', []) == []:
+    if (
+        all_articles.get("totalResults", 0) == 0
+        or all_articles.get("articles", []) == []
+    ):
         logger.warning(all_articles)
-        speaker.speak(text=f"I wasn't able to find any news around you {models.env.title}!")
+        speaker.speak(
+            text=f"I wasn't able to find any news around you {models.env.title}!"
+        )
         return
     speaker.speak(text="News around you!")
-    speaker.speak(text=' '.join([article['title'] for article in all_articles['articles']]))
+    speaker.speak(
+        text=" ".join([article["title"] for article in all_articles["articles"]])
+    )
     if shared.called_by_offline:
         return
 
-    if shared.called['report']:
+    if shared.called["report"]:
         speaker.speak(run=True)
 
 
 def report(*args) -> None:
     """Initiates a list of functions, that I tend to check first thing in the morning."""
     support.write_screen(text="Starting today's report")
-    shared.called['report'] = True
+    shared.called["report"] = True
     date_time.current_date()
     date_time.current_time()
     weather.weather()
     todo_list.get_todo()
     communicator.read_gmail()
     robinhood.robinhood()
     news()
-    shared.called['report'] = False
+    shared.called["report"] = False
 
 
 def celebrate(phrase: str = None) -> str:
     """Function to look if the current date is a holiday or a birthday.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
@@ -361,80 +426,95 @@
         date, day, tense = support.extract_humanized_date(phrase)
         logger.info(f"Extracted humanized date: {date}")
     else:
         date, day, tense = datetime.today().date(), "today", "is"
     if phrase:
         phrase = phrase.strip()
         countries = {
-            country[1]: [' '.join(re.findall('[A-Z][^A-Z]*', country[0])), country[2]] for country in COUNTRIES.values()
+            country[1]: [" ".join(re.findall("[A-Z][^A-Z]*", country[0])), country[2]]
+            for country in COUNTRIES.values()
         }
         for code, names in countries.items():
             # If country code is used, then it should be a precise match, otherwise just regex it
             if code in phrase.split() or any(name in phrase for name in names):
                 countryname = names[0]
                 countrycode = code
                 logger.info("%s: %s", countrycode, countryname)
                 break
     else:
         location = files.get_location()
-        if not (countrycode := location.get('address', {}).get('country_code')):  # get country code from location.yaml
-            if idna_timezone := location.get('timezone'):  # get timezone from location.yaml
-                countrycode = support.country_timezone().get(idna_timezone)  # get country code using timezone map
+        # get country code from location.yaml
+        if not (countrycode := location.get("address", {}).get("country_code")):
+            # get timezone from location.yaml
+            if idna_timezone := location.get("timezone"):
+                # get country code using timezone map
+                countrycode = support.country_timezone().get(str(idna_timezone))
     if not countrycode:
         countrycode = "US"
         countryname = "USA"
     if current_holiday := country_holidays(countrycode.upper()).get(date):
         if phrase:
-            speaker.speak(text=f"{string.capwords(day)} {tense} {current_holiday!r} in {countryname}")
+            speaker.speak(
+                text=f"{string.capwords(day)} {tense} {current_holiday!r} in {countryname}"
+            )
         else:
             return current_holiday
     elif models.env.birthday == date.strftime("%d-%B"):
         if phrase:
-            speaker.speak(text=f"{string.capwords(day)} {tense} your birthday {models.env.title}!")
+            speaker.speak(
+                text=f"{string.capwords(day)} {tense} your birthday {models.env.title}!"
+            )
         else:
             return "Birthday"
     elif phrase:
         speaker.speak(text=f"There are no events to celebrate {day}, in {countryname}")
 
 
 def abusive(phrase: str) -> None:
     """Response for abusive phrases.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
     """
     logger.warning(phrase)
-    speaker.speak(text="I don't respond to abusive words. Ask me nicely, you might get a response.")
+    speaker.speak(
+        text="I don't respond to abusive words. Ask me nicely, you might get a response."
+    )
 
 
 def photo(*args) -> str:
     """Captures a picture of the ambience using the connected camera.
 
     Returns:
         str:
         Filename.
     """
     # Ret value will be used only by offline communicator
-    filename = os.path.join(models.fileio.root, f"{datetime.now().strftime('%B_%d_%Y_%I_%M_%p')}.jpg")
+    filename = os.path.join(
+        models.fileio.root, f"{datetime.now().strftime('%B_%d_%Y_%I_%M_%p')}.jpg"
+    )
     try:
         facenet = face.FaceNet()
     except CameraError as error:
         logger.error(error)
         return f"I'm sorry {models.env.title}! I wasn't able to take a picture."
     facenet.capture_image(filename=filename)
     if os.path.isfile(filename):
-        if not shared.called_by_offline:  # don't show preview on screen if requested via offline
+        # don't show preview on screen if requested via offline
+        if not shared.called_by_offline:
             if models.settings.os != models.supported_platforms.windows:
                 subprocess.call(["open", filename])
             else:
-                os.system(f'start {filename}')
+                os.system(f"start {filename}")
         speaker.speak(text=f"A photo has been captured {models.env.title}!")
         return filename
     else:
-        speaker.speak(text=f"I'm sorry {models.env.title}! I wasn't able to take a picture.")
+        speaker.speak(
+            text=f"I'm sorry {models.env.title}! I wasn't able to take a picture."
+        )
         return f"I'm sorry {models.env.title}! I wasn't able to take a picture."
 
 
 def pypi_versions(package_name: str) -> List[str]:
     """Get all available versions from pypi.
 
     Args:
@@ -443,15 +523,19 @@
     Returns:
         List[str]:
         List of version numbers.
     """
     url = f"https://pypi.org/pypi/{package_name}/json"
     try:
         data = json.load(urllib.request.urlopen(urllib.request.Request(url=url)))
-    except (urllib.error.URLError, urllib.error.HTTPError, urllib.error.ContentTooShortError) as error:
+    except (
+        urllib.error.URLError,
+        urllib.error.HTTPError,
+        urllib.error.ContentTooShortError,
+    ) as error:
         logger.error(error)
     else:
         pypi = list(data.get("releases", {}).keys())
         pypi.sort(key=Version)
         return pypi
 
 
@@ -463,121 +547,137 @@
         if module_version == pkg_version or pkg_version == f"{module_version}0":
             text += ", I'm up to date."
         else:
             text += f", but the latest released version is {pkg_version}"
     speaker.speak(text=text)
 
 
-def get_aws_secrets(name: str = None) -> Union[Union[str, Dict[str, str]], List[str]]:
+def get_aws_secrets(name: str = None) -> str | List[str]:
     """Get secrets from AWS secretsmanager.
 
     Args:
         name: Get name of the particular secret.
 
     Returns:
-        Union[Union[str, Dict[str]], List[str]]:
+        str | List[str]:
         Returns the value of the secret or list of all secrets' names.
     """
     if name:
-        response = SECRET_CLIENT.get_secret_value(
-            SecretId=name
-        )
-        return response['SecretString']
-    paginator = SECRET_CLIENT.get_paginator('list_secrets')
+        response = SECRET_CLIENT.get_secret_value(SecretId=name)
+        return response["SecretString"]
+    paginator = SECRET_CLIENT.get_paginator("list_secrets")
     page_results = paginator.paginate().build_full_result()
-    return [page['Name'] for page in page_results['SecretList']]
+    return [page["Name"] for page in page_results["SecretList"]]
 
 
-def get_aws_params(name: str = None) -> Union[str, List[str]]:
+def get_aws_params(name: str = None) -> str | List[str]:
     """Get SSM parameters from AWS.
 
     Args:
         name: Get name of the particular parameter.
 
     Returns:
-        Union[str, List[str]]:
+        str | List[str]:
         Returns the value of the parameter or list of all parameter names.
     """
     if name:
         response = SSM_CLIENT.get_parameter(Name=name, WithDecryption=True)
-        return response['Parameter']['Value']
-    paginator = SSM_CLIENT.get_paginator('describe_parameters')
+        return response["Parameter"]["Value"]
+    paginator = SSM_CLIENT.get_paginator("describe_parameters")
     page_results = paginator.paginate().build_full_result()
-    return [page['Name'] for page in page_results['Parameters']]
+    return [page["Name"] for page in page_results["Parameters"]]
 
 
 def secrets(phrase: str) -> str:
     """Handle getting secrets from AWS or local env vars.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
 
     Returns:
         str:
         Response to the user.
     """
     text = phrase.lower().split()
 
-    if 'create' in text or 'share' in text:
+    if "create" in text or "share" in text:
         before, part, after = phrase.partition("for")
         if custom_secret := after.strip():
             key = util.keygen_uuid()
-            files.put_secure_send(data={key: {'secret': custom_secret}})
+            files.put_secure_send(data={key: {"secret": custom_secret}})
             return key
         else:
-            return "Please specify the secret to create after the keyword 'for'\n" \
-                   "example: create and share secret for drogon589#"
-
-    if 'list' in text:  # calling list will always create a new list in the dict regardless of what exists
-        if 'aws' in text:
-            SECRET_STORAGE['aws'] = []  # reset everytime list param is called
-            if 'ssm' in text:
+            return (
+                "Please specify the secret to create after the keyword 'for'\n"
+                "example: create and share secret for drogon589#"
+            )
+
+    # Calling list will always create a new list in the dict regardless of what exists
+    if "list" in text:
+        if "aws" in text:
+            SECRET_STORAGE["aws"] = []  # reset everytime list param is called
+            if "ssm" in text:
                 try:
-                    SECRET_STORAGE['aws'].extend(get_aws_params())
+                    SECRET_STORAGE["aws"].extend(get_aws_params())
                 except Exception as error:
                     logger.error(error)
             else:
                 try:
-                    SECRET_STORAGE['aws'].extend(get_aws_secrets())
+                    SECRET_STORAGE["aws"].extend(get_aws_secrets())
                 except Exception as error:
                     logger.error(error)
-            return ', '.join(SECRET_STORAGE['aws']) if SECRET_STORAGE['aws'] else "No parameters were found"
-        if 'local' in text:
-            SECRET_STORAGE['local'] = list(models.env.__dict__.keys())
-            return ', '.join(SECRET_STORAGE['local'])
+            return (
+                ", ".join(SECRET_STORAGE["aws"])
+                if SECRET_STORAGE["aws"]
+                else "No parameters were found"
+            )
+        if "local" in text:
+            SECRET_STORAGE["local"] = list(models.env.__dict__.keys())
+            return ", ".join(SECRET_STORAGE["local"])
         return "Please specify which secrets you want to list: 'aws' or 'local''"
 
-    if 'get' in text or 'send' in text:  # calling get will always return the latest information in the existing dict
-        if 'aws' in text:
-            if SECRET_STORAGE['aws']:
-                if aws_key := [key for key in phrase.split() if key in SECRET_STORAGE['aws']]:
+    # calling get will always return the latest information in the existing dict
+    if "get" in text or "send" in text:
+        if "aws" in text:
+            if SECRET_STORAGE["aws"]:
+                if aws_key := [
+                    key for key in phrase.split() if key in SECRET_STORAGE["aws"]
+                ]:
                     aws_key = aws_key[0]
                 else:
                     return "No AWS params were found matching your request."
             else:
                 return "Please use 'list secret' before using 'get secret'"
-            if 'ssm' in text:
+            if "ssm" in text:
                 try:
                     key = util.keygen_uuid()
-                    files.put_secure_send(data={key: {aws_key: get_aws_params(name=aws_key)}})
+                    files.put_secure_send(
+                        data={key: {aws_key: get_aws_params(name=aws_key)}}
+                    )
                     return key
                 except Exception as error:  # if secret is removed between 'list' and 'get'
                     logger.error(error)
             else:
                 try:
                     key = util.keygen_uuid()
-                    files.put_secure_send(data={key: {aws_key: get_aws_secrets(name=aws_key)}})
+                    files.put_secure_send(
+                        data={key: {aws_key: get_aws_secrets(name=aws_key)}}
+                    )
                     return key
                 except Exception as error:  # if secret is removed between 'list' and 'get'
                     logger.error(error)
             return f"Failed to retrieve {aws_key!r}"
-        if 'local' in text:
-            if not SECRET_STORAGE['local']:
-                SECRET_STORAGE['local'] = list(models.env.__dict__.keys())
-            if local_key := [key for key in phrase.split() if key in SECRET_STORAGE['local']]:
+        if "local" in text:
+            if not SECRET_STORAGE["local"]:
+                SECRET_STORAGE["local"] = list(models.env.__dict__.keys())
+            if local_key := [
+                key for key in phrase.split() if key in SECRET_STORAGE["local"]
+            ]:
                 local_key = local_key[0]
             else:
                 return "No local params were found matching your request."
             key = util.keygen_uuid()
-            files.put_secure_send(data={key: {local_key: models.env.__dict__[local_key]}})
+            files.put_secure_send(
+                data={key: {local_key: models.env.__dict__[local_key]}}
+            )
             return key
         return "Please specify which type of secret you want the value for: 'aws' or 'local'"
```

## jarvis/executors/port_handler.py

```diff
@@ -1,14 +1,13 @@
 import os
 import signal
 import socket
 import subprocess
 import sys
 import warnings
-from typing import Union
 
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 
 
 def is_port_in_use(port: int) -> bool:
     """Connect to a remote socket at address, to identify if the port is currently being used.
@@ -17,18 +16,18 @@
         port: Takes the port number as an argument.
 
     Returns:
         bool:
         A boolean flag to indicate whether a port is open.
     """
     with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
-        return sock.connect_ex(('localhost', port)) == 0
+        return sock.connect_ex(("localhost", port)) == 0
 
 
-def kill_port_pid(port: int, protocol: str = 'tcp') -> Union[bool, None]:
+def kill_port_pid(port: int, protocol: str = "tcp") -> bool | None:
     """Uses List all open files ``lsof`` to get the PID of the process that is listening on the given port and kills it.
 
     Args:
         port: Port number which the application is listening on.
         protocol: Protocol serving the port. Defaults to ``TCP``
 
     Warnings:
@@ -38,32 +37,46 @@
             - If the PID is the same as that of ``MainProcess``, triggers a warning without terminating the process.
 
     Returns:
         bool:
         Flag to indicate whether the process was terminated successfully.
     """
     try:
-        active_sessions = subprocess.check_output(f"lsof -i {protocol}:{port}", shell=True).decode('utf-8').splitlines()
+        active_sessions = (
+            subprocess.check_output(f"lsof -i {protocol}:{port}", shell=True)
+            .decode("utf-8")
+            .splitlines()
+        )
         for each in active_sessions:
             each_split = each.split()
-            if each_split[0].strip() == 'Python':
-                logger.info("Application hosted on %s is listening to port: %d", each_split[-2], port)
+            if each_split[0].strip() == "Python":
+                logger.info(
+                    "Application hosted on %s is listening to port: %d",
+                    each_split[-2],
+                    port,
+                )
                 pid = int(each_split[1])
                 if pid == models.settings.pid:
                     called_function = sys._getframe(1).f_code.co_name  # noqa
-                    called_file = sys._getframe(1).f_code.co_filename.replace(f'{os.getcwd()}/', '')  # noqa
-                    logger.warning("%s from %s tried to kill the running process.", called_function, called_file)
+                    called_file = sys._getframe(1).f_code.co_filename.replace(
+                        f"{os.getcwd()}/", ""
+                    )  # noqa
+                    logger.warning(
+                        "%s from %s tried to kill the running process.",
+                        called_function,
+                        called_file,
+                    )
                     warnings.warn(
-                        f'OPERATION DENIED: {called_function} from {called_file} tried to kill the running process.'
+                        f"OPERATION DENIED: {called_function} from {called_file} tried to kill the running process."
                     )
                     return
                 os.kill(pid, signal.SIGTERM)
                 logger.info("Killed PID: %d", pid)
                 return True
         logger.info("No active process running on %d", port)
         return False
     except (subprocess.SubprocessError, subprocess.CalledProcessError) as error:
         if isinstance(error, subprocess.CalledProcessError):
-            result = error.output.decode(encoding='UTF-8').strip()
+            result = error.output.decode(encoding="UTF-8").strip()
             logger.error("[%d]: %s", error.returncode, result)
         else:
             logger.error(error)
```

## jarvis/executors/process_map.py

```diff
@@ -1,15 +1,86 @@
+import os
+import shutil
+from datetime import datetime
+from multiprocessing import Process
 from typing import Dict, List
 
 import yaml
 
+from jarvis.api.server import jarvis_api
+from jarvis.executors import crontab, offline, telegram
+from jarvis.modules.audio import speech_synthesis
 from jarvis.modules.logger import logger
+from jarvis.modules.microphone import graph_mic
 from jarvis.modules.models import models
 
 
+def base() -> Dict[str, Dict[str, Process | List[str]]]:
+    """Creates a base mapping with all the processes handled by Jarvis.
+
+    Returns:
+        Dict[str, Dict[str, Process | List[str]]]:
+        Nested dictionary of process mapping.
+    """
+    base_mapping = {
+        # process map will not be removed
+        jarvis_api.__name__: {
+            "process": Process(target=jarvis_api),
+            "impact": [
+                "Offline communicator",
+                "Robinhood portfolio report",
+                "Jarvis UI",
+                "Stock monitor",
+                "Surveillance",
+                "Telegram",
+            ],
+        },
+        # process map will not be removed
+        offline.background_tasks.__name__: {
+            "process": Process(target=offline.background_tasks),
+            "impact": [
+                "Home automation",
+                "Alarms",
+                "Reminders",
+                "Meetings and Events sync",
+                "Wi-Fi connector",
+                "Cron jobs",
+                "Background tasks",
+            ],
+        },
+        # process map will be removed if speech_synthesis is disabled
+        speech_synthesis.speech_synthesis_api.__name__: {
+            "process": Process(target=speech_synthesis.speech_synthesis_api),
+            "impact": ["Speech Synthesis"],
+        },
+        # process map will be removed if telegram bot is hosted via Jarvis API
+        telegram.telegram_api.__name__: {
+            "process": Process(target=telegram.telegram_api),
+            "impact": ["Telegram Bot"],
+        },
+    }
+    if models.env.plot_mic:
+        statement = shutil.which(cmd="python") + " " + graph_mic.__file__
+        # process map will be removed if plot_mic is disabled
+        base_mapping[graph_mic.plot_mic.__name__] = {
+            "process": Process(
+                target=crontab.executor,
+                kwargs={
+                    "statement": statement,
+                    "log_file": datetime.now().strftime(
+                        os.path.join("logs", "mic_plotter_%d-%m-%Y.log")
+                    ),
+                    "process_name": graph_mic.plot_mic.__name__,
+                },
+            ),
+            "impact": ["Realtime microphone usage plotter"],
+        }
+    return base_mapping
+
+
 def get() -> Dict[str, Dict[int, List[str]]]:
     """Get the existing process map.
 
     Returns:
         Dict[str, Dict[int, List[str]]]:
         Returns the dictionary of process data and the impact information.
     """
@@ -19,32 +90,36 @@
 
 def add(data: Dict[str, Dict[int, List[str]]]) -> None:
     """Dumps the process map data into the mapping file.
 
     Args:
         data: Dictionary of process data and the impact information.
     """
-    with open(models.fileio.processes, 'w') as file:
+    with open(models.fileio.processes, "w") as file:
         yaml.dump(stream=file, data=data)
 
 
 def remove(func_name: str) -> None:
     """Remove process map for a function that has stopped running.
 
     Args:
         func_name: Name of the function that has to be removed from the mapping.
     """
     with open(models.fileio.processes) as file:
         process_map = yaml.load(stream=file, Loader=yaml.FullLoader)
     logger.debug(process_map)
     if process_map.get(func_name):
-        logger.info("%s: %s has been removed from processes mapping", func_name, process_map[func_name])
+        logger.info(
+            "%s: %s has been removed from processes mapping",
+            func_name,
+            process_map[func_name],
+        )
         del process_map[func_name]
     logger.debug(process_map)
-    with open(models.fileio.processes, 'w') as file:
+    with open(models.fileio.processes, "w") as file:
         yaml.dump(data=process_map, stream=file)
 
 
 def update(func_name: str, old_pid: int, new_pid: int) -> None:
     """Remove process map for a function that has stopped running.
 
     Args:
@@ -55,11 +130,13 @@
     with open(models.fileio.processes) as file:
         process_map = yaml.load(stream=file, Loader=yaml.FullLoader)
     logger.debug(process_map)
     if process_map.get(func_name) and process_map[func_name].get(old_pid):
         _temp = process_map[func_name][old_pid]
         del process_map[func_name][old_pid]
         process_map[func_name][new_pid] = _temp
-        logger.info("%s has been updated from pid '%d' to pid '%d'", func_name, old_pid, new_pid)
+        logger.info(
+            "%s has been updated from pid '%d' to pid '%d'", func_name, old_pid, new_pid
+        )
     logger.debug(process_map)
-    with open(models.fileio.processes, 'w') as file:
+    with open(models.fileio.processes, "w") as file:
         yaml.dump(data=process_map, stream=file)
```

## jarvis/executors/processor.py

```diff
@@ -1,23 +1,16 @@
 import os
-import shutil
-import warnings
-from datetime import datetime
 from multiprocessing import Process
-from threading import Thread
-from typing import Dict, List, Union
+from typing import Dict, List
 
 import psutil
 
-from jarvis.api.server import jarvis_api
-from jarvis.executors import crontab, offline, process_map, telegram
-from jarvis.modules.audio import speech_synthesis
+from jarvis.executors import process_map
 from jarvis.modules.database import database
 from jarvis.modules.logger import logger
-from jarvis.modules.microphone import graph_mic
 from jarvis.modules.models import models
 from jarvis.modules.retry import retry
 from jarvis.modules.utils import shared, support, util
 
 db = database.Database(database=models.fileio.base_db)
 
 
@@ -36,111 +29,101 @@
     """Deletes entries from all databases except for the tables assigned to hold data forever."""
     with db.connection:
         cursor = db.connection.cursor()
         for table, column in models.TABLES.items():
             if table in models.KEEP_TABLES:
                 continue
             # Use f-string or %s as table names cannot be parametrized
-            data = cursor.execute(f'SELECT * FROM {table}').fetchall()
-            logger.info("Deleting data from %s: %s", table, util.matrix_to_flat_list([list(filter(None, d))
-                                                                                      for d in data if any(d)]))
+            data = cursor.execute(f"SELECT * FROM {table}").fetchall()
+            logger.info(
+                "Deleting data from %s: %s",
+                table,
+                util.matrix_to_flat_list(
+                    [list(filter(None, d)) for d in data if any(d)]
+                ),
+            )
             cursor.execute(f"DELETE FROM {table}")
 
 
 # noinspection LongLine
-def create_process_mapping(processes: Dict[str, Process], func_name: str = None) -> None:
+def create_process_mapping(
+    processes: Dict[str, Dict[str, Process | List[str]]], func_name: str = None
+) -> None:
     """Creates or updates the processes mapping file.
 
     Args:
-        processes: Dictionary of process names and the process.
-        func_name: Function name of each process.
-
-    See Also:
-        - This is a special function, that uses doc strings to create a python dict.
-
-    Handles:
-        - speech_synthesis_api: Speech Synthesis
-        - telegram_api: Telegram Bot
-        - jarvis_api: Offline communicator, Robinhood portfolio report, Jarvis UI, Stock monitor, Surveillance, Telegram
-        - background_tasks: Home automation, Alarms, Reminders, Meetings and Events sync, Wi-Fi connector, Cron jobs, Background tasks
-        - plot_mic: Plot microphone usage in real time
+        processes: Dictionary of process names, process id and their impact.
+        func_name: Function name of the process.
     """
-    impact_lib = {}
-    for doc in create_process_mapping.__doc__.split('Handles:')[1].splitlines():
-        if doc.strip():
-            element = doc.strip().split(':')
-            func = element[0].lstrip('- ')
-            desc = element[1].strip().split(', ')
-            if processes.get(func):
-                impact_lib[func] = desc
-            else:
-                logger.warning("'%s' not found in list of processes initiated", func)
-    if not func_name and sorted(impact_lib.keys()) != sorted(processes.keys()):
-        warnings.warn(message=f"{list(impact_lib.keys())} does not match {list(processes.keys())}")
-    if func_name:  # Assumes a processes mapping file exists already, since flag passed during process specific restart
+    if func_name:
+        # Assumes a processes mapping file exists already, since flag is passed during process specific restart
         dump = process_map.get()
-        dump[func_name] = {processes[func_name].pid: impact_lib[func_name]}
+        dump[func_name] = {
+            processes[func_name]["process"].pid: processes[func_name]["impact"]
+        }
     else:
-        dump = {k: {v.pid: impact_lib[k]} for k, v in processes.items()}
+        dump = {
+            k: {v["process"].pid: processes[k]["impact"]} for k, v in processes.items()
+        }
         dump["jarvis"] = {models.settings.pid: ["Main Process"]}
     logger.debug("Processes data: %s", dump)
     process_map.add(dump)
 
 
-def start_processes(func_name: str = None) -> Union[Process, Dict[str, Process]]:
+def start_processes(func_name: str = None) -> Process | Dict[str, Process]:
     """Initiates multiple background processes to achieve parallelization.
 
     Args:
         func_name: Name of the function that has to be started.
 
     Returns:
-        Union[Process, Dict[str, Process]]:
+        Process | Dict[str, Process]:
         Returns a process object if a function name is passed, otherwise a mapping of function name and process objects.
 
     See Also:
         - speech_synthesis_api: Initiates docker container for speech synthesis.
         - telegram_api: Initiates polling Telegram API to execute offline commands (if no webhook config is available)
         - jarvis_api: Initiates uvicorn server to process API requests, stock monitor and robinhood report generation.
         - background_tasks: Initiates internal background tasks, cron jobs, alarms, reminders, events and meetings sync.
         - plot_mic: Initiates plotting realtime microphone usage using matplotlib.
     """
-    process_dict = {
-        jarvis_api.__name__: Process(target=jarvis_api),  # no process map removal
-        offline.background_tasks.__name__: Process(target=offline.background_tasks),  # no process map removal
-        speech_synthesis.speech_synthesis_api.__name__: Process(target=speech_synthesis.speech_synthesis_api),
-        telegram.telegram_api.__name__: Process(target=telegram.telegram_api)
-    }
-    if models.env.plot_mic:
-        statement = shutil.which(cmd="python") + " " + graph_mic.__file__
-        process_dict[graph_mic.plot_mic.__name__] = Process(
-            target=crontab.executor,
-            kwargs={'statement': statement,
-                    'log_file': datetime.now().strftime(os.path.join('logs', 'mic_plotter_%d-%m-%Y.log')),
-                    'process_name': graph_mic.plot_mic.__name__}
-        )
-    # Used when a single process is requested to be triggered
-    processes: Dict[str, Process] = {func_name: process_dict[func_name]} if func_name else process_dict
+    process_dict = process_map.base()
+    # Used when a single process is requested to be triggered/restarted
+    if func_name:
+        processes: Dict[str, Process] = {func_name: process_dict[func_name]["process"]}
+    else:
+        processes: Dict[str, Process] = {
+            func: process_dict[func]["process"] for func in process_dict.keys()
+        }
     for func, process in processes.items():
         process.name = func
         process.start()
-        logger.info("Started function: {func} with PID: {pid}".format(func=func, pid=process.pid))
-    Thread(target=create_process_mapping, kwargs=dict(processes=processes, func_name=func_name)).start()
+        logger.info(
+            "Started function: {func} with PID: {pid}".format(
+                func=func, pid=process.pid
+            )
+        )
+    create_process_mapping(process_dict, func_name)
     return processes[func_name] if func_name else processes
 
 
 def stop_child_processes() -> None:
     """Stops sub processes (for meetings and events) triggered by child processes."""
     children: Dict[str, List[int]] = {}
     with db.connection:
         cursor = db.connection.cursor()
         for child in models.TABLES["children"]:
             # Use f-string or %s as condition cannot be parametrized
             data = cursor.execute(f"SELECT {child} FROM children").fetchall()
-            children[child]: List[int] = util.matrix_to_flat_list([list(filter(None, d)) for d in data if any(d)])
-    logger.info(children)  # Include empty lists so logs have more information but will get skipped when looping anyway
+            children[child]: List[int] = util.matrix_to_flat_list(
+                [list(filter(None, d)) for d in data if any(d)]
+            )
+    logger.info(
+        children
+    )  # Include empty lists so logs have more information but will get skipped when looping anyway
     for category, pids in children.items():
         for pid in pids:
             try:
                 proc = psutil.Process(pid=pid)
             except psutil.NoSuchProcess:
                 # Occurs commonly since child processes run only for a short time and `INSERT or REPLACE` leaves dupes
                 logger.debug("Process [%s] PID not found %d", category, pid)
```

## jarvis/executors/remind.py

```diff
@@ -6,20 +6,27 @@
 
 import pynotification
 
 from jarvis.executors import communicator, files, word_match
 from jarvis.modules.audio import listener, speaker
 from jarvis.modules.conditions import conversation
 from jarvis.modules.logger import logger
-from jarvis.modules.models import models
+from jarvis.modules.models import classes, models
+from jarvis.modules.telegram import bot
 from jarvis.modules.utils import shared, support, util
 
 
-def create_reminder(reminder_time: datetime, message: str, to_about: str, phrase: str,
-                    day: str = None, timer: str = None) -> None:
+def create_reminder(
+    reminder_time: datetime,
+    message: str,
+    to_about: str,
+    phrase: str,
+    day: str = None,
+    timer: str = None,
+) -> None:
     """Updates the reminder file to set a reminder.
 
     Args:
         reminder_time: Time of reminder as a datetime object.
         message: Message to be reminded for.
         to_about: remind to or remind about as said in phrase.
         phrase: Phrase spoken by the user.
@@ -28,178 +35,294 @@
     """
     existing_reminders = files.get_reminders()
     name = find_name(phrase)
     formatted = dict(
         name=name,
         message=message,
         date=reminder_time.date(),
-        reminder_time=reminder_time.strftime("%I:%M %p")
+        reminder_time=reminder_time.strftime("%I:%M %p"),
     )
     name = name or "you"
     if formatted in existing_reminders:
         speaker.speak(text=f"You have a duplicate reminder {models.env.title}!")
         return
     existing_reminders.append(formatted)
     files.put_reminders(data=existing_reminders)
-    logger.info("Reminder created for '%s' at %s", message, reminder_time.strftime("%I:%M %p"))
+    logger.info(
+        "Reminder created for '%s' at %s", message, reminder_time.strftime("%I:%M %p")
+    )
     if timer:
-        response = f"{random.choice(conversation.acknowledgement)}! " \
-                   f"I will remind {name} {to_about} {message}, after {timer}."
+        response = (
+            f"{random.choice(conversation.acknowledgement)}! "
+            f"I will remind {name} {to_about} {message}, after {timer}."
+        )
     elif day in ("today", "tonight", "tomorrow"):
-        response = f"{random.choice(conversation.acknowledgement)}! " \
-                   f"I will remind {name} {to_about} {message}, {day} at {reminder_time.strftime('%I:%M %p')}."
+        response = (
+            f"{random.choice(conversation.acknowledgement)}! "
+            f"I will remind {name} {to_about} {message}, {day} at {reminder_time.strftime('%I:%M %p')}."
+        )
     elif reminder_time.date() == datetime.today().date():
-        response = f"{random.choice(conversation.acknowledgement)}! " \
-                   f"I will remind {name} {to_about} {message}, today at {reminder_time.strftime('%I:%M %p')}."
+        response = (
+            f"{random.choice(conversation.acknowledgement)}! "
+            f"I will remind {name} {to_about} {message}, today at {reminder_time.strftime('%I:%M %p')}."
+        )
     elif day:
-        response = f"{random.choice(conversation.acknowledgement)}! " \
-                   f"I will remind {name} {to_about} {message}, on {day} at {reminder_time.strftime('%I:%M %p')}."
+        response = (
+            f"{random.choice(conversation.acknowledgement)}! "
+            f"I will remind {name} {to_about} {message}, on {day} at {reminder_time.strftime('%I:%M %p')}."
+        )
     else:
-        response = f"{random.choice(conversation.acknowledgement)}! " \
-                   f"I will remind {name} {to_about} {message}, at {reminder_time.strftime('%I:%M %p')}."
+        response = (
+            f"{random.choice(conversation.acknowledgement)}! "
+            f"I will remind {name} {to_about} {message}, at {reminder_time.strftime('%I:%M %p')}."
+        )
     if "every" in phrase:
         response += " For repeated reminders, please use the automation feature."
     speaker.speak(text=response)
 
 
 def find_name(phrase: str) -> str:
     """Looks for names in contact file if there is any matching the phrase."""
     contacts = files.get_contacts()
-    if (name := word_match.word_match(phrase=phrase, match_list=list(contacts.get('phone', {}).keys()))) or \
-            (name := word_match.word_match(phrase=phrase, match_list=list(contacts.get('email', {}).keys()))):
+    if (
+        name := word_match.word_match(
+            phrase=phrase, match_list=list(contacts.get("phone", {}).keys())
+        )
+    ) or (
+        name := word_match.word_match(
+            phrase=phrase, match_list=list(contacts.get("email", {}).keys())
+        )
+    ):
         logger.info("Reminder requested for third party: %s", name)
         return name
 
 
 def get_reminder_state() -> List[str]:
     """Frames a response text with all the reminders present.
 
     Returns:
         List[str]:
         Returns a list of reminders framed as a response.
     """
     reminders = files.get_reminders()
     response = []
     for reminder_ in reminders:
-        if reminder_['name']:
-            response.append(f"{reminder_['message']} to {reminder_['name']} at {reminder_['reminder_time']}")
+        if reminder_["name"]:
+            response.append(
+                f"{reminder_['message']} to {reminder_['name']} at {reminder_['reminder_time']}"
+            )
         else:
             response.append(f"{reminder_['message']} at {reminder_['reminder_time']}")
     return response
 
 
 def reminder(phrase: str) -> None:
     """Passes hour, minute, am/pm and reminder message to Reminder class which initiates a thread for reminder.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
     """
     if models.settings.limited:
-        speaker.speak(text="Reminder features are currently unavailable, as you're running on restricted mode.")
+        speaker.speak(
+            text="Reminder features are currently unavailable, as you're running on restricted mode."
+        )
         return
-    message = re.search(' to (.*) at ', phrase) or re.search(' about (.*) at ', phrase) or \
-        re.search(' to (.*) after ', phrase) or re.search(' about (.*) after ', phrase) or \
-        re.search(' to (.*) in ', phrase) or re.search(' about (.*) in ', phrase) or \
-        re.search(' to (.*)', phrase) or re.search(' about (.*)', phrase)
+    message = (
+        re.search(" to (.*) in ", phrase)
+        or re.search(" about (.*) in ", phrase)
+        or re.search(" to (.*) after ", phrase)
+        or re.search(" about (.*) after ", phrase)
+        or re.search(" to (.*) at ", phrase)
+        or re.search(" about (.*) at ", phrase)
+        or re.search(" to (.*)", phrase)
+        or re.search(" about (.*)", phrase)
+    )
     if not message:
-        if word_match.word_match(phrase=phrase,
-                                 match_list=('get', 'what', 'send', 'list', 'exist', 'existing', 'do', 'have', 'i')):
+        if word_match.word_match(
+            phrase=phrase,
+            match_list=(
+                "get",
+                "what",
+                "send",
+                "list",
+                "exist",
+                "existing",
+                "do",
+                "have",
+                "i",
+            ),
+        ):
             if reminder_list := get_reminder_state():
-                speaker.speak(text=f"You have {len(reminder_list)} reminders {models.env.title}! "
-                                   f"{string.capwords(util.comma_separator(reminder_list))}")
+                speaker.speak(
+                    text=f"You have {len(reminder_list)} reminders {models.env.title}! "
+                    f"{string.capwords(util.comma_separator(reminder_list))}"
+                )
             else:
                 speaker.speak(text=f"You don't have any reminders {models.env.title}!")
             return
-        speaker.speak(text='Reminder format should be::Remind me to do something, at some time.')
+        speaker.speak(
+            text="Reminder format should be::Remind me to do something, at some time."
+        )
         return
-    to_about = 'about' if 'about' in phrase else 'to'
-    if 'minute' in phrase or "now" in phrase:
+    to_about = "about" if "about" in phrase else "to"
+    if "minute" in phrase or "now" in phrase:
         phrase = phrase.replace("a minute", "1 minute").replace("now", "1 minute")
         if minutes := util.extract_nos(input_=phrase, method=int):
-            min_ = 'minutes' if minutes > 1 else 'minute'
-            create_reminder(reminder_time=datetime.now() + timedelta(minutes=minutes), message=message.group(1).strip(),
-                            timer=f"{minutes} {min_}", to_about=to_about, phrase=phrase)
+            min_ = "minutes" if minutes > 1 else "minute"
+            create_reminder(
+                reminder_time=datetime.now() + timedelta(minutes=minutes),
+                message=message.group(1).strip(),
+                timer=f"{minutes} {min_}",
+                to_about=to_about,
+                phrase=phrase,
+            )
             return
-    elif 'hour' in phrase:
+    elif "hour" in phrase:
         if hours := util.extract_nos(input_=phrase, method=int):
-            hour_ = 'hours' if hours > 1 else 'hour'
-            create_reminder(reminder_time=datetime.now() + timedelta(hours=hours), message=message.group(1).strip(),
-                            timer=f"{hours} {hour_}", to_about=to_about, phrase=phrase)
+            hour_ = "hours" if hours > 1 else "hour"
+            create_reminder(
+                reminder_time=datetime.now() + timedelta(hours=hours),
+                message=message.group(1).strip(),
+                timer=f"{hours} {hour_}",
+                to_about=to_about,
+                phrase=phrase,
+            )
             return
     if not (extracted_time := util.extract_time(input_=phrase)):
         if shared.called_by_offline:
-            speaker.speak(text='Reminder format should be::Remind me to do something, at some time.')
+            speaker.speak(
+                text="Reminder format should be::Remind me to do something, at some time."
+            )
             return
-        speaker.speak(text=f"When do you want to be reminded {models.env.title}?", run=True)
+        speaker.speak(
+            text=f"When do you want to be reminded {models.env.title}?", run=True
+        )
         if not (phrase := listener.listen()):
             return
         if not (extracted_time := util.extract_time(input_=phrase)):
             return
     message = message.group(1).strip()
-    extracted_time = extracted_time[0]
-    am_pm = extracted_time.split()[-1]
-    am_pm = str(am_pm).replace('a.m.', 'AM').replace('p.m.', 'PM')
-    remind_time = extracted_time.split()[0]
-    if ":" in extracted_time:
-        hour = int(remind_time.split(":")[0])
-        minute = int(remind_time.split(":")[-1])
-    else:
-        hour = int(remind_time.split()[0])
-        minute = 0
-    # makes sure hour and minutes are two digits
-    hour, minute = f"{hour:02}", f"{minute:02}"
+    hour, minute, am_pm = util.split_time(extracted_time[0])
     if int(hour) <= 12 and int(minute) <= 59:
         reminder_time_ = f"{hour}:{minute} {am_pm}"
         try:
-            reminder_date_, day, _ = support.extract_humanized_date(phrase=phrase, fail_past=True)
-            datetime_obj = datetime.combine(reminder_date_, datetime.strptime(reminder_time_, "%I:%M %p").time())
+            reminder_date_, day, _ = support.extract_humanized_date(
+                phrase=phrase, fail_past=True
+            )
+            datetime_obj = datetime.combine(
+                reminder_date_, datetime.strptime(reminder_time_, "%I:%M %p").time()
+            )
             # if user specifically mentions today or tonight with a time in the past
-            if datetime_obj <= datetime.now() and "today" in phrase or "tonight" in phrase:
+            if (
+                datetime_obj <= datetime.now()
+                and "today" in phrase
+                or "tonight" in phrase
+            ):
                 raise ValueError(f"{datetime_obj!r} is in the past!")
         except ValueError as error:
             logger.error(error)
-            speaker.speak("We are not time travellers yet, so reminders in the past is not a thing.")
+            speaker.speak(
+                "We are not time travellers yet, so reminders in the past is not a thing."
+            )
             return
 
         # if user doesn't specify the date but time is in the past, reminder will be defaulted for the next day
         if datetime_obj.date() == datetime.now().date() and datetime_obj.hour > 17:
             day = "tonight"
         elif datetime_obj <= datetime.now():
             datetime_obj += timedelta(days=1)
             day = "tomorrow"
-        elif datetime_obj.date() == (datetime.now().date() + timedelta(days=1)):  # requested for next day
+        # requested for next day
+        elif datetime_obj.date() == (datetime.now().date() + timedelta(days=1)):
             day = "tomorrow"
 
-        message = message.replace(day, "")  # strip off statements like today, tomorrow, day after tomorrow from message
+        # strip off statements like today, tomorrow, day after tomorrow from message
+        message = message.replace(day, "")
 
-        create_reminder(reminder_time=datetime_obj, to_about=to_about,
-                        message=message, phrase=phrase, day=day)
+        create_reminder(
+            reminder_time=datetime_obj,
+            to_about=to_about,
+            message=message,
+            phrase=phrase,
+            day=day,
+        )
     else:
-        speaker.speak(text=f"A reminder at {hour}:{minute} {am_pm}? Are you an alien? "
-                           f"I don't think a time like that exists on Earth.")
+        speaker.speak(
+            text=f"A reminder at {hour}:{minute} {am_pm}? Are you an alien? "
+            f"I don't think a time like that exists on Earth."
+        )
 
 
 def executor(message: str, contact: str = None) -> None:
-    """Notifies user about the reminder and displays a notification on the device.
+    """Notifies user about the reminder (per the options set in env vars) and displays a notification on the device.
 
     Args:
         message: Takes the reminder message as an argument.
         contact: Name of the person to send the reminder to.
 
     See Also:
+        - Uses phone number to send SMS notification
+        - Uses recipient email address to send email notification
+        - Uses telegram account ID to send a message notification
+        - Uses NTFY topic to send a push notification
+
+    See Also:
         - Personalized icons for `Linux OS <https://wiki.ubuntu.com/Artwork/BreatheIconSet/Icons>`__
     """
-    title = f"REMINDER from Jarvis {datetime.now().strftime('%c')}"
+    if classes.ReminderOptions.all in models.env.notify_reminders:
+        notify_phone, notify_email, notify_telegram, ntfy = True, True, True, True
+    else:
+        notify_phone = classes.ReminderOptions.phone in models.env.notify_reminders
+        notify_email = classes.ReminderOptions.email in models.env.notify_reminders
+        notify_telegram = (
+            classes.ReminderOptions.telegram in models.env.notify_reminders
+        )
+        ntfy = classes.ReminderOptions.ntfy in models.env.notify_reminders
+    title = f"REMINDER from Jarvis - {datetime.now().strftime('%c')}"
     if contact:
         contacts = files.get_contacts()
-        if phone := contacts.get('phone', {}).get(contact):
-            communicator.send_sms(user=models.env.gmail_user, password=models.env.gmail_pass,
-                                  number=phone, body=message, subject=title)
-        if email := contacts.get('email', {}).get(contact):
-            communicator.send_email(gmail_user=models.env.open_gmail_user, gmail_pass=models.env.open_gmail_pass,
-                                    recipient=email, subject=title, body=message)
+        if notify_phone and (phone := contacts.get("phone", {}).get(contact)):
+            communicator.send_sms(
+                user=models.env.gmail_user,
+                password=models.env.gmail_pass,
+                number=phone,
+                body=message,
+                subject=title,
+            )
+        if notify_email and (email := contacts.get("email", {}).get(contact)):
+            communicator.send_email(
+                gmail_user=models.env.open_gmail_user,
+                gmail_pass=models.env.open_gmail_pass,
+                recipient=email,
+                subject=title,
+                body=message,
+            )
+        if notify_telegram and (chat_id := contacts.get("telegram", {}).get(contact)):
+            bot.send_message(chat_id=int(chat_id), response=f"*{title}*\n\n{message}")
+        if ntfy and (ntfy_topic := contacts.get("ntfy", {}).get(contact)):
+            communicator.ntfy_send(topic=ntfy_topic, title=title, message=message)
         return
-    communicator.send_sms(user=models.env.gmail_user, password=models.env.gmail_pass, number=models.env.phone_number,
-                          body=message, subject=title)
-    communicator.send_email(gmail_user=models.env.open_gmail_user, gmail_pass=models.env.open_gmail_pass,
-                            recipient=models.env.recipient, subject=title, body=message)
+    if notify_phone and models.env.phone_number:
+        communicator.send_sms(
+            user=models.env.gmail_user,
+            password=models.env.gmail_pass,
+            number=models.env.phone_number,
+            body=message,
+            subject=title,
+        )
+    if notify_email and models.env.recipient:
+        communicator.send_email(
+            gmail_user=models.env.open_gmail_user,
+            gmail_pass=models.env.open_gmail_pass,
+            recipient=models.env.recipient,
+            subject=title,
+            body=message,
+        )
+    if notify_telegram and models.env.telegram_id:
+        bot.send_message(
+            chat_id=models.env.telegram_id, response=f"*{title}*\n\n{message}"
+        )
+    if ntfy and models.env.ntfy_topic:
+        communicator.ntfy_send(
+            topic=models.env.ntfy_topic, title=title, message=message
+        )
     pynotification.pynotifier(title=title, message=message, debug=True, logger=logger)
```

## jarvis/executors/restrictions.py

```diff
@@ -21,16 +21,18 @@
     """
     if not (restricted_functions := files.get_restrictions()):
         logger.debug("No restrictions in place.")
         return False
     for category, identifiers in keywords.keywords.items():
         if word_match.word_match(phrase=phrase, match_list=identifiers):
             if category in restricted_functions:
-                speaker.speak(text=f"I'm sorry {models.env.title}! "
-                                   f"{string.capwords(category)} category is restricted via offline communicator.")
+                speaker.speak(
+                    text=f"I'm sorry {models.env.title}! "
+                    f"{string.capwords(category)} category is restricted via offline communicator."
+                )
                 return True
 
 
 def get_func(phrase: str) -> str:
     """Extract function name from the phrase.
 
     Args:
@@ -50,15 +52,17 @@
     elif "on" in phrase:
         func = phrase.split("on")[1].strip()
     elif "restrict" in phrase:
         func = phrase.split("restrict")[1].strip()
     elif "release" in phrase:
         func = phrase.split("release")[1].strip()
     else:
-        raise InvalidArgument("Please specify a valid function name to add or remove restrictions.")
+        raise InvalidArgument(
+            "Please specify a valid function name to add or remove restrictions."
+        )
     function_names = list(functions.function_mapping().keys())
     if func in function_names:
         return func
     raise InvalidArgument(f"No such function present. Valid: {function_names}")
 
 
 def handle_restrictions(phrase: str) -> str:
@@ -73,15 +77,17 @@
 
     Returns:
         str:
         Returns the response as a string.
     """
     phrase = phrase.lower()
     current_restrictions = files.get_restrictions()
-    if word_match.word_match(phrase=phrase, match_list=("get", "current", "exist", "present")):
+    if word_match.word_match(
+        phrase=phrase, match_list=("get", "current", "exist", "present")
+    ):
         if current_restrictions:
             return f"Current restrictions are: {util.comma_separator(current_restrictions)}"
         return "Currently, there are no restrictions for offline communicators."
     if "add" in phrase or "restrict" in phrase:
         func = get_func(phrase)
         if func in current_restrictions:
             return f"Restriction for {string.capwords(func)} is already in place {models.env.title}!"
@@ -92,8 +98,10 @@
         func = get_func(phrase)
         if func in current_restrictions:
             current_restrictions.remove(func)
             files.put_restrictions(restrictions=current_restrictions)
             return f"{string.capwords(func)} has been removed from restricted functions {models.env.title}!"
         else:
             return f"Restriction for {string.capwords(func)} was never in place {models.env.title}!"
-    raise InvalidArgument("Please specify the function that has to be added or removed from the restrictions' list.")
+    raise InvalidArgument(
+        "Please specify the function that has to be added or removed from the restrictions' list."
+    )
```

## jarvis/executors/robinhood.py

```diff
@@ -1,30 +1,38 @@
 """Initiates robinhood client to get the portfolio details."""
 
 import math
 
 from pyrh import Robinhood
-from pyrh.exceptions import InvalidInstrumentId, InvalidTickerSymbol
+from pyrh.exceptions import AuthenticationError, PyrhException
 
 from jarvis.modules.audio import speaker
 from jarvis.modules.database import database
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.utils import support
 
 db = database.Database(database=models.fileio.base_db)
 
 
-def watcher(rh, result: list) -> str:
+def get_summary() -> str:
     """Fetches all necessary information about the user's investment portfolio.
 
     Returns:
         str:
         A string value of total purchased stocks and resultant profit/loss.
     """
+    rh = Robinhood(
+        username=models.env.robinhood_user,
+        password=models.env.robinhood_pass,
+        mfa=models.env.robinhood_qr,
+    )
+    rh.login()
+    raw_result = rh.positions()
+    result = raw_result["results"]
     shares_total = []
     loss_total = []
     profit_total = []
     n = 0
     n_ = 0
     for data in result:
         share_id = str(data["instrument"].split("/")[-2])
@@ -33,56 +41,82 @@
         if shares_count != 0:
             n = n + 1
             n_ = n_ + shares_count
         else:
             continue
         try:
             raw_details = rh.get_quote(share_id)
-        except (InvalidTickerSymbol, InvalidInstrumentId) as error:
+        except PyrhException as error:
             logger.error(error)
             continue
         total = round(shares_count * float(buy), 2)
         shares_total.append(total)
-        current = (round(float(raw_details["last_trade_price"]), 2))
+        current = round(float(raw_details["last_trade_price"]), 2)
         current_total = round(shares_count * current, 2)
-        difference = round(float(current_total - total), 2)  # calculates difference between current and purchased total
+        difference = round(
+            float(current_total - total), 2
+        )  # calculates difference between current and purchased total
         if difference < 0:
             loss_total.append(-difference)
         else:
             profit_total.append(difference)
 
-    net_worth = round(rh.equity())
+    portfolio = rh.portfolio()
+    net_worth = round(float(portfolio.equity))
+    withdrawable_amount = round(float(portfolio.withdrawable_amount))
     total_buy = round(math.fsum(shares_total))
-    total_diff = round(net_worth - total_buy)
+    total_diff = round(net_worth - total_buy) - withdrawable_amount
 
-    output = f"You have purchased {n:,} stocks and currently own {n_:,} shares {models.env.title}. " \
-             f"Your total investment is ${net_worth:,} now, and it was ${total_buy:,} when you purchased. "
+    output = (
+        f"You have purchased {n:,} stocks and currently own {n_:,} shares {models.env.title}. "
+        f"Your total investment is ${net_worth:,} now, and it was ${total_buy:,} when you purchased. "
+        f"Your current withdrawable amount is ${withdrawable_amount:,}. "
+    )
 
     if total_diff < 0:
         output += f"Currently we are on an overall loss of ${total_diff:,} {models.env.title}."
     else:
         output += f"Currently we are on an overall profit of ${total_diff:,} {models.env.title}."
 
     return output
 
 
 def robinhood(*args) -> None:
     """Gets investment details from robinhood API."""
-    if not all([models.env.robinhood_user, models.env.robinhood_pass, models.env.robinhood_qr]):
+    if not all(
+        [models.env.robinhood_user, models.env.robinhood_pass, models.env.robinhood_qr]
+    ):
         logger.warning("Robinhood username, password or QR code not found.")
         support.no_env_vars()
         return
 
     # Tries to get information from DB from the hourly CRON job for stock report
     with db.connection:
         cursor = db.connection.cursor()
         state = cursor.execute("SELECT summary FROM robinhood").fetchone()
     if state and state[0]:
-        logger.info("Retrieved summary stored by hourly stock report")
+        logger.info("Retrieved previously stored summary")
         speaker.speak(text=state[0])
         return
-    rh = Robinhood()
-    rh.login(username=models.env.robinhood_user, password=models.env.robinhood_pass, qr_code=models.env.robinhood_qr)
-    raw_result = rh.positions()
-    result = raw_result["results"]
-    stock_value = watcher(rh, result)
-    speaker.speak(text=stock_value)
+    try:
+        summary = get_summary()
+    except AuthenticationError as error:
+        logger.error(error)
+        speaker.speak(
+            text=f"I'm sorry {models.env.title}! I ran into an authentication error."
+        )
+        return
+    except PyrhException as error:
+        logger.error(error)
+        speaker.speak(
+            text=f"I'm sorry {models.env.title}! I wasn't able to fetch your investment summary."
+        )
+        return
+    speaker.speak(text=summary)
+    with db.connection:
+        cursor = db.connection.cursor()
+        cursor.execute("DELETE FROM robinhood;")
+        cursor.execute(
+            "INSERT or REPLACE INTO robinhood (summary) VALUES (?);", (summary,)
+        )
+        db.connection.commit()
+    logger.info("Stored summary in database.")
```

## jarvis/executors/simulator.py

```diff
@@ -34,15 +34,17 @@
 def initiate_simulator(simulation_data: Dict[str, List[str]]) -> None:
     """Runs simulation on a preset of phrases.
 
     Args:
         simulation_data: A key value pair of category and phrase list.
     """
     start = time.time()
-    log_file = multiprocessing_logger(filename=os.path.join('logs', 'simulation_%d-%m-%Y_%H:%M_%p.log'))
+    log_file = multiprocessing_logger(
+        filename=os.path.join("logs", "simulation_%d-%m-%Y_%H:%M_%p.log")
+    )
     successful, failed = 0, 0
     shared.called_by_offline = True
     for category, task_list in simulation_data.items():
         logger.info("Requesting category: %s", category)
         for task in task_list:
             logger.info("Request: %s", task)
             try:
@@ -54,32 +56,42 @@
                 if not response or response.startswith("I was unable to process"):
                     failed += 1
                 else:
                     successful += 1
                     logger.info("Response: %s", response)
     shared.called_by_offline = False
     with open(log_file) as file:
-        errors = len(file.read().split('ERROR')) - 1
-    mail_obj = gmailconnector.SendEmail(gmail_user=models.env.open_gmail_user, gmail_pass=models.env.open_gmail_pass)
-    mail_res = mail_obj.send_email(subject=f"Simulation results - {datetime.now().strftime('%c')}",
-                                   attachment=log_file, recipient=models.env.recipient, sender="Jarvis Simulator",
-                                   body=f"Total simulations attempted: {sum(len(i) for i in simulation_data.values())}"
-                                        f"\n\nSuccessful: {successful}\n\nFailed: {failed}\n\nError-ed: {errors}\n\n"
-                                        f"Run Time: {support.time_converter(second=time.time() - start)}")
+        errors = len(file.read().split("ERROR")) - 1
+    mail_obj = gmailconnector.SendEmail(
+        gmail_user=models.env.open_gmail_user, gmail_pass=models.env.open_gmail_pass
+    )
+    mail_res = mail_obj.send_email(
+        subject=f"Simulation results - {datetime.now().strftime('%c')}",
+        attachment=log_file,
+        recipient=models.env.recipient,
+        sender="Jarvis Simulator",
+        body=f"Total simulations attempted: {sum(len(i) for i in simulation_data.values())}"
+        f"\n\nSuccessful: {successful}\n\nFailed: {failed}\n\nError-ed: {errors}\n\n"
+        f"Run Time: {support.time_converter(second=time.time() - start)}",
+    )
     if mail_res.ok:
         logger.info("Test result has been sent via email")
     else:
         logger.critical("ATTENTION::Failed to send test results via email")
         logger.critical(mail_res.json())
 
 
 def simulation(*args) -> None:
     """Initiates simulation in a dedicated process logging into a dedicated file."""
     simulation_data = get_simulation_data()
     if not simulation_data:
-        speaker.speak(f"There are no metrics for me to run a simulation {models.env.title}!")
+        speaker.speak(
+            f"There are no metrics for me to run a simulation {models.env.title}!"
+        )
         return
     process = Process(target=initiate_simulator, args=(simulation_data,))
     process.name = "simulator"
     process.start()
-    speaker.speak(text=f"Initiated simulation {models.env.title}! "
-                       "I will send you an email with the results once it is complete.")
+    speaker.speak(
+        text=f"Initiated simulation {models.env.title}! "
+        "I will send you an email with the results once it is complete."
+    )
```

## jarvis/executors/static_responses.py

```diff
@@ -11,59 +11,84 @@
 def form(*args) -> None:
     """Response for form."""
     speaker.speak(text="I am a program, I'm without form.")
 
 
 def greeting(*args) -> None:
     """Response for greeting."""
-    speaker.speak(text=random.choice(['I am spectacular. I hope you are doing fine too.', 'I am doing well. Thank you.',
-                                      'I am great. Thank you.']))
+    speaker.speak(
+        text=random.choice(
+            [
+                "I am spectacular. I hope you are doing fine too.",
+                "I am doing well. Thank you.",
+                "I am great. Thank you.",
+            ]
+        )
+    )
 
 
 def capabilities(*args) -> None:
     """Response for capabilities."""
-    speaker.speak(text='There is a lot I can do. For example: I can get you the weather at any location, news around '
-                       'you, meanings of words, launch applications, create a to-do list, check your emails, get your '
-                       'system configuration, tell your investment details, locate your phone, find distance between '
-                       'places, set an alarm, play music on smart devices around you, control your TV, tell a joke, '
-                       'send a message, set reminders, scan and clone your GitHub repositories, and much more. '
-                       'Time to ask,.')
+    speaker.speak(
+        text="There is a lot I can do. For example: I can get you the weather at any location, news around "
+        "you, meanings of words, launch applications, create a to-do list, check your emails, get your "
+        "system configuration, tell your investment details, locate your phone, find distance between "
+        "places, set an alarm, play music on smart devices around you, control your TV, tell a joke, "
+        "send a message, set reminders, scan and clone your GitHub repositories, and much more. "
+        "Time to ask,."
+    )
 
 
 def languages(*args) -> None:
     """Response for languages."""
-    speaker.speak(text="Tricky question!. I'm configured in python, and I can speak English.")
+    speaker.speak(
+        text="Tricky question!. I'm configured in python, and I can speak English."
+    )
 
 
 def whats_up(*args) -> None:
     """Response for what's up."""
-    speaker.speak(text="My listeners are up. There is nothing I cannot process. So ask me anything..")
+    speaker.speak(
+        text="My listeners are up. There is nothing I cannot process. So ask me anything.."
+    )
 
 
 def what(*args) -> None:
     """Response for what."""
-    speaker.speak(text="The name is Jarvis. I'm just a pre-programmed virtual assistant.")
+    speaker.speak(
+        text="The name is Jarvis. I'm just a pre-programmed virtual assistant."
+    )
 
 
 def hi(*args) -> None:
     """Response for hi and hello."""
-    speaker.speak(text="Hello there! My name is Jarvis" +
-                       random.choice((f", good {util.part_of_day()}! How can I be of service today?",
-                                      ", and I'm ready to assist you. How can I help you today?")))
+    speaker.speak(
+        text="Hello there! My name is Jarvis"
+        + random.choice(
+            (
+                f", good {util.part_of_day()}! How can I be of service today?",
+                ", and I'm ready to assist you. How can I help you today?",
+            )
+        )
+    )
 
 
 def who(*args) -> None:
     """Response for whom."""
     speaker.speak(text="I am Jarvis. A virtual assistant designed by Mr.Raauv.")
 
 
 def age(*args) -> None:
     """Response for age."""
-    relative_date = relativedelta(dt1=datetime.strptime(datetime.strftime(datetime.now(), "%Y-%m-%d"), "%Y-%m-%d"),
-                                  dt2=datetime.strptime("2020-09-06", "%Y-%m-%d"))
+    relative_date = relativedelta(
+        dt1=datetime.strptime(
+            datetime.strftime(datetime.now(), "%Y-%m-%d"), "%Y-%m-%d"
+        ),
+        dt2=datetime.strptime("2020-09-06", "%Y-%m-%d"),
+    )
     statement = f"{relative_date.years} years, {relative_date.months} months and {relative_date.days} days"
     if not relative_date.years:
         statement = statement.replace(f"{relative_date.years} years, ", "")
     elif relative_date.years == 1:
         statement = statement.replace("years", "year")
     if not relative_date.months:
         statement = statement.replace(f"{relative_date.months} months", "")
@@ -74,20 +99,24 @@
     elif relative_date.days == 1:
         statement = statement.replace("days", "day")
     speaker.speak(text=f"I'm {statement} old.")
 
 
 def about_me(*args) -> None:
     """Response for about me."""
-    speaker.speak(text="I am Jarvis. I am a virtual assistant designed by Mr. Raauv. "
-                       "Given enough access I can be your home assistant. "
-                       "I can seamlessly take care of your daily tasks, and also help with most of your work!")
+    speaker.speak(
+        text="I am Jarvis. I am a virtual assistant designed by Mr. Raauv. "
+        "Given enough access I can be your home assistant. "
+        "I can seamlessly take care of your daily tasks, and also help with most of your work!"
+    )
 
 
 def not_allowed_offline() -> None:
     """Response for tasks not supported via offline communicator."""
     speaker.speak(text="That's not supported via offline communicator.")
 
 
 def un_processable() -> None:
     """Speaker response for un-processable requests."""
-    speaker.speak(text=f"I'm sorry {models.env.title}! I wasn't able to process your request.")
+    speaker.speak(
+        text=f"I'm sorry {models.env.title}! I wasn't able to process your request."
+    )
```

## jarvis/executors/system.py

```diff
@@ -20,147 +20,202 @@
 
 def system_info(*args) -> None:
     """Tells the system configuration."""
     disk_usage = shutil.disk_usage("/")
     total = support.size_converter(byte_size=disk_usage.total)
     used = support.size_converter(byte_size=disk_usage.used)
     free = support.size_converter(byte_size=disk_usage.free)
-    ram = support.size_converter(byte_size=models.settings.ram).replace('.0', '')
-    ram_used = support.size_converter(byte_size=psutil.virtual_memory().percent).replace(' B', ' %')
+    ram = support.size_converter(byte_size=models.settings.ram).replace(".0", "")
+    ram_used = support.size_converter(
+        byte_size=psutil.virtual_memory().percent
+    ).replace(" B", " %")
     system = None
     if models.settings.os == models.supported_platforms.linux:
         mapping = get_distributor_info_linux()
-        if mapping.get('distributor_id') and mapping.get('release'):
+        if mapping.get("distributor_id") and mapping.get("release"):
             system = f"{mapping['distributor_id']} {mapping['release']}"
     if not system:
-        if not shared.hosted_device.get('os_version'):
+        if not shared.hosted_device.get("os_version"):
             hosted_device_info()
-        system = f"{shared.hosted_device.get('os_name', models.settings.os)} " \
-                 f"{shared.hosted_device.get('os_version', '')}"
-    speaker.speak(text=f"You're running {system}, with {models.settings.physical_cores} "
-                       f"physical cores, and {models.settings.logical_cores} logical cores. Your physical drive "
-                       f"capacity is {total}. You have used up {used} of space. Your free space is {free}. Your "
-                       f"RAM capacity is {ram}. You are currently utilizing {ram_used} of your memory.")
+        system = (
+            f"{shared.hosted_device.get('os_name', models.settings.os)} "
+            f"{shared.hosted_device.get('os_version', '')}"
+        )
+    speaker.speak(
+        text=f"You're running {system}, with {models.settings.physical_cores} "
+        f"physical cores, and {models.settings.logical_cores} logical cores. Your physical drive "
+        f"capacity is {total}. You have used up {used} of space. Your free space is {free}. Your "
+        f"RAM capacity is {ram}. You are currently utilizing {ram_used} of your memory."
+    )
 
 
 def system_vitals(*args) -> None:
     """Reads system vitals.
 
     See Also:
         - Jarvis will suggest a reboot if the system uptime is more than 2 days.
         - If confirmed, invokes `restart <https://jarvis-docs.vigneshrao.com/#jarvis.restart>`__ function.
     """
     output = ""
     if models.settings.os == models.supported_platforms.macOS:
         if not models.env.root_password:
-            speaker.speak(text=f"You haven't provided a root password for me to read system vitals {models.env.title}! "
-                               "Add the root password as an environment variable for me to read.")
+            speaker.speak(
+                text=f"You haven't provided a root password for me to read system vitals {models.env.title}! "
+                "Add the root password as an environment variable for me to read."
+            )
             return
 
-        logger.info('Fetching system vitals')
+        logger.info("Fetching system vitals")
         cpu_temp, gpu_temp, fan_speed, output = None, None, None, ""
 
         # Tested on 10.13, 10.14, 11.6 and 12.3 versions
-        if not shared.hosted_device.get('os_version'):
+        if not shared.hosted_device.get("os_version"):
             hosted_device_info()
-        if packaging.version.parse(shared.hosted_device.get('os_version')) > packaging.version.parse('10.14'):
-            critical_info = [each.strip() for each in (os.popen(
-                f'echo {models.env.root_password} | sudo -S powermetrics --samplers smc -i1 -n1'
-            )).read().split('\n') if each != '']
+        if packaging.version.parse(
+            shared.hosted_device.get("os_version")
+        ) > packaging.version.parse("10.14"):
+            critical_info = [
+                each.strip()
+                for each in (
+                    os.popen(
+                        f"echo {models.env.root_password} | sudo -S powermetrics --samplers smc -i1 -n1"
+                    )
+                )
+                .read()
+                .split("\n")
+                if each != ""
+            ]
             support.flush_screen()
 
             for info in critical_info:
-                if 'CPU die temperature' in info:
-                    cpu_temp = info.strip('CPU die temperature: ').replace(' C', '').strip()
-                if 'GPU die temperature' in info:
-                    gpu_temp = info.strip('GPU die temperature: ').replace(' C', '').strip()
-                if 'Fan' in info:
-                    fan_speed = info.strip('Fan: ').replace(' rpm', '').strip()
+                if "CPU die temperature" in info:
+                    cpu_temp = (
+                        info.strip("CPU die temperature: ").replace(" C", "").strip()
+                    )
+                if "GPU die temperature" in info:
+                    gpu_temp = (
+                        info.strip("GPU die temperature: ").replace(" C", "").strip()
+                    )
+                if "Fan" in info:
+                    fan_speed = info.strip("Fan: ").replace(" rpm", "").strip()
         else:
             fan_speed = subprocess.check_output(
-                f'echo {models.env.root_password} | sudo -S spindump 1 1 -file /tmp/spindump.txt > /dev/null 2>&1;grep '
-                f'"Fan speed" /tmp/spindump.txt;sudo rm /tmp/spindump.txt', shell=True
-            ).decode('utf-8')
+                f"echo {models.env.root_password} | sudo -S spindump 1 1 -file /tmp/spindump.txt > /dev/null 2>&1;grep "
+                f'"Fan speed" /tmp/spindump.txt;sudo rm /tmp/spindump.txt',
+                shell=True,
+            ).decode("utf-8")
 
         if cpu_temp:
             if models.env.temperature_unit == models.TemperatureUnits.METRIC:
                 cpu_temp = util.format_nos(input_=util.extract_nos(input_=cpu_temp))
             else:
-                cpu_temp = util.format_nos(input_=temperature.c2f(arg=util.extract_nos(input_=cpu_temp)))
-            cpu = f'Your current average CPU temperature is {cpu_temp}\N{DEGREE SIGN}{models.temperature_symbol}. '
+                cpu_temp = util.format_nos(
+                    input_=temperature.c2f(arg=util.extract_nos(input_=cpu_temp))
+                )
+            cpu = f"Your current average CPU temperature is {cpu_temp}\N{DEGREE SIGN}{models.temperature_symbol}. "
             output += cpu
             speaker.speak(text=cpu)
         if gpu_temp:
             if models.env.temperature_unit == models.TemperatureUnits.METRIC:
                 gpu_temp = util.format_nos(input_=util.extract_nos(input_=gpu_temp))
             else:
-                gpu_temp = util.format_nos(input_=temperature.c2f(arg=util.extract_nos(input_=gpu_temp)))
-            gpu = f'GPU temperature is {gpu_temp}\N{DEGREE SIGN}{models.temperature_symbol}. '
+                gpu_temp = util.format_nos(
+                    input_=temperature.c2f(arg=util.extract_nos(input_=gpu_temp))
+                )
+            gpu = f"GPU temperature is {gpu_temp}\N{DEGREE SIGN}{models.temperature_symbol}. "
             output += gpu
             speaker.speak(text=gpu)
         if fan_speed:
-            fan = f'Current fan speed is {util.format_nos(util.extract_nos(fan_speed))} RPM. '
+            fan = f"Current fan speed is {util.format_nos(util.extract_nos(fan_speed))} RPM. "
             output += fan
             speaker.speak(text=fan)
 
     restart_time = datetime.fromtimestamp(psutil.boot_time())
     second = (datetime.now() - restart_time).total_seconds()
     restart_time = datetime.strftime(restart_time, "%A, %B %d, at %I:%M %p")
     restart_duration = support.time_converter(second=second)
-    output += f'Restarted on: {restart_time} - {restart_duration} ago from now.'
+    output += f"Restarted on: {restart_time} - {restart_duration} ago from now."
     if shared.called_by_offline:
         speaker.speak(text=output)
         return
     support.write_screen(text=output)
-    speaker.speak(text=f"Your {shared.hosted_device.get('device')} was last booted on {restart_time}. "
-                       f"Current boot time is: {restart_duration}.")
+    speaker.speak(
+        text=f"Your {shared.hosted_device.get('device')} was last booted on {restart_time}. "
+        f"Current boot time is: {restart_duration}."
+    )
     if second >= 259_200:  # 3 days
-        if boot_extreme := re.search('(.*) days', restart_duration):
-            warn = int(boot_extreme.group().replace(' days', '').strip())
-            speaker.speak(text=f"{models.env.title}! your {shared.hosted_device.get('device')} has been running for "
-                               f"more than {warn} days. You must consider a reboot for better performance. Would you "
-                               f"like me to restart it for you {models.env.title}?",
-                          run=True)
-            if word_match.word_match(phrase=listener.listen(), match_list=keywords.keywords['ok']):
-                logger.info("Restarting %s", shared.hosted_device.get('device'))
+        if boot_extreme := re.search("(.*) days", restart_duration):
+            warn = int(boot_extreme.group().replace(" days", "").strip())
+            speaker.speak(
+                text=f"{models.env.title}! your {shared.hosted_device.get('device')} has been running for "
+                f"more than {warn} days. You must consider a reboot for better performance. Would you "
+                f"like me to restart it for you {models.env.title}?",
+                run=True,
+            )
+            if word_match.word_match(
+                phrase=listener.listen(), match_list=keywords.keywords["ok"]
+            ):
+                logger.info("Restarting %s", shared.hosted_device.get("device"))
                 controls.restart(ask=False)
 
 
 def get_distributor_info_linux() -> Dict[str, str]:
     """Returns distributor information (i.e., Ubuntu) for Linux based systems.
 
     Returns:
         dict:
         A dictionary of key-value pairs with distributor id, name and version.
     """
     try:
-        result = subprocess.check_output('lsb_release -a', shell=True, stderr=subprocess.DEVNULL)
-        return {i.split(':')[0].strip().lower().replace(' ', '_'): i.split(':')[1].strip()
-                for i in result.decode(encoding="UTF-8").splitlines() if ':' in i}
+        result = subprocess.check_output(
+            "lsb_release -a", shell=True, stderr=subprocess.DEVNULL
+        )
+        return {
+            i.split(":")[0].strip().lower().replace(" ", "_"): i.split(":")[1].strip()
+            for i in result.decode(encoding="UTF-8").splitlines()
+            if ":" in i
+        }
     except (subprocess.SubprocessError, subprocess.CalledProcessError) as error:
         if isinstance(error, subprocess.CalledProcessError):
-            result = error.output.decode(encoding='UTF-8').strip()
+            result = error.output.decode(encoding="UTF-8").strip()
             logger.error("[%d]: %s", error.returncode, result)
         else:
             logger.error(error)
         return {}
 
 
 def hosted_device_info() -> Dict[str, str]:
     """Gets basic information of the hosted device.
 
     Returns:
         dict:
         A dictionary of key-value pairs with device type, operating system, os version.
     """
     if models.settings.os == models.supported_platforms.macOS:
-        system_kernel = subprocess.check_output("sysctl hw.model", shell=True).decode('utf-8').splitlines()
-        device = util.extract_str(system_kernel[0].split(':')[1])
+        system_kernel = (
+            subprocess.check_output("sysctl hw.model", shell=True)
+            .decode("utf-8")
+            .splitlines()
+        )
+        device = util.extract_str(system_kernel[0].split(":")[1])
     elif models.settings.os == models.supported_platforms.windows:
-        device = subprocess.getoutput("WMIC CSPRODUCT GET VENDOR").replace('Vendor', '').strip()
+        device = (
+            subprocess.getoutput("WMIC CSPRODUCT GET VENDOR")
+            .replace("Vendor", "")
+            .strip()
+        )
     else:
-        device = subprocess.check_output("cat /sys/devices/virtual/dmi/id/product_name",
-                                         shell=True).decode('utf-8').strip()
-    platform_info = platform.platform(terse=True).split('-')
-    device_data = {'device': device, 'os_name': platform_info[0], 'os_version': platform_info[1]}
+        device = (
+            subprocess.check_output(
+                "cat /sys/devices/virtual/dmi/id/product_name", shell=True
+            )
+            .decode("utf-8")
+            .strip()
+        )
+    platform_info = platform.platform(terse=True).split("-")
+    device_data = {
+        "device": device,
+        "os_name": platform_info[0],
+        "os_version": platform_info[1],
+    }
     shared.hosted_device = device_data
     return device_data
```

## jarvis/executors/telegram.py

```diff
@@ -1,24 +1,23 @@
 import importlib
 import logging
 import os
 import time
 from urllib.parse import urljoin
 
 from jarvis.executors import controls, internet, process_map
-from jarvis.modules.exceptions import (BotInUse, BotWebhookConflict,
-                                       EgressErrors)
+from jarvis.modules.exceptions import BotInUse, BotWebhookConflict, EgressErrors
 from jarvis.modules.logger import logger, multiprocessing_logger
 from jarvis.modules.models import models
 from jarvis.modules.telegram import bot, webhook
 from jarvis.modules.utils import support
 
 importlib.reload(module=logging)
 
-FAILED_CONNECTIONS = {'count': 0}
+FAILED_CONNECTIONS = {"count": 0}
 
 
 def get_webhook_origin(retry: int) -> str:
     """Get the telegram bot webhook origin.
 
     Args:
         retry: Number of retry attempts to get public URL.
@@ -27,15 +26,17 @@
         str:
         Public URL where the telegram webhook is hosted.
     """
     if models.env.bot_webhook:
         return str(models.env.bot_webhook)
     for i in range(retry):
         if url := internet.get_tunnel():
-            logger.info("Public URL was fetched on %s attempt", support.ENGINE.ordinal(i + 1))
+            logger.info(
+                "Public URL was fetched on %s attempt", support.ENGINE.ordinal(i + 1)
+            )
             return url
         time.sleep(3)
 
 
 def telegram_api(webhook_trials: int = 20) -> None:
     """Initiates polling for new messages.
 
@@ -46,20 +47,24 @@
         - ``webhook_trials`` is set to 3 when polling fails (which is already a fallback for webhook retries)
 
     Handles:
         - BotWebhookConflict: When there's a broken webhook set already.
         - BotInUse: Restarts polling to take control over.
         - EgressErrors: Initiates after 10, 20 or 30 seconds. Depends on retry count. Restarts after 3 attempts.
     """
-    multiprocessing_logger(filename=os.path.join('logs', 'telegram_api_%d-%m-%Y.log'))
+    multiprocessing_logger(filename=os.path.join("logs", "telegram_api_%d-%m-%Y.log"))
     if not models.env.bot_token:
         logger.info("Bot token is required to start the Telegram Bot")
         return
-    if (public_url := get_webhook_origin(webhook_trials)) and (response := webhook.set_webhook(
-            base_url=bot.BASE_URL, webhook=urljoin(public_url, models.env.bot_endpoint), logger=logger)
+    if (public_url := get_webhook_origin(webhook_trials)) and (
+        response := webhook.set_webhook(
+            base_url=bot.BASE_URL,
+            webhook=urljoin(public_url, models.env.bot_endpoint),
+            logger=logger,
+        )
     ):
         logger.info("Telegram API will be hosted via webhook.")
         logger.info(response)
         process_map.remove(telegram_api.__name__)
         return
     try:
         bot.poll_for_messages()
@@ -70,18 +75,20 @@
         telegram_api(3)
     except BotInUse as error:
         logger.error(error)
         logger.info("Restarting message poll to take over..")
         telegram_api(3)
     except EgressErrors as error:
         logger.error(error)
-        FAILED_CONNECTIONS['count'] += 1
-        if FAILED_CONNECTIONS['count'] > 3:
-            logger.critical("ATTENTION::Couldn't recover from connection error. Restarting current process.")
+        FAILED_CONNECTIONS["count"] += 1
+        if FAILED_CONNECTIONS["count"] > 3:
+            logger.critical(
+                "ATTENTION::Couldn't recover from connection error. Restarting current process."
+            )
             controls.restart_control(quiet=True)
         else:
-            logger.info("Restarting in %d seconds.", FAILED_CONNECTIONS['count'] * 10)
-            time.sleep(FAILED_CONNECTIONS['count'] * 10)
+            logger.info("Restarting in %d seconds.", FAILED_CONNECTIONS["count"] * 10)
+            time.sleep(FAILED_CONNECTIONS["count"] * 10)
             telegram_api(3)
     except Exception as error:
         logger.critical("ATTENTION: %s", error.__str__())
         controls.restart_control(quiet=True)
```

## jarvis/executors/thermostat.py

```diff
@@ -1,158 +1,196 @@
 import time
 from threading import Thread
-from typing import Union
 
-from pyhtcc import (AuthenticationError, NoZonesFoundError, PyHTCC,
-                    UnauthorizedError, Zone)
+from pyhtcc import AuthenticationError, LoginCredentialsInvalidError, PyHTCC, Zone
 
 from jarvis.executors import word_match
 from jarvis.modules.audio import speaker
 from jarvis.modules.exceptions import EgressErrors
 from jarvis.modules.logger import logger
 from jarvis.modules.models import classes, models
 from jarvis.modules.utils import support, util
 
 
 def create_connection() -> None:
     """Creates a new connection and stores the device object and expiration time in a dedicated object."""
     try:
         tcc_object: PyHTCC = PyHTCC(models.env.tcc_username, models.env.tcc_password)
-    except AuthenticationError as error:
+    except (AuthenticationError, LoginCredentialsInvalidError) as error:
         logger.error(error)
         classes.Thermostat.device = "AuthenticationError"
         return
     except EgressErrors as error:
         logger.error(error)
         classes.Thermostat.device = "ConnectionError"
         return
     try:
-        classes.Thermostat.device = tcc_object.get_zone_by_name(models.env.tcc_device_name)
+        classes.Thermostat.device = tcc_object.get_zone_by_name(
+            models.env.tcc_device_name
+        )
         classes.Thermostat.expiration = time.time() + 86_400
-    except NoZonesFoundError as error:
+    except (EnvironmentError, ValueError, NameError, KeyError, IndexError) as error:
         logger.error(error)
-        classes.Thermostat.device = "NoZonesFoundError"
-    except UnauthorizedError as error:
-        logger.error(error)
-        classes.Thermostat.device = "AuthenticationError"
-    except (NameError, IndexError) as error:
-        logger.error(error)
-        classes.Thermostat.device = "NameError"
-    except EgressErrors as error:
-        logger.error(error)
-        classes.Thermostat.device = "ConnectionError"
+        classes.Thermostat.device = error.__class__.__name__
 
 
 # Initiate connection only for main and offline communicators
 # WATCH OUT: for changes in function name
-if models.settings.pname in ('JARVIS', 'telegram_api', 'jarvis_api'):
-    if all((models.env.tcc_username, models.env.tcc_password, models.env.tcc_device_name)):
-        logger.info("Creating a new thermostat connection for '%s'", models.settings.pname)
+if models.settings.pname in ("JARVIS", "telegram_api", "jarvis_api"):
+    if all(
+        (models.env.tcc_username, models.env.tcc_password, models.env.tcc_device_name)
+    ):
+        logger.info(
+            "Creating a new thermostat connection for '%s'", models.settings.pname
+        )
         Thread(target=create_connection).start()
 
 
 def get_thermostat(device: Zone, phrase: str) -> None:
     """Get operations to be performed on the thermostat.
 
     Args:
         device: Authenticated device object.
         phrase: Takes the phrase spoken as an argument.
     """
     if "indoor" in phrase:
         if "humidity" in phrase:
             value = str(util.format_nos(device.get_indoor_humidity_raw())) + "%"
             logger.info("Humidity: %s", value)
-            speaker.speak(text=f"The current indoor humidity is {value} {models.env.title}!")
+            speaker.speak(
+                text=f"The current indoor humidity is {value} {models.env.title}!"
+            )
             return
         if "temperature" in phrase:
             value = util.format_nos(device.get_indoor_temperature_raw())
             logger.info("Temperature: %s\N{DEGREE SIGN}F", value)
-            speaker.speak(text=f"The current indoor temperature is {value}\N{DEGREE SIGN}F {models.env.title}!")
+            speaker.speak(
+                text=f"The current indoor temperature is {value}\N{DEGREE SIGN}F {models.env.title}!"
+            )
             return
     if "outdoor" in phrase:
         if "temperature" in phrase:
             value = util.format_nos(device.get_outdoor_temperature_raw())
             logger.info("Outdoor temperature: %s\N{DEGREE SIGN}F", value)
-            speaker.speak(text=f"The current outdoor temperature is {value}\N{DEGREE SIGN}F {models.env.title}!")
+            speaker.speak(
+                text=f"The current outdoor temperature is {value}\N{DEGREE SIGN}F {models.env.title}!"
+            )
             return
     if word_match.word_match(phrase, ("status", "fan", "mode")):
         mode = device.get_system_mode()
         fan = device.get_fan_mode()
-        speaker.speak(text=f"Currently your thermostat is set to {mode.name.lower()}, and "
-                           f"the fan is set to {fan.name.lower()}")
-        return
-    speaker.speak(f"I'm sorry {models.env.title}! I'm not programmed to retrieve this information.")
+        speaker.speak(
+            text=f"Currently your thermostat is set to {mode.name.lower()}, and "
+            f"the fan is set to {fan.name.lower()}"
+        )
+        return
+    speaker.speak(
+        f"I'm sorry {models.env.title}! I'm not programmed to retrieve this information."
+    )
 
 
 def set_thermostat(device: Zone, phrase: str) -> None:
     """Update operations to be performed on the thermostat.
 
     Args:
         device: Authenticated device object.
         phrase: Takes the phrase spoken as an argument.
     """
     if "cool" in phrase or "cold" in phrase:
         if value := util.extract_nos(phrase, method=int):
             device.set_temp_cool_setpoint(value)
-            speaker.speak(text=f"I've set the thermostat to cool, {value}\N{DEGREE SIGN}F {models.env.title}!")
+            speaker.speak(
+                text=f"I've set the thermostat to cool, {value}\N{DEGREE SIGN}F {models.env.title}!"
+            )
         else:
-            speaker.speak(text=f"Please specify a value for the cool point {models.env.title}!")
+            speaker.speak(
+                text=f"Please specify a value for the cool point {models.env.title}!"
+            )
         return
     if "heat" in phrase or "hot" in phrase or "warm" in phrase:
         if value := util.extract_nos(phrase, method=int):
             device.set_temp_heat_setpoint(value)
-            speaker.speak(text=f"I've set the thermostat to heat, {value}\N{DEGREE SIGN}F {models.env.title}!")
+            speaker.speak(
+                text=f"I've set the thermostat to heat, {value}\N{DEGREE SIGN}F {models.env.title}!"
+            )
         else:
-            speaker.speak(text=f"Please specify a value for the heat point {models.env.title}!")
+            speaker.speak(
+                text=f"Please specify a value for the heat point {models.env.title}!"
+            )
         return
-    speaker.speak(text=f"I'm sorry {models.env.title}! Please specify if you want to set it as heat or cool.")
+    speaker.speak(
+        text=f"I'm sorry {models.env.title}! Please specify if you want to set it as heat or cool."
+    )
 
 
-def get_auth_object() -> Union[Zone, None]:
+def get_auth_object() -> Zone | None:
     """Loads the authenticated Zone object with a built-in retry logic and expiration check.
 
     Returns:
         Zone:
         Authenticated Zone object.
     """
-    if isinstance(classes.Thermostat.device, str):  # retry in case there was an error previously
+    # retry in case there was an error previously
+    if isinstance(classes.Thermostat.device, str):
         logger.warning("Previous error: '%s', retrying", classes.Thermostat.device)
         create_connection()
-    if classes.Thermostat.device == "AuthenticationError":
-        speaker.speak(f"I'm sorry {models.env.title}! I ran into an authentication error.")
-        return
-    if classes.Thermostat.device == "NameError":
-        speaker.speak(f"I'm sorry {models.env.title}! "
-                      f"I wasn't able to find the thermostat, {models.env.tcc_device_name} in your account.")
-        return
-    if classes.Thermostat.device == "ConnectionError":
-        speaker.speak(f"I'm sorry {models.env.title}! I wasn't able to connect to your thermostat.")
-        return
-    if classes.Thermostat.device == "NoZonesFoundError":
-        speaker.speak(f"I'm sorry {models.env.title}! There are no thermostats found in your account.")
-        return
-    expiry = util.epoch_to_datetime(seconds=classes.Thermostat.expiration, format_="%B %d, %Y - %I:%M %p")
+    if isinstance(classes.Thermostat.device, str):  # failed even after retry:
+        match classes.Thermostat.device:
+            case "AuthenticationError":
+                speaker.speak(
+                    f"I'm sorry {models.env.title}! I ran into an authentication error."
+                )
+            case "NameError":
+                speaker.speak(
+                    f"I'm sorry {models.env.title}! "
+                    f"I wasn't able to find the thermostat, {models.env.tcc_device_name} in your account."
+                )
+            case "ConnectionError":
+                speaker.speak(
+                    f"I'm sorry {models.env.title}! I wasn't able to connect to your thermostat."
+                )
+            case "NoZonesFoundError":
+                speaker.speak(
+                    f"I'm sorry {models.env.title}! There are no thermostats found in your account."
+                )
+            case _:
+                speaker.speak(
+                    f"I'm sorry {models.env.title}! There was an unexpected error."
+                )
+        return
+    # Check for expiry after informing about the error, since a retry logic is in place when device object is a string
+    expiry = util.epoch_to_datetime(
+        seconds=classes.Thermostat.expiration, format_="%B %d, %Y - %I:%M %p"
+    )
     if time.time() - classes.Thermostat.expiration >= 86_400:
-        logger.info("Creating a new connection since the current session expired at: %s", expiry)
+        logger.info(
+            "Creating a new connection since the current session expired at: %s", expiry
+        )
         create_connection()
     else:
         logger.info("Current session is valid until: %s", expiry)
     return classes.Thermostat.device
 
 
 def thermostat_controls(phrase: str) -> None:
     """Directs to the target function based on user requirement.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
     """
-    if all((models.env.tcc_username, models.env.tcc_password, models.env.tcc_device_name)):
+    if all(
+        (models.env.tcc_username, models.env.tcc_password, models.env.tcc_device_name)
+    ):
         phrase = phrase.lower()
     else:
         logger.warning("TCC email or password or device_name not found.")
         support.no_env_vars()
         return
-    if device := get_auth_object():
-        if "set" in phrase.split():
-            set_thermostat(device, phrase)
-        else:
-            get_thermostat(device, phrase)
+    try:
+        if device := get_auth_object():
+            if "set" in phrase.split():
+                set_thermostat(device, phrase)
+            else:
+                get_thermostat(device, phrase)
+    except Exception as error:
+        logger.critical(error)
+        speaker.speak(f"I'm sorry {models.env.title}! There was an unexpected error.")
```

## jarvis/executors/todo_list.py

```diff
@@ -38,79 +38,108 @@
     with tdb.connection:
         cursor = tdb.connection.cursor()
         downloaded = cursor.execute("SELECT category, item FROM tasks").fetchall()
     result = {}
     for category, item in downloaded:
         # condition below makes sure one category can have multiple items without repeating category for each item
         if category not in result:
-            result[category] = item  # creates dict for category and item if category is not found in result
+            result[
+                category
+            ] = item  # creates dict for category and item if category is not found in result
         else:
-            result[category] = result[category] + ', ' + item  # updates category if already found in result
+            result[category] = (
+                result[category] + ", " + item
+            )  # updates category if already found in result
     if result:
         if shared.called_by_offline:
             speaker.speak(text=json.dumps(result))
             return
-        speaker.speak(text='Your to-do items are')
-        for category, item in result.items():  # browses dictionary and stores result in response and says it
+        speaker.speak(text="Your to-do items are")
+        # browses dictionary and stores result in response and says it
+        for (
+            category,
+            item,
+        ) in result.items():
             response = f"{item}, in {category} category."
             speaker.speak(text=response)
     else:
-        speaker.speak(text=f"You don't have any tasks in your to-do list {models.env.title}.")
+        speaker.speak(
+            text=f"You don't have any tasks in your to-do list {models.env.title}."
+        )
 
-    if shared.called['report']:
+    if shared.called["report"]:
         speaker.speak(run=True)
 
 
 def add_todo() -> None:
     """Adds new items to the to-do list."""
     speaker.speak(text=f"What's your plan {models.env.title}?", run=True)
-    if not (item := listener.listen()) or \
-            word_match.word_match(phrase=item, match_list=keywords.keywords['exit_']):
-        speaker.speak(text=f'Your to-do list has been left intact {models.env.title}.')
+    if not (item := listener.listen()) or word_match.word_match(
+        phrase=item, match_list=keywords.keywords["exit_"]
+    ):
+        speaker.speak(text=f"Your to-do list has been left intact {models.env.title}.")
         return
-    speaker.speak(text=f"I heard {item}. Which category you want me to add it to?", run=True)
+    speaker.speak(
+        text=f"I heard {item}. Which category you want me to add it to?", run=True
+    )
     if not (category := listener.listen()):
-        category = 'Unknown'
-    if word_match.word_match(phrase=category, match_list=keywords.keywords['exit_']):
-        speaker.speak(text=f'Your to-do list has been left intact {models.env.title}.')
+        category = "Unknown"
+    if word_match.word_match(phrase=category, match_list=keywords.keywords["exit_"]):
+        speaker.speak(text=f"Your to-do list has been left intact {models.env.title}.")
         return
     with tdb.connection:
         cursor = tdb.connection.cursor()
         downloaded = cursor.execute("SELECT category, item FROM tasks").fetchall()
     if downloaded:
         for c, i in downloaded:  # browses through all categories and items
-            if i == item and c == category:  # checks if already present and updates items in case of repeated category
-                speaker.speak(text=f"Looks like you already have the item: {item} added in, {category} category")
+            # checks if already present and updates items in case of repeated category
+            if i == item and c == category:
+                speaker.speak(
+                    text=f"Looks like you already have the item: {item} added in, {category} category"
+                )
                 return
     with tdb.connection:
         cursor = tdb.connection.cursor()
-        cursor.execute("INSERT or REPLACE INTO tasks (category, item) VALUES (?,?)", (category, item))
-    speaker.speak(text=f"I've added the item: {item} to the category: {category}. "
-                       "Do you want to add anything else to your to-do list?", run=True)
-    if (category_continue := listener.listen()) and \
-            word_match.word_match(phrase=category_continue.lower(), match_list=keywords.keywords['ok']):
+        cursor.execute(
+            "INSERT or REPLACE INTO tasks (category, item) VALUES (?,?)",
+            (category, item),
+        )
+    speaker.speak(
+        text=f"I've added the item: {item} to the category: {category}. "
+        "Do you want to add anything else to your to-do list?",
+        run=True,
+    )
+    if (category_continue := listener.listen()) and word_match.word_match(
+        phrase=category_continue.lower(), match_list=keywords.keywords["ok"]
+    ):
         add_todo()
     else:
-        speaker.speak(text='Alright')
+        speaker.speak(text="Alright")
 
 
 def delete_todo_items() -> None:
     """Deletes items from an existing to-do list."""
     speaker.speak(text=f"Which one should I remove {models.env.title}?", run=True)
-    if not (word := listener.listen()) or \
-            word_match.word_match(phrase=word, match_list=keywords.keywords['exit_']):
-        speaker.speak(text=f'Your to-do list has been left intact {models.env.title}.')
+    if not (word := listener.listen()) or word_match.word_match(
+        phrase=word, match_list=keywords.keywords["exit_"]
+    ):
+        speaker.speak(text=f"Your to-do list has been left intact {models.env.title}.")
         return
     with tdb.connection:
         cursor = tdb.connection.cursor()
-        cursor.execute("DELETE FROM tasks WHERE item=:item OR category=:category", {'item': word, 'category': word})
+        cursor.execute(
+            "DELETE FROM tasks WHERE item=:item OR category=:category",
+            {"item": word, "category": word},
+        )
         cursor.connection.commit()
-    speaker.speak(text=f'Done {models.env.title}!', run=True)
+    speaker.speak(text=f"Done {models.env.title}!", run=True)
 
 
 def delete_todo() -> None:
     """Deletes all the data from the table ``tasks`` in the database."""
     with tdb.connection:
         cursor = tdb.connection.cursor()
-        cursor.execute('DELETE FROM tasks')
+        cursor.execute("DELETE FROM tasks")
         cursor.connection.commit()
-    speaker.speak(text=f"I've deleted all your tasks from the database {models.env.title}.")
+    speaker.speak(
+        text=f"I've deleted all your tasks from the database {models.env.title}."
+    )
```

## jarvis/executors/tv.py

```diff
@@ -1,29 +1,29 @@
 import os
 import time
 from concurrent.futures import ThreadPoolExecutor
 from threading import Thread
-from typing import Dict, List, Tuple, Union
+from typing import Dict, List, Tuple
 
 from jarvis.executors import files, internet, tv_controls, word_match
 from jarvis.modules.audio import speaker
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.utils import shared, support
 from jarvis.modules.wakeonlan import wakeonlan
 
 
-def get_tv(data: dict) -> Tuple[Dict[str, Dict[str, Union[str, List[str]]]], str]:
+def get_tv(data: dict) -> Tuple[Dict[str, Dict[str, str | List[str]]], str]:
     """Extract TV mapping from the data in smart devices.
 
     Args:
         data: Raw data from smart devices.
 
     Returns:
-        Tuple[Dict[str, Dict[str, Union[str, List[str]]]], str]:
+        Tuple[Dict[str, Dict[str, str | List[str]]], str]:
         Return TV information and the key name under which it was stored. The key will be used to update the file.
     """
     for key, value in data.items():
         if key.lower() in ("tv", "tvs", "television", "televisions"):
             return data[key], key
 
 
@@ -44,40 +44,72 @@
     """
     if models.settings.os == models.supported_platforms.windows:
         command = "ping -c 1 -t 2 {IP_ADDRESS} > NUL"
     else:
         command = "ping -c 1 -t 2 {IP_ADDRESS} >/dev/null 2>&1"
     for ip in tv_ip_list:
         if tv_stat := os.system(command=command.format(IP_ADDRESS=ip)):
-            logger.error("Connection timed out on %s. Ping result: %s", ip, tv_stat) if not attempt else None
+            logger.error(
+                "Connection timed out on %s. Ping result: %s", ip, tv_stat
+            ) if not attempt else None
         else:
             return ip
 
 
 def television(phrase: str) -> None:
     """Controls all actions on a TV (LG Web OS or Roku).
 
     Args:
         phrase: Takes the phrase spoken as an argument.
     """
-    match_words = ['turn on', 'connect', 'shutdown', 'shut down', 'turn off', 'increase',
-                   'decrease', 'reduce', 'mute', 'stop', 'content', 'stop', 'pause', 'resume', 'play',
-                   'rewind', 'forward', 'set', 'volume', 'volume', 'app', 'application', 'open',
-                   'launch', "what's", 'currently', 'change', 'source']
+    match_words = [
+        "turn on",
+        "connect",
+        "shutdown",
+        "shut down",
+        "turn off",
+        "increase",
+        "decrease",
+        "reduce",
+        "mute",
+        "stop",
+        "content",
+        "stop",
+        "pause",
+        "resume",
+        "play",
+        "rewind",
+        "forward",
+        "set",
+        "volume",
+        "volume",
+        "app",
+        "application",
+        "open",
+        "launch",
+        "what's",
+        "currently",
+        "change",
+        "source",
+    ]
     if not word_match.word_match(phrase=phrase, match_list=match_words):
-        speaker.speak(text=f"I didn't quite get that {models.env.title}! What do you want me to do to your tv?")
-        Thread(target=support.unrecognized_dumper, args=[{'TV': phrase}]).start()
+        speaker.speak(
+            text=f"I didn't quite get that {models.env.title}! What do you want me to do to your tv?"
+        )
+        Thread(target=support.unrecognized_dumper, args=[{"TV": phrase}]).start()
         return
 
     if not internet.vpn_checker():
         return
 
     smart_devices = files.get_smart_devices()
     if smart_devices is False:
-        speaker.speak(text=f"I'm sorry {models.env.title}! I wasn't able to read the source information.")
+        speaker.speak(
+            text=f"I'm sorry {models.env.title}! I wasn't able to read the source information."
+        )
         return
     if smart_devices and (tv_mapping := get_tv(data=smart_devices)):
         tv_map, key = tv_mapping
         logger.debug("%s stored with key: '%s'", tv_map, key)
     else:
         logger.warning("%s is empty for tv.", models.fileio.smart_devices)
         support.no_env_vars()
@@ -85,86 +117,113 @@
 
     tvs = list(tv_map.keys())
     if "all" in phrase:
         tv_iterate = tvs
     elif selected := word_match.word_match(phrase=phrase, match_list=tvs):
         tv_iterate = [selected]
     else:
-        speaker.speak(text=f"You have {len(tvs)} TVs added {models.env.title}! "
-                           "Please specify which TV I should access.")
+        speaker.speak(
+            text=f"You have {len(tvs)} TVs added {models.env.title}! "
+            "Please specify which TV I should access."
+        )
         return
 
     logger.info("Chosen TVs: %s", tv_iterate)
     for target_tv in tv_iterate:
         logger.info("Iterating over: %s", target_tv)
-        tv_name = tv_map[target_tv].get('hostname')
-        tv_mac = tv_map[target_tv].get('mac_address')
-        tv_client_key = tv_map[target_tv].get('client_key')
+        tv_name = tv_map[target_tv].get("hostname")
+        tv_mac = tv_map[target_tv].get("mac_address")
+        tv_client_key = tv_map[target_tv].get("client_key")
 
         if not all((tv_name, tv_mac)):
-            speaker.speak(text=f"I'm sorry {models.env.title}! "
-                               f"I was unable to find the {target_tv}'s name or MAC address.")
+            speaker.speak(
+                text=f"I'm sorry {models.env.title}! "
+                f"I was unable to find the {target_tv}'s name or MAC address."
+            )
             continue
 
-        if 'lg' in tv_name.lower() or 'roku' in tv_name.lower():
+        if "lg" in tv_name.lower() or "roku" in tv_name.lower():
             logger.debug("'%s' is supported.", tv_name)
         else:
             logger.error("tv's name [%s] is not supported.", tv_name)
-            speaker.speak(text=f"I'm sorry {models.env.title}! Your {target_tv}'s name is neither LG or Roku."
-                               "So, I will not be able to control the television.")
+            speaker.speak(
+                text=f"I'm sorry {models.env.title}! Your {target_tv}'s name is neither LG or Roku."
+                "So, I will not be able to control the television."
+            )
             continue
 
-        if 'lg' in tv_name.lower() and not tv_client_key:
-            speaker.speak(text="LG televisions require a client key, but that seems to be missing. "
-                               "Proceeding without it. User confirmation on TV screen may be required.")
+        if "lg" in tv_name.lower() and not tv_client_key:
+            speaker.speak(
+                text="LG televisions require a client key, but that seems to be missing. "
+                "Proceeding without it. User confirmation on TV screen may be required."
+            )
 
         tv_ip_list = support.hostname_to_ip(hostname=tv_name)
         tv_ip_list = list(filter(None, tv_ip_list))
         if not tv_ip_list:
             speaker.speak(
                 text=f"I'm sorry {models.env.title}! I wasn't able to get the IP address of your {target_tv}."
             )
             continue
 
         if isinstance(tv_mac, str):
             tv_mac = [tv_mac]
 
-        if 'turn off' in phrase.lower() or 'shutdown' in phrase.lower() or 'shut down' in phrase.lower():
+        if (
+            "turn off" in phrase.lower()
+            or "shutdown" in phrase.lower()
+            or "shut down" in phrase.lower()
+        ):
             if not (tv_ip := tv_status(tv_ip_list=tv_ip_list)):
                 # WARNING: TV that was turned off recently might still respond to ping
-                speaker.speak(text=f"I wasn't able to connect to your {target_tv} {models.env.title}! "
-                                   "I guess your TV is powered off already.")
+                speaker.speak(
+                    text=f"I wasn't able to connect to your {target_tv} {models.env.title}! "
+                    "I guess your TV is powered off already."
+                )
                 continue
         elif not (tv_ip := tv_status(tv_ip_list=tv_ip_list)):
-            logger.info("Trying to power on the device using the mac addresses: %s", tv_mac)
+            logger.info(
+                "Trying to power on the device using the mac addresses: %s", tv_mac
+            )
             power_controller = wakeonlan.WakeOnLan()
-            for _ in range(3):  # REDUNDANT-Roku: Send magic packets thrice to ensure device wakes up from sleep
+            # REDUNDANT-Roku: Send magic packets thrice to ensure device wakes up from sleep
+            for _ in range(3):
                 with ThreadPoolExecutor(max_workers=len(tv_mac)) as executor:
                     executor.map(power_controller.send_packet, tv_mac)
             if not shared.called_by_offline:
-                speaker.speak(text=f"Looks like your {target_tv} is powered off {models.env.title}! "
-                                   "Let me try to turn it back on!", run=True)
+                speaker.speak(
+                    text=f"Looks like your {target_tv} is powered off {models.env.title}! "
+                    "Let me try to turn it back on!",
+                    run=True,
+                )
 
         if not tv_ip:
             for i in range(5):
                 if tv_ip := tv_status(tv_ip_list=tv_ip_list, attempt=i):
                     break
                 time.sleep(0.5)
             else:
-                speaker.speak(text=f"I wasn't able to connect to your {target_tv} {models.env.title}! "
-                                   "Please make sure you are on the same network as your TV, and "
-                                   "your TV is connected to a power source.")
+                speaker.speak(
+                    text=f"I wasn't able to connect to your {target_tv} {models.env.title}! "
+                    "Please make sure you are on the same network as your TV, and "
+                    "your TV is connected to a power source."
+                )
                 continue
 
         # Instantiate dictionary if not present
         if not shared.tv.get(target_tv):
             shared.tv[target_tv] = None
         logger.debug("TV database: %s", shared.tv)
-        if 'lg' in tv_name.lower():
+        if "lg" in tv_name.lower():
             kwargs = dict(
-                phrase=phrase, tv_ip=tv_ip, identifier='LG', client_key=tv_client_key, nickname=target_tv, key=key
+                phrase=phrase,
+                tv_ip=tv_ip,
+                identifier="LG",
+                client_key=tv_client_key,
+                nickname=target_tv,
+                key=key,
             )
         else:
             kwargs = dict(
-                phrase=phrase, tv_ip=tv_ip, identifier='ROKU', nickname=target_tv
+                phrase=phrase, tv_ip=tv_ip, identifier="ROKU", nickname=target_tv
             )
         tv_controls.tv_controller(**kwargs)
```

## jarvis/executors/tv_controls.py

```diff
@@ -1,126 +1,182 @@
 import random
-import time
 from threading import Thread
 
 from jarvis.modules.audio import speaker
 from jarvis.modules.conditions import conversation
 from jarvis.modules.exceptions import TVError
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.tv import lg, roku
 from jarvis.modules.utils import shared, support, util
 
 
-def tv_controller(phrase: str, tv_ip: str, identifier: str, nickname: str,
-                  client_key: str = None, key: str = None) -> None:
+def tv_controller(
+    phrase: str,
+    tv_ip: str,
+    identifier: str,
+    nickname: str,
+    client_key: str = None,
+    key: str = None,
+) -> None:
     """Controller for Roku or LG tv actions.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
         tv_ip: IP address of the television.
         identifier: String to control roku or LG WebOS.
         nickname: Name as in the source yaml file.
         key: Key under which the TV information was stored in source file.
         client_key: Client key to connect to the LG WebOS tv.
     """
-    phrase_lower = phrase.replace('TV', '').lower()
+    phrase_lower = phrase.replace("TV", "").lower()
 
     if not shared.tv[nickname]:
         try:
-            if identifier == 'LG':
-                shared.tv[nickname] = lg.LGWebOS(ip_address=tv_ip, client_key=client_key, nickname=nickname, key=key)
-            elif identifier == 'ROKU':
+            if identifier == "LG":
+                shared.tv[nickname] = lg.LGWebOS(
+                    ip_address=tv_ip, client_key=client_key, nickname=nickname, key=key
+                )
+            elif identifier == "ROKU":
                 shared.tv[nickname] = roku.RokuECP(ip_address=tv_ip)
                 # todo: launch a harmless app to actually startup the TV
         except TVError as error:
             logger.error("Failed to connect to the TV. %s", error)
-            speaker.speak(text=f"I was unable to connect to the {nickname} {models.env.title}! "
-                               f"It appears to be a connection issue. You might want to try again later.")
+            speaker.speak(
+                text=f"I was unable to connect to the {nickname} {models.env.title}! "
+                f"It appears to be a connection issue. You might want to try again later."
+            )
             return
         else:
-            if 'turn on' in phrase_lower or 'connect' in phrase_lower:
-                speaker.speak(text=f"TV features have been integrated {models.env.title}!")
+            if "turn on" in phrase_lower or "connect" in phrase_lower:
+                speaker.speak(
+                    text=f"TV features have been integrated {models.env.title}!"
+                )
                 return
 
     if shared.tv[nickname]:
-        if 'turn on' in phrase_lower or 'connect' in phrase_lower:
-            speaker.speak(text=f'Your {nickname} is already powered on {models.env.title}!')
-        elif 'shutdown' in phrase_lower or 'shut down' in phrase_lower or 'turn off' in phrase_lower:
+        if "turn on" in phrase_lower or "connect" in phrase_lower:
+            speaker.speak(
+                text=f"Your {nickname} is already powered on {models.env.title}!"
+            )
+        elif (
+            "shutdown" in phrase_lower
+            or "shut down" in phrase_lower
+            or "turn off" in phrase_lower
+        ):
             # ROKU:
             #   Connections to Roku TVs are made with IP, so it almost always connects as long as it is powered
             #   Roku tends to return 'Home' even when powered off, so check state of the TV first
             # LG:
             #   Extremely unlikely to reach as LG TVs typically close the connections when powered off
             #   Edge case scenario is when the TV is powered on and off by different processes
             #   leaving the processes that powered on with a memory reference that'd assume the TV is powered on
             #   end up failing to connect to the TV as it is powered off already
-            if shared.tv[nickname].get_state() and (running_app := shared.tv[nickname].current_app()):
+            if shared.tv[nickname].get_state() and (
+                running_app := shared.tv[nickname].current_app()
+            ):
                 logger.info("Currently running '%s'", running_app)
             else:
-                speaker.speak(text=f"I don't think your {nickname} is powered on {models.env.title}!")
+                speaker.speak(
+                    text=f"I don't think your {nickname} is powered on {models.env.title}!"
+                )
                 return
             Thread(target=shared.tv[nickname].shutdown).start()
-            speaker.speak(text=f'{random.choice(conversation.acknowledgement)}! Turning your {nickname} off.')
+            speaker.speak(
+                text=f"{random.choice(conversation.acknowledgement)}! Turning your {nickname} off."
+            )
             shared.tv.pop(nickname)
-        elif 'increase' in phrase_lower:
+        elif "increase" in phrase_lower:
             shared.tv[nickname].increase_volume()
-            speaker.speak(text=f'{random.choice(conversation.acknowledgement)}!')
-        elif 'decrease' in phrase_lower or 'reduce' in phrase_lower:
+            speaker.speak(text=f"{random.choice(conversation.acknowledgement)}!")
+        elif "decrease" in phrase_lower or "reduce" in phrase_lower:
             shared.tv[nickname].decrease_volume()
-            speaker.speak(text=f'{random.choice(conversation.acknowledgement)}!')
-        elif 'mute' in phrase_lower:
+            speaker.speak(text=f"{random.choice(conversation.acknowledgement)}!")
+        elif "mute" in phrase_lower:
             shared.tv[nickname].mute()
-            speaker.speak(text=f'{random.choice(conversation.acknowledgement)}!')
-        elif 'stop' in phrase_lower and 'content' in phrase_lower:
+            speaker.speak(text=f"{random.choice(conversation.acknowledgement)}!")
+        elif "stop" in phrase_lower and "content" in phrase_lower:
             shared.tv[nickname].stop()
-            speaker.speak(text=f'{random.choice(conversation.acknowledgement)}!')
-        elif 'stop' in phrase_lower or 'pause' in phrase_lower:
+            speaker.speak(text=f"{random.choice(conversation.acknowledgement)}!")
+        elif "stop" in phrase_lower or "pause" in phrase_lower:
             shared.tv[nickname].pause()
-            speaker.speak(text=f'{random.choice(conversation.acknowledgement)}!')
-        elif 'resume' in phrase_lower or 'play' in phrase_lower:
+            speaker.speak(text=f"{random.choice(conversation.acknowledgement)}!")
+        elif "resume" in phrase_lower or "play" in phrase_lower:
             shared.tv[nickname].play()
-            speaker.speak(text=f'{random.choice(conversation.acknowledgement)}!')
-        elif 'rewind' in phrase_lower:
+            speaker.speak(text=f"{random.choice(conversation.acknowledgement)}!")
+        elif "rewind" in phrase_lower:
             shared.tv[nickname].rewind()
-            speaker.speak(text=f'{random.choice(conversation.acknowledgement)}!')
-        elif 'forward' in phrase_lower:
+            speaker.speak(text=f"{random.choice(conversation.acknowledgement)}!")
+        elif "forward" in phrase_lower:
             shared.tv[nickname].forward()
-            speaker.speak(text=f'{random.choice(conversation.acknowledgement)}!')
-        elif 'set' in phrase_lower and 'volume' in phrase_lower:
+            speaker.speak(text=f"{random.choice(conversation.acknowledgement)}!")
+        elif "set" in phrase_lower and "volume" in phrase_lower:
             vol = util.extract_nos(input_=phrase_lower, method=int)
             if vol is None:
-                speaker.speak(text=f"Requested volume doesn't match the right format {models.env.title}!")
+                speaker.speak(
+                    text=f"Requested volume doesn't match the right format {models.env.title}!"
+                )
             else:
                 shared.tv[nickname].set_volume(target=vol)
                 speaker.speak(text=f"I've set the volume to {vol}% {models.env.title}.")
-        elif 'volume' in phrase_lower:
-            speaker.speak(text=f"The current volume on your {nickname} is, {shared.tv[nickname].get_volume()}%")
-        elif 'app' in phrase_lower or 'application' in phrase_lower:
-            speaker.speak(text=f'The applications on your {nickname} are, '
-                               f'{util.comma_separator(list(shared.tv[nickname].get_apps()))}!')
-        elif 'open' in phrase_lower or 'launch' in phrase_lower:
+        elif "volume" in phrase_lower:
+            speaker.speak(
+                text=f"The current volume on your {nickname} is, {shared.tv[nickname].get_volume()}%"
+            )
+        elif "app" in phrase_lower or "application" in phrase_lower:
+            speaker.speak(
+                text=f"The applications on your {nickname} are, "
+                f"{util.comma_separator(list(shared.tv[nickname].get_apps()))}!"
+            )
+        elif "open" in phrase_lower or "launch" in phrase_lower:
             app_name = util.get_closest_match(
-                text=' '.join([w for w in phrase.split() if w not in ['launch', 'open', 'on', 'my', 'the',
-                                                                      'tv'] + nickname.split() + identifier.split()]),
-                match_list=list(shared.tv[nickname].get_apps())
+                text=" ".join(
+                    [
+                        w
+                        for w in phrase.split()
+                        if w
+                        not in ["launch", "open", "on", "my", "the", "tv"]
+                        + nickname.split()
+                        + identifier.split()
+                    ]
+                ),
+                match_list=list(shared.tv[nickname].get_apps()),
             )
             logger.info("%s -> %s", phrase, app_name)
             shared.tv[nickname].launch_app(app_name=app_name)
-            speaker.speak(text=f"I've launched {app_name} on your {nickname} {models.env.title}!")
-        elif "what's" in phrase_lower or 'currently' in phrase_lower:
-            speaker.speak(text=f'{shared.tv[nickname].current_app()} is running on your {nickname}.')
-        elif 'change' in phrase_lower or 'source' in phrase_lower:
+            speaker.speak(
+                text=f"I've launched {app_name} on your {nickname} {models.env.title}!"
+            )
+        elif "what's" in phrase_lower or "currently" in phrase_lower:
+            speaker.speak(
+                text=f"{shared.tv[nickname].current_app()} is running on your {nickname}."
+            )
+        elif "change" in phrase_lower or "source" in phrase_lower:
             source = util.get_closest_match(
-                text=' '.join([w for w in phrase.split() if w not in ['set', 'the', 'source', 'on', 'my', 'of', 'to',
-                                                                      'tv'] + nickname.split() + identifier.split()]),
-                match_list=list(shared.tv[nickname].get_sources())
+                text=" ".join(
+                    [
+                        w
+                        for w in phrase.split()
+                        if w
+                        not in ["set", "the", "source", "on", "my", "of", "to", "tv"]
+                        + nickname.split()
+                        + identifier.split()
+                    ]
+                ),
+                match_list=list(shared.tv[nickname].get_sources()),
             )
             logger.info("%s -> %s", phrase, source)
             shared.tv[nickname].set_source(val=source)
             speaker.speak(text=f"I've changed the source to {source}.")
         else:
             speaker.speak(text="I didn't quite get that.")
-            Thread(target=support.unrecognized_dumper, args=[{'TV': phrase}]).start()
+            Thread(target=support.unrecognized_dumper, args=[{"TV": phrase}]).start()
     else:
-        phrase = phrase.replace('my', 'your').replace('please', '').replace('will you', '').strip()
-        speaker.speak(text=f"I'm sorry {models.env.title}! I wasn't able to {phrase}, as the TV state is unknown!")
+        phrase = (
+            phrase.replace("my", "your")
+            .replace("please", "")
+            .replace("will you", "")
+            .strip()
+        )
+        speaker.speak(
+            text=f"I'm sorry {models.env.title}! I wasn't able to {phrase}, as the TV state is unknown!"
+        )
```

## jarvis/executors/unconditional.py

```diff
@@ -26,82 +26,108 @@
         Boolean True if Google's maps API is unable to fetch consumable results.
     """
     if not models.env.maps_api:
         return False
 
     maps_url = "https://maps.googleapis.com/maps/api/place/textsearch/json?"
     try:
-        response = requests.get(maps_url + 'query=' + query + '&key=' + models.env.maps_api)
+        response = requests.get(
+            maps_url + "query=" + query + "&key=" + models.env.maps_api
+        )
     except EgressErrors as error:
         logger.error(error)
         return False
-    collection = response.json().get('results', [])
+    collection = response.json().get("results", [])
     required = []
     for data in collection:
         try:
-            required.append({
-                "Name": data['name'],
-                "Rating": data['rating'],
-                "Location": data['geometry']['location'],
-                "Address": re.search('(.*)Rd|(.*)Ave|(.*)St |(.*)St,|(.*)Blvd|(.*)Ct',
-                                     data['formatted_address']).group().replace(',', '')
-            })
+            required.append(
+                {
+                    "Name": data["name"],
+                    "Rating": data["rating"],
+                    "Location": data["geometry"]["location"],
+                    "Address": re.search(
+                        "(.*)Rd|(.*)Ave|(.*)St |(.*)St,|(.*)Blvd|(.*)Ct",
+                        data["formatted_address"],
+                    )
+                    .group()
+                    .replace(",", ""),
+                }
+            )
         except (AttributeError, KeyError) as error:
             logger.warning(error)
     if required:
-        required = sorted(required, key=lambda sort: sort['Rating'], reverse=True)
+        required = sorted(required, key=lambda sort: sort["Rating"], reverse=True)
     else:
         logger.warning("No results were found")
         return False
 
     current_location = files.get_location()
-    if not all((current_location.get('latitude'), current_location.get('longitude'))):
+    if not all((current_location.get("latitude"), current_location.get("longitude"))):
         logger.warning("Coordinates are missing")
         return False
     results = len(required)
-    speaker.speak(text=f"I found {results} results {models.env.title}!") if results != 1 else None
-    start = current_location['latitude'], current_location['longitude']
+    speaker.speak(
+        text=f"I found {results} results {models.env.title}!"
+    ) if results != 1 else None
+    start = current_location["latitude"], current_location["longitude"]
     n = 0
     for item in required:
-        item['Address'] = item['Address'].replace(' N ', ' North ').replace(' S ', ' South ').replace(' E ', ' East ') \
-            .replace(' W ', ' West ').replace(' Rd', ' Road').replace(' St', ' Street').replace(' Ave', ' Avenue') \
-            .replace(' Blvd', ' Boulevard').replace(' Ct', ' Court')
-        latitude, longitude = item['Location']['lat'], item['Location']['lng']
+        item["Address"] = (
+            item["Address"]
+            .replace(" N ", " North ")
+            .replace(" S ", " South ")
+            .replace(" E ", " East ")
+            .replace(" W ", " West ")
+            .replace(" Rd", " Road")
+            .replace(" St", " Street")
+            .replace(" Ave", " Avenue")
+            .replace(" Blvd", " Boulevard")
+            .replace(" Ct", " Court")
+        )
+        latitude, longitude = item["Location"]["lat"], item["Location"]["lng"]
         end = f"{latitude},{longitude}"
         if models.env.distance_unit == models.DistanceUnits.MILES:
             far = round(geodesic(start, end).miles)
         else:
             far = round(geodesic(start, end).kilometers)
         if far > 1:
             dist = f"{far} {models.env.distance_unit.value}"
         else:
             dist = f"{far} {models.env.distance_unit.value.rstrip('s')}"
         n += 1
         if results == 1:
-            option = 'only option I found is'
+            option = "only option I found is"
             next_val = f"Do you want to head there {models.env.title}?"
         elif n <= 2:
-            option = f'{support.ENGINE.ordinal(n)} option is'
+            option = f"{support.ENGINE.ordinal(n)} option is"
             next_val = f"Do you want to head there {models.env.title}?"
         elif n <= 5:
-            option = 'next option would be'
+            option = "next option would be"
             next_val = "Would you like to try that?"
         else:
-            option = 'other'
-            next_val = 'How about that?'
-        speaker.speak(text=f"The {option}, {item['Name']}, with {item['Rating']} rating, "
-                           f"on{''.join([j for j in item['Address'] if not j.isdigit()])}, which is approximately "
-                           f"{dist} away. {next_val}", run=True)
-        support.write_screen(text=f"{item['Name']} -- {item['Rating']} -- "
-                                  f"{''.join([j for j in item['Address'] if not j.isdigit()])}")
+            option = "other"
+            next_val = "How about that?"
+        speaker.speak(
+            text=f"The {option}, {item['Name']}, with {item['Rating']} rating, "
+            f"on{''.join([j for j in item['Address'] if not j.isdigit()])}, which is approximately "
+            f"{dist} away. {next_val}",
+            run=True,
+        )
+        support.write_screen(
+            text=f"{item['Name']} -- {item['Rating']} -- "
+            f"{''.join([j for j in item['Address'] if not j.isdigit()])}"
+        )
         if converted := listener.listen():
-            if 'exit' in converted or 'quit' in converted or 'Xzibit' in converted:
+            if "exit" in converted or "quit" in converted or "Xzibit" in converted:
                 break
-            elif word_match.word_match(phrase=converted.lower(), match_list=keywords.keywords['ok']):
-                maps_url = f'https://www.google.com/maps/dir/{start}/{end}/'
+            elif word_match.word_match(
+                phrase=converted.lower(), match_list=keywords.keywords["ok"]
+            ):
+                maps_url = f"https://www.google.com/maps/dir/{start}/{end}/"
                 webbrowser.open(url=maps_url)
                 speaker.speak(text=f"Directions on your screen {models.env.title}!")
                 return True
             elif results == 1:
                 return True
             elif n == results:
                 speaker.speak(text=f"I've run out of options {models.env.title}!")
```

## jarvis/executors/volume.py

```diff
@@ -12,16 +12,18 @@
 
 def speaker_volume(level: int) -> None:
     """Changes volume just for Jarvis' speech without disturbing the system volume.
 
     Args:
         level: Takes the volume level as an argument.
     """
-    logger.info("Jarvis' volume has been set to %d" % level + "%")  # % is mandatory because of string concatenation
-    models.AUDIO_DRIVER.setProperty('volume', level / 100)
+    logger.info(
+        "Jarvis' volume has been set to %d" % level + "%"
+    )  # % is mandatory because of string concatenation
+    models.AUDIO_DRIVER.setProperty("volume", level / 100)
 
 
 def volume(phrase: str = None, level: int = None) -> None:
     """Controls volume from the numbers received. Defaults to 50%.
 
     See Also:
         SetVolume for Windows: https://rlatour.com/setvol/
@@ -30,29 +32,29 @@
         phrase: Takes the phrase spoken as an argument.
         level: Level of volume to which the system has to set.
     """
     response = None
     if not level and phrase:
         response = random.choice(conversation.acknowledgement)
         phrase = phrase.lower()
-        if 'unmute' in phrase:
+        if "unmute" in phrase:
             level = models.env.volume
-        elif 'mute' in phrase:
+        elif "mute" in phrase:
             level = 0
-        elif 'max' in phrase or 'full' in phrase:
+        elif "max" in phrase or "full" in phrase:
             level = 100
         else:
             level = util.extract_nos(input_=phrase, method=int)
     if level is None:
         level = models.env.volume
     phrase = phrase or ""
     caller = sys._getframe(1).f_code.co_name  # noqa
-    if 'master' in phrase or 'main' in phrase or caller in ('executor', 'starter'):
+    if "master" in phrase or "main" in phrase or caller in ("executor", "starter"):
         pyvolume.custom(level, logger)
         speaker_volume(level=level)
     else:
-        if shared.called_by_offline or 'system' in phrase:
+        if shared.called_by_offline or "system" in phrase:
             pyvolume.custom(level, logger)
         else:
             speaker_volume(level=level)
     if response:
         speaker.speak(text=response)
```

## jarvis/executors/vpn_server.py

```diff
@@ -9,15 +9,15 @@
 from jarvis.modules.audio import speaker
 from jarvis.modules.database import database
 from jarvis.modules.logger import logger, multiprocessing_logger
 from jarvis.modules.models import models
 from jarvis.modules.utils import support, util
 
 db = database.Database(database=models.fileio.base_db)
-available_regions = {'regions': []}
+available_regions = {"regions": []}
 
 
 def regional_phrase(phrase: str) -> Generator[str]:
     """Converts alphabetical numbers into actual numbers.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
@@ -40,61 +40,82 @@
         phrase: Takes the phrase spoken as an argument.
 
     Returns:
         str:
         Region name if a match is found.
     """
     phrase = " ".join(regional_phrase(phrase=phrase))
-    if not available_regions['regions']:
-        available_regions['regions'] = list(vpn.util.available_regions())
-    for region in available_regions['regions']:
-        if region.replace('-', ' ') in phrase:
+    if not available_regions["regions"]:
+        available_regions["regions"] = list(vpn.util.available_regions())
+    for region in available_regions["regions"]:
+        if region.replace("-", " ") in phrase:
             logger.info("Custom region chosen: %s", region)
             return region
 
 
 def vpn_server(phrase: str) -> None:
     """Enables or disables VPN server.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
     """
     if not all((models.env.vpn_username, models.env.vpn_password)):
-        speaker.speak(text="VPN username and password are required for any VPN server related operations.")
+        speaker.speak(
+            text="VPN username and password are required for any VPN server related operations."
+        )
         return
 
     with db.connection:
         cursor = db.connection.cursor()
         state = cursor.execute("SELECT state FROM vpn").fetchone()
     if state:
-        speaker.speak(text=f'VPN Server was recently {state[0]}, and the process is still running {models.env.title}! '
-                           'Please wait and retry.')
+        speaker.speak(
+            text=f"VPN Server was recently {state[0]}, and the process is still running {models.env.title}! "
+            "Please wait and retry."
+        )
         return
 
     phrase = phrase.lower()
-    if 'start' in phrase or 'trigger' in phrase or 'initiate' in phrase or 'enable' in phrase or 'spin up' in phrase:
+    if (
+        "start" in phrase
+        or "trigger" in phrase
+        or "initiate" in phrase
+        or "enable" in phrase
+        or "spin up" in phrase
+    ):
         if custom_region := extract_custom_region(phrase=phrase):
-            process = Process(target=vpn_server_switch, kwargs={'operation': 'enabled', 'custom_region': custom_region})
-            text = f'VPN Server has been initiated in {custom_region} {models.env.title}! ' \
-                   'Login details will be sent to you shortly.'
+            process = Process(
+                target=vpn_server_switch,
+                kwargs={"operation": "enabled", "custom_region": custom_region},
+            )
+            text = (
+                f"VPN Server has been initiated in {custom_region} {models.env.title}! "
+                "Login details will be sent to you shortly."
+            )
         else:
-            process = Process(target=vpn_server_switch, kwargs={'operation': 'enabled'})
-            text = f'VPN Server has been initiated {models.env.title}! Login details will be sent to you shortly.'
+            process = Process(target=vpn_server_switch, kwargs={"operation": "enabled"})
+            text = f"VPN Server has been initiated {models.env.title}! Login details will be sent to you shortly."
         speaker.speak(text=text)
-    elif 'stop' in phrase or 'shut' in phrase or 'close' in phrase or 'disable' in phrase:
+    elif (
+        "stop" in phrase or "shut" in phrase or "close" in phrase or "disable" in phrase
+    ):
         if not os.path.isfile(models.env.vpn_info_file):
-            speaker.speak(text=f'Input file for VPN Server is missing {models.env.title}! '
-                               'The VPN Server might have been shut down already.')
+            speaker.speak(
+                text=f"Input file for VPN Server is missing {models.env.title}! "
+                "The VPN Server might have been shut down already."
+            )
             return
-        process = Process(target=vpn_server_switch, kwargs={'operation': 'disabled'})
-        speaker.speak(text=f'VPN Server will be shutdown {models.env.title}!')
+        process = Process(target=vpn_server_switch, kwargs={"operation": "disabled"})
+        speaker.speak(text=f"VPN Server will be shutdown {models.env.title}!")
     else:
-        speaker.speak(text=f"I don't understand the request {models.env.title}! "
-                           "You can ask me to enable or disable the VPN server.")
-        Thread(target=support.unrecognized_dumper, args=[{'VPNServer': phrase}]).start()
+        speaker.speak(
+            text=f"I don't understand the request {models.env.title}! "
+            "You can ask me to enable or disable the VPN server."
+        )
+        Thread(target=support.unrecognized_dumper, args=[{"VPNServer": phrase}]).start()
         return
     process.name = "vpn_server"
     process.start()
 
 
 def vpn_server_switch(operation: str, custom_region: str = None) -> None:
     """Automator to ``create`` or ``destroy`` a VPN server.
@@ -102,48 +123,63 @@
     Args:
         operation: Takes ``enabled`` or ``disabled`` as argument.
         custom_region: Takes a custom AWS region as argument.
 
     See Also:
         - Check Read Me in `vpn-server <https://git.io/JzCbi>`__ for more information.
     """
-    log_file = multiprocessing_logger(filename=os.path.join('logs', 'vpn_server_%d_%m_%Y_%H_%M.log'))
-    kwargs = dict(vpn_username=models.env.vpn_username,
-                  vpn_password=models.env.vpn_password,
-                  vpn_info=models.env.vpn_info_file,
-                  subdomain=models.env.vpn_subdomain,
-                  logger=logger)
+    log_file = multiprocessing_logger(
+        filename=os.path.join("logs", "vpn_server_%d_%m_%Y_%H_%M.log")
+    )
+    kwargs = dict(
+        vpn_username=models.env.vpn_username,
+        vpn_password=models.env.vpn_password,
+        vpn_info=models.env.vpn_info_file,
+        subdomain=models.env.vpn_subdomain,
+        logger=logger,
+    )
     if models.env.vpn_hosted_zone:
         kwargs["hosted_zone"] = models.env.vpn_hosted_zone
     if models.env.vpn_key_pair:
         kwargs["key_pair"] = models.env.vpn_key_pair
     if models.env.vpn_security_group:
         kwargs["security_group"] = models.env.vpn_security_group
 
     if custom_region:
-        kwargs['aws_region_name'] = custom_region
-        success_subject = f"VPN Server on {custom_region!r} has been configured successfully!"
+        kwargs["aws_region_name"] = custom_region
+        success_subject = (
+            f"VPN Server on {custom_region!r} has been configured successfully!"
+        )
         fail_subject = f"Failed to create VPN Server on {custom_region!r}!"
     else:
         success_subject = "VPN Server has been configured successfully!"
         fail_subject = "Failed to create VPN Server!"
     vpn_object = vpn.VPNServer(**kwargs)
     with db.connection:
         cursor = db.connection.cursor()
         cursor.execute("INSERT or REPLACE INTO vpn (state) VALUES (?);", (operation,))
         db.connection.commit()
-    if operation == 'enabled':
+    if operation == "enabled":
         if vpn_data := vpn_object.create_vpn_server():
-            entrypoint = vpn_data.get('entrypoint') or vpn_data.get('public_dns')
-            communicator.send_email(subject=success_subject, body=f"Entrypoint: {entrypoint}", title="VPN Server",
-                                    recipient=models.env.recipient, attachment=models.env.vpn_info_file)
+            entrypoint = vpn_data.get("entrypoint") or vpn_data.get("public_dns")
+            communicator.send_email(
+                subject=success_subject,
+                body=f"Entrypoint: {entrypoint}",
+                title="VPN Server",
+                recipient=models.env.recipient,
+                attachment=models.env.vpn_info_file,
+            )
         else:
-            communicator.send_email(subject=fail_subject, recipient=models.env.recipient, title="VPN Server",
-                                    attachment=log_file,
-                                    body="Failed to initiate VPN server. "
-                                         "Please check the logs (attached) for more information.")
-    elif operation == 'disabled':
+            communicator.send_email(
+                subject=fail_subject,
+                recipient=models.env.recipient,
+                title="VPN Server",
+                attachment=log_file,
+                body="Failed to initiate VPN server. "
+                "Please check the logs (attached) for more information.",
+            )
+    elif operation == "disabled":
         vpn_object.delete_vpn_server()
     with db.connection:
         cursor = db.connection.cursor()
         cursor.execute("DELETE FROM vpn WHERE state=?", (operation,))
         db.connection.commit()
```

## jarvis/executors/weather.py

```diff
@@ -1,50 +1,58 @@
 import string
 from collections import OrderedDict
 from datetime import datetime
-from typing import Any, Dict, Optional, Tuple, Union
+from typing import Any, Dict, Optional, Tuple
 from urllib.parse import urlencode
 
 import requests
 
 from jarvis.executors import files, location, word_match
 from jarvis.modules.audio import speaker
 from jarvis.modules.conditions import keywords
 from jarvis.modules.exceptions import EgressErrors
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.utils import support
 
 
-def make_request(lat: float, lon: float) -> Union[Dict, None]:
+def make_request(lat: float, lon: float) -> Dict | None:
     """Get weather information from OpenWeatherMap API.
 
     Args:
         lat: Latitude of location to get weather info.
         lon: Longitude of location to get weather info.
 
     Returns:
         dict:
         JSON response from api.
     """
-    query_string = urlencode(OrderedDict(lat=lat, lon=lon, exclude="minutely,hourly",
-                                         appid=models.env.weather_api,
-                                         units=models.env.temperature_unit.value))
-    url = 'https://api.openweathermap.org/data/2.5/onecall?' + query_string
+    query_string = urlencode(
+        OrderedDict(
+            lat=lat,
+            lon=lon,
+            exclude="minutely,hourly",
+            appid=models.env.weather_api,
+            units=models.env.temperature_unit.value,
+        )
+    )
+    url = "https://api.openweathermap.org/data/2.5/onecall?" + query_string
     try:
         response = requests.get(url=url)
         if response.ok:
             return response.json()
         else:
             response.raise_for_status()
     except EgressErrors + (requests.JSONDecodeError,) as error:
         logger.error(error)
 
 
-def weather(phrase: str = None, monitor: bool = False) -> Union[Tuple[Any, int, int, int, Optional[str]], None]:
+def weather(
+    phrase: str = None, monitor: bool = False
+) -> Tuple[Any, int, int, int, Optional[str]] | None:
     """Says weather at any location if a specific location is mentioned.
 
     Says weather at current location by getting IP using reverse geocoding if no place is received.
 
     References:
         - https://www.weather.gov/mlb/seasonal_wind_threat
 
@@ -56,161 +64,239 @@
         logger.warning("Weather apikey not found.")
         support.no_env_vars()
         return
 
     place = None
     if phrase:
         # ignore days in week and the keywords for weather as they are guaranteed to not be places
-        place = support.get_capitalized(phrase=phrase,
-                                        ignore=support.days_in_week +
-                                        tuple(string.capwords(w) for w in keywords.keywords['weather']))
+        place = support.get_capitalized(
+            phrase=phrase,
+            ignore=support.days_in_week
+            + tuple(string.capwords(w) for w in keywords.keywords["weather"]),
+        )
         phrase = phrase.lower()
     if place:
         logger.info("Identified place: %s", place)
         desired_location = location.geo_locator.geocode(place)
         if not desired_location:
             logger.error("Failed to get coordinates for the place: '%s'", place)
-            speaker.speak(text=f"I'm sorry {models.env.title}! "
-                               f"I wasn't able to get the weather information at {place}!")
+            speaker.speak(
+                text=f"I'm sorry {models.env.title}! "
+                f"I wasn't able to get the weather information at {place}!"
+            )
             return
         coordinates = desired_location.latitude, desired_location.longitude
-        located = location.geo_locator.reverse(coordinates, language='en')
-        address = located.raw['address']
-        city = address.get('city') or address.get('town') or address.get('hamlet') or 'Unknown'
-        state = address.get('state', 'Unknown')
+        located = location.geo_locator.reverse(coordinates, language="en")
+        address = located.raw["address"]
+        city = (
+            address.get("city")
+            or address.get("town")
+            or address.get("hamlet")
+            or "Unknown"
+        )
+        state = address.get("state", "Unknown")
         lat = located.latitude
         lon = located.longitude
     else:
         current_location = files.get_location()
-        address = current_location.get('address', {})
-        city = address.get('city') or address.get('town') or address.get('hamlet') or 'Unknown'
-        state = address.get('state', 'Unknown')
-        lat = current_location['latitude']
-        lon = current_location['longitude']
+        address = current_location.get("address", {})
+        city = (
+            address.get("city")
+            or address.get("town")
+            or address.get("hamlet")
+            or "Unknown"
+        )
+        state = address.get("state", "Unknown")
+        lat = current_location["latitude"]
+        lon = current_location["longitude"]
     if not (response := make_request(lat=lat, lon=lon)):
-        speaker.speak(text=f"I'm sorry {models.env.title}! I ran into an exception. Please check your logs.")
+        speaker.speak(
+            text=f"I'm sorry {models.env.title}! I ran into an exception. Please check your logs."
+        )
         return
 
-    weather_location = f'{city} {state}'.replace('None', '') if city != state else city or state
-
-    if word_match.word_match(phrase=phrase, match_list=('tomorrow', 'day after', 'next week',
-                                                        'tonight', 'afternoon', 'evening')):
+    weather_location = (
+        f"{city} {state}".replace("None", "") if city != state else city or state
+    )
+
+    if word_match.word_match(
+        phrase=phrase,
+        match_list=(
+            "tomorrow",
+            "day after",
+            "next week",
+            "tonight",
+            "afternoon",
+            "evening",
+        ),
+    ):
         # when the weather info was requested
-        if 'tonight' in phrase:
+        if "tonight" in phrase:
             key = 0
-            tell = 'tonight'
-        elif 'day after' in phrase:
+            tell = "tonight"
+        elif "day after" in phrase:
             key = 2
-            tell = 'day after tomorrow'
-        elif 'tomorrow' in phrase:
+            tell = "day after tomorrow"
+        elif "tomorrow" in phrase:
             key = 1
-            tell = 'tomorrow'
-        elif 'next week' in phrase:
+            tell = "tomorrow"
+        elif "next week" in phrase:
             key = -1
-            next_week = datetime.fromtimestamp(response['daily'][-1]['dt']).strftime("%A, %B %d")
+            next_week = datetime.fromtimestamp(response["daily"][-1]["dt"]).strftime(
+                "%A, %B %d"
+            )
             tell = f"on {' '.join(next_week.split()[:-1])} {support.ENGINE.ordinal(next_week.split()[-1])}"
         else:
             key = 0
-            tell = 'today'
+            tell = "today"
 
         # which part of the day (after noon or noon is considered as full day as midday values range same as full day)
-        if 'morning' in phrase:
-            when = 'morn'
-            tell += ' morning'
-        elif 'evening' in phrase:
-            when = 'eve'
-            tell += ' evening'
-        elif 'tonight' in phrase:
-            when = 'night'
-        elif 'night' in phrase:
-            when = 'night'
-            tell += ' night'
+        if "morning" in phrase:
+            when = "morn"
+            tell += " morning"
+        elif "evening" in phrase:
+            when = "eve"
+            tell += " evening"
+        elif "tonight" in phrase:
+            when = "night"
+        elif "night" in phrase:
+            when = "night"
+            tell += " night"
         else:
-            when = 'day'
-            tell += ''
+            when = "day"
+            tell += ""
 
-        if 'alerts' in response:
-            alerts = response['alerts'][0]['event']
-            start_alert = datetime.fromtimestamp(response['alerts'][0]['start']).strftime("%I:%M %p")
-            end_alert = datetime.fromtimestamp(response['alerts'][0]['end']).strftime("%I:%M %p")
+        if "alerts" in response:
+            alerts = response["alerts"][0]["event"]
+            start_alert = datetime.fromtimestamp(
+                response["alerts"][0]["start"]
+            ).strftime("%I:%M %p")
+            end_alert = datetime.fromtimestamp(response["alerts"][0]["end"]).strftime(
+                "%I:%M %p"
+            )
         else:
             alerts, start_alert, end_alert = None, None, None
-        during_key = response['daily'][key]
-        condition = during_key['weather'][0]['description']
-        high = int(during_key['temp']['max'])
-        low = int(during_key['temp']['min'])
-        temp_f = int(during_key['temp'][when])
-        temp_feel_f = int(during_key['feels_like'][when])
-        sunrise = datetime.fromtimestamp(during_key['sunrise']).strftime("%I:%M %p")
-        sunset = datetime.fromtimestamp(during_key['sunset']).strftime("%I:%M %p")
-        if 'sunrise' in phrase or 'sun rise' in phrase or ('sun' in phrase and 'rise' in phrase):
-            if datetime.strptime(datetime.today().strftime("%I:%M %p"), "%I:%M %p") >= \
-                    datetime.strptime(sunrise, "%I:%M %p"):
+        during_key = response["daily"][key]
+        condition = during_key["weather"][0]["description"]
+        high = int(during_key["temp"]["max"])
+        low = int(during_key["temp"]["min"])
+        temp_f = int(during_key["temp"][when])
+        temp_feel_f = int(during_key["feels_like"][when])
+        sunrise = datetime.fromtimestamp(during_key["sunrise"]).strftime("%I:%M %p")
+        sunset = datetime.fromtimestamp(during_key["sunset"]).strftime("%I:%M %p")
+        if (
+            "sunrise" in phrase
+            or "sun rise" in phrase
+            or ("sun" in phrase and "rise" in phrase)
+        ):
+            if datetime.strptime(
+                datetime.today().strftime("%I:%M %p"), "%I:%M %p"
+            ) >= datetime.strptime(sunrise, "%I:%M %p"):
                 tense = "will be"
             else:
                 tense = "was"
-            speaker.speak(text=f"{tell} in {weather_location}, sunrise {tense} at {sunrise}.")
+            speaker.speak(
+                text=f"{tell} in {weather_location}, sunrise {tense} at {sunrise}."
+            )
             return
-        if 'sunset' in phrase or 'sun set' in phrase or ('sun' in phrase and 'set' in phrase):
-            if datetime.strptime(datetime.today().strftime("%I:%M %p"), "%I:%M %p") >= \
-                    datetime.strptime(sunset, "%I:%M %p"):
+        if (
+            "sunset" in phrase
+            or "sun set" in phrase
+            or ("sun" in phrase and "set" in phrase)
+        ):
+            if datetime.strptime(
+                datetime.today().strftime("%I:%M %p"), "%I:%M %p"
+            ) >= datetime.strptime(sunset, "%I:%M %p"):
                 tense = "will be"
             else:
                 tense = "was"
-            speaker.speak(text=f"{tell} in {weather_location}, sunset {tense} at {sunset}")
+            speaker.speak(
+                text=f"{tell} in {weather_location}, sunset {tense} at {sunset}"
+            )
             return
-        output = f"The weather in {weather_location} {tell} would be " \
-                 f"{temp_f}\N{DEGREE SIGN}{models.temperature_symbol}, " \
-                 f"with a high of {high}, and a low of {low}. "
-        if temp_feel_f != temp_f and condition not in ("clear sky", "broken clouds", "fog", "few clouds"):
-            output += f"But due to {condition} it will fee like it is " \
-                      f"{temp_feel_f}\N{DEGREE SIGN}{models.temperature_symbol}. "
+        output = (
+            f"The weather in {weather_location} {tell} would be "
+            f"{temp_f}\N{DEGREE SIGN}{models.temperature_symbol}, "
+            f"with a high of {high}, and a low of {low}. "
+        )
+        if temp_feel_f != temp_f and condition not in (
+            "clear sky",
+            "broken clouds",
+            "fog",
+            "few clouds",
+        ):
+            output += (
+                f"But due to {condition} it will fee like it is "
+                f"{temp_feel_f}\N{DEGREE SIGN}{models.temperature_symbol}. "
+            )
         output += f"Sunrise at {sunrise}. Sunset at {sunset}. "
         if alerts and start_alert and end_alert:
-            output += f'There is a weather alert for {alerts} between {start_alert} and {end_alert}'
+            output += f"There is a weather alert for {alerts} between {start_alert} and {end_alert}"
         speaker.speak(text=output)
         return
 
-    condition = response['current']['weather'][0]['description']
-    high = int(response['daily'][0]['temp']['max'])
-    low = int(response['daily'][0]['temp']['min'])
-    temp_f = int(response['current']['temp'])
-    temp_feel_f = int(response['current']['feels_like'])
-    sunrise = datetime.fromtimestamp(response['daily'][0]['sunrise']).strftime("%I:%M %p")
-    sunset = datetime.fromtimestamp(response['daily'][0]['sunset']).strftime("%I:%M %p")
+    condition = response["current"]["weather"][0]["description"]
+    high = int(response["daily"][0]["temp"]["max"])
+    low = int(response["daily"][0]["temp"]["min"])
+    temp_f = int(response["current"]["temp"])
+    temp_feel_f = int(response["current"]["feels_like"])
+    sunrise = datetime.fromtimestamp(response["daily"][0]["sunrise"]).strftime(
+        "%I:%M %p"
+    )
+    sunset = datetime.fromtimestamp(response["daily"][0]["sunset"]).strftime("%I:%M %p")
     if monitor:
-        if 'alerts' in response:
-            alerts = response['alerts'][0]['event']
-            start_alert = datetime.fromtimestamp(response['alerts'][0]['start']).strftime("%m-%d %H:%M")
-            end_alert = datetime.fromtimestamp(response['alerts'][0]['end']).strftime("%m-%d %H:%M")
-            alert = f'{string.capwords(alerts)} from {start_alert} to {end_alert}'
+        if "alerts" in response:
+            alerts = response["alerts"][0]["event"]
+            start_alert = datetime.fromtimestamp(
+                response["alerts"][0]["start"]
+            ).strftime("%m-%d %H:%M")
+            end_alert = datetime.fromtimestamp(response["alerts"][0]["end"]).strftime(
+                "%m-%d %H:%M"
+            )
+            alert = f"{string.capwords(alerts)} from {start_alert} to {end_alert}"
         else:
             alert = None
         return condition, high, low, temp_f, alert
     if phrase:
-        if 'sunrise' in phrase or 'sun rise' in phrase or ('sun' in phrase and 'rise' in phrase):
-            if datetime.strptime(datetime.today().strftime("%I:%M %p"), "%I:%M %p") >= \
-                    datetime.strptime(sunrise, "%I:%M %p"):
+        if (
+            "sunrise" in phrase
+            or "sun rise" in phrase
+            or ("sun" in phrase and "rise" in phrase)
+        ):
+            if datetime.strptime(
+                datetime.today().strftime("%I:%M %p"), "%I:%M %p"
+            ) >= datetime.strptime(sunrise, "%I:%M %p"):
                 tense = "will be"
             else:
                 tense = "was"
             speaker.speak(text=f"In {weather_location}, sunrise {tense} at {sunrise}.")
             return
-        if 'sunset' in phrase or 'sun set' in phrase or ('sun' in phrase and 'set' in phrase):
-            if datetime.strptime(datetime.today().strftime("%I:%M %p"), "%I:%M %p") >= \
-                    datetime.strptime(sunset, "%I:%M %p"):
+        if (
+            "sunset" in phrase
+            or "sun set" in phrase
+            or ("sun" in phrase and "set" in phrase)
+        ):
+            if datetime.strptime(
+                datetime.today().strftime("%I:%M %p"), "%I:%M %p"
+            ) >= datetime.strptime(sunset, "%I:%M %p"):
                 tense = "will be"
             else:
                 tense = "was"
             speaker.speak(text=f"In {weather_location}, sunset {tense} at {sunset}")
             return
-    output = f'The weather in {weather_location} is ' \
-             f'{temp_f}\N{DEGREE SIGN}{models.temperature_symbol}, with a high of {high}, ' \
-             f'and a low of {low}. It currently feels like ' \
-             f'{temp_feel_f}\N{DEGREE SIGN}{models.temperature_symbol}, ' \
-             f'and the current condition is {condition}. Sunrise at {sunrise}. Sunset at {sunset}.'
-    if 'alerts' in response:
-        alerts = response['alerts'][0]['event']
-        start_alert = datetime.fromtimestamp(response['alerts'][0]['start']).strftime("%I:%M %p")
-        end_alert = datetime.fromtimestamp(response['alerts'][0]['end']).strftime("%I:%M %p")
-        output += f' You have a weather alert for {alerts} between {start_alert} and {end_alert}'
+    output = (
+        f"The weather in {weather_location} is "
+        f"{temp_f}\N{DEGREE SIGN}{models.temperature_symbol}, with a high of {high}, "
+        f"and a low of {low}. It currently feels like "
+        f"{temp_feel_f}\N{DEGREE SIGN}{models.temperature_symbol}, "
+        f"and the current condition is {condition}. Sunrise at {sunrise}. Sunset at {sunset}."
+    )
+    if "alerts" in response:
+        alerts = response["alerts"][0]["event"]
+        start_alert = datetime.fromtimestamp(response["alerts"][0]["start"]).strftime(
+            "%I:%M %p"
+        )
+        end_alert = datetime.fromtimestamp(response["alerts"][0]["end"]).strftime(
+            "%I:%M %p"
+        )
+        output += f" You have a weather alert for {alerts} between {start_alert} and {end_alert}"
     speaker.speak(text=output)
```

## jarvis/executors/weather_monitor.py

```diff
@@ -5,60 +5,94 @@
 from jarvis.executors import communicator, weather
 from jarvis.modules.logger import logger, multiprocessing_logger
 from jarvis.modules.models import models
 
 
 def monitor() -> None:
     """Weather monitoring system to trigger notifications for high, low weather and severe weather alert."""
-    multiprocessing_logger(filename=os.path.join('logs', 'background_tasks_%d-%m-%Y.log'))
+    multiprocessing_logger(
+        filename=os.path.join("logs", "background_tasks_%d-%m-%Y.log")
+    )
     try:
         condition, high, low, temp_f, alert = weather.weather(monitor=True)
     except TypeError:
         logger.error("Failed to get weather alerts")
         return
-    if not any((high >= models.env.weather_alert_max, low <= models.env.weather_alert_min, alert)):
-        logger.debug(dict(condition=condition, high=high, low=low, temperature=temp_f, alert=alert))
+    if not any(
+        (
+            high >= models.env.weather_alert_max,
+            low <= models.env.weather_alert_min,
+            alert,
+        )
+    ):
+        logger.debug(
+            dict(
+                condition=condition, high=high, low=low, temperature=temp_f, alert=alert
+            )
+        )
         logger.info("No alerts to report")
         return
     title = "Weather Alert"
     sender = "Jarvis Weather Alert System"
-    subject = title + " " + datetime.now().strftime('%c')
-    body = f"Highest Temperature: {high}\N{DEGREE SIGN}F\n" \
-           f"Lowest Temperature: {low}\N{DEGREE SIGN}F\n" \
-           f"Current Temperature: {temp_f}\N{DEGREE SIGN}F\n" \
-           f"Current Condition: {string.capwords(condition)}"
-    email_args = dict(body=body, recipient=models.env.recipient, subject=subject, sender=sender, title=title,
-                      gmail_user=models.env.open_gmail_user, gmail_pass=models.env.open_gmail_pass)
-    phone_args = dict(user=models.env.open_gmail_user, password=models.env.open_gmail_pass,
-                      body=body, number=models.env.phone_number, subject=subject)
-    if high >= models.env.weather_alert_max:  # high will definitely be greater than or equal to current
+    subject = title + " " + datetime.now().strftime("%c")
+    body = (
+        f"Highest Temperature: {high}\N{DEGREE SIGN}F\n"
+        f"Lowest Temperature: {low}\N{DEGREE SIGN}F\n"
+        f"Current Temperature: {temp_f}\N{DEGREE SIGN}F\n"
+        f"Current Condition: {string.capwords(condition)}"
+    )
+    email_args = dict(
+        body=body,
+        recipient=models.env.recipient,
+        subject=subject,
+        sender=sender,
+        title=title,
+        gmail_user=models.env.open_gmail_user,
+        gmail_pass=models.env.open_gmail_pass,
+    )
+    phone_args = dict(
+        user=models.env.open_gmail_user,
+        password=models.env.open_gmail_pass,
+        body=body,
+        number=models.env.phone_number,
+        subject=subject,
+    )
+    # high will definitely be greater than or equal to current
+    if high >= models.env.weather_alert_max:
         if alert:
-            email_args['body'] = f"High weather alert!\n{alert}\n\n" + email_args['body']
-            phone_args['body'] = f"High weather alert!\n{alert}\n\n" + phone_args['body']
+            email_args["body"] = (
+                f"High weather alert!\n{alert}\n\n" + email_args["body"]
+            )
+            phone_args["body"] = (
+                f"High weather alert!\n{alert}\n\n" + phone_args["body"]
+            )
         else:
-            email_args['body'] = "High weather alert!\n" + email_args['body']
-            phone_args['body'] = "High weather alert!\n" + phone_args['body']
+            email_args["body"] = "High weather alert!\n" + email_args["body"]
+            phone_args["body"] = "High weather alert!\n" + phone_args["body"]
         logger.info("high temperature alert")
-        email_args['body'] = email_args['body'].replace('\n', '<br>')
+        email_args["body"] = email_args["body"].replace("\n", "<br>")
         communicator.send_email(**email_args)
         communicator.send_sms(**phone_args)
         return
-    if low <= models.env.weather_alert_min:  # low will definitely be lesser than or equal to current
+    # low will definitely be lesser than or equal to current
+    if low <= models.env.weather_alert_min:
         if alert:
-            email_args['body'] = f"Low weather alert!\n{alert}\n\n" + email_args['body']
-            phone_args['body'] = f"Low weather alert!\n{alert}\n\n" + phone_args['body']
+            email_args["body"] = f"Low weather alert!\n{alert}\n\n" + email_args["body"]
+            phone_args["body"] = f"Low weather alert!\n{alert}\n\n" + phone_args["body"]
         else:
-            email_args['body'] = "Low weather alert!\n" + email_args['body']
-            phone_args['body'] = "Low weather alert!\n" + phone_args['body']
+            email_args["body"] = "Low weather alert!\n" + email_args["body"]
+            phone_args["body"] = "Low weather alert!\n" + phone_args["body"]
         logger.info("low temperature alert")
-        email_args['body'] = email_args['body'].replace('\n', '<br>')
+        email_args["body"] = email_args["body"].replace("\n", "<br>")
         communicator.send_email(**email_args)
         communicator.send_sms(**phone_args)
         return
     if alert:
-        email_args['body'] = f"Critical weather alert!\n{alert}\n\n" + email_args['body']
-        phone_args['body'] = "Critical weather alert!\n" + phone_args['body']
+        email_args["body"] = (
+            f"Critical weather alert!\n{alert}\n\n" + email_args["body"]
+        )
+        phone_args["body"] = "Critical weather alert!\n" + phone_args["body"]
         logger.info("critical weather alert")
-        email_args['body'] = email_args['body'].replace('\n', '<br>')
+        email_args["body"] = email_args["body"].replace("\n", "<br>")
         communicator.send_email(**email_args)
         communicator.send_sms(**phone_args)
         return
```

## jarvis/executors/wiki.py

```diff
@@ -10,44 +10,56 @@
 
 def wikipedia_(phrase: str) -> None:
     """Gets any information from wikipedia using its API.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
     """
-    _, _, keyword = phrase.lower().partition(' keyword ')
+    _, _, keyword = phrase.lower().partition(" keyword ")
     if keyword:
         keyword = keyword.strip()
     else:
-        _, _, keyword = phrase.lower().partition(' for ')
+        _, _, keyword = phrase.lower().partition(" for ")
     if keyword:
         keyword = keyword.strip()
     else:
-        speaker.speak(text=f"I'm sorry {models.env.title}! I can't get the information without a keyword.")
+        speaker.speak(
+            text=f"I'm sorry {models.env.title}! I can't get the information without a keyword."
+        )
         return
     try:
         result = WikipediaPage(keyword).summary
     except DisambiguationError as error:
         logger.error(error)
-        speaker.speak(text=f"Your keyword has multiple results {models.env.title}. {' '.join(error.options)}. "
-                           "Please pick one and try again.")
+        speaker.speak(
+            text=f"Your keyword has multiple results {models.env.title}. {' '.join(error.options)}. "
+            "Please pick one and try again."
+        )
         if shared.called_by_offline:
             return
         speaker.speak(run=True)
-        if not (alt_keyword := listener.listen()) or \
-                'exit' in alt_keyword or 'quit' in alt_keyword or 'Xzibit' in alt_keyword:
+        if (
+            not (alt_keyword := listener.listen())
+            or "exit" in alt_keyword
+            or "quit" in alt_keyword
+            or "Xzibit" in alt_keyword
+        ):
             return
         result = WikipediaPage(alt_keyword).summary
     except PageError as error:
         logger.error(error)
-        speaker.speak(text=f"I'm sorry {models.env.title}! I didn't get a response for the phrase: {keyword}.")
+        speaker.speak(
+            text=f"I'm sorry {models.env.title}! I didn't get a response for the phrase: {keyword}."
+        )
         return
     # stops with two sentences before reading whole passage
     formatted = ". ".join(result.split(". ")[:2]) + "."
     if shared.called_by_offline:
         # No long messages via offline communicators as Telegram API returns 400, too hard to read on FastAPI interfaces
         speaker.speak(text=formatted)
         return
-    speaker.speak(text=f"{formatted}. Do you want me to continue {models.env.title}?", run=True)
+    speaker.speak(
+        text=f"{formatted}. Do you want me to continue {models.env.title}?", run=True
+    )
     if response := listener.listen():
-        if word_match.word_match(phrase=response, match_list=keywords.keywords['ok']):
+        if word_match.word_match(phrase=response, match_list=keywords.keywords["ok"]):
             speaker.speak(text=". ".join(result.split(". ")[3:]))
```

## jarvis/executors/word_match.py

```diff
@@ -1,50 +1,54 @@
 # noinspection PyUnresolvedReferences
 """Module for keyword classification algorithm.
 
 >>> KeywordClassifier
 
 """
 
-from typing import List, Tuple, Union
+from typing import List, Tuple
 
 
-def reverse_lookup(lookup: str,
-                   match_list: Union[List, Tuple]) -> Union[str, None]:
+def reverse_lookup(lookup: str, match_list: List | Tuple) -> str | None:
     """Returns the word in phrase that matches the one in given list."""
-    reverse = sum([w.lower().split() for w in match_list], [])  # extract multi worded conditions in match list
+    reverse = sum(
+        [w.lower().split() for w in match_list], []
+    )  # extract multi worded conditions in match list
     for word in lookup.split():  # loop through words in the phrase
-        if word in reverse:  # check at least one word in phrase matches the multi worded condition
+        # check at least one word in phrase matches the multi worded condition
+        if word in reverse:
             return word
 
 
-def forward_lookup(lookup: Union[str, List, Tuple],
-                   match_list: Union[List, Tuple]) -> Union[str, None]:
+def forward_lookup(lookup: str | List | Tuple, match_list: List | Tuple) -> str | None:
     """Returns the word in list that matches with the phrase given as string or list."""
     for word in match_list:
         if word.lower() in lookup:
             return word
 
 
-def word_match(phrase: str,
-               match_list: Union[List, Tuple],
-               strict: bool = False) -> Union[str, None]:
+def word_match(
+    phrase: str, match_list: List | Tuple, strict: bool = False
+) -> str | None:
     """Keyword classifier.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
         match_list: List or tuple of words against which the phrase has to be checked.
         strict: Look for the exact word match instead of regex.
 
     Returns:
         str:
         Returns the word that was matched.
     """
     if not all((phrase, match_list)):
         return
-    if strict:  # simply check at least one string in the match list is present in phrase
+    # simply check at least one string in the match list is present in phrase
+    if strict:
         lookup = phrase.lower().split()
         return forward_lookup(lookup, match_list)
     else:
         lookup = phrase.lower()
-        if (fl := forward_lookup(lookup, match_list)) and reverse_lookup(lookup, match_list):
+        if (fl := forward_lookup(lookup, match_list)) and reverse_lookup(
+            lookup, match_list
+        ):
             return fl
```

## jarvis/lib/install.sh

```diff
@@ -1,182 +1,224 @@
 #!/bin/bash
 # 'set -e' stops the execution of a script if a command or pipeline has an error.
 # This is the opposite of the default shell behaviour, which is to ignore errors in scripts.
 set -e
 
-OSName=$(python -c "import platform; print(platform.system())")
+# defaults
+osname=""
+architecture=""
+
+# Get to the current directory
+current_dir="$(dirname "$(realpath "$0")")"
+export current_dir=$current_dir
+source "$current_dir/squire/detector.sh"
+
+if ! [ -x "$(command -v python)" ] && ! [ -x "$(command -v python3)" ]; then
+  echo -e '\n***************************************************************************************************'
+  echo "                       Neither 'python' nor 'python3' command found!!"
+  echo "                      Please install 'python' 3.10 or 3.11 to proceed!"
+  echo -e '***************************************************************************************************\n'
+  exit 1
+fi
+
+if ! [ -x "$(command -v python)" ]; then
+  alias python=python3
+fi
+
 ver=$(python -c "import sys; print(f'{sys.version_info.major}{sys.version_info.minor}')")
 echo_ver=$(python -c "import sys; print(f'{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}')")
 
-if [ "$ver" -ge 38 ] && [ "$ver" -le 311 ]; then
-  pyaudio="PyAudio-0.2.11-cp$ver-cp$ver-win_amd64.whl"
+if [ "$ver" -eq 310 ] || [ "$ver" -eq 311 ]; then
+  echo -e '\n***************************************************************************************************'
+  echo "                            $osname-$architecture running python $echo_ver"
+  echo -e '***************************************************************************************************\n'
 else
-  echo "Python version $echo_ver is unsupported for Jarvis. Please use any python version between 3.8.* and 3.11.*"
-  exit
+  echo "Python version $echo_ver is unsupported for Jarvis. Please use any python version between 3.10.* and 3.11.*"
+  exit 1
 fi
 
-echo -e '\n***************************************************************************************************'
-echo "                               $OSName running python $echo_ver"
-echo -e '***************************************************************************************************\n'
-
-# Upgrades pip module
-python -m pip install --upgrade pip
+# Upgrades pip, setuptools and wheel
+python -m pip install --upgrade pip setuptools wheel
 
 os_agnostic() {
-    # Get to the current directory and install the module specific packages
-    current_dir="$(dirname "$(realpath "$0")")"
-    python -m pip install --no-cache-dir -r "$current_dir"/version_pinned_requirements.txt
-    python -m pip install --no-cache-dir -r "$current_dir"/version_locked_requirements.txt
-    python -m pip install --no-cache-dir --upgrade -r "$current_dir"/version_upgrade_requirements.txt
-}
-
-download_from_ext_sources_windows() {
-    # Downloads ffmpeg for audio conversion when received voice commands from Telegram API
-    curl -L https://github.com/BtbN/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-win64-lgpl.zip --output ffmpeg.zip --silent && unzip ffmpeg.zip && rm -rf ffmpeg.zip && mv ffmpeg-master-latest-win64-lgpl ffmpeg
-
-    # Downloads PyAudio's wheel file to install it on Windows
-    curl https://vigneshrao.com/Jarvis/"$pyaudio" --output "$pyaudio" --silent
-    pip install "$pyaudio"
-    rm "$pyaudio"
-}
-
-handle_dlib_error() {
-    # Certain macOS versions like Catalina and Big Sur, don't support dlib version 19.24.0,
-    # so bypass for those with exception handling
-    python -m pip install dlib==19.24.2
+  echo -e '\n***************************************************************************************************'
+  echo "                             Installing OS agnostic dependencies"
+  echo -e '***************************************************************************************************\n'
+  python -m pip install --no-cache -r "$current_dir"/version_pinned_requirements.txt
+  python -m pip install --no-cache -r "$current_dir"/version_locked_requirements.txt
+  python -m pip install --no-cache --upgrade -r "$current_dir"/version_upgrade_requirements.txt
 }
 
-
-if [[ "$OSName" == "Darwin" ]]; then
-    # Looks for xcode installation and installs only if xcode is not found already
-    which xcodebuild > tmp_xcode && xcode_check=$(cat tmp_xcode) && rm tmp_xcode
-    if  [[ "$xcode_check" == "/usr/bin/xcodebuild" ]] || [[ $HOST == "/*" ]] ; then
-        xcode_version=$(pkgutil --pkg-info=com.apple.pkg.CLTools_Executables | grep version)
-        echo "xcode $xcode_version"
-    else
-        echo "Installing xcode"
-        xcode-select --install
-    fi
-
-    # Looks for brew installation and installs only if brew is not found
-    brew_check=$(which brew)
-    if [[ "$brew_check" == "/usr/local/bin/brew" ]] || [[ "$brew_check" == "/usr/bin/brew" ]]; then
-        brew -v > tmp_brew && brew_version=$(head -n 1 tmp_brew) && rm tmp_brew
-        echo "$brew_version"
-    else
-        echo "Installing Homebrew"
-        /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)"
-    fi
-
-    # Looks for git and installs only if git is not found in /usr/bin or /usr/local/bin (if installed using brew)
-    git_check=$(which git)
-    if [[ "$git_check" == "/usr/bin/git" || "$git_check" == "/usr/local/bin/git" ]]; then
-        git_version="$(git --version)"
-        echo "$git_version"
-    else
-      echo "Installing Git CLI"
-      brew install git
-    fi
-
-    # Packages installed using homebrew
-    brew install portaudio coreutils ffmpeg lame
-
-    # Installs the OS agnostic packages
-    os_agnostic
-
-    # Mac specifics
-    python -m pip install PyAudio==0.2.13 playsound==1.3.0 ftransc==7.0.3 pyobjc-framework-CoreWLAN==9.0.1 cmake==3.25.0
-
-    # Checks current version and installs legacy version of dependencies if macOS is older han 10.14
-    base_ver="10.14"  # Versions older than Mojave (High Sierra and older versions)
-    os_ver=$(sw_vers | grep ProductVersion | cut -d':' -f2 | tr -d ' ')
-    if awk "BEGIN {exit !($base_ver > $os_ver)}"; then
-      python -m pip install pvporcupine==1.6.0 dlib==19.21.0 opencv-python==4.4.0.44
-    else
-      python -m pip install pvporcupine==1.9.5
-      trap 'handle_dlib_error' ERR
-      python -m pip install dlib==19.24.0 || true  # this will bypass the set -e flag, and continue with rest of the script
-      trap - ERR
-      python -m pip install opencv-python==4.5.5.64
-    fi
-
-    # Install as stand alone as face recognition depends on dlib
-    python -m pip install face-recognition==1.3.0
-elif [[ "$OSName" == "Windows" ]]; then
-    clear
-    echo "*****************************************************************************************************************"
-    echo "*****************************************************************************************************************"
-    echo ""
-    echo "Make sure Git, Anaconda (or Miniconda) and VS C++ BuildTools are installed."
-    echo ""
-    echo "Refer the below links for:"
-    echo "Anaconda installation: https://docs.conda.io/projects/conda/en/latest/user-guide/install/"
-    echo "Miniconda installation: https://docs.conda.io/en/latest/miniconda.html#windows-installers"
-    echo "VisualStudio C++ BuildTools: https://visualstudio.microsoft.com/visual-cpp-build-tools/"
-    echo "Git: https://git-scm.com/download/win/"
+if [[ "$osname" == "darwin" ]]; then
+  echo -e '\n***************************************************************************************************'
+  echo "                             Installing dependencies specific to macOS"
+  echo -e '***************************************************************************************************\n'
+
+  # Looks for xcode installation and installs only if xcode is not found already
+  which xcodebuild > tmp_xcode && xcode_check=$(cat tmp_xcode) && rm tmp_xcode
+  if [[ "$xcode_check" == "/usr/bin/xcodebuild" ]] || [[ $HOST == "/*" ]]; then
+    xcode_version=$(pkgutil --pkg-info=com.apple.pkg.CLTools_Executables | grep version)
+    echo "xcode $xcode_version"
+  else
+    echo "Installing xcode"
+    xcode-select --install
+  fi
+
+  # Looks for brew installation and installs only if brew is not found
+  if ! [ -x "$(command -v brew)" ]; then
+    echo "Installing Homebrew"
+    /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)"
+  fi
+  brew -v > tmp_brew && brew_version=$(head -n 1 tmp_brew) && rm tmp_brew
+  echo "$brew_version"
+
+  # Looks for git and installs only if git is not found in /usr/bin or /usr/local/bin (if installed using brew)
+  if ! [ -x "$(command -v git)" ]; then
+    echo "Installing Git CLI"
+    brew install git
+  fi
+  git_version="$(git --version)"
+  echo "$git_version"
+
+  # Packages installed using homebrew
+  brew install portaudio coreutils ffmpeg lame
+
+  # Installs the OS agnostic packages
+  os_agnostic
+
+  # Install macOS specifics
+  python -m pip install playsound==1.3.0 ftransc==7.0.3 pyobjc-framework-CoreWLAN==9.0.1
+
+  # Checks current version and installs legacy version of dependencies if macOS is older han 10.14
+  base_ver="10.14" # Versions older than Mojave (High Sierra and older versions)
+  os_ver=$(sw_vers | grep ProductVersion | cut -d':' -f2 | tr -d ' ' | xargs)
+  # Uninstall any remaining cmake packages from pypi before brew installing it to avoid conflict
+  python -m pip uninstall --no-cache --no-cache-dir cmake && brew install cmake
+  if awk "BEGIN {exit !($base_ver > $os_ver)}"; then
     echo ""
     echo "*****************************************************************************************************************"
+    echo "                            macOS $os_ver will be deprecated in the near future"
+    echo "                             Please upgrade to $base_ver to continue using Jarvis"
     echo "*****************************************************************************************************************"
-    read -r -p "Are you sure you want to continue? <Y/N> " prompt
-    if ! [[ $prompt =~ [yY](es)* ]]; then
-        echo ""
-        echo "***************************************************************************************************************"
-        echo "Bye. Hope to see you soon."
-        echo "***************************************************************************************************************"
-        exit
+    echo ""
+    python -m pip install pvporcupine==1.6.0 dlib==19.21.0 opencv-python==4.4.0.44
+  else
+    if [ "$ver" -eq 310 ]; then
+      python -m pip install dlib==19.24.0
     fi
+    if [ "$ver" -eq 311 ]; then
+      python -m pip install dlib==19.24.4
+    fi
+    python -m pip install pvporcupine==1.9.5 opencv-python==4.9.0.80
+  fi
 
-    download_from_ext_sources_windows
-
-    conda install portaudio=19.6.0
-
-    # Installs the OS agnostic packages
-    os_agnostic
-
-    # Install Windows specifics
-    python -m pip install pywin32==305 playsound==1.2.2 pydub==0.25.1 pvporcupine==1.9.5
-
-    # Install face-recognition/detection dependencies as stand alone so users aren't blocked until then
-    python -m pip install opencv-python==4.5.5.64
-    python -m pip install cmake==3.25.0
+  # Install as stand alone as face recognition depends on dlib
+  python -m pip install face-recognition==1.3.0
+elif [[ "$osname" == "windows" ]]; then
+  clear
+  echo "*****************************************************************************************************************"
+  echo "                            Installing dependencies specific to Windows"
+  echo "*****************************************************************************************************************"
+  echo ""
+  echo "Make sure Git, Anaconda (or Miniconda) and VS C++ BuildTools are installed."
+  echo ""
+  echo "Refer the below links for:"
+  echo "Anaconda installation: https://docs.conda.io/projects/conda/en/latest/user-guide/install/"
+  echo "Miniconda installation: https://docs.conda.io/en/latest/miniconda.html#windows-installers"
+  echo "VisualStudio C++ BuildTools: https://visualstudio.microsoft.com/visual-cpp-build-tools/"
+  echo "Git: https://git-scm.com/download/win/"
+  echo ""
+  echo "*****************************************************************************************************************"
+  echo "*****************************************************************************************************************"
+  read -r -p "Are you sure you want to continue? <Y/N> " prompt
+  if ! [[ $prompt =~ [yY](es)* ]]; then
+    echo ""
+    echo "***************************************************************************************************************"
+    echo "Bye. Hope to see you soon."
+    echo "***************************************************************************************************************"
+    exit
+  fi
+
+  git_version="$(conda --version)"
+  echo "$git_version"
+
+  git_version="$(git --version)"
+  echo "$git_version"
+
+  conda install ffmpeg=4.2.2 portaudio=19.6.0
+
+  # Installs the OS agnostic packages
+  os_agnostic
+
+  # Install Windows specifics
+  python -m pip install pywin32==305 playsound==1.2.2 pydub==0.25.1 pvporcupine==1.9.5
+
+  # CMake must be installed to build dlib
+  python -m pip uninstall --no-cache-dir cmake # Remove cmake distro installed by pip
+  conda install cmake                          # Install cmake from conda
+  if [ "$ver" -eq 310 ]; then
     python -m pip install dlib==19.24.0
-    python -m pip install face-recognition==1.3.0
-elif [[ "$OSName" == "Linux" ]]; then
-    dot_ver=$(python -c "import sys; print(f'{sys.version_info.major}.{sys.version_info.minor}')")
-    sudo apt install -y "python$dot_ver-distutils"  # Install distutils for the current python version
-    sudo apt-get install -y git libasound-dev portaudio19-dev libportaudio2 libportaudiocpp0
-    sudo apt install -y build-essential ffmpeg espeak python3-pyaudio "python$dot_ver-dev"
-
-    sudo apt install -y libopencv-dev python3-opencv
-
-    sudo apt install -y python3-gi
-    sudo apt install -y pkg-config libcairo2-dev gcc python3-dev libgirepository1.0-dev
-
-    sudo apt install -y gnome-screensaver brightnessctl v4l-utils
-
-    # Installs the OS agnostic packages
-    os_agnostic
-
-    python -m pip install pyaudio pvporcupine==1.9.5 PyAudio==0.2.12
-
-    # CMake must be installed to build dlib
-    python -m pip install cmake==3.25.0
-    python -m pip install dlib==19.24.0 opencv-python==4.5.5.64
+  fi
+  if [ "$ver" -eq 311 ]; then
+    python -m pip install dlib==19.24.4
+  fi
+
+  # Install as stand alone as face recognition depends on dlib
+  python -m pip install opencv-python==4.9.0.80 face-recognition==1.3.0
+elif [[ "$osname" == "linux" ]]; then
+  echo -e '\n***************************************************************************************************'
+  echo "                             Installing dependencies specific to Linux"
+  echo -e '***************************************************************************************************\n'
+
+  sudo apt update
+  dot_ver=$(python -c "import sys; print(f'{sys.version_info.major}.{sys.version_info.minor}')")
+  sudo apt install -y "python$dot_ver-distutils" # Install distutils for the current python version
+  sudo apt-get install -y git libasound-dev portaudio19-dev libportaudio2 libportaudiocpp0
+  sudo apt install -y build-essential ffmpeg espeak python3-pyaudio "python$dot_ver-dev"
+
+  sudo apt install -y libopencv-dev python3-opencv
+
+  sudo apt install -y python3-gi
+  sudo apt install -y pkg-config libcairo2-dev gcc python3-dev libgirepository1.0-dev
+
+  sudo apt install -y gnome-screensaver brightnessctl v4l-utils
+
+  # Installs the OS agnostic packages
+  os_agnostic
+
+  # Install Linux specifics
+  python -m pip install pvporcupine==1.9.5
+
+  # CMake must be installed to build dlib
+  python -m pip uninstall --no-cache-dir cmake # Remove cmake distro installed by pip
+  sudo apt install cmake                       # Install cmake from apt repository
+  if [ "$ver" -eq 310 ]; then
+    python -m pip install dlib==19.24.0
+  fi
+  if [ "$ver" -eq 311 ]; then
+    python -m pip install dlib==19.24.4
+  fi
 
-    # Install as stand alone as face recognition depends on dlib
-    python -m pip install face-recognition==1.3.0
+  # Install as stand alone as face recognition depends on dlib
+  python -m pip install opencv-python==4.9.0.80 face-recognition==1.3.0
 
-    python -m pip install gobject PyGObject
+  python -m pip install gobject==0.1.0 PyGObject==3.48.2
 
-    # Install as stand alone as playsound depends on gobject
-    python -m pip install playsound==1.3.0
+  # Install as stand alone as playsound depends on gobject
+  python -m pip install playsound==1.3.0
 else
-    clear
-    echo "*****************************************************************************************************************"
-    echo "*****************************************************************************************************************"
-    echo ""
-    echo "Current Operating System: $OSName"
-    echo "Jarvis is currently supported only on Linux, MacOS and Windows"
-    echo ""
-    echo "*****************************************************************************************************************"
-    echo "*****************************************************************************************************************"
+  # todo: include support for raspberry-pi
+  # todo: possible arch (arm11, cortex-a7, cortex-a53, cortex-53-aarch64, cortex-a72, cortex-a72-aarch64)
+  clear
+  echo "*****************************************************************************************************************"
+  echo "*****************************************************************************************************************"
+  echo ""
+  echo "Current Operating System: $osname"
+  echo "Jarvis is currently supported only on Linux, MacOS and Windows"
+  echo ""
+  echo "*****************************************************************************************************************"
+  echo "*****************************************************************************************************************"
 fi
+
+freezer="$osname-$architecture-python$ver.txt"
+echo "Freezing the dependencies to $freezer"
+python -m pip freeze > "$current_dir/frozen/$freezer"
```

## jarvis/lib/version_locked_requirements.txt

```diff
@@ -1,18 +1,19 @@
-# third party pypi modules tested and version locked
 axju-jokes==1.0.3
 googlehomepush==0.1.0
 holidays==0.37
 icalendar==5.0.11
+jlrpy==1.7.0
 newsapi-python==0.2.7
 packaging==23.2
+PyAudio==0.2.14
 PyChromecast==2.3.0  # Do not upgrade, as googlehomepush module relies on this version
 pyhtcc==0.1.55
 pyicloud==1.0.0
-pyrh==2.0  # Do not upgrade, as the new version doesn't have the option for QR
+pyrh==2.1.2
 pywebostv==0.8.9
 randfacts==0.21.0
 sounddevice==0.4.6
 SpeechRecognition==3.10.0
 speedtest-cli==2.1.3
 timezonefinder==6.2.0
 webcolors==1.13
```

## jarvis/lib/version_pinned_requirements.txt

```diff
@@ -1,12 +1,11 @@
-# third party pypi modules from well known sources
 aiofiles==23.2.*
 aiohttp==3.8.*
 bs4==0.0.*
-certifi==2023.7.*
+certifi  # Follows year based versioning
 deepdiff==6.6.*
 docker==6.1.*
 fastapi==0.103.*
 geopy==2.4.*
 inflect==7.0.*
 Jinja2==3.1.*
 lxml==4.9.*
@@ -17,14 +16,14 @@
 psutil==5.9.*
 pydantic==2.4.*
 pydantic-settings==2.0.*
 PyJWT==2.8.*
 pytest==7.4.*
 python-dateutil==2.8.*
 python-multipart==0.0.*
-pytz==2023.3.*
+pytz  # Follows year based versioning
 PyYAML==6.0.*
 requests==2.31.*
 SoundFile==0.12.*
 uvicorn==0.23.*
 wave==0.0.*
 websockets==11.0.*
```

## jarvis/lib/version_upgrade_requirements.txt

```diff
@@ -1,5 +1,5 @@
 # pypi modules created/maintained by the author: Vignesh Rao
-gmail-connector
-py3-tts
-pycontrols
-vpn-server
+gmail-connector>=1.0
+py3-tts>=3.5
+pycontrols>=0.0.4
+vpn-server>=1.7
```

## jarvis/modules/builtin_overrides.py

```diff
@@ -1,15 +1,14 @@
 import collections
 import contextlib
 import logging
 
 import uvicorn
 import yaml
-from yaml.dumper import Dumper
-from yaml.nodes import Node
+from yaml.nodes import MappingNode
 
 
 class APIServer(uvicorn.Server):
     """Shared servers state that is available between all protocol instances.
 
     >>> APIServer
 
@@ -23,17 +22,17 @@
 
     @contextlib.contextmanager
     def run_in_parallel(self) -> None:
         """Initiates ``Server.run`` in a dedicated process."""
         self.run()
 
 
-def ordered_load(stream,
-                 Loader=yaml.SafeLoader,  # noqa
-                 object_pairs_hook=collections.OrderedDict) -> collections.OrderedDict:  # noqa
+def ordered_load(
+    stream, Loader=yaml.SafeLoader, object_pairs_hook=collections.OrderedDict  # noqa
+) -> collections.OrderedDict:  # noqa
     """Custom loader for OrderedDict.
 
     Args:
         stream: FileIO stream.
         Loader: Yaml loader.
         object_pairs_hook: OrderedDict object.
 
@@ -47,28 +46,31 @@
 
         >>> OrderedLoader
 
         """
 
         pass
 
-    def construct_mapping(loader: Loader, node: Node) -> collections.OrderedDict:
+    def construct_mapping(loader: Loader, node: MappingNode) -> collections.OrderedDict:
         """Create a mapping for the constructor."""
         loader.flatten_mapping(node)
         return object_pairs_hook(loader.construct_pairs(node))
 
     OrderedLoader.add_constructor(
         tag=yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG,
-        constructor=construct_mapping
+        constructor=construct_mapping,
     )
 
     return yaml.load(stream=stream, Loader=OrderedLoader)
 
 
-def ordered_dump(data, stream=None, Dumper=yaml.SafeDumper, **kwds) -> 'Dumper':  # noqa
+# noinspection PyPep8Naming
+def ordered_dump(
+    data, stream=None, Dumper=yaml.SafeDumper, **kwds  # noqa: N803
+) -> None | str | bytes:  # noqa
     """Custom dumper to serialize OrderedDict.
 
     Args:
         data: Data to be dumped into yaml file.
         stream: FileIO stream.
         Dumper: Yaml dumper.
         kwds: Keyword arguments like indent.
@@ -95,19 +97,20 @@
             data: data to be dumped.
 
         Returns:
             Node:
             Returns the representer node.
         """
         return dumper.represent_mapping(
-            yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG,
-            data.items()
+            yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG, data.items()
         )
 
-    OrderedDumper.add_representer(data_type=collections.OrderedDict, representer=_dict_representer)
+    OrderedDumper.add_representer(
+        data_type=collections.OrderedDict, representer=_dict_representer
+    )
     return yaml.dump(data=data, stream=stream, Dumper=OrderedDumper, **kwds)
 
 
 class AddProcessName(logging.Filter):
     """Wrapper that overrides ``logging.Filter`` to add ``processName`` to the existing log format.
 
     >>> AddProcessName
```

## jarvis/modules/exceptions.py

```diff
@@ -10,26 +10,30 @@
 from contextlib import contextmanager
 from http import HTTPStatus
 from typing import ByteString
 
 import requests
 from fastapi import HTTPException
 
-EgressErrors = (ConnectionError, TimeoutError, requests.RequestException, requests.Timeout)
+EgressErrors = (
+    ConnectionError,
+    TimeoutError,
+    requests.RequestException,
+    requests.Timeout,
+)
 
-ALSA_ERROR_HANDLER = ctypes.CFUNCTYPE(None,
-                                      ctypes.c_char_p,
-                                      ctypes.c_int,
-                                      ctypes.c_char_p,
-                                      ctypes.c_int,
-                                      ctypes.c_char_p)
+ALSA_ERROR_HANDLER = ctypes.CFUNCTYPE(
+    None, ctypes.c_char_p, ctypes.c_int, ctypes.c_char_p, ctypes.c_int, ctypes.c_char_p
+)
 
 
 # noinspection PyUnusedLocal
-def py_error_handler(filename: ByteString, line: int, function: ByteString, err: int, fmt: ByteString) -> None:
+def py_error_handler(
+    filename: ByteString, line: int, function: ByteString, err: int, fmt: ByteString
+) -> None:
     """Handles errors from pyaudio module especially for Linux based operating systems."""
     pass
 
 
 c_error_handler = ALSA_ERROR_HANDLER(py_error_handler)
 
 
@@ -50,15 +54,15 @@
 
     References:
         - https://github.com/Uberi/speech_recognition/issues/100
         - https://github.com/Uberi/speech_recognition/issues/182
         - https://github.com/Uberi/speech_recognition/issues/191
         - https://forums.raspberrypi.com/viewtopic.php?t=136974
     """
-    sound = ctypes.cdll.LoadLibrary('libasound.so')
+    sound = ctypes.cdll.LoadLibrary("libasound.so")
     sound.snd_lib_error_set_handler(c_error_handler)
     yield
     sound.snd_lib_error_set_handler(None)
 
 
 class UnsupportedOS(OSError):
     """Custom ``OSError`` raised when initiated in an unsupported operating system.
@@ -73,15 +77,15 @@
 
     >>> CameraError
 
     """
 
 
 class BotError(Exception):
-    """Custom base exception for Telegram Bot
+    """Custom base exception for Telegram Bot.
 
     >>> BotError
 
     """
 
 
 class BotWebhookConflict(BotError):
@@ -147,9 +151,9 @@
 
     """
 
 
 CONDITIONAL_ENDPOINT_RESTRICTION = APIResponse(
     status_code=HTTPStatus.NOT_IMPLEMENTED.real,
     detail="Required environment variables have not been setup.\nPlease refer: "
-           "https://github.com/thevickypedia/Jarvis/wiki#conditional-api-endpoints"
+    "https://github.com/thevickypedia/Jarvis/wiki#conditional-api-endpoints",
 )
```

## jarvis/modules/logger.py

```diff
@@ -6,35 +6,41 @@
 from logging.config import dictConfig
 
 from pydantic import BaseModel
 
 from jarvis.modules.builtin_overrides import AddProcessName
 from jarvis.modules.models import models
 
-if not os.path.isdir('logs'):
-    os.mkdir('logs')  # Creates only logs dir if limited mode is enabled
+if not os.path.isdir("logs"):
+    os.mkdir("logs")  # Creates only logs dir if limited mode is enabled
 
-DEFAULT_LOG_FORM = '%(asctime)s - %(levelname)s - [%(processName)s:%(module)s:%(lineno)d] - %(funcName)s - %(message)s'
-DEFAULT_FORMATTER = logging.Formatter(datefmt='%b-%d-%Y %I:%M:%S %p', fmt=DEFAULT_LOG_FORM)
+DEFAULT_LOG_FORM = "%(asctime)s - %(levelname)s - [%(processName)s:%(module)s:%(lineno)d] - %(funcName)s - %(message)s"
+DEFAULT_FORMATTER = logging.Formatter(
+    datefmt="%b-%d-%Y %I:%M:%S %p", fmt=DEFAULT_LOG_FORM
+)
 
 importlib.reload(module=logging)
-dictConfig({
-    'version': 1,
-    'disable_existing_loggers': True,
-})
+dictConfig(
+    {
+        "version": 1,
+        "disable_existing_loggers": True,
+    }
+)
 logging.getLogger("_code_cache").propagate = False
 
 logger = logging.getLogger("JARVIS")
 if models.env.debug:
     logger.setLevel(level=logging.DEBUG)
 else:
     logger.setLevel(level=logging.INFO)
 
 
-def multiprocessing_logger(filename: str, log_format: Formatter = DEFAULT_FORMATTER) -> str:
+def multiprocessing_logger(
+    filename: str, log_format: Formatter = DEFAULT_FORMATTER
+) -> str:
     """Remove existing handlers and adds a new handler when a child process kicks in.
 
     Args:
         filename: Filename where the subprocess should log.
         log_format: Custom log format dedicated for each process.
 
     See Also:
@@ -62,19 +68,25 @@
 
     >>> APIConfig
 
     """
 
     DEFAULT_LOG_LEVEL: str = "INFO"
 
-    ACCESS_LOG_FILENAME: str = datetime.now().strftime(os.path.join('logs', 'jarvis_api_access_%d-%m-%Y.log'))
-    DEFAULT_LOG_FILENAME: str = datetime.now().strftime(os.path.join('logs', 'jarvis_api_%d-%m-%Y.log'))
-
-    ACCESS_LOG_FORMAT: str = '%(levelprefix)s %(client_addr)s - "%(request_line)s" %(status_code)s'
-    ERROR_LOG_FORMAT: str = '%(levelname)s\t %(message)s'
+    ACCESS_LOG_FILENAME: str = datetime.now().strftime(
+        os.path.join("logs", "jarvis_api_access_%d-%m-%Y.log")
+    )
+    DEFAULT_LOG_FILENAME: str = datetime.now().strftime(
+        os.path.join("logs", "jarvis_api_%d-%m-%Y.log")
+    )
+
+    ACCESS_LOG_FORMAT: str = (
+        '%(levelprefix)s %(client_addr)s - "%(request_line)s" %(status_code)s'
+    )
+    ERROR_LOG_FORMAT: str = "%(levelname)s\t %(message)s"
 
     LOG_CONFIG: dict = {
         "version": 1,
         "disable_existing_loggers": True,
         "formatters": {
             "default": {
                 "()": "uvicorn.logging.DefaultFormatter",
@@ -92,58 +104,62 @@
                 "use_colors": False,
             },
         },
         "handlers": {
             "default": {
                 "formatter": "default",
                 "class": "logging.FileHandler",
-                "filename": DEFAULT_LOG_FILENAME
+                "filename": DEFAULT_LOG_FILENAME,
             },
             "access": {
                 "formatter": "access",
                 "class": "logging.FileHandler",
-                "filename": ACCESS_LOG_FILENAME
+                "filename": ACCESS_LOG_FILENAME,
             },
             "error": {
                 "formatter": "error",
                 "class": "logging.FileHandler",
-                "filename": DEFAULT_LOG_FILENAME
-            }
+                "filename": DEFAULT_LOG_FILENAME,
+            },
         },
         "loggers": {
-            "uvicorn": {
-                "handlers": ["default"], "level": DEFAULT_LOG_LEVEL
-            },
-            "uvicorn.access": {
-                "handlers": ["access"], "level": DEFAULT_LOG_LEVEL
-            },
+            "uvicorn": {"handlers": ["default"], "level": DEFAULT_LOG_LEVEL},
+            "uvicorn.access": {"handlers": ["access"], "level": DEFAULT_LOG_LEVEL},
             "uvicorn.error": {
-                "handlers": ["error"], "level": DEFAULT_LOG_LEVEL, "propagate": True  # Since FastAPI is threaded
-            }
-        }
+                "handlers": ["error"],
+                "level": DEFAULT_LOG_LEVEL,
+                "propagate": True,  # Since FastAPI is threaded
+            },
+        },
     }
 
 
 def log_file(filename: str) -> str:
     """Creates a log file and writes the headers into it.
 
     Returns:
         str:
         Log filename.
     """
     return datetime.now().strftime(filename)
 
 
-def custom_handler(filename: str = None, log_format: logging.Formatter = None) -> logging.FileHandler:
+def custom_handler(
+    filename: str = None, log_format: logging.Formatter = None
+) -> logging.FileHandler:
     """Creates a FileHandler, sets the log format and returns it.
 
     Returns:
         logging.FileHandler:
         Returns file handler.
     """
-    handler = logging.FileHandler(filename=log_file(filename=filename or os.path.join('logs', 'jarvis_%d-%m-%Y.log')),
-                                  mode='a')
+    handler = logging.FileHandler(
+        filename=log_file(
+            filename=filename or os.path.join("logs", "jarvis_%d-%m-%Y.log")
+        ),
+        mode="a",
+    )
     handler.setFormatter(fmt=log_format or DEFAULT_FORMATTER)
     return handler
 
 
 logger.addHandler(hdlr=custom_handler())
```

## jarvis/modules/peripherals.py

```diff
@@ -2,46 +2,55 @@
 """This is a space to test peripherals and get index numbers for each peripheral.
 
 >>> Exceptions
 
 """
 
 import platform
+import sys
 from collections.abc import Generator
-from enum import Enum
-from typing import Dict, Union
+from typing import Dict
 
 import pyaudio
 
 from jarvis.modules.exceptions import no_alsa_err
 
+if sys.version_info.minor > 10:
+    from enum import StrEnum
+else:
+    from enum import Enum
+
+    class StrEnum(str, Enum):
+        """Override for python 3.10 due to lack of StrEnum."""
+
+
 if platform.system() == "Linux":
     with no_alsa_err():
         audio_engine = pyaudio.PyAudio()
 else:
     audio_engine = pyaudio.PyAudio()
 # audio_engine.open(output_device_index=6, output=True, channels=1, format=pyaudio.paInt16, rate=16000)
 _device_range = audio_engine.get_device_count()
 
 
-class ChannelType(str, Enum):
+class ChannelType(StrEnum):
     """Allowed values for channel types.
 
     >>> ChannelType
 
     """
 
-    input_channels: str = 'maxInputChannels'
-    output_channels: str = 'maxOutputChannels'
+    input_channels: str = "maxInputChannels"
+    output_channels: str = "maxOutputChannels"
 
 
 channel_type = ChannelType
 
 
-def get_audio_devices(channels: str) -> Generator[Dict[str, Union[str, int, float]]]:
+def get_audio_devices(channels: str) -> Generator[Dict[str, str | int | float]]:
     """Iterates over all devices and yields the device that has input channels.
 
     Args:
         channels: Takes an argument to determine whether to yield input or output channels.
 
     Yields:
         dict:
```

## jarvis/modules/audio/listener.py

```diff
@@ -1,19 +1,23 @@
 # noinspection PyUnresolvedReferences
 """Module for speech recognition listener.
 
 >>> Listener
 
 """
-from typing import Union
 
 from playsound import playsound
 from pydantic import PositiveFloat, PositiveInt
-from speech_recognition import (Microphone, Recognizer, RequestError,
-                                UnknownValueError, WaitTimeoutError)
+from speech_recognition import (
+    Microphone,
+    Recognizer,
+    RequestError,
+    UnknownValueError,
+    WaitTimeoutError,
+)
 
 from jarvis.executors import files, word_match
 from jarvis.modules.audio import speaker
 from jarvis.modules.exceptions import EgressErrors
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.utils import shared, support
@@ -26,17 +30,20 @@
     recognizer.energy_threshold = recognizer_settings.energy_threshold
     recognizer.pause_threshold = recognizer_settings.pause_threshold
     recognizer.phrase_threshold = recognizer_settings.phrase_threshold
     recognizer.dynamic_energy_threshold = recognizer_settings.dynamic_energy_threshold
     recognizer.non_speaking_duration = recognizer_settings.non_speaking_duration
 
 
-def listen(sound: bool = True, no_conf: bool = False,
-           timeout: Union[PositiveInt, PositiveFloat] = models.env.listener_timeout,
-           phrase_time_limit: Union[PositiveInt, PositiveFloat] = models.env.listener_phrase_limit) -> Union[str, None]:
+def listen(
+    sound: bool = True,
+    no_conf: bool = False,
+    timeout: PositiveInt | PositiveFloat = models.env.listener_timeout,
+    phrase_time_limit: PositiveInt | PositiveFloat = models.env.listener_phrase_limit,
+) -> str | None:
     """Function to activate listener, this function will be called by most upcoming functions to listen to user input.
 
     Args:
         sound: Flag whether to play the listener indicator sound. Defaults to True unless set to False.
         no_conf: Boolean flag to skip confidence check.
         timeout: Custom timeout for functions expecting a longer wait time.
         phrase_time_limit: Custom time limit for functions expecting a longer user input.
@@ -44,24 +51,32 @@
     Returns:
         str:
          - Returns recognized statement from the microphone.
     """
     with microphone as source:
         try:
             playsound(sound=models.indicators.start, block=False) if sound else None
-            support.write_screen(text=f"Listener activated [{timeout}: {phrase_time_limit}]")
-            listened = recognizer.listen(source=source, timeout=timeout, phrase_time_limit=phrase_time_limit)
+            support.write_screen(
+                text=f"Listener activated [{timeout}: {phrase_time_limit}]"
+            )
+            listened = recognizer.listen(
+                source=source, timeout=timeout, phrase_time_limit=phrase_time_limit
+            )
             playsound(sound=models.indicators.end, block=False) if sound else None
             support.flush_screen()
-            recognized, confidence = recognizer.recognize_google(audio_data=listened, with_confidence=True)
+            recognized, confidence = recognizer.recognize_google(
+                audio_data=listened, with_confidence=True
+            )
             # Should never meet the condition for called by offline but just a safety net
             if no_conf or shared.called_by_offline:
                 logger.info(recognized)
                 return recognized
-            logger.info("Recognized '%s' with a confidence rate '%.2f'", recognized, confidence)
+            logger.info(
+                "Recognized '%s' with a confidence rate '%.2f'", recognized, confidence
+            )
             if confidence > models.env.recognizer_confidence:
                 return recognized
             else:
                 speaker.speak(text=f"Did you mean {recognized!r}?", run=True)
                 if listen_recursive(source, 5, 5):
                     return recognized
         except (UnknownValueError, RequestError, WaitTimeoutError):
@@ -80,13 +95,17 @@
 
     Returns:
         bool:
         True if confirmation was received from the user via voice input.
     """
     playsound(sound=models.indicators.start, block=False)
     support.write_screen(text=f"Listener activated [{timeout}: {phrase_time_limit}]")
-    listened = recognizer.listen(source=source, timeout=timeout, phrase_time_limit=phrase_time_limit)
+    listened = recognizer.listen(
+        source=source, timeout=timeout, phrase_time_limit=phrase_time_limit
+    )
     playsound(sound=models.indicators.end, block=False)
     support.flush_screen()
     recognized = recognizer.recognize_google(audio_data=listened)
-    if word_match.word_match(phrase=recognized, match_list=('yes', 'yeah', 'yep', 'yeh', 'indeed')):
+    if word_match.word_match(
+        phrase=recognized, match_list=("yes", "yeah", "yep", "yeh", "indeed")
+    ):
         return True
```

## jarvis/modules/audio/speaker.py

```diff
@@ -5,115 +5,139 @@
 
 """
 import os
 import re
 import sys
 from datetime import datetime
 from threading import Thread
-from typing import Union
 
 import pynotification
 import requests
 from playsound import playsound
 
 from jarvis.executors import files
 from jarvis.modules.exceptions import EgressErrors
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.utils import shared, support
 
 
-def speech_synthesizer(text: str,
-                       timeout: Union[int, float] = None,
-                       quality: str = models.env.speech_synthesis_quality,
-                       voice: str = models.env.speech_synthesis_voice) -> bool:
+def speech_synthesizer(
+    text: str,
+    timeout: int | float = None,
+    quality: str = models.env.speech_synthesis_quality,
+    voice: str = models.env.speech_synthesis_voice,
+) -> bool:
     """Makes a post call to docker container for speech synthesis.
 
     Args:
         text: Takes the text that has to be spoken as an argument.
         timeout: Time to wait for the docker image to process text-to-speech request.
         quality: Quality at which the conversion is to be done.
         voice: Voice for speech synthesis.
 
     Returns:
         bool:
         A boolean flag to indicate whether speech synthesis has worked.
     """
     logger.info("Request for speech synthesis: %s", text)
     text = text.replace("%", " percent")
-    if time_in_str := re.findall(r'(\d+:\d+\s?(?:AM|PM|am|pm:?))', text):
+    if time_in_str := re.findall(r"(\d+:\d+\s?(?:AM|PM|am|pm:?))", text):
         for t_12 in time_in_str:
             t_24 = datetime.strftime(datetime.strptime(t_12, "%I:%M %p"), "%H:%M")
             logger.info("Converted %s -> %s", t_12, t_24)
             text = text.replace(t_12, t_24)
-    if 'IP' in text.split():
-        ip_new = '-'.join([i for i in text.split(' ')[-1]]).replace('-.-', ', ')  # 192.168.1.1 -> 1-9-2, 1-6-8, 1, 1
-        text = text.replace(text.split(' ')[-1], ip_new).replace(' IP ', ' I.P. ')
+    if "IP" in text.split():
+        ip_new = "-".join([i for i in text.split(" ")[-1]]).replace(
+            "-.-", ", "
+        )  # 192.168.1.1 -> 1-9-2, 1-6-8, 1, 1
+        text = text.replace(text.split(" ")[-1], ip_new).replace(" IP ", " I.P. ")
     # Raises UnicodeDecodeError within docker container
     text = text.replace("\N{DEGREE SIGN}F", " degrees fahrenheit")
     text = text.replace("\N{DEGREE SIGN}C", " degrees celsius")
     try:
         response = requests.post(
             url=f"http://{models.env.speech_synthesis_host}:{models.env.speech_synthesis_port}/api/tts",
-            headers={"Content-Type": "text/plain"}, params={"voice": voice, "vocoder": quality},
-            data=text, verify=False,
-            timeout=timeout or models.env.speech_synthesis_timeout  # set timeout here as speak() sets it on demand
+            headers={"Content-Type": "text/plain"},
+            params={"voice": voice, "vocoder": quality},
+            data=text,
+            verify=False,
+            timeout=timeout
+            or models.env.speech_synthesis_timeout,  # set timeout here as speak() sets it on demand
         )
         if response.ok:
             with open(file=models.fileio.speech_synthesis_wav, mode="wb") as file:
                 file.write(response.content)
                 file.flush()
             return True
-        logger.error("{code}::http://{host}:{port}/api/tts".format(code=response.status_code,
-                                                                   host=models.env.speech_synthesis_host,
-                                                                   port=models.env.speech_synthesis_port))
+        logger.error(
+            "{code}::http://{host}:{port}/api/tts".format(
+                code=response.status_code,
+                host=models.env.speech_synthesis_host,
+                port=models.env.speech_synthesis_port,
+            )
+        )
         return False
     except UnicodeError as error:
         logger.error(error)
     except EgressErrors as error:
         logger.error(error)
         logger.info("Disabling speech synthesis")
         # Purposely exclude timeout since, speech-synthesis takes more time initially to download the required voice
-        if not any((isinstance(error, TimeoutError), isinstance(error, requests.Timeout))):
+        if not any(
+            (isinstance(error, TimeoutError), isinstance(error, requests.Timeout))
+        ):
             models.env.speech_synthesis_timeout = 0
 
 
 def speak(text: str = None, run: bool = False, block: bool = True) -> None:
     """Speaks a statement from the received text.
 
     Args:
         text: Takes the text that has to be spoken as an argument.
         run: Takes a boolean flag to choose whether to run the loop.
         block: Takes a boolean flag to await other tasks while speaking. [Applies only for speech-synthesis on docker]
     """
     if not models.AUDIO_DRIVER:
         models.env.speech_synthesis_timeout = 10
-    caller = sys._getframe(1).f_code.co_name  # noqa: PyProtectedMember,PyUnresolvedReferences
-    if caller not in ('conditions', 'custom_conditions'):  # function where all the magic happens
+    caller = sys._getframe(  # noqa: PyProtectedMember,PyUnresolvedReferences
+        1
+    ).f_code.co_name
+    # function where all the magic happens
+    if caller not in (
+        "conditions",
+        "custom_conditions",
+    ):
         Thread(target=frequently_used, kwargs={"function_name": caller}).start()
     if text:
-        text = text.replace('\n', '\t').strip()
+        text = text.replace("\n", "\t").strip()
         shared.text_spoken = text
         if shared.called_by_offline:
             logger.debug("Speaker called by: '%s' with text: '%s'", caller, text)
             shared.offline_caller = caller
             return
         logger.info("Response: %s", text)
         support.write_screen(text=text)
-        if models.env.speech_synthesis_timeout and \
-                speech_synthesizer(text=text) and \
-                os.path.isfile(models.fileio.speech_synthesis_wav):
+        if (
+            models.env.speech_synthesis_timeout
+            and speech_synthesizer(text=text)
+            and os.path.isfile(models.fileio.speech_synthesis_wav)
+        ):
             playsound(sound=models.fileio.speech_synthesis_wav, block=block)
             os.remove(models.fileio.speech_synthesis_wav)
         elif models.AUDIO_DRIVER:
             models.AUDIO_DRIVER.say(text=text)
         else:
             support.flush_screen()
-            pynotification.pynotifier(message="speech-synthesis became unavailable when audio driver was faulty\n"
-                                              "resolving to on-screen response", title="AUDIO ERROR", dialog=True)
+            pynotification.pynotifier(
+                message="speech-synthesis became unavailable when audio driver was faulty\n"
+                "resolving to on-screen response",
+                title="AUDIO ERROR",
+                dialog=True,
+            )
             print(text)
     if run and models.AUDIO_DRIVER and not shared.called_by_offline:
         logger.debug("Speaker called by: '%s'", caller)
         models.AUDIO_DRIVER.runAndWait()
 
 
 def frequently_used(function_name: str) -> None:
@@ -127,9 +151,11 @@
     """
     data = files.get_frequent()
     data = {k: v for k, v in data.items() if isinstance(v, int)}  # clean up
     if data.get(function_name):
         data[function_name] += 1
     else:
         data[function_name] = 1
-    data = {k: v for k, v in sorted(data.items(), key=lambda x: x[1], reverse=True)}  # sort by size
+    data = {
+        k: v for k, v in sorted(data.items(), key=lambda x: x[1], reverse=True)
+    }  # sort by size
     files.put_frequent(data=data)
```

## jarvis/modules/audio/speech_synthesis.py

```diff
@@ -4,15 +4,15 @@
 >>> SpeechSynthesis
 
 """
 
 import os
 import subprocess
 import time
-from typing import NoReturn, Union
+from typing import NoReturn
 
 import docker
 import psutil
 import requests
 from docker.client import DockerClient
 from docker.errors import APIError, ContainerError, DockerException, NotFound
 
@@ -29,28 +29,34 @@
         port: Port number that the process is listening to.
 
     Returns:
         int:
         ID of the process that's listening to the port.
     """
     try:
-        for conn in psutil.net_connections(kind='inet'):
+        for conn in psutil.net_connections(kind="inet"):
             if conn.laddr.port == port:
                 return conn.pid
     except psutil.Error as error:
         # network connections aren't available via psutil for macOS
         if models.settings.os != models.supported_platforms.macOS:
             logger.error(error)
     try:
-        result = subprocess.run(['lsof', '-i', f':{port}', '-t'], capture_output=True, text=True)
+        result = subprocess.run(
+            ["lsof", "-i", f":{port}", "-t"], capture_output=True, text=True
+        )
         if result.returncode == 0:
             return int(result.stdout.strip())
-    except (subprocess.CalledProcessError, subprocess.SubprocessError, FileNotFoundError) as error:
+    except (
+        subprocess.CalledProcessError,
+        subprocess.SubprocessError,
+        FileNotFoundError,
+    ) as error:
         if isinstance(error, subprocess.CalledProcessError):
-            result = error.output.decode(encoding='UTF-8').strip()
+            result = error.output.decode(encoding="UTF-8").strip()
             logger.error("[%d]: %s", error.returncode, result)
         else:
             logger.error(error)
 
 
 def check_existing() -> bool:
     """Checks for existing connection.
@@ -58,28 +64,36 @@
     Returns:
         bool:
         A boolean flag whether a valid connection is present.
     """
     if port_handler.is_port_in_use(port=models.env.speech_synthesis_port):
         logger.info("%d is currently in use.", models.env.speech_synthesis_port)
         try:
-            res = requests.get(url=f"http://{models.env.speech_synthesis_host}:{models.env.speech_synthesis_port}",
-                               timeout=1)
+            res = requests.get(
+                url=f"http://{models.env.speech_synthesis_host}:{models.env.speech_synthesis_port}",
+                timeout=1,
+            )
             if res.ok:
-                logger.info('http://{host}:{port} is accessible.'.format(host=models.env.speech_synthesis_host,
-                                                                         port=models.env.speech_synthesis_port))
+                logger.info(
+                    "http://{host}:{port} is accessible.".format(
+                        host=models.env.speech_synthesis_host,
+                        port=models.env.speech_synthesis_port,
+                    )
+                )
                 return True
             return False
         except EgressErrors as error:
             logger.error(error)
             if not port_handler.kill_port_pid(port=models.env.speech_synthesis_port):
-                logger.critical('ATTENTION::Failed to kill existing PID. Attempting to re-create session.')
+                logger.critical(
+                    "ATTENTION::Failed to kill existing PID. Attempting to re-create session."
+                )
 
 
-def run_existing_container(client: DockerClient, verified: bool = False) -> Union[str, None]:
+def run_existing_container(client: DockerClient, verified: bool = False) -> str | None:
     """Tries to run the container if a container ID is present in the CID file in fileio directory.
 
     Args:
         client: DockerClient object.
         verified: Boolean flag to simply validate the container ID and return it.
 
     See Also:
@@ -100,35 +114,56 @@
         if verified:
             logger.info("Container ID not found")
         return
     try:
         container = client.containers.get(container_id)
         if verified:
             return container.id
-        state = container.attrs.get('State')
-        if any((state['Running'], state['Dead'], state['ExitCode'], state['Error'], state['OOMKilled'])):
-            logger.info("Purging available container [%s] since one or more reuse conditions weren't met", container.id)
+        state = container.attrs.get("State")
+        if any(
+            (
+                state["Running"],
+                state["Dead"],
+                state["ExitCode"],
+                state["Error"],
+                state["OOMKilled"],
+            )
+        ):
+            logger.info(
+                "Purging available container [%s] since one or more reuse conditions weren't met",
+                container.id,
+            )
             container.remove()
             return
-        logger.info("Starting available container [%s] since all the reuse conditions were met", container.id)
+        logger.info(
+            "Starting available container [%s] since all the reuse conditions were met",
+            container.id,
+        )
         container.start()
         # Just because the container ID is valid, it doesn't mean
         #   it belongs to speech-synthesis, or it runs and maps the expected port
         time.sleep(5)
         if check_existing():
             return container.id
         else:
-            logger.warning("Container ID is valid, but API is unreachable. Hence removing container.")
+            logger.warning(
+                "Container ID is valid, but API is unreachable. Hence removing container."
+            )
             container.remove()
     except NotFound as error:
         logger.warning(error.explanation)
     except ContainerError as error:
         err = f": {error.stderr}" if error.stderr else ""
-        logger.error("Command '{}' in image '{}' returned non-zero exit status {}{}",
-                     error.command, error.image, error.exit_status, err)
+        logger.error(
+            "Command '{}' in image '{}' returned non-zero exit status {}{}",
+            error.command,
+            error.image,
+            error.exit_status,
+            err,
+        )
     except DockerException as error:
         logger.critical(error.__str__())
 
 
 def run_new_container(client: DockerClient) -> str:
     """Spins up a new docker container for speech-synthesis. Pulls the image if not found locally.
 
@@ -141,44 +176,61 @@
     """
     models.env.home = str(models.env.home)
     try:
         # This may take a while depending on image availability
         logger.info("Spinning up a new docker container to run speech-synthesis API")
         result = client.containers.run(
             image="thevickypedia/speech-synthesis",
-            ports={f"5002/tcp": models.env.speech_synthesis_port},
+            ports={"5002/tcp": models.env.speech_synthesis_port},
             environment=[f"HOME={models.env.home}"],
             volumes={models.env.home: {"bind": models.env.home, "mode": "rw"}},
             working_dir=os.getcwd(),
-            user=f"{os.getuid()}:{os.getgid()}", detach=True,
-            restart_policy={"Name": "on-failure", "MaximumRetryCount": 10}
+            user=f"{os.getuid()}:{os.getgid()}",
+            detach=True,
+            restart_policy={"Name": "on-failure", "MaximumRetryCount": 10},
         )
         return result.id
     except ContainerError as error:
         # should never get here since detach flag is set to true
         err = f": {error.stderr}" if error.stderr else ""
-        logger.error("Command '{}' in image '{}' returned non-zero exit status {}{}",
-                     error.command, error.image, error.exit_status, err)
+        logger.error(
+            "Command '{}' in image '{}' returned non-zero exit status {}{}",
+            error.command,
+            error.image,
+            error.exit_status,
+            err,
+        )
     except APIError as error:
         logger.error(error.explanation)
 
 
 def stream_logs(client: DockerClient, container_id: str) -> NoReturn:
     """Stream logs into the log file specific for speech synthesis.
 
     Args:
         client: DockerClient object.
         container_id: Container ID.
     """
-    logs = client.api.logs(container=container_id, stdout=True, stderr=True, stream=True, timestamps=True,
-                           tail='all', since=None, follow=None, until=None)
-    log_file = open(file=models.fileio.speech_synthesis_log, mode="a", buffering=1)  # 1 line buffer on file
+    logs = client.api.logs(
+        container=container_id,
+        stdout=True,
+        stderr=True,
+        stream=True,
+        timestamps=True,
+        tail="all",
+        since=None,
+        follow=None,
+        until=None,
+    )
+    log_file = open(
+        file=models.fileio.speech_synthesis_log, mode="a", buffering=1
+    )  # 1 line buffer on file
     os.fsync(log_file.fileno())  # Tell os module to write the buffer of the file
-    __asterisks = ''.join(['*' for _ in range(120)])
-    __spaces = ''.join(['-' for _ in range(47)])
+    __asterisks = "".join(["*" for _ in range(120)])
+    __spaces = "".join(["-" for _ in range(47)])
     log_file.write(f"\n{__asterisks}\n")
     log_file.write(f"{__spaces} STREAMING CONTAINER LOGS {__spaces}\n")
     log_file.write(f"{__asterisks}\n\n")
     for line in logs:
         log_file.write(line.decode(encoding="UTF-8"))
         log_file.flush()  # Write everything in buffer to file right away
     log_file.close()
@@ -189,29 +241,36 @@
     multiprocessing_logger(filename=models.fileio.speech_synthesis_log)
     try:
         docker_client = docker.from_env()
     except DockerException as error:
         logger.critical(error.__str__())
         return
     if check_existing():  # Test call to speech synthesis API successful
-        if container_id := run_existing_container(docker_client, True):  # Map existing API session with docker
+        # Map existing API session with docker
+        if container_id := run_existing_container(docker_client, True):
             logger.info("Dry run successful, streaming logs")
             stream_logs(docker_client, container_id)
         logger.warning("Unable to stream container logs locally")
         # Container logs will not be available outside docker, so try to update the process map with docker's PID
-        if pid := find_pid_by_port(models.env.speech_synthesis_port):  # Identified the PID to update in process map
+        # Identified the PID to update in process map
+        if pid := find_pid_by_port(models.env.speech_synthesis_port):
             process_map.update(speech_synthesis_api.__name__, models.settings.pid, pid)
         else:
             # Failed to get the PID of the listening API, hence removing entry from process map
             process_map.remove(speech_synthesis_api.__name__)
         return
 
-    container_id = run_existing_container(docker_client) or run_new_container(docker_client)
+    container_id = run_existing_container(docker_client) or run_new_container(
+        docker_client
+    )
     if not container_id:
         return
     # Due to lack of a "cidfile" flag, create one manually
-    with open(models.fileio.speech_synthesis_cid, 'w') as file:
+    with open(models.fileio.speech_synthesis_cid, "w") as file:
         file.write(container_id)
     logger.info(f"Started speech synthesis in docker container {container_id!r}")
     if models.env.speech_synthesis_port != 5002:
-        logger.info("Docker port 5002 has been mapped to %d on localhost", models.env.speech_synthesis_port)
+        logger.info(
+            "Docker port 5002 has been mapped to %d on localhost",
+            models.env.speech_synthesis_port,
+        )
     stream_logs(docker_client, container_id)
```

## jarvis/modules/audio/tts_stt.py

```diff
@@ -3,30 +3,29 @@
 
 >>> TTS and STT
 
 """
 
 import os
 import time
-from typing import Union
 
 import soundfile
 from pydantic import FilePath
 from speech_recognition import AudioFile, Recognizer, UnknownValueError
 
 from jarvis.modules.audio import voices
 from jarvis.modules.logger import logger
 from jarvis.modules.utils import shared
 
 recognizer = Recognizer()
 
 AUDIO_DRIVER = voices.voice_default()
 
 
-def text_to_audio(text: str, filename: Union[FilePath, str] = None) -> Union[FilePath, str, None]:
+def text_to_audio(text: str, filename: FilePath | str = None) -> FilePath | str | None:
     """Converts text into an audio file using the default speaker configuration.
 
     Args:
         filename: Name of the file that has to be generated.
         text: Text that has to be converted to audio.
 
     Warnings:
@@ -43,15 +42,15 @@
     if os.path.isfile(filename) and os.stat(filename).st_size:
         logger.info("Generated %s", filename)
         data, samplerate = soundfile.read(file=filename)
         soundfile.write(file=filename, data=data, samplerate=samplerate)
         return filename
 
 
-def audio_to_text(filename: Union[FilePath, str]) -> str:
+def audio_to_text(filename: FilePath | str) -> str:
     """Converts audio to text using speech recognition.
 
     Args:
         filename: Filename to process the information from.
 
     Returns:
         str:
```

## jarvis/modules/audio/voices.py

```diff
@@ -22,16 +22,19 @@
 
     Returns:
         Engine:
         Returns the audio driver as an object.
     """
     if models.settings.invoker != "sphinx-build":
         for voice in models.voices:
-            if voice.name == models.env.voice_name or models.env.voice_name in voice.name:
-                if models.settings.pname == 'JARVIS':
+            if (
+                voice.name == models.env.voice_name
+                or models.env.voice_name in voice.name
+            ):
+                if models.settings.pname == "JARVIS":
                     logger.debug(voice.__dict__)
                 models.AUDIO_DRIVER.setProperty("voice", voice.id)
                 models.AUDIO_DRIVER.setProperty("rate", models.env.speech_rate)
                 break
     return models.AUDIO_DRIVER
 
 
@@ -41,31 +44,39 @@
     Args:
         phrase: Takes the phrase spoken as an argument.
     """
     if not phrase:
         voice_default()
         return
 
-    choices_to_say = ["My voice module has been reconfigured. Would you like me to retain this?",
-                      "Here's an example of one of my other voices. Would you like me to use this one?",
-                      "How about this one?"]
+    choices_to_say = [
+        "My voice module has been reconfigured. Would you like me to retain this?",
+        "Here's an example of one of my other voices. Would you like me to use this one?",
+        "How about this one?",
+    ]
 
     for ind, voice in enumerate(models.voices):
         models.AUDIO_DRIVER.setProperty("voice", models.voices[ind].id)
         speaker.speak(text=f"I am {voice.name} {models.env.title}!")
-        support.write_screen(f"Voice module has been re-configured to {ind}::{voice.name}")
+        support.write_screen(
+            f"Voice module has been re-configured to {ind}::{voice.name}"
+        )
         if ind < len(choices_to_say):
             speaker.speak(text=choices_to_say[ind])
         else:
             speaker.speak(text=random.choice(choices_to_say))
         speaker.speak(run=True)
         if not (keyword := listener.listen()):
             voice_default()
-            speaker.speak(text=f"Sorry {models.env.title}! I had trouble understanding. I'm back to my default voice.")
+            speaker.speak(
+                text=f"Sorry {models.env.title}! I had trouble understanding. I'm back to my default voice."
+            )
             return
         elif "exit" in keyword or "quit" in keyword or "Xzibit" in keyword:
             voice_default()
-            speaker.speak(text=f"Reverting the changes to default voice module {models.env.title}!")
+            speaker.speak(
+                text=f"Reverting the changes to default voice module {models.env.title}!"
+            )
             return
-        elif word_match.word_match(phrase=keyword, match_list=keywords.keywords['ok']):
+        elif word_match.word_match(phrase=keyword, match_list=keywords.keywords["ok"]):
             speaker.speak(text=random.choice(conversation.acknowledgement))
             return
```

## jarvis/modules/camera/camera.py

```diff
@@ -2,20 +2,22 @@
 
 >>> Camera
 
 """
 
 import subprocess
 from collections.abc import Generator
-from typing import Dict, List, Union
+from typing import Dict, List
 
 from jarvis.modules.exceptions import CameraError
 from jarvis.modules.models import models
 
-Windows = """wmic path CIM_LogicalDevice where "Description like 'USB Video%'" get /value"""
+Windows = (
+    """wmic path CIM_LogicalDevice where "Description like 'USB Video%'" get /value"""
+)
 Darwin = "system_profiler SPCameraDataType"
 Linux = "v4l2-ctl --list-devices"
 
 
 def list_splitter(original_list: List[str], delimiter: str) -> List[List[str]]:
     """Splits a list into multiple lists at a specific value given.
 
@@ -35,20 +37,29 @@
         delimiter: Value where the list has to be split.
 
     Returns:
         List[List[str]]:
         Returns list of list(s).
     """
     # Split indices at the required value where the list as to be split and rebuilt as a new one
-    split_indices = [index + 1 for index, val in enumerate(original_list) if val.startswith(delimiter)]
+    split_indices = [
+        index + 1
+        for index, val in enumerate(original_list)
+        if val.startswith(delimiter)
+    ]
 
     # Rebuild the new list split at the given index value
-    return [original_list[i: j] for i, j in
-            zip([0] + split_indices,
-                split_indices + ([len(original_list)] if split_indices[-1] != len(original_list) else []))]
+    return [
+        original_list[i:j]
+        for i, j in zip(
+            [0] + split_indices,
+            split_indices
+            + ([len(original_list)] if split_indices[-1] != len(original_list) else []),
+        )
+    ]
 
 
 class Camera:
     """Initiates camera object to get information about the connected cameras.
 
     >>> Camera
 
@@ -72,111 +83,117 @@
 
         self.output, err = subprocess.Popen(
             cmd,
             shell=True,
             stdout=subprocess.PIPE,
             stderr=subprocess.PIPE,
         ).communicate()
-        if error := err.decode(encoding='UTF-8'):
+        if error := err.decode(encoding="UTF-8"):
             raise CameraError(error)
-        self.output = self.output.decode(encoding='UTF-8').splitlines()
+        self.output = self.output.decode(encoding="UTF-8").splitlines()
 
     def _get_camera_info_linux(self) -> Generator[str]:
         """Get camera information for Linux.
 
         Warnings:
             - Results will be yielded in raw terminal output format.
 
         Yields:
             str:
             Returns the information of all connected cameras as a list of string.
         """
         for cam in self.output:
-            if cam.strip().startswith('/dev/video'):
-                result = subprocess.check_output(f"v4l2-ctl --device={cam.strip()} --all", shell=True)
-                yield result.decode(encoding='UTF-8')
+            if cam.strip().startswith("/dev/video"):
+                result = subprocess.check_output(
+                    f"v4l2-ctl --device={cam.strip()} --all", shell=True
+                )
+                yield result.decode(encoding="UTF-8")
 
     def _list_cameras_linux(self) -> Generator[str]:
         """Yields the camera name for Linux.
 
         Yields:
             str:
             Names of the connected cameras.
         """
         for cam in self.output:
-            if cam.strip().startswith('/dev/video'):
+            if cam.strip().startswith("/dev/video"):
                 try:
-                    result = subprocess.check_output(f"v4l2-ctl --device={cam.strip()} --all | grep Name", shell=True)
-                    yield result.decode(encoding='UTF-8').replace('Name', '').strip().lstrip(':').strip()
+                    result = subprocess.check_output(
+                        f"v4l2-ctl --device={cam.strip()} --all | grep Name", shell=True
+                    )
+                    yield result.decode(encoding="UTF-8").replace(
+                        "Name", ""
+                    ).strip().lstrip(":").strip()
                 except subprocess.CalledProcessError:
                     continue
 
     def _get_camera_info_windows(self) -> Generator[Dict[str, str]]:
         """Get camera information for WindowsOS.
 
         Yields:
             Dict[str, str]:
             Returns the information of all connected cameras as a list of dictionary.
         """
         output = list(filter(None, self.output))  # Filter null values in the list
         if not output:
             return
 
-        for list_ in list_splitter(original_list=output, delimiter='SystemName'):
+        for list_ in list_splitter(original_list=output, delimiter="SystemName"):
             values = {}
             for sub_list in list_:
-                values[sub_list.split('=')[0]] = sub_list.split('=')[1]
+                values[sub_list.split("=")[0]] = sub_list.split("=")[1]
             yield values
 
     def _list_cameras_windows(self) -> Generator[str]:
         """Yields the camera name for WindowsOS.
 
         Yields:
             str:
             Names of the connected cameras.
         """
         for camera in self._get_camera_info_windows():
-            yield camera.get('Name')
+            yield camera.get("Name")
 
     def _get_camera_info_darwin(self) -> Generator[Dict[str, str]]:
         """Get camera information for macOS.
 
         Returns:
             Dict[str, str]:
             Returns the raw XML output as a dictionary.
         """
         output = list(filter(None, self.output))
         if not output:
             return
         output = [v.strip() for v in output][1:]
 
-        for list_ in list_splitter(original_list=output, delimiter='Unique ID'):
+        for list_ in list_splitter(original_list=output, delimiter="Unique ID"):
             values = {}
             for sub_list in list_:
-                if sub_list.endswith(':'):
-                    values['Name'] = sub_list.rstrip(':')
+                if sub_list.endswith(":"):
+                    values["Name"] = sub_list.rstrip(":")
                 else:
-                    values[sub_list.split(':')[0]] = sub_list.split(':')[1]
+                    values[sub_list.split(":")[0]] = sub_list.split(":")[1]
             yield values
 
     def _list_cameras_darwin(self) -> Generator[str]:
         """Yields the camera name for macOS.
 
         Yields:
             str:
             Names of the connected cameras.
         """
         for camera in self._get_camera_info_darwin():
-            yield camera.get('Name')
+            yield camera.get("Name")
 
-    def get_camera_info(self) -> List[Union[Dict[str, str], str]]:
+    def get_camera_info(self) -> List[Dict[str, str] | str]:
         """Gets the yielded camera information as a generator object and returns as a list.
 
         Returns:
-            List[Dict[str]]:
+            List[Dict[str, str] | str]:
             List of dictionaries.
         """
         if models.settings.os == models.supported_platforms.macOS:
             return list(self._get_camera_info_darwin())
         elif models.settings.os == models.supported_platforms.windows:
             return list(self._get_camera_info_windows())
         else:
@@ -199,8 +216,8 @@
     def get_index(self) -> str:
         """Get the index and name of each connected camera.
 
         Returns:
             str:
             Index and name of cameras as a string.
         """
-        return '\n'.join([f"{i}: {c}" for i, c in enumerate(self.list_cameras())])
+        return "\n".join([f"{i}: {c}" for i, c in enumerate(self.list_cameras())])
```

## jarvis/modules/conditions/conversation.py

```diff
@@ -15,39 +15,89 @@
     """Returns a dictionary of base keywords mapping.
 
     Returns:
         OrderedDict:
         OrderedDict of category and keywords as key-value pairs.
     """
     return OrderedDict(
-        greeting=["how are you", "how are you doing", "how have you been", "how do you do", "how's it going",
-                  "hows it going"],
+        greeting=[
+            "how are you",
+            "how are you doing",
+            "how have you been",
+            "how do you do",
+            "how's it going",
+            "hows it going",
+        ],
         hi=["hey", "hola", "hello", "hi", "howdy", "hey", "chao", "hiya", "aloha"],
-        capabilities=["what can you do", "what all can you do", "what are your capabilities", "what's your capacity",
-                      "what are you capable of", "whats your capacity"],
-        languages=["what languages do you speak", "what are all the languages you can speak",
-                   "what languages do you know", "can you speak in a different language",
-                   "how many languages can you speak", "what are you made of", "what languages can you speak",
-                   "what languages do you speak", "what are the languages you can speak"],
+        capabilities=[
+            "what can you do",
+            "what all can you do",
+            "what are your capabilities",
+            "what's your capacity",
+            "what are you capable of",
+            "whats your capacity",
+        ],
+        languages=[
+            "what languages do you speak",
+            "what are all the languages you can speak",
+            "what languages do you know",
+            "can you speak in a different language",
+            "how many languages can you speak",
+            "what are you made of",
+            "what languages can you speak",
+            "what languages do you speak",
+            "what are the languages you can speak",
+        ],
         what=["what are you"],
-        who=["who are you", "what do I call you", "what's your name", "what is your name", "whats your name"],
-        age=["how old are you", "what is your age", "what's your age", "whats your age"],
+        who=[
+            "who are you",
+            "what do I call you",
+            "what's your name",
+            "what is your name",
+            "whats your name",
+        ],
+        age=[
+            "how old are you",
+            "what is your age",
+            "what's your age",
+            "whats your age",
+        ],
         form=["where is your body", "where's your body", "wheres your body"],
         whats_up=["what's up", "what is up", "what's going on", "sup", "whats up"],
-        about_me=["tell me about you", "tell me something about you", "i would like to get you know you",
-                  "tell me about yourself"],
+        about_me=[
+            "tell me about you",
+            "tell me something about you",
+            "i would like to get you know you",
+            "tell me about yourself",
+        ],
     )
 
 
-wake_up1 = [f"For you {models.env.title}! Always!", f"At your service {models.env.title}!"]
-wake_up2 = [f"Up and running {models.env.title}!", f"We are online and ready {models.env.title}!",
-            f"I have indeed been uploaded {models.env.title}!",
-            f"My listeners have been activated {models.env.title}!"]
+wake_up1 = [
+    f"For you {models.env.title}! Always!",
+    f"At your service {models.env.title}!",
+]
+wake_up2 = [
+    f"Up and running {models.env.title}!",
+    f"We are online and ready {models.env.title}!",
+    f"I have indeed been uploaded {models.env.title}!",
+    f"My listeners have been activated {models.env.title}!",
+]
 wake_up3 = [f"I'm here {models.env.title}!"]
-confirmation = [f"Requesting confirmation {models.env.title}! Did you mean",
-                f"{models.env.title}, are you sure you want to"]
-acknowledgement = ["Check", "Roger that!", f"Will do {models.env.title}!", f"You got it {models.env.title}!",
-                   f"Done {models.env.title}!", f"By all means {models.env.title}!",
-                   f"Indeed {models.env.title}!",
-                   f"Gladly {models.env.title}!", f"Sure {models.env.title}!",
-                   f"Without fail {models.env.title}!",
-                   f"Buttoned up {models.env.title}!", f"Executed {models.env.title}!"]
+confirmation = [
+    f"Requesting confirmation {models.env.title}! Did you mean",
+    f"{models.env.title}, are you sure you want to",
+]
+acknowledgement = [
+    "Check",
+    "Roger that!",
+    f"Will do {models.env.title}!",
+    f"You got it {models.env.title}!",
+    f"Done {models.env.title}!",
+    f"By all means {models.env.title}!",
+    f"Indeed {models.env.title}!",
+    f"Gladly {models.env.title}!",
+    f"Sure {models.env.title}!",
+    f"Without fail {models.env.title}!",
+    f"Buttoned up {models.env.title}!",
+    f"Executed {models.env.title}!",
+]
```

## jarvis/modules/conditions/keywords.py

```diff
@@ -28,88 +28,212 @@
         - But the approach is time taking and inconsistent.
 
     Returns:
         OrderedDict:
         OrderedDict of category and keywords as key-value pairs.
     """
     return OrderedDict(
-        listener_control=['listener'],
-        send_notification=['message', 'text', 'sms', 'mail', 'email', 'messages', 'mails', 'emails'],
-        lights=['light', 'party mode', 'lights'],
-        television=['tv', 'television', 'tvs', 'televisions', "tv's", "television's"],
-        volume=['volume', 'mute'],
-        car=['car', 'vehicle'],
-        thermostat=['indoor', 'outdoor', 'thermostat'],
-        weather=['weather', 'temperature', 'sunrise', 'sun rise', 'sunset', 'sun set'],
-        restart_control=['restart', 'reboot'],
-
+        listener_control=["listener"],
+        send_notification=[
+            "message",
+            "text",
+            "sms",
+            "mail",
+            "email",
+            "messages",
+            "mails",
+            "emails",
+        ],
+        lights=["light", "party mode", "lights"],
+        television=["tv", "television", "tvs", "televisions", "tv's", "television's"],
+        volume=["volume", "mute"],
+        car=["car", "vehicle"],
+        thermostat=["indoor", "outdoor", "thermostat"],
+        weather=["weather", "temperature", "sunrise", "sun rise", "sunset", "sun set"],
+        restart_control=["restart", "reboot"],
         # ORDER OF THE ABOVE SHOULD BE RETAINED, AS THE CONDITION LOOP WILL RUN IN THE SAME ORDER
         # internal
-
-        meetings=['meeting', 'meetings'],
+        meetings=["meeting", "meetings"],
         events=[],  # will be loaded based on the event app that's chosen during startup
-        current_date=["today's date", 'current date', 'what is the date', "what's the date", 'todays date',
-                      'whats the date'],
-        current_time=['current time', 'time now', 'time in', 'what is the time', "what's the time", 'whats the time'],
-        system_info=['configuration', 'system config'],
-        ip_info=['address'],
-        wikipedia_=['wikipedia', 'info', 'information'],
-        news=['news'],
-        report=['report'],
-        robinhood=['robinhood', 'investment', 'portfolio', 'summary'],
-        repeat=['repeat'],
-        location=['location', 'where are you'],
-        locate=['locate', 'where is my', "where's my", 'wheres my'],
-        read_gmail=['email', 'mail', 'mails', 'emails'],
-        meaning=['meaning', 'dictionary', 'definition', 'meanings', 'definitions'],
-        todo=['plan', 'to do', 'to-do', 'todo', 'plans'],
-        kill_alarm=['stop alarm', 'stop my alarm', 'stop another alarm', 'stop an alarm', 'stop timer', 'stop my timer',
-                    'stop another timer', 'stop an timer', 'turn off my alarm', 'turn my alarm off',
-                    'stop another alarm', 'turn off alarm', 'turn off my timer', 'turn my timer off',
-                    'stop another timer', 'turn off timer', 'delete alarm', 'delete my alarm', 'delete another alarm',
-                    'delete an alarm', 'delete timer', 'delete my timer', 'delete another timer', 'delete an timer',
-                    'stop all my alarms', 'turn off all my alarms', 'delete all my alarms'],
-        set_alarm=['alarm', 'alarms', 'wake me', 'timer'],
-        google_home=['google home', 'googlehome'],
-        jokes=['joke', 'jokes', 'make me laugh'],
-        reminder=['remind', 'reminder', 'reminders'],
-        distance=['far', 'distance', 'miles', 'kilometers', 'mile', 'kilometer'],
-        locate_places=['where is', "where's", 'which city', 'which state', 'which country', 'which county', 'wheres'],
-        directions=['take me', 'directions'],
-        notes=['notes', 'note'],
-        github=['git', 'github', 'clone', 'GitHub'],
-        apps=['launch'],
-        music=['music', 'songs', 'play', 'song'],
-        faces=['face', 'recognize', 'who am i', 'detect', 'facial', 'recognition', 'detection', 'faces'],
-        speed_test=['speed', 'fast'],
-        brightness=['brightness', 'bright', 'dim'],
-        guard_enable=['turn on security mode', 'enable security mode', 'turn on guardian mode', 'enable guardian mode'],
-        guard_disable=['turn off security mode', 'disable security mode', 'turn off guardian mode',
-                       'disable guardian mode'],
-        flip_a_coin=['head', 'tail', 'flip', 'heads', 'tails'],
-        facts=['fact', 'facts'],
-        voice_changer=['voice', 'voices'],
-        system_vitals=['vitals', 'statistics', 'readings', 'stats'],
-        vpn_server=['vpn'],
-        automation_handler=['automation'],
-        background_task_handler=['background'],
-        photo=['picture', 'snap', 'photo', 'pictures', 'photos'],
-        version=['version'],
-        simulation=['simulator', 'variation', 'simulation', 'variations'],
-        celebrate=['festival', 'festivals', 'celebrate', 'celebration', 'holiday', 'holidays', 'event', 'events'],
-        sleep_control=['lock', 'screen', 'pc', 'computer'],
-        sentry=['sleep', 'activate sentry mode'],
-        shutdown=['shutdown', 'shut down', 'terminate'],
-        ok=['yeah', 'yes', 'yep', 'go ahead', 'proceed', 'continue', 'carry on', 'please', 'keep going'],
-        exit_=['exit', 'quit', 'no', 'nope', 'thank you', 'Xzibit', 'bye', 'good bye', 'see you later',
-               'talk to you later', "that's it", 'that is it', 'never mind', 'nevermind', 'thats it'],
-        kill=['kill', 'terminate yourself', 'stop running'],
-        avoid=['sun', 'moon', 'mercury', 'venus', 'earth', 'mars', 'jupiter', 'saturn', 'uranus', 'neptune', 'pluto',
-               'a.m.', 'p.m.', 'update my to do list', 'launch', 'safari', 'body', 'human', 'centimeter', 'server',
-               'cloud', 'update'],
-        ngrok=['ngrok', 'public url'],
-        secrets=['secret', 'secrets', 'param', 'params', 'parameter', 'parameters'],
-        restrictions=['restriction', 'restrictions', 'restrict', 'release']
+        current_date=[
+            "today's date",
+            "current date",
+            "what is the date",
+            "what's the date",
+            "todays date",
+            "whats the date",
+        ],
+        current_time=[
+            "current time",
+            "time now",
+            "time in",
+            "what is the time",
+            "what's the time",
+            "whats the time",
+        ],
+        system_info=["configuration", "system config"],
+        ip_info=["address"],
+        wikipedia_=["wikipedia", "info", "information"],
+        news=["news"],
+        report=["report"],
+        robinhood=["robinhood", "investment", "portfolio", "summary"],
+        repeat=["repeat"],
+        location=["location", "where are you"],
+        locate=["locate", "where is my", "where's my", "wheres my"],
+        read_gmail=["email", "mail", "mails", "emails"],
+        meaning=["meaning", "dictionary", "definition", "meanings", "definitions"],
+        todo=["plan", "to do", "to-do", "todo", "plans"],
+        kill_alarm=[
+            "stop alarm",
+            "stop my alarm",
+            "stop another alarm",
+            "stop an alarm",
+            "stop timer",
+            "stop my timer",
+            "stop another timer",
+            "stop an timer",
+            "turn off my alarm",
+            "turn my alarm off",
+            "stop another alarm",
+            "turn off alarm",
+            "turn off my timer",
+            "turn my timer off",
+            "stop another timer",
+            "turn off timer",
+            "delete alarm",
+            "delete my alarm",
+            "delete another alarm",
+            "delete an alarm",
+            "delete timer",
+            "delete my timer",
+            "delete another timer",
+            "delete an timer",
+            "stop all my alarms",
+            "turn off all my alarms",
+            "delete all my alarms",
+        ],
+        set_alarm=["alarm", "alarms", "wake me", "timer"],
+        google_home=["google home", "googlehome"],
+        jokes=["joke", "jokes", "make me laugh"],
+        reminder=["remind", "reminder", "reminders"],
+        distance=["far", "distance", "miles", "kilometers", "mile", "kilometer"],
+        locate_places=[
+            "where is",
+            "where's",
+            "which city",
+            "which state",
+            "which country",
+            "which county",
+            "wheres",
+        ],
+        directions=["take me", "directions"],
+        notes=["notes", "note"],
+        github=["git", "github", "clone", "GitHub"],
+        apps=["launch"],
+        music=["music", "songs", "play", "song"],
+        faces=[
+            "face",
+            "recognize",
+            "who am i",
+            "detect",
+            "facial",
+            "recognition",
+            "detection",
+            "faces",
+        ],
+        speed_test=["speed", "fast"],
+        brightness=["brightness", "bright", "dim"],
+        guard_enable=[
+            "turn on security mode",
+            "enable security mode",
+            "turn on guardian mode",
+            "enable guardian mode",
+        ],
+        guard_disable=[
+            "turn off security mode",
+            "disable security mode",
+            "turn off guardian mode",
+            "disable guardian mode",
+        ],
+        flip_a_coin=["head", "tail", "flip", "heads", "tails"],
+        facts=["fact", "facts"],
+        voice_changer=["voice", "voices"],
+        system_vitals=["vitals", "statistics", "readings", "stats"],
+        vpn_server=["vpn"],
+        automation_handler=["automation"],
+        background_task_handler=["background"],
+        photo=["picture", "snap", "photo", "pictures", "photos"],
+        version=["version"],
+        simulation=["simulator", "variation", "simulation", "variations"],
+        celebrate=[
+            "festival",
+            "festivals",
+            "celebrate",
+            "celebration",
+            "holiday",
+            "holidays",
+            "event",
+            "events",
+        ],
+        sleep_control=["lock", "screen", "pc", "computer"],
+        sentry=["sleep", "activate sentry mode"],
+        shutdown=["shutdown", "shut down", "terminate"],
+        ok=[
+            "yeah",
+            "yes",
+            "yep",
+            "go ahead",
+            "proceed",
+            "continue",
+            "carry on",
+            "please",
+            "keep going",
+        ],
+        exit_=[
+            "exit",
+            "quit",
+            "no",
+            "nope",
+            "thank you",
+            "Xzibit",
+            "bye",
+            "good bye",
+            "see you later",
+            "talk to you later",
+            "that's it",
+            "that is it",
+            "never mind",
+            "nevermind",
+            "thats it",
+        ],
+        kill=["kill", "terminate yourself", "stop running"],
+        avoid=[
+            "sun",
+            "moon",
+            "mercury",
+            "venus",
+            "earth",
+            "mars",
+            "jupiter",
+            "saturn",
+            "uranus",
+            "neptune",
+            "pluto",
+            "a.m.",
+            "p.m.",
+            "update my to do list",
+            "launch",
+            "safari",
+            "body",
+            "human",
+            "centimeter",
+            "server",
+            "cloud",
+            "update",
+        ],
+        ngrok=["ngrok", "public url"],
+        secrets=["secret", "secrets", "param", "params", "parameter", "parameters"],
+        restrictions=["restriction", "restrictions", "restrict", "release"],
     )
 
 
 ignore_after, ignore_and = [], []
```

## jarvis/modules/crontab/expression.py

```diff
@@ -3,48 +3,65 @@
 
 >>> Expression
 
 """
 
 import calendar
 import datetime
-from typing import Tuple, Union
+from typing import Tuple
 
 from jarvis.modules.exceptions import InvalidArgument
 
 
 class CronExpression:
     """Initiates CronExpression object to validate a crontab entry.
 
     >>> CronExpression
 
     """
 
-    DAY_NAMES = zip(('sun', 'mon', 'tue', 'wed', 'thu', 'fri', 'sat'), range(7))
+    DAY_NAMES = zip(("sun", "mon", "tue", "wed", "thu", "fri", "sat"), range(7))
     MINUTES = (0, 59)
     HOURS = (0, 23)
     DAYS_OF_MONTH = (1, 31)
     MONTHS = (1, 12)
     DAYS_OF_WEEK = (0, 6)
     L_FIELDS = (DAYS_OF_WEEK, DAYS_OF_MONTH)
     FIELD_RANGES = (MINUTES, HOURS, DAYS_OF_MONTH, MONTHS, DAYS_OF_WEEK)
-    MONTH_NAMES = zip(('jan', 'feb', 'mar', 'apr', 'may', 'jun',
-                       'jul', 'aug', 'sep', 'oct', 'nov', 'dec'), range(1, 13))
+    MONTH_NAMES = zip(
+        (
+            "jan",
+            "feb",
+            "mar",
+            "apr",
+            "may",
+            "jun",
+            "jul",
+            "aug",
+            "sep",
+            "oct",
+            "nov",
+            "dec",
+        ),
+        range(1, 13),
+    )
     DEFAULT_EPOCH = (1970, 1, 1, 0, 0, 0)
     SUBSTITUTIONS = {
         "@yearly": "0 0 1 1 *",
         "@annually": "0 0 1 1 *",
         "@monthly": "0 0 1 * *",
         "@weekly": "0 0 * * 0",
         "@daily": "0 0 * * *",
         "@midnight": "0 0 * * *",
-        "@hourly": "0 * * * *"
+        "@hourly": "0 * * * *",
     }
 
-    def __init__(self, line: str, epoch: tuple = DEFAULT_EPOCH, epoch_utc_offset: int = 0):
+    def __init__(
+        self, line: str, epoch: tuple = DEFAULT_EPOCH, epoch_utc_offset: int = 0
+    ):
         """Instantiates a CronExpression object with an optionally defined epoch.
 
         Raises:
             InvalidArgument:
             If the given number of fields is invalid.
 
         Notes:
@@ -56,24 +73,24 @@
         for key, value in self.SUBSTITUTIONS.items():
             if line.startswith(key):
                 line = line.replace(key, value)
                 break
 
         fields = line.split(None, 5)
         if len(fields) == 5:
-            fields.append('')
+            fields.append("")
 
         if len(fields) < 6:
             raise InvalidArgument(f"{line!r} has invalid cron expression!")
 
         minutes, hours, dom, months, dow, self.comment = fields
-        self.expression = ' '.join(fields[:5])
+        self.expression = " ".join(fields[:5])
 
-        dow = dow.replace('7', '0').replace('?', '*')
-        dom = dom.replace('?', '*')
+        dow = dow.replace("7", "0").replace("?", "*")
+        dom = dom.replace("?", "*")
 
         for monthstr, monthnum in self.MONTH_NAMES:
             months = months.lower().replace(monthstr, str(monthnum))
 
         for dowstr, downum in self.DAY_NAMES:
             dow = dow.lower().replace(dowstr, str(downum))
 
@@ -90,15 +107,15 @@
 
     def __str__(self):
         """Built-in override."""
         base = self.__class__.__name__ + "(%s)"
         cron_line = self.string_tab + [str(self.comment)]
         if not self.comment:
             cron_line.pop()
-        arguments = '"' + ' '.join(cron_line) + '"'
+        arguments = '"' + " ".join(cron_line) + '"'
         if self.epoch != self.DEFAULT_EPOCH:
             return base % (arguments + ", epoch=" + repr(self.epoch))
         else:
             return base % arguments
 
     def __repr__(self):
         """Built-in override."""
@@ -109,34 +126,37 @@
 
         Notes:
             This method should only be called by the user if the string_tab member is modified.
         """
         self.numerical_tab = []
 
         for field_str, span in zip(self.string_tab, self.FIELD_RANGES):
-            split_field_str = field_str.split(',')
+            split_field_str = field_str.split(",")
             if len(split_field_str) > 1 and "*" in split_field_str:
-                raise InvalidArgument("\"*\" must be alone in a field.")
+                raise InvalidArgument('"*" must be alone in a field.')
 
             unified = set()
             for cron_atom in split_field_str:
                 # parse_atom only handles static cases
-                for special_char in ('%', '#', 'L', 'W'):
+                for special_char in ("%", "#", "L", "W"):
                     if special_char in cron_atom:
                         break
                 else:
                     unified.update(parse_atom(cron_atom, span))
 
             self.numerical_tab.append(unified)
 
         if self.string_tab[2] == "*" and self.string_tab[4] != "*":
             self.numerical_tab[2] = set()
 
-    def check_trigger(self, date_tuple: Union[Tuple[int, int, int, int, int], Tuple[int, ...]] = None,
-                      utc_offset: int = 0) -> bool:
+    def check_trigger(
+        self,
+        date_tuple: Tuple[int, int, int, int, int] | Tuple[int, ...] = None,
+        utc_offset: int = 0,
+    ) -> bool:
         """Returns boolean indicating if the trigger is active at the given time.
 
         Args:
             date_tuple: Tuple of year, month, date, hour and minute. Defaults to current.
             utc_offset: UTC offset.
 
         See Also:
@@ -147,15 +167,17 @@
         Returns:
             bool:
             A boolean flag to indicate whether the given datetime matches the crontab entry.
         """
         if date_tuple:
             year, month, day, hour, mins = date_tuple
         else:
-            year, month, day, hour, mins = tuple(map(int, datetime.datetime.now().strftime("%Y %m %d %H %M").split()))
+            year, month, day, hour, mins = tuple(
+                map(int, datetime.datetime.now().strftime("%Y %m %d %H %M").split())
+            )
         given_date = datetime.date(year, month, day)
         zeroday = datetime.date(*self.epoch[:3])
         last_dom = calendar.monthrange(year, month)[-1]
         dom_matched = True
 
         # In calendar and datetime.date.weekday, Monday = 0
         given_dow = (datetime.date.weekday(given_date) + 1) % 7
@@ -166,72 +188,76 @@
         mod_delta_yrs = year - self.epoch[0]
         mod_delta_mon = month - self.epoch[1] + mod_delta_yrs * 12
         mod_delta_day = (given_date - zeroday).days
         mod_delta_hrs = hour - self.epoch[3] + mod_delta_day * 24 + utc_diff
         mod_delta_min = mins - self.epoch[4] + mod_delta_hrs * 60
 
         # Makes iterating through like components easier.
-        quintuple = zip((mins, hour, day, month, given_dow), self.numerical_tab, self.string_tab,
-                        (mod_delta_min, mod_delta_hrs, mod_delta_day, mod_delta_mon, mod_delta_day),
-                        self.FIELD_RANGES)
+        quintuple = zip(
+            (mins, hour, day, month, given_dow),
+            self.numerical_tab,
+            self.string_tab,
+            (mod_delta_min, mod_delta_hrs, mod_delta_day, mod_delta_mon, mod_delta_day),
+            self.FIELD_RANGES,
+        )
 
         for value, valid_values, field_str, delta_t, field_type in quintuple:
             # All valid, static values for the fields are stored in sets
             if value in valid_values:
                 continue
 
             # The following for loop implements the logic for context
             # sensitive and epoch sensitive constraints. break statements,
             # which are executed when a match is found, lead to a continue
             # in the outer loop. If there are no matches found, the given date
             # does not match expression constraints, so the function returns
             # False as seen at the end of this for...else... construct.
-            for cron_atom in field_str.split(','):
-                if cron_atom[0] == '%':
+            for cron_atom in field_str.split(","):
+                if cron_atom[0] == "%":
                     if not (delta_t % int(cron_atom[1:])):
                         break
 
-                elif field_type == self.DAYS_OF_WEEK and '#' in cron_atom:
+                elif field_type == self.DAYS_OF_WEEK and "#" in cron_atom:
                     d, n = int(cron_atom[0]), int(cron_atom[2])
                     # Computes Nth occurence of D day of the week
                     if (((d - first_dow) % 7) + 1 + 7 * (n - 1)) == day:
                         break
 
-                elif field_type == self.DAYS_OF_MONTH and cron_atom[-1] == 'W':
+                elif field_type == self.DAYS_OF_MONTH and cron_atom[-1] == "W":
                     target = min(int(cron_atom[:-1]), last_dom)
                     lands_on = (first_dow + target - 1) % 7
                     if lands_on == 0:
                         # Shift from Sun. to Mon. unless Mon. is next month
                         target += 1 if target < last_dom else -2
                     elif lands_on == 6:
                         # Shift from Sat. to Fri. unless Fri. in prior month
                         target += -1 if target > 1 else 2
 
                     # Break if the day is correct, and target is a weekday
                     if target == day and (first_dow + target - 7) % 7 > 1:
                         break
 
-                elif field_type in self.L_FIELDS and cron_atom.endswith('L'):
+                elif field_type in self.L_FIELDS and cron_atom.endswith("L"):
                     # In dom field, L means the last day of the month
                     target = last_dom
 
                     if field_type == self.DAYS_OF_WEEK:
                         # Calculates the last occurence of given day of week
                         desired_dow = int(cron_atom[:-1])
-                        target = (((desired_dow - first_dow) % 7) + 29)
+                        target = ((desired_dow - first_dow) % 7) + 29
                         target -= 7 if target > last_dom else 0
 
                     if target == day:
                         break
             else:
                 # See 2010.11.15 of CHANGELOG
-                if field_type == self.DAYS_OF_MONTH and self.string_tab[4] != '*':
+                if field_type == self.DAYS_OF_MONTH and self.string_tab[4] != "*":
                     dom_matched = False
                     continue
-                elif field_type == self.DAYS_OF_WEEK and self.string_tab[2] != '*':
+                elif field_type == self.DAYS_OF_WEEK and self.string_tab[2] != "*":
                     # If we got here, then days of months validated so it does
                     # not matter that days of the week failed.
                     return dom_matched
 
                 # None of the expressions matched which means this field fails
                 return False
 
@@ -262,36 +288,36 @@
         set([18, 22, 0, 4])
 
         >>> parse_atom("*/9",(0,23))
         set([0, 9, 18])
     """
     parse = parse.strip()
     increment = 1
-    if parse == '*':
+    if parse == "*":
         return set(range(minmax[0], minmax[1] + 1))
     elif parse.isdigit():
         # A single number still needs to be returned as a set
         value = int(parse)
         if minmax[0] <= value <= minmax[1]:
             return {value}
         else:
             raise InvalidArgument(f"invalid bounds: {parse}")
-    elif '-' in parse or '/' in parse:
-        divide = parse.split('/')
+    elif "-" in parse or "/" in parse:
+        divide = parse.split("/")
         subrange = divide[0]
         if len(divide) == 2:
             # Example: 1-3/5 or */7 increment should be 5 and 7 respectively
             increment = int(divide[1])
 
-        if '-' in subrange:
+        if "-" in subrange:
             # Example: a-b
-            prefix, suffix = [int(n) for n in subrange.split('-')]
+            prefix, suffix = [int(n) for n in subrange.split("-")]
             if prefix < minmax[0] or suffix > minmax[1]:
                 raise InvalidArgument(f"invalid bounds: {parse}")
-        elif subrange == '*':
+        elif subrange == "*":
             # Include all values with the given range
             prefix, suffix = minmax
         else:
             raise InvalidArgument(f"unrecognized symbol: {subrange}")
 
         if prefix < suffix:
             # Example: 7-10
@@ -299,16 +325,22 @@
         else:
             # Example: 12-4/2; (12, 12 + n, ..., 12 + m*n) U (n_0, ..., 4)
             noskips = list(range(prefix, minmax[1] + 1))
             noskips += list(range(minmax[0], suffix + 1))
             return set(noskips[::increment])
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     job = CronExpression("0 0 * * 1-5/2 find /var/log -delete")
     print(job.comment)
     print(job.expression)
 
-    print(job.check_trigger(tuple(map(int, datetime.datetime.now().strftime("%Y,%m,%d,%H,%M").split(",")))))
+    print(
+        job.check_trigger(
+            tuple(
+                map(int, datetime.datetime.now().strftime("%Y,%m,%d,%H,%M").split(","))
+            )
+        )
+    )
 
     print(job.check_trigger((2022, 7, 27, 0, 0)))
     print(job.check_trigger((2022, 7, 26, 0, 0)))
```

## jarvis/modules/database/database.py

```diff
@@ -5,49 +5,53 @@
 """
 
 import importlib
 import logging
 import os
 import random
 import sqlite3
-from typing import List, Tuple, Union
+from typing import List, Tuple
 
 from pydantic import FilePath
 
 
 class Database:
     """Creates a connection to the base DB.
 
     >>> Database
 
     """
 
-    def __init__(self, database: Union[FilePath, str], timeout: int = 10):
+    def __init__(self, database: FilePath | str, timeout: int = 10):
         """Instantiates the class ``Database`` to create a connection and a cursor.
 
         Args:
             database: Name of the database file.
             timeout: Timeout for the connection to database.
         """
-        if not database.endswith('.db'):
-            database = database + '.db'
+        if not database.endswith(".db"):
+            database = database + ".db"
         self.datastore = database
-        self.connection = sqlite3.connect(database=self.datastore, check_same_thread=False, timeout=timeout)
+        self.connection = sqlite3.connect(
+            database=self.datastore, check_same_thread=False, timeout=timeout
+        )
 
-    def create_table(self, table_name: str, columns: Union[List[str], Tuple[str]]) -> None:
+    def create_table(self, table_name: str, columns: List[str] | Tuple[str]) -> None:
         """Creates the table with the required columns.
 
         Args:
             table_name: Name of the table that has to be created.
             columns: List of columns that has to be created.
         """
         with self.connection:
             cursor = self.connection.cursor()
             # Use f-string or %s as table names cannot be parametrized
-            cursor.execute(f"CREATE TABLE IF NOT EXISTS {table_name} ({', '.join(columns)})")
+            cursor.execute(
+                f"CREATE TABLE IF NOT EXISTS {table_name} ({', '.join(columns)})"
+            )
 
 
 class __TestDatabase:
     """Basic examples of a test database.
 
     >>> __TestDatabase
 
@@ -55,16 +59,16 @@
 
     def __init__(self):
         """Initiates all the imported modules and creates a database file named ``sample``."""
         importlib.reload(module=logging)
 
         handler = logging.StreamHandler()
         fmt_ = logging.Formatter(
-            fmt='%(asctime)s - %(levelname)s - [%(module)s:%(lineno)d] - %(funcName)s - %(message)s',
-            datefmt='%b-%d-%Y %I:%M:%S %p'
+            fmt="%(asctime)s - %(levelname)s - [%(module)s:%(lineno)d] - %(funcName)s - %(message)s",
+            datefmt="%b-%d-%Y %I:%M:%S %p",
         )
         handler.setFormatter(fmt=fmt_)
         logging.root.addHandler(hdlr=handler)
         logging.root.setLevel(level=logging.DEBUG)
         self.db = Database(database="sample")
 
     def at_exit(self):
@@ -88,26 +92,33 @@
             self.db.connection.commit()
 
     def random_double(self) -> None:
         """Example using two columns with only one holding a value at any given time."""
         self.db.create_table(table_name="TestDatabase", columns=["row", "column"])
         with self.db.connection:
             cursor_ = self.db.connection.cursor()
-            cursor_.execute(f"INSERT INTO TestDatabase ({random.choice(['row', 'column'])}) VALUES (?);", (True,))
+            cursor_.execute(
+                f"INSERT INTO TestDatabase ({random.choice(['row', 'column'])}) VALUES (?);",
+                (True,),
+            )
             self.db.connection.commit()
-            if (row := cursor_.execute("SELECT row FROM TestDatabase").fetchone()) and row[0]:
+            if (
+                row := cursor_.execute("SELECT row FROM TestDatabase").fetchone()
+            ) and row[0]:
                 logging.info(f"Row: {row[0]}")
                 cursor_.execute("DELETE FROM TestDatabase WHERE row=1")
                 self.db.connection.commit()
-            if (col := cursor_.execute("SELECT column FROM TestDatabase").fetchone()) and col[0]:
+            if (
+                col := cursor_.execute("SELECT column FROM TestDatabase").fetchone()
+            ) and col[0]:
                 logging.info(f"Column: {col[0]}")
                 cursor_.execute("DELETE FROM TestDatabase WHERE column=1")
                 self.db.connection.commit()
             cursor_.execute("DROP TABLE IF EXISTS TestDatabase")
             self.db.connection.commit()
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     test_db = __TestDatabase()
     test_db.random_single()
     test_db.random_double()
     test_db.at_exit()
```

## jarvis/modules/dictionary/dictionary.py

```diff
@@ -2,24 +2,24 @@
 """Module to get meanings of words from `wordnetweb.princeton.edu <http://wordnetweb.princeton.edu/perl/webwn?s=>`__.
 
 >>> Dictionary
 
 """
 
 import re
-from typing import Dict, Union
+from typing import Dict
 
 import requests
 from bs4 import BeautifulSoup, ResultSet
 
 from jarvis.modules.exceptions import EgressErrors
 from jarvis.modules.logger import logger
 
 
-def meaning(term: str) -> Union[Dict, None]:
+def meaning(term: str) -> Dict | None:
     """Gets the meaning of a word from `wordnetweb.princeton.edu <http://wordnetweb.princeton.edu/perl/webwn?s=>`__.
 
     Args:
         term: Word for which the meaning has to be fetched.
 
     Returns:
         dict:
@@ -41,15 +41,15 @@
             logger.error(types[0].text)
         logger.error("Failed to get meaning for '%s'", term)
         return
     out = {}
     for a in types:
         reg = str(lists[types.index(a)])
         meanings = []
-        for x in re.findall(r'\((.*?)\)', reg):
-            if 'often followed by' in x:
+        for x in re.findall(r"\((.*?)\)", reg):
+            if "often followed by" in x:
                 pass
-            elif len(x) > 5 or ' ' in str(x):
+            elif len(x) > 5 or " " in str(x):
                 meanings.append(x)
         name = a.text
         out[name] = meanings
     return out
```

## jarvis/modules/facenet/face.py

```diff
@@ -3,27 +3,26 @@
 
 >>> Face
 
 """
 
 import imghdr
 import os
-from typing import Union
 
+import cv2
 import face_recognition
-from cv2 import cv2
-from cv2 import data as cv2_data
+from cv2.data import haarcascades
 from PIL import Image, UnidentifiedImageError
 from pydantic import FilePath
 
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 
 
-def verify_image(filename: Union[str, FilePath]) -> bool:
+def verify_image(filename: str | FilePath) -> bool:
     """Verifies if a particular image can be used for training.
 
     Args:
         filename: Name/path of the file.
 
     Returns:
         bool:
@@ -34,27 +33,27 @@
     except UnidentifiedImageError as error:
         logger.error(error)
         return False
     if imghdr.what(file=filename).lower() in ("jpg", "png", "jpeg"):
         return True
 
 
-def condition_check(filename: Union[str, FilePath]) -> bool:
+def condition_check(filename: str | FilePath) -> bool:
     """Condition check to load the dataset.
 
     Args:
         filename: Name of the file to check.
 
     Returns:
         bool:
         Boolean flag whether the file can be considered for training.
     """
     if not os.path.isfile(filename):
         return False
-    if os.path.split(filename)[-1].startswith('.'):
+    if os.path.split(filename)[-1].startswith("."):
         return False
     if not verify_image(filename):
         return False
     return True
 
 
 class FaceNet:
@@ -80,50 +79,76 @@
     def load_dataset(self, location: str) -> None:
         """Loads the dataset."""
         logger.debug("Loading dataset to classify existing images.")
         for char_dir in os.listdir(location):  # loads the training dataset
             if not os.path.isdir(os.path.join(location, char_dir)):
                 continue
             for file_name in os.listdir(os.path.join(location, char_dir)):
-                if not condition_check(filename=os.path.join(location, char_dir, file_name)):
+                if not condition_check(
+                    filename=os.path.join(location, char_dir, file_name)
+                ):
                     continue
                 # loads all the files within the named repo
-                img = face_recognition.load_image_file(os.path.join(location, char_dir, file_name))
-                if encoded := face_recognition.face_encodings(img):  # generates face encoding matrix
+                img = face_recognition.load_image_file(
+                    os.path.join(location, char_dir, file_name)
+                )
+                # generates face encoding matrix
+                if encoded := face_recognition.face_encodings(img):
                     encoded = encoded[0]
                     self.train_faces.append(encoded)  # loads ended values to match
-                    self.train_names.append(char_dir)  # loads the names of each named subdirectories
-
-    def face_recognition(self, location: Union[str, FilePath], retry_count: int = 20) -> str:
+                    self.train_names.append(
+                        char_dir
+                    )  # loads the names of each named subdirectories
+
+    def face_recognition(
+        self, location: str | FilePath, retry_count: int = 20
+    ) -> str | None:
         """Recognizes faces from the training dataset - images in the ``train`` directory.
 
         Returns:
             retry_count: Number of trials to recognize a face before the function can quit.
 
         Returns:
             str:
             Name of the enclosing directory in case of a recognized face.
         """
+        if not face_recognition:
+            logger.error("Requirement unsatisfied!!")
+            return
         logger.debug("Initiating face recognition.")
         self.load_dataset(location=location)
         for _ in range(retry_count):
             ret, img = self.validation_video.read()  # reads video from web cam
             if not ret:
-                logger.warning("Unable to read from camera index: %d", models.env.camera_index)
+                logger.warning(
+                    "Unable to read from camera index: %d", models.env.camera_index
+                )
                 continue
-            identifier = face_recognition.face_locations(img, model=self.MODEL)  # gets image from the video read above
-            encoded_ = face_recognition.face_encodings(img, identifier)  # creates an encoding for the image
+            identifier = face_recognition.face_locations(
+                img, model=self.MODEL
+            )  # gets image from the video read above
+            encoded_ = face_recognition.face_encodings(
+                img, identifier
+            )  # creates an encoding for the image
             for face_encoding, face_location in zip(encoded_, identifier):
                 # using learning_rate, the encoding is matched against the encoded matrix for images in named directory
-                results = face_recognition.compare_faces(self.train_faces, face_encoding, self.LEARNING_RATE)
-                if True in results:  # if a match is found the directory name is rendered and returned as match value
+                results = face_recognition.compare_faces(
+                    self.train_faces, face_encoding, self.LEARNING_RATE
+                )
+                # if a match is found the directory name is rendered and returned as match value
+                if True in results:
                     return self.train_names[results.index(True)]
 
-    def face_detection(self, retry_count: int = 20, mirror: bool = False, filename: str = 'cv2_open.jpg',
-                       display: bool = False) -> bool:
+    def face_detection(
+        self,
+        retry_count: int = 20,
+        mirror: bool = False,
+        filename: str = "cv2_open.jpg",
+        display: bool = False,
+    ) -> bool:
         """Detects faces by converting it to grayscale and neighbor match method.
 
         Args:
             retry_count: Number of trials to detect a face before the function can quit.
             mirror: Mirrors the live feed vertically.
             filename: Filename under which the detected face has to be stored.
             display: Only displays the live feed instead of saving it to a file.
@@ -132,47 +157,54 @@
             Filename should not include the file path but just the name.
 
         Returns:
             bool:
             A boolean value if not a face was detected.
         """
         logger.debug("Initiating face detection.")
-        cv2_cascades = cv2_data.haarcascades + "haarcascade_frontalface_default.xml"
+        cv2_cascades = haarcascades + "haarcascade_frontalface_default.xml"
         if not os.path.isfile(cv2_cascades):
             logger.debug("Cascades not found at: %s", cv2_cascades)
             raise FileNotFoundError(cv2_cascades)
         cascade = cv2.CascadeClassifier(cv2_cascades)
         for _ in range(retry_count + 1):
             ret, image = self.validation_video.read()  # reads video from web cam
             if not ret:
                 continue
             try:
-                img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # convert the captured image to grayscale
+                img = cv2.cvtColor(
+                    image, cv2.COLOR_BGR2GRAY
+                )  # convert the captured image to grayscale
             except cv2.error as error:
                 logger.error(error)
                 img = image  # proceed without performing grayscale
-            scale_factor = 1.1  # specify how much the image size is reduced at each image scale
+            scale_factor = (
+                1.1  # specify how much the image size is reduced at each image scale
+            )
             min_neighbors = 5  # specify how many neighbors each candidate rectangle should have to retain it
             img = cv2.flip(img, 1) if mirror else img
-            faces = cascade.detectMultiScale(image=img, scaleFactor=scale_factor, minNeighbors=min_neighbors)
+            faces = cascade.detectMultiScale(
+                image=img, scaleFactor=scale_factor, minNeighbors=min_neighbors
+            )
             if display:
                 # Rectangle box around each face
                 for (x, y, w, h) in faces:
                     cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)
-                cv2.imshow('img', img)
-                k = cv2.waitKey(30) & 0xff
+                cv2.imshow("img", img)
+                k = cv2.waitKey(30) & 0xFF
                 if k == 27:
                     break
                 continue
-            if len(faces):  # Returns an empty tuple when no face is detected, returns a matrix when a face is detected
+            # Returns an empty tuple when no face is detected, returns a matrix when a face is detected
+            if len(faces):
                 self.capture_image(filename=filename)
                 if os.path.isfile(filename):
                     return True
 
-    def capture_image(self, filename: str = 'cv2_open.jpg') -> None:
+    def capture_image(self, filename: str = "cv2_open.jpg") -> None:
         """Captures an image and saves it locally.
 
         Args:
             filename: Name of the file to be saved.
         """
         ret, image = self.validation_video.read()
         if not ret:
```

## jarvis/modules/lights/preset_values.py

```diff
@@ -21,9 +21,9 @@
     "green blink": 50,
     "blue blink": 51,
     "yellow blink": 52,
     "light blue blink": 53,
     "violet blink": 54,
     "white blue blink": 55,
     "change colors slowly": 56,
-    "slowly change colors": 57
+    "slowly change colors": 57,
 }
```

## jarvis/modules/lights/smart_lights.py

```diff
@@ -7,15 +7,14 @@
     - https://github.com/adamkempenich/magichome-python/blob/master/magichome.py
     - https://github.com/SynTexDZN/homebridge-syntex-magichome/blob/master/src/flux_led.py
 """
 
 import socket
 import struct
 import time
-from typing import Union
 
 import webcolors
 
 from jarvis.modules.lights import preset_values
 from jarvis.modules.logger import logger
 from jarvis.modules.utils import support
 
@@ -91,37 +90,41 @@
             self.sock.connect((self.device_ip, self.API_PORT))
         except socket.error as error:
             self.sock.close()
             raise socket.error(error)
 
     def turn_on(self) -> None:
         """Turn a device on."""
-        self.send_bytes(0x71, 0x23, 0x0F, 0xA3) if self.device_type < 4 else self.send_bytes(0xCC, 0x23, 0x33)
+        self.send_bytes(
+            0x71, 0x23, 0x0F, 0xA3
+        ) if self.device_type < 4 else self.send_bytes(0xCC, 0x23, 0x33)
 
     def turn_off(self) -> None:
         """Turn a device off."""
-        self.send_bytes(0x71, 0x24, 0x0F, 0xA4) if self.device_type < 4 else self.send_bytes(0xCC, 0x24, 0x33)
+        self.send_bytes(
+            0x71, 0x24, 0x0F, 0xA4
+        ) if self.device_type < 4 else self.send_bytes(0xCC, 0x24, 0x33)
 
     @staticmethod
     def byte_to_percent(byte: int) -> int:
         """Converts byte integer into a percentile."""
         if byte > 255:
             byte = 255
         if byte < 0:
             byte = 0
         return int((byte * 100) / 255)
 
-    def get_status(self) -> Union[str, None]:
+    def get_status(self) -> str | None:
         """Get the current status of a device.
 
         Returns:
             str:
             Status of the light as string.
         """
-        msg = bytearray([0x81, 0x8a, 0x8b])
+        msg = bytearray([0x81, 0x8A, 0x8B])
         csum = sum(msg) & 0xFF
         msg.append(csum)
         try:
             self.sock.send(msg)
         except OSError as error:
             logger.error(error)
             return
@@ -145,19 +148,19 @@
             mode = "custom"
         elif pattern in preset_values.PRESET_VALUES.values():
             mode = "preset"
         else:
             mode = "unknown"
         delay = rx[5]
         delay = delay - 1
-        if delay > 0x1f - 1:
-            delay = 0x1f - 1
+        if delay > 0x1F - 1:
+            delay = 0x1F - 1
         if delay < 0:
             delay = 0
-        inv_speed = int((delay * 100) / (0x1f - 1))
+        inv_speed = int((delay * 100) / (0x1F - 1))
         speed = 100 - inv_speed
         if mode == "color":
             red = rx[6]
             green = rx[7]
             blue = rx[8]
             color_name = webcolors.rgb_to_name((red, green, blue))
             mode_str = f"Color: {color_name}"
@@ -177,15 +180,22 @@
             mode_str = f"Custom pattern (Speed {speed}%)"
         else:
             mode_str = "Unknown mode 0x{:x}".format(pattern)
         if pattern == 0x62:
             mode_str += " (tmp)"
         return f"{power_str} [{mode_str}]"
 
-    def update_device(self, r: int = 0, g: int = 0, b: int = 0, warm_white: int = None, cool_white: int = None) -> None:
+    def update_device(
+        self,
+        r: int = 0,
+        g: int = 0,
+        b: int = 0,
+        warm_white: int = None,
+        cool_white: int = None,
+    ) -> None:
         """Updates a device based upon what we're sending to it.
 
         Values are excepted as integers between 0-255.
         Whites can have a value of None.
 
         Args:
             r: Values for the color Red. [0-255]
@@ -193,58 +203,86 @@
             b: Values for the color Blue. [0-255]
             warm_white: RGB values for the warm white color.
             cool_white: RGB values for the cool white color.
         """
         if self.device_type <= 1:
             # Update an RGB or an RGB + WW device
             warm_white = check_number_range(warm_white)
-            message = [0x31, r, g, b, warm_white, 0x00, 0x0f]
+            message = [0x31, r, g, b, warm_white, 0x00, 0x0F]
             self.send_bytes(*(message + [calculate_checksum(message)]))
 
         elif self.device_type == 2:
             # Update an RGB + WW + CW device
-            message = [0x31,
-                       check_number_range(r),
-                       check_number_range(g),
-                       check_number_range(b),
-                       check_number_range(warm_white),
-                       check_number_range(cool_white),
-                       0x0f, 0x0f]
+            message = [
+                0x31,
+                check_number_range(r),
+                check_number_range(g),
+                check_number_range(b),
+                check_number_range(warm_white),
+                check_number_range(cool_white),
+                0x0F,
+                0x0F,
+            ]
             self.send_bytes(*(message + [calculate_checksum(message)]))
 
         elif self.device_type == 3:
             # Update the white, or color, of a bulb
             if warm_white:
-                message = [0x31, 0x00, 0x00, 0x00,
-                           check_number_range(warm_white),
-                           0x0f, 0x0f]
+                message = [
+                    0x31,
+                    0x00,
+                    0x00,
+                    0x00,
+                    check_number_range(warm_white),
+                    0x0F,
+                    0x0F,
+                ]
                 self.send_bytes(*(message + [calculate_checksum(message)]))
             else:
-                message = [0x31,
-                           check_number_range(r),
-                           check_number_range(g),
-                           check_number_range(b),
-                           0x00, 0xf0, 0x0f]
+                message = [
+                    0x31,
+                    check_number_range(r),
+                    check_number_range(g),
+                    check_number_range(b),
+                    0x00,
+                    0xF0,
+                    0x0F,
+                ]
                 self.send_bytes(*(message + [calculate_checksum(message)]))
 
         elif self.device_type == 4:
             # Update the white, or color, of a legacy bulb
             if warm_white:
-                message = [0x56, 0x00, 0x00, 0x00,
-                           check_number_range(warm_white),
-                           0x0f, 0xaa, 0x56, 0x00, 0x00, 0x00,
-                           check_number_range(warm_white),
-                           0x0f, 0xaa]
+                message = [
+                    0x56,
+                    0x00,
+                    0x00,
+                    0x00,
+                    check_number_range(warm_white),
+                    0x0F,
+                    0xAA,
+                    0x56,
+                    0x00,
+                    0x00,
+                    0x00,
+                    check_number_range(warm_white),
+                    0x0F,
+                    0xAA,
+                ]
                 self.send_bytes(*(message + [calculate_checksum(message)]))
             else:
-                message = [0x56,
-                           check_number_range(r),
-                           check_number_range(g),
-                           check_number_range(b),
-                           0x00, 0xf0, 0xaa]
+                message = [
+                    0x56,
+                    check_number_range(r),
+                    check_number_range(g),
+                    check_number_range(b),
+                    0x00,
+                    0xF0,
+                    0xAA,
+                ]
                 self.send_bytes(*(message + [calculate_checksum(message)]))
         else:
             support.write_screen(text="Incompatible device type received.")
 
     def send_preset_function(self, preset_number: int, speed: int) -> None:
         """Send a preset command to a device.
```

## jarvis/modules/meetings/events.py

```diff
@@ -7,16 +7,17 @@
 
 import os
 import re
 import sqlite3
 import subprocess
 from datetime import datetime
 from multiprocessing import Process
-from multiprocessing.context import \
-    TimeoutError as ThreadTimeoutError  # noqa: PyProtectedMember
+
+# noinspection PyProtectedMember
+from multiprocessing.context import TimeoutError as ThreadTimeoutError
 from multiprocessing.pool import ThreadPool
 
 import pynotification
 
 from jarvis.modules.audio import speaker
 from jarvis.modules.database import database
 from jarvis.modules.logger import logger
@@ -30,19 +31,23 @@
 @retry.retry(attempts=3, interval=2, exclude_exc=sqlite3.OperationalError)
 def events_writer() -> None:
     """Gets return value from ``events_gatherer`` function and writes it to events table in the database.
 
     This function runs in a dedicated process to avoid wait time when events information is requested.
     """
     info = events_gatherer()
-    query = f"INSERT or REPLACE INTO {models.env.event_app} (info, date) VALUES " \
-            f"{(info, datetime.now().strftime('%Y_%m_%d'))}"
+    query = (
+        f"INSERT or REPLACE INTO {models.env.event_app} (info, date) VALUES "
+        f"{(info, datetime.now().strftime('%Y_%m_%d'))}"
+    )
     with db.connection:
         cursor = db.connection.cursor()
-        cursor.execute(f"DELETE FROM {models.env.event_app}")  # Use f-string or %s as table names can't be parametrized
+        cursor.execute(
+            f"DELETE FROM {models.env.event_app}"
+        )  # Use f-string or %s as table names can't be parametrized
         cursor.connection.commit()
         cursor.execute(query)
         cursor.connection.commit()
     return
 
 
 def event_app_launcher() -> None:
@@ -63,96 +68,141 @@
     Returns:
         str:
         - On success, returns a message saying which event is scheduled at what time.
         - If no events, returns a message saying there are no events in the next 12 hours.
         - On failure, returns a message saying Jarvis was unable to read calendar/outlook.
     """
     if not models.env.event_app:
-        return ("No event application was chosen to scan for events. "
-                f"Please specify either {classes.EventApp.CALENDAR.value} or {classes.EventApp.OUTLOOK.value} "
-                "in the environment variables.")
+        return (
+            "No event application was chosen to scan for events. "
+            f"Please specify either {classes.EventApp.CALENDAR.value} or {classes.EventApp.OUTLOOK.value} "
+            "in the environment variables."
+        )
     if models.settings.os != models.supported_platforms.macOS:
-        return f"Reading events from {models.env.event_app} is currently possible only on macOS, " \
-               f"but the host machine is currently running {models.settings.os}."
+        return (
+            f"Reading events from {models.env.event_app} is currently possible only on macOS, "
+            f"but the host machine is currently running {models.settings.os}."
+        )
     failure = None
-    process = subprocess.Popen(["/usr/bin/osascript", models.fileio.event_script] + [str(arg) for arg in [1, 3]],
-                               stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)
+    process = subprocess.Popen(
+        ["/usr/bin/osascript", models.fileio.event_script]
+        + [str(arg) for arg in [1, 3]],
+        stdout=subprocess.PIPE,
+        stderr=subprocess.PIPE,
+        shell=True,
+    )
     out, err = process.communicate()
     # Undo unspecified changes done by ScriptEditor (should only be necessary when package is not pip installed)
     os.system(f"git checkout HEAD -- {models.fileio.event_script} >/dev/null 2>&1")
     # noinspection GrazieInspection
     if error := process.returncode:  # stores non zero error
         err_msg = err.decode("UTF-8")
         err_code = err_msg.split()[-1].strip()
-        if err_code == "(-1728)":  # If 'Jarvis' is unavailable in calendar/outlook application
+        # If 'Jarvis' is unavailable in calendar/outlook application
+        if err_code == "(-1728)":
             logger.warning("'Jarvis' is unavailable in %s.", models.env.event_app)
             return f"Jarvis is unavailable in your {models.env.event_app} {models.env.title}!"
-        elif err_code == "(-1712)":  # If an event takes 2+ minutes, the Apple Event Manager reports a time-out error.
-            failure = f"{models.env.event_app}/event took an unusually long time to respond/complete.\nInclude, " \
-                      f"'with timeout of 300 seconds' to your {models.fileio.event_script} right after the " \
-                      f"'tell application {models.env.event_app}' step and 'end timeout' before the 'end tell' step."
-        elif err_code in ["(-10810)", "(-609)", "(-600)"]:  # If unable to launch the app or app terminates.
+        # If an event takes 2+ minutes, the Apple Event Manager reports a time-out error.
+        elif err_code == "(-1712)":
+            failure = (
+                f"{models.env.event_app}/event took an unusually long time to respond/complete.\nInclude, "
+                f"'with timeout of 300 seconds' to your {models.fileio.event_script} right after the "
+                f"'tell application {models.env.event_app}' step and 'end timeout' before the 'end tell' step."
+            )
+        elif err_code in [
+            "(-10810)",
+            "(-609)",
+            "(-600)",
+        ]:  # If unable to launch the app or app terminates.
             event_app_launcher()
         if not failure:
             failure = f"[{models.env.event_app}:{error}] - {err_msg}"
-        failure = failure.replace('"', '')  # An identifier cant go after this "
+        failure = failure.replace('"', "")  # An identifier cant go after this "
         logger.error(failure)
         pynotification.pynotifier(title="Jarvis", message=failure)
         return f"I was unable to read your {models.env.event_app} {models.env.title}! Please make sure it is in sync."
 
     local_events = out.decode().strip()
     if not local_events or local_events == ",":
         return f"You don't have any events in the next 12 hours {models.env.title}!"
 
     local_events = local_events.replace(", date ", " rEpLaCInG ")
     event_time = local_events.split("rEpLaCInG")[1:]
     event_name = local_events.split("rEpLaCInG")[0].split(", ")
     event_name = util.remove_duplicates(input_=event_name)
     count = len(event_time)
-    [event_name.remove(e) for e in event_name if len(e) <= 5] if count != len(event_name) else None
-    event_status = f"You have {count} events in the next 12 hours {models.env.title}! " if count > 1 else ""
+    [event_name.remove(e) for e in event_name if len(e) <= 5] if count != len(
+        event_name
+    ) else None
+    event_status = (
+        f"You have {count} events in the next 12 hours {models.env.title}! "
+        if count > 1
+        else ""
+    )
     local_events = {}
     for i in range(count):
         if i < len(event_name):
             event_time[i] = re.search(" at (.*)", event_time[i]).group(1).strip()
             dt_string = datetime.strptime(event_time[i], "%I:%M:%S %p")
             event_time[i] = dt_string.strftime("%I:%M %p")
             local_events.update({event_name[i]: event_time[i]})
-    ordered_data = sorted(local_events.items(), key=lambda x: datetime.strptime(x[1], "%I:%M %p"))
+    ordered_data = sorted(
+        local_events.items(), key=lambda x: datetime.strptime(x[1], "%I:%M %p")
+    )
     for index, event in enumerate(ordered_data):
         if count == 1:
             event_status += f"You have an event at {event[1]} {models.env.title}! {event[0].upper()}. "
         else:
-            event_status += f"{event[0]} at {event[1]}, " if index + 1 < len(ordered_data) else \
-                f"{event[0]} at {event[1]}."
+            event_status += (
+                f"{event[0]} at {event[1]}, "
+                if index + 1 < len(ordered_data)
+                else f"{event[0]} at {event[1]}."
+            )
     return event_status
 
 
 def events(*args) -> None:
     """Controller for events."""
     with db.connection:
         cursor = db.connection.cursor()
         # Use f-string or %s as table names cannot be parametrized
-        event_status = cursor.execute(f"SELECT info, date FROM {models.env.event_app}").fetchone()
-    if event_status and event_status[1] == datetime.now().strftime('%Y_%m_%d'):
+        event_status = cursor.execute(
+            f"SELECT info, date FROM {models.env.event_app}"
+        ).fetchone()
+    if event_status and event_status[1] == datetime.now().strftime("%Y_%m_%d"):
         speaker.speak(text=event_status[0])
     elif event_status:
-        logger.warning("Date in event status (%s) does not match the current date (%s)",
-                       event_status[1], datetime.now().strftime('%Y_%m_%d'))
+        logger.warning(
+            "Date in event status (%s) does not match the current date (%s)",
+            event_status[1],
+            datetime.now().strftime("%Y_%m_%d"),
+        )
         logger.info("Starting adhoc process to update %s table.", models.env.event_app)
         Process(target=events_writer).start()
-        speaker.speak(text=f"Events table is outdated {models.env.title}. Please try again in a minute or two.")
+        speaker.speak(
+            text=f"Events table is outdated {models.env.title}. Please try again in a minute or two."
+        )
     else:
         if shared.called_by_offline:
-            logger.info("Starting adhoc process to get events from %s.", models.env.event_app)
+            logger.info(
+                "Starting adhoc process to get events from %s.", models.env.event_app
+            )
             Process(target=events_writer).start()
-            speaker.speak(text=f"Events table is empty {models.env.title}. Please try again in a minute or two.")
+            speaker.speak(
+                text=f"Events table is empty {models.env.title}. Please try again in a minute or two."
+            )
             return
-        event = ThreadPool(processes=1).apply_async(func=events_gatherer)  # Runs parallely and awaits completion
-        speaker.speak(text=f"Please give me a moment {models.env.title}! Let me check your {models.env.event_app}.",
-                      run=True)
+        event = ThreadPool(processes=1).apply_async(
+            func=events_gatherer
+        )  # Runs parallely and awaits completion
+        speaker.speak(
+            text=f"Please give me a moment {models.env.title}! Let me check your {models.env.event_app}.",
+            run=True,
+        )
         try:
             speaker.speak(text=event.get(timeout=60), run=True)
         except ThreadTimeoutError:
             logger.error("Unable to read the calendar within 60 seconds.")
-            speaker.speak(text=f"I wasn't able to read your calendar within the set time limit {models.env.title}!",
-                          run=True)
+            speaker.speak(
+                text=f"I wasn't able to read your calendar within the set time limit {models.env.title}!",
+                run=True,
+            )
```

## jarvis/modules/meetings/ics.py

```diff
@@ -13,27 +13,27 @@
 
 from jarvis.modules.logger import logger
 
 
 class ICS:
     """Wrapper for ics events."""
 
-    __slots__ = ['summary', 'start', 'end', 'all_day', 'duration']
+    __slots__ = ["summary", "start", "end", "all_day", "duration"]
 
     def __init__(self, **kwargs):
         """Instantiates the ICS object to load all required attributes.
 
         Args:
             kwargs: Takes the data as dictionary to load attributes in the object.
         """
-        self.summary: str = kwargs['summary']
-        self.start: datetime.datetime = kwargs['start']
-        self.end: datetime.datetime = kwargs['end']
-        self.all_day: bool = kwargs['all_day']
-        self.duration: datetime.timedelta = kwargs['duration']
+        self.summary: str = kwargs["summary"]
+        self.start: datetime.datetime = kwargs["start"]
+        self.end: datetime.datetime = kwargs["end"]
+        self.all_day: bool = kwargs["all_day"]
+        self.duration: datetime.timedelta = kwargs["duration"]
 
 
 def convert_to_local_tz(ddd_object: vDDDTypes) -> datetime.datetime:
     """Converts any datetime from any timezone to local time.
 
     Args:
         ddd_object: Parsed Datetime, Date, Duration object.
@@ -41,15 +41,17 @@
     Returns:
         datetime.datetime:
         Local datetime object.
     """
     origin_zone = ddd_object.dt.replace(tzinfo=ddd_object.dt.tzinfo)
     destin_zone = origin_zone.astimezone(tz=dateutil.tz.gettz())
     # convert to a datetime object of desired format
-    return datetime.datetime.strptime(destin_zone.strftime("%Y-%m-%d %H:%M:%S"), "%Y-%m-%d %H:%M:%S")
+    return datetime.datetime.strptime(
+        destin_zone.strftime("%Y-%m-%d %H:%M:%S"), "%Y-%m-%d %H:%M:%S"
+    )
 
 
 def all_day_event(dt_start: vDDDTypes, dt_end: vDDDTypes) -> bool:
     """Check if an event is all day by looking for timestamp in the datetime objects.
 
     Args:
         dt_start: Start of the event.
@@ -78,30 +80,52 @@
     Yields:
         ICS:
         Custom ICS object with event summary, start time, end time, duration and all day event flag.
     """
     calendar = Calendar.from_ical(calendar_data)
     for component in calendar.walk():
         if component.name == "VEVENT":
-            summary: vText = component.get('summary')
-            dt_start: vDDDTypes = component.get('dtstart')
-            dt_end: vDDDTypes = component.get('dtend')
+            summary: vText = component.get("summary")
+            dt_start: vDDDTypes = component.get("dtstart")
+            dt_end: vDDDTypes = component.get("dtend")
             if not all((summary, dt_start, dt_end)):
                 logger.warning("Error while parsing, component information is missing.")
-                logger.error("summary: [%s], start: [%s], end: [%s]", summary, dt_start, dt_end)
+                logger.error(
+                    "summary: [%s], start: [%s], end: [%s]", summary, dt_start, dt_end
+                )
                 logger.error(component)
                 continue
             # create a datetime.date object since start/end can be datetime.datetime if it is not an all day event
-            start = datetime.date(year=dt_start.dt.year, month=dt_start.dt.month, day=dt_start.dt.day)
-            end = datetime.date(year=dt_end.dt.year, month=dt_end.dt.month, day=dt_end.dt.day)
+            start = datetime.date(
+                year=dt_start.dt.year, month=dt_start.dt.month, day=dt_start.dt.day
+            )
+            end = datetime.date(
+                year=dt_end.dt.year, month=dt_end.dt.month, day=dt_end.dt.day
+            )
             # event during current date or lookup date is between start and end date (repeat events)
             if start == lookup_date or start <= lookup_date <= end:
                 if all_day_event(dt_start, dt_end):
                     # add a timestamp to all day events' start and end
-                    _start = datetime.datetime.strptime(start.strftime("%Y-%m-%d 00:00:00"), "%Y-%m-%d %H:%M:%S")
-                    _end = datetime.datetime.strptime(end.strftime("%Y-%m-%d 23:59:59"), "%Y-%m-%d %H:%M:%S")
-                    yield ICS(summary=summary, start=_start, end=_end, all_day=True, duration=_end - _start)
+                    _start = datetime.datetime.strptime(
+                        start.strftime("%Y-%m-%d 00:00:00"), "%Y-%m-%d %H:%M:%S"
+                    )
+                    _end = datetime.datetime.strptime(
+                        end.strftime("%Y-%m-%d 23:59:59"), "%Y-%m-%d %H:%M:%S"
+                    )
+                    yield ICS(
+                        summary=summary,
+                        start=_start,
+                        end=_end,
+                        all_day=True,
+                        duration=_end - _start,
+                    )
                 else:
                     # convert to local timezone
                     _start = convert_to_local_tz(ddd_object=dt_start)
                     _end = convert_to_local_tz(ddd_object=dt_end)
-                    yield ICS(summary=summary, start=_start, end=_end, all_day=False, duration=_end - _start)
+                    yield ICS(
+                        summary=summary,
+                        start=_start,
+                        end=_end,
+                        all_day=False,
+                        duration=_end - _start,
+                    )
```

## jarvis/modules/meetings/ics_meetings.py

```diff
@@ -5,16 +5,17 @@
 
 """
 
 import datetime
 import sqlite3
 import time
 from multiprocessing import Process, Queue
-from multiprocessing.context import \
-    TimeoutError as ThreadTimeoutError  # noqa: PyProtectedMember
+
+# noinspection PyProtectedMember
+from multiprocessing.context import TimeoutError as ThreadTimeoutError
 from multiprocessing.pool import ThreadPool
 from typing import List
 
 import requests
 
 from jarvis.executors import word_match
 from jarvis.modules.audio import speaker
@@ -39,21 +40,28 @@
         queue: Multiprocessing queue in case mute for meetings is enabled.
     """
     info = meetings_gatherer(queue=queue)
     with db.connection:
         cursor = db.connection.cursor()
         cursor.execute("DELETE FROM ics")
         cursor.connection.commit()
-        cursor.execute("INSERT or REPLACE INTO ics (info, date) VALUES (?,?)",
-                       (info, datetime.datetime.now().strftime('%Y_%m_%d'),))
+        cursor.execute(
+            "INSERT or REPLACE INTO ics (info, date) VALUES (?,?)",
+            (
+                info,
+                datetime.datetime.now().strftime("%Y_%m_%d"),
+            ),
+        )
         cursor.connection.commit()
     return
 
 
-def meetings_gatherer(custom_date: datetime.date = None, addon: str = "today", queue: Queue = None) -> str:
+def meetings_gatherer(
+    custom_date: datetime.date = None, addon: str = "today", queue: Queue = None
+) -> str:
     """Get ICS data, parse it and frame a statement with meeting information.
 
     Args:
         custom_date: Takes custom date as a datetime object.
         addon: When the custom date is.
         queue: Multiprocessing queue to put events' time during which the listener will be deactivated.
 
@@ -70,56 +78,78 @@
     except EgressErrors as error:
         logger.error(error)
         return f"I'm sorry {models.env.title}! I was unable to connect to the shared calendar!"
     if not response.ok:
         logger.error("[%d]: [%s]", response.status_code, response.text)
         return "I wasn't able to read your calendar schedule sir! Please check the shared URL."
     if custom_date:
-        events: List[ics.ICS] = list(ics.parse_calendar(calendar_data=response.text, lookup_date=custom_date))
+        events: List[ics.ICS] = list(
+            ics.parse_calendar(calendar_data=response.text, lookup_date=custom_date)
+        )
     else:
         now = datetime.datetime.now()
-        events: List[ics.ICS] = list(ics.parse_calendar(
-            calendar_data=response.text, lookup_date=datetime.date(year=now.year, month=now.month, day=now.day))
+        events: List[ics.ICS] = list(
+            ics.parse_calendar(
+                calendar_data=response.text,
+                lookup_date=datetime.date(year=now.year, month=now.month, day=now.day),
+            )
         )
     if not events:
         if "last" in addon or "yesterday" in addon:
             return f"You did not have any meetings {addon} {models.env.title}!"
         return f"You don't have any meetings {addon} {models.env.title}!"
     meeting_status, count = "", 0
     for index, event in enumerate(events):
         # Skips if meeting ended earlier than current time
-        if time.mktime(event.end.timetuple()) < int(time.time()) and \
-                "last" not in addon and "yesterday" not in addon:
+        if (
+            time.mktime(event.end.timetuple()) < int(time.time())
+            and "last" not in addon
+            and "yesterday" not in addon
+        ):
             continue
         count += 1
         begin_local = event.start.strftime("%I:%M %p")
         event_duration = support.time_converter(second=event.duration.total_seconds())
         if queue and models.env.mute_for_meetings and not event.all_day:
-            logger.debug("Adding entry to mute during meetings: %s: %s", begin_local, event_duration)
+            logger.debug(
+                "Adding entry to mute during meetings: %s: %s",
+                begin_local,
+                event_duration,
+            )
             # create a dict instead of putting the event in queue, as duplicate objects cannot be stripped
             queue.put({event.summary: [begin_local, event.duration.total_seconds()]})
         if len(events) == 1:
             if event.all_day:
-                meeting_status += f"You have an all day meeting {models.env.title}! {event.summary}. "
+                meeting_status += (
+                    f"You have an all day meeting {models.env.title}! {event.summary}. "
+                )
             else:
-                meeting_status += f"You have a meeting at {begin_local} for {event_duration} {models.env.title}! " \
-                                  f"{event.summary}. "
+                meeting_status += (
+                    f"You have a meeting at {begin_local} for {event_duration} {models.env.title}! "
+                    f"{event.summary}. "
+                )
         else:
             if event.all_day:
                 meeting_status += f"{event.summary} - all day"
             else:
-                meeting_status += f"{event.summary} at {begin_local} for {event_duration}"
-            meeting_status += ', ' if index + 1 < len(events) else '.'
+                meeting_status += (
+                    f"{event.summary} at {begin_local} for {event_duration}"
+                )
+            meeting_status += ", " if index + 1 < len(events) else "."
     if count:
         plural = "meeting" if count == 1 else "meetings"
-        meeting_status = f"You have {count} {plural} {addon} {models.env.title}! {meeting_status}"
+        meeting_status = (
+            f"You have {count} {plural} {addon} {models.env.title}! {meeting_status}"
+        )
     else:
         plural = "meeting" if len(events) == 1 else "meetings"
-        meeting_status = f"You have no more meetings for rest of the day {models.env.title}! " \
-                         f"However, you had {len(events)} {plural} earlier {addon}. {meeting_status}"
+        meeting_status = (
+            f"You have no more meetings for rest of the day {models.env.title}! "
+            f"However, you had {len(events)} {plural} earlier {addon}. {meeting_status}"
+        )
     if "last" in addon or "yesterday" in addon:
         meeting_status = meeting_status.replace("You have", "You had")
     return meeting_status
 
 
 def custom_meetings(phrase: str) -> bool:
     """Handles meeting request for a custom date.
@@ -130,49 +160,67 @@
     Returns:
         bool:
         A true flag if the custom meetings request matches the supported format.
     """
     if tuple_res := support.detect_lookup_date(phrase):
         datetime_obj, addon = tuple_res
         meeting_status = meetings_gatherer(
-            custom_date=datetime.date(year=datetime_obj.year, month=datetime_obj.month, day=datetime_obj.day),
-            addon=addon
+            custom_date=datetime.date(
+                year=datetime_obj.year, month=datetime_obj.month, day=datetime_obj.day
+            ),
+            addon=addon,
         )
         speaker.speak(meeting_status)
         return True
 
 
 def meetings(phrase: str) -> None:
     """Controller for meetings.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
     """
     phrase = phrase.lower()
-    if word_match.word_match(phrase=phrase, match_list=("tomorrow", "yesterday", "last", "this", "next")) and \
-            custom_meetings(phrase=phrase):
+    if word_match.word_match(
+        phrase=phrase, match_list=("tomorrow", "yesterday", "last", "this", "next")
+    ) and custom_meetings(phrase=phrase):
         return
     with db.connection:
         cursor = db.connection.cursor()
         meeting_status = cursor.execute("SELECT info, date FROM ics").fetchone()
-    if meeting_status and meeting_status[1] == datetime.datetime.now().strftime('%Y_%m_%d'):
+    if meeting_status and meeting_status[1] == datetime.datetime.now().strftime(
+        "%Y_%m_%d"
+    ):
         speaker.speak(text=meeting_status[0])
     elif meeting_status:
-        logger.warning("Date in meeting status (%s) does not match the current date (%s)" %
-                       (meeting_status[1], datetime.datetime.now().strftime('%Y_%m_%d')))
+        logger.warning(
+            "Date in meeting status (%s) does not match the current date (%s)"
+            % (meeting_status[1], datetime.datetime.now().strftime("%Y_%m_%d"))
+        )
         logger.info("Starting adhoc process to update ics table.")
         Process(target=meetings_writer).start()
-        speaker.speak(text=f"Meetings table is outdated {models.env.title}. Please try again in a minute or two.")
+        speaker.speak(
+            text=f"Meetings table is outdated {models.env.title}. Please try again in a minute or two."
+        )
     else:
         if shared.called_by_offline:
             logger.info("Starting adhoc process to get meetings from ICS.")
             Process(target=meetings_writer).start()
-            speaker.speak(text=f"Meetings table is empty {models.env.title}. Please try again in a minute or two.")
+            speaker.speak(
+                text=f"Meetings table is empty {models.env.title}. Please try again in a minute or two."
+            )
             return
-        meeting = ThreadPool(processes=1).apply_async(func=meetings_gatherer)  # Runs parallely and awaits completion
-        speaker.speak(text=f"Please give me a moment {models.env.title}! I'm working on it.", run=True)
+        meeting = ThreadPool(processes=1).apply_async(
+            func=meetings_gatherer
+        )  # Runs parallely and awaits completion
+        speaker.speak(
+            text=f"Please give me a moment {models.env.title}! I'm working on it.",
+            run=True,
+        )
         try:
             speaker.speak(text=meeting.get(timeout=60), run=True)
         except ThreadTimeoutError:
             logger.error("Unable to read the calendar schedule within 60 seconds.")
-            speaker.speak(text=f"I wasn't able to read your calendar within the set time limit {models.env.title}!",
-                          run=True)
+            speaker.speak(
+                text=f"I wasn't able to read your calendar within the set time limit {models.env.title}!",
+                run=True,
+            )
```

## jarvis/modules/microphone/graph_mic.py

```diff
@@ -8,15 +8,15 @@
     `sound device readthedocs <https://python-sounddevice.readthedocs.io/en/0.3.14/examples.html#plot
     -microphone-signal-s-in-real-time>`__
 """
 
 import os
 import queue
 from struct import Struct
-from typing import List, Optional, Tuple, Union, cast
+from typing import List, Optional, Tuple, cast
 
 import matplotlib.pyplot as plt
 import numpy as np
 import sounddevice
 import yaml
 from matplotlib.animation import FuncAnimation
 from matplotlib.axes import Subplot
@@ -31,15 +31,15 @@
 
     >>> Settings
 
     """
 
     # User config
     channels: Optional[List[int]]
-    device: Optional[Union[str, int]]
+    device: Optional[str | int]
     window: Optional[int]
     interval: Optional[int]
     samplerate: Optional[float]
     down_sample: Optional[int]
     window_size: Optional[Tuple[int, int]]
     rate: Optional[int]
     dark_mode: Optional[bool]
@@ -55,20 +55,22 @@
 
 def list_devices() -> sounddevice.DeviceList:
     """List audion devices."""
     return sounddevice.query_devices()
 
 
 # noinspection PyUnusedLocal
-def audio_callback(indata: np.ndarray, frames: int, time: Struct, status: sounddevice.CallbackFlags) -> None:
+def audio_callback(
+    indata: np.ndarray, frames: int, time: Struct, status: sounddevice.CallbackFlags
+) -> None:
     """This is called (from a separate thread) for each audio block."""
     if status:
         logger.info(status)
     # Fancy indexing with mapping creates a (necessary!) copy:
-    QUEUE.put(indata[::settings.down_sample, settings.mapping])
+    QUEUE.put(indata[:: settings.down_sample, settings.mapping])
 
 
 # noinspection PyUnusedLocal
 def update_plot(frame: int) -> List[Line2D]:
     """This is called by matplotlib for each plot update.
 
     - | Typically, audio callbacks happen more frequently than plot updates,
@@ -84,119 +86,153 @@
         settings.plot_data = np.roll(settings.plot_data, -shift, axis=0)
         settings.plot_data[-shift:, :] = data
     for column, line in enumerate(settings.lines):
         line.set_ydata(settings.plot_data[:, column])
     return settings.lines
 
 
-def plot_mic(channels: List[int] = None, device: Union[str, int] = None, window: int = 200,
-             interval: int = 30, samplerate: float = None, down_sample: int = 10,
-             window_size: Tuple[int, int] = (5, 3), rate: int = 40, dark_mode: bool = True) -> None:
+def plot_mic(
+    channels: List[int] = None,
+    device: str | int = None,
+    window: int = 200,
+    interval: int = 30,
+    samplerate: float = None,
+    down_sample: int = 10,
+    window_size: Tuple[int, int] = (5, 3),
+    rate: int = 40,
+    dark_mode: bool = True,
+) -> None:
     """Loads all the arguments into a dict and kicks off the mapping.
 
     Args:
         channels: Input channels to plot (default: the first [1])
         device: Input device (numeric ID or substring)
         window: Visible time slot (default: 200 ms)
         interval: Minimum time between plot updates (default: 30 ms)
         samplerate: Sampling rate of audio device
         down_sample: Display every Nth sample (default: 10)
         window_size: Size of the spectrum window (default: 7 inches in width, 5 inches in height)
         rate: How quick the graph should be moving on screen (lower is slower, 1000 is pretty quick)
         dark_mode: Sets graph background to almost black
     """
-    multiprocessing_logger(filename=os.path.join('logs', 'mic_plotter_%d-%m-%Y.log'))
+    multiprocessing_logger(filename=os.path.join("logs", "mic_plotter_%d-%m-%Y.log"))
     subprocess_id = os.getpid()
     logger.info("Updating process ID [%d] in [plot_mic] children table.", subprocess_id)
     db = database.Database(database=models.fileio.base_db)
     with db.connection:
         cursor = db.connection.cursor()
         cursor.execute("UPDATE children SET plot_mic=null")
-        cursor.execute("INSERT or REPLACE INTO children (plot_mic) VALUES (?);", (subprocess_id,))
+        cursor.execute(
+            "INSERT or REPLACE INTO children (plot_mic) VALUES (?);", (subprocess_id,)
+        )
         db.connection.commit()
-    logger.info("Updating process ID [%d] in [plot_mic] processes mapping.", subprocess_id)
+    logger.info(
+        "Updating process ID [%d] in [plot_mic] processes mapping.", subprocess_id
+    )
     if os.path.isfile(models.fileio.processes):
         with open(models.fileio.processes) as file:
             dump = yaml.load(stream=file, Loader=yaml.FullLoader) or {}
         if not dump.get(plot_mic.__name__):
-            logger.critical("ATTENTION::Missing %s's process ID in '%s'" %
-                            (plot_mic.__name__, models.fileio.processes))
+            logger.critical(
+                "ATTENTION::Missing %s's process ID in '%s'"
+                % (plot_mic.__name__, models.fileio.processes)
+            )
         # WATCH OUT: for changes in docstring in "processor.py -> create_process_mapping() -> Handles -> plot_mic"
         dump[plot_mic.__name__] = [subprocess_id, "Plot microphone usage in real time"]
-        with open(models.fileio.processes, 'w') as file:
+        with open(models.fileio.processes, "w") as file:
             yaml.dump(data=dump, stream=file)
     else:
         logger.critical("ATTENTION::Missing '%s'", models.fileio.processes)
     logger.info("Feeding all arguments into dict.")
     if not channels:
         channels = [1]
     if not samplerate:
-        device_info = sounddevice.query_devices(device, 'input')
-        samplerate = device_info['default_samplerate']
+        device_info = sounddevice.query_devices(device, "input")
+        samplerate = device_info["default_samplerate"]
     settings.channels = channels
     settings.device = device
     settings.window = window
     settings.interval = interval
     settings.samplerate = samplerate
     settings.down_sample = down_sample
     settings.window_size = window_size
     settings.rate = rate
     settings.dark_mode = dark_mode
     settings.mapping = [c - 1 for c in channels]  # Channel numbers start with 1
     logger.info(settings.__dict__)
     try:
         _kick_off()
     except Exception as error:
-        logger.error(type(error).__name__ + ': ' + error.__str__())
+        logger.error(type(error).__name__ + ": " + error.__str__())
 
 
 def _kick_off() -> None:
     """Plots the live microphone signal(s) with matplotlib."""
     logger.info("Initiating microphone plotter")
     if settings.samplerate is None:
-        device_info = sounddevice.query_devices(settings.device, 'input')
-        settings.samplerate = device_info['default_samplerate']
+        device_info = sounddevice.query_devices(settings.device, "input")
+        settings.samplerate = device_info["default_samplerate"]
 
-    length = int(settings.window * settings.samplerate / (settings.rate * settings.down_sample))
+    length = int(
+        settings.window * settings.samplerate / (settings.rate * settings.down_sample)
+    )
     settings.plot_data = np.zeros((length, len(settings.channels)))
 
     # Add type hint when unpacking a tuple (lazy way to avoid variables)
     fig, ax = cast(Tuple[Figure, Subplot], plt.subplots())
     fig.set_size_inches(settings.window_size)
     settings.lines = ax.plot(settings.plot_data)
     if len(settings.channels) > 1:
-        ax.legend([f'channel {c}' for c in settings.channels],
-                  loc='lower left', ncol=len(settings.channels))
+        ax.legend(
+            [f"channel {c}" for c in settings.channels],
+            loc="lower left",
+            ncol=len(settings.channels),
+        )
     ax.axis((0, len(settings.plot_data), -1, 1))
     ax.set_yticks([0])
     ax.yaxis.grid(True)
-    ax.tick_params(bottom=False, top=False, labelbottom=False,
-                   right=False, left=False, labelleft=False)
+    ax.tick_params(
+        bottom=False,
+        top=False,
+        labelbottom=False,
+        right=False,
+        left=False,
+        labelleft=False,
+    )
     # Labels are not set, but if it is to be set, then set padding at least to 2
     # ax.set_xlabel('Time')
     # ax.set_ylabel('Frequency')
     fig.tight_layout(pad=0)  # no padding
     plt.legend(["Microphone Amplitude"])
     fig.canvas.manager.set_window_title("Realtime Spectrum Display")
     if settings.dark_mode:
-        ax.set_facecolor('xkcd:almost black')  # https://xkcd.com/color/rgb/
+        ax.set_facecolor("xkcd:almost black")  # https://xkcd.com/color/rgb/
         # Takes RGB or RGBA values as arguments
         # ax.set_facecolor((0.1, 0.1, 0.1))  # https://matplotlib.org/stable/api/colors_api.html
 
     stream = sounddevice.InputStream(
-        device=settings.device, channels=max(settings.channels),
-        samplerate=settings.samplerate, callback=audio_callback
+        device=settings.device,
+        channels=max(settings.channels),
+        samplerate=settings.samplerate,
+        callback=audio_callback,
+    )
+    # noinspection PyUnusedLocal
+    ani = FuncAnimation(  # noqa: F841
+        fig=fig,
+        func=update_plot,
+        interval=settings.interval,
+        blit=True,
+        cache_frame_data=False,
     )
-    ani = FuncAnimation(fig=fig, func=update_plot, interval=settings.interval, blit=True, cache_frame_data=False)  # noqa
     with stream:
         plt.show()
     process_map.remove(plot_mic.__name__)
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     # imports within __main__ to avoid potential/future path error and circular import
     # override 'current_process().name' to avoid being set as 'MainProcess'
     # importing at top level requires setting current_process().name at top level which will in turn override any import
     from multiprocessing import current_process
 
     current_process().name = "PlotMic"
     from jarvis.executors import process_map
```

## jarvis/modules/microphone/recognizer.py

```diff
@@ -20,54 +20,66 @@
 
 RECOGNIZER = speech_recognition.Recognizer()
 if platform.system() == "Linux":
     with no_alsa_err():
         MICROPHONE = speech_recognition.Microphone()
 else:
     MICROPHONE = speech_recognition.Microphone()
-COMMON_ERRORS = speech_recognition.UnknownValueError, speech_recognition.RequestError, \
-    speech_recognition.WaitTimeoutError, TimeoutError, ConnectionError,
-
-defaults = dict(energy_threshold=RECOGNIZER.energy_threshold,
-                dynamic_energy_threshold=RECOGNIZER.dynamic_energy_threshold,
-                pause_threshold=RECOGNIZER.pause_threshold,
-                phrase_threshold=RECOGNIZER.phrase_threshold,
-                non_speaking_duration=RECOGNIZER.non_speaking_duration)
+COMMON_ERRORS = (
+    speech_recognition.UnknownValueError,
+    speech_recognition.RequestError,
+    speech_recognition.WaitTimeoutError,
+    TimeoutError,
+    ConnectionError,
+)
+
+defaults = dict(
+    energy_threshold=RECOGNIZER.energy_threshold,
+    dynamic_energy_threshold=RECOGNIZER.dynamic_energy_threshold,
+    pause_threshold=RECOGNIZER.pause_threshold,
+    phrase_threshold=RECOGNIZER.phrase_threshold,
+    non_speaking_duration=RECOGNIZER.non_speaking_duration,
+)
 RECOGNIZER.energy_threshold = 300
 RECOGNIZER.dynamic_energy_threshold = False
 RECOGNIZER.pause_threshold = 2
 RECOGNIZER.phrase_threshold = 0.1
 RECOGNIZER.non_speaking_duration = 2
 
-assert RECOGNIZER.pause_threshold >= RECOGNIZER.non_speaking_duration > 0, \
-    "'pause_threshold' cannot be lower than 'non_speaking_duration' or 0"
-
-changed = dict(energy_threshold=RECOGNIZER.energy_threshold,
-               dynamic_energy_threshold=RECOGNIZER.dynamic_energy_threshold,
-               pause_threshold=RECOGNIZER.pause_threshold,
-               phrase_threshold=RECOGNIZER.phrase_threshold,
-               non_speaking_duration=RECOGNIZER.non_speaking_duration)
+assert (
+    RECOGNIZER.pause_threshold >= RECOGNIZER.non_speaking_duration > 0
+), "'pause_threshold' cannot be lower than 'non_speaking_duration' or 0"
+
+changed = dict(
+    energy_threshold=RECOGNIZER.energy_threshold,
+    dynamic_energy_threshold=RECOGNIZER.dynamic_energy_threshold,
+    pause_threshold=RECOGNIZER.pause_threshold,
+    phrase_threshold=RECOGNIZER.phrase_threshold,
+    non_speaking_duration=RECOGNIZER.non_speaking_duration,
+)
 
 
 async def save_for_reference() -> None:
     """Saves the original config and new config in a yaml file."""
-    with open('speech_recognition_values.yaml', 'w') as file:
+    with open("speech_recognition_values.yaml", "w") as file:
         yaml.dump(data={"defaults": defaults, "modified": changed}, stream=file)
 
 
 async def main() -> None:
     """Initiates yaml dump in an asynchronous call and initiates listener in a never ending loop."""
     asyncio.create_task(save_for_reference())
     with MICROPHONE as source:
         while True:
             try:
-                logger.info('Listening..')
+                logger.info("Listening..")
                 audio = RECOGNIZER.listen(source)
-                logger.info('Recognizing..')
-                recognized = RECOGNIZER.recognize_google(audio_data=audio)  # Requires stable internet connection
+                logger.info("Recognizing..")
+                recognized = RECOGNIZER.recognize_google(
+                    audio_data=audio
+                )  # Requires stable internet connection
                 # recognized = RECOGNIZER.recognize_sphinx(audio_data=audio)  # Requires pocketsphinx module
                 print(recognized)
                 if "stop" in recognized.lower().split():
                     break
             except COMMON_ERRORS as error:
                 logger.debug(error)
                 continue
```

## jarvis/modules/models/classes.py

```diff
@@ -5,42 +5,60 @@
 
 """
 
 import getpass
 import os
 import pathlib
 import platform
+import re
 import socket
 import sys
 from collections import ChainMap
 from datetime import datetime
-from enum import Enum
 from ipaddress import IPv4Address
 from multiprocessing import current_process
-from typing import Callable, Dict, List, Optional, Union
+from typing import Dict, List, Optional
 from uuid import UUID
 
+import jlrpy
 import psutil
 import pyttsx3
 from packaging.version import Version
-from pydantic import (BaseModel, DirectoryPath, EmailStr, Field, FilePath,
-                      HttpUrl, PositiveFloat, PositiveInt, constr,
-                      field_validator)
+from pydantic import (
+    AliasChoices,
+    BaseModel,
+    DirectoryPath,
+    EmailStr,
+    Field,
+    FilePath,
+    HttpUrl,
+    PositiveFloat,
+    PositiveInt,
+    constr,
+    field_validator,
+)
 from pydantic_settings import BaseSettings
 from pyhtcc import Zone
 
 from jarvis import indicators, scripts
-from jarvis.modules.crontab import expression
 from jarvis.modules.exceptions import InvalidEnvVars, UnsupportedOS
 from jarvis.modules.peripherals import channel_type, get_audio_devices
 
 AUDIO_DRIVER = pyttsx3.init()
 
+if sys.version_info.minor > 10:
+    from enum import StrEnum
+else:
+    from enum import Enum
 
-class SupportedPlatforms(str, Enum):
+    class StrEnum(str, Enum):
+        """Override for python 3.10 due to lack of StrEnum."""
+
+
+class SupportedPlatforms(StrEnum):
     """Supported operating systems."""
 
     windows: str = "Windows"
     macOS: str = "Darwin"
     linux: str = "Linux"
 
 
@@ -59,36 +77,41 @@
 
     if sys.stdin.isatty():
         interactive: bool = True
     else:
         interactive: bool = False
     pid: PositiveInt = os.getpid()
     pname: str = current_process().name
-    ram: Union[PositiveInt, PositiveFloat] = psutil.virtual_memory().total
+    ram: PositiveInt | PositiveFloat = psutil.virtual_memory().total
     physical_cores: PositiveInt = psutil.cpu_count(logical=False)
     logical_cores: PositiveInt = psutil.cpu_count(logical=True)
     limited: bool = True if physical_cores < 4 else False
     invoker: str = pathlib.PurePath(sys.argv[0]).stem
 
     os: str = platform.system()
-    if os not in (supported_platforms.macOS, supported_platforms.linux, supported_platforms.windows):
+    if os not in (
+        supported_platforms.macOS,
+        supported_platforms.linux,
+        supported_platforms.windows,
+    ):
         raise UnsupportedOS(
             f"\n{''.join('*' for _ in range(80))}\n\n"
             "Currently Jarvis can run only on Linux, Mac and Windows OS.\n\n"
             f"\n{''.join('*' for _ in range(80))}\n"
         )
-    if os == supported_platforms.macOS and Version(platform.mac_ver()[0]) < Version('10.14'):
+    legacy: bool = False
+    if os == supported_platforms.macOS and Version(platform.mac_ver()[0]) < Version(
+        "10.14"
+    ):
         legacy: bool = True
-    else:
-        legacy: bool = False
 
 
 settings = Settings()
 # Intermittently changes to Windows_NT because of pydantic
-if settings.os.startswith('Windows'):
+if settings.os.startswith("Windows"):
     settings.os = "Windows"
 
 
 class WiFiConnection(BaseModel):
     """Wrapper to store Wi-Fi controls.
 
     >>> WiFiConnection
@@ -102,103 +125,105 @@
 class Thermostat(BaseModel):
     """Wrapper to store thermostat controls.
 
     >>> Thermostat
 
     """
 
-    device: Optional[Union[Zone, str]] = None
+    device: Optional[Zone | str] = None
     expiration: Optional[float] = None
 
     class Config:
         """Config to allow arbitrary types."""
 
         arbitrary_types_allowed = True
 
 
-class VehicleAuthorization(BaseModel):
-    """Wrapper to store vehicle authorization.
-
-    >>> VehicleAuthorization
-
-    """
-
-    device_id: Optional[str] = None
-    expiration: Optional[float] = None
-    refresh_token: Optional[Union[str, UUID]] = None
-
-
 class VehicleConnection(BaseModel):
     """Wrapper to create and store vehicle connection.
 
     >>> VehicleConnection
 
     """
 
     vin: Optional[str] = None
-    connection: Optional[Callable] = None
+    device_id: Optional[str] = None
+    expiration: Optional[float] = None
+    control: Optional[jlrpy.Vehicle] = None
+    refresh_token: Optional[str | UUID] = None
+
+    class Config:
+        """Config to allow arbitrary types."""
+
+        arbitrary_types_allowed = True
 
 
 class RecognizerSettings(BaseModel):
     """Settings for speech recognition.
 
     >>> RecognizerSettings
 
+    See Also:
+        - energy_threshold: Minimum energy to consider for recording. Greater the value, louder the voice should be.
+        - dynamic_energy_threshold: Change considerable audio energy threshold dynamically.
+        - pause_threshold: Seconds of non-speaking audio before a phrase is considered complete.
+        - phrase_threshold: Minimum seconds of speaking audio before it can be considered a phrase.
+        - non_speaking_duration: Seconds of non-speaking audio to keep on both sides of the recording.
     """
 
     energy_threshold: PositiveInt = 700
-    pause_threshold: Union[PositiveInt, float] = 2
-    phrase_threshold: Union[PositiveInt, float] = 0.1
+    pause_threshold: PositiveInt | float = 2
+    phrase_threshold: PositiveInt | float = 0.1
     dynamic_energy_threshold: bool = False
-    non_speaking_duration: Union[PositiveInt, float] = 2
+    non_speaking_duration: PositiveInt | float = 2
 
 
-class TemperatureUnits(str, Enum):
+class TemperatureUnits(StrEnum):
     """Types of temperature units supported by Jarvis.
 
     >>> TemperatureUnits
 
     """
 
-    METRIC: str = 'metric'
-    IMPERIAL: str = 'imperial'
+    METRIC: str = "metric"
+    IMPERIAL: str = "imperial"
 
 
-class DistanceUnits(str, Enum):
+class DistanceUnits(StrEnum):
     """Types of distance units supported by Jarvis.
 
     >>> DistanceUnits
 
     """
 
-    MILES: str = 'miles'
-    KILOMETERS: str = 'kilometers'
+    MILES: str = "miles"
+    KILOMETERS: str = "kilometers"
 
 
-class EventApp(str, Enum):
+class EventApp(StrEnum):
     """Types of event applications supported by Jarvis.
 
     >>> EventApp
 
     """
 
-    CALENDAR = 'calendar'
-    OUTLOOK = 'outlook'
+    CALENDAR = "calendar"
+    OUTLOOK = "outlook"
 
 
-class SSQuality(str, Enum):
+class SSQuality(StrEnum):
     """Quality modes available for speech synthesis.
 
     >>> SSQuality
 
     """
 
-    High_Quality = 'high'
-    Medium_Quality = 'medium'
-    Low_Quality = 'low'
+    High_Quality = "high"
+    Medium_Quality = "medium"
+    Low_Quality = "low"
 
 
 def handle_multiform(form_list: List[str]) -> List[int]:
     """Handles ignore_hours in the format 7-10.
 
     Args:
         form_list: Takes the split string as an argument.
@@ -213,15 +238,17 @@
     """
     form_list[0] = form_list[0].strip()
     form_list[1] = form_list[1].strip()
     try:
         assert form_list[0].isdigit()
         assert form_list[1].isdigit()
     except AssertionError:
-        raise ValueError('string format can either be start-end (7-10) or just the hour by itself (7)')
+        raise ValueError(
+            "string format can either be start-end (7-10) or just the hour by itself (7)"
+        )
     start_hour = int(form_list[0])
     end_hour = int(form_list[1])
     if start_hour <= end_hour:
         # Handle the case where the range is not wrapped around midnight
         v = list(range(start_hour, end_hour + 1))
     else:
         # Handle the case where the range wraps around midnight
@@ -230,273 +257,359 @@
 
 
 class BackgroundTask(BaseModel):
     """Custom links model."""
 
     seconds: int
     task: constr(strip_whitespace=True)
-    ignore_hours: Union[List[int], List[str], str, int, List[Union[int, str]], None] = []
+    ignore_hours: List[int] | List[str] | str | int | List[int | str] | None = []
 
-    @field_validator('task', mode='before', check_fields=True)
+    @field_validator("task", mode="before", check_fields=True)
     def check_empty_string(cls, v, values, **kwargs):  # noqa
         """Validate task field in tasks."""
         if v:
             return v
-        raise ValueError('bad value')
+        raise ValueError("bad value")
 
-    @field_validator('ignore_hours', check_fields=True)
+    @field_validator("ignore_hours", check_fields=True)
     def check_hours_format(cls, v, values, **kwargs):  # noqa
         """Validate each entry in ignore hours list."""
         if not v:
             return []
         if isinstance(v, int):
             if v < 0 or v > 24:
-                raise ValueError('24h format cannot be less than 0 or greater than 24')
+                raise ValueError("24h format cannot be less than 0 or greater than 24")
             v = [v]
         elif isinstance(v, str):
-            form_list = v.split('-')
+            form_list = v.split("-")
             if len(form_list) == 1:
                 try:
                     assert form_list[0].isdigit()
                 except AssertionError:
-                    raise ValueError('string format can either be start-end (7-10) or just the hour by itself (7)')
+                    raise ValueError(
+                        "string format can either be start-end (7-10) or just the hour by itself (7)"
+                    )
                 else:
                     v = [int(form_list[0])]
             elif len(form_list) == 2:
                 v = handle_multiform(form_list)
             else:
-                raise ValueError('string format can either be start-end (7-10) or just the hour by itself (7)')
+                raise ValueError(
+                    "string format can either be start-end (7-10) or just the hour by itself (7)"
+                )
         refined = []
         for multiple in v:
             if isinstance(multiple, str):
-                refined.extend(handle_multiform(multiple.split('-')))  # comes back as a list of string
+                refined.extend(
+                    handle_multiform(multiple.split("-"))
+                )  # comes back as a list of string
             else:
                 refined.append(multiple)
         if refined:
             v = refined
         for hour in v:
             try:
-                datetime.strptime(str(hour), '%H')
+                datetime.strptime(str(hour), "%H")
             except ValueError:
-                raise ValueError('ignore hours should be 24H format')
+                raise ValueError("ignore hours should be 24H format")
         return v
 
 
+class ReminderOptions(StrEnum):
+    """Supported reminder options."""
+
+    phone: str = "phone"
+    email: str = "email"
+    telegram: str = "telegram"
+    ntfy: str = "ntfy"
+    all: str = "all"
+
+
 class EnvConfig(BaseSettings):
     """Configure all env vars and validate using ``pydantic`` to share across modules.
 
     >>> EnvConfig
 
     """
 
     # Custom units
-    distance_unit: Union[DistanceUnits, None] = None
-    temperature_unit: Union[TemperatureUnits, None] = None
+    distance_unit: DistanceUnits | None = None
+    temperature_unit: TemperatureUnits | None = None
 
     # System config
-    home: DirectoryPath = os.path.expanduser('~')
+    home: DirectoryPath = os.path.expanduser("~")
     volume: PositiveInt = 50
     limited: bool = False
     root_user: str = getpass.getuser()
-    root_password: Union[str, None] = None
+    root_password: str | None = Field(
+        None, validation_alias=AliasChoices("root_password", "password")
+    )
 
     # Mute during meetings
     mute_for_meetings: bool = False
 
     # Built-in speaker config
-    voice_name: Union[str, None] = None
-    speech_rate: Union[PositiveInt, PositiveFloat] = AUDIO_DRIVER.getProperty("rate")
+    voice_name: str | None = None
+    speech_rate: PositiveInt | PositiveFloat = AUDIO_DRIVER.getProperty("rate")
 
     # Peripheral config
-    camera_index: Union[int, PositiveInt, None] = None
-    speaker_index: Union[int, PositiveInt, None] = None
-    microphone_index: Union[int, PositiveInt, None] = None
+    camera_index: int | PositiveInt | None = None
+    speaker_index: int | PositiveInt | None = None
+    microphone_index: int | PositiveInt | None = None
 
     # Log config
     debug: bool = False
-    log_retention: Union[int, PositiveInt] = Field(10, lt=90, gt=0)
+    log_retention: int | PositiveInt = Field(10, lt=90, gt=0)
 
     # User add-ons
-    birthday: Union[str, None] = None
-    title: str = 'sir'
-    name: str = 'Vignesh'
-    website: HttpUrl = 'https://vigneshrao.com'
+    birthday: str | None = None
+    title: str = "sir"
+    name: str = "Vignesh"
+    website: HttpUrl | List[HttpUrl] = []
     plot_mic: bool = True
+    ntfy_url: HttpUrl | None = None
+    ntfy_username: str | None = None
+    ntfy_password: str | None = None
+    ntfy_topic: str | None = None
+    notify_reminders: ReminderOptions | List[ReminderOptions] = ReminderOptions.all
 
     # Author specific
     author_mode: bool = False
 
     # Third party api config
-    weather_api: Union[str, None] = None
-    maps_api: Union[str, None] = None
-    news_api: Union[str, None] = None
-    openai_api: Union[str, None] = None
-    openai_model: str = 'gpt-3.5-turbo'
+    weather_api: str | None = None
+    maps_api: str | None = None
+    news_api: str | None = None
+    openai_api: str | None = None
+    openai_model: str = "gpt-3.5-turbo"
     openai_timeout: int = Field(5, le=10, ge=1)
-    openai_reuse_threshold: Union[float, None] = Field(None, ge=0.5, le=0.9)
+    openai_reuse_threshold: float | None = Field(None, ge=0.5, le=0.9)
 
     # Communication config
-    gmail_user: Union[EmailStr, None] = None
-    gmail_pass: Union[str, None] = None
-    open_gmail_user: Union[EmailStr, None] = None
-    open_gmail_pass: Union[str, None] = None
-    recipient: Union[EmailStr, None] = None
-    phone_number: Union[str, None] = Field(None, pattern="\\d{10}$")
+    gmail_user: EmailStr | None = None
+    gmail_pass: str | None = None
+    open_gmail_user: EmailStr | None = None
+    open_gmail_pass: str | None = None
+    recipient: EmailStr | None = None
+    phone_number: str | None = Field(None, pattern="\\d{10}$")
+    telegram_id: int | None = None
 
     # Offline communicator config
-    offline_host: str = socket.gethostbyname('localhost')
+    offline_host: str = socket.gethostbyname("localhost")
     offline_port: PositiveInt = 4483
-    offline_pass: str = 'OfflineComm'
+    offline_pass: str = "OfflineComm"
     workers: PositiveInt = 1
 
     # Calendar events and meetings config
-    event_app: Union[EventApp, None] = None
-    ics_url: Union[HttpUrl, None] = None
+    event_app: EventApp | None = None
+    ics_url: HttpUrl | None = None
     # Set background sync limits to range: 15 minutes to 12 hours
-    sync_meetings: Union[int, None] = Field(None, ge=900, le=43_200)
-    sync_events: Union[int, None] = Field(None, ge=900, le=43_200)
+    sync_meetings: int | None = Field(None, ge=900, le=43_200)
+    sync_events: int | None = Field(None, ge=900, le=43_200)
 
     # Stock monitor apikey
     stock_monitor_api: Dict[EmailStr, str] = {}
 
     # Surveillance config
-    surveillance_endpoint_auth: Union[str, None] = None
+    surveillance_endpoint_auth: str | None = None
     surveillance_session_timeout: PositiveInt = 300
 
     # Apple devices' config
-    icloud_user: Union[EmailStr, None] = None
-    icloud_pass: Union[str, None] = None
-    icloud_recovery: Union[str, None] = Field(None, pattern="\\d{10}$")
+    icloud_user: EmailStr | None = None
+    icloud_pass: str | None = None
+    icloud_recovery: str | None = Field(None, pattern="\\d{10}$")
 
     # Robinhood config
-    robinhood_user: Union[EmailStr, None] = None
-    robinhood_pass: Union[str, None] = None
-    robinhood_qr: Union[str, None] = None
-    robinhood_endpoint_auth: Union[str, None] = None
+    robinhood_user: EmailStr | None = None
+    robinhood_pass: str | None = None
+    robinhood_qr: str | None = None
+    robinhood_endpoint_auth: str | None = None
 
     # GitHub config
-    git_user: Union[str, None] = None
-    git_pass: Union[str, None] = None
+    git_user: str | None = None
+    git_pass: str | None = None
 
     # VPN Server config
-    vpn_username: Union[str, None] = None
-    vpn_password: Union[str, None] = None
+    vpn_username: str | None = None
+    vpn_password: str | None = None
     vpn_subdomain: str = "vpn"
     vpn_key_pair: str = "OpenVPN"
     vpn_security_group: str = "OpenVPN Access Server"
     vpn_info_file: str = Field("vpn_info.json", pattern=r".+\.json$")
-    vpn_hosted_zone: Union[str, None] = None
+    vpn_hosted_zone: str | None = None
 
     # Vehicle config
-    car_username: Union[EmailStr, None] = None
-    car_password: Union[str, None] = None
-    car_pin: Union[str, None] = Field(None, pattern="\\d{4}$")
+    car_username: EmailStr | None = None
+    car_password: str | None = None
+    car_pin: str | None = Field(None, pattern="\\d{4}$")
 
     # Thermostat config
-    tcc_username: Union[EmailStr, None] = None
-    tcc_password: Union[str, None] = None
-    tcc_device_name: Union[str, None] = None
+    tcc_username: EmailStr | None = None
+    tcc_password: str | None = None
+    tcc_device_name: str | None = None
 
     # Listener config
-    sensitivity: Union[float, PositiveInt, List[float], List[PositiveInt]] = Field(0.5, le=1, ge=0)
-    listener_timeout: Union[PositiveFloat, PositiveInt] = 3
-    listener_phrase_limit: Union[PositiveFloat, PositiveInt] = 5
-    recognizer_confidence: Union[float, PositiveInt] = Field(0, le=1, ge=0)
+    sensitivity: float | PositiveInt | List[float] | List[PositiveInt] = Field(
+        0.5, le=1, ge=0
+    )
+    listener_timeout: PositiveFloat | PositiveInt = 3
+    listener_phrase_limit: PositiveFloat | PositiveInt = 5
+    recognizer_confidence: float | PositiveInt = Field(0, le=1, ge=0)
 
     # Telegram config
-    bot_token: Union[str, None] = None
+    bot_token: str | None = None
     bot_chat_ids: List[int] = []
     bot_users: List[str] = []
     # Telegram Webhook specific
-    bot_webhook: Union[HttpUrl, None] = None
-    bot_webhook_ip: Union[IPv4Address, None] = None
+    bot_webhook: HttpUrl | None = None
+    bot_webhook_ip: IPv4Address | None = None
     bot_endpoint: str = Field("/telegram-webhook", pattern=r"^\/")
-    bot_secret: Union[str, None] = Field(None, pattern="^[A-Za-z0-9_-]{1,256}$")
-    bot_certificate: Union[FilePath, None] = None
+    bot_secret: str | None = Field(None, pattern="^[A-Za-z0-9_-]{1,256}$")
+    bot_certificate: FilePath | None = None
 
     # Speech synthesis config
     speech_synthesis_timeout: int = 3
-    speech_synthesis_voice: str = 'en-us_northern_english_male-glow_tts'
+    speech_synthesis_voice: str = "en-us_northern_english_male-glow_tts"
     speech_synthesis_quality: SSQuality = SSQuality.Medium_Quality
-    speech_synthesis_host: str = socket.gethostbyname('localhost')
+    speech_synthesis_host: str = socket.gethostbyname("localhost")
     speech_synthesis_port: PositiveInt = 5002
 
     # Background tasks
-    crontab: List[expression.CronExpression] = []  # todo: move to yaml file in config dir
-    weather_alert: Union[str, datetime, None] = None
-    weather_alert_min: Union[int, PositiveInt] = 36
-    weather_alert_max: Union[int, PositiveInt] = 104
+    weather_alert: str | datetime | None = None
+    weather_alert_min: int | PositiveInt = 36
+    weather_alert_max: int | PositiveInt = 104
 
     # WiFi config
-    wifi_ssid: Union[str, None] = None
-    wifi_password: Union[str, None] = None
-    connection_retry: Union[PositiveInt, PositiveFloat] = 10
+    wifi_ssid: str | None = None
+    wifi_password: str | None = None
+    connection_retry: PositiveInt | PositiveFloat = 10
 
     # Legacy macOS config
     if settings.legacy:
-        wake_words: List[str] = ['alexa']
+        wake_words: List[str] = ["alexa"]
     else:
-        wake_words: List[str] = ['jarvis']
+        wake_words: List[str] = ["jarvis"]
 
     class Config:
         """Environment variables configuration."""
 
         env_prefix = ""
         env_file = os.environ.get("env_file", os.environ.get("ENV_FILE", ".env"))
         extra = "allow"
 
     # noinspection PyMethodParameters
-    @field_validator("microphone_index", mode='before', check_fields=True)
-    def parse_microphone_index(cls, value: Union[int, PositiveInt]) -> Union[int, PositiveInt, None]:
+    @field_validator("website", mode="after", check_fields=True)
+    def parse_websites(cls, value: HttpUrl | List[HttpUrl]) -> List[HttpUrl]:
+        """Validate websites."""
+        if isinstance(value, list):
+            return value
+        return [value]
+
+    # noinspection PyMethodParameters
+    @field_validator("notify_reminders", mode="after", check_fields=True)
+    def parse_notify_reminders(
+        cls, value: ReminderOptions | List[ReminderOptions]
+    ) -> List[ReminderOptions]:
+        """Validate reminder options."""
+        if isinstance(value, list):
+            if ReminderOptions.all in value:
+                return [ReminderOptions.all]
+            return value
+        return [value]
+
+    # noinspection PyMethodParameters
+    @field_validator("microphone_index", mode="before", check_fields=True)
+    def parse_microphone_index(
+        cls, value: int | PositiveInt
+    ) -> int | PositiveInt | None:
         """Validates microphone index."""
         if not value:
             return
-        if int(value) in list(map(lambda tag: tag['index'], get_audio_devices(channels=channel_type.input_channels))):
+        if int(value) in list(
+            map(
+                lambda tag: tag["index"],
+                get_audio_devices(channels=channel_type.input_channels),
+            )
+        ):
             return value
         else:
-            complicated = dict(ChainMap(*list(map(lambda tag: {tag['index']: tag['name']},
-                                                  get_audio_devices(channels=channel_type.input_channels)))))
+            complicated = dict(
+                ChainMap(
+                    *list(
+                        map(
+                            lambda tag: {tag["index"]: tag["name"]},
+                            get_audio_devices(channels=channel_type.input_channels),
+                        )
+                    )
+                )
+            )
             raise InvalidEnvVars(f"value should be one of {complicated}")
 
     # noinspection PyMethodParameters
-    @field_validator("speaker_index", mode='before', check_fields=True)
-    def parse_speaker_index(cls, value: Union[int, PositiveInt]) -> Union[int, PositiveInt, None]:
+    @field_validator("speaker_index", mode="before", check_fields=True)
+    def parse_speaker_index(cls, value: int | PositiveInt) -> int | PositiveInt | None:
         """Validates speaker index."""
         # TODO: Create an OS agnostic model for usage (currently the index value is unused)
         if not value:
             return
-        if int(value) in list(map(lambda tag: tag['index'], get_audio_devices(channels=channel_type.output_channels))):
+        if int(value) in list(
+            map(
+                lambda tag: tag["index"],
+                get_audio_devices(channels=channel_type.output_channels),
+            )
+        ):
             return value
         else:
-            complicated = dict(ChainMap(*list(map(lambda tag: {tag['index']: tag['name']},
-                                                  get_audio_devices(channels=channel_type.output_channels)))))
+            complicated = dict(
+                ChainMap(
+                    *list(
+                        map(
+                            lambda tag: {tag["index"]: tag["name"]},
+                            get_audio_devices(channels=channel_type.output_channels),
+                        )
+                    )
+                )
+            )
             raise InvalidEnvVars(f"value should be one of {complicated}")
 
     # noinspection PyMethodParameters
-    @field_validator("birthday", mode='before', check_fields=True)
-    def parse_birthday(cls, value: str) -> Union[str, None]:
+    @field_validator("birthday", mode="before", check_fields=True)
+    def parse_birthday(cls, value: str) -> str | None:
         """Validates date value to be in DD-MM format."""
         if not value:
             return
         try:
             if datetime.strptime(value, "%d-%B"):
                 return value
         except ValueError:
             raise InvalidEnvVars("format should be 'DD-MM'")
 
+    @field_validator("vpn_password", mode="before", check_fields=True)
+    def validate_vpn_password(cls, v: str) -> str:
+        """Validates vpn_password as per the required regex."""
+        if v:
+            if re.match(
+                pattern=r"^(?=.*\d)(?=.*[A-Z])(?=.*[!@#$%&'()*+,-/[\]^_`{|}~<>]).+$",
+                string=v,
+            ):
+                return v
+            raise ValueError(
+                r"Password must contain a digit, an Uppercase letter, and a symbol from !@#$%&'()*+,-/[\]^_`{|}~<>"
+            )
+
     # noinspection PyMethodParameters
-    @field_validator("weather_alert", mode='before', check_fields=True)
-    def parse_weather_alert(cls, value: str) -> Union[str, None, datetime]:
+    @field_validator("weather_alert", mode="before", check_fields=True)
+    def parse_weather_alert(cls, value: str) -> str | None:
         """Validates date value to be in DD-MM format."""
         if not value:
             return
         try:
             # Convert datetime to string as the '07' for '%I' will pass validation but fail comparison
-            if val := datetime.strptime(value, '%I:%M %p'):
-                return val.strftime('%I:%M %p')
+            if val := datetime.strptime(value, "%I:%M %p"):
+                return val.strftime("%I:%M %p")
         except ValueError:
             raise InvalidEnvVars("format should be '%I:%M %p'")
 
 
 env = EnvConfig()
 
 
@@ -504,74 +617,75 @@
     """Loads all the files' path required/created by Jarvis.
 
     >>> FileIO
 
     """
 
     # Directories
-    root: DirectoryPath = os.path.realpath('fileio')
+    root: DirectoryPath = os.path.realpath("fileio")
 
     # Speech Recognition config
-    recognizer: FilePath = os.path.join(root, 'recognizer.yaml')
+    recognizer: FilePath = os.path.join(root, "recognizer.yaml")
 
     # Home automation
-    crontab: FilePath = os.path.join(root, 'crontab.yaml')
-    automation: FilePath = os.path.join(root, 'automation.yaml')
-    tmp_automation: FilePath = os.path.join(root, 'tmp_automation.yaml')
-    background_tasks: FilePath = os.path.join(root, 'background_tasks.yaml')
-    tmp_background_tasks: FilePath = os.path.join(root, 'tmp_background_tasks.yaml')
-    smart_devices: FilePath = os.path.join(root, 'smart_devices.yaml')
-    contacts: FilePath = os.path.join(root, 'contacts.yaml')
+    crontab: FilePath = os.path.join(root, "crontab.yaml")
+    tmp_crontab: FilePath = os.path.join(root, "tmp_crontab.yaml")
+    automation: FilePath = os.path.join(root, "automation.yaml")
+    tmp_automation: FilePath = os.path.join(root, "tmp_automation.yaml")
+    background_tasks: FilePath = os.path.join(root, "background_tasks.yaml")
+    tmp_background_tasks: FilePath = os.path.join(root, "tmp_background_tasks.yaml")
+    smart_devices: FilePath = os.path.join(root, "smart_devices.yaml")
+    contacts: FilePath = os.path.join(root, "contacts.yaml")
 
     # Alarms and Reminders
-    alarms: FilePath = os.path.join(root, 'alarms.yaml')
-    reminders: FilePath = os.path.join(root, 'reminders.yaml')
+    alarms: FilePath = os.path.join(root, "alarms.yaml")
+    reminders: FilePath = os.path.join(root, "reminders.yaml")
 
     # Simulation
-    simulation: FilePath = os.path.join(root, 'simulation.yaml')
+    simulation: FilePath = os.path.join(root, "simulation.yaml")
 
     # Custom keyword-function map
-    keywords: FilePath = os.path.join(root, 'keywords.yaml')
-    conditions: FilePath = os.path.join(root, 'conditions.yaml')
-    restrictions: FilePath = os.path.join(root, 'restrictions.yaml')
+    keywords: FilePath = os.path.join(root, "keywords.yaml")
+    conditions: FilePath = os.path.join(root, "conditions.yaml")
+    restrictions: FilePath = os.path.join(root, "restrictions.yaml")
 
     # Databases
-    base_db: FilePath = os.path.join(root, 'database.db')
-    task_db: FilePath = os.path.join(root, 'tasks.db')
-    stock_db: FilePath = os.path.join(root, 'stock.db')
+    base_db: FilePath = os.path.join(root, "database.db")
+    task_db: FilePath = os.path.join(root, "tasks.db")
+    stock_db: FilePath = os.path.join(root, "stock.db")
 
     # API used
-    robinhood: FilePath = os.path.join(root, 'robinhood.html')
-    stock_list_backup: FilePath = os.path.join(root, 'stock_list_backup.yaml')
+    robinhood: FilePath = os.path.join(root, "robinhood.html")
+    stock_list_backup: FilePath = os.path.join(root, "stock_list_backup.yaml")
 
     # Future useful
-    frequent: FilePath = os.path.join(root, 'frequent.yaml')
-    training_data: FilePath = os.path.join(root, 'training_data.yaml')
-    gpt_data: FilePath = os.path.join(root, 'gpt_history.yaml')
+    frequent: FilePath = os.path.join(root, "frequent.yaml")
+    training_data: FilePath = os.path.join(root, "training_data.yaml")
+    gpt_data: FilePath = os.path.join(root, "gpt_history.yaml")
 
     # Jarvis internal
-    startup_dir: DirectoryPath = os.path.join(root, 'startup')
-    location: FilePath = os.path.join(root, 'location.yaml')
-    notes: FilePath = os.path.join(root, 'notes.txt')
-    processes: FilePath = os.path.join(root, 'processes.yaml')
+    startup_dir: DirectoryPath = os.path.join(root, "startup")
+    location: FilePath = os.path.join(root, "location.yaml")
+    notes: FilePath = os.path.join(root, "notes.txt")
+    processes: FilePath = os.path.join(root, "processes.yaml")
 
     # macOS specifics
-    app_launcher: FilePath = os.path.join(scripts.__path__[0], 'applauncher.scpt')
-    event_script: FilePath = os.path.join(scripts.__path__[0], f'{env.event_app}.scpt')
+    app_launcher: FilePath = os.path.join(scripts.__path__[0], "applauncher.scpt")
+    event_script: FilePath = os.path.join(scripts.__path__[0], f"{env.event_app}.scpt")
 
     # Speech Synthesis
-    speech_synthesis_wav: FilePath = os.path.join(root, 'speech_synthesis.wav')
+    speech_synthesis_wav: FilePath = os.path.join(root, "speech_synthesis.wav")
     # Store log file name in a variable as it is used in multiple modules with file IO
-    # todo: remove datetime from id and create log files in dedicated functions
-    # todo: check if there are any specific use cases for cid file to have datetime
-    speech_synthesis_cid: FilePath = os.path.join(root, 'speech_synthesis.cid')
-    speech_synthesis_log: FilePath = datetime.now().strftime(os.path.join('logs', 'speech_synthesis_%d-%m-%Y.log'))
+    speech_synthesis_cid: FilePath = os.path.join(root, "speech_synthesis.cid")
+    speech_synthesis_log: FilePath = datetime.now().strftime(
+        os.path.join("logs", "speech_synthesis_%d-%m-%Y.log")
+    )
 
     # Secure Send
-    secure_send: FilePath = os.path.join(root, 'secure_send.yaml')
+    secure_send: FilePath = os.path.join(root, "secure_send.yaml")
 
     # On demand storage
     uploads: DirectoryPath = os.path.join(root, "uploads")
 
 
 fileio = FileIO()
 
@@ -579,12 +693,14 @@
 class Indicators(BaseModel):
     """Loads all the mp3 files' path required by Jarvis.
 
     >>> Indicators
 
     """
 
-    acknowledgement: FilePath = os.path.join(indicators.__path__[0], 'acknowledgement.mp3')
-    alarm: FilePath = os.path.join(indicators.__path__[0], 'alarm.mp3')
-    coin: FilePath = os.path.join(indicators.__path__[0], 'coin.mp3')
-    end: FilePath = os.path.join(indicators.__path__[0], 'end.mp3')
-    start: FilePath = os.path.join(indicators.__path__[0], 'start.mp3')
+    acknowledgement: FilePath = os.path.join(
+        indicators.__path__[0], "acknowledgement.mp3"
+    )
+    alarm: FilePath = os.path.join(indicators.__path__[0], "alarm.mp3")
+    coin: FilePath = os.path.join(indicators.__path__[0], "coin.mp3")
+    end: FilePath = os.path.join(indicators.__path__[0], "end.mp3")
+    start: FilePath = os.path.join(indicators.__path__[0], "start.mp3")
```

## jarvis/modules/models/models.py

```diff
@@ -3,41 +3,60 @@
 
 >>> Models
 
 """
 
 import os
 import pathlib
+import platform
 import warnings
 
 import cv2
 import pvporcupine
 import requests
 from pydantic import PositiveInt
 
 from jarvis.modules.camera import camera
 from jarvis.modules.database import database
-from jarvis.modules.exceptions import (CameraError, EgressErrors,
-                                       InvalidEnvVars, MissingEnvVars)
-from jarvis.modules.models.classes import (AUDIO_DRIVER, DistanceUnits,
-                                           Indicators, TemperatureUnits, env,
-                                           fileio, settings,
-                                           supported_platforms)
+from jarvis.modules.exceptions import (
+    CameraError,
+    EgressErrors,
+    InvalidEnvVars,
+    MissingEnvVars,
+)
+from jarvis.modules.models.classes import (
+    AUDIO_DRIVER,
+    DistanceUnits,
+    Indicators,
+    TemperatureUnits,
+    env,
+    fileio,
+    settings,
+    supported_platforms,
+)
 from jarvis.modules.utils import util
 
 # Shared across other modules
 voices = AUDIO_DRIVER.getProperty("voices")
 indicators = Indicators()
 # TABLES to be created in `fileio.base_db`
 TABLES = {
     env.event_app: ("info", "date"),
     "ics": ("info", "date"),
     "stopper": ("flag", "caller"),
     "restart": ("flag", "caller"),
-    "children": ("meetings", "events", "crontab", "party", "guard", "surveillance", "plot_mic"),
+    "children": (
+        "meetings",
+        "events",
+        "crontab",
+        "party",
+        "guard",
+        "surveillance",
+        "plot_mic",
+    ),
     "vpn": ("state",),
     "party": ("pid",),
     "guard": ("state", "trigger"),
     "robinhood": ("summary",),
     "listener": ("state",),
 }
 KEEP_TABLES = ("vpn", "party", "listener")  # TABLES to keep from `fileio.base_db`
@@ -86,25 +105,35 @@
 
 
 def _main_process_validations() -> None:
     """Validations that should happen only when the main process is triggered."""
     if settings.legacy:
         pvporcupine.KEYWORD_PATHS = {}
         base_path = os.path.dirname(pvporcupine.__file__)
-        pvporcupine.MODEL_PATH = os.path.join(base_path, 'lib/common/porcupine_params.pv')
-        pvporcupine.LIBRARY_PATH = os.path.join(base_path, 'lib/mac/x86_64/libpv_porcupine.dylib')
+        pvporcupine.MODEL_PATH = os.path.join(
+            base_path, "lib/common/porcupine_params.pv"
+        )
+        pvporcupine.LIBRARY_PATH = os.path.join(
+            base_path, "lib/mac/x86_64/libpv_porcupine.dylib"
+        )
 
         # Iterates over the available flash files, to override the object reference
-        for x in os.listdir(os.path.join(base_path, 'resources/keyword_files/mac/')):
-            pvporcupine.KEYWORD_PATHS[x.split('_')[0]] = os.path.join(base_path, f'resources/keyword_files/mac/{x}')
+        for x in os.listdir(os.path.join(base_path, "resources/keyword_files/mac/")):
+            pvporcupine.KEYWORD_PATHS[x.split("_")[0]] = os.path.join(
+                base_path, f"resources/keyword_files/mac/{x}"
+            )
 
     for keyword in env.wake_words:
-        if not pvporcupine.KEYWORD_PATHS.get(keyword) or not os.path.isfile(pvporcupine.KEYWORD_PATHS[keyword]):
-            raise InvalidEnvVars(f"Detecting {keyword!r} is unsupported!\n"
-                                 f"Available keywords are: {', '.join(list(pvporcupine.KEYWORD_PATHS.keys()))}")
+        if not pvporcupine.KEYWORD_PATHS.get(keyword) or not os.path.isfile(
+            pvporcupine.KEYWORD_PATHS[keyword]
+        ):
+            raise InvalidEnvVars(
+                f"Detecting {keyword!r} is unsupported!\n"
+                f"Available keywords are: {', '.join(list(pvporcupine.KEYWORD_PATHS.keys()))}"
+            )
 
     # If sensitivity is an integer or float, converts it to a list
     if isinstance(env.sensitivity, float) or isinstance(env.sensitivity, PositiveInt):
         env.sensitivity = [env.sensitivity] * len(env.wake_words)
 
     # Create all necessary DB tables during startup
     if not os.path.isdir(fileio.root):
@@ -130,62 +159,69 @@
     if settings.os == supported_platforms.linux:
         if not env.root_password:
             raise MissingEnvVars(
                 "Linux requires the host machine's password to be set as the env var: "
                 "ROOT_PASSWORD due to terminal automations."
             )
 
+    if settings.legacy:
+        warnings.warn(
+            f"\nmacOS {platform.mac_ver()[0]} will be deprecated in the near future\n"
+            f"Please upgrade to 10.14 or above to continue using Jarvis",
+            DeprecationWarning,
+        )
+
     if voice_names := [__voice.name for __voice in voices]:
         if not env.voice_name:
             _set_default_voice_name()
         elif env.voice_name not in voice_names:
             if main:
-                raise InvalidEnvVars(f"{env.voice_name!r} is not available.\n"
-                                     f"Available voices are: {', '.join(voice_names)}")
+                raise InvalidEnvVars(
+                    f"{env.voice_name!r} is not available.\n"
+                    f"Available voices are: {', '.join(voice_names)}"
+                )
             else:
                 _set_default_voice_name()
                 warnings.warn(
                     f"{env.voice_name!r} is not available. Defaulting to {env.voice_name!r}"
                 )
 
     if not all((env.open_gmail_user, env.open_gmail_pass)):
         env.open_gmail_user = env.gmail_user
         env.open_gmail_pass = env.gmail_pass
 
     # Note: Pydantic validation for ICS_URL can be implemented using regex=".*ics$"
     # However it will NOT work in this use case, since the type hint is HttpUrl
-    if env.ics_url and not env.ics_url.path.endswith('.ics'):
+    if env.ics_url and not env.ics_url.path.endswith(".ics"):
         if main:
             raise InvalidEnvVars("'ICS_URL' should end with .ics")
         else:
             env.ics_url = None
-            warnings.warn(
-                "'ICS_URL' should end with .ics"
-            )
+            warnings.warn("'ICS_URL' should end with .ics")
 
     if env.speech_synthesis_port == env.offline_port:
         if main:
             raise InvalidEnvVars(
                 "Speech synthesizer and offline communicator cannot run simultaneously on the same port number."
             )
         else:
             env.speech_synthesis_port = util.get_free_port()
             warnings.warn(
                 "Speech synthesizer and offline communicator cannot run on same port number. "
                 f"Defaulting to {env.speech_synthesis_port}"
             )
 
-    if env.limited:  # Forces limited version if env var is set, otherwise it is enforced based on the number of cores
+    # Forces limited version if env var is set, otherwise it is enforced based on the number of cores
+    if env.limited:
         settings.limited = True
-    if env.limited is False:  # If env var is set as False to brute force full version on a device with < 4 processors
+    # If env var is set as False to brute force full version on a device with < 4 processors
+    if env.limited is False:
         settings.limited = False
     if settings.limited is True and env.weather_alert:
-        warnings.warn(
-            "weather alert cannot function on limited mode"
-        )
+        warnings.warn("weather alert cannot function on limited mode")
     if env.author_mode and settings.limited:
         warnings.warn(
             "'author_mode' cannot be set when 'limited' mode is enabled, disabling author mode."
         )
 
     # Validate if able to read camera only if a camera env var is set,
     try:
@@ -215,26 +251,35 @@
 
     if env.camera_index is None:
         env.camera_index = 0  # Set default but skip validation
     else:
         cam = cv2.VideoCapture(env.camera_index)
         if cam is None or not cam.isOpened() or cam.read() == (False, None):
             if main:
-                raise CameraError(f"Unable to read the camera - {cameras[env.camera_index]}")
+                raise CameraError(
+                    f"Unable to read the camera - {cameras[env.camera_index]}"
+                )
             else:
-                warnings.warn(f"Unable to read the camera - {cameras[env.camera_index]}")
+                warnings.warn(
+                    f"Unable to read the camera - {cameras[env.camera_index]}"
+                )
                 env.camera_index = None
         cam.release()
 
     # Validate voice for speech synthesis
     try:
-        response = requests.get(url=f"http://{env.speech_synthesis_host}:{env.speech_synthesis_port}/api/voices",
-                                timeout=(3, 3))  # Set connect and read timeout explicitly
+        response = requests.get(
+            url=f"http://{env.speech_synthesis_host}:{env.speech_synthesis_port}/api/voices",
+            timeout=(3, 3),
+        )  # Set connect and read timeout explicitly
         if response.ok:
-            available_voices = [value.get('id').replace('/', '_') for key, value in response.json().items()]
+            available_voices = [
+                value.get("id").replace("/", "_")
+                for key, value in response.json().items()
+            ]
             if env.speech_synthesis_voice not in available_voices:
                 if main:
                     raise InvalidEnvVars(
                         f"{env.speech_synthesis_voice} is not available.\n"
                         f"Available Voices for Speech Synthesis: {', '.join(available_voices).replace('/', '_')}"
                     )
                 else:
```

## jarvis/modules/retry/retry.py

```diff
@@ -10,16 +10,18 @@
 import warnings
 from typing import Any, Callable, Union
 
 from jarvis.modules.logger import logger
 from jarvis.modules.utils import support
 
 
-def retry(attempts: int = 3, interval: Union[int, float] = 0, warn: bool = False, exclude_exc=None) -> \
-        Union[Callable, Any, None]:
+# Cannot find reference '|' in 'Callable'
+def retry(
+    attempts: int = 3, interval: int | float = 0, warn: bool = False, exclude_exc=None
+) -> Union[Callable, Any, None]:
     """Wrapper for any function that has to be retried upon failure.
 
     Args:
         attempts: Number of retry attempts.
         interval: Seconds to wait between each iteration.
         warn: Takes a boolean flag whether to throw a warning message instead of raising final exception.
         exclude_exc: Exception(s) that has to be logged and ignored.
@@ -63,23 +65,23 @@
                 exclusions = (exclude_exc, KeyboardInterrupt)
             return_exc = None
             for i in range(1, attempts + 1):
                 try:
                     return_val = func(*args, **kwargs)
                     # Log messages only when the function did not return during the first attempt
                     if i > 1:
-                        logger.info(f"{func.__name__} returned at {support.ENGINE.ordinal(num=i)} attempt")
+                        logger.info(
+                            f"{func.__name__} returned at {support.ENGINE.ordinal(num=i)} attempt"
+                        )
                     return return_val
                 except exclusions as excl_error:
                     logger.error(excl_error)
                 except Exception as error:
                     return_exc = error
                 time.sleep(interval)
             logger.error(f"{func.__name__} exceeded retry count::{attempts}")
             if return_exc and warn:
-                warnings.warn(
-                    f"{type(return_exc).__name__}: {return_exc.__str__()}"
-                )
+                warnings.warn(f"{type(return_exc).__name__}: {return_exc.__str__()}")
 
         return wrapper
 
     return decorator
```

## jarvis/modules/speaker/speak.py

```diff
@@ -3,143 +3,166 @@
 
 >>> Speak
 
 """
 
 import logging
 from collections.abc import Generator
-from typing import Dict, Union
+from typing import Dict
 
 import pyttsx3
 
 handler = logging.StreamHandler()
 default_format = logging.Formatter(
-    datefmt='%b-%d-%Y %I:%M:%S %p',
-    fmt='%(asctime)s - %(levelname)s - [%(module)s:%(lineno)d] - %(funcName)s - %(message)s'
+    datefmt="%b-%d-%Y %I:%M:%S %p",
+    fmt="%(asctime)s - %(levelname)s - [%(module)s:%(lineno)d] - %(funcName)s - %(message)s",
 )
 handler.setFormatter(fmt=default_format)
 
 logger = logging.getLogger(__name__)
 logger.setLevel(level=logging.INFO)
 logger.addHandler(hdlr=handler)
 
-SAMPLE_TEXT = 'Neutron stars are one of the most extreme and violent things in the universe. ' \
-              'Giant atomic nuclei, only a few kilometers in diameter, but as massive as stars. ' \
-              'And they owe their existence to the death of something majestic.'
+SAMPLE_TEXT = (
+    "Neutron stars are one of the most extreme and violent things in the universe. "
+    "Giant atomic nuclei, only a few kilometers in diameter, but as massive as stars. "
+    "And they owe their existence to the death of something majestic."
+)
 
 
 class Speaker:
     """Initiates speaker object to test the speaker's voice and rate.
 
     >>> Speaker
 
     """
 
     def __init__(self):
         """Instantiates the speaker engine and loads the voices available in the hosting machine."""
         self.engine = pyttsx3.init()
-        self.voices = self.engine.getProperty("voices")  # gets the list of voices available
+        self.voices = self.engine.getProperty(
+            "voices"
+        )  # gets the list of voices available
 
     # noinspection PyTypeChecker
-    def get_all_voices(self) -> Generator[Dict[str, Union[str, int]]]:
+    def get_all_voices(self) -> Generator[Dict[str, str | int]]:
         """Yields all the available voices, converting attributes into dict."""
-        logger.info('Getting all voice attributes.')
+        logger.info("Getting all voice attributes.")
         for index, voice in enumerate(self.voices):
-            yield {'index': index, 'id': voice.id, 'name': voice.name, 'gender': voice.gender}
+            yield {
+                "index": index,
+                "id": voice.id,
+                "name": voice.name,
+                "gender": voice.gender,
+            }
 
     # noinspection PyTypeChecker
-    def get_english_voices(self) -> Generator[Dict[str, Union[str, int]]]:
+    def get_english_voices(self) -> Generator[Dict[str, str | int]]:
         """Yields all the available voices for english language, converting attributes into dict."""
-        logger.info('Getting voice attributes for english language.')
+        logger.info("Getting voice attributes for english language.")
         for index, voice in enumerate(self.voices):
-            if 'en_US' in voice.languages:
-                yield {'index': index, 'id': voice.id, 'name': voice.name, 'gender': voice.gender}
+            if "en_US" in voice.languages:
+                yield {
+                    "index": index,
+                    "id": voice.id,
+                    "name": voice.name,
+                    "gender": voice.gender,
+                }
 
     # noinspection PyTypeChecker
-    def get_voice_by_language(self, lang_code: str) -> Generator[Dict[str, Union[str, int]]]:
+    def get_voice_by_language(self, lang_code: str) -> Generator[Dict[str, str | int]]:
         """Yields all the available voices for the given language, converting attributes into dict."""
         logger.info("Getting voice for the language code: '%s'", lang_code)
         for index, voice in enumerate(self.voices):
             if lang_code in voice.languages:
-                yield {'index': index, 'id': voice.id, 'name': voice.name, 'gender': voice.gender}
+                yield {
+                    "index": index,
+                    "id": voice.id,
+                    "name": voice.name,
+                    "gender": voice.gender,
+                }
 
-    def get_voice_by_index(self, index: int) -> Dict[str, Union[str, int]]:
+    def get_voice_by_index(self, index: int) -> Dict[str, str | int]:
         """Yields all the available voices for the given index, converting attributes into dict."""
         logger.info("Getting voice for the index: '%s'", index)
         for voice in self.get_all_voices():
-            if voice['index'] == index:
+            if voice["index"] == index:
                 return voice
 
-    def get_voice_by_name(self, name: str) -> Generator[Dict[str, Union[str, int]]]:
+    def get_voice_by_name(self, name: str) -> Generator[Dict[str, str | int]]:
         """Yields all the available voices matching the given name, converting attributes into dict."""
         logger.info("Getting voices for the name: %s", name)
         for voice in self.get_all_voices():
-            if name.lower() in voice['name'].lower():
+            if name.lower() in voice["name"].lower():
                 yield voice
 
-    def get_voice_by_gender(self, gender: str) -> Generator[Dict[str, Union[str, int]]]:
+    def get_voice_by_gender(self, gender: str) -> Generator[Dict[str, str | int]]:
         """Yields all the available voices matching the given gender, converting attributes into dict."""
-        gender = "VoiceGenderMale" if gender.lower() == 'male' else "VoiceGenderFemale"
+        gender = "VoiceGenderMale" if gender.lower() == "male" else "VoiceGenderFemale"
         logger.info("Getting voices for the gender: %s", gender)
         for voice in self.get_all_voices():
-            if gender == voice['gender']:
+            if gender == voice["gender"]:
                 yield voice
 
     # noinspection PyUnresolvedReferences
     def set_voice_by_index(self, voice_index: int, rate: int = 200) -> None:
         """Set voice attributes per given values.
 
         Args:
             voice_index: Index of the voice that has to be used.
             rate: Rate at which the voice should speak.
         """
-        logger.debug("Setting voice index to %d and speech rate to '%d'", voice_index, rate)
+        logger.debug(
+            "Setting voice index to %d and speech rate to '%d'", voice_index, rate
+        )
         self.engine.setProperty("voice", self.voices[voice_index].id)
         self.engine.setProperty("rate", rate)
 
     def set_voice_by_name(self, voice_name: str, rate: int = 200) -> None:
         """Set voice attributes per given values.
 
         Args:
             voice_name: Name of the voice that has to be used.
             rate: Rate at which the voice should speak.
         """
-        logger.debug("Setting voice name to %s and speech rate to '%d'", voice_name, rate)
-        voices: Union[list, object] = self.engine.getProperty("voices")
+        logger.debug(
+            "Setting voice name to %s and speech rate to '%d'", voice_name, rate
+        )
+        voices: list | object = self.engine.getProperty("voices")
         for voice in voices:
             if voice.name == voice_name or voice_name in voice.name:
                 self.engine.setProperty("voice", voice.id)
                 self.engine.setProperty("rate", rate)
                 break
         else:
             raise ValueError("No matching voice found for the name: '%s'" % voice_name)
 
     def speak_all_voices(self) -> None:
         """Speaks the voice name in all available voices."""
         for voice in self.get_all_voices():
-            self.set_voice_by_index(voice_index=voice['index'])
-            logger.info("Speaker voice [%s]: '%s'", voice['index'], voice['name'])
+            self.set_voice_by_index(voice_index=voice["index"])
+            logger.info("Speaker voice [%s]: '%s'", voice["index"], voice["name"])
             self.run(text=f"Hello, I am {voice['name']}. This is my voice.")
 
     def speak_english_voices(self) -> None:
         """Speaks the voice name in all available english voices."""
         for voice in self.get_english_voices():
-            self.set_voice_by_index(voice_index=voice['index'])
-            logger.info("Speaker voice [%s]: '%s'", voice['index'], voice['name'])
+            self.set_voice_by_index(voice_index=voice["index"])
+            logger.info("Speaker voice [%s]: '%s'", voice["index"], voice["name"])
             self.run(text=f"Hello, I am {voice['name']}. This is my voice.")
 
     def run(self, text: str = None) -> None:
         """Speaks the given text in the voice set.
 
         Args:
             text: Text that has to be spoken. Defaults to a sample text.
         """
         if text is None:
             text = SAMPLE_TEXT
         self.engine.say(text)
         self.engine.runAndWait()
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     speaker = Speaker()
     speaker.set_voice_by_name(voice_name="Daniel (Enhanced)", rate=182)
     speaker.run(text="Welcome to the world of natural language processing.")
```

## jarvis/modules/telegram/audio_handler.py

```diff
@@ -4,15 +4,15 @@
 >>> AudioHandler
 
 """
 
 import importlib
 import logging
 import os
-from typing import Callable, Union
+from typing import Callable
 
 from pydantic import FilePath
 
 from jarvis.modules.logger import logger
 
 importlib.reload(module=logging)
 
@@ -22,45 +22,51 @@
 
     Returns:
         Callable:
         Transcode function from ftransc.
     """
     try:
         from ftransc.core.transcoders import transcode  # noqa
+
         return transcode
-    except (SystemExit, ModuleNotFoundError) as error:
+    except (SystemExit, ModuleNotFoundError, ImportError) as error:
         logger.error(error)
 
 
-def audio_converter_win(input_filename: Union[FilePath, str], output_audio_format: str) -> Union[str, None]:
+def audio_converter_win(
+    input_filename: FilePath | str, output_audio_format: str
+) -> str | None:
     """Imports AudioSegment from pydub.
 
     Args:
         input_filename: Input filename.
         output_audio_format: Output audio format.
 
     Returns:
         str:
         Output filename if conversion is successful.
     """
     ffmpeg_path = os.path.join("ffmpeg", "bin")
     if not os.path.exists(path=ffmpeg_path):
         logger.warning("ffmpeg codec is missing!")
         return
-    os.environ['PATH'] += f";{ffmpeg_path}"
+    os.environ["PATH"] += f";{ffmpeg_path}"
     from pydub import AudioSegment  # noqa
+
     if input_filename.endswith(".ogg"):
         audio = AudioSegment.from_ogg(input_filename)
         output_filename = input_filename.replace(".ogg", f".{output_audio_format}")
     elif input_filename.endswith(".wav"):
         audio = AudioSegment.from_wav(input_filename)
         output_filename = input_filename.replace(".wav", f".{output_audio_format}")
     else:
         return
     try:
         audio.export(input_filename, format=output_audio_format)
         os.remove(input_filename)
         if os.path.isfile(output_filename):
             return output_filename
-        raise FileNotFoundError(f"{output_filename} was not found after exporting audio to {output_audio_format}")
+        raise FileNotFoundError(
+            f"{output_filename} was not found after exporting audio to {output_audio_format}"
+        )
     except FileNotFoundError as error:  # raised by audio.export when conversion fails
         logger.error(error)
```

## jarvis/modules/telegram/bot.py

```diff
@@ -8,36 +8,41 @@
 import json
 import os
 import random
 import secrets
 import sys
 import time
 import traceback
-from typing import Dict, List, Union
+from typing import Dict, List
 
 import requests
 from pydantic import FilePath
 
-from jarvis.executors import (commander, offline, others, restrictions,
-                              word_match)
+from jarvis.executors import commander, offline, others, restrictions, word_match
 from jarvis.modules.audio import tts_stt
 from jarvis.modules.conditions import keywords
 from jarvis.modules.database import database
-from jarvis.modules.exceptions import (BotInUse, BotWebhookConflict,
-                                       EgressErrors, InvalidArgument)
+from jarvis.modules.exceptions import (
+    BotInUse,
+    BotWebhookConflict,
+    EgressErrors,
+    InvalidArgument,
+)
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.telegram import audio_handler, file_handler, settings
 from jarvis.modules.utils import support, util
 
 db = database.Database(database=models.fileio.base_db)
 
 USER_TITLE = {}
-BASE_URL = f'https://api.telegram.org/bot{models.env.bot_token}'
-FILE_CONTENT_URL = f'https://api.telegram.org/file/bot{models.env.bot_token}/' + '{file_path}'
+BASE_URL = f"https://api.telegram.org/bot{models.env.bot_token}"
+FILE_CONTENT_URL = (
+    f"https://api.telegram.org/file/bot{models.env.bot_token}/" + "{file_path}"
+)
 
 
 def username_is_valid(username: str) -> bool:
     """Compares username and returns True if username is allowed."""
     for user in models.env.bot_users:
         if secrets.compare_digest(user, username):
             return True
@@ -65,88 +70,96 @@
         str:
         ``mam`` if predicted to be female, ``sir`` if gender is predicted to be male or unpredicted.
     """
     if name.lower() == models.env.name.lower():
         return models.env.title
     logger.info("Identifying gender for '%s'", name)
     try:
-        response = requests.get(url=f"https://api.genderize.io/?name={name}", timeout=(3, 3))
+        response = requests.get(
+            url=f"https://api.genderize.io/?name={name}", timeout=(3, 3)
+        )
     except EgressErrors as error:
         logger.critical(error)
         return models.env.title
     if not response.ok:
         logger.critical("%d: %s", response.status_code, response.text)
         return models.env.title
     response_json = response.json()
     logger.info(response_json)
-    if response_json.get('gender', 'unidentified').lower() == 'female':
-        return 'mam'
-    return 'sir'
+    if response_json.get("gender", "unidentified").lower() == "female":
+        return "mam"
+    return "sir"
 
 
 def intro() -> str:
     """Returns a welcome message as a string.
 
     Returns:
         str:
     """
-    return "\nI am *Jarvis*, a pre-programmed virtual assistant designed by Mr. Rao\n" \
-           "You may start giving me commands to execute.\n\n" \
-           "*Examples*\n\n" \
-           "*Car Controls*\n" \
-           "start my car\n" \
-           "set my car to 66 degrees\n" \
-           "turn off my car\n" \
-           "lock my car\n" \
-           "unlock my car\n\n" \
-           "*Thermostat Controls*\n" \
-           "get me the status of my thermostat\n" \
-           "what's the indoor temperature\n" \
-           "set my thermostat to heat 70 degrees\n\n" \
-           "*TV*\n" \
-           "launch Netflix on my tv\n" \
-           "increase the volume on my tv\n" \
-           "what's currently playing on my tv\n" \
-           "turn off on my tv\n\n" \
-           "*Lights*\n" \
-           "turn on hallway lights\n" \
-           "set my hallway lights to warm\n" \
-           "set my bedroom lights to 5 percent\n" \
-           "turn off all my lights\n\n" \
-           "*Some more...*\n" \
-           "do I have any meetings today?\n" \
-           "where is my iPhone 12 Pro\n" \
-           "do I have any emails?\n" \
-           "what is the weather in Detroit?\n" \
-           "get me the local news\n" \
-           "what is the meaning of Legionnaire\n" \
-           "tell a joke\n" \
-           "flip a coin for me\n"
+    return (
+        "\nI am *Jarvis*, a pre-programmed virtual assistant designed by Mr. Rao\n"
+        "You may start giving me commands to execute.\n\n"
+        "*Examples*\n\n"
+        "*Car Controls*\n"
+        "start my car\n"
+        "set my car to 66 degrees\n"
+        "turn off my car\n"
+        "lock my car\n"
+        "unlock my car\n\n"
+        "*Thermostat Controls*\n"
+        "get me the status of my thermostat\n"
+        "what's the indoor temperature\n"
+        "set my thermostat to heat 70 degrees\n\n"
+        "*TV*\n"
+        "launch Netflix on my tv\n"
+        "increase the volume on my tv\n"
+        "what's currently playing on my tv\n"
+        "turn off on my tv\n\n"
+        "*Lights*\n"
+        "turn on hallway lights\n"
+        "set my hallway lights to warm\n"
+        "set my bedroom lights to 5 percent\n"
+        "turn off all my lights\n\n"
+        "*Some more...*\n"
+        "do I have any meetings today?\n"
+        "where is my iPhone 12 Pro\n"
+        "do I have any emails?\n"
+        "what is the weather in Detroit?\n"
+        "get me the local news\n"
+        "what is the meaning of Legionnaire\n"
+        "tell a joke\n"
+        "flip a coin for me\n"
+    )
 
 
-def _get_file(data_class: Union[settings.Voice, settings.Document]) -> Union[bytes, None]:
+def _get_file(data_class: settings.Voice | settings.Document) -> bytes | None:
     """Makes a request to get the file and file path.
 
     Args:
         data_class: Required section of the payload as Voice or Document object.
 
     Returns:
         bytes:
         Returns the file content as bytes.
     """
-    response = _make_request(url=BASE_URL + '/getFile', payload={'file_id': data_class.file_id})
+    response = _make_request(
+        url=BASE_URL + "/getFile", payload={"file_id": data_class.file_id}
+    )
     try:
         json_response = json.loads(response.content)
     except json.JSONDecodeError as error:
         logger.error(error)
         return
-    if not response.ok or not json_response.get('ok'):
+    if not response.ok or not json_response.get("ok"):
         logger.error(response.content)
         return
-    response = requests.get(url=FILE_CONTENT_URL.format(file_path=json_response['result']['file_path']))
+    response = requests.get(
+        url=FILE_CONTENT_URL.format(file_path=json_response["result"]["file_path"])
+    )
     if not response.ok:
         logger.error(response.content)
         return
     return response.content
 
 
 def _make_request(url: str, payload: dict, files: dict = None) -> requests.Response:
@@ -166,109 +179,141 @@
         logger.debug(payload)
         logger.debug(files)
         logger.warning("Called by: '%s'", sys._getframe(1).f_code.co_name)  # noqa
         logger.error(response.json())
     return response
 
 
-def send_audio(chat_id: int, filename: Union[str, FilePath], parse_mode: str = 'HTML') -> requests.Response:
+def send_audio(
+    chat_id: int, filename: str | FilePath, parse_mode: str = "HTML"
+) -> requests.Response:
     """Sends an audio file to the user.
 
     Args:
         chat_id: Chat ID.
         filename: Name of the audio file that has to be sent.
         parse_mode: Parse mode. Defaults to ``HTML``
 
     Returns:
         Response:
         Response class.
     """
-    with open(filename, 'rb') as audio:
-        files = {'audio': audio.read()}
-    return _make_request(url=BASE_URL + '/sendAudio', files=files,
-                         payload={'chat_id': chat_id, 'title': filename, 'parse_mode': parse_mode})
+    with open(filename, "rb") as audio:
+        files = {"audio": audio.read()}
+    return _make_request(
+        url=BASE_URL + "/sendAudio",
+        files=files,
+        payload={"chat_id": chat_id, "title": filename, "parse_mode": parse_mode},
+    )
 
 
-def send_document(chat_id: int, filename: Union[str, FilePath], parse_mode: str = 'HTML') -> \
-        requests.Response:
+def send_document(
+    chat_id: int, filename: str | FilePath, parse_mode: str = "HTML"
+) -> requests.Response:
     """Sends a document to the user.
 
     Args:
         chat_id: Chat ID.
         filename: Name of the audio file that has to be sent.
         parse_mode: Parse mode. Defaults to ``HTML``
 
     Returns:
         Response:
         Response class.
     """
-    files = {'document': open(filename, 'rb')}
-    return _make_request(url=BASE_URL + '/sendDocument', files=files,
-                         payload={'chat_id': chat_id, 'caption': os.path.basename(filename),
-                                  'parse_mode': parse_mode})
+    files = {"document": open(filename, "rb")}
+    return _make_request(
+        url=BASE_URL + "/sendDocument",
+        files=files,
+        payload={
+            "chat_id": chat_id,
+            "caption": os.path.basename(filename),
+            "parse_mode": parse_mode,
+        },
+    )
 
 
-def send_photo(chat_id: int, filename: Union[str, FilePath]) -> requests.Response:
+def send_photo(chat_id: int, filename: str | FilePath) -> requests.Response:
     """Sends an image file to the user.
 
     Args:
         chat_id: Chat ID.
         filename: Name of the image file that has to be sent.
 
     Returns:
         Response:
         Response class.
     """
-    with open(filename, 'rb') as image:
-        files = {'photo': image.read()}
-    return _make_request(url=BASE_URL + '/sendPhoto', files=files,
-                         payload={'chat_id': chat_id, 'title': os.path.split(filename)[-1]})
+    with open(filename, "rb") as image:
+        files = {"photo": image.read()}
+    return _make_request(
+        url=BASE_URL + "/sendPhoto",
+        files=files,
+        payload={"chat_id": chat_id, "title": os.path.split(filename)[-1]},
+    )
 
 
-def reply_to(chat: settings.Chat, response: str, parse_mode: Union[str, None] = 'markdown',
-             retry: bool = False) -> requests.Response:
+def reply_to(
+    chat: settings.Chat,
+    response: str,
+    parse_mode: str | None = "markdown",
+    retry: bool = False,
+) -> requests.Response:
     """Generates a payload to reply to a message received.
 
     Args:
         chat: Required section of the payload as Chat object.
         response: Message to be sent to the user.
         parse_mode: Parse mode. Defaults to ``markdown``
         retry: Retry reply in case reply failed because of parsing.
 
     Returns:
         Response:
         Response class.
     """
-    result = _make_request(url=BASE_URL + '/sendMessage',
-                           payload={'chat_id': chat.id,
-                                    'reply_to_message_id': chat.message_id,
-                                    'text': response, 'parse_mode': parse_mode})
-    if result.status_code == 400 and parse_mode and not retry:  # Retry with response as plain text
+    result = _make_request(
+        url=BASE_URL + "/sendMessage",
+        payload={
+            "chat_id": chat.id,
+            "reply_to_message_id": chat.message_id,
+            "text": response,
+            "parse_mode": parse_mode,
+        },
+    )
+    # Retry with response as plain text
+    if result.status_code == 400 and parse_mode and not retry:
         logger.warning("Retrying response as plain text with no parsing")
         reply_to(chat, response, None, True)
     return result
 
 
-def send_message(chat_id: int, response: str, parse_mode: Union[str, None] = 'markdown',
-                 retry: bool = False) -> requests.Response:
+def send_message(
+    chat_id: int,
+    response: str,
+    parse_mode: str | None = "markdown",
+    retry: bool = False,
+) -> requests.Response:
     """Generates a payload to reply to a message received.
 
     Args:
         chat_id: Chat ID.
         response: Message to be sent to the user.
         parse_mode: Parse mode. Defaults to ``markdown``
         retry: Retry reply in case reply failed because of parsing.
 
     Returns:
         Response:
         Response class.
     """
-    result = _make_request(url=BASE_URL + '/sendMessage',
-                           payload={'chat_id': chat_id, 'text': response, 'parse_mode': parse_mode})
-    if result.status_code == 400 and parse_mode and not retry:  # Retry with response as plain text
+    result = _make_request(
+        url=BASE_URL + "/sendMessage",
+        payload={"chat_id": chat_id, "text": response, "parse_mode": parse_mode},
+    )
+    # Retry with response as plain text
+    if result.status_code == 400 and parse_mode and not retry:
         logger.warning("Retrying response as plain text with no parsing")
         send_message(chat_id=chat_id, response=response, parse_mode=None, retry=True)
     return result
 
 
 def poll_for_messages() -> None:
     """Polls ``api.telegram.org`` for new messages.
@@ -281,70 +326,73 @@
 
     See Also:
         Swaps ``offset`` value during every iteration to avoid reprocessing messages.
     """
     offset = 0
     logger.info("Polling for incoming messages..")
     while True:
-        response = _make_request(url=BASE_URL + '/getUpdates',
-                                 payload={'offset': offset, 'timeout': 60})
+        response = _make_request(
+            url=BASE_URL + "/getUpdates", payload={"offset": offset, "timeout": 60}
+        )
         if response.ok:
             response = response.json()
         else:
             if response.status_code == 409:
-                err_desc = response.json().get('description')
+                err_desc = response.json().get("description")
                 # If it has come to this, then webhook has already failed
-                if err_desc == ("Conflict: can't use getUpdates method while webhook is active; "
-                                "use deleteWebhook to delete the webhook first"):
+                if err_desc == (
+                    "Conflict: can't use getUpdates method while webhook is active; "
+                    "use deleteWebhook to delete the webhook first"
+                ):
                     raise BotWebhookConflict(err_desc)
                 raise BotInUse(err_desc)
             raise ConnectionError(response.json())
-        if not response.get('result'):
+        if not response.get("result"):
             continue
-        for result in response['result']:
-            if payload := result.get('message'):
+        for result in response["result"]:
+            if payload := result.get("message"):
                 process_request(payload)
             else:
                 logger.error("Received empty payload!!")
-            offset = result['update_id'] + 1
+            offset = result["update_id"] + 1
 
 
-def process_request(payload: Dict[str, Union[int, dict]]) -> None:
+def process_request(payload: Dict[str, int | dict]) -> None:
     """Processes the request via Telegram messages.
 
     Args:
         payload: Payload as received.
     """
     logger.debug(payload)
-    chat = settings.Chat(**{**payload, **payload['chat'], **payload['from']})
+    chat = settings.Chat(**{**payload, **payload["chat"], **payload["from"]})
     if not authenticate(chat):
         logger.warning(payload)
         return
     if not verify_timeout(chat):
         logger.warning(payload)
         return
-    if payload.get('text'):
-        chat.message_type = 'text'
+    if payload.get("text"):
+        chat.message_type = "text"
         process_text(chat, settings.Text(**payload))
-    elif payload.get('voice'):
-        chat.message_type = 'voice'
-        process_voice(chat, settings.Voice(**payload['voice']))
-    elif payload.get('document'):
-        chat.message_type = 'document'
-        process_document(chat, settings.Document(**payload['document']))
-    elif payload.get('video'):
-        chat.message_type = 'video'
-        process_video(chat, settings.Video(**payload['video']))
-    elif payload.get('audio'):
-        chat.message_type = 'audio'
-        process_audio(chat, settings.Audio(**payload['audio']))
-    elif payload.get('photo'):
+    elif payload.get("voice"):
+        chat.message_type = "voice"
+        process_voice(chat, settings.Voice(**payload["voice"]))
+    elif payload.get("document"):
+        chat.message_type = "document"
+        process_document(chat, settings.Document(**payload["document"]))
+    elif payload.get("video"):
+        chat.message_type = "video"
+        process_video(chat, settings.Video(**payload["video"]))
+    elif payload.get("audio"):
+        chat.message_type = "audio"
+        process_audio(chat, settings.Audio(**payload["audio"]))
+    elif payload.get("photo"):
         # Matches for compressed images
-        chat.message_type = 'photo'
-        process_photo(chat, [settings.PhotoFragment(**d) for d in payload['photo']])
+        chat.message_type = "photo"
+        process_photo(chat, [settings.PhotoFragment(**d) for d in payload["photo"]])
     else:
         reply_to(chat, "Payload type is not allowed.")
 
 
 def authenticate(chat: settings.Chat) -> bool:
     """Authenticates the user with ``userId`` and ``userName``.
 
@@ -353,20 +401,28 @@
 
     Returns:
         bool:
         Returns a boolean to indicate whether the user is authenticated.
     """
     if chat.is_bot:
         logger.error("Bot request from %s", chat.username)
-        send_message(chat_id=chat.id,
-                     response=f"Sorry {chat.first_name}! I can't process requests from bots.")
+        send_message(
+            chat_id=chat.id,
+            response=f"Sorry {chat.first_name}! I can't process requests from bots.",
+        )
         return False
-    if chat.id not in models.env.bot_chat_ids or not username_is_valid(username=chat.username):
-        logger.error("Unauthorized chatID [%d] or userName [%s]", chat.id, chat['username'])
-        send_message(chat_id=chat.id, response=f"401 Unauthorized user: ({chat['username']})")
+    if chat.id not in models.env.bot_chat_ids or not username_is_valid(
+        username=chat.username
+    ):
+        logger.error(
+            "Unauthorized chatID [%d] or userName [%s]", chat.id, chat["username"]
+        )
+        send_message(
+            chat_id=chat.id, response=f"401 Unauthorized user: ({chat['username']})"
+        )
         return False
     if not USER_TITLE.get(chat.username):
         USER_TITLE[chat.username] = get_title_by_name(name=chat.first_name)
     return True
 
 
 def verify_timeout(chat: settings.Chat) -> bool:
@@ -377,54 +433,72 @@
 
     Returns:
         bool:
         True or False flag to indicate if the request timed out.
     """
     if int(time.time()) - chat.date < 60:
         return True
-    request_time = time.strftime('%m-%d-%Y %H:%M:%S', time.localtime(chat.date))
+    request_time = time.strftime("%m-%d-%Y %H:%M:%S", time.localtime(chat.date))
     logger.warning("Request timed out [%s] for %s", request_time, chat.username)
-    reply_to(chat, f"Request timed out\nRequested: {request_time}\n"
-                   f"Processed: {time.strftime('%m-%d-%Y %H:%M:%S', time.localtime(time.time()))}")
+    reply_to(
+        chat,
+        f"Request timed out\nRequested: {request_time}\n"
+        f"Processed: {time.strftime('%m-%d-%Y %H:%M:%S', time.localtime(time.time()))}",
+    )
 
 
 def verify_stop(chat: settings.Chat, data_class: settings.Text) -> bool:
     """Stops Jarvis by setting stop flag in ``base_db`` if stop is requested by the user with an override flag.
 
     Args:
         chat: Required section of the payload as Chat object.
         data_class: Required section of the payload as Text object.
 
     Returns:
         bool:
         Boolean flag to indicate whether to proceed.
     """
-    if not word_match.word_match(phrase=data_class.text, match_list=keywords.keywords['kill']):
+    if not word_match.word_match(
+        phrase=data_class.text, match_list=keywords.keywords["kill"]
+    ):
         return True
     if "override" in data_class.text.lower():
         logger.info("%s requested a STOP override.", chat.username)
-        reply_to(chat, f"Shutting down now {models.env.title}!\n{support.exit_message()}")
+        reply_to(
+            chat, f"Shutting down now {models.env.title}!\n{support.exit_message()}"
+        )
         with db.connection:
             cursor = db.connection.cursor()
-            cursor.execute("INSERT or REPLACE INTO stopper (flag, caller) VALUES (?,?);", (True, 'TelegramAPI'))
+            cursor.execute(
+                "INSERT or REPLACE INTO stopper (flag, caller) VALUES (?,?);",
+                (True, "TelegramAPI"),
+            )
             cursor.connection.commit()
     else:
-        reply_to(chat, "Jarvis cannot be stopped via offline communication without an 'override' flag.")
+        reply_to(
+            chat,
+            "Jarvis cannot be stopped via offline communication without the 'override' keyword.",
+        )
 
 
-def process_photo(chat: settings.Chat, data_class: List[settings.PhotoFragment]) -> None:
+def process_photo(
+    chat: settings.Chat, data_class: List[settings.PhotoFragment]
+) -> None:
     """Processes a photo input.
 
     Args:
         chat: Required section of the payload as Chat object.
         data_class: Required section of the payload as Voice object.
     """
     logger.info(data_class)
-    reply_to(chat, "Image fragments are not supported. If you're sending a compressed image, "
-                   "please try sending it without compression.")
+    reply_to(
+        chat,
+        "Image fragments are not supported. If you're sending a compressed image, "
+        "please try sending it without compression.",
+    )
 
 
 def process_audio(chat: settings.Chat, data_class: settings.Audio) -> None:
     """Processes an audio input.
 
     Args:
         chat: Required section of the payload as Chat object.
@@ -447,31 +521,38 @@
     """Processes the audio file in payload received after checking for authentication.
 
     Args:
         chat: Required section of the payload as Chat object.
         data_class: Required section of the payload as Voice object.
     """
     if bytes_obj := _get_file(data_class):
-        if data_class.mime_type == 'audio/ogg':
+        if data_class.mime_type == "audio/ogg":
             filename = f"{data_class.file_unique_id}.ogg"
         else:
             logger.error("Unknown FileType received.")
             logger.error(data_class)
-            reply_to(chat, "Your voice command was received as an unknown file type: "
-                           f"{data_class.mime_type}\nPlease try the command as a text.")
+            reply_to(
+                chat,
+                "Your voice command was received as an unknown file type: "
+                f"{data_class.mime_type}\nPlease try the command as a text.",
+            )
             return
-        with open(filename, 'wb') as file:
+        with open(filename, "wb") as file:
             file.write(bytes_obj)
         converted = False
         if models.settings.os == models.supported_platforms.macOS:
             transcode = audio_handler.audio_converter_mac()
-            if transcode and transcode(input_file_name=filename, output_audio_format="flac"):
+            if transcode and transcode(
+                input_file_name=filename, output_audio_format="flac"
+            ):
                 converted = True
         elif models.settings.os == models.supported_platforms.windows:
-            if audio_handler.audio_converter_win(input_filename=filename, output_audio_format="flac"):
+            if audio_handler.audio_converter_win(
+                input_filename=filename, output_audio_format="flac"
+            ):
                 converted = True
         if converted:
             os.remove(filename)
             filename = filename.replace(".ogg", ".flac")
             audio_to_text = tts_stt.audio_to_text(filename=filename)
             if audio_to_text:
                 jarvis(audio_to_text, chat)
@@ -479,36 +560,45 @@
         else:
             logger.error("Failed to transcode OPUS to Native FLAC")
     else:
         logger.error("Unable to get file for the file id in the payload received.")
         logger.error(data_class)
     # Catches both unconverted source ogg and unconverted audio to text
     title = USER_TITLE.get(chat.username, models.env.title)
-    if filename := tts_stt.text_to_audio(text=f"I'm sorry {title}! I was unable to process your voice command. "
-                                              "Please try again!"):
+    if filename := tts_stt.text_to_audio(
+        text=f"I'm sorry {title}! I was unable to process your voice command. "
+        "Please try again!"
+    ):
         send_audio(filename=filename, chat_id=chat.id)
         os.remove(filename)
     else:
         reply_to(chat, "Failed to convert audio. Please try text input.")
 
 
-def process_document(chat: settings.Chat, data_class: Union[settings.Document, settings.Audio, settings.Video]) -> None:
+def process_document(
+    chat: settings.Chat, data_class: settings.Document | settings.Audio | settings.Video
+) -> None:
     """Processes the document in payload received after checking for authentication.
 
     Args:
         chat: Required section of the payload as Chat object.
         data_class: Required section of the payload as Document object.
     """
     if bytes_obj := _get_file(data_class):
-        response = file_handler.put_file(filename=data_class.file_name, file_content=bytes_obj)
+        response = file_handler.put_file(
+            filename=data_class.file_name, file_content=bytes_obj
+        )
         send_message(chat_id=chat.id, response=response, parse_mode=None)
     else:
         title = USER_TITLE.get(chat.username, models.env.title)
-        reply_to(chat, f"I'm sorry {title}! I was unable to process your document. Please try again!",
-                 None)
+        reply_to(
+            chat,
+            f"I'm sorry {title}! I was unable to process your document. Please try again!",
+            None,
+        )
 
 
 def process_text(chat: settings.Chat, data_class: settings.Text) -> None:
     """Processes the text in payload received after checking for authentication.
 
     Args:
         chat: Required section of the payload as Chat object.
@@ -519,75 +609,114 @@
           | other requests using 'and' or 'also'
     """
     if data_class.text:
         data_class.text = data_class.text.strip()
     else:
         send_message(chat_id=chat.id, response="Un-processable payload")
         return
-    if data_class.text.lower() == 'help':
-        send_message(chat_id=chat.id,
-                     response=f"{greeting()} {chat.first_name}!\n"
-                              f"Good {util.part_of_day()}! {intro()}\n\n"
-                              "Please reach out at https://vigneshrao.com/contact for more info.")
+    if data_class.text.lower() == "help":
+        send_message(
+            chat_id=chat.id,
+            response=f"{greeting()} {chat.first_name}!\n"
+            f"Good {util.part_of_day()}! {intro()}\n\n"
+            "Please reach out at https://vigneshrao.com/contact for more info.",
+        )
         return
     if not verify_stop(chat, data_class):
         return
-    data_class.text = data_class.text.replace('override', '').replace('OVERRIDE', '')
-    if match_word := word_match.word_match(phrase=data_class.text.lower(),
-                                           match_list=("hey", "hola", "what's up", "ssup", "whats up", "hello",
-                                                       "hi", "howdy", "hey", "chao", "hiya", "aloha"), strict=True):
-        rest_of_msg = data_class.text.replace(match_word, '')
-        if not rest_of_msg or 'jarvis' in rest_of_msg.strip().lower():
-            reply_to(chat, f"{greeting()} {chat.first_name}!\n"
-                           f"Good {util.part_of_day()}! How can I be of service today?")
+    data_class.text = data_class.text.replace("override", "").replace("OVERRIDE", "")
+    if match_word := word_match.word_match(
+        phrase=data_class.text.lower(),
+        match_list=(
+            "hey",
+            "hola",
+            "what's up",
+            "ssup",
+            "whats up",
+            "hello",
+            "hi",
+            "howdy",
+            "hey",
+            "chao",
+            "hiya",
+            "aloha",
+        ),
+        strict=True,
+    ):
+        rest_of_msg = data_class.text.replace(match_word, "")
+        if not rest_of_msg or "jarvis" in rest_of_msg.strip().lower():
+            reply_to(
+                chat,
+                f"{greeting()} {chat.first_name}!\n"
+                f"Good {util.part_of_day()}! How can I be of service today?",
+            )
             return
-    if data_class.text == '/start':
+    if data_class.text == "/start":
         send_message(chat.id, f"{greeting()} {chat.first_name}! {intro()}")
         return
-    if data_class.text.startswith('/'):
-        if '_' not in data_class.text:  # Auto-complete can be setup using "/" commands so ignore if "_" is present
-            reply_to(chat, "*Deprecation Notice*\n\nSlash commands ('/') have been deprecated. Please use "
-                           "commands directly instead.")
-        data_class.text = data_class.text.lstrip('/').replace('jarvis', '').replace('_', ' ').strip()
+    if data_class.text.startswith("/"):
+        # Auto-complete can be setup using "/" commands so ignore if "_" is present
+        if "_" not in data_class.text:
+            reply_to(
+                chat,
+                "*Deprecation Notice*\n\nSlash commands ('/') have been deprecated. Please use "
+                "commands directly instead.",
+            )
+        data_class.text = (
+            data_class.text.lstrip("/").replace("jarvis", "").replace("_", " ").strip()
+        )
     if not data_class.text:
         return
     split_text = data_class.text.lower().split()
-    if ('file' in split_text or 'files' in split_text) and \
-            ('send' in split_text or 'get' in split_text or 'list' in split_text):
-        if 'list' in split_text and ('files' in split_text or 'file' in split_text):
+    if ("file" in split_text or "files" in split_text) and (
+        "send" in split_text or "get" in split_text or "list" in split_text
+    ):
+        if "list" in split_text and ("files" in split_text or "file" in split_text):
             # Set parse_mode to an explicit None, so the API doesn't try to parse as HTML or Markdown
             # since the result has file names and paths
-            send_message(chat_id=chat.id, response=file_handler.list_files(), parse_mode=None)
+            send_message(
+                chat_id=chat.id, response=file_handler.list_files(), parse_mode=None
+            )
             return
-        _, _, filename = data_class.text.partition(' file ')
+        _, _, filename = data_class.text.partition(" file ")
         if filename:
             response = file_handler.get_file(filename=filename.strip())
-            if response['ok']:
-                send_document(filename=response['msg'], chat_id=chat.id)
+            if response["ok"]:
+                send_document(filename=response["msg"], chat_id=chat.id)
             else:
-                reply_to(chat, response['msg'], None)
+                reply_to(chat, response["msg"], None)
         else:
-            reply_to(chat, "No filename was received. "
-                           "Please include only the filename after the keyword 'file'.")
-        return
-    if word_match.word_match(phrase=data_class.text, match_list=keywords.keywords['restrictions']):
+            reply_to(
+                chat,
+                "No filename was received. "
+                "Please include only the filename after the keyword 'file'.",
+            )
+        return
+    if word_match.word_match(
+        phrase=data_class.text, match_list=keywords.keywords["restrictions"]
+    ):
         try:
             response = restrictions.handle_restrictions(phrase=data_class.text)
         except InvalidArgument as error:
             response = error.__str__()
         send_message(chat_id=chat.id, response=response)
         return
     # this feature for telegram bot relies on Jarvis API to function
-    if word_match.word_match(phrase=data_class.text, match_list=keywords.keywords['secrets']) and \
-            word_match.word_match(phrase=data_class.text, match_list=('list', 'get', 'send', 'create', 'share')):
+    if word_match.word_match(
+        phrase=data_class.text, match_list=keywords.keywords["secrets"]
+    ) and word_match.word_match(
+        phrase=data_class.text, match_list=("list", "get", "send", "create", "share")
+    ):
         res = others.secrets(phrase=data_class.text)
         if len(res.split()) == 1:
-            res = "The secret requested can be accessed from '_secure-send_' endpoint using the token below.\n\n" \
-                  "*Note* that the secret cannot be retrieved again using the same token and the token will " \
-                  f"expire in 5 minutes.\n\n{res}"
+            res = (
+                "The secret requested can be accessed from '_secure-send_' endpoint using the token below.\n\n"
+                "*Note* that the secret cannot be retrieved again using the same token and the token will "
+                f"expire in 5 minutes.\n\n{res}"
+            )
             send_message(chat_id=chat.id, response=res)
         else:
             send_message(chat_id=chat.id, response=res, parse_mode=None)
         return
     jarvis(data_class.text, chat)
 
 
@@ -595,33 +724,42 @@
     """Uses the table ``offline`` in the database to process a response.
 
     Args:
         command: Command to execute.
         chat: Required section of the payload as Chat object.
     """
     command_lower = command.lower()
-    if 'alarm' in command_lower or 'remind' in command_lower:
+    if "alarm" in command_lower or "remind" in command_lower:
         command = command_lower
-    if command_lower == 'test':
+    if command_lower == "test":
         send_message(chat.id, "Test message received.")
         return
 
-    if ' and ' in command and not word_match.word_match(phrase=command, match_list=keywords.ignore_and):
-        and_phrases = command.split(' and ')
+    if " and " in command and not word_match.word_match(
+        phrase=command, match_list=keywords.ignore_and
+    ):
+        and_phrases = command.split(" and ")
         logger.info("Looping through %s in iterations.", and_phrases)
         for each in and_phrases:
             executor(each, chat)
         return
 
-    if ' after ' in command_lower and not word_match.word_match(phrase=command, match_list=keywords.ignore_after):
+    if " after " in command_lower and not word_match.word_match(
+        phrase=command, match_list=keywords.ignore_after
+    ):
         if delay_info := commander.timed_delay(phrase=command):
             logger.info("Request: %s", delay_info[0])
-            process_response("I will execute it after "
-                             f"{support.time_converter(second=delay_info[1])} {models.env.title}!", chat)
-            logger.info("Response: Task will be executed after %d seconds", delay_info[1])
+            process_response(
+                "I will execute it after "
+                f"{support.time_converter(second=delay_info[1])} {models.env.title}!",
+                chat,
+            )
+            logger.info(
+                "Response: Task will be executed after %d seconds", delay_info[1]
+            )
             return
     executor(command, chat)
 
 
 def executor(command: str, chat: settings.Chat) -> None:
     """Executes the command via offline communicator.
 
@@ -645,17 +783,17 @@
 def process_response(response: str, chat: settings.Chat) -> None:
     """Processes the response via Telegram API.
 
     Args:
         response: Response from Jarvis.
         chat: Required section of the payload as Chat object.
     """
-    if os.path.isfile(response) and response.endswith('jpg'):
+    if os.path.isfile(response) and response.endswith("jpg"):
         send_photo(chat.id, response)
         os.remove(response)
         return
-    if chat.message_type == 'voice':
+    if chat.message_type == "voice":
         filename = tts_stt.text_to_audio(text=response)
         send_audio(chat.id, filename)
         os.remove(filename)
         return
     send_message(chat.id, response, None)
```

## jarvis/modules/telegram/file_handler.py

```diff
@@ -16,30 +16,44 @@
 def _list_files() -> Dict[str, str]:
     """Get all YAML files from fileio and all log files from logs directory.
 
     Returns:
         Dict[str, List[str]]:
         Dictionary of files that can be downloaded or uploaded.
     """
-    return {**{"logs": [file_ for __path, __directory, __file in os.walk('logs') for file_ in __file]},
-            **{"fileio": [f for f in os.listdir(models.fileio.root) if f.endswith('.yaml')]},
-            **{"uploads": [f for f in os.listdir(models.fileio.uploads) if not f.startswith('.')]}}
+    return {
+        **{
+            "logs": [
+                file_
+                for __path, __directory, __file in os.walk("logs")
+                for file_ in __file
+            ]
+        },
+        **{
+            "fileio": [f for f in os.listdir(models.fileio.root) if f.endswith(".yaml")]
+        },
+        **{
+            "uploads": [
+                f for f in os.listdir(models.fileio.uploads) if not f.startswith(".")
+            ]
+        },
+    }
 
 
 def list_files() -> str:
     """List all downloadable files.
 
     Returns:
         str:
         Returns response as a string.
     """
     all_files = _list_files()
-    joined_logs = '\n'.join(all_files['logs'])
-    joined_fileio = '\n'.join(all_files['fileio'])
-    joined_uploads = '\n'.join(all_files['uploads'])
+    joined_logs = "\n".join(all_files["logs"])
+    joined_fileio = "\n".join(all_files["fileio"])
+    joined_uploads = "\n".join(all_files["uploads"])
     return f"{joined_logs}\n\n{joined_fileio}\n\n{joined_uploads}"
 
 
 def get_file(filename: str) -> Dict:
     """Download a particular YAML file from fileio or log file from logs directory.
 
     Args:
@@ -47,31 +61,37 @@
 
     Returns:
         Response:
         Returns the Response object to further process send document via API.
     """
     allowed_files = _list_files()
     if filename not in allowed_files["fileio"] + allowed_files["logs"]:
-        return {'ok': False,
-                'msg': f"{filename!r} is either unavailable or not allowed. "
-                       "Please use the command 'list files' to get a list of downloadable files."}
+        return {
+            "ok": False,
+            "msg": f"{filename!r} is either unavailable or not allowed. "
+            "Please use the command 'list files' to get a list of downloadable files.",
+        }
     if filename.endswith(".log"):
-        if path := [__path for __path, __directory, __file in os.walk("logs") if filename in __file]:
+        if path := [
+            __path
+            for __path, __directory, __file in os.walk("logs")
+            if filename in __file
+        ]:
             target_file = os.path.join(path[0], filename)
         else:
             logger.critical("ATTENTION::'%s' wasn't found.", filename)
             return {
                 "ok": False,
                 "msg": f"{filename!r} was not found. "
-                       "Please use the command 'list files' to get a list of downloadable files."
+                "Please use the command 'list files' to get a list of downloadable files.",
             }
     else:
         target_file = os.path.join(models.fileio.root, filename)
     logger.info("Requested file: '%s' for download.", filename)
-    return {'ok': True, 'msg': target_file}
+    return {"ok": True, "msg": target_file}
 
 
 def put_file(filename: str, file_content: bytes) -> str:
     """Upload a particular YAML file to the fileio directory.
 
     Args:
         filename: Name of the file.
@@ -80,14 +100,19 @@
     Returns:
         str:
         Response to the user.
     """
     logger.info("Requested file: '%s' for upload.", filename)
     allowed_files = _list_files()
     if filename not in allowed_files["fileio"]:
-        with open(os.path.join(models.fileio.uploads,
-                               f"{datetime.now().strftime('%d_%B_%Y-%I_%M_%p')}-{filename}"), "wb") as f_stream:
+        with open(
+            os.path.join(
+                models.fileio.uploads,
+                f"{datetime.now().strftime('%d_%B_%Y-%I_%M_%p')}-{filename}",
+            ),
+            "wb",
+        ) as f_stream:
             f_stream.write(file_content)
         return f"{filename!r} is not allowed for an update. Hence, storing as standalone file."
     with open(os.path.join(models.fileio.root, filename), "wb") as f_stream:
         f_stream.write(file_content)
     return f"{filename!r} was uploaded to {os.path.basename(models.fileio.root)}."
```

## jarvis/modules/telegram/webhook.py

```diff
@@ -1,9 +1,8 @@
 import logging
-from typing import Union
 
 import requests
 from pydantic import HttpUrl
 
 from jarvis.modules.models import models
 
 
@@ -17,47 +16,51 @@
     response = requests.get(url=get_info)
     if response.ok:
         logger.info(response.json())
         return response.json()
     response.raise_for_status()
 
 
-def delete_webhook(base_url: Union[str, HttpUrl], logger: logging.Logger):
+def delete_webhook(base_url: str | HttpUrl, logger: logging.Logger):
     """Delete webhook.
 
     References:
         https://core.telegram.org/bots/api#deletewebhook
     """
     del_info = f"{base_url}/setWebhook"
     response = requests.post(url=del_info, params=dict(url=None))
     if response.ok:
         logger.info("Webhook has been removed.")
         return response.json()
     response.raise_for_status()
 
 
-def set_webhook(base_url: Union[HttpUrl, str], webhook: Union[HttpUrl, str], logger: logging.Logger):
+def set_webhook(
+    base_url: HttpUrl | str, webhook: HttpUrl | str, logger: logging.Logger
+):
     """Set webhook.
 
     References:
         https://core.telegram.org/bots/api#setwebhook
     """
     put_info = f"{base_url}/setWebhook"
-    payload = dict(
-        url=webhook,
-        secret_token=models.env.bot_secret
-    )
+    payload = dict(url=webhook, secret_token=models.env.bot_secret)
     if models.env.bot_webhook_ip:
-        payload['ip_address'] = models.env.bot_webhook_ip.__str__()
+        payload["ip_address"] = models.env.bot_webhook_ip.__str__()
     logger.debug(payload)
     if models.env.bot_certificate:
         response = requests.post(
-            url=put_info, data=payload,
-            files={'certificate': (models.env.bot_certificate.stem + models.env.bot_certificate.suffix,
-                                   models.env.bot_certificate.certificate.open(mode="rb"))}
+            url=put_info,
+            data=payload,
+            files={
+                "certificate": (
+                    models.env.bot_certificate.stem + models.env.bot_certificate.suffix,
+                    models.env.bot_certificate.certificate.open(mode="rb"),
+                )
+            },
         )
     else:
         response = requests.post(url=put_info, params=payload)
     if response.ok:
         logger.info("Webhook has been set to: %s", webhook)
         return response.json()
     else:
```

## jarvis/modules/templates/robinhood.html

```diff
@@ -1,24 +1,25 @@
 <!DOCTYPE html>
 <html lang="en">
   <head>
     <title>Robinhood Portfolio</title>
     <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
     <meta http-equiv="Pragma" content="no-cache">
     <meta http-equiv="Expires" content="0">
-    <!-- Disables 404 for favicon.ico which is a logo on top of the webpage tab -->
-    <link rel="shortcut icon" href="#">
+    <!-- Favicon.ico and Apple Touch Icon -->
+    <link rel="icon" href="https://thevickypedia.github.io/open-source/images/logo/robinhood.ico">
+    <link rel="apple-touch-icon" href="https://thevickypedia.github.io/open-source/images/logo/robinhood.png">
     <!-- jQuery CDN - Google -->
     <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
     <!-- jQuery CDN - Microsoft -->
     <script src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.2.1.min.js"></script>
     <!-- CSS and JS for night mode -->
     <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.2/jquery.min.js"></script>
-    <script type="text/javascript" src="https://rawgit.com/thevickypedia/open-source/main/nightmode/night.js" defer></script>
-    <link rel="stylesheet" href="https://rawgit.com/thevickypedia/open-source/main/nightmode/night.css">
+    <script type="text/javascript" src="https://thevickypedia.github.io/open-source/nightmode/night.js" defer></script>
+    <link rel="stylesheet" type="text/css" href="https://thevickypedia.github.io/open-source/nightmode/night.css">
   </head>
   <style>
     body {
       font-family: 'PT Serif', serif;
     }
     .tab {
       margin-left: 40px;
```

## jarvis/modules/templates/surveillance.html

```diff
@@ -1,16 +1,17 @@
 <!DOCTYPE html>
 <html>
 <head>
     <title>WebCam - LiveView</title>
         <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
         <meta http-equiv="Pragma" content="no-cache">
         <meta http-equiv="Expires" content="0">
-        <!-- Disables 404 for favicon.ico which is a logo on top of the webpage tab -->
-        <link rel="shortcut icon" href="#">
+        <!-- Favicon.ico and Apple Touch Icon -->
+        <link rel="icon" href="https://thevickypedia.github.io/open-source/images/logo/fastapi.ico">
+        <link rel="apple-touch-icon" href="https://thevickypedia.github.io/open-source/images/logo/fastapi.png">
         <!-- jQuery CDN - Google -->
         <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
         <!-- jQuery CDN - Microsoft -->
         <script src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.2.1.min.js"></script>
 </head>
 <body onload="sendMessage()">
 <div class="container">
```

## jarvis/modules/templates/templates.py

```diff
@@ -13,60 +13,70 @@
 class EmailTemplates:
     """HTML templates used to send outbound email.
 
     >>> EmailTemplates
 
     """
 
-    if models.settings.invoker != 'sphinx-build':
-        with open(os.path.join(os.path.dirname(__file__), 'email_threat_audio.html')) as file:
+    if models.settings.invoker != "sphinx-build":
+        with open(
+            os.path.join(os.path.dirname(__file__), "email_threat_audio.html")
+        ) as file:
             threat_audio = file.read()
 
-        with open(os.path.join(os.path.dirname(__file__), 'email_threat_image.html')) as file:
+        with open(
+            os.path.join(os.path.dirname(__file__), "email_threat_image.html")
+        ) as file:
             threat_image = file.read()
 
-        with open(os.path.join(os.path.dirname(__file__), 'email_threat_image_audio.html')) as file:
+        with open(
+            os.path.join(os.path.dirname(__file__), "email_threat_image_audio.html")
+        ) as file:
             threat_image_audio = file.read()
 
-        with open(os.path.join(os.path.dirname(__file__), 'email_stock_alert.html')) as file:
+        with open(
+            os.path.join(os.path.dirname(__file__), "email_stock_alert.html")
+        ) as file:
             stock_alert = file.read()
 
-        with open(os.path.join(os.path.dirname(__file__), 'email_OTP.html')) as file:
+        with open(os.path.join(os.path.dirname(__file__), "email_OTP.html")) as file:
             one_time_passcode = file.read()
 
-        with open(os.path.join(os.path.dirname(__file__), 'email.html')) as file:
+        with open(os.path.join(os.path.dirname(__file__), "email.html")) as file:
             notification = file.read()
 
-        with open(os.path.join(os.path.dirname(__file__), 'car_report.html')) as file:
+        with open(os.path.join(os.path.dirname(__file__), "car_report.html")) as file:
             car_report = file.read()
 
 
 class EndpointTemplates:
     """HTML templates used for hosting endpoints.
 
     >>> EndpointTemplates
 
     """
 
-    if models.settings.invoker != 'sphinx-build':
-        with open(os.path.join(os.path.dirname(__file__), 'robinhood.html')) as file:
+    if models.settings.invoker != "sphinx-build":
+        with open(os.path.join(os.path.dirname(__file__), "robinhood.html")) as file:
             robinhood = file.read()
 
-        with open(os.path.join(os.path.dirname(__file__), 'surveillance.html')) as file:
+        with open(os.path.join(os.path.dirname(__file__), "surveillance.html")) as file:
             surveillance = file.read()
 
 
 class GenericTemplates:
     """HTML templates used for generic purposes.
 
     >>> GenericTemplates
 
     """
 
-    if models.settings.invoker != 'sphinx-build':
-        with open(os.path.join(os.path.dirname(__file__), 'win_wifi_config.xml')) as file:
+    if models.settings.invoker != "sphinx-build":
+        with open(
+            os.path.join(os.path.dirname(__file__), "win_wifi_config.xml")
+        ) as file:
             win_wifi_xml = file.read()
 
 
 email = EmailTemplates
 generic = GenericTemplates
 endpoint = EndpointTemplates
```

## jarvis/modules/timeout/timeout.py

```diff
@@ -4,45 +4,62 @@
 >>> Timeout
 
 """
 
 import multiprocessing
 import time
 from logging import Logger
-from typing import Callable, Dict, List, Tuple, Union
+from typing import Callable, Dict, List, Tuple
 
 from pydantic import PositiveFloat, PositiveInt
 
 
-def timeout(seconds: Union[PositiveInt, PositiveFloat], function: Callable,
-            args: Union[List, Tuple] = None, kwargs: Dict = None, logger: Logger = None) -> bool:
+def timeout(
+    seconds: PositiveInt | PositiveFloat,
+    function: Callable,
+    args: List | Tuple = None,
+    kwargs: Dict = None,
+    logger: Logger = None,
+) -> bool:
     """Run the given function and kill it if exceeds the set timeout.
 
     Args:
         seconds: Timeout after which the said function has to be terminated.
         function: Function to run and timeout.
         args: Args to be passed to the function.
         kwargs: Keyword args to be passed to the function.
         logger: Logger to optionally log the timeout events.
 
     Returns:
         bool:
         Boolean flag to indicate if the function completed within the set timeout.
     """
-    process = multiprocessing.Process(target=function, args=args or [], kwargs=kwargs or {})
+    process = multiprocessing.Process(
+        target=function, args=args or [], kwargs=kwargs or {}
+    )
     _start = time.time()
     if logger:
-        logger.info("Starting %s at %s with timeout: %s" %
-                    (function.__name__, time.strftime('%H:%M:%S', time.localtime(_start)), seconds))
+        logger.info(
+            "Starting %s at %s with timeout: %s"
+            % (
+                function.__name__,
+                time.strftime("%H:%M:%S", time.localtime(_start)),
+                seconds,
+            )
+        )
     process.start()
     process.join(timeout=seconds)
     exec_time = round(float(time.time() - _start), 2)
-    logger.info("Joined process %d after %d seconds.", process.pid, exec_time) if logger else None
+    logger.info(
+        "Joined process %d after %d seconds.", process.pid, exec_time
+    ) if logger else None
     if process.is_alive():
-        logger.warning("Process %d is still alive. Terminating.", process.pid) if logger else None
+        logger.warning(
+            "Process %d is still alive. Terminating.", process.pid
+        ) if logger else None
         process.terminate()
         process.join(timeout=1e-01)
         try:
             logger.info("Closing process: %d", process.pid) if logger else None
             process.close()  # Close immediately instead of waiting to be garbage collected
         except ValueError as error:
             # Expected when join timeout is insufficient. The resources will be released eventually but not immediately.
```

## jarvis/modules/transformer/gpt.py

```diff
@@ -1,14 +1,14 @@
 import collections
 import difflib
-from multiprocessing.context import \
-    TimeoutError as ThreadTimeoutError  # noqa: PyProtectedMember
+
+# noinspection PyProtectedMember
+from multiprocessing.context import TimeoutError as ThreadTimeoutError
 from multiprocessing.pool import ThreadPool
 from threading import Thread
-from typing import Union
 
 import openai
 from openai.error import AuthenticationError, OpenAIError
 from openai.openai_object import OpenAIObject
 
 from jarvis.executors import files, static_responses
 from jarvis.modules.audio import speaker
@@ -21,19 +21,19 @@
     """Dump responses from GPT to a yaml file for future response.
 
     Args:
         request: Request from user.
         response: Response from GPT.
     """
     data = files.get_gpt_data()
-    data.append({'request': request, 'response': response})
+    data.append({"request": request, "response": response})
     files.put_gpt_data(data)
 
 
-def existing_response(request: str) -> Union[str, None]:
+def existing_response(request: str) -> str | None:
     """Return existing response if new request closely matches historical requests.
 
     Args:
         request: Request from user.
 
     See Also:
         - Reusing responses is not enabled by default.
@@ -50,43 +50,57 @@
 
     Returns:
         str:
         Returns the closest matching response stored in historical transactions.
     """
     # exclude if numbers present in new request
     if any(word.isdigit() for word in request):
-        logger.debug("request: '%s' contains numbers in it, so skipping existing search", request)
+        logger.debug(
+            "request: '%s' contains numbers in it, so skipping existing search", request
+        )
         return
     if not (data := files.get_gpt_data()):
         logger.debug("GPT history is empty")
         return
 
     # unpack data and store the request: response, match ratio in a new dict
     new_req = request.lower()
     ratios = {}
     for d in data:
-        ex_req = d['request'].lower()
+        ex_req = d["request"].lower()
         if ex_req == new_req:
-            logger.info("Identical historical request: '%s'", d['request'])
-            return d['response']
-        ratios[d['request']] = (d['response'], difflib.SequenceMatcher(a=ex_req, b=new_req).ratio())
+            logger.info("Identical historical request: '%s'", d["request"])
+            return d["response"]
+        ratios[d["request"]] = (
+            d["response"],
+            difflib.SequenceMatcher(a=ex_req, b=new_req).ratio(),
+        )
 
     # no identical requests found in history, and reuse threshold was not set
     if not models.env.openai_reuse_threshold:
-        logger.warning("No identical requests found in history, and reuse threshold was not set.")
+        logger.warning(
+            "No identical requests found in history, and reuse threshold was not set."
+        )
         return
 
     # sort the new dict in reverse order so the closest match gets returned first
-    ratios = collections.OrderedDict(sorted(ratios.items(), key=lambda kv: kv[1][1], reverse=True))
+    ratios = collections.OrderedDict(
+        sorted(ratios.items(), key=lambda kv: kv[1][1], reverse=True)
+    )
 
     # iterate over the ordered dict to look for numbers in existing requests and ignore them
     for existing_request, response_ratio in ratios.items():
-        if response_ratio[1] >= models.env.openai_reuse_threshold and \
-                not any(word.isdigit() for word in existing_request):
-            logger.info("Closest historical request [%s]: '%s'", response_ratio[1], existing_request)
+        if response_ratio[1] >= models.env.openai_reuse_threshold and not any(
+            word.isdigit() for word in existing_request
+        ):
+            logger.info(
+                "Closest historical request [%s]: '%s'",
+                response_ratio[1],
+                existing_request,
+            )
             return response_ratio[0]
 
 
 class ChatGPT:
     """Wrapper for OpenAI's ChatGPT API.
 
     >>> ChatGPT
@@ -105,26 +119,30 @@
     def authenticate(self) -> None:
         """Initiates authentication and prepares GPT responses ready to be audio fed."""
         if models.env.openai_api:
             openai.api_key = models.env.openai_api
         else:
             logger.warning("'openai_api' wasn't found to proceed")
             return
-        self.MESSAGES.append({
-            "role": "system",
-            "content": "All your response will be audio fed, "
-                       "so keep your replies within 1 to 2 sentences without any parenthesis."
-        })
+        self.MESSAGES.append(
+            {
+                "role": "system",
+                "content": "All your response will be audio fed, "
+                "so keep your replies within 1 to 2 sentences without any parenthesis.",
+            }
+        )
         try:
             chat: OpenAIObject = openai.ChatCompletion.create(
                 messages=self.MESSAGES,
                 model=models.env.openai_model,
-                timeout=models.env.openai_timeout
+                timeout=models.env.openai_timeout,
+            )
+            self.MESSAGES.append(
+                {"role": "system", "content": chat.choices[0].message.content}
             )
-            self.MESSAGES.append({"role": "system", "content": chat.choices[0].message.content})
             self.authenticated = True
         except AuthenticationError as error:
             logger.error(error)
         except OpenAIError as error:
             logger.critical(error)
 
     def query(self, phrase: str) -> None:
@@ -143,15 +161,15 @@
         self.MESSAGES.append(
             {"role": "user", "content": phrase},
         )
         try:
             chat: OpenAIObject = openai.ChatCompletion.create(
                 messages=self.MESSAGES,
                 model=models.env.openai_model,
-                timeout=models.env.openai_timeout
+                timeout=models.env.openai_timeout,
             )
         except OpenAIError as error:
             logger.error(error)
             static_responses.un_processable()
             return
         if chat.choices:
             reply = chat.choices[0].message.content
@@ -160,18 +178,21 @@
             speaker.speak(text=reply)
         else:
             logger.error(chat)
             static_responses.un_processable()
 
 
 # WATCH OUT: for changes in function name
-if models.settings.pname in ('JARVIS', 'telegram_api', 'jarvis_api'):
+if models.settings.pname in ("JARVIS", "telegram_api", "jarvis_api"):
     if models.env.openai_reuse_threshold:
-        logger.info("Initiating GPT instance for '%s' with a reuse threshold of '%.2f'",
-                    models.settings.pname, models.env.openai_reuse_threshold)
+        logger.info(
+            "Initiating GPT instance for '%s' with a reuse threshold of '%.2f'",
+            models.settings.pname,
+            models.env.openai_reuse_threshold,
+        )
     else:
         logger.info("Initiating GPT instance for '%s'", models.settings.pname)
     try:
         # because, openai built-in timeout doesn't really timeout when failed to initiate
         instance = ThreadPool(processes=1).apply_async(func=ChatGPT)
         instance = instance.get(timeout=10)
         logger.info("GPT instance has been loaded for '%s'", models.settings.pname)
```

## jarvis/modules/tv/lg.py

```diff
@@ -7,16 +7,21 @@
 
 import socket
 import time
 from collections.abc import Generator
 from typing import List
 
 from pywebostv.connection import WebOSClient
-from pywebostv.controls import (ApplicationControl, AudioOutputSource,
-                                MediaControl, SourceControl, SystemControl)
+from pywebostv.controls import (
+    ApplicationControl,
+    AudioOutputSource,
+    MediaControl,
+    SourceControl,
+    SystemControl,
+)
 
 from jarvis.executors import files
 from jarvis.modules.audio import speaker
 from jarvis.modules.exceptions import TVError
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.utils import shared, support
@@ -44,25 +49,28 @@
 
         Raises:
             TVError:
             - If unable to connect to the TV.
             - If no TV was found in the IP range.
             - If a connection timeout occurs (usually because of unstable internet or multiple connection types)
         """
-        store = {'client_key': client_key} if client_key else {}
+        store = {"client_key": client_key} if client_key else {}
 
         try:
             self.client = WebOSClient(ip_address)
             self.client.connect()
         except (socket.gaierror, ConnectionRefusedError) as error:
             logger.error(error)
             self._reconnect = True
             if not shared.called_by_offline:
-                speaker.speak(f"The TV's IP has either changed or unreachable {models.env.title}! "
-                              "Scanning your IP range now.", run=True)
+                speaker.speak(
+                    f"The TV's IP has either changed or unreachable {models.env.title}! "
+                    "Scanning your IP range now.",
+                    run=True,
+                )
             if discovered := WebOSClient.discover():
                 self.client = discovered[0]
                 try:
                     self.client.connect()
                 except (TimeoutError, BrokenPipeError) as error:
                     logger.error(error)
                     raise TVError
@@ -70,63 +78,82 @@
                 raise TVError
         except (TimeoutError, BrokenPipeError) as error:
             logger.error(error)
             raise TVError
 
         for status in self.client.register(store):
             if status == WebOSClient.REGISTERED and not self._init_status:
-                support.write_screen(text='Connected to the TV.')
+                support.write_screen(text="Connected to the TV.")
                 break
             elif status == WebOSClient.PROMPTED:
                 if shared.called_by_offline:
                     logger.info("Connection request sent to '%s'", nickname)
                 else:
-                    speaker.speak(text=f"Please accept the connection request on your TV {models.env.title}!", run=True)
+                    speaker.speak(
+                        text=f"Please accept the connection request on your TV {models.env.title}!",
+                        run=True,
+                    )
                 self._reconnect = True
-                support.write_screen(text='Please accept the connection request on your TV.')
+                support.write_screen(
+                    text="Please accept the connection request on your TV."
+                )
 
         if self._reconnect:
             self._reconnect = False
-            if (smart_devices := files.get_smart_devices()) and store.get('client_key'):
-                smart_devices[key][nickname]['client_key'] = store['client_key']
+            if (smart_devices := files.get_smart_devices()) and store.get("client_key"):
+                smart_devices[key][nickname]["client_key"] = store["client_key"]
                 files.put_smart_devices(data=smart_devices)
-                logger.info("Client key '%s' has been stored in '%s'", store['client_key'], models.fileio.smart_devices)
+                logger.info(
+                    "Client key '%s' has been stored in '%s'",
+                    store["client_key"],
+                    models.fileio.smart_devices,
+                )
             else:
-                logger.critical("ATTENTION::Client key has been generated. Store it in '%s' to re-use." %
-                                models.fileio.smart_devices)
+                logger.critical(
+                    "ATTENTION::Client key has been generated. Store it in '%s' to re-use."
+                    % models.fileio.smart_devices
+                )
                 logger.critical(str(store))
 
         self.system = SystemControl(self.client)
-        self.system.notify("Jarvis is controlling the TV now.") if not self._init_status else None
+        self.system.notify(
+            "Jarvis is controlling the TV now."
+        ) if not self._init_status else None
         self.media = MediaControl(self.client)
         self.app = ApplicationControl(self.client)
         self.source_control = SourceControl(self.client)
         self._init_status = True
 
     def increase_volume(self) -> None:
         """Increases the volume by ``10`` units."""
         for _ in range(10):
             self.media.volume_up()
-        self.system.notify(f"Jarvis::Increased Volume: {self.media.get_volume()['volume']}%")
+        self.system.notify(
+            f"Jarvis::Increased Volume: {self.media.get_volume()['volume']}%"
+        )
 
     def decrease_volume(self) -> None:
         """Decreases the volume by ``10`` units."""
         for _ in range(10):
             self.media.volume_down()
-        self.system.notify(f"Jarvis::Decreased Volume: {self.media.get_volume()['volume']}%")
+        self.system.notify(
+            f"Jarvis::Decreased Volume: {self.media.get_volume()['volume']}%"
+        )
 
     def get_volume(self) -> int:
         """Get volume status.
 
         Returns:
             int:
             Volume level.
         """
-        self.system.notify(f"Jarvis::Current Volume: {self.media.get_volume()['volume']}%")
-        return self.media.get_volume()['volume']
+        self.system.notify(
+            f"Jarvis::Current Volume: {self.media.get_volume()['volume']}%"
+        )
+        return self.media.get_volume()["volume"]
 
     def get_state(self) -> bool:
         """Get current state of the TV.
 
         Notes:
             Since LGWebOS module doesn't have a status call, get the current volume to check if TV is powered on.
 
@@ -139,15 +166,17 @@
 
     def set_volume(self, target: int) -> None:
         """The argument is an integer from 1 to 100.
 
         Args:
             target: Takes an integer as argument to set the volume.
         """
-        self.system.notify(f"Jarvis::Volume has been set to: {self.media.get_volume()['volume']}%")
+        self.system.notify(
+            f"Jarvis::Volume has been set to: {self.media.get_volume()['volume']}%"
+        )
         self.media.set_volume(target)
 
     def mute(self) -> None:
         """Mutes the TV."""
         self.system.notify("Jarvis::Muted")
         self.media.mute(True)
 
@@ -188,15 +217,17 @@
 
     def launch_app(self, app_name: str) -> None:
         """Launches an application.
 
         Args:
             app_name: Takes the application name as argument.
         """
-        app_launcher = [x for x in self.app.list_apps() if app_name.lower() in x["title"].lower()][0]
+        app_launcher = [
+            x for x in self.app.list_apps() if app_name.lower() in x["title"].lower()
+        ][0]
         self.app.launch(app_launcher, content_id=None)
 
     def close_app(self, app_name: str) -> None:
         """Closes a particular app using the launch_info received from launch_app method.
 
         Args:
             app_name: Application name that has to be closed.
@@ -207,15 +238,15 @@
         """Checks for the input sources on the TV.
 
         Yields:
             str:
             Yields ``InputSource`` instance.
         """
         for source in self.source_control.list_sources():
-            yield source['label']
+            yield source["label"]
 
     def set_source(self, val: str) -> None:
         """Sets an ``InputSource`` instance.
 
         Args:
             val: Takes the input source instance value as argument.
         """
@@ -227,15 +258,15 @@
         """Scans the current application running in foreground.
 
         Returns:
             str:
             Title of the current app that is running
         """
         app_id = self.app.get_current()
-        return [x for x in self.app.list_apps() if app_id == x["id"]][0]['title']
+        return [x for x in self.app.list_apps() if app_id == x["id"]][0]["title"]
 
     def audio_output(self) -> AudioOutputSource:
         """Returns the currently used audio output source as AudioOutputSource instance.
 
         Returns:
             AudioOutputSource:
             Returns the audio output source as an object.
@@ -254,13 +285,13 @@
     def set_audio_output_source(self) -> None:
         """Sets to a particular AudioOutputSource instance."""
         self.media.set_audio_output(self.audio_output_source[0])  # noqa
 
     def shutdown(self) -> None:
         """Notifies the TV about shutdown and shuts down after 3 seconds."""
         try:
-            self.system.notify('Jarvis::SHUTTING DOWN now')
+            self.system.notify("Jarvis::SHUTTING DOWN now")
         except AttributeError as error:  # Happens when TV is already powered off
             logger.error(error)
             return
         time.sleep(3)
         self.system.power_off()
```

## jarvis/modules/tv/roku.py

```diff
@@ -4,15 +4,15 @@
 >>> Roku
 
 """
 
 import socket
 from collections.abc import Generator
 from threading import Thread
-from typing import Dict, Union
+from typing import Dict
 from xml.etree import ElementTree
 
 import requests
 
 from jarvis.modules.exceptions import EgressErrors, TVError
 from jarvis.modules.logger import logger
 
@@ -31,27 +31,27 @@
 
     def __init__(self, ip_address: str):
         """Instantiates the roku tv and makes a test call.
 
         Args:
             ip_address: IP address of the TV.
         """
-        self.BASE_URL = f'http://{ip_address}:{self.PORT}'
+        self.BASE_URL = f"http://{ip_address}:{self.PORT}"
         try:
             response = requests.get(url=self.BASE_URL)
         except EgressErrors as error:
             logger.error(error)
             raise TVError
         if response.ok:
             try:
                 resolved = socket.gethostbyaddr(str(ip_address))
             except socket.error as error:
                 logger.error(error)
                 raise TVError
-            logger.info("Connected to '%s'", resolved[0].split('.')[0])
+            logger.info("Connected to '%s'", resolved[0].split(".")[0])
         else:
             logger.error("%d - %s", response.status_code, response.text)
             raise TVError
 
     def make_call(self, path: str, method: str) -> requests.Response:
         """Makes a session call using the path and method provided.
 
@@ -59,103 +59,103 @@
             path: URL path to make the call.
             method: Method using which the call has to be made.
 
         Returns:
             requests.Response:
             Response from the session call.
         """
-        if method == 'GET':
+        if method == "GET":
             return self.SESSION.get(url=self.BASE_URL + path)
-        if method == 'POST':
+        if method == "POST":
             return self.SESSION.post(url=self.BASE_URL + path)
 
     def get_state(self) -> bool:
         """Gets the TV state to determine whether it is powered on or off.
 
         Returns:
             bool:
             True if powered on.
         """
-        response = self.make_call(path='/query/device-info', method='GET')
+        response = self.make_call(path="/query/device-info", method="GET")
         xml_parsed = ElementTree.fromstring(response.content)
-        if xml_parsed.find('power-mode').text:
-            return xml_parsed.find('power-mode').text == 'PowerOn'
+        if xml_parsed.find("power-mode").text:
+            return xml_parsed.find("power-mode").text == "PowerOn"
 
     def startup(self) -> None:
         """Powers on the TV and launches Home screen."""
-        self.make_call(path='/keypress/PowerOn', method='POST')
-        self.make_call(path='/keypress/Home', method='POST')
+        self.make_call(path="/keypress/PowerOn", method="POST")
+        self.make_call(path="/keypress/Home", method="POST")
 
     def shutdown(self) -> None:
         """Turns off the TV is it is powered on."""
         if self.get_state():
-            self.make_call(path='/keypress/PowerOff', method='POST')
+            self.make_call(path="/keypress/PowerOff", method="POST")
 
     def increase_volume(self, limit: int = 10) -> None:
         """Increases the volume on the TV.
 
         Args:
             limit: Number of iterations to increase the volume.
         """
         # RokuTVs perform in 2-step iterations for volume, so a single VolumeUp button increases the volume by 2%
         for _ in range(int(limit / 2)):
-            self.make_call(path='/keypress/VolumeUp', method='POST')
+            self.make_call(path="/keypress/VolumeUp", method="POST")
 
     def decrease_volume(self, limit: int = 10) -> None:
         """Decreases the volume on the TV.
 
         Args:
             limit: Number of iterations to decrease the volume.
         """
         # RokuTVs perform in 2-step iterations for volume, so a single VolumeDown button decreases the volume by 2%
         for _ in range(int(limit / 2)):
-            self.make_call(path='/keypress/VolumeDown', method='POST')
+            self.make_call(path="/keypress/VolumeDown", method="POST")
 
     def mute(self) -> None:
         """Mutes the TV."""
-        self.make_call(path='/keypress/VolumeMute', method='POST')
+        self.make_call(path="/keypress/VolumeMute", method="POST")
 
     def stop(self) -> None:
         """Sends a keypress to stop content on TV."""
-        self.make_call(path='/keypress/Stop', method='POST')
+        self.make_call(path="/keypress/Stop", method="POST")
 
     def pause(self) -> None:
         """Sends a keypress to pause content on TV."""
-        self.make_call(path='/keypress/Pause', method='POST')
+        self.make_call(path="/keypress/Pause", method="POST")
 
     def play(self) -> None:
         """Sends a keypress to play content on TV."""
-        self.make_call(path='/keypress/Play', method='POST')
+        self.make_call(path="/keypress/Play", method="POST")
 
     def forward(self) -> None:
         """Sends a keypress to forward content on TV."""
-        self.make_call(path='/keypress/Fwd', method='POST')
+        self.make_call(path="/keypress/Fwd", method="POST")
 
     def rewind(self) -> None:
         """Sends a keypress to rewind content on TV."""
-        self.make_call(path='/keypress/Rev', method='POST')
+        self.make_call(path="/keypress/Rev", method="POST")
 
     def get_sources(self) -> Generator[str]:
         """Returns a list of predetermined sources.
 
         Yields:
             str:
             Yields preset source's name.
         """
         for app in self.get_apps(raw=True):
-            if app['id'].startswith('tvinput'):
-                yield app['name']
+            if app["id"].startswith("tvinput"):
+                yield app["name"]
 
     def set_source(self, val: str) -> None:
         """Set input source on TV.
 
         Args:
             val: Source name.
         """
-        self.make_call(path=f'/keypress/{val}', method='POST')
+        self.make_call(path=f"/keypress/{val}", method="POST")
 
     def _set_vol_executor(self, target: int) -> None:
         """Executed in thread to set volume to a specific level.
 
         With the lack of a better option, volume is decreased to zero and then increased to the required level.
 
         Args:
@@ -168,62 +168,76 @@
         """Initiates threaded volume setter.
 
         Args:
             target: Volume in percentage.
         """
         Thread(target=self._set_vol_executor, args=(target,)).start()
 
-    def current_app(self) -> Union[str, None]:
+    def current_app(self) -> str | None:
         """Find current app running on the TV.
 
         Returns:
             str:
             Name of the application.
         """
-        response = self.make_call(path='/query/active-app', method='GET')
+        response = self.make_call(path="/query/active-app", method="GET")
         xml_parsed = ElementTree.fromstring(response.content)
-        app_info = xml_parsed.find('screensaver')
+        app_info = xml_parsed.find("screensaver")
         if app_info is None:
-            app_info = xml_parsed.find('app')
+            app_info = xml_parsed.find("app")
         if app_info is None:
             return
-        logger.debug(dict(id=app_info.get('id'), version=app_info.get('version'), name=app_info.text))
+        logger.debug(
+            dict(
+                id=app_info.get("id"),
+                version=app_info.get("version"),
+                name=app_info.text,
+            )
+        )
         return app_info.text
 
     @staticmethod
     def get_volume() -> str:
         """Placeholder method as there is no call to get this information at the time of development."""
-        return 'unknown'
+        return "unknown"
 
     def launch_app(self, app_name: str) -> None:
         """Launches an application on the TV.
 
         Args:
             app_name: Name of the application to launch.
         """
-        app_id = next((item for item in self.get_apps(raw=True)
-                       if item['name'].lower() == app_name.lower()), {}).get('id')
+        app_id = next(
+            (
+                item
+                for item in self.get_apps(raw=True)
+                if item["name"].lower() == app_name.lower()
+            ),
+            {},
+        ).get("id")
         if app_id:
-            response = self.make_call(path=f'/launch/{app_id}', method='POST')
+            response = self.make_call(path=f"/launch/{app_id}", method="POST")
             if not response.ok:
                 logger.error("%d: %s", response.status_code, response.text)
         else:
             logger.error("%s not found in tv", app_name)
 
-    def get_apps(self, raw: bool = False) -> Union[Generator[Dict[str, str]], Generator[str]]:
+    def get_apps(self, raw: bool = False) -> Generator[Dict[str, str]] | Generator[str]:
         """Get list of applications installed on the TV.
 
         Args:
             raw: Takes a boolean flag if the entire dictionary has to be returned.
 
         Yields:
-            Union[Dict[str, str], str]:
+            Generator[Dict[str, str]] | Generator[str]:
             Yields of app name or information dict if requested as raw.
         """
-        response = self.make_call(path='/query/apps', method='GET')
+        response = self.make_call(path="/query/apps", method="GET")
         xml_parsed = ElementTree.fromstring(response.content)
         if raw:
             for node in xml_parsed:
-                yield dict(id=node.get('id'), version=node.get('version'), name=node.text)
+                yield dict(
+                    id=node.get("id"), version=node.get("version"), name=node.text
+                )
         else:
             for node in xml_parsed:
                 yield node.text
```

## jarvis/modules/utils/shared.py

```diff
@@ -16,11 +16,11 @@
 offline_caller = None
 tv = {}
 
 processes = {}
 hosted_device = {}
 
 called = {
-    'report': False,
-    'locate_places': False,
-    'directions': False,
+    "report": False,
+    "locate_places": False,
+    "directions": False,
 }
```

## jarvis/modules/utils/support.py

```diff
@@ -8,15 +8,15 @@
 import os
 import socket
 import string
 import sys
 import time
 from datetime import datetime, timedelta, timezone
 from http.client import HTTPSConnection
-from typing import Any, Dict, Iterable, List, Tuple, Union
+from typing import Any, Dict, Iterable, List, Tuple
 
 import dateutil.tz
 import inflect
 import psutil
 import pytz
 import yaml
 from dateutil import parser, relativedelta
@@ -27,15 +27,23 @@
 from jarvis.modules.database import database
 from jarvis.modules.logger import logger
 from jarvis.modules.models import models
 from jarvis.modules.utils import shared
 
 ENGINE = inflect.engine()
 
-days_in_week = ("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")
+days_in_week = (
+    "Monday",
+    "Tuesday",
+    "Wednesday",
+    "Thursday",
+    "Friday",
+    "Saturday",
+    "Sunday",
+)
 db = database.Database(database=models.fileio.base_db)
 
 
 def hostname_to_ip(hostname: str, localhost: bool = True) -> List[str]:
     """Uses ``socket.gethostbyname_ex`` to translate a host name to IPv4 address format, extended interface.
 
     See Also:
@@ -56,28 +64,37 @@
         localhost: Takes a boolean value to behave differently in case of localhost.
     """
     try:
         _hostname, _alias_list, _ipaddr_list = socket.gethostbyname_ex(hostname)
     except socket.error as error:
         logger.error("%s [%d] on %s", error.strerror, error.errno, hostname)
         return []
-    logger.debug({"Hostname": _hostname, "Alias": _alias_list, "Interfaces": _ipaddr_list})
+    logger.debug(
+        {"Hostname": _hostname, "Alias": _alias_list, "Interfaces": _ipaddr_list}
+    )
     if not _ipaddr_list:
         logger.critical("ATTENTION::No interfaces found for %s", hostname)
     elif len(_ipaddr_list) > 1:
-        logger.warning("Host %s has multiple interfaces. %s", hostname, _ipaddr_list) if localhost else None
+        logger.warning(
+            "Host %s has multiple interfaces. %s", hostname, _ipaddr_list
+        ) if localhost else None
         return _ipaddr_list
     else:
         if localhost:
             ip_addr = internet.ip_address()
-            if _ipaddr_list[0].split('.')[0] == ip_addr.split('.')[0]:
+            if _ipaddr_list[0].split(".")[0] == ip_addr.split(".")[0]:
                 return _ipaddr_list
             else:
-                logger.error("NetworkID of the InterfaceIP [%s] of host '%s' does not match the network id of the "
-                             "DeviceIP [%s].", ip_addr, hostname, ', '.join(_ipaddr_list))
+                logger.error(
+                    "NetworkID of the InterfaceIP [%s] of host '%s' does not match the network id of the "
+                    "DeviceIP [%s].",
+                    ip_addr,
+                    hostname,
+                    ", ".join(_ipaddr_list),
+                )
                 return []
         else:
             return _ipaddr_list
 
 
 def country_timezone() -> Dict[str, str]:
     """Returns a mapping of timezone and the country where the timezone belongs."""
@@ -85,31 +102,34 @@
     for countrycode in pytz.country_timezones:
         timezones = pytz.country_timezones[countrycode]
         for timezone_ in timezones:
             timezone_country[timezone_] = countrycode
     return timezone_country
 
 
-def get_capitalized(phrase: str, ignore: Iterable = None, dot: bool = True) -> Union[str, None]:
+def get_capitalized(
+    phrase: str, ignore: Iterable = None, dot: bool = True
+) -> str | None:
     """Looks for words starting with an upper-case letter.
 
     Args:
         phrase: Takes input string as an argument.
         ignore: Takes an iterable of upper case strings to be ignored.
         dot: Takes a boolean flag whether to include words separated by (.) dot.
 
     Returns:
         str:
         Returns the upper case words if skimmed.
     """
     # Set ignore as a tuple with avoid keywords regardless of current state
-    ignore = tuple(ignore or ()) + tuple(keywords.keywords['avoid'])
+    ignore = tuple(ignore or ()) + tuple(keywords.keywords["avoid"])
     place = ""
     for word in phrase.split():
-        if word[0].isupper() and word.lower() not in map(lambda x: x.lower(), ignore):  # convert iterable to lowercase
+        # convert iterable to lowercase
+        if word[0].isupper() and word.lower() not in map(lambda x: x.lower(), ignore):
             place += word + " "
         elif "." in word and dot:
             place += word + " "
     return place.strip() if place.strip() else None
 
 
 def unrecognized_dumper(train_data: dict) -> None:
@@ -124,33 +144,40 @@
         try:
             with open(models.fileio.training_data) as reader:
                 data = yaml.load(stream=reader, Loader=yaml.FullLoader) or {}
         except yaml.YAMLError as error:
             logger.error(error)
             os.rename(
                 src=models.fileio.training_data,
-                dst=str(models.fileio.training_data).replace(".", f"_{datetime.now().strftime('%m_%d_%Y_%H_%M')}.")
+                dst=str(models.fileio.training_data).replace(
+                    ".", f"_{datetime.now().strftime('%m_%d_%Y_%H_%M')}."
+                ),
             )
         for key, value in train_data.items():
             if data.get(key):
                 data[key].update({dt_string: value})
             else:
                 data.update({key: {dt_string: value}})
 
     if not data:
         data = {key1: {dt_string: value1} for key1, value1 in train_data.items()}
 
     data = {
         func: {
-            dt: unrec for dt, unrec in sorted(unrec_dict.items(), reverse=True,
-                                              key=lambda item: datetime.strptime(item[0], "%B %d, %Y %H:%M:%S.%f"))
-        } for func, unrec_dict in data.items()
+            dt: unrec
+            for dt, unrec in sorted(
+                unrec_dict.items(),
+                reverse=True,
+                key=lambda item: datetime.strptime(item[0], "%B %d, %Y %H:%M:%S.%f"),
+            )
+        }
+        for func, unrec_dict in data.items()
     }
 
-    with open(models.fileio.training_data, 'w') as writer:
+    with open(models.fileio.training_data, "w") as writer:
         yaml.dump(data=data, stream=writer, sort_keys=False)
 
 
 def size_converter(byte_size: int) -> str:
     """Gets the current memory consumed and converts it to human friendly format.
 
     Args:
@@ -188,16 +215,20 @@
     Args:
         utc_dt: Takes UTC datetime object as an argument
 
     Returns:
         datetime:
         Local datetime as an object.
     """
-    utc_dt = utc_dt.replace(tzinfo=timezone.utc)  # Tell datetime object that the tz is UTC
-    local_tz = dateutil.tz.gettz(datetime.now().astimezone().tzname())  # Get local timezone
+    utc_dt = utc_dt.replace(
+        tzinfo=timezone.utc
+    )  # Tell datetime object that the tz is UTC
+    local_tz = dateutil.tz.gettz(
+        datetime.now().astimezone().tzname()
+    )  # Get local timezone
     return utc_dt.astimezone(local_tz)  # Convert the UTC timestamp to local
 
 
 def build_lookup() -> List[str]:
     """Build an array and get the number of days ahead and before of a certain day to lookup.
 
     Returns:
@@ -206,15 +237,17 @@
     """
     day_str = datetime.today().strftime("%A")
     floating_days = [""] * 8
     for idx, day in enumerate(days_in_week):
         if day == day_str:
             floating_days[0] = day_str
             floating_days[7] = day_str
-            for i, j in zip(range(idx + 1, len(days_in_week)), range(1, len(days_in_week))):
+            for i, j in zip(
+                range(idx + 1, len(days_in_week)), range(1, len(days_in_week))
+            ):
                 floating_days[j] = days_in_week[i]
             for i in range(idx):
                 floating_days[7 - (idx - i)] = days_in_week[i]
     return floating_days
 
 
 def detect_lookup_date(phrase: str) -> Tuple[datetime, str]:
@@ -240,15 +273,15 @@
         datetime_obj = datetime.today() + timedelta(days=1)
         addon = "tomorrow"
     else:
         return humanized_day_to_datetime(phrase=phrase)
     return datetime_obj, addon
 
 
-def humanized_day_to_datetime(phrase: str) -> Union[Tuple[datetime, str], None]:
+def humanized_day_to_datetime(phrase: str) -> Tuple[datetime, str] | None:
     """Converts human date from general conversations into a datetime object.
 
     Args:
         phrase: Takes input string as an argument.
 
     See Also:
         - | Supports terms like ``day before yesterday``, ``yesterday``, ``tomorrow``, ``day after tomorrow``,
@@ -257,15 +290,16 @@
 
     Returns:
         Tuple[datetime, str]:
         Returns a tuple of the datetime object, the detected/supported humanized date.
     """
     floating_days = build_lookup()
     lookup_day = get_capitalized(phrase=phrase)
-    if not lookup_day or lookup_day not in days_in_week:  # basically, if lookup day is in lower case
+    # basically, if lookup day is in lower case
+    if not lookup_day or lookup_day not in days_in_week:
         if matched := word_match.word_match(phrase=phrase, match_list=days_in_week):
             lookup_day = string.capwords(matched)
     if not lookup_day or lookup_day not in days_in_week:
         logger.error("Received incorrect lookup day: %s", lookup_day)
         return
     if "last" in phrase.lower():
         td = timedelta(days=-(7 - floating_days.index(lookup_day)))
@@ -278,15 +312,17 @@
         addon = f"this {lookup_day}"
     else:
         logger.error("Supports only 'last', 'next' and 'this' but received %s", phrase)
         return
     return datetime.today() + td, addon
 
 
-def extract_humanized_date(phrase: str, fail_past: bool = False) -> Union[Tuple[datetime.date, str, str], None]:
+def extract_humanized_date(
+    phrase: str, fail_past: bool = False
+) -> Tuple[datetime.date, str, str] | None:
     """Converts most humanized date into datetime object.
 
     Args:
         phrase: Takes the phrase spoken as an argument.
         fail_past: Boolean value to raise an error in case the humanized datetime is in the past.
 
     Returns:
@@ -296,15 +332,19 @@
     today = datetime.now().date()
 
     if "day after tomorrow" in phrase:
         return today + relativedelta.relativedelta(days=2), "day after tomorrow", "is"
     elif "day before yesterday" in phrase:
         if fail_past:
             raise ValueError("'day before yesterday' is in the past!")
-        return today - relativedelta.relativedelta(days=2), "day before yesterday", "was"
+        return (
+            today - relativedelta.relativedelta(days=2),
+            "day before yesterday",
+            "was",
+        )
     elif "tomorrow" in phrase:
         return today + relativedelta.relativedelta(days=1), "tomorrow", "is"
     elif "yesterday" in phrase:
         if fail_past:
             raise ValueError("'yesterday' is in the past!")
         return today - relativedelta.relativedelta(days=1), "yesterday", "was"
 
@@ -312,28 +352,41 @@
         parsed_date = parser.parse(phrase, fuzzy=True)
     except parser.ParserError as error:
         logger.error(error)
         return today, "today", "is"
 
     if "next" in phrase:
         next_occurrence = parsed_date + relativedelta.relativedelta(weeks=1)
-        return next_occurrence.date(), f"next {next_occurrence.strftime('%A')}, ({next_occurrence.strftime('%B')} " \
-                                       f"{ENGINE.ordinal(next_occurrence.strftime('%d'))})", "is"
+        return (
+            next_occurrence.date(),
+            f"next {next_occurrence.strftime('%A')}, ({next_occurrence.strftime('%B')} "
+            f"{ENGINE.ordinal(next_occurrence.strftime('%d'))})",
+            "is",
+        )
     elif "last" in phrase:
         last_occurrence = parsed_date - relativedelta.relativedelta(weeks=1)
         if fail_past:
             raise ValueError(f"'last {last_occurrence.strftime('%A')}' is in the past!")
-        return last_occurrence.date(), f"last {last_occurrence.strftime('%A')}, ({last_occurrence.strftime('%B')} " \
-                                       f"{ENGINE.ordinal(last_occurrence.strftime('%d'))})", "was"
+        return (
+            last_occurrence.date(),
+            f"last {last_occurrence.strftime('%A')}, ({last_occurrence.strftime('%B')} "
+            f"{ENGINE.ordinal(last_occurrence.strftime('%d'))})",
+            "was",
+        )
 
-    if parsed_date.date() < today and fail_past:  # validates only the date, so the date might be same with a past-time
+    # validates only the date, so the date might be same with a past-time
+    if parsed_date.date() < today and fail_past:
         raise ValueError(f"{parsed_date!r} is in the past!")
 
-    return parsed_date.date(), f"{parsed_date.strftime('%A')}, ({parsed_date.strftime('%B')} " \
-                               f"{ENGINE.ordinal(parsed_date.strftime('%d'))})", "is"
+    return (
+        parsed_date.date(),
+        f"{parsed_date.strftime('%A')}, ({parsed_date.strftime('%B')} "
+        f"{ENGINE.ordinal(parsed_date.strftime('%d'))})",
+        "is",
+    )
 
 
 def check_stop() -> List[str]:
     """Checks for entries in the stopper table in base db.
 
     Returns:
         list:
@@ -358,15 +411,19 @@
     hour = datetime.now().strftime("%I")  # current hour
     day = datetime.now().strftime("%A")  # current day
 
     if am_pm == "AM" and int(hour) < 10:
         exit_msg = f"Have a nice day, and happy {day}."
     elif am_pm == "AM" and int(hour) >= 10:
         exit_msg = f"Enjoy your {day}."
-    elif am_pm == "PM" and (int(hour) == 12 or int(hour) < 3) and day in ["Friday", "Saturday"]:
+    elif (
+        am_pm == "PM"
+        and (int(hour) == 12 or int(hour) < 3)
+        and day in ["Friday", "Saturday"]
+    ):
         exit_msg = "Have a nice afternoon, and enjoy your weekend."
     elif am_pm == "PM" and (int(hour) == 12 or int(hour) < 3):
         exit_msg = "Have a nice afternoon."
     elif am_pm == "PM" and int(hour) < 6 and day in ["Friday", "Saturday"]:
         exit_msg = "Have a nice evening, and enjoy your weekend."
     elif am_pm == "PM" and int(hour) < 6:
         exit_msg = "Have a nice evening."
@@ -386,15 +443,17 @@
     logger.error("Called by: %s", sys._getframe(1).f_code.co_name)  # noqa
     speaker.speak(text=f"I'm sorry {models.env.title}! I lack the permissions!")
 
 
 def unsupported_features() -> None:
     """Says a message about unsupported features."""
     logger.error("Called by: %s", sys._getframe(1).f_code.co_name)  # noqa
-    speaker.speak(text=f"I'm sorry {models.env.title}! This feature is yet to be implemented on {models.settings.os}!")
+    speaker.speak(
+        text=f"I'm sorry {models.env.title}! This feature is yet to be implemented on {models.settings.os}!"
+    )
 
 
 def write_screen(text: Any) -> None:
     """Write text on screen that can be cleared later.
 
     Args:
         text: Text to be written.
@@ -407,35 +466,39 @@
 def flush_screen() -> None:
     """Flushes the screen output.
 
     See Also:
         Writes new set of empty strings for the size of the terminal if ran using one.
     """
     if models.settings.interactive:
-        sys.stdout.write(f"\r{' '.join(['' for _ in range(os.get_terminal_size().columns)])}")
+        sys.stdout.write(
+            f"\r{' '.join(['' for _ in range(os.get_terminal_size().columns)])}"
+        )
     else:
         sys.stdout.write("\r")
 
 
-def number_to_words(input_: Union[int, str], capitalize: bool = False) -> str:
+def number_to_words(input_: int | str, capitalize: bool = False) -> str:
     """Converts integer version of a number into words.
 
     Args:
         input_: Takes the integer version of a number as an argument.
         capitalize: Boolean flag to capitalize the first letter.
 
     Returns:
         str:
         String version of the number.
     """
     result = ENGINE.number_to_words(num=input_)
     return result[0].upper() + result[1:] if capitalize else result
 
 
-def pluralize(count: int, word: str, to_words: bool = False, cap_word: bool = False) -> str:
+def pluralize(
+    count: int, word: str, to_words: bool = False, cap_word: bool = False
+) -> str:
     """Helper for ``time_converter`` function.
 
     Args:
         count: Number based on which plural form should be determined.
         word: Word for which the plural form should be converted.
         to_words: Boolean flag to convert numeric to words in the response string.
         cap_word: If to_words is passed as True, then analyzes whether the first letter should be capitalized.
@@ -463,46 +526,52 @@
     second = round(second % (24 * 3600))
     hour = round(second // 3600)
     second %= 3600
     minute = round(second // 60)
     second %= 60
     pluralize.counter = -1
     if day and hour and minute and second:
-        return f"{pluralize(day, 'day')}, {pluralize(hour, 'hour')}, " \
-               f"{pluralize(minute, 'minute')}, and {pluralize(second, 'second')}"
+        return (
+            f"{pluralize(day, 'day')}, {pluralize(hour, 'hour')}, "
+            f"{pluralize(minute, 'minute')}, and {pluralize(second, 'second')}"
+        )
     elif day and hour and minute:
-        return f"{pluralize(day, 'day')}, {pluralize(hour, 'hour')}, " \
-               f"and {pluralize(minute, 'minute')}"
+        return (
+            f"{pluralize(day, 'day')}, {pluralize(hour, 'hour')}, "
+            f"and {pluralize(minute, 'minute')}"
+        )
     elif day and hour:
         return f"{pluralize(day, 'day')}, and {pluralize(hour, 'hour')}"
     elif day:
-        return pluralize(day, 'day')
+        return pluralize(day, "day")
     elif hour and minute and second:
         return f"{pluralize(hour, 'hour')}, {pluralize(minute, 'minute')}, and {pluralize(second, 'second')}"
     elif hour and minute:
         return f"{pluralize(hour, 'hour')}, and {pluralize(minute, 'minute')}"
     elif hour:
-        return pluralize(hour, 'hour')
+        return pluralize(hour, "hour")
     elif minute and second:
         return f"{pluralize(minute, 'minute')}, and {pluralize(second, 'second')}"
     elif minute:
-        return pluralize(minute, 'minute')
+        return pluralize(minute, "minute")
     else:
-        return pluralize(second, 'second')
+        return pluralize(second, "second")
 
 
 def remove_file(filepath: str, delay: int = 0) -> None:
     """Deletes the requested file after a certain time.
 
     Args:
         filepath: Filepath that has to be removed.
         delay: Delay in seconds after which the requested file is to be deleted.
     """
     time.sleep(delay)
-    os.remove(filepath) if os.path.isfile(filepath) else logger.error("%s not found.", filepath)
+    os.remove(filepath) if os.path.isfile(filepath) else logger.error(
+        "%s not found.", filepath
+    )
 
 
 def stop_process(pid: int) -> None:
     """Stop a particular process using ``SIGTERM`` and ``SIGKILL`` signals.
 
     Args:
         pid: Process ID that has to be shut down.
@@ -524,15 +593,17 @@
     Returns:
         bool:
         True if connection is active, False otherwise.
     """
     socket_ = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
     try:
         if models.settings.os == models.supported_platforms.windows:
-            connection = HTTPSConnection("8.8.8.8", timeout=5)  # Recreate a new connection everytime
+            connection = HTTPSConnection(
+                "8.8.8.8", timeout=5
+            )  # Recreate a new connection everytime
             connection.request("HEAD", "/")
         else:
             socket_.connect(("8.8.8.8", 80))
         return True
     except OSError as error:
         logger.error("OSError [%d]: %s", error.errno, error.strerror)
     except Exception as error:
```

## jarvis/modules/utils/util.py

```diff
@@ -10,54 +10,56 @@
 import hashlib
 import random
 import re
 import socket
 import string
 import uuid
 from datetime import datetime, timezone
-from typing import Any, Dict, Hashable, List, Union
+from typing import Any, Dict, Hashable, List, Tuple
 
 
 def get_timezone() -> str:
     """Get local timezone using datetime module.
 
     Returns:
         str:
         Returns local timezone abbreviation.
     """
     return datetime.utcnow().astimezone().tzname()
 
 
-def epoch_to_datetime(seconds: Union[int, float], format_: str = None, zone: timezone = None) -> Union[datetime, str]:
+def epoch_to_datetime(
+    seconds: int | float, format_: str = None, zone: timezone = None
+) -> datetime | str:
     """Convert epoch time to datetime.
 
     Args:
         seconds: Epoch timestamp.
         format_: Custom datetime string format.
         zone: Timezone of epoch.
 
     Returns:
-        Union[datetime, str]:
+        datetime | str:
         Returns either a datetime object or a string formatted datetime.
     """
     if zone:
         datetime_obj = datetime.fromtimestamp(seconds, zone)
     else:
         datetime_obj = datetime.fromtimestamp(seconds)
     if format_:
         return datetime_obj.strftime(format_)
     return datetime_obj
 
 
-def miles_to_kms(miles: Union[int, float]) -> float:
+def miles_to_kms(miles: int | float) -> float:
     """Takes miles as an argument and returns it in kilometers."""
     return round(miles / 0.621371, 2)
 
 
-def kms_to_miles(kms: Union[int, float]) -> float:
+def kms_to_miles(kms: int | float) -> float:
     """Takes kilometers as an argument and returns it in miles."""
     return round(kms * 0.621371, 2)
 
 
 def part_of_day() -> str:
     """Checks the current hour to determine the part of day.
 
@@ -71,27 +73,32 @@
     if 12 <= current_hour <= 15:
         return "Afternoon"
     if 16 <= current_hour <= 19:
         return "Evening"
     return "Night"
 
 
-def get_closest_match(text: str, match_list: list, get_ratio: bool = False) -> Union[Dict[str, float], str]:
+def get_closest_match(
+    text: str, match_list: list, get_ratio: bool = False
+) -> Dict[str, float] | str:
     """Get the closest matching word from a list of words.
 
     Args:
         text: Text to look for in the matching list.
         match_list: List to be compared against.
         get_ratio: Boolean flag to return the closest match along with the ratio, as a dict.
 
     Returns:
-        Union[Dict[str, float], str]:
+        Dict[str, float] | str:
         Returns the text that matches closest in the list or a dictionary of the closest match and the match ratio.
     """
-    closest_match = [{"text": key, "ratio": difflib.SequenceMatcher(a=text, b=key).ratio()} for key in match_list]
+    closest_match = [
+        {"text": key, "ratio": difflib.SequenceMatcher(a=text, b=key).ratio()}
+        for key in match_list
+    ]
     if get_ratio:
         return sorted(closest_match, key=lambda d: d["ratio"], reverse=True)[0]
     return sorted(closest_match, key=lambda d: d["ratio"], reverse=True)[0].get("text")
 
 
 def hashed(key: uuid.UUID) -> Hashable:
     """Generates sha from UUID.
@@ -155,116 +162,144 @@
 
     Returns:
         int:
         Integer version of the words.
     """
     input_ = input_.lower()
     number_mapping = {
-        'zero': 0,
-        'one': 1,
-        'two': 2,
-        'three': 3,
-        'four': 4,
-        'five': 5,
-        'six': 6,
-        'seven': 7,
-        'eight': 8,
-        'nine': 9,
-        'ten': 10,
-        'eleven': 11,
-        'twelve': 12,
-        'thirteen': 13,
-        'fourteen': 14,
-        'fifteen': 15,
-        'sixteen': 16,
-        'seventeen': 17,
-        'eighteen': 18,
-        'nineteen': 19,
-        'twenty': 20,
-        'thirty': 30,
-        'forty': 40,
-        'fifty': 50,
-        'sixty': 60,
-        'seventy': 70,
-        'eighty': 80,
-        'ninety': 90,
+        "zero": 0,
+        "one": 1,
+        "two": 2,
+        "three": 3,
+        "four": 4,
+        "five": 5,
+        "six": 6,
+        "seven": 7,
+        "eight": 8,
+        "nine": 9,
+        "ten": 10,
+        "eleven": 11,
+        "twelve": 12,
+        "thirteen": 13,
+        "fourteen": 14,
+        "fifteen": 15,
+        "sixteen": 16,
+        "seventeen": 17,
+        "eighteen": 18,
+        "nineteen": 19,
+        "twenty": 20,
+        "thirty": 30,
+        "forty": 40,
+        "fifty": 50,
+        "sixty": 60,
+        "seventy": 70,
+        "eighty": 80,
+        "ninety": 90,
     }
     numbers = []
-    for word in input_.replace('-', ' ').split():
+    for word in input_.replace("-", " ").split():
         if word in number_mapping:
             numbers.append(number_mapping[word])
-        elif word == 'hundred':
+        elif word == "hundred":
             numbers[-1] *= 100
-        elif word == 'thousand':
+        elif word == "thousand":
             numbers = [x * 1000 for x in numbers]
-        elif word == 'million':
+        elif word == "million":
             numbers = [x * 1000000 for x in numbers]
     return sum(numbers)
 
 
 def comma_separator(list_: list) -> str:
     """Separates commas using simple ``.join()`` function and analysis based on length of the list taken as argument.
 
     Args:
         list_: Takes a list of elements as an argument.
 
     Returns:
         str:
         Comma separated list of elements.
     """
-    return ", and ".join([", ".join(list_[:-1]), list_[-1]] if len(list_) > 2 else list_)
+    return ", and ".join(
+        [", ".join(list_[:-1]), list_[-1]] if len(list_) > 2 else list_
+    )
 
 
 def extract_time(input_: str) -> List[str]:
     """Extracts 12-hour time value from a string.
 
     Args:
-        input_: Int if found, else returns the received float value.
+        input_: Takes the phrase spoken as an argument.
 
     Returns:
         List[str]:
         Extracted time from the string.
     """
     input_ = input_.lower()
-    return re.findall(r'(\d+:\d+\s?(?:a.m.|p.m.:?))', input_) or \
-        re.findall(r'(\d+\s?(?:a.m.|p.m.:?))', input_) or \
-        re.findall(r'(\d+:\d+\s?(?:am|pm:?))', input_) or \
-        re.findall(r'(\d+\s?(?:am|pm:?))', input_)
+    return (
+        re.findall(r"(\d+:\d+\s?(?:a.m.|p.m.:?))", input_)
+        or re.findall(r"(\d+\s?(?:a.m.|p.m.:?))", input_)
+        or re.findall(r"(\d+:\d+\s?(?:am|pm:?))", input_)
+        or re.findall(r"(\d+\s?(?:am|pm:?))", input_)
+    )
 
 
-def delay_calculator(phrase: str) -> Union[int, float]:
+def split_time(input_: str) -> Tuple[str, str, str]:
+    """Splits the 12-hour time value from a string into a tuple.
+
+    Args:
+        input_: Input string from the function ``extract_time``.
+
+    Returns:
+        Tuple[str, str, str]:
+        Hour, minute and am/pm as a tuple of strings.
+    """
+    assert len(input_.split()) == 2, "Invalid extraction passed"
+    splitter = input_.split()[0]
+    if ":" in input_:
+        hour = int(splitter.split(":")[0])
+        minute = int(splitter.split(":")[-1])
+    else:
+        hour = int(splitter.split()[0])
+        minute = 0
+    # makes sure hour and minutes are two digits
+    hour, minute = f"{hour:02}", f"{minute:02}"
+    am_pm = "AM" if "A" in input_.split()[-1].upper() else "PM"
+    return hour, minute, am_pm
+
+
+def delay_calculator(phrase: str) -> int | float:
     """Calculates the delay in phrase (if any).
 
     Args:
         phrase: Takes the phrase spoken as an argument.
 
     Returns:
-        Union[int, float]:
+        int | float:
         Seconds of delay.
     """
     if not (count := extract_nos(input_=phrase)):
         count = 1
-    if 'hour' in phrase:
+    if "hour" in phrase:
         delay = 3_600
-    elif 'minute' in phrase:
+    elif "minute" in phrase:
         delay = 60
     else:  # Default to # as seconds
         delay = 60
     return count * delay
 
 
-def extract_nos(input_: str, method: type = float) -> Union[int, float]:
+def extract_nos(input_: str, method: type = float) -> int | float:
     """Extracts number part from a string.
 
     Args:
         input_: Takes string as an argument.
         method: Takes a type to return a float or int value.
 
     Returns:
-        Union[int, float]:
+        int | float:
         Float values.
     """
     if value := re.findall(r"\d+", input_):
         if method == float:
             try:
                 return method(".".join(value))
             except ValueError:
@@ -292,28 +327,35 @@
     Args:
         input_: Takes a string as argument.
 
     Returns:
         str:
         A string after removing special characters.
     """
-    return "".join([i for i in input_ if not i.isdigit() and i not in [",", ".", "?", "-", ";", "!", ":"]]).strip()
+    return "".join(
+        [
+            i
+            for i in input_
+            if not i.isdigit() and i not in [",", ".", "?", "-", ";", "!", ":"]
+        ]
+    ).strip()
 
 
 def matrix_to_flat_list(input_: List[list]) -> List:
     """Converts a matrix into flat list.
 
     Args:
         input_: Takes a list of list as an argument.
 
     Returns:
         list:
         Flat list.
     """
-    if filter(lambda x: isinstance(x, list), input_):  # do conversion only if it is a real matrix
+    # do conversion only if it is a real matrix
+    if filter(lambda x: isinstance(x, list), input_):
         return sum(input_, []) or [item for sublist in input_ for item in sublist]
     return input_
 
 
 def remove_none(input_: List[Any]) -> List[Any]:
     """Removes None values from a list.
 
@@ -333,16 +375,16 @@
     Args:
         input_: Takes a list as an argument.
 
     Returns:
         List[Any]:
         Returns a cleaned up list.
     """
-    # return list(set(input_))
-    return [i for n, i in enumerate(input_) if i not in input_[n + 1:]]
+    return [i for n, i in enumerate(input_) if i not in input_[n + 1:]] or list(set(input_))  # fmt: skip
+    # black formats to include space between '1' and ':', refer: https://github.com/psf/black/issues/1323
 
 
 def get_free_port() -> int:
     """Chooses a PORT number dynamically that is not being used to ensure we don't rely on a single port.
 
     Instead of binding to a specific port, ``sock.bind(('', 0))`` is used to bind to 0.
 
@@ -358,10 +400,10 @@
         - Dynamically available: 49152 to 65535
 
     Returns:
         int:
         Randomly chosen port number that is not in use.
     """
     with contextlib.closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as sock:
-        sock.bind(('', 0))
+        sock.bind(("", 0))
         sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
         return sock.getsockname()[1]
```

## jarvis/modules/wakeonlan/wakeonlan.py

```diff
@@ -37,16 +37,21 @@
         """
         if len(macaddress) == 17:
             macaddress = macaddress.replace(macaddress[2], "")
         elif len(macaddress) != 12:
             raise InvalidArgument(f"invalid mac address: {macaddress}")
         return bytes.fromhex("F" * 12 + macaddress * 16)
 
-    def send_packet(self, *mac_addresses: str, ip_address: str = BROADCAST_IP, port: int = DEFAULT_PORT,
-                    interface: str = None) -> None:
+    def send_packet(
+        self,
+        *mac_addresses: str,
+        ip_address: str = BROADCAST_IP,
+        port: int = DEFAULT_PORT,
+        interface: str = None,
+    ) -> None:
         """Wake up devices using mac addresses.
 
         Notes:
             Wake on lan must be enabled on the host device.
 
         Args:
             mac_addresses: One or more mac addresses of machines to wake.
```

## Comparing `jarvis_ironman-4.4.2.dist-info/LICENSE` & `jarvis_ironman-4.5.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `jarvis_ironman-4.4.2.dist-info/METADATA` & `jarvis_ironman-4.5.dist-info/METADATA`

 * *Files 21% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: jarvis-ironman
-Version: 4.4.2
+Version: 4.5
 Summary: Voice-Activated Natural Language UI
 Author-email: Vignesh Rao <svignesh1793@gmail.com>
 License: MIT License
         
         Copyright (c) 2020 Vignesh Rao
         
         Permission is hereby granted, free of charge, to any person obtaining a copy
@@ -36,16 +36,14 @@
 Keywords: python,home-automation,natural-language-processing,text-to-speech,speech-recognition,jarvis,hotword-detection,virtual-assistant
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Information Technology
 Classifier: Operating System :: MacOS :: MacOS X
 Classifier: Operating System :: Microsoft :: Windows :: Windows 10
 Classifier: Operating System :: POSIX :: Linux
 Classifier: License :: OSI Approved :: MIT License
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Classifier: Topic :: Multimedia :: Sound/Audio :: Speech
 Classifier: Topic :: Scientific/Engineering :: Human Machine Interfaces
 Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
 Classifier: Topic :: Home Automation
 Classifier: Topic :: Scientific/Engineering :: Image Recognition
@@ -56,40 +54,42 @@
 Classifier: Topic :: System :: Hardware :: Symmetric Multi-processing
 Classifier: Topic :: System :: Hardware :: Universal Serial Bus (USB) :: Human Interface Device (HID)
 Classifier: Framework :: FastAPI
 Classifier: Framework :: AsyncIO
 Classifier: Framework :: Sphinx
 Classifier: Framework :: aiohttp
 Classifier: Natural Language :: English
-Requires-Python: >=3.8
+Requires-Python: <3.12,>=3.10
 Description-Content-Type: text/markdown
 License-File: LICENSE
 Requires-Dist: axju-jokes ==1.0.3
 Requires-Dist: googlehomepush ==0.1.0
 Requires-Dist: holidays ==0.37
 Requires-Dist: icalendar ==5.0.11
+Requires-Dist: jlrpy ==1.7.0
 Requires-Dist: newsapi-python ==0.2.7
 Requires-Dist: packaging ==23.2
+Requires-Dist: PyAudio ==0.2.14
 Requires-Dist: PyChromecast ==2.3.0
 Requires-Dist: pyhtcc ==0.1.55
 Requires-Dist: pyicloud ==1.0.0
-Requires-Dist: pyrh ==2.0
+Requires-Dist: pyrh ==2.1.2
 Requires-Dist: pywebostv ==0.8.9
 Requires-Dist: randfacts ==0.21.0
 Requires-Dist: sounddevice ==0.4.6
 Requires-Dist: SpeechRecognition ==3.10.0
 Requires-Dist: speedtest-cli ==2.1.3
 Requires-Dist: timezonefinder ==6.2.0
 Requires-Dist: webcolors ==1.13
 Requires-Dist: webull ==0.6.1
 Requires-Dist: wikipedia ==1.4.0
 Requires-Dist: aiofiles ==23.2.*
 Requires-Dist: aiohttp ==3.8.*
 Requires-Dist: bs4 ==0.0.*
-Requires-Dist: certifi ==2023.7.*
+Requires-Dist: certifi
 Requires-Dist: deepdiff ==6.6.*
 Requires-Dist: docker ==6.1.*
 Requires-Dist: fastapi ==0.103.*
 Requires-Dist: geopy ==2.4.*
 Requires-Dist: inflect ==7.0.*
 Requires-Dist: Jinja2 ==3.1.*
 Requires-Dist: lxml ==4.9.*
@@ -100,107 +100,109 @@
 Requires-Dist: psutil ==5.9.*
 Requires-Dist: pydantic ==2.4.*
 Requires-Dist: pydantic-settings ==2.0.*
 Requires-Dist: PyJWT ==2.8.*
 Requires-Dist: pytest ==7.4.*
 Requires-Dist: python-dateutil ==2.8.*
 Requires-Dist: python-multipart ==0.0.*
-Requires-Dist: pytz ==2023.3.*
+Requires-Dist: pytz
 Requires-Dist: PyYAML ==6.0.*
 Requires-Dist: requests ==2.31.*
 Requires-Dist: SoundFile ==0.12.*
 Requires-Dist: uvicorn ==0.23.*
 Requires-Dist: wave ==0.0.*
 Requires-Dist: websockets ==11.0.*
-Requires-Dist: gmail-connector
-Requires-Dist: py3-tts
-Requires-Dist: pycontrols
-Requires-Dist: vpn-server
+Requires-Dist: gmail-connector >=1.0
+Requires-Dist: py3-tts >=3.5
+Requires-Dist: pycontrols >=0.0.4
+Requires-Dist: vpn-server >=1.7
 Provides-Extra: dev
 Requires-Dist: sphinx ==5.1.1 ; extra == 'dev'
 Requires-Dist: pre-commit ; extra == 'dev'
 Requires-Dist: recommonmark ; extra == 'dev'
 Requires-Dist: pytest ; extra == 'dev'
 
 <p align="center" style="text-align: center">
-  <img src="https://vigneshrao.com/Jarvis/logo.png" width="371px" height="350px">
+  <img src="https://thevickypedia.github.io/open-source/images/logo/jarvis.png" width="371px" height="350px">
 </p>
 <h2 align="center">Voice-Activated Natural Language UI</h2>
 
-[![made-with-python](https://img.shields.io/badge/Made%20with-Python-blue?style=for-the-badge&logo=Python)][python]
+[![made-with-python][label-python]][python]
 
-![Python](https://img.shields.io/badge/python-3.8%20%7C%203.9%20%7C%203.10%20%7C%203.11-orange)
-![Pypi-downloads](https://img.shields.io/pypi/dm/jarvis-ironman)
+![Python][label-pyversion]
+![Pypi-downloads][label-pypi-downloads]
 
 **Platform Supported**
 
-![Platform](https://img.shields.io/badge/Platform-Linux|MacOS|Windows-1f425f.svg)
+![Platform][label-platform]
 
 **Language Stats**
 
-![Language count](https://img.shields.io/github/languages/count/thevickypedia/Jarvis)
-![Code coverage](https://img.shields.io/github/languages/top/thevickypedia/Jarvis)
+![Language count][label-language-ct]
+![Code coverage][label-code-coverage]
 
 **[Repo Stats][repo]**
 
-[![GitHub](https://img.shields.io/github/license/thevickypedia/Jarvis)][license]
+[![GitHub][label-license]][license]
 
-![GitHub Repo stars](https://img.shields.io/github/stars/thevickypedia/Jarvis)
-![GitHub Repo forks](https://img.shields.io/github/forks/thevickypedia/Jarvis)
-![GitHub Repo watchers](https://img.shields.io/github/watchers/thevickypedia/Jarvis)
-
-![GitHub repo size](https://img.shields.io/github/repo-size/thevickypedia/Jarvis)
-![GitHub code size](https://img.shields.io/github/languages/code-size/thevickypedia/Jarvis)
-
-![GitHub Repo issues](https://img.shields.io/github/issues-closed-raw/thevickypedia/Jarvis)
-![GitHub Repo issues](https://img.shields.io/github/issues-raw/thevickypedia/Jarvis)
-![GitHub Repo pr](https://img.shields.io/github/issues-pr-closed-raw/thevickypedia/Jarvis)
-![GitHub Repo pr](https://img.shields.io/github/issues-pr-raw/thevickypedia/Jarvis)
+![GitHub Repo stars][label-stars]
+![GitHub Repo forks][label-forks]
+![GitHub Repo watchers][label-watchers]
+
+![GitHub repo size][label-repo-size]
+![GitHub code size][label-code-size]
+
+![GitHub Repo issues][label-issues-closed]
+![GitHub Repo issues][label-issues-raw]
+![GitHub Repo pr][label-pr-closed]
+![GitHub Repo pr][label-pr-raw]
 
 **Code Stats**
 
-![Modules](https://img.shields.io/github/search/thevickypedia/Jarvis/module)
-![Python](https://img.shields.io/github/search/thevickypedia/Jarvis/.py)
-![Threads](https://img.shields.io/github/search/thevickypedia/Jarvis/thread)
-![Listener](https://img.shields.io/github/search/thevickypedia/Jarvis/listener)
-![Speaker](https://img.shields.io/github/search/thevickypedia/Jarvis/speaker)
-![Bash](https://img.shields.io/github/search/thevickypedia/Jarvis/.sh)
-![AppleScript](https://img.shields.io/github/search/thevickypedia/Jarvis/.scpt)
-![Make](https://img.shields.io/github/search/thevickypedia/Jarvis/Makefile)
+![Modules][label-stats-Modules]
+![Python][label-stats-Python]
+![Threads][label-stats-Threads]
+![Listener][label-stats-Listener]
+![Speaker][label-stats-Speaker]
+![Bash][label-stats-Bash]
+![AppleScript][label-stats-AppleScript]
+![Make][label-stats-Make]
 
 **Deployments**
 
-[![pages](https://github.com/thevickypedia/Jarvis/actions/workflows/pages/pages-build-deployment/badge.svg)][gha_pages]
-[![pypi](https://github.com/thevickypedia/Jarvis/actions/workflows/python-publish.yml/badge.svg)][gha_pypi]
-[![markdown](https://github.com/thevickypedia/Jarvis/actions/workflows/markdown-validation.yml/badge.svg)][gha_md_valid]
-
-[![PyPI version shields.io](https://img.shields.io/pypi/v/jarvis-ironman)][pypi]
-[![Pypi-format](https://img.shields.io/pypi/format/jarvis-ironman)](https://pypi.org/project/jarvis-ironman/#files)
-[![Pypi-status](https://img.shields.io/pypi/status/jarvis-ironman)][pypi]
+[![pages][label-actions-pages]][gha_pages]
+[![pypi][label-actions-pypi]][gha_pypi]
+
+[![markdown][label-actions-markdown]][gha_md_valid]
+[![cleanup][label-actions-cleanup]][gha_cleanup]
+
+[![Pypi][label-pypi]][pypi]
+[![Pypi-format][label-pypi-format]][pypi-files]
+[![Pypi-status][label-pypi-status]][pypi]
 
 **Activity**
 
-![GitHub Repo created](https://img.shields.io/date/1599432310)
-![GitHub commit activity](https://img.shields.io/github/commit-activity/y/thevickypedia/Jarvis)
-![GitHub last commit](https://img.shields.io/github/last-commit/thevickypedia/Jarvis)
-![GitHub last release](https://img.shields.io/github/release-date/thevickypedia/Jarvis)
+![GitHub Repo created][label-github-repo-created]
+![GitHub commit activity][label-github-commit-activity]
+![GitHub last commit][label-github-last-commit]
+![GitHub last release][label-github-last-release]
 
 **Development and Maintenance**
 
-![Active Development](https://img.shields.io/badge/Development%20Level-Actively%20Developed-success.svg)
-![Actively Maintained](https://img.shields.io/badge/Maintenance%20Level-Actively%20Maintained-success.svg)
-[![Maintainer](https://img.shields.io/badge/Maintained%20By-Vignesh%20Sivanandha%20Rao-blue.svg)][webpage]
+![Active Development][label-active-development]
+![Actively Maintained][label-actively-maintained]
+[![Maintainer][label-maintainer]][webpage]
 
 **Reach Out**
 
-[![ askme ](https://img.shields.io/badge/SELECT%20*%20FROM-questions-1abc9c.svg)][webpage_contact]
+[![askme][label-askme]][webpage_contact]
 
 ## Kick off
 
-> :bulb: Using a dedicated [virtual environment][venv] and an IDE like [PyCharm][pycharm] is highly recommended.
+> :bulb: Using a dedicated [virtual environment] with [python3.11] and an IDE like [PyCharm] is highly recommended.
 
 **Install**
 ```shell
 python -m pip install jarvis-ironman
 ```
 
 **Initiate**
@@ -227,15 +229,15 @@
      - Unlike macOS and Windows, `Ubuntu` does not have app specific permissions.
 
    - **Windows** <br> _Tested on **Windows 10**_
      - `Settings`  `Privacy`
        - `Microphone` - **Required** to listen and respond.
        - `Camera` - **[Optional]** Required only during face recognition/detection.
        - Unlike `macOS`, `Windows` pops a confirmation window to **Allow** or **Deny** access to files and folders.
-     - Install [Anaconda][conda] or [Miniconda][miniconda], [VisualStudio C++ BuildTools][vcpp], and [Git][git-cli]
+     - Install [Anaconda] or [Miniconda], [VisualStudio C++ BuildTools][vcpp], and [Git][git-cli]
      - Make sure C++ build tools are installed completely and restart
      - Add anaconda/miniconda scripts location to `PATH` in Environment Variables
 
 ## Enchiridion
 Handbook - [GitHub Wiki][wiki]
 
 ## Coding Standards
@@ -255,15 +257,15 @@
 
 ## Linting
 `pre-commit` will ensure linting, run pytest, generate runbook & release notes, and validate hyperlinks in ALL
 markdown files (including Wiki pages)
 
 **Requirement**
 ```shell
-pip install sphinx==5.1.1 pre-commit recommonmark
+python -m pip install sphinx==5.1.1 pre-commit recommonmark
 ```
 
 **Usage**
 ```shell
 pre-commit run --all-files
 ```
 
@@ -280,29 +282,85 @@
 ## License & copyright
 
 &copy; Vignesh Rao
 
 Licensed under the [MIT License][license]
 
 [python]: https://python.org
-[venv]: https://docs.python.org/3/tutorial/venv.html
-[pycharm]: https://www.jetbrains.com/pycharm/
+[python3.11]: https://docs.python.org/3/whatsnew/3.11.html
+[virtual environment]: https://docs.python.org/3/tutorial/venv.html
+[PyCharm]: https://www.jetbrains.com/pycharm/
 [repo]: https://api.github.com/repos/thevickypedia/Jarvis
 [license]: https://github.com/thevickypedia/Jarvis/blob/master/LICENSE
 [pypi]: https://pypi.org/project/jarvis-ironman
+[pypi-files]: https://pypi.org/project/jarvis-ironman/#files
 [pypi-repo]: https://packaging.python.org/tutorials/packaging-projects/
 [wiki]: https://github.com/thevickypedia/Jarvis/wiki
 [release-notes]: https://github.com/thevickypedia/Jarvis/blob/master/release_notes.rst
 [gha_pages]: https://github.com/thevickypedia/Jarvis/actions/workflows/pages/pages-build-deployment
 [gha_pypi]: https://github.com/thevickypedia/Jarvis/actions/workflows/python-publish.yml
 [gha_md_valid]: https://github.com/thevickypedia/Jarvis/actions/workflows/markdown-validation.yml
+[gha_cleanup]: https://github.com/thevickypedia/Jarvis/actions/workflows/cleanup.yml
 [webpage]: https://vigneshrao.com/
 [webpage_contact]: https://vigneshrao.com/contact
-[conda]: https://docs.conda.io/projects/conda/en/latest/user-guide/install/
-[miniconda]: https://docs.conda.io/en/latest/miniconda.html#windows-installers
+[Anaconda]: https://docs.conda.io/projects/conda/en/latest/user-guide/install/
+[Miniconda]: https://docs.conda.io/en/latest/miniconda.html#windows-installers
 [vcpp]: https://visualstudio.microsoft.com/visual-cpp-build-tools/
 [git-cli]: https://git-scm.com/download/win/
 [google-docs]: https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings
 [pep8]: https://www.python.org/dev/peps/pep-0008/
 [isort]: https://pycqa.github.io/isort/
 [sphinx]: https://www.sphinx-doc.org/en/master/man/sphinx-autogen.html
 [runbook]: https://jarvis-docs.vigneshrao.com/
+
+<!-- labels -->
+
+[label-python]: https://img.shields.io/badge/Made%20with-Python-blue?style=for-the-badge&logo=Python
+[label-pyversion]: https://img.shields.io/badge/python-3.10%20%7C%203.11-orange
+[label-pypi-downloads]: https://img.shields.io/pypi/dm/jarvis-ironman
+[label-platform]: https://img.shields.io/badge/Platform-Linux|MacOS|Windows-1f425f.svg
+
+[label-language-ct]: https://img.shields.io/github/languages/count/thevickypedia/Jarvis
+[label-code-coverage]: https://img.shields.io/github/languages/top/thevickypedia/Jarvis
+
+[label-license]: https://img.shields.io/github/license/thevickypedia/Jarvis
+
+[label-stars]: https://img.shields.io/github/stars/thevickypedia/Jarvis
+[label-forks]: https://img.shields.io/github/forks/thevickypedia/Jarvis
+[label-watchers]: https://img.shields.io/github/watchers/thevickypedia/Jarvis
+
+[label-repo-size]: https://img.shields.io/github/repo-size/thevickypedia/Jarvis
+[label-code-size]: https://img.shields.io/github/languages/code-size/thevickypedia/Jarvis
+
+[label-issues-closed]: https://img.shields.io/github/issues-closed-raw/thevickypedia/Jarvis
+[label-issues-raw]: https://img.shields.io/github/issues-raw/thevickypedia/Jarvis
+[label-pr-closed]: https://img.shields.io/github/issues-pr-closed-raw/thevickypedia/Jarvis
+[label-pr-raw]: https://img.shields.io/github/issues-pr-raw/thevickypedia/Jarvis
+
+[label-stats-Modules]: https://img.shields.io/github/search/thevickypedia/Jarvis/module
+[label-stats-Python]: https://img.shields.io/github/search/thevickypedia/Jarvis/.py
+[label-stats-Threads]: https://img.shields.io/github/search/thevickypedia/Jarvis/thread
+[label-stats-Listener]: https://img.shields.io/github/search/thevickypedia/Jarvis/listener
+[label-stats-Speaker]: https://img.shields.io/github/search/thevickypedia/Jarvis/speaker
+[label-stats-Bash]: https://img.shields.io/github/search/thevickypedia/Jarvis/.sh
+[label-stats-AppleScript]: https://img.shields.io/github/search/thevickypedia/Jarvis/.scpt
+[label-stats-Make]: https://img.shields.io/github/search/thevickypedia/Jarvis/Makefile
+
+[label-actions-pages]: https://github.com/thevickypedia/Jarvis/actions/workflows/pages/pages-build-deployment/badge.svg
+[label-actions-pypi]: https://github.com/thevickypedia/Jarvis/actions/workflows/python-publish.yml/badge.svg
+[label-actions-markdown]: https://github.com/thevickypedia/Jarvis/actions/workflows/markdown-validation.yml/badge.svg
+[label-actions-cleanup]: https://github.com/thevickypedia/Jarvis/actions/workflows/cleanup.yml/badge.svg
+
+[label-pypi]: https://img.shields.io/pypi/v/jarvis-ironman
+[label-pypi-format]: https://img.shields.io/pypi/format/jarvis-ironman
+[label-pypi-status]: https://img.shields.io/pypi/status/jarvis-ironman
+
+[label-github-repo-created]: https://img.shields.io/date/1599432310
+[label-github-commit-activity]: https://img.shields.io/github/commit-activity/y/thevickypedia/Jarvis
+[label-github-last-commit]: https://img.shields.io/github/last-commit/thevickypedia/Jarvis
+[label-github-last-release]: https://img.shields.io/github/release-date/thevickypedia/Jarvis
+
+[label-active-development]: https://img.shields.io/badge/Development%20Level-Actively%20Developed-success.svg
+[label-actively-maintained]: https://img.shields.io/badge/Maintenance%20Level-Actively%20Maintained-success.svg
+[label-maintainer]: https://img.shields.io/badge/Maintained%20By-Vignesh%20Rao-blue.svg
+
+[label-askme]: https://img.shields.io/badge/SELECT%20*%20FROM-questions-1abc9c.svg
```

## Comparing `jarvis_ironman-4.4.2.dist-info/RECORD` & `jarvis_ironman-4.5.dist-info/RECORD`

 * *Files 16% similar despite different names*

```diff
@@ -1,150 +1,151 @@
-jarvis/__init__.py,sha256=dX3GObH8UiiMx6VzCXjm0-IpLKdEXPCvO2OdD5jLC3o,839
-jarvis/main.py,sha256=CqdltBYKxDDdnuKGIZwJutomSZ2K-LoMmWotA6S6ueE,9388
-jarvis/_preexec/keywords_handler.py,sha256=VG98So4j_zaS7wiWwPSimJIrMcqAI-5gmNQyH3BNdko,2781
-jarvis/api/logger.py,sha256=XqNck3gX8IHaQIBVM3Fw6CDiIHppHctv7Dr2lYKBxT0,1173
-jarvis/api/main.py,sha256=hUJXmsr0a5JnEFXxKQM73tlAoP1IfEFk-pXzLBw_1jo,3414
-jarvis/api/server.py,sha256=pRpXAaTPIj11Q_tbeaMdYfNOzH-sx-nzQLSnmFL--Yo,2272
-jarvis/api/models/authenticator.py,sha256=tPY22FM2wIJ2t8DWnN71jlSiT8Rf6W9cadK4DC2O3t0,2388
-jarvis/api/models/modals.py,sha256=HNVbPukHnJ2vWpIZUglxVsqWPFa2mckUFvH9gPfy_Es,1193
-jarvis/api/models/settings.py,sha256=cdZOEAssWYeP25drk2CpojHnW2k0RxsfgKOO-Q4xB5A,2784
-jarvis/api/routers/basics.py,sha256=sbzVQrqs1pctSm7SUFf5us3LYNqdwNRbR7T9FECH5pA,1938
+jarvis/__init__.py,sha256=t46NMMwn4S7IuNIGPNT0-sKuDvAiw-jTjoJ420XrFbs,870
+jarvis/main.py,sha256=-Oq1Jvy51LMoNuPDiUqG66EZeop5aZ2MAGjmVB33E-A,9688
+jarvis/_preexec/keywords_handler.py,sha256=de20wtbmze1pYJ1zgio5xHdMDNXqq_xxLIaahcDUP1Y,2929
+jarvis/api/logger.py,sha256=c5jXv8l_B6IAsXHcyJwfc5V6duw5Xnx3W0gLO6PjiQE,1179
+jarvis/api/main.py,sha256=yHv_E_UX7GMGtwLMUR--BF74_Cx3HyYBDpiKcFK4ToE,3650
+jarvis/api/server.py,sha256=F4NhTYtk0w71nVhebx23966XkqRCX5I1ehFPqLMZx8U,2328
+jarvis/api/models/authenticator.py,sha256=sVlHbh6ZdiAcRq8m4sWEi_cWfHoppPKvHFzyQhuViiM,2437
+jarvis/api/models/modals.py,sha256=O7dK2SgARjKDbyJSz_9nQOIJN6dt1zmtTDF7ZMMn4HQ,1156
+jarvis/api/models/settings.py,sha256=WEKwgFg_W5nXKofON5znloqYuXr7vWmKE-HL0me6Hp8,2902
+jarvis/api/routers/basics.py,sha256=pCaReZHf_tZ_twwhhOCRe8BypUIHJE6xOc1d9Y0T0nU,1999
 jarvis/api/routers/favicon.ico,sha256=WMmt7kTMDjd0HmR4sFloGQm0WohOPVry9ivdK40AAqc,15406
-jarvis/api/routers/fileio.py,sha256=-wJ5pZzxnJg1aRN_ouq0ECt0IUszbDgIpTvT7FloPkk,3438
-jarvis/api/routers/investment.py,sha256=_eqqd06Sv6crmVqT5Svp5I28LGfb9u1elodxnulDKSI,5907
-jarvis/api/routers/offline.py,sha256=6ZkwZF4ssY_uQM9ecEG0QvHYbMtmtkchHQbrEXhr4Kw,7913
-jarvis/api/routers/secure_send.py,sha256=ySPu6oa01k24NxI3as2wxRJUX__T4fUvdJtna9-yCl0,2176
-jarvis/api/routers/speech_synthesis.py,sha256=Hc4RyOPi9DMavv6DwR2M96XwrLwrHVdx1dNJhPalEbA,4294
-jarvis/api/routers/stock_analysis.py,sha256=Vo6kJgYJgefJ-_eJ1QYaWmF0WXHHGP8NaE5bNHBqdM4,6672
-jarvis/api/routers/stock_monitor.py,sha256=T7b0t-3-yGBAwsZNqi7I5eFk5U4OUcoxfXPKOhBQWJE,13660
-jarvis/api/routers/surveillance.py,sha256=8408T_2y1WAhxgD7_E5DgUZ-9jZnR33YZuQROD2GC50,12313
-jarvis/api/routers/telegram.py,sha256=cBhLguF3gTQjU7BAgWrwP4b0urfzk079_V8609kieDc,2131
-jarvis/api/squire/discover.py,sha256=gfGwfyI8d3Qm1X67w24c2qyHZkXDvUVSedSwBLkWqX4,2792
-jarvis/api/squire/scheduler.py,sha256=7QnpKfW6DtCCdLWnW2dUN6KytSwAXdIbFIxUIELiW38,2722
-jarvis/api/squire/stockanalysis_squire.py,sha256=Gsbai8DMRsrArQMMPtkWLYVNp29rS7os7mDoo4fVJUY,4134
-jarvis/api/squire/stockmonitor_squire.py,sha256=a22ZC8KYpBAl3QMdUSjJ68WGFXh_dNGFo5PN-NHNxPw,4243
-jarvis/api/squire/surveillance_squire.py,sha256=vbKwnVGtxt0H4fW4fhiyNJ8cIc_dIJ7Dq8fSnUpkkPk,5375
+jarvis/api/routers/fileio.py,sha256=HAdwCk-Fwp-RQZ1MmUKHF1UfIGSxv95S64Ubxkv-xnI,3800
+jarvis/api/routers/investment.py,sha256=3AIBBsEUMNL5WDJtzHASG2PXs00sgFSz8d4qPBDNPvI,5964
+jarvis/api/routers/offline.py,sha256=RkUOMsxSIu1FH_ytgDJ9sfbpKDWuuw7iul_-GrGhzRw,8386
+jarvis/api/routers/proxy_service.py,sha256=-cfUx0U524KnbKGn5j910FMwsnCYiJdRbgfGf_ky_Pc,2050
+jarvis/api/routers/secure_send.py,sha256=dMeYqi2goISE3kPRQ-gSUQA9Ryr-eWFyYjW3-PjAsJw,2366
+jarvis/api/routers/speech_synthesis.py,sha256=iOPXzt9s17WJ_SBsC4YvwGviJjn5EUpp_Bk-Z9bVmfo,4558
+jarvis/api/routers/stock_analysis.py,sha256=IEqw4XChh7RFdZLK6Di87KUd2QWrsPSk9GWpamk5PcI,6994
+jarvis/api/routers/stock_monitor.py,sha256=toKF1PG02v0ml3DBE2cJCgxlEcgHVC3cQhkLqxW6rjA,14288
+jarvis/api/routers/surveillance.py,sha256=NmRoKmCDlP4rQC3uhu426d0FqiWRPaUbNyDig3gEINI,12566
+jarvis/api/routers/telegram.py,sha256=gVPV5ci9NrQba3qhFefFMAjY3sdhgMql3s1w1THcJtM,2261
+jarvis/api/squire/discover.py,sha256=fB_GtQa9mZnci9Ae3bRxClg4cWZ0e0ez0l_ibU2N7kQ,2966
+jarvis/api/squire/scheduler.py,sha256=gl50xgPIECB99hCd2-UbFck2FVTE80l9DW_fd26LQVg,2818
+jarvis/api/squire/stockanalysis_squire.py,sha256=nhBWMQE_MLM4e6w3RzNzFa33cRDY1lvpk5mjZcURoR4,4432
+jarvis/api/squire/stockmonitor_squire.py,sha256=hmRf20bNbv2Tw-pwlK7SMXsXzuFseelwEzKZG3nPaDw,4286
+jarvis/api/squire/surveillance_squire.py,sha256=p0NbFzkmi4aNhQwfbQaWdlnZ0bWyCpaTX_jOf5cQ6rg,5460
 jarvis/api/squire/timeout_otp.py,sha256=BV_Xzf0Dy4qTsp6raSExkgWXLbA7C1UfyvlOUiFUeHg,647
-jarvis/api/triggers/stock_monitor.py,sha256=hqVRfcwVJ_2KkmF5DCT6eUG3Z5G5CdQ9jbEEblP9X8k,13533
-jarvis/api/triggers/stock_report.py,sha256=tBMct0DGxRD0_H-XkKjldoNI8Q3M8RTh44keqZOpzPc,11567
-jarvis/executors/alarm.py,sha256=CnJyKAWLoV_U7S5l_sDz9W-LB26FYCzyzZvzOw-ughc,13780
-jarvis/executors/automation.py,sha256=UYmOH2nVISjElhPzs6xs-yIttZARUJCqACTYTE52oOU,6955
-jarvis/executors/background_task.py,sha256=1cSl-k7rK6e-Cl0CffwyYHIzgM3y8tOrGkUeM3e9QHE,5617
-jarvis/executors/car.py,sha256=RyeTRrvxcZvPjC2HWsKqPb1AJBUrmuW1NP5TOtZ5VP4,25308
-jarvis/executors/comm_squire.py,sha256=Kma_PU7K1UY0COsWoi4UsBkdOm4biEvRPyV0v75_4lE,9157
-jarvis/executors/commander.py,sha256=DMEQXeRE0PEk_VRstTp__8eR1zxQ4yi4wvbiOMSFdRE,6159
-jarvis/executors/communicator.py,sha256=vWPicLjsgw7ofMTpqL8khhG5_F9FMOr8aeMScw-9OUc,5437
-jarvis/executors/conditions.py,sha256=EgYEcWUVsX9qodEQy_KZEiWqYwJ8oSd79uxplWbTgiI,4919
-jarvis/executors/connection.py,sha256=hDwKwsOguNyp3plCrbVnAXpDb9l4RuuaIUnQ5H2nOt4,2133
-jarvis/executors/controls.py,sha256=qbZ9fbE6PzLuJkuYX3nmAbf-euuFwXY_QoFKs-90aAo,12942
-jarvis/executors/crontab.py,sha256=7kkfMiWetJegsELfGnBgXT-ey6KqKWON9kJqZFxeN40,3440
-jarvis/executors/custom_conditions.py,sha256=0GI68_vDIl6j94yvwmSlQ_OuRAXYOFaBlnxUbegjaUY,1891
-jarvis/executors/date_time.py,sha256=gkf5U3wabD2J_SInaHD6hyE65CRZLtjuaG8NA1hqmlM,2433
-jarvis/executors/display_functions.py,sha256=Di7P13JwAnlt-ti7vGV3QPAjDXK9JuCD9sqZ9zsFz9M,1319
-jarvis/executors/face.py,sha256=bJOZHsAarH60Ro_WwJuCUY2Y_njpaXZx770aD92mbhM,4220
-jarvis/executors/files.py,sha256=1FDsXGbBhuTswqGdwcrLBL1lJDrZw2AOWQpGwqMGVC8,10545
-jarvis/executors/functions.py,sha256=bPYU-_ihJzCj0kMRju25xQz0nD8wc1aadZ_c_pk5FmQ,3654
-jarvis/executors/github.py,sha256=6lcE_XuQO71xIeqcELNb_HRiU7sPHMfZd2vf3LD26mU,4014
-jarvis/executors/guard.py,sha256=YVeZrmyXP19QMSMMYlZjhEJ4lbQbYD588YTDbQXWRho,10561
-jarvis/executors/internet.py,sha256=DVf7-4HMpFTbNMb4l6EGwg7V_OoEvpBEEbX9hMzz-hs,8101
-jarvis/executors/ios_functions.py,sha256=DMQW3s2PdDb5063f3DmtsH_cauQ5QBu_3FmDIAqlU7w,6207
-jarvis/executors/lights.py,sha256=jTf89WTBZ2_pZwi3zMOS9y3R18oN3aov29DVk8XgU6Q,10738
-jarvis/executors/lights_squire.py,sha256=T2vw-IkGIgFnX22Zvp3-E6SxtQ5TtI6yposPR0sXwWQ,5146
-jarvis/executors/listener_controls.py,sha256=2MNZtlKVQEnnWjMshq1O1WnKKHw-uE7ruRFSsev3oXA,2545
-jarvis/executors/location.py,sha256=CK6ePkUeFI8wiGQjiz9bKTJRqlH5sIUH7IINBFGu3ec,13439
-jarvis/executors/method.py,sha256=4DFzarnFek9wD2FBxJELqjDgB-PVT3W7guXA4nQWxDM,596
-jarvis/executors/offline.py,sha256=Ho2RZ441daWMmx7ZG-cvZHjV2-SXLIVpTkCz830b-WI,13082
-jarvis/executors/others.py,sha256=fAmcAsZef3FJCD_mFHTXEaRAw11DJdR7Z7g-JHGDpRg,23672
-jarvis/executors/port_handler.py,sha256=KoXlX5V21jCg2cNOCoQhMZoivB07BB2S8N1YRtp8tsA,2864
-jarvis/executors/process_map.py,sha256=_7fIIDeFxw4u7ug7zGF5YbyKY65y7VbCVLoIkr6K8Uk,2358
-jarvis/executors/processor.py,sha256=GjyBIRafjBTiJ1PkXtuY5y_VCAP-Bsm-zUf0ayrfdeA,7644
-jarvis/executors/remind.py,sha256=DOxBJVBe9BgGnlkOvCju0lIvyJAFFgMKHVKHkLmp4IE,10188
-jarvis/executors/restrictions.py,sha256=z2Fgx55DDXk0ODClJZzKWAh6cwuB34n16BFVulDD-uI,3967
-jarvis/executors/robinhood.py,sha256=kunvsRCVvWL9us68w0mHZtxy3rTHT9rO6j98bjuWsco,3264
-jarvis/executors/simulator.py,sha256=aDI3r3DwyZbl-8NjekV-O4D8eqSSeJfT5E5IXUHu47M,3548
-jarvis/executors/static_responses.py,sha256=uCnfamHw8MManGlLlC5xNhk90EkusCZaeyl0NO5V8HE,3918
-jarvis/executors/system.py,sha256=jBY5I3-bvUxfvqA4Du0QyuvrcjB42axXb9CykbxMOik,8338
-jarvis/executors/telegram.py,sha256=7exW9tuaH3djeCbuz8-FkEHkSqV_W0OrfPEuaUe0RHc,3281
-jarvis/executors/thermostat.py,sha256=pQol3WC81w4BiMlFgoOm36WT0hN6pF1Pam1dpaTmGBg,6952
-jarvis/executors/todo_list.py,sha256=MT_ppEnDM-rfVdrhJ2neidGQGmDayU8jwtQ0mlub_kM,5097
-jarvis/executors/tv.py,sha256=mLZMaPSz7TyXZWzjYBE3oobW8qMFBaeiFDmfd-9S3YY,7382
-jarvis/executors/tv_controls.py,sha256=M8QqQ8F4xSFWawiMAH1Wxoksw-smMXewmpP98smT3_I,7378
-jarvis/executors/unconditional.py,sha256=4TNxs1MaoJ5V7bceS8cjuFg5gVZGE8Y9jFkd0f5gJ2k,4831
-jarvis/executors/volume.py,sha256=eKdm7DtpT457s1eDGn1cg9PuhjddELkBPIU5PfeYQjM,1910
-jarvis/executors/vpn_server.py,sha256=hI2XLXAkTTJx6RQfqjDVAnFKbuKNrYSmq8CjyRPa6n4,6341
-jarvis/executors/weather.py,sha256=fa8SvtrAamCCWaDM3XPPrOelEBwavHOoDR4KfgkUmSE,10249
-jarvis/executors/weather_monitor.py,sha256=FUi6dc3CPiRreB-7GQTlYz_ioZ46uoD9Os4qWrZvj6I,3415
-jarvis/executors/wiki.py,sha256=tfwtVbBeAztgpNQsXmdtMeCPPhqEKIYyOsk-ZnyMYBE,2261
-jarvis/executors/word_match.py,sha256=gcZAllkMKDqG7BR3B7cktQ4pcPtL6aE3atoZQo6LZY0,1787
+jarvis/api/triggers/stock_monitor.py,sha256=eoY4Ad3Y0r3UhFG9dX6JZO1FQfNHO6_TSqDEyME-964,14399
+jarvis/api/triggers/stock_report.py,sha256=37IvxBwvcnKUbBuqkUdm2cvcc7fv8upDVsp_0dnliqI,11823
+jarvis/executors/alarm.py,sha256=tiu494PtgdJ7V54Xo6AqzJ49j9WzAfFqErK2ndfMc2g,13915
+jarvis/executors/automation.py,sha256=Zj9bvKS1yGCJ4G0jg6JjnazqO9VDUovJfsWe3olSRQc,7561
+jarvis/executors/background_task.py,sha256=XpUoxRHTQ35iXhHneH1BgUs6HAv2gd8EWz8o-PAn75Q,6241
+jarvis/executors/car.py,sha256=6NFZMRJr-K8ZXso5UVVyTlmattTtG65uzrR7x6O1e2c,26854
+jarvis/executors/comm_squire.py,sha256=tx8m8UVp1bQZ8eXv4FujUGveZCd5hjX6A2c3PxyZA04,9465
+jarvis/executors/commander.py,sha256=Uct2tBmRpUyuWVpbVUJg1c85iVodq4MvjyStBWDp-sY,5480
+jarvis/executors/communicator.py,sha256=JvqVT1x_oHnEnNu4GTND-7Zrfb2oQkRX5SALYQ4nHIs,7035
+jarvis/executors/conditions.py,sha256=EiL7iHaMsA2styAvVKQed3UD78xN1RMPe4o8vCC9J3o,5491
+jarvis/executors/connection.py,sha256=D6UDTpUkHggMt2Y855vsy94r0yTIv6RKTEauyQO890w,2140
+jarvis/executors/controls.py,sha256=fbHVwzNkihlWKcWmrMTiK2gVYk2mZo7bdPYkYkrZ9lQ,13691
+jarvis/executors/crontab.py,sha256=Ri6_gSMhgJXUKMJ2V5L6ukPAQE3-J5rcZJSJl4FHS3s,2761
+jarvis/executors/custom_conditions.py,sha256=U81vltXBtgDtdupOu1hQr3xVjc9VsqD7FYTitB0W430,2044
+jarvis/executors/date_time.py,sha256=m952uH5S2E68gQeoSfXel4WzQ12wjB1Ky4u2PsmnrRM,2539
+jarvis/executors/display_functions.py,sha256=75OvpgjEHJypD9bbXi11ARGpGmAtRP-4avFz_FMD10Y,1419
+jarvis/executors/face.py,sha256=f9gZLeRCpZaI5fpiFftBbP7zE3kE53aoFvWLHWI8cqA,4450
+jarvis/executors/files.py,sha256=q0ER4L6DoCbrvq4J1xexHnQ8zrQ1z4Kx2Xm0zok77DM,11580
+jarvis/executors/functions.py,sha256=y--TVlque5yDf2svANaAzO4D8FnaWVrivRk45a037XE,3598
+jarvis/executors/github.py,sha256=OIP_-OLNZ1RXCTAnRPWYZbaXUseM9Plo_RFjiqbhACU,4386
+jarvis/executors/guard.py,sha256=Fspgj6vQTyHg09BfLN7ohHYYtEhKB8czwWSluriJkEU,10813
+jarvis/executors/internet.py,sha256=4eHIOoVabEPlif20dKsdhxWa-bpq_w5aVlAUSYDUd2g,8414
+jarvis/executors/ios_functions.py,sha256=cPYImNhzcF_6Ydx761ukD_oql8zbFx36RQ5adleEh4A,6520
+jarvis/executors/lights.py,sha256=RMm0usA3qYHkkUrFecoxFI26jO-eAD_wg_A8aFU26tE,11435
+jarvis/executors/lights_squire.py,sha256=BRXm3gIYN1hHrhSvTt_wtm2jDZQo5QHDAvihRQaKDXA,5269
+jarvis/executors/listener_controls.py,sha256=K5sTkSRwDfhaNebRE56VY68_t0fFkwYx8uVR7yJxMYw,2575
+jarvis/executors/location.py,sha256=5IENfrnHeaS68SjqQRcpgavXhAibhfb_woHuvoNzrJc,14100
+jarvis/executors/method.py,sha256=5q9EPMRHeSmUJEdmVJJ4TPcCWpw84gbGQ7axQ8OQWjQ,599
+jarvis/executors/offline.py,sha256=VWsmu69d2-9A5bAEYtao7RI1i3hwyeTAeE3RqEJ4oPo,14253
+jarvis/executors/others.py,sha256=fYiW82tT6PRoDs6SnCbTKKethPK1BLr7lmUr79Y9KmY,24567
+jarvis/executors/port_handler.py,sha256=W9TqShBZZq8culrlu1aYxEPaSLLN9qaoB1xkROZBmiA,3103
+jarvis/executors/process_map.py,sha256=rZaHUKYARvk6xbS-ZoYUWL1kCQSi2zcD9OebBcobteo,5009
+jarvis/executors/processor.py,sha256=yU8qKk_4weeN3IFjuDxfaBdjAxiz491hEvTcjc_Xdeo,5784
+jarvis/executors/remind.py,sha256=5qBNlr5anlHEh0fjBHBiNPFfhutbhuyuN8NuVrrISmI,12483
+jarvis/executors/restrictions.py,sha256=mi4mn9xBeHggpsB55rl1u0a7vL9E4pUI4kYXyA_i_jM,4040
+jarvis/executors/robinhood.py,sha256=bRowaZWQiuJAdmyfR1A7KhlizdnWxbSD-TdE3l9tVgI,4201
+jarvis/executors/simulator.py,sha256=O_w4nFaKGf-eBbt2OlLTyAK0CyzoXTLhF0A9VBGwXg8,3510
+jarvis/executors/static_responses.py,sha256=7uhdOn0b8ygPbFLz2C9O18B__Fm9TIDVVpiNCiUAjkY,3999
+jarvis/executors/system.py,sha256=4s6olCVJvn-kSWKaz8SWDrctXXetqj79yLZohg09gn4,8956
+jarvis/executors/telegram.py,sha256=KLL99Gd-r-sy9WZSG5hNuuDTG08FYc2axzzxLyT9v4k,3343
+jarvis/executors/thermostat.py,sha256=HcxpwATcu8-FwRGSgMndsFhxmXVvWPIuMofrUcludBQ,7599
+jarvis/executors/todo_list.py,sha256=UvJKY6Yg0wKMzJNvlp-BdbhL8XSOV9IEevH79eVJjPk,5380
+jarvis/executors/tv.py,sha256=jG8AzoDgAO79EIdcY4fOIKRLT4VJyzcY6EB_PKCc6Ng,7908
+jarvis/executors/tv_controls.py,sha256=02dgFJ7jf7CnFOSz6rLzzTO1hqsdi0EGBIthR64CqF4,8140
+jarvis/executors/unconditional.py,sha256=n6YJNbjoTeIPD_mhrmv2EDoAWqwgsEpZmF7tVtKOvEQ,5140
+jarvis/executors/volume.py,sha256=UsxymyhBORvF7NnrlyOUAg7uXNLWMShUEI8EIZspmI4,1924
+jarvis/executors/vpn_server.py,sha256=VKactupDQSrUFrcFJ3CEV7Q7tcb1MnSJAR-O2ZKua8k,6600
+jarvis/executors/weather.py,sha256=LviE_NxuxtDDmLEayYawC9pbK93b6VlWyYVI8gpbXXI,11002
+jarvis/executors/weather_monitor.py,sha256=_C3xBg7AgLwiu1ei-AansaWlg8vdBQALMxy8O-LH6zU,3703
+jarvis/executors/wiki.py,sha256=vdFICDjUaO1ywqYbH06MirZ-dPP8lbCrdsJH_rwxMeI,2368
+jarvis/executors/word_match.py,sha256=3ouDj-OwVYLbh1-Zk-3SPIhgp1FL1zH2F_SiblU9zdQ,1723
 jarvis/indicators/acknowledgement.mp3,sha256=P-S3PFZIeiJFqA2C5ZKtrs8mcmLEVF8nJUXyl0uetv4,9239
 jarvis/indicators/alarm.mp3,sha256=Owyx3lMW4TFcqu0RzHSfATtisCO-X2wTr5aSNOPLOO8,3087321
 jarvis/indicators/coin.mp3,sha256=aanaWMluO1qkRDUGJTSjIuhsStkuNgUxyWcI6F_AP5Q,17350
 jarvis/indicators/end.mp3,sha256=2JRvDqzUoHtKIUmK7avk6ZzkGhPXCwbkJpNPJ29saAA,9448
 jarvis/indicators/start.mp3,sha256=MbMvddN-d4RTTAXS3Hv71i3uQgpHbOB0qhK_odDDrnw,11538
-jarvis/lib/install.sh,sha256=i0aIWKnziiOeL1rsSa4HJfmO0ToUqyBP6ZsmWqy9VEo,8581
-jarvis/lib/version_locked_requirements.txt,sha256=LbRt5h6agaJIoYvsYgHQFoFuulf7-kEyDOpiEmuIQ6E,531
-jarvis/lib/version_pinned_requirements.txt,sha256=08jUSciwGol0buBR2fF0shpxMHI4sxw5YAL9oQ3faz8,515
-jarvis/lib/version_upgrade_requirements.txt,sha256=DCCJkgioBW4qMbM07ZdHzSJSkSU--yUWAnVy-QwLOI8,107
+jarvis/lib/install.sh,sha256=HD9tr2q9bEjeNJ_F6_vrOzRtvJ8vveL9ZlEC310eisU,10392
+jarvis/lib/version_locked_requirements.txt,sha256=dJDTJUmWl4Jp7x9Qr39gqOHit7LFfaM4v4D4vCArTtc,440
+jarvis/lib/version_pinned_requirements.txt,sha256=lupwhuDQyZHyFlbPKwfjcCQszANbvxsyDWT9_0_PNoU,510
+jarvis/lib/version_upgrade_requirements.txt,sha256=1yRoeTz7IuNYzGkmN15QJH4i0tHcW9G80IRdiYEAwDo,129
+jarvis/lib/squire/detector.sh,sha256=nEpQbzwMlMnnTmY-RSf7NltjhgYOhsX28rzeotPlZIE,1666
 jarvis/modules/auth_bearer.py,sha256=9oAERfASspVERGo80gLRjec8MnAThHpi8JGdGfvJEWw,1076
-jarvis/modules/builtin_overrides.py,sha256=uuytoWofdyHazMiZ45jJ4EjDZPmQJ3ZOpnruHW0vU9s,3359
-jarvis/modules/exceptions.py,sha256=nZBcoN9usJlYAQek6Pb3Xuxn8oOIy30n-HmWZdfzFso,3989
-jarvis/modules/logger.py,sha256=94r0dZEPUHCxP6qZlGDmKpXteD1oV4e-GBNCKRq87Qs,4828
-jarvis/modules/peripherals.py,sha256=CZVHz1QTr5v8RDDuhcf54M1qAaXqL9X0qzuT2YLgMAo,1401
-jarvis/modules/audio/listener.py,sha256=nes2Fn0BEOpst6lbdrLsUDwRqTKjFU0jeAdXc2GSShQ,4336
-jarvis/modules/audio/speaker.py,sha256=KkoJRQyfnvL_BSmmpBzZo9uFAL0DPaIUMyj9l30Q1jU,6049
-jarvis/modules/audio/speech_synthesis.py,sha256=gWlGfmjhlR-U-wS8SAelPwn5sdCc650BUBMsEpCKgx0,9213
-jarvis/modules/audio/tts_stt.py,sha256=cMxjvuH_tqtw6J7rdt6x_9dBKnfa2dAD82LSI4efP4o,2095
-jarvis/modules/audio/voices.py,sha256=E-RSFFqUF48UZg8cPWmFG08dZbbTVmvoFwDL4ddG8Mo,2661
-jarvis/modules/camera/camera.py,sha256=RYS1X3nNDprJ-W6-PH1mJD-Kz1kXVDzCEiwtVFrvHr0,7084
-jarvis/modules/car/connector.py,sha256=w_j8Ks-2ReCnQrYA-9FJuFXuD1mrRUVeZjJyfGaceFo,9425
-jarvis/modules/car/controller.py,sha256=QHPhjVgi5b3B5hQp8qUPHo1IiyuazcRzsN0kUiF87Dk,30541
-jarvis/modules/conditions/conversation.py,sha256=eoF4Z0cISIt0WMyr2ySa-Wha0xvq38R-n36Yaj3ORAs,2846
-jarvis/modules/conditions/keywords.py,sha256=b3n00W6OT1FVqCziXWAPe2vVVy82v7Lp5LySLizsMcs,5926
-jarvis/modules/crontab/expression.py,sha256=KiumyRpk2HQbg6aAA_w94BqmMJZpAovHGYhPqivaF3E,12259
-jarvis/modules/database/database.py,sha256=01GF_L-2G8PQkj3byBX1bBRjaSp5swMBRcpM0xqFRpI,4189
-jarvis/modules/dictionary/dictionary.py,sha256=li0X_zQXov-L2AjaWFTKf_4S4UckXSu9qQHcGGU31VY,1631
-jarvis/modules/facenet/face.py,sha256=cldWfKUPb1Q4UN_ySSroGdFCPAuKPoT-toW8LB0Z32s,7462
-jarvis/modules/lights/preset_values.py,sha256=DH_Ss-8voNvyE48jSiqRQDnJK9GijX8Y-QU6vsIMfQU,639
-jarvis/modules/lights/smart_lights.py,sha256=CDxUzP_jtgBf9P6XjXeFqJdMlDFCn4X6dKp72NUPdb4,9715
-jarvis/modules/meetings/events.py,sha256=ykny4s50_0og4FGjUxdxw5fcHZQlljSsY4HGq7r8o5Q,8208
-jarvis/modules/meetings/ics.py,sha256=SnFNF2OqH7blUHB2l3FWxCcWI1cr_HEPZtBshBjxceY,4342
-jarvis/modules/meetings/ics_meetings.py,sha256=cvnFxVRiFNHG-T0QaxK0SttAMMcmTvGyqx4Qfzg1LlM,8069
-jarvis/modules/microphone/graph_mic.py,sha256=cccsrxaTXlsbdnp0j-VBuv0G56O-xqBguPw99_pPCA0,8190
-jarvis/modules/microphone/recognizer.py,sha256=_1wZ_EVW-KCFNLjRVuEfqM32vYXFt9ugscGpWOnb9RI,2812
-jarvis/modules/models/classes.py,sha256=0gaUTTmU-sghqF4em2vTvoEjP5OxXz3K6kRv2H__vAc,19437
-jarvis/modules/models/models.py,sha256=tTXInLGm8GaPnzKBXSoiYwsCP7DMWpzbdnO-aMpon5M,11344
-jarvis/modules/retry/retry.py,sha256=xzPnVDMb88CBsuUgUYY8cd-_VIbEpbLjFqOWuCp6d2U,2920
-jarvis/modules/speaker/speak.py,sha256=Nx4MtLa9dnafpT0gphtH4GIag_jN_bbYRLAWZ80Hzns,6325
-jarvis/modules/telegram/audio_handler.py,sha256=69jUDmaojKlHNhioubhp9WEmuVZCqXUjFxebfbW_940,2023
-jarvis/modules/telegram/bot.py,sha256=bPFQm64KRFWXYDEBzzO8CRhpLPhZ0A-8iJi193lkThs,26158
-jarvis/modules/telegram/file_handler.py,sha256=p-dxscks6i0KJ1RhNRrha9uKyy4_k2EcWEpOL3mTcHQ,3401
+jarvis/modules/builtin_overrides.py,sha256=R6mnj7lQZ-GrBfeRhT2Z1tiiWeVrboX0CbSgM8Spv68,3375
+jarvis/modules/exceptions.py,sha256=9cpVg5QjFSplNZmL1VhAIIXY3ikCEgPUirHn9dORdLg,3825
+jarvis/modules/logger.py,sha256=ExiG-gsXX2CvBWgJK6kbqg-7g8vQ-eQ0LgTX0RrApLo,4898
+jarvis/modules/peripherals.py,sha256=74JHUJ-MGJ33eSuin6u6MwlmfYjFZ7FJNiKgOr2_Q7Y,1565
+jarvis/modules/audio/listener.py,sha256=DtMgkdhaHiBzfUSAd8vHA3KTAyZ9Gf9JtM90FspM-lg,4429
+jarvis/modules/audio/speaker.py,sha256=6C1ycY29lujFJSS6jTFtbXQ0lYMZqyMuPZhsX-bH0kw,6099
+jarvis/modules/audio/speech_synthesis.py,sha256=8gUg8jAfGDuGLjNKfZ2una0oNKEqk7WXqA0mzPJtgQs,9813
+jarvis/modules/audio/tts_stt.py,sha256=Nc3vtlmU1_VNC9FmgdFZeaNKqxXkpCu2eBLtqIsXmSc,2053
+jarvis/modules/audio/voices.py,sha256=M7XWBsUAcTc9oauwVzcXZhiJOdJsyT0eLubmxuU5POk,2778
+jarvis/modules/camera/camera.py,sha256=tYPvsh2zdivQfJW-rs2UZ7cU9bqtXiQmomQ-XBIonfg,7290
+jarvis/modules/conditions/conversation.py,sha256=vw8ILJikqCGR6oXKYhUE__PXN0zv2mxNL4d4Vv8qj08,3162
+jarvis/modules/conditions/keywords.py,sha256=TRTWiGHBUqDjXtJSIRmhhDqzidmCvK17CHVW3bDDkbo,7355
+jarvis/modules/crontab/expression.py,sha256=YAERbJIq2W6Qrn0n_9NaLZQD8eNAbJgvrAoRWmO0dJQ,12540
+jarvis/modules/database/database.py,sha256=TpL-Ynv-KzPkRG3VM0Y7tsthfKfCtHnh_R4a-bE8mHM,4330
+jarvis/modules/dictionary/dictionary.py,sha256=P37s2MgOUCZml4StW4gZtqM5dmkolV3DpHUa1hnb20o,1618
+jarvis/modules/facenet/face.py,sha256=4YWk3NW4n-YdibSrJSX0YrB1483l5r3HqPkPV-3QvF0,7952
+jarvis/modules/lights/preset_values.py,sha256=KrP5xsPMnoRWKdS5ssorYfI1qTnJ0Vde0SVacvFnzi4,640
+jarvis/modules/lights/smart_lights.py,sha256=vk5TQXafqOWGu9mmftuPXKxqAfnZfN11S4GRmQReOkM,10186
+jarvis/modules/meetings/events.py,sha256=v0qPpHPDb1aMZsvSi8dQGXix-d29yvOeah6NcJxga-Q,8657
+jarvis/modules/meetings/ics.py,sha256=Ae3eqjtFMqhYlRsKu-X7YVzaCwZi-mZZhz7LaG0xhlw,4832
+jarvis/modules/meetings/ics_meetings.py,sha256=23OSzbDoL_F0x1wHL2hpFSeQNX5hXjvU4teOePxcfM0,8619
+jarvis/modules/microphone/graph_mic.py,sha256=kkMKw41DORKNEwR5SvMta_ULOk0FntHOdZACwzKh2zc,8427
+jarvis/modules/microphone/recognizer.py,sha256=7La2AjmQSt5uKgnCND7eMDPhJQ5g9p1r0siYJimd7iQ,2792
+jarvis/modules/models/classes.py,sha256=1Pjkraio1Om4xrt6AKdWQ3Nu2nZLCwd12Uj_I2DVewM,21937
+jarvis/modules/models/models.py,sha256=qaM-VaMayfrYiYSoga3Gw9gXLyq1GEOgs20tS7NsS4g,11769
+jarvis/modules/retry/retry.py,sha256=PFWJfX1FqrG6l8gCs7tiMGo6eDkQvPcCZP-DmHJQYkk,2968
+jarvis/modules/speaker/speak.py,sha256=0Kv1XMWW2td-kaAowVE_P0ks51rKSFTdsgSZizY8l10,6604
+jarvis/modules/telegram/audio_handler.py,sha256=fIOBvhGA0Y1x7ARvImY_CMxY2DZ1ou5OzC69Jf-GKWI,2047
+jarvis/modules/telegram/bot.py,sha256=xER3P8818fl8qiTpPE-Uw_D6Es5tGU9ZnjPEdt_jlsM,26739
+jarvis/modules/telegram/file_handler.py,sha256=DqszcmHWmgpHdZQM5PVqJWrFVONg48UpSW4QPHtXc7g,3665
 jarvis/modules/telegram/settings.py,sha256=xEOsZwDQ0ERvQJRm2sud74bI9L_Iq-_mYlh4BeiGYhA,1766
-jarvis/modules/telegram/webhook.py,sha256=qeBwvcbQxeDy4azkNaa6zR1A5SdE0MG85A0RzsUYD48,1933
+jarvis/modules/telegram/webhook.py,sha256=aUpZXidM3o1vWHoyUwKS1gaVzUgVekhF9BQ3nWPfubc,1941
 jarvis/modules/temperature/temperature.py,sha256=Za53mzAr-IEtupRVJcKKwvi64t4KeFhWVTSBzRJcH6Q,1616
 jarvis/modules/templates/car_report.html,sha256=lkt3N2yUT4xurzBy4q-aFhcEjnX2eWOMqx-zU0BMfxo,2821
 jarvis/modules/templates/email.html,sha256=EoF5gZfeC9soJrW7pTPQo2ZtXYhTP0Zy9OxsqRZhBMA,25812
 jarvis/modules/templates/email_OTP.html,sha256=b0ddNxv-Kanm534juQmAmTjrICcHGCQCI-N6GH4gc44,3386
 jarvis/modules/templates/email_stock_alert.html,sha256=UFgfRNtL4FrHGuoFuqFgU5XuX_gYCP50JJiOG4-bGUc,412
 jarvis/modules/templates/email_threat_audio.html,sha256=Q-l0hQEVZkFS6jngZuCmA4wDCa0Uv42STW3ueqmDcuk,128
 jarvis/modules/templates/email_threat_image.html,sha256=LTZcqXml58wvXaGEZNJkXkEGisHWc0TlK7zpi-KeZwM,136
 jarvis/modules/templates/email_threat_image_audio.html,sha256=ewYVfloJRESZhTGNYQxxad9lGFic4EUY68IsHVMXLTU,180
-jarvis/modules/templates/robinhood.html,sha256=N3Lai7bm5A_r8WyRIwuu9UcFRA6jJn-gmwPxXg7oyXg,2285
-jarvis/modules/templates/surveillance.html,sha256=x3II9a41avWeJQ071dBmamnz0VQ_TzjsexRGNPzTlBg,2370
-jarvis/modules/templates/templates.py,sha256=TnJ39GHVMrQaFIlLm_ltyEIVzNbTr2Y6cXt3vo8h9xs,2059
+jarvis/modules/templates/robinhood.html,sha256=M4ptJ1gO1DKuUHrD-go6Vp22nXDPQSlRG4D7JNKQcoY,2421
+jarvis/modules/templates/surveillance.html,sha256=Jh1JwNgpfqXa1L4TOepAvd65ods-qUCuL0yaFEvY0QM,2502
+jarvis/modules/templates/templates.py,sha256=4ZgxTmwOhg9VQAeYv7RrXA7QUiyNZgNacMaZoese0wQ,2169
 jarvis/modules/templates/win_wifi_config.xml,sha256=m8b_rkpgKpXn2NfP_qRYJY2oJ5DLzlwKcYJKClL1dlM,637
-jarvis/modules/timeout/timeout.py,sha256=IJNmE_XdyN3to4JTse14ux-Yao5USR_fvLLNoN9WglQ,2070
-jarvis/modules/transformer/gpt.py,sha256=hOW3AawPZB3_-S48XA_p3wI5JIytAo4NmV5qI6Kml9I,7065
-jarvis/modules/tv/lg.py,sha256=WK31SPYliPJ9_NUyOnN89iBWIrT0wsENxf4jBdQQyJI,9402
-jarvis/modules/tv/roku.py,sha256=Mvhsd_1IarPMfu5ZHcApcWhrxMAY91TIUmEvA5_hUqI,7760
-jarvis/modules/utils/shared.py,sha256=2PI6VdndlEeyutl8uM-weASLvDhZEdSHxaEGNrHaDyI,402
-jarvis/modules/utils/support.py,sha256=nObDtMiG9YMyA4pBgs0kp09Knxx3qY7LLyW48pdEysI,20336
-jarvis/modules/utils/util.py,sha256=5ubmRjXRtzUFKCpDnYQ2NIiSJWEzvIqJAgoK1wckzc8,10011
-jarvis/modules/wakeonlan/wakeonlan.py,sha256=Y0F3c0aCy69bov9CgDbw4vjjs-5y77uUMB2IAwFu79M,2137
+jarvis/modules/timeout/timeout.py,sha256=SIU8XyksnWhNjjGkW3jo8w-c9raXRO3s04PmX65l1Eg,2189
+jarvis/modules/transformer/gpt.py,sha256=SCq3TiQSMewlZr2o08RzbNy8o3jpMG7QyM9FNBgIKik,7282
+jarvis/modules/tv/lg.py,sha256=NErzK0mBgaFLSOBdvZp7LT84O735G4o6o0tnqDfaf9g,9788
+jarvis/modules/tv/roku.py,sha256=iia2tmeEzO0KXLB2jjRdVNxcz7dCr2xOmmRadrDxkAg,7954
+jarvis/modules/utils/shared.py,sha256=a6Cd7koa1c8nmD9hmC0To6BVWUiID7a2tZk8g4Zf_gE,402
+jarvis/modules/utils/support.py,sha256=FtOuJIkhAIURYUMcc5TJUe32HFmjM_Q5zr8bt_y-Ngc,20874
+jarvis/modules/utils/util.py,sha256=t6UdbgIYWMsQn_DRoKt1H9nQ4hXosNSwVPnDzvl5VUo,10934
+jarvis/modules/wakeonlan/wakeonlan.py,sha256=OGf_0a5g0lR0Wid26yrWQr-NiN-1lF3SQ_c3dfoRILc,2164
 jarvis/scripts/applauncher.scpt,sha256=CMi4ym4LTMNi3Ln7TmclfWK4enWE3PY2S1BXmJDGi1s,1044
 jarvis/scripts/calendar.scpt,sha256=c9CNVYXGpwShrGNi1OjCQNSKy__j-MQdNxTdWwFtFCg,2750
 jarvis/scripts/outlook.scpt,sha256=e0HyaQYrCiqszI65hGNLq_H2978GngUEG-CsMCfLqp4,2504
-jarvis_ironman-4.4.2.data/scripts/install.sh,sha256=i0aIWKnziiOeL1rsSa4HJfmO0ToUqyBP6ZsmWqy9VEo,8581
-jarvis_ironman-4.4.2.dist-info/LICENSE,sha256=Mt4Kd3HfxBic9vkEe-Q9nwl27S_r0tv9ha4dcnFQXEk,1068
-jarvis_ironman-4.4.2.dist-info/METADATA,sha256=ouPAY-oKI_Z3AjiaBRbqQiQz4PcYy1dvxxfnAok65Ew,13561
-jarvis_ironman-4.4.2.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
-jarvis_ironman-4.4.2.dist-info/top_level.txt,sha256=1BOxyWfzOP_ZXj8rVTDnNCJ92bBGB0rwq8N1PCpoMIs,7
-jarvis_ironman-4.4.2.dist-info/RECORD,,
+jarvis_ironman-4.5.data/scripts/detector.sh,sha256=nEpQbzwMlMnnTmY-RSf7NltjhgYOhsX28rzeotPlZIE,1666
+jarvis_ironman-4.5.data/scripts/install.sh,sha256=HD9tr2q9bEjeNJ_F6_vrOzRtvJ8vveL9ZlEC310eisU,10392
+jarvis_ironman-4.5.dist-info/LICENSE,sha256=Mt4Kd3HfxBic9vkEe-Q9nwl27S_r0tv9ha4dcnFQXEk,1068
+jarvis_ironman-4.5.dist-info/METADATA,sha256=-t2dDcXQ_J-8Gzzb-5E2sS1RiE7Bruru9MBKDgHSdMs,15397
+jarvis_ironman-4.5.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+jarvis_ironman-4.5.dist-info/top_level.txt,sha256=1BOxyWfzOP_ZXj8rVTDnNCJ92bBGB0rwq8N1PCpoMIs,7
+jarvis_ironman-4.5.dist-info/RECORD,,
```

